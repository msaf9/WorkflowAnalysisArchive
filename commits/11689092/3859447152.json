[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -1267,7 +1267,7 @@ def _kernel(z, BLOCK: tl.constexpr,\n # ---------------\n \n \n-@pytest.mark.parametrize(\"dtype_str, size, size_diff\", [(dtype_str, size, size_diff) for dtype_str in torch_dtypes for size in [128, 512] for size_diff in [1, 2, 3, 4]])\n+@pytest.mark.parametrize(\"dtype_str, size, size_diff\", [(dtype_str, size, size_diff) for dtype_str in torch_dtypes for size in [128, 512] for size_diff in [0, 1, 2, 3, 4]])\n def test_masked_load(dtype_str, size, size_diff, device='cuda'):\n     dtype = getattr(torch, dtype_str)\n     check_type_supported(dtype)  # bfloat16 on cc < 80 will not be tested\n@@ -1286,18 +1286,18 @@ def test_masked_load(dtype_str, size, size_diff, device='cuda'):\n     def _kernel(in_ptr, out_ptr, in_size: tl.constexpr, out_size: tl.constexpr):\n         in_offsets = tl.arange(0, out_size)\n         # Load inputs.\n-        x = tl.load(in_ptr + in_offsets, mask=in_offsets < in_size, other=1)\n+        x = GENERATE_TEST_HERE\n         # Store output\n         output_offsets = tl.arange(0, out_size)\n         tl.store(out_ptr + output_offsets, x)\n \n-    _kernel[(1,)](input, output, input_size, output_size)\n+    mask_str = \"mask=in_offsets < in_size, other=1\" if size_diff > 0 else \"None\"\n+    kernel = patch_kernel(_kernel, {'GENERATE_TEST_HERE': f\"tl.load(in_ptr + in_offsets, {mask_str})\"})\n+    kernel[(1,)](input, output, input_size, output_size)\n \n-    reference_out = input\n-    reference_out = torch.cat((reference_out, torch.ones((size_diff,), dtype=dtype, device=device)))\n+    reference_out = torch.cat((input, torch.ones((size_diff,), dtype=dtype, device=device)))\n     triton.testing.allclose(output, reference_out)\n \n-# 'bfloat16': torch.bfloat16,\n # Testing masked loads with an intermate copy to shared memory run.\n \n "}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -830,9 +830,9 @@ def load(pointer, mask=None, other=None, cache_modifier=\"\", eviction_policy=\"\",\n     'type cache_modifier: str, optional\n     \"\"\"\n     # mask, other can be constexpr\n-    if mask is not None:\n+    if _constexpr_to_value(mask) is not None:\n         mask = _to_tensor(mask, _builder)\n-    if other is not None:\n+    if _constexpr_to_value(other) is not None:\n         other = _to_tensor(other, _builder)\n     cache_modifier = _constexpr_to_value(cache_modifier)\n     eviction_policy = _constexpr_to_value(eviction_policy)\n@@ -856,7 +856,7 @@ def store(pointer, value, mask=None, _builder=None):\n     \"\"\"\n     # value can be constexpr\n     value = _to_tensor(value, _builder)\n-    if mask is not None:\n+    if _constexpr_to_value(mask) is not None:\n         mask = _to_tensor(mask, _builder)\n     return semantic.store(pointer, value, mask, _builder)\n "}]