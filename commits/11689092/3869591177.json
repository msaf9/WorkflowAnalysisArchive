[{"filename": "include/triton/Target/LLVMIR/LLVMIRTranslation.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -31,8 +31,6 @@ translateTritonGPUToLLVMIR(llvm::LLVMContext *llvmContext,\n std::unique_ptr<llvm::Module>\n translateLLVMToLLVMIR(llvm::LLVMContext *llvmContext, mlir::ModuleOp module);\n \n-bool linkExternLib(llvm::Module &module, llvm::StringRef path);\n-\n } // namespace triton\n } // namespace mlir\n "}, {"filename": "lib/Target/LLVMIR/LLVMIRTranslation.cpp", "status": "modified", "additions": 127, "deletions": 75, "changes": 202, "file_content_changes": "@@ -18,6 +18,7 @@\n #include \"llvm/IRReader/IRReader.h\"\n #include \"llvm/Linker/Linker.h\"\n #include \"llvm/Support/SourceMgr.h\"\n+#include <filesystem>\n \n namespace mlir {\n namespace triton {\n@@ -26,19 +27,18 @@ namespace triton {\n // information from mlir module.\n struct NVVMMetadata {\n   int maxntidx{-1};\n-  bool is_kernel{};\n+  bool isKernel{};\n   // Free to extend with other information.\n };\n \n // Add the nvvm related metadata to LLVM IR.\n-void amendLLVMFunc(llvm::Function *func, const NVVMMetadata &metadata) {\n+static void amendLLVMFunc(llvm::Function *func, const NVVMMetadata &metadata) {\n   auto *module = func->getParent();\n   auto &ctx = func->getContext();\n \n   if (metadata.maxntidx > 0) {\n-    auto i32_ty = llvm::IntegerType::get(ctx, 32);\n-    auto warps =\n-        llvm::ConstantInt::get(i32_ty, llvm::APInt(32, metadata.maxntidx));\n+    auto warps = llvm::ConstantInt::get(llvm::IntegerType::get(ctx, 32),\n+                                        llvm::APInt(32, metadata.maxntidx));\n \n     llvm::Metadata *md_args[] = {llvm::ValueAsMetadata::get(func),\n                                  llvm::MDString::get(ctx, \"maxntidx\"),\n@@ -48,18 +48,19 @@ void amendLLVMFunc(llvm::Function *func, const NVVMMetadata &metadata) {\n         ->addOperand(llvm::MDNode::get(ctx, md_args));\n   }\n \n-  if (metadata.is_kernel) {\n-    llvm::Metadata *md_args[] = {\n+  if (metadata.isKernel) {\n+    llvm::Metadata *mdArgs[] = {\n         llvm::ValueAsMetadata::get(func), llvm::MDString::get(ctx, \"kernel\"),\n         llvm::ValueAsMetadata::get(\n             llvm::ConstantInt::get(llvm::Type::getInt32Ty(ctx), 1))};\n     module->getOrInsertNamedMetadata(\"nvvm.annotations\")\n-        ->addOperand(llvm::MDNode::get(ctx, md_args));\n+        ->addOperand(llvm::MDNode::get(ctx, mdArgs));\n   }\n }\n \n-void extractNVVMMetadata(mlir::ModuleOp module,\n-                         llvm::DenseMap<llvm::StringRef, NVVMMetadata> *dic) {\n+static void\n+extractNVVMMetadata(mlir::ModuleOp module,\n+                    llvm::DenseMap<llvm::StringRef, NVVMMetadata> *dic) {\n   for (auto op : module.getOps<LLVM::LLVMFuncOp>()) {\n     NVVMMetadata meta;\n \n@@ -74,7 +75,7 @@ void extractNVVMMetadata(mlir::ModuleOp module,\n \n     // kernel\n     if (op->hasAttr(\"nvvm.kernel\")) {\n-      meta.is_kernel = true;\n+      meta.isKernel = true;\n       hasMetadata = true;\n     }\n \n@@ -83,13 +84,109 @@ void extractNVVMMetadata(mlir::ModuleOp module,\n   }\n }\n \n+static std::map<std::string, std::string> getExternLibs(mlir::ModuleOp module) {\n+  std::map<std::string, std::string> externLibs;\n+  SmallVector<LLVM::LLVMFuncOp> funcs;\n+  module.walk([&](LLVM::LLVMFuncOp func) {\n+    if (func.isExternal())\n+      funcs.push_back(func);\n+  });\n+\n+  for (auto &func : funcs) {\n+    if (func.getOperation()->hasAttr(\"libname\")) {\n+      auto name =\n+          func.getOperation()->getAttr(\"libname\").dyn_cast<StringAttr>();\n+      auto path =\n+          func.getOperation()->getAttr(\"libpath\").dyn_cast<StringAttr>();\n+      if (name) {\n+        std::string libName = name.str();\n+        externLibs[libName] = path.str();\n+      }\n+    }\n+  }\n+\n+  if (module.getOperation()->hasAttr(\"triton_gpu.externs\")) {\n+    auto dict = module.getOperation()\n+                    ->getAttr(\"triton_gpu.externs\")\n+                    .dyn_cast<DictionaryAttr>();\n+    for (auto &attr : dict) {\n+      externLibs[attr.getName().strref().trim().str()] =\n+          attr.getValue().dyn_cast<StringAttr>().strref().trim().str();\n+    }\n+  }\n+\n+  if (!funcs.empty()) {\n+    // When using the Math Dialect, it is possible that some ops (e.g., log) are\n+    // lowered to a function call. In this case, we need to link libdevice\n+    // using its default path:\n+    // [triton root dir]/python/triton/language/libdevice.10.bc\n+    // TODO(Keren): handle external linkage other than libdevice?\n+    namespace fs = std::filesystem;\n+    static const std::string libdevice = \"libdevice\";\n+    static const std::filesystem::path path = std::filesystem::path(__FILE__)\n+                                                  .parent_path()\n+                                                  .parent_path()\n+                                                  .parent_path()\n+                                                  .parent_path() /\n+                                              \"python\" / \"triton\" / \"language\" /\n+                                              \"libdevice.10.bc\";\n+    externLibs.try_emplace(libdevice, path.string());\n+  }\n+\n+  return externLibs;\n+}\n+\n+static void linkLibdevice(llvm::Module &module) {\n+  // please check https://llvm.org/docs/NVPTXUsage.html#reflection-parameters\n+  // this will enable fast math path in libdevice\n+  // for example, when enable nvvm-reflect-ftz, sqrt.approx.f32 will change to\n+  // sqrt.approx.ftz.f32\n+  auto &ctx = module.getContext();\n+  llvm::Type *i32 = llvm::Type::getInt32Ty(ctx);\n+  llvm::Metadata *mdFour =\n+      llvm::ConstantAsMetadata::get(llvm::ConstantInt::getSigned(i32, 4));\n+  llvm::Metadata *mdName = llvm::MDString::get(ctx, \"nvvm-reflect-ftz\");\n+  llvm::Metadata *mdOne =\n+      llvm::ConstantAsMetadata::get(llvm::ConstantInt::getSigned(i32, 1));\n+  llvm::MDNode *reflect = llvm::MDNode::get(ctx, {mdFour, mdName, mdOne});\n+  module.addModuleFlag(reflect);\n+}\n+\n+static bool linkExternLib(llvm::Module &module, llvm::StringRef name,\n+                          llvm::StringRef path) {\n+  llvm::SMDiagnostic err;\n+  auto &ctx = module.getContext();\n+\n+  auto extMod = llvm::parseIRFile(path, err, ctx);\n+  if (!extMod) {\n+    llvm::errs() << \"Failed to load \" << path;\n+    return true;\n+  }\n+\n+  extMod->setTargetTriple(module.getTargetTriple());\n+  extMod->setDataLayout(module.getDataLayout());\n+\n+  if (llvm::Linker::linkModules(module, std::move(extMod),\n+                                llvm::Linker::Flags::LinkOnlyNeeded)) {\n+    llvm::errs() << \"Failed to link \" << path;\n+    return true;\n+  }\n+\n+  if (name == \"libdevice\") {\n+    linkLibdevice(module);\n+  } else {\n+    assert(false && \"unknown extern lib: \");\n+  }\n+\n+  return false;\n+}\n+\n std::unique_ptr<llvm::Module>\n translateLLVMToLLVMIR(llvm::LLVMContext *llvmContext, mlir::ModuleOp module) {\n-  auto context = module->getContext();\n   DialectRegistry registry;\n   mlir::registerLLVMDialectTranslation(registry);\n   mlir::registerNVVMDialectTranslation(registry);\n-  context->appendDialectRegistry(registry);\n+  module->getContext()->appendDialectRegistry(registry);\n \n   llvm::DenseMap<llvm::StringRef, NVVMMetadata> nvvmMetadata;\n   extractNVVMMetadata(module, &nvvmMetadata);\n@@ -100,6 +197,20 @@ translateLLVMToLLVMIR(llvm::LLVMContext *llvmContext, mlir::ModuleOp module) {\n     return nullptr;\n   }\n \n+  // Link external libraries before perform optimizations\n+  // Note from libdevice users guide:\n+  // https://docs.nvidia.com/cuda/libdevice-users-guide/basic-usage.html\n+  // The standard process for linking with libdevice is to first link it with\n+  // the target module, then run the standard LLVM optimization and code\n+  // generation passes. This allows the optimizers to inline and perform\n+  // analyses on the used library functions, and eliminate any used functions as\n+  // dead code.\n+  auto externLibs = getExternLibs(module);\n+  for (auto &lib : externLibs) {\n+    if (linkExternLib(*llvmModule, lib.first, lib.second))\n+      return nullptr;\n+  }\n+\n   auto optPipeline = mlir::makeOptimizingTransformer(\n       /*optLevel=*/3, /*sizeLevel=*/0,\n       /*targetMachine=*/nullptr);\n@@ -147,49 +258,12 @@ translateTritonGPUToLLVMIR(llvm::LLVMContext *llvmContext,\n     return nullptr;\n   }\n \n-  std::map<std::string, std::string> externLibs;\n-  SmallVector<LLVM::LLVMFuncOp> funcs;\n-  module.walk([&](LLVM::LLVMFuncOp func) {\n-    if (func.isExternal())\n-      funcs.push_back(func);\n-  });\n-\n-  for (auto &func : funcs) {\n-    if (func.getOperation()->hasAttr(\"libname\")) {\n-      auto name =\n-          func.getOperation()->getAttr(\"libname\").dyn_cast<StringAttr>();\n-      auto path =\n-          func.getOperation()->getAttr(\"libpath\").dyn_cast<StringAttr>();\n-      if (name) {\n-        std::string lib_name = name.str();\n-        externLibs[lib_name] = path.str();\n-      }\n-    }\n-  }\n-\n-  if (module.getOperation()->hasAttr(\"triton_gpu.externs\")) {\n-    auto dict = module.getOperation()\n-                    ->getAttr(\"triton_gpu.externs\")\n-                    .dyn_cast<DictionaryAttr>();\n-    for (auto &attr : dict) {\n-      externLibs[attr.getName().strref().trim().str()] =\n-          attr.getValue().dyn_cast<StringAttr>().strref().trim().str();\n-    }\n-  }\n-\n-  auto llvmir = translateLLVMToLLVMIR(llvmContext, module);\n-  if (!llvmir) {\n+  auto llvmIR = translateLLVMToLLVMIR(llvmContext, module);\n+  if (!llvmIR) {\n     llvm::errs() << \"Translate to LLVM IR failed\";\n     return nullptr;\n   }\n-\n-  llvm::SMDiagnostic err;\n-  for (auto &lib : externLibs) {\n-    if (linkExternLib(*llvmir, lib.second))\n-      return nullptr;\n-  }\n-\n-  return llvmir;\n+  return llvmIR;\n }\n \n void addExternalLibs(mlir::ModuleOp &module,\n@@ -211,27 +285,5 @@ void addExternalLibs(mlir::ModuleOp &module,\n   module.getOperation()->setAttr(\"triton_gpu.externs\", dict);\n }\n \n-bool linkExternLib(llvm::Module &module, llvm::StringRef path) {\n-  llvm::SMDiagnostic err;\n-  auto &ctx = module.getContext();\n-\n-  auto extMod = llvm::parseIRFile(path, err, ctx);\n-  if (!extMod) {\n-    llvm::errs() << \"Failed to load \" << path;\n-    return true;\n-  }\n-\n-  extMod->setTargetTriple(module.getTargetTriple());\n-  extMod->setDataLayout(module.getDataLayout());\n-\n-  if (llvm::Linker::linkModules(module, std::move(extMod),\n-                                llvm::Linker::Flags::LinkOnlyNeeded)) {\n-    llvm::errs() << \"Failed to link \" << path;\n-    return true;\n-  }\n-\n-  return false;\n-}\n-\n } // namespace triton\n } // namespace mlir"}, {"filename": "lib/Target/PTX/PTXTranslation.cpp", "status": "modified", "additions": 0, "deletions": 41, "changes": 41, "file_content_changes": "@@ -8,7 +8,6 @@\n #include \"llvm/MC/TargetRegistry.h\"\n #include \"llvm/Support/TargetSelect.h\"\n #include \"llvm/Target/TargetMachine.h\"\n-#include <filesystem>\n \n namespace triton {\n \n@@ -31,47 +30,7 @@ static bool findAndReplace(std::string &str, const std::string &begin,\n   return true;\n }\n \n-static void linkExternal(llvm::Module &module) {\n-  bool hasExternal = false;\n-  for (auto &func : module) {\n-    if (func.hasExternalLinkage()) {\n-      hasExternal = true;\n-      break;\n-    }\n-  }\n-\n-  if (hasExternal) {\n-    namespace fs = std::filesystem;\n-    // [triton root dir]/python/triton/language/libdevice.10.bc\n-    static const fs::path libdevice = fs::path(__FILE__)\n-                                          .parent_path()\n-                                          .parent_path()\n-                                          .parent_path()\n-                                          .parent_path() /\n-                                      \"python\" / \"triton\" / \"language\" /\n-                                      \"libdevice.10.bc\";\n-    if (mlir::triton::linkExternLib(module, libdevice.string()))\n-      llvm::errs() << \"link failed for: \" << libdevice.string();\n-\n-    // please check https://llvm.org/docs/NVPTXUsage.html#reflection-parameters\n-    // this will enable fast math path in libdevice\n-    // for example, when enable nvvm-reflect-ftz, sqrt.approx.f32 will change to\n-    // sqrt.approx.ftz.f32\n-    auto &ctx = module.getContext();\n-    llvm::Type *I32 = llvm::Type::getInt32Ty(ctx);\n-    llvm::Metadata *mdFour =\n-        llvm::ConstantAsMetadata::get(llvm::ConstantInt::getSigned(I32, 4));\n-    llvm::Metadata *mdName = llvm::MDString::get(ctx, \"nvvm-reflect-ftz\");\n-    llvm::Metadata *mdOne =\n-        llvm::ConstantAsMetadata::get(llvm::ConstantInt::getSigned(I32, 1));\n-    llvm::MDNode *reflect = llvm::MDNode::get(ctx, {mdFour, mdName, mdOne});\n-    module.addModuleFlag(reflect);\n-  }\n-}\n-\n std::string translateLLVMIRToPTX(llvm::Module &module, int cc, int version) {\n-  linkExternal(module);\n-\n   // LLVM version in use may not officially support target hardware\n   int maxNNVMCC = 75;\n   // options"}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -1116,11 +1116,13 @@ def xor_sum(input: tl.tensor, axis: int, builder: ir.builder) -> tl.tensor:\n \n def umulhi(x: tl.tensor, y: tl.tensor, builder: ir.builder) -> tl.tensor:\n     x, y = binary_op_type_checking_impl(x, y, builder)\n+    # FIXME(Keren): not portable, should be fixed\n     from . import libdevice\n     return libdevice.mulhi(x, y, _builder=builder)\n \n \n def floor(x: tl.tensor, builder: ir.builder) -> tl.tensor:\n+    # FIXME(Keren): not portable, should be fixed\n     from . import libdevice\n     return libdevice.floor(x, _builder=builder)\n "}]