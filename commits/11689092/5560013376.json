[{"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -809,11 +809,11 @@ void LoopPipeliner::prefetchNextIteration(scf::ForOp newForOp,\n                                     nextIV, newForOp.getUpperBound());\n \n   pipelineIterIdx = newForOp.getRegionIterArgs()[ivIndex + 1];\n-  Value insertSliceIndex = builder.create<arith::RemSIOp>(\n+  Value insertSliceIndex = builder.create<arith::RemUIOp>(\n       nextIV.getLoc(), pipelineIterIdx,\n       builder.create<arith::ConstantIntOp>(nextIV.getLoc(), numStages, 32));\n   loopIterIdx = newForOp.getRegionIterArgs()[ivIndex + 2];\n-  Value extractSliceIndex = builder.create<arith::RemSIOp>(\n+  Value extractSliceIndex = builder.create<arith::RemUIOp>(\n       nextIV.getLoc(), loopIterIdx,\n       builder.create<arith::ConstantIntOp>(nextIV.getLoc(), numStages, 32));\n "}, {"filename": "python/setup.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -125,8 +125,8 @@ def download_and_copy_ptxas():\n \n     base_dir = os.path.dirname(__file__)\n     src_path = \"bin/ptxas\"\n-    version = \"12.1.105\"\n-    url = f\"https://conda.anaconda.org/nvidia/label/cuda-12.1.1/linux-64/cuda-nvcc-{version}-0.tar.bz2\"\n+    version = \"12.2.91\"\n+    url = f\"https://conda.anaconda.org/nvidia/label/cuda-12.2.0/linux-64/cuda-nvcc-{version}-0.tar.bz2\"\n     dst_prefix = os.path.join(base_dir, \"triton\")\n     dst_suffix = os.path.join(\"third_party\", \"cuda\", src_path)\n     dst_path = os.path.join(dst_prefix, dst_suffix)"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 25, "deletions": 3, "changes": 28, "file_content_changes": "@@ -7,7 +7,7 @@\n \n from .._C.libtriton.triton import ir\n from ..runtime.jit import jit\n-from . import semantic\n+from . import math, semantic\n \n T = TypeVar('T')\n \n@@ -1422,6 +1422,11 @@ def _argmax_combine_tie_break_fast(value1, index1, value2, index2):\n     return _argmax_combine(value1, index1, value2, index2, False)\n \n \n+@jit\n+def _fast_max(x, y):\n+    return math.max(x, y)\n+\n+\n @jit\n @_add_reduction_docstr(\"maximum\",\n                        return_indices_arg=\"return_indices\",\n@@ -1434,7 +1439,13 @@ def max(input, axis=None, return_indices=False, return_indices_tie_break_left=Tr\n         else:\n             return _reduce_with_indices(input, axis, _argmax_combine_tie_break_fast)\n     else:\n-        return reduce(input, axis, maximum)\n+        if constexpr(input.dtype.primitive_bitwidth) < 32:\n+            if constexpr(input.dtype.is_floating()):\n+                input = input.to(float32)\n+            else:\n+                assert input.dtype.is_integer_type()\n+                input = input.to(int32)\n+        return reduce(input, axis, _fast_max)\n \n \n @jit\n@@ -1468,6 +1479,11 @@ def _argmin_combine_tie_break_fast(value1, index1, value2, index2):\n     return _argmin_combine(value1, index1, value2, index2, False)\n \n \n+@jit\n+def _fast_min(x, y):\n+    return math.min(x, y)\n+\n+\n @jit\n @_add_reduction_docstr(\"minimum\",\n                        return_indices_arg=\"return_indices\",\n@@ -1480,7 +1496,13 @@ def min(input, axis=None, return_indices=False, return_indices_tie_break_left=Tr\n         else:\n             return _reduce_with_indices(input, axis, _argmin_combine_tie_break_fast)\n     else:\n-        return reduce(input, axis, minimum)\n+        if constexpr(input.dtype.primitive_bitwidth) < 32:\n+            if constexpr(input.dtype.is_floating()):\n+                input = input.to(float32)\n+            else:\n+                assert input.dtype.is_integer_type()\n+                input = input.to(int32)\n+        return reduce(input, axis, _fast_min)\n \n \n @jit"}, {"filename": "python/triton/third_party/cuda/bin/ptxas", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "file_content_changes": "@@ -13,6 +13,11 @@\n import triton.language as tl\n \n \n+@triton.jit\n+def max_fn(x, y):\n+    return tl.math.max(x, y)\n+\n+\n @triton.jit\n def _fwd_kernel(\n     Q, K, V, sm_scale,"}, {"filename": "test/TritonGPU/loop-pipeline.mlir", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -37,8 +37,8 @@\n // CHECK:   %[[arg_b0_dot_op_0:.*]] = triton_gpu.convert_layout %[[arg_b0]]\n // CHECK:   %[[arg_b0_dot_op_1:.*]] = arith.mulf %[[arg_b0_dot_op_0]]\n // CHECK:   tt.dot %[[arg_a0_dot_op]], %[[arg_b0_dot_op_1]], {{.*}}\n-// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n-// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remui %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remui %[[LOOP_IDX]], %[[CONSTANT_3]]\n // CHECK:   %[[NEXT_A_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:   %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:   triton_gpu.async_wait {num = 2 : i32}\n@@ -110,8 +110,8 @@ tt.func @matmul_loop(%lb : index, %ub : index, %step : index,\n // CHECK:     %[[arg_a0_dot_op:.*]] = triton_gpu.convert_layout %[[arg_a0]]\n // CHECK:     %[[arg_b0_dot_op:.*]] = triton_gpu.convert_layout %[[arg_b0]]\n // CHECK:     tt.dot %[[arg_a0_dot_op]], %[[arg_b0_dot_op]], {{.*}}\n-// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n-// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remui %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remui %[[LOOP_IDX]], %[[CONSTANT_3]]\n // CHECK:     %[[NEXT_A_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:     %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:     triton_gpu.async_wait {num = 2 : i32}\n@@ -179,8 +179,8 @@ tt.func @matmul_loop_nested(%lb : index, %ub : index, %step : index,\n // CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_1]]\n // CHECK:   %[[arg_b0_dot_op:.*]] = triton_gpu.convert_layout %[[arg_b0]]\n // CHECK:   tt.dot {{.*}}, %[[arg_b0_dot_op]], {{.*}}\n-// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n-// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remui %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remui %[[LOOP_IDX]], %[[CONSTANT_3]]\n // CHECK:   %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:   triton_gpu.async_wait {num = 1 : i32}\n // CHECK:   %[[NEXT_B:.*]] = triton_gpu.extract_slice %[[NEXT_B_BUFFER]][%[[EXTRACT_IDX]], 0, 0]"}]