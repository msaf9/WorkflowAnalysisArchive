[{"filename": "python/triton/compiler.py", "status": "modified", "additions": 9, "deletions": 2, "changes": 11, "file_content_changes": "@@ -969,6 +969,13 @@ def _build(name, src, path):\n     return so\n \n \n+def binary_name_to_header_name(name):\n+    if len(name) > 128:\n+        # avoid filename too long errors (filename limit is 255)\n+        name = \"kernel_\" + hashlib.sha256(name.encode(\"utf-8\")).hexdigest()\n+    return f\"{name}.h\"\n+\n+\n def generate_torch_glue(kernel_name, constants, signature, num_warps, binaries, tmpdir):\n     headers = dict()\n \n@@ -981,7 +988,7 @@ def generate_torch_glue(kernel_name, constants, signature, num_warps, binaries,\n const char* {name}_ptx = R\"({bin[\"ptx\"]})\";\n unsigned char {name}_bin[] = {{ {','.join(map(hex, bin[\"cubin\"]))} }};\n unsigned int {name}_shmem = {shmem_size};\"\"\"\n-        headers[name] = os.path.join(tmpdir, f\"{name}.h\")\n+        headers[name] = os.path.join(tmpdir, binary_name_to_header_name(name))\n         with open(headers[name], \"w\") as f:\n             f.write(initializer)\n \n@@ -1018,7 +1025,7 @@ def format_of(ty):\n     # generate glue code\n     src = \"\"\n     for bin, shmem_size, name in binaries:\n-        src += f\"#include \\\"{name}.h\\\"\\n\"\n+        src += f\"#include \\\"{headers[name]}\\\"\\n\"\n     src += f\"\"\"\n #include \\\"cuda.h\\\"\n #include <Python.h>"}]