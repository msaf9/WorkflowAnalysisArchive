[{"filename": "include/triton/Dialect/Triton/IR/Dialect.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "file_content_changes": "@@ -25,6 +25,10 @@ class DialectInferLayoutInterface\n public:\n   DialectInferLayoutInterface(Dialect *dialect) : Base(dialect) {}\n \n+  virtual LogicalResult\n+  inferTransOpEncoding(Attribute operandEncoding,\n+                       Attribute &resultEncoding) const = 0;\n+\n   virtual LogicalResult\n   inferReduceOpEncoding(Attribute operandEncoding, unsigned axis,\n                         Attribute &resultEncoding) const = 0;"}, {"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -289,7 +289,7 @@ def TT_CatOp : TT_Op<\"cat\", [NoSideEffect,\n }\n \n def TT_TransOp : TT_Op<\"trans\", [NoSideEffect,\n-                                 SameOperandsAndResultElementType]> {\n+                                 DeclareOpInterfaceMethods<InferTypeOpInterface>]> {\n \n     let summary = \"transpose a tensor\";\n "}, {"filename": "include/triton/Dialect/TritonGPU/Transforms/Passes.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "file_content_changes": "@@ -13,6 +13,10 @@ std::unique_ptr<Pass> createTritonGPUCanonicalizeLoopsPass();\n \n std::unique_ptr<Pass> createTritonGPUCoalescePass();\n \n+std::unique_ptr<Pass> createTritonGPUReorderInstructionsPass();\n+\n+std::unique_ptr<Pass> createTritonGPUDecomposeConversionsPass();\n+\n std::unique_ptr<Pass> createTritonGPUCombineOpsPass(int computeCapability = 80);\n \n std::unique_ptr<Pass> createTritonGPUVerifier();"}, {"filename": "include/triton/Dialect/TritonGPU/Transforms/Passes.td", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "file_content_changes": "@@ -71,6 +71,30 @@ def TritonGPUCombineOps : Pass<\"tritongpu-combine\", \"mlir::ModuleOp\"> {\n   ];\n }\n \n+def TritonGPUReorderInstructions: Pass<\"tritongpu-reorder-instructions\", \"mlir::ModuleOp\"> {\n+  let summary = \"Reorder instructions\";\n+\n+  let description = \"This pass reorder instructions so as to (1) decrease register pressure (e.g., by moving \"\n+                    \"conversions from shared memory before their first use) and (2) promote LLVM instruction \"\n+                    \"order more friendly to `ptxas`.\";\n+\n+  let constructor = \"mlir::createTritonGPUReorderInstructionsPass()\";\n+\n+  let dependentDialects = [\"mlir::triton::gpu::TritonGPUDialect\",\n+                           \"mlir::triton::TritonDialect\"];\n+}\n+\n+def TritonGPUDecomposeConversions: Pass<\"tritongpu-decompose-conversions\", \"mlir::ModuleOp\"> {\n+  let summary = \"Decompose convert[distributed -> dotOperand] into convert[distributed -> shared -> dotOperand]\";\n+\n+  let description = \"Decomposing conversions this way makes it possible to use CSE and re-use #shared tensors\";\n+\n+  let constructor = \"mlir::createTritonGPUDecomposeConversionsPass()\";\n+\n+  let dependentDialects = [\"mlir::triton::gpu::TritonGPUDialect\",\n+                           \"mlir::triton::TritonDialect\"];\n+}\n+\n def TritonGPUCanonicalizeLoops: Pass<\"tritongpu-canonicalize-loops\", \"mlir::ModuleOp\"> {\n   let summary = \"canonicalize scf.ForOp ops\";\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -251,7 +251,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     // z = 0b00000zzzz\n     // then (x + y) XOR z = 0byyyyxxxx XOR 0b00000zzzz = (x XOR z) + y\n     // This means that we can use some immediate offsets for shared memory\n-    // operations. More specifically\n+    // operations.\n     auto dstPtrTy = ptr_ty(resElemTy, 3);\n     auto dstOffset = dot(rewriter, loc, offsetVals, smemObj.strides);\n     Value dstPtrBase = gep(dstPtrTy, smemObj.base, dstOffset);"}, {"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 1, "deletions": 14, "changes": 15, "file_content_changes": "@@ -319,20 +319,7 @@ struct TritonTransPattern : public OpConversionPattern<triton::TransOp> {\n       src = rewriter.create<triton::gpu::ConvertLayoutOp>(src.getLoc(), srcType,\n                                                           src);\n     }\n-    auto srcSharedEncoding =\n-        srcEncoding.cast<triton::gpu::SharedEncodingAttr>();\n-    SmallVector<unsigned> retOrder(srcSharedEncoding.getOrder().begin(),\n-                                   srcSharedEncoding.getOrder().end());\n-    SmallVector<int64_t> retShapes(srcType.getShape().begin(),\n-                                   srcType.getShape().end());\n-    std::reverse(retOrder.begin(), retOrder.end());\n-    std::reverse(retShapes.begin(), retShapes.end());\n-    auto retEncoding =\n-        triton::gpu::SharedEncodingAttr::get(getContext(), 1, 1, 1, retOrder);\n-    auto retType =\n-        RankedTensorType::get(retShapes, srcType.getElementType(), retEncoding);\n-\n-    rewriter.replaceOpWithNewOp<triton::TransOp>(op, retType, src);\n+    rewriter.replaceOpWithNewOp<triton::TransOp>(op, src);\n     return success();\n   }\n };"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "file_content_changes": "@@ -206,6 +206,33 @@ void LoadOp::build(::mlir::OpBuilder &builder, ::mlir::OperationState &state,\n   state.addTypes({resultType});\n }\n \n+//-- TransOp --\n+mlir::LogicalResult mlir::triton::TransOp::inferReturnTypes(\n+    MLIRContext *context, Optional<Location> location, ValueRange operands,\n+    DictionaryAttr attributes, RegionRange regions,\n+    SmallVectorImpl<Type> &inferredReturnTypes) {\n+  // type is the same as the input\n+  auto argTy = operands[0].getType().cast<RankedTensorType>();\n+  SmallVector<int64_t> retShape(argTy.getShape().begin(),\n+                                argTy.getShape().end());\n+  std::reverse(retShape.begin(), retShape.end());\n+  auto retEltTy = argTy.getElementType();\n+  Attribute argEncoding = argTy.getEncoding();\n+  Attribute retEncoding;\n+  if (argEncoding) {\n+    Dialect &dialect = argEncoding.getDialect();\n+    auto inferLayoutInterface = dyn_cast<DialectInferLayoutInterface>(&dialect);\n+    if (inferLayoutInterface->inferTransOpEncoding(argEncoding, retEncoding)\n+            .failed()) {\n+      llvm::report_fatal_error(\"failed to infer layout for ReduceOp\");\n+      return mlir::failure();\n+    }\n+  }\n+  inferredReturnTypes.push_back(\n+      RankedTensorType::get(retShape, retEltTy, retEncoding));\n+  return mlir::success();\n+}\n+\n //-- DotOp --\n mlir::LogicalResult mlir::triton::DotOp::inferReturnTypes(\n     MLIRContext *context, Optional<Location> location, ValueRange operands,"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 24, "deletions": 2, "changes": 26, "file_content_changes": "@@ -104,7 +104,10 @@ SmallVector<unsigned> getSizePerThread(const Attribute &layout) {\n     return SmallVector<unsigned>(blockedLayout.getSizePerThread().begin(),\n                                  blockedLayout.getSizePerThread().end());\n   } else if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n-    return getSizePerThread(sliceLayout.getParent());\n+    auto ret = getSizePerThread(sliceLayout.getParent());\n+    return ret;\n+    // ret.erase(ret.begin() + sliceLayout.getDim());\n+    return ret;\n   } else if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n     if (mmaLayout.isAmpere()) {\n       return {2, 2};\n@@ -158,7 +161,11 @@ SmallVector<unsigned> getThreadsPerCTA(const Attribute &layout) {\n       threads.push_back(blockedLayout.getThreadsPerWarp()[d] *\n                         blockedLayout.getWarpsPerCTA()[d]);\n   } else if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n-    assert(0 && \"Unimplemented usage of MmaEncodingAttr\");\n+    if (mmaLayout.getVersionMajor() == 2) {\n+      threads = {8 * mmaLayout.getWarpsPerCTA()[0],\n+                 4 * mmaLayout.getWarpsPerCTA()[1]};\n+    } else\n+      assert(0 && \"Unimplemented usage of MmaEncodingAttr\");\n   } else {\n     assert(0 && \"Unimplemented usage of getShapePerCTA\");\n   }\n@@ -734,6 +741,21 @@ struct TritonGPUInferLayoutInterface\n     return success();\n   }\n \n+  LogicalResult inferTransOpEncoding(Attribute operandEncoding,\n+                                     Attribute &resultEncoding) const override {\n+    SharedEncodingAttr sharedEncoding =\n+        operandEncoding.dyn_cast<SharedEncodingAttr>();\n+    if (!sharedEncoding)\n+      return failure();\n+    SmallVector<unsigned> retOrder(sharedEncoding.getOrder().begin(),\n+                                   sharedEncoding.getOrder().end());\n+    std::reverse(retOrder.begin(), retOrder.end());\n+    resultEncoding = SharedEncodingAttr::get(\n+        getDialect()->getContext(), sharedEncoding.getVec(),\n+        sharedEncoding.getPerPhase(), sharedEncoding.getMaxPhase(), retOrder);\n+    return mlir::success();\n+  }\n+\n   LogicalResult\n   inferExpandDimsOpEncoding(Attribute operandEncoding, unsigned axis,\n                             Attribute &resultEncoding,"}, {"filename": "lib/Dialect/TritonGPU/Transforms/CMakeLists.txt", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -8,6 +8,8 @@ add_mlir_dialect_library(TritonGPUTransforms\n   Combine.cpp\n   Pipeline.cpp\n   Prefetch.cpp\n+  ReorderInstructions.cpp\n+  DecomposeConversions.cpp\n   TritonGPUConversion.cpp\n \n   DEPENDS"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 107, "deletions": 1, "changes": 108, "file_content_changes": "@@ -482,7 +482,7 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n       return op->getBlock() == cvt->getBlock() &&\n              !(isa<triton::ReduceOp>(op) &&\n                !op->getResult(0).getType().isa<RankedTensorType>()) &&\n-             !isa<scf::YieldOp>(op);\n+             !isa<triton::gpu::ConvertLayoutOp>(op) && !isa<scf::YieldOp>(op);\n     };\n     mlir::getForwardSlice(cvt.getResult(), &cvtSlices, filter);\n     if (cvtSlices.empty())\n@@ -1255,6 +1255,110 @@ class CollectMmaToUpdateForVolta : public mlir::RewritePattern {\n   }\n };\n \n+// Convert + trans + convert\n+// x = convert_layout distributed -> #shared_x\n+// y = trans x -> #shared_y\n+// z = convert_layout y -> #dot_operand\n+class ConvertTransConvert : public mlir::RewritePattern {\n+\n+public:\n+  ConvertTransConvert(mlir::MLIRContext *context)\n+      : mlir::RewritePattern(triton::gpu::ConvertLayoutOp::getOperationName(),\n+                             1, context) {}\n+\n+  LogicalResult\n+  matchAndRewrite(mlir::Operation *op,\n+                  mlir::PatternRewriter &rewriter) const override {\n+    auto dstOp = cast<triton::gpu::ConvertLayoutOp>(op);\n+    auto tmpOp = dyn_cast_or_null<triton::TransOp>(dstOp.src().getDefiningOp());\n+    if (!tmpOp)\n+      return mlir::failure();\n+    auto srcOp = dyn_cast_or_null<triton::gpu::ConvertLayoutOp>(\n+        tmpOp.src().getDefiningOp());\n+    if (!srcOp)\n+      return mlir::failure();\n+    auto arg = srcOp.src();\n+    auto X = tmpOp.src();\n+    auto Y = dstOp.src();\n+    // types\n+    auto argType = arg.getType().cast<RankedTensorType>();\n+    auto XType = X.getType().cast<RankedTensorType>();\n+    auto YType = Y.getType().cast<RankedTensorType>();\n+    auto ZType = dstOp.getResult().getType().cast<RankedTensorType>();\n+    // encodings\n+    auto argEncoding = argType.getEncoding();\n+    auto XEncoding =\n+        XType.getEncoding().cast<triton::gpu::SharedEncodingAttr>();\n+    auto YEncoding =\n+        YType.getEncoding().cast<triton::gpu::SharedEncodingAttr>();\n+    auto ZEncoding =\n+        ZType.getEncoding().dyn_cast<triton::gpu::DotOperandEncodingAttr>();\n+    if (!ZEncoding)\n+      return mlir::failure();\n+    // new X encoding\n+    auto newXOrder = triton::gpu::getOrder(argEncoding);\n+    auto newXEncoding = triton::gpu::SharedEncodingAttr::get(\n+        getContext(), ZEncoding, XType.getShape(), newXOrder,\n+        XType.getElementType());\n+    auto newXType = RankedTensorType::get(XType.getShape(),\n+                                          XType.getElementType(), newXEncoding);\n+    if (XEncoding == newXEncoding)\n+      return mlir::failure();\n+\n+    auto newX = rewriter.create<triton::gpu::ConvertLayoutOp>(srcOp.getLoc(),\n+                                                              newXType, arg);\n+    auto newY = rewriter.create<triton::TransOp>(tmpOp.getLoc(), newX);\n+    rewriter.replaceOpWithNewOp<triton::gpu::ConvertLayoutOp>(dstOp, ZType,\n+                                                              newY);\n+    return mlir::success();\n+  }\n+};\n+\n+//\n+class ConvertDotConvert : public mlir::RewritePattern {\n+public:\n+  ConvertDotConvert(mlir::MLIRContext *context)\n+      : mlir::RewritePattern(triton::gpu::ConvertLayoutOp::getOperationName(),\n+                             1, context) {}\n+\n+  LogicalResult\n+  matchAndRewrite(mlir::Operation *op,\n+                  mlir::PatternRewriter &rewriter) const override {\n+    auto dstOp = cast<triton::gpu::ConvertLayoutOp>(op);\n+    auto dotOp = dyn_cast_or_null<triton::DotOp>(dstOp.src().getDefiningOp());\n+    if (!dotOp)\n+      return mlir::failure();\n+    if (std::distance(dstOp->user_begin(), dstOp->user_end()) != 1 ||\n+        std::distance(dotOp->user_begin(), dotOp->user_end()) != 1)\n+      return mlir::failure();\n+    auto cvtOp = dyn_cast_or_null<triton::gpu::ConvertLayoutOp>(\n+        dotOp.getOperand(2).getDefiningOp());\n+    if (!cvtOp)\n+      return mlir::failure();\n+    auto loadOp = dyn_cast_or_null<triton::LoadOp>(cvtOp.src().getDefiningOp());\n+    if (!loadOp)\n+      return mlir::failure();\n+    auto dstTy = dstOp.getResult().getType().cast<RankedTensorType>();\n+    auto srcTy = cvtOp.getOperand().getType().cast<RankedTensorType>();\n+    if (dstTy != srcTy)\n+      return mlir::failure();\n+\n+    // TODO: int tensor cores\n+    auto _0f = rewriter.create<arith::ConstantFloatOp>(\n+        op->getLoc(), APFloat(0.0f), dstTy.getElementType().cast<FloatType>());\n+    auto _0 = rewriter.create<triton::SplatOp>(\n+        op->getLoc(), dotOp.getResult().getType(), _0f);\n+    auto newDot = rewriter.create<triton::DotOp>(\n+        op->getLoc(), dotOp.getResult().getType(), dotOp.getOperand(0),\n+        dotOp.getOperand(1), _0, dotOp.allowTF32());\n+    auto newCvt = rewriter.create<triton::gpu::ConvertLayoutOp>(\n+        op->getLoc(), dstTy, newDot.getResult());\n+    auto newAdd = rewriter.replaceOpWithNewOp<arith::AddFOp>(\n+        op, newCvt, cvtOp.getOperand());\n+    return mlir::success();\n+  }\n+};\n+\n // Correct the versionMinor field in MmaEncodingAttr for Volta.\n class UpdateMMAVersionMinorForVolta : public mlir::RewritePattern {\n   const DenseMap<MmaEncodingAttr, MmaEncodingAttr> &mmaToUpdate;\n@@ -1423,6 +1527,8 @@ class TritonGPUCombineOpsPass\n     patterns.add<MoveConvertOutOfLoop>(context);\n     patterns.add<MoveConvertOutOfIf>(context);\n     patterns.add<BlockedToMMA>(context, computeCapability);\n+    patterns.add<ConvertTransConvert>(context);\n+    patterns.add<ConvertDotConvert>(context);\n \n     if (applyPatternsAndFoldGreedily(m, std::move(patterns)).failed()) {\n       signalPassFailure();"}, {"filename": "lib/Dialect/TritonGPU/Transforms/DecomposeConversions.cpp", "status": "added", "additions": 69, "deletions": 0, "changes": 69, "file_content_changes": "@@ -0,0 +1,69 @@\n+#include \"mlir/Analysis/SliceAnalysis.h\"\n+#include \"mlir/Dialect/SCF/SCF.h\"\n+#include \"mlir/IR/BlockAndValueMapping.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/Matchers.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Verifier.h\"\n+#include \"mlir/Interfaces/InferTypeOpInterface.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Pass/PassManager.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"mlir/Transforms/Passes.h\"\n+#include \"mlir/Transforms/RegionUtils.h\"\n+#include \"triton/Analysis/Utility.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n+#include \"triton/Dialect/TritonGPU/Transforms/TritonGPUConversion.h\"\n+#define GEN_PASS_CLASSES\n+#include \"triton/Dialect/TritonGPU/Transforms/Passes.h.inc\"\n+\n+using namespace mlir;\n+\n+class TritonGPUDecomposeConversionsPass\n+    : public TritonGPUDecomposeConversionsBase<\n+          TritonGPUDecomposeConversionsPass> {\n+public:\n+  TritonGPUDecomposeConversionsPass() = default;\n+\n+  void runOnOperation() override {\n+    MLIRContext *context = &getContext();\n+    ModuleOp mod = getOperation();\n+    mod.walk([&](triton::gpu::ConvertLayoutOp cvtOp) -> void {\n+      OpBuilder builder(cvtOp);\n+      auto srcType = cvtOp.getOperand().getType().cast<RankedTensorType>();\n+      auto dstType = cvtOp.getType().cast<RankedTensorType>();\n+      auto srcEncoding = srcType.getEncoding();\n+      if (srcEncoding.isa<triton::gpu::SharedEncodingAttr>())\n+        return;\n+      auto dstDotOp =\n+          dstType.getEncoding().dyn_cast<triton::gpu::DotOperandEncodingAttr>();\n+      if (!dstDotOp)\n+        return;\n+      if (auto srcMmaEncoding =\n+              srcEncoding.dyn_cast<triton::gpu::MmaEncodingAttr>()) {\n+\n+        if (srcMmaEncoding.getVersionMajor() == 1 ||\n+            (srcMmaEncoding.getWarpsPerCTA()[1] == 1 &&\n+             dstDotOp.getParent() == srcMmaEncoding))\n+          return;\n+      }\n+      auto tmpType = RankedTensorType::get(\n+          dstType.getShape(), dstType.getElementType(),\n+          triton::gpu::SharedEncodingAttr::get(\n+              mod.getContext(), dstDotOp, srcType.getShape(),\n+              triton::gpu::getOrder(srcEncoding), srcType.getElementType()));\n+      auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n+          cvtOp.getLoc(), tmpType, cvtOp.getOperand());\n+      auto newConvert = builder.create<triton::gpu::ConvertLayoutOp>(\n+          cvtOp.getLoc(), dstType, tmp);\n+      cvtOp.replaceAllUsesWith(newConvert.getResult());\n+      cvtOp.erase();\n+    });\n+  }\n+};\n+\n+std::unique_ptr<Pass> mlir::createTritonGPUDecomposeConversionsPass() {\n+  return std::make_unique<TritonGPUDecomposeConversionsPass>();\n+}"}, {"filename": "lib/Dialect/TritonGPU/Transforms/ReorderInstructions.cpp", "status": "added", "additions": 101, "deletions": 0, "changes": 101, "file_content_changes": "@@ -0,0 +1,101 @@\n+#include \"mlir/Analysis/SliceAnalysis.h\"\n+#include \"mlir/Dialect/SCF/SCF.h\"\n+#include \"mlir/IR/BlockAndValueMapping.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/Matchers.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Verifier.h\"\n+#include \"mlir/Interfaces/InferTypeOpInterface.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Pass/PassManager.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"mlir/Transforms/Passes.h\"\n+#include \"mlir/Transforms/RegionUtils.h\"\n+#include \"triton/Analysis/Utility.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n+#include \"triton/Dialect/TritonGPU/Transforms/TritonGPUConversion.h\"\n+#define GEN_PASS_CLASSES\n+#include \"triton/Dialect/TritonGPU/Transforms/Passes.h.inc\"\n+\n+using namespace mlir;\n+\n+static inline bool\n+willIncreaseRegisterPressure(triton::gpu::ConvertLayoutOp op) {\n+  auto srcType = op.getOperand().getType().cast<RankedTensorType>();\n+  auto dstType = op.getResult().getType().cast<RankedTensorType>();\n+  auto srcEncoding = srcType.getEncoding();\n+  auto dstEncoding = dstType.getEncoding();\n+  if (srcEncoding.isa<triton::gpu::SharedEncodingAttr>())\n+    return true;\n+  if (dstEncoding.isa<triton::gpu::DotOperandEncodingAttr>())\n+    return true;\n+  return false;\n+}\n+\n+class TritonGPUReorderInstructionsPass\n+    : public TritonGPUReorderInstructionsBase<\n+          TritonGPUReorderInstructionsPass> {\n+public:\n+  TritonGPUReorderInstructionsPass() = default;\n+\n+  void runOnOperation() override {\n+    MLIRContext *context = &getContext();\n+    ModuleOp m = getOperation();\n+    // Sink conversions into loops when they will increase\n+    // register pressure\n+    DenseMap<Operation *, Operation *> opToMove;\n+    m.walk([&](triton::gpu::ConvertLayoutOp op) {\n+      if (!willIncreaseRegisterPressure(op))\n+        return;\n+      auto user_begin = op->user_begin();\n+      auto user_end = op->user_end();\n+      if (std::distance(user_begin, user_end) != 1)\n+        return;\n+      opToMove.insert({op, *user_begin});\n+    });\n+    for (auto &kv : opToMove)\n+      kv.first->moveBefore(kv.second);\n+    // Move convert(load) immediately after dependent load\n+    m.walk([&](triton::gpu::ConvertLayoutOp op) {\n+      auto dstType = op.getResult().getType().cast<RankedTensorType>();\n+      auto dstEncoding = dstType.getEncoding();\n+      if (!dstEncoding.isa<triton::gpu::SharedEncodingAttr>())\n+        return;\n+      Operation *argOp = op.getOperand().getDefiningOp();\n+      if (!argOp)\n+        return;\n+      op->moveAfter(argOp);\n+    });\n+    // Move transpositions just after their definition\n+    opToMove.clear();\n+    m.walk([&](triton::TransOp op) {\n+      Operation *argOp = op.getOperand().getDefiningOp();\n+      if (!argOp)\n+        return;\n+      op->moveAfter(argOp);\n+    });\n+    // Move `dot` operand so that conversions to opIdx=0 happens before\n+    // conversions to opIdx=1\n+    m.walk([&](triton::gpu::ConvertLayoutOp op) {\n+      auto dstType = op.getResult().getType().cast<RankedTensorType>();\n+      auto dstEncoding =\n+          dstType.getEncoding().dyn_cast<triton::gpu::DotOperandEncodingAttr>();\n+      if (!dstEncoding)\n+        return;\n+      int opIdx = dstEncoding.getOpIdx();\n+      if (opIdx != 1)\n+        return;\n+      if (op->getUsers().empty())\n+        return;\n+      auto user_begin = op->user_begin();\n+      op->moveBefore(*user_begin);\n+    });\n+    return;\n+  }\n+};\n+\n+std::unique_ptr<Pass> mlir::createTritonGPUReorderInstructionsPass() {\n+  return std::make_unique<TritonGPUReorderInstructionsPass>();\n+}"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "file_content_changes": "@@ -1342,11 +1342,19 @@ void init_triton_ir(py::module &&m) {\n            [](mlir::PassManager &self) {\n              self.addPass(mlir::createTritonGPUPrefetchPass());\n            })\n-      .def(\"add_triton_gpu_combine_pass\",\n+      .def(\"add_tritongpu_combine_pass\",\n            [](mlir::PassManager &self, int computeCapability) {\n              self.addPass(\n                  mlir::createTritonGPUCombineOpsPass(computeCapability));\n            })\n+      .def(\"add_tritongpu_reorder_instructions_pass\",\n+           [](mlir::PassManager &self) {\n+             self.addPass(mlir::createTritonGPUReorderInstructionsPass());\n+           })\n+      .def(\"add_tritongpu_decompose_conversions_pass\",\n+           [](mlir::PassManager &self) {\n+             self.addPass(mlir::createTritonGPUDecomposeConversionsPass());\n+           })\n       .def(\"add_triton_gpu_to_llvm\",\n            [](mlir::PassManager &self) {\n              self.addPass(mlir::triton::createConvertTritonGPUToLLVMPass());"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "file_content_changes": "@@ -890,17 +890,21 @@ def ttir_to_ttgir(mod, num_warps, num_stages, compute_capability):\n     pm.add_coalesce_pass()\n     # The combine pass converts blocked layout to mma layout\n     # for dot ops so that pipeline can get shared memory swizzled correctly.\n-    pm.add_triton_gpu_combine_pass(compute_capability)\n+    pm.add_tritongpu_combine_pass(compute_capability)\n     pm.add_tritongpu_pipeline_pass(num_stages)\n     # Prefetch must be done after pipeline pass because pipeline pass\n     # extracts slices from the original tensor.\n     pm.add_tritongpu_prefetch_pass()\n     pm.add_canonicalizer_pass()\n     pm.add_cse_pass()\n-    pm.add_triton_gpu_combine_pass(compute_capability)\n+    pm.add_tritongpu_combine_pass(compute_capability)\n     pm.add_licm_pass()\n-    pm.add_triton_gpu_combine_pass(compute_capability)\n+    pm.add_tritongpu_combine_pass(compute_capability)\n     pm.add_cse_pass()\n+    pm.add_tritongpu_decompose_conversions_pass()\n+    pm.add_cse_pass()\n+    pm.add_symbol_dce_pass()\n+    pm.add_tritongpu_reorder_instructions_pass()\n     pm.run(mod)\n     return mod\n "}, {"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 6, "deletions": 9, "changes": 15, "file_content_changes": "@@ -225,18 +225,18 @@ def forward(ctx, q, k, v, sm_scale):\n             q.shape[0], q.shape[1], q.shape[2],\n             BLOCK_M=BLOCK, BLOCK_N=BLOCK,\n             BLOCK_DMODEL=Lk, num_warps=num_warps,\n-            num_stages=1,\n+            num_stages=2,\n         )\n \n         ctx.save_for_backward(q, k, v, o, L, m)\n-        ctx.BLOCK = BLOCK\n         ctx.grid = grid\n         ctx.sm_scale = sm_scale\n         ctx.BLOCK_DMODEL = Lk\n         return o\n \n     @staticmethod\n     def backward(ctx, do):\n+        BLOCK = 128\n         q, k, v, o, l, m = ctx.saved_tensors\n         do = do.contiguous()\n         dq = torch.zeros_like(q, dtype=torch.float32)\n@@ -247,11 +247,8 @@ def backward(ctx, do):\n         _bwd_preprocess[(ctx.grid[0] * ctx.grid[1], )](\n             o, do, l,\n             do_scaled, delta,\n-            BLOCK_M=ctx.BLOCK, D_HEAD=ctx.BLOCK_DMODEL,\n+            BLOCK_M=BLOCK, D_HEAD=ctx.BLOCK_DMODEL,\n         )\n-\n-        # NOTE: kernel currently buggy for other values of `num_warps`\n-        num_warps = 8\n         _bwd_kernel[(ctx.grid[1],)](\n             q, k, v, ctx.sm_scale,\n             o, do_scaled,\n@@ -263,8 +260,8 @@ def backward(ctx, do):\n             v.stride(0), v.stride(1), v.stride(2), v.stride(3),\n             q.shape[0], q.shape[1], q.shape[2],\n             ctx.grid[0],\n-            BLOCK_M=ctx.BLOCK, BLOCK_N=ctx.BLOCK,\n-            BLOCK_DMODEL=ctx.BLOCK_DMODEL, num_warps=num_warps,\n+            BLOCK_M=BLOCK, BLOCK_N=BLOCK,\n+            BLOCK_DMODEL=ctx.BLOCK_DMODEL, num_warps=8,\n             num_stages=1,\n         )\n         return dq, dk, dv, None\n@@ -319,7 +316,7 @@ def test_op(Z, H, N_CTX, D_HEAD, dtype=torch.float16):\n # vary seq length for fixed head and batch=4\n configs = [triton.testing.Benchmark(\n     x_names=['N_CTX'],\n-    x_vals=[2**i for i in range(10, 16)],\n+    x_vals=[2**i for i in range(10, 15)],\n     line_arg='provider',\n     line_vals=['triton'] + (['flash'] if HAS_FLASH else []),\n     line_names=['Triton'] + (['Flash'] if HAS_FLASH else []),"}, {"filename": "test/Analysis/test-alias.mlir", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -3,6 +3,7 @@\n #AL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n #BL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A_SHARED = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n+#A_SHARED_T = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [0, 1]}>\n #B_SHARED = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n #C = #triton_gpu.mma<{versionMajor = 2, warpsPerCTA = [4, 1]}>\n #A_DOT = #triton_gpu.dot_op<{opIdx = 0, parent = #C}>\n@@ -57,7 +58,7 @@ func @trans(%A : !tt.ptr<f16>) {\n   // CHECK: %cst -> %cst\n   %tensor = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n   // CHECK: %0 -> %cst\n-  %b = tt.trans %tensor : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n+  %b = tt.trans %tensor : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED_T>\n   return\n }\n "}, {"filename": "test/Analysis/test-allocation.mlir", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -4,6 +4,7 @@\n #sliceAd0 = #triton_gpu.slice<{dim = 0, parent = #AL}>\n #BL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A_SHARED = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n+#A_SHARED_T = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [0, 1]}>\n #B_SHARED = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n #C = #triton_gpu.mma<{versionMajor = 2, warpsPerCTA = [4, 1]}>\n #A_DOT = #triton_gpu.dot_op<{opIdx = 0, parent = #C}>\n@@ -178,7 +179,7 @@ func @scratch() {\n func @trans(%A : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 1024\n   %tensor = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n-  %b = tt.trans %tensor : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n+  %b = tt.trans %tensor : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED_T>\n   return\n }\n \n@@ -303,7 +304,7 @@ func @for_use_ancestor(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16\n   // CHECK-NEXT: offset = 16384, size = 8192\n   %c_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   %a_shared, %b_shared = scf.for %iv = %lb to %ub step %step iter_args(%a_shared = %a_shared_init, %b_shared = %b_shared_init) -> (tensor<128x32xf16, #A_SHARED>, tensor<128x32xf16, #A_SHARED>) {\n-    %c0 = tt.trans %c_shared_init : (tensor<128x32xf16, #A_SHARED>) -> tensor<32x128xf16, #A_SHARED>\n+    %c0 = tt.trans %c_shared_init : (tensor<128x32xf16, #A_SHARED>) -> tensor<32x128xf16, #A_SHARED_T>\n     // CHECK-NEXT: offset = 24576, size = 8192\n     %c1 = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n     scf.yield %b_shared, %a_shared: tensor<128x32xf16, #A_SHARED>, tensor<128x32xf16, #A_SHARED>"}, {"filename": "test/Analysis/test-membar.mlir", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -4,6 +4,7 @@\n #sliceAd0 = #triton_gpu.slice<{dim = 0, parent = #AL}>\n #BL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A_SHARED = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n+#A_SHARED_T = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [0, 1]}>\n #B_SHARED = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n #C = #triton_gpu.mma<{versionMajor = 2, warpsPerCTA = [4, 1]}>\n #A_DOT = #triton_gpu.dot_op<{opIdx = 0, parent = #C}>\n@@ -114,7 +115,7 @@ func @extract_slice() {\n // CHECK-LABEL: trans\n func @trans() {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n-  %b = tt.trans %cst0 : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n+  %b = tt.trans %cst0 : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED_T>\n   return\n }\n "}]