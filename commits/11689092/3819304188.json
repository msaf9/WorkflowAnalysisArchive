[{"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -39,6 +39,8 @@ SmallVector<unsigned> getShapePerCTA(const Attribute &layout);\n \n SmallVector<unsigned> getOrder(const Attribute &layout);\n \n+bool isaDistributedLayout(const Attribute &layout);\n+\n } // namespace gpu\n } // namespace triton\n } // namespace mlir"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 54, "deletions": 104, "changes": 158, "file_content_changes": "@@ -9,10 +9,12 @@ using ::mlir::LLVM::getStridesFromShapeAndOrder;\n using ::mlir::LLVM::getStructFromElements;\n using ::mlir::LLVM::MMA16816ConversionHelper;\n using ::mlir::triton::gpu::DotOperandEncodingAttr;\n+using ::mlir::triton::gpu::getContigPerThread;\n using ::mlir::triton::gpu::getElemsPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n+using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n bool isMmaToDotShortcut(MmaEncodingAttr &mmaLayout,\n@@ -24,108 +26,63 @@ bool isMmaToDotShortcut(MmaEncodingAttr &mmaLayout,\n          dotOperandLayout.getParent() == mmaLayout;\n }\n \n-void storeBlockedToShared(Value src, Value llSrc, ArrayRef<Value> srcStrides,\n-                          ArrayRef<Value> srcIndices, Value dst, Value smemBase,\n-                          Type elemTy, Location loc,\n-                          ConversionPatternRewriter &rewriter) {\n+void storeDistributedToShared(Value src, Value llSrc,\n+                              ArrayRef<Value> dstStrides,\n+                              ArrayRef<SmallVector<Value>> srcIndices,\n+                              Value dst, Value smemBase, Type elemTy,\n+                              Location loc,\n+                              ConversionPatternRewriter &rewriter) {\n   auto srcTy = src.getType().cast<RankedTensorType>();\n   auto srcShape = srcTy.getShape();\n-  assert(srcShape.size() == 2 && \"Unexpected rank of insertSlice\");\n-\n+  assert(srcShape.size() == 2 && \"Unexpected rank of storeDistributedToShared\");\n   auto dstTy = dst.getType().cast<RankedTensorType>();\n-  auto srcBlockedLayout = srcTy.getEncoding().cast<BlockedEncodingAttr>();\n+  auto srcDistributedLayout = srcTy.getEncoding();\n+  if (auto mmaLayout = srcDistributedLayout.dyn_cast<MmaEncodingAttr>()) {\n+    assert((!mmaLayout.isVolta()) &&\n+           \"ConvertLayout MMAv1->Shared is not suppported yet\");\n+  }\n   auto dstSharedLayout = dstTy.getEncoding().cast<SharedEncodingAttr>();\n-  auto inOrd = srcBlockedLayout.getOrder();\n+  auto inOrd = getOrder(srcDistributedLayout);\n   auto outOrd = dstSharedLayout.getOrder();\n-  if (inOrd != outOrd)\n-    llvm_unreachable(\n-        \"blocked -> shared with different order not yet implemented\");\n   unsigned inVec =\n-      inOrd == outOrd ? srcBlockedLayout.getSizePerThread()[inOrd[0]] : 1;\n+      inOrd == outOrd ? getContigPerThread(srcDistributedLayout)[inOrd[0]] : 1;\n   unsigned outVec = dstSharedLayout.getVec();\n   unsigned minVec = std::min(outVec, inVec);\n   unsigned perPhase = dstSharedLayout.getPerPhase();\n   unsigned maxPhase = dstSharedLayout.getMaxPhase();\n   unsigned numElems = getElemsPerThread(srcTy);\n+  assert(numElems == srcIndices.size());\n   auto inVals = getElementsFromStruct(loc, llSrc, rewriter);\n-  auto srcAccumSizeInThreads =\n-      product<unsigned>(srcBlockedLayout.getSizePerThread());\n   auto wordTy = vec_ty(elemTy, minVec);\n   auto elemPtrTy = ptr_ty(elemTy);\n-\n-  SmallVector<unsigned> srcShapePerCTA = getShapePerCTA(srcBlockedLayout);\n-  SmallVector<unsigned> reps{ceil<unsigned>(srcShape[0], srcShapePerCTA[0]),\n-                             ceil<unsigned>(srcShape[1], srcShapePerCTA[1])};\n-\n-  // Visit each input value in the order they are placed in inVals\n-  //\n-  // Please note that the order was not awaring of blockLayout.getOrder(),\n-  // thus the adjacent elems may not belong to a same word. This could be\n-  // improved if we update the elements order by emitIndicesForBlockedLayout()\n-  SmallVector<unsigned> wordsInEachRep(2);\n-  wordsInEachRep[0] = inOrd[0] == 0\n-                          ? srcBlockedLayout.getSizePerThread()[0] / minVec\n-                          : srcBlockedLayout.getSizePerThread()[0];\n-  wordsInEachRep[1] = inOrd[0] == 0\n-                          ? srcBlockedLayout.getSizePerThread()[1]\n-                          : srcBlockedLayout.getSizePerThread()[1] / minVec;\n   Value outVecVal = i32_val(outVec);\n   Value minVecVal = i32_val(minVec);\n-  auto numWordsEachRep = product<unsigned>(wordsInEachRep);\n-  SmallVector<Value> wordVecs(numWordsEachRep);\n+  Value word;\n   for (unsigned i = 0; i < numElems; ++i) {\n-    if (i % srcAccumSizeInThreads == 0) {\n-      // start of a replication\n-      for (unsigned w = 0; w < numWordsEachRep; ++w) {\n-        wordVecs[w] = undef(wordTy);\n-      }\n-    }\n-    unsigned linearIdxInNanoTile = i % srcAccumSizeInThreads;\n-    auto multiDimIdxInNanoTile = getMultiDimIndex<unsigned>(\n-        linearIdxInNanoTile, srcBlockedLayout.getSizePerThread(), inOrd);\n-    unsigned pos = multiDimIdxInNanoTile[inOrd[0]] % minVec;\n-    multiDimIdxInNanoTile[inOrd[0]] /= minVec;\n-    auto wordVecIdx =\n-        getLinearIndex<unsigned>(multiDimIdxInNanoTile, wordsInEachRep, inOrd);\n-    wordVecs[wordVecIdx] =\n-        insert_element(wordTy, wordVecs[wordVecIdx], inVals[i], i32_val(pos));\n-\n-    if (i % srcAccumSizeInThreads == srcAccumSizeInThreads - 1) {\n-      // end of replication, store the vectors into shared memory\n-      unsigned linearRepIdx = i / srcAccumSizeInThreads;\n-      auto multiDimRepIdx =\n-          getMultiDimIndex<unsigned>(linearRepIdx, reps, inOrd);\n-      for (unsigned linearWordIdx = 0; linearWordIdx < numWordsEachRep;\n-           ++linearWordIdx) {\n-        // step 1: recover the multidim_index from the index of\n-        // input_elements\n-        auto multiDimWordIdx =\n-            getMultiDimIndex<unsigned>(linearWordIdx, wordsInEachRep, inOrd);\n-        SmallVector<Value> multiDimIdx(2);\n-        auto wordOffset0 = multiDimRepIdx[0] * srcShapePerCTA[0] +\n-                           multiDimWordIdx[0] * (inOrd[0] == 0 ? minVec : 1);\n-        auto wordOffset1 = multiDimRepIdx[1] * srcShapePerCTA[1] +\n-                           multiDimWordIdx[1] * (inOrd[0] == 1 ? minVec : 1);\n-        multiDimIdx[0] = add(srcIndices[0], i32_val(wordOffset0));\n-        multiDimIdx[1] = add(srcIndices[1], i32_val(wordOffset1));\n-\n-        // step 2: do swizzling\n-        Value remained = urem(multiDimIdx[outOrd[0]], outVecVal);\n-        multiDimIdx[outOrd[0]] = udiv(multiDimIdx[outOrd[0]], outVecVal);\n-        Value off_1 = mul(multiDimIdx[outOrd[1]], srcStrides[outOrd[1]]);\n-        Value phaseId = udiv(multiDimIdx[outOrd[1]], i32_val(perPhase));\n-        phaseId = urem(phaseId, i32_val(maxPhase));\n-        Value off_0 = xor_(multiDimIdx[outOrd[0]], phaseId);\n-        off_0 = mul(off_0, outVecVal);\n-        remained = udiv(remained, minVecVal);\n-        off_0 = add(off_0, mul(remained, minVecVal));\n-        Value offset = add(off_1, off_0);\n-\n-        // step 3: store\n-        Value smemAddr = gep(elemPtrTy, smemBase, offset);\n-        smemAddr = bitcast(smemAddr, ptr_ty(wordTy, 3));\n-        store(wordVecs[linearWordIdx], smemAddr);\n-      }\n+    if (i % minVec == 0)\n+      word = undef(wordTy);\n+    word = insert_element(wordTy, word, inVals[i], i32_val(i % minVec));\n+    if (i % minVec == minVec - 1) {\n+      // step 1: recover the multidim_index from the index of\n+      SmallVector<Value> multiDimIdx = srcIndices[i];\n+      SmallVector<Value> dbgVal = srcIndices[i];\n+\n+      // step 2: do swizzling\n+      Value remained = urem(multiDimIdx[outOrd[0]], outVecVal);\n+      multiDimIdx[outOrd[0]] = udiv(multiDimIdx[outOrd[0]], outVecVal);\n+      Value off_1 = mul(multiDimIdx[outOrd[1]], dstStrides[outOrd[1]]);\n+      Value phaseId = udiv(multiDimIdx[outOrd[1]], i32_val(perPhase));\n+      phaseId = urem(phaseId, i32_val(maxPhase));\n+      Value off_0 = xor_(multiDimIdx[outOrd[0]], phaseId);\n+      off_0 = mul(off_0, outVecVal);\n+      remained = udiv(remained, minVecVal);\n+      off_0 = add(off_0, mul(remained, minVecVal));\n+      Value offset = add(off_1, mul(off_0, dstStrides[outOrd[0]]));\n+\n+      // step 3: store\n+      Value smemAddr = gep(elemPtrTy, smemBase, offset);\n+      smemAddr = bitcast(smemAddr, ptr_ty(wordTy, 3));\n+      store(word, smemAddr);\n     }\n   }\n }\n@@ -145,20 +102,15 @@ struct ConvertLayoutOpConversion\n     auto dstTy = dst.getType().cast<RankedTensorType>();\n     Attribute srcLayout = srcTy.getEncoding();\n     Attribute dstLayout = dstTy.getEncoding();\n-    if (srcLayout.isa<BlockedEncodingAttr>() &&\n+    if (isaDistributedLayout(srcLayout) &&\n         dstLayout.isa<SharedEncodingAttr>()) {\n-      return lowerBlockedToShared(op, adaptor, rewriter);\n+      return lowerDistributedToShared(op, adaptor, rewriter);\n     }\n     if (srcLayout.isa<SharedEncodingAttr>() &&\n         dstLayout.isa<DotOperandEncodingAttr>()) {\n       return lowerSharedToDotOperand(op, adaptor, rewriter);\n     }\n-    if ((srcLayout.isa<BlockedEncodingAttr>() ||\n-         srcLayout.isa<MmaEncodingAttr>() ||\n-         srcLayout.isa<SliceEncodingAttr>()) &&\n-        (dstLayout.isa<BlockedEncodingAttr>() ||\n-         dstLayout.isa<MmaEncodingAttr>() ||\n-         dstLayout.isa<SliceEncodingAttr>())) {\n+    if (isaDistributedLayout(srcLayout) && isaDistributedLayout(dstLayout)) {\n       return lowerDistributedToDistributed(op, adaptor, rewriter);\n     }\n     if (srcLayout.isa<MmaEncodingAttr>() &&\n@@ -476,8 +428,8 @@ struct ConvertLayoutOpConversion\n   // Swizzling in shared memory to avoid bank conflict. Normally used for\n   // A/B operands of dots.\n   LogicalResult\n-  lowerBlockedToShared(triton::gpu::ConvertLayoutOp op, OpAdaptor adaptor,\n-                       ConversionPatternRewriter &rewriter) const {\n+  lowerDistributedToShared(triton::gpu::ConvertLayoutOp op, OpAdaptor adaptor,\n+                           ConversionPatternRewriter &rewriter) const {\n     auto loc = op.getLoc();\n     Value src = op.src();\n     Value dst = op.result();\n@@ -487,22 +439,20 @@ struct ConvertLayoutOpConversion\n     auto dstShape = dstTy.getShape();\n     assert(srcShape.size() == 2 &&\n            \"Unexpected rank of ConvertLayout(blocked->shared)\");\n-    auto srcBlockedLayout = srcTy.getEncoding().cast<BlockedEncodingAttr>();\n+    auto srcLayout = srcTy.getEncoding();\n     auto dstSharedLayout = dstTy.getEncoding().cast<SharedEncodingAttr>();\n-    auto inOrd = srcBlockedLayout.getOrder();\n+    auto inOrd = getOrder(srcLayout);\n     auto outOrd = dstSharedLayout.getOrder();\n     Value smemBase = getSharedMemoryBase(loc, rewriter, dst);\n     auto elemTy = getTypeConverter()->convertType(srcTy.getElementType());\n     auto elemPtrTy = ptr_ty(getTypeConverter()->convertType(elemTy), 3);\n     smemBase = bitcast(smemBase, elemPtrTy);\n \n-    auto srcStrides =\n-        getStridesFromShapeAndOrder(srcShape, inOrd, loc, rewriter);\n-    auto srcIndices =\n-        emitBaseIndexForLayout(loc, rewriter, srcBlockedLayout, srcShape);\n-    storeBlockedToShared(src, adaptor.src(), srcStrides, srcIndices, dst,\n-                         smemBase, elemTy, loc, rewriter);\n-\n+    auto dstStrides =\n+        getStridesFromShapeAndOrder(dstShape, outOrd, loc, rewriter);\n+    auto srcIndices = emitIndices(loc, rewriter, srcLayout, srcShape);\n+    storeDistributedToShared(src, adaptor.src(), dstStrides, srcIndices, dst,\n+                             smemBase, elemTy, loc, rewriter);\n     auto smemObj =\n         SharedMemoryObject(smemBase, dstShape, outOrd, loc, rewriter);\n     auto retVal = getStructFromSharedMemoryObject(loc, smemObj, rewriter);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.h", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "file_content_changes": "@@ -11,10 +11,12 @@ using ::mlir::triton::gpu::DotOperandEncodingAttr;\n bool isMmaToDotShortcut(MmaEncodingAttr &mmaLayout,\n                         DotOperandEncodingAttr &dotOperandLayout);\n \n-void storeBlockedToShared(Value src, Value llSrc, ArrayRef<Value> srcStrides,\n-                          ArrayRef<Value> srcIndices, Value dst, Value smemBase,\n-                          Type elemPtrTy, Location loc,\n-                          ConversionPatternRewriter &rewriter);\n+void storeDistributedToShared(Value src, Value llSrc,\n+                              ArrayRef<Value> srcStrides,\n+                              ArrayRef<SmallVector<Value>> srcIndices,\n+                              Value dst, Value smemBase, Type elemPtrTy,\n+                              Location loc,\n+                              ConversionPatternRewriter &rewriter);\n \n void populateConvertLayoutOpToLLVMPatterns(\n     mlir::LLVMTypeConverter &typeConverter, RewritePatternSet &patterns,"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "file_content_changes": "@@ -639,10 +639,9 @@ struct InsertSliceOpConversion\n     auto smemBase = gep(elemPtrTy, smemObj.base, offset);\n \n     auto llSrc = adaptor.source();\n-    auto srcIndices =\n-        emitBaseIndexForLayout(loc, rewriter, srcLayout, srcShape);\n-    storeBlockedToShared(src, llSrc, srcStrides, srcIndices, dst, smemBase,\n-                         elemTy, loc, rewriter);\n+    auto srcIndices = emitIndices(loc, rewriter, srcLayout, srcShape);\n+    storeDistributedToShared(src, llSrc, srcStrides, srcIndices, dst, smemBase,\n+                             elemTy, loc, rewriter);\n     // Barrier is not necessary.\n     // The membar pass knows that it writes to shared memory and will handle it\n     // properly."}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "file_content_changes": "@@ -254,6 +254,11 @@ SmallVector<unsigned> getOrder(const Attribute &layout) {\n   }\n };\n \n+bool isaDistributedLayout(const Attribute &layout) {\n+  return layout.isa<BlockedEncodingAttr>() || layout.isa<MmaEncodingAttr>() ||\n+         layout.isa<SliceEncodingAttr>();\n+}\n+\n } // namespace gpu\n } // namespace triton\n } // namespace mlir"}]