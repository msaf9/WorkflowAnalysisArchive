[{"filename": "python/bench/bench_blocksparse.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -40,7 +40,7 @@ def bench_matmul(M, N, K, block, layout_mode, op_mode, AT, BT, dtype, provider,\n     # create op\n     tflops = lambda ms: num_flops / ms * 1e3\n     if provider == 'triton':\n-        op = triton.ops.blocksparse.matmul(layout, block, op_mode, trans_a=AT, trans_b=BT)\n+        op = triton.ops.blocksparse.matmul(layout, block, op_mode, device=\"cuda\", trans_a=AT, trans_b=BT)\n         # inputs\n         a = triton.testing.sparsify_tensor(a, layout, block) if op_mode == 'dsd' else a\n         b = triton.testing.sparsify_tensor(b, layout, block) if op_mode == 'dds' else b\n@@ -83,7 +83,7 @@ def bench_softmax(M, N, block, layout_mode, dtype, provider, warmup=10, rep=50):\n     a = torch.randn((Z, H, M, N), dtype=dtype, device='cuda')\n     if provider == 'triton':\n         a = triton.testing.sparsify_tensor(a, layout, block)\n-        op = triton.ops.blocksparse.softmax(layout, block)\n+        op = triton.ops.blocksparse.softmax(layout, block, device=\"cuda\")\n         gbps = lambda ms: (2 * a.numel() * a.element_size() * 1e-9) / (ms * 1e-3)\n         mean_ms, min_ms, max_ms = triton.testing.do_bench(lambda: op(a), warmup=warmup, rep=rep)\n         return gbps(mean_ms), gbps(min_ms), gbps(max_ms)"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -644,7 +644,7 @@ def copy_kernel(input_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n     )\n     assert torch.all(\n         torch.logical_not(mismatch)\n-    ), f\"{f16_input[mismatch]=} {f16_output[mismatch]=} {abs_error[mismatch]=} {min_error[mismatch]=}\"\n+    ), f\"f16_input[mismatch]={f16_input[mismatch]} f16_output[mismatch]={f16_output[mismatch]} abs_error[mismatch]={abs_error[mismatch]} min_error[mismatch]={min_error[mismatch]}\"\n \n \n # ---------------"}]