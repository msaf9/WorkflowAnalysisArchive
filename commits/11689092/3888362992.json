[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -893,7 +893,7 @@ def get_reduced_dtype(dtype_str, op):\n \n @pytest.mark.parametrize(\"op, dtype_str, shape\",\n                          [(op, dtype, shape)\n-                          for op in ['min', 'max', 'sum']\n+                          for op in ['min', 'max', 'sum', 'argmin', 'argmax']\n                           for dtype in dtypes_with_bfloat16\n                           for shape in [32, 64, 128, 512]])\n def test_reduce1d(op, dtype_str, shape, device='cuda'):\n@@ -914,7 +914,7 @@ def kernel(X, Z, BLOCK: tl.constexpr):\n     numpy_op = {'sum': np.sum, 'max': np.max, 'min': np.min,\n                 'argmin': np.argmin, 'argmax': np.argmax}[op]\n     # numpy result\n-    z_dtype_str = get_reduced_dtype(dtype_str, op)\n+    z_dtype_str = 'int32' if op == 'argmin' or op == 'argmax' else dtype_str\n     z_tri_dtype_str = z_dtype_str\n     if op not in ['argmin', 'argmax'] and dtype_str == 'bfloat16':\n         z_dtype_str = 'float32'"}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -1036,15 +1036,18 @@ def where(condition: tl.tensor,\n def reduce_impl(input: tl.tensor, axis: int, builder: ir.builder, name: str,\n                 FLOAT_OP: ir.REDUCE_OP, INT_OP: ir.REDUCE_OP) -> tl.tensor:\n     scalar_ty = input.type.scalar\n+    out_scalar_ty = scalar_ty\n     # input is extended to 32-bits if necessary\n     # this increases numerical accuracy and can be done pretty much for free\n     # on GPUs\n     if scalar_ty.is_int() and scalar_ty.int_bitwidth <= 32:\n         input = cast(input, tl.int32, builder)\n+        out_scalar_ty = tl.int32\n \n     # hardware doesn't support FMAX, FMIN, CMP for bfloat16\n     if scalar_ty is tl.bfloat16:\n         input = cast(input, tl.float32, builder)\n+        out_scalar_ty = tl.float32\n \n     # choose the right unsigned operation\n     if scalar_ty.is_int_unsigned():\n@@ -1058,7 +1061,6 @@ def reduce_impl(input: tl.tensor, axis: int, builder: ir.builder, name: str,\n             INT_OP = int_op_to_unit[INT_OP]\n \n     # If we are doing an argmin or argmax we want to use an int32 output type\n-    out_scalar_ty = scalar_ty\n     if FLOAT_OP is ir.REDUCE_OP.ARGFMAX or INT_OP is ir.REDUCE_OP.ARGMAX:\n         out_scalar_ty = tl.int32\n     elif FLOAT_OP is ir.REDUCE_OP.ARGFMIN or INT_OP is ir.REDUCE_OP.ARGMIN:"}]