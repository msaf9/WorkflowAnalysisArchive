[{"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -96,8 +96,8 @@ def TT_FpToFpOp : TT_Op<\"fp_to_fp\", [SameOperandsAndResultShape,\n \n def TT_AddPtrOp : TT_Op<\"addptr\",\n                      [NoSideEffect,\n-                     SameOperandsAndResultShape,\n-                     SameOperandsAndResultEncoding,\n+                      SameOperandsAndResultShape,\n+                      SameOperandsAndResultEncoding,\n                       TypesMatchWith<\"result type matches ptr type\",\n                                      \"result\", \"ptr\", \"$_self\">]> {\n     let arguments = (ins TT_PtrLike:$ptr, TT_IntLike:$offset);"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUOps.td", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "file_content_changes": "@@ -16,7 +16,9 @@ class TTG_Op<string mnemonic, list<Trait> traits = []> :\n     Op<TritonGPU_Dialect, mnemonic, traits>;\n \n def TTG_ConvertLayoutOp : TTG_Op<\"convert_layout\",\n-                                 [SameOperandsAndResultShape, NoSideEffect]> {\n+                                 [SameOperandsAndResultShape,\n+                                  SameOperandsAndResultElementType,\n+                                  NoSideEffect]> {\n   let summary = \"convert layout\";\n \n   let arguments = (ins TT_Tensor:$src);\n@@ -87,8 +89,8 @@ def TTG_CmpFOp : TTG_Op<\"cmpf\", [NoSideEffect, Elementwise,\n \n // TODO: migrate to arith::SelectOp on LLVM16\n def TTG_SelectOp : TTG_Op<\"select\", [NoSideEffect, Elementwise, \n-                                 SameOperandsAndResultShape, \n-                                 SameOperandsAndResultEncoding]> {\n+                                     SameOperandsAndResultShape, \n+                                     SameOperandsAndResultEncoding]> {\n   let summary = \"select operation\";\n \n   let description = [{}];"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 9, "deletions": 10, "changes": 19, "file_content_changes": "@@ -498,8 +498,6 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n       // don't rematerialize non-element-wise\n       if (!op->hasTrait<mlir::OpTrait::Elementwise>())\n         return failure();\n-      Attribute dstEncoding =\n-          cvt.getOperand().getType().cast<RankedTensorType>().getEncoding();\n       // don't rematerialize if it adds an extra conversion that can't\n       // be removed\n       for (Value arg : op->getOperands()) {\n@@ -509,7 +507,7 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n         llvm::MapVector<Value, Attribute> toConvert;\n         if (argOp && (argOp != cvt) && cvtSlices.count(argOp) == 0 &&\n             failed(simulateBackwardRematerialization(argOp, processed, layout,\n-                                                     toConvert, dstEncoding))) {\n+                                                     toConvert, srcEncoding))) {\n           return failure();\n         }\n       }\n@@ -521,8 +519,11 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n       if (arg.getDefiningOp() == cvt)\n         mapping.map(arg, cvt.getOperand());\n       else {\n-        auto cvtI = rewriter.create<triton::gpu::ConvertLayoutOp>(\n-            arg.getLoc(), cvt.getOperand().getType(), arg);\n+        auto oldType = arg.getType().cast<RankedTensorType>();\n+        auto newType = RankedTensorType::get(\n+            oldType.getShape(), oldType.getElementType(), srcEncoding);\n+        auto cvtI = rewriter.create<triton::gpu::ConvertLayoutOp>(arg.getLoc(),\n+                                                                  newType, arg);\n         if (Operation *argOp = arg.getDefiningOp())\n           cvtI->moveAfter(argOp);\n         mapping.map(arg, cvtI);\n@@ -531,14 +532,12 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n     rewriter.setInsertionPoint(op);\n     Operation *newOp = rewriter.clone(*op, mapping);\n     auto oldType = op->getResult(0).getType().cast<RankedTensorType>();\n-    auto newType = RankedTensorType::get(\n-        oldType.getShape(), oldType.getElementType(),\n-        cvt.getOperand().getType().cast<RankedTensorType>().getEncoding());\n+    auto newType = RankedTensorType::get(oldType.getShape(),\n+                                         oldType.getElementType(), srcEncoding);\n \n     newOp->getResult(0).setType(newType);\n     auto newCvtType = RankedTensorType::get(\n-        oldType.getShape(), oldType.getElementType(),\n-        cvt.getResult().getType().cast<RankedTensorType>().getEncoding());\n+        oldType.getShape(), oldType.getElementType(), dstEncoding);\n     auto newCvt = rewriter.create<triton::gpu::ConvertLayoutOp>(\n         newOp->getLoc(), newCvtType, newOp->getResult(0));\n     rewriter.replaceOp(op, newCvt->getResults());"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 52, "deletions": 0, "changes": 52, "file_content_changes": "@@ -50,6 +50,7 @@ func @remat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n   // CHECK: return %6 : tensor<1024xi32, [[target_layout]]>\n }\n \n+\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>\n #slice1dim1 = #triton_gpu.slice<{dim = 1, parent = #blocked1}>\n@@ -183,3 +184,54 @@ func @vecadd(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f3\n   tt.store %21, %22 : tensor<256xf32, #layout1>\n   return\n }\n+\n+// Select has args with different element types\n+// CHECK-LABEL: select\n+func @select(%arg0: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32}) {\n+  // CHECK-NOT: triton_gpu.convert_layout\n+  %cst = arith.constant dense<30000> : tensor<1x1xi32, #blocked2>\n+  %cst_0 = arith.constant dense<30000> : tensor<1x512xi32, #blocked2>\n+  %c512 = arith.constant 512 : index\n+  %c30000 = arith.constant 30000 : index\n+  %c0 = arith.constant 0 : index\n+  %cst_1 = arith.constant dense<2048> : tensor<1x1xi32, #blocked2>\n+  %cst_2 = arith.constant dense<0.000000e+00> : tensor<1x512xf64, #blocked2>\n+  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %1 = tt.make_range {end = 1 : i32, start = 0 : i32} : tensor<1xi32, #blocked0>\n+  %2 = triton_gpu.convert_layout %1 : (tensor<1xi32, #blocked0>) -> tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>\n+  %3 = tt.expand_dims %2 {axis = 1 : i32} : (tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>) -> tensor<1x1xi32, #blocked1>\n+  %4 = triton_gpu.convert_layout %3 : (tensor<1x1xi32, #blocked1>) -> tensor<1x1xi32, #blocked2>\n+  %5 = tt.splat %0 : (i32) -> tensor<1x1xi32, #blocked2>\n+  %6 = arith.addi %5, %4 : tensor<1x1xi32, #blocked2>\n+  %7 = \"triton_gpu.cmpi\"(%6, %cst_1) {predicate = 2 : i64} : (tensor<1x1xi32, #blocked2>, tensor<1x1xi32, #blocked2>) -> tensor<1x1xi1, #blocked2>\n+  %8 = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #blocked0>\n+  %9 = triton_gpu.convert_layout %8 : (tensor<512xi32, #blocked0>) -> tensor<512xi32, #triton_gpu.slice<{dim = 0, parent = #blocked2}>>\n+  %10 = tt.expand_dims %9 {axis = 0 : i32} : (tensor<512xi32, #triton_gpu.slice<{dim = 0, parent = #blocked2}>>) -> tensor<1x512xi32, #blocked2>\n+  %11 = arith.muli %6, %cst : tensor<1x1xi32, #blocked2>\n+  %12 = tt.broadcast %11 : (tensor<1x1xi32, #blocked2>) -> tensor<1x512xi32, #blocked2>\n+  %13 = tt.splat %arg0 : (!tt.ptr<f64>) -> tensor<1x512x!tt.ptr<f64>, #blocked2>\n+  %14 = tt.broadcast %7 : (tensor<1x1xi1, #blocked2>) -> tensor<1x512xi1, #blocked2>\n+  %15 = scf.for %arg3 = %c0 to %c30000 step %c512 iter_args(%arg4 = %cst_2) -> (tensor<1x512xf64, #blocked2>) {\n+    %16 = arith.index_cast %arg3 : index to i32\n+    %17 = tt.splat %16 : (i32) -> tensor<1x512xi32, #blocked2>\n+    %18 = arith.addi %17, %10 : tensor<1x512xi32, #blocked2>\n+    %19 = \"triton_gpu.cmpi\"(%18, %cst_0) {predicate = 2 : i64} : (tensor<1x512xi32, #blocked2>, tensor<1x512xi32, #blocked2>) -> tensor<1x512xi1, #blocked2>\n+    %20 = arith.addi %18, %12 : tensor<1x512xi32, #blocked2>\n+    %21 = tt.addptr %13, %20 : tensor<1x512x!tt.ptr<f64>, #blocked2>, tensor<1x512xi32, #blocked2>\n+    %22 = arith.andi %19, %14 : tensor<1x512xi1, #blocked2>\n+    %23 = triton_gpu.convert_layout %21 : (tensor<1x512x!tt.ptr<f64>, #blocked2>) -> tensor<1x512x!tt.ptr<f64>, #blocked3>\n+    %24 = triton_gpu.convert_layout %22 : (tensor<1x512xi1, #blocked2>) -> tensor<1x512xi1, #blocked3>\n+    %25 = tt.load %23, %24 {cache = 1 : i32, evict = 3 : i32, isVolatile = false} : tensor<1x512xf64, #blocked3>\n+    %26 = triton_gpu.convert_layout %25 : (tensor<1x512xf64, #blocked3>) -> tensor<1x512xf64, #blocked2>\n+    %27 = arith.andi %14, %19 : tensor<1x512xi1, #blocked2>\n+    %28 = \"triton_gpu.cmpf\"(%arg4, %26) {predicate = 4 : i64} : (tensor<1x512xf64, #blocked2>, tensor<1x512xf64, #blocked2>) -> tensor<1x512xi1, #blocked2>\n+    %29 = arith.andi %27, %28 : tensor<1x512xi1, #blocked2>\n+    %30 = \"triton_gpu.select\"(%29, %26, %arg4) : (tensor<1x512xi1, #blocked2>, tensor<1x512xf64, #blocked2>, tensor<1x512xf64, #blocked2>) -> tensor<1x512xf64, #blocked2>\n+    %31 = triton_gpu.convert_layout %21 : (tensor<1x512x!tt.ptr<f64>, #blocked2>) -> tensor<1x512x!tt.ptr<f64>, #blocked3>\n+    %32 = triton_gpu.convert_layout %30 : (tensor<1x512xf64, #blocked2>) -> tensor<1x512xf64, #blocked3>\n+    %33 = triton_gpu.convert_layout %27 : (tensor<1x512xi1, #blocked2>) -> tensor<1x512xi1, #blocked3>\n+    tt.store %31, %32, %33 : tensor<1x512xf64, #blocked3>\n+    scf.yield %30 : tensor<1x512xf64, #blocked2>\n+  }\n+  return\n+}\n\\ No newline at end of file"}]