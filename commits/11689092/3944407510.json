[{"filename": "include/triton/Conversion/TritonGPUToLLVM/PTXAsmFormat.h", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -161,9 +161,8 @@ struct PTXBuilder {\n \n   std::string dump() const;\n \n-  mlir::Value launch(ConversionPatternRewriter &rewriter, Location loc,\n-                     Type resTy, bool hasSideEffect = true,\n-                     bool isAlignStack = false,\n+  mlir::Value launch(OpBuilder &rewriter, Location loc, Type resTy,\n+                     bool hasSideEffect = true, bool isAlignStack = false,\n                      ArrayRef<Attribute> attrs = {}) const;\n \n private:"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUOps.td", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "file_content_changes": "@@ -40,6 +40,19 @@ def TTG_AsyncWaitOp : TTG_Op<\"async_wait\"> {\n   }];\n }\n \n+def TTG_AsyncCommitGroupOp : TTG_Op<\"async_commit_group\"> {\n+  let summary = \"async commit group\";\n+\n+  let assemblyFormat = \"attr-dict\";\n+\n+  let extraClassDeclaration = [{\n+    static bool isSupported(int computeCapability) {\n+      return computeCapability >= 80;\n+    }\n+  }];\n+}\n+\n+\n // Port Arith_CmpIOp & Arith_CmpFOp & Std_SelectOp to TritonGPU.\n // This is needed because these ops don't\n // handle encodings"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpHelpers.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -1391,7 +1391,9 @@ struct MMA16816ConversionHelper {\n       unsigned colsPerThread = numRepN * 2;\n       PTXBuilder builder;\n       auto &mma = *builder.create(helper.getMmaInstr().str());\n-      auto retArgs = builder.newListOperand(4, \"=r\");\n+      // using =r for float32 works but leads to less readable ptx.\n+      bool isIntMMA = dTensorTy.getElementType().isInteger(32);\n+      auto retArgs = builder.newListOperand(4, isIntMMA ? \"=r\" : \"=f\");\n       auto aArgs = builder.newListOperand({\n           {ha[{m, k}], \"r\"},\n           {ha[{m + 1, k}], \"r\"},"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -177,7 +177,9 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n       PTXBuilder builder;\n       auto idx = getIdx(m, n);\n \n-      auto *resOprs = builder.newListOperand(8, \"=f\");\n+      // note: using \"=f\" for float leads to cleaner PTX\n+      bool isIntMMA = DTensorTy.getElementType().isInteger(32);\n+      auto *resOprs = builder.newListOperand(8, isIntMMA ? \"=r\" : \"=f\");\n       auto *AOprs = builder.newListOperand({\n           {ha.first, \"r\"},\n           {ha.second, \"r\"},"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "file_content_changes": "@@ -802,9 +802,6 @@ struct InsertSliceAsyncOpConversion\n       }\n     }\n \n-    PTXBuilder ptxBuilder;\n-    ptxBuilder.create<>(\"cp.async.commit_group\")->operator()();\n-    ptxBuilder.launch(rewriter, loc, void_ty(getContext()));\n     rewriter.replaceOp(op, llDst);\n     return success();\n   }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/PTXAsmFormat.cpp", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -78,9 +78,8 @@ SmallVector<PTXBuilder::Operand *, 4> PTXBuilder::getAllArgs() const {\n   return res;\n }\n \n-mlir::Value PTXBuilder::launch(ConversionPatternRewriter &rewriter,\n-                               Location loc, Type resTy, bool hasSideEffect,\n-                               bool isAlignStack,\n+mlir::Value PTXBuilder::launch(OpBuilder &rewriter, Location loc, Type resTy,\n+                               bool hasSideEffect, bool isAlignStack,\n                                ArrayRef<Attribute> attrs) const {\n   auto *ctx = rewriter.getContext();\n   auto inlineAsm = rewriter.create<LLVM::InlineAsmOp>("}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "file_content_changes": "@@ -505,6 +505,24 @@ struct AsyncWaitOpConversion\n   }\n };\n \n+struct AsyncCommitGroupOpConversion\n+    : public ConvertTritonGPUOpToLLVMPattern<triton::gpu::AsyncCommitGroupOp> {\n+  using ConvertTritonGPUOpToLLVMPattern<\n+      triton::gpu::AsyncCommitGroupOp>::ConvertTritonGPUOpToLLVMPattern;\n+\n+  LogicalResult\n+  matchAndRewrite(triton::gpu::AsyncCommitGroupOp op, OpAdaptor adaptor,\n+                  ConversionPatternRewriter &rewriter) const override {\n+\n+    PTXBuilder ptxBuilder;\n+    ptxBuilder.create<>(\"cp.async.commit_group\")->operator()();\n+    ptxBuilder.launch(rewriter, op.getLoc(), void_ty(op.getContext()));\n+    // Safe to remove the op since it doesn't have any return value.\n+    rewriter.eraseOp(op);\n+    return success();\n+  }\n+};\n+\n void populateTritonGPUToLLVMPatterns(\n     mlir::LLVMTypeConverter &typeConverter, RewritePatternSet &patterns,\n     int numWarps, AxisInfoAnalysis &axisInfoAnalysis,\n@@ -514,6 +532,7 @@ void populateTritonGPUToLLVMPatterns(\n   patterns.add<AddPtrOpConversion>(typeConverter, benefit);\n   patterns.add<AllocTensorOpConversion>(typeConverter, allocation, smem,\n                                         benefit);\n+  patterns.add<AsyncCommitGroupOpConversion>(typeConverter, benefit);\n   patterns.add<AsyncWaitOpConversion>(typeConverter, benefit);\n   patterns.add<BroadcastOpConversion>(typeConverter, benefit);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "file_content_changes": "@@ -388,6 +388,11 @@ class ConvertTritonGPUToLLVM\n       decomposed = true;\n     });\n \n+    mod.walk([&](triton::gpu::AsyncCommitGroupOp asyncCommitGroupOp) -> void {\n+      if (!triton::gpu::AsyncCommitGroupOp::isSupported(computeCapability))\n+        asyncCommitGroupOp.erase();\n+    });\n+\n     mod.walk([&](triton::gpu::AsyncWaitOp asyncWaitOp) -> void {\n       if (!triton::gpu::AsyncWaitOp::isSupported(computeCapability)) {\n         // async wait is supported in Ampere and later"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 43, "deletions": 17, "changes": 60, "file_content_changes": "@@ -302,6 +302,7 @@ void LoopPipeliner::emitPrologue() {\n               loadStageBuffer[loadOp][stage], pipelineIterIdx, newMask,\n               lookupOrDefault(loadOp.other(), stage), loadOp.cache(),\n               loadOp.evict(), loadOp.isVolatile(), /*axis*/ 0);\n+          builder.create<triton::gpu::AsyncCommitGroupOp>(op->getLoc());\n           loadStageBuffer[loadOp].push_back(newOp->getResult(0));\n         } else\n           llvm_unreachable(\"This should be LoadOp\");\n@@ -319,6 +320,9 @@ void LoopPipeliner::emitPrologue() {\n       }\n \n       // Update mapping of results\n+      // if (stage == numStages - 2)\n+      //   continue;\n+\n       for (unsigned dstIdx : llvm::seq(unsigned(0), op->getNumResults())) {\n         Value originalResult = op->getResult(dstIdx);\n         // copy_async will update the value of its only use\n@@ -383,7 +387,7 @@ scf::ForOp LoopPipeliner::createNewForOp() {\n   //   (original args)\n   //   (insertSliceAsync buffer at stage numStages - 1) for each load\n   //   (extracted tensor) for each load\n-  //   (depArgs at stage numStages - 1)\n+  //   (depArgs at stage numStages - 2)\n   //   (iv at stage numStages - 2)\n   //   (pipeline iteration index)\n   //   (loop iteration index)\n@@ -404,7 +408,7 @@ scf::ForOp LoopPipeliner::createNewForOp() {\n   size_t depArgsBeginIdx = newLoopArgs.size();\n   for (BlockArgument depArg : depArgs) {\n     depArgsIdx[depArg] = newLoopArgs.size();\n-    newLoopArgs.push_back(valueMapping[depArg][numStages - 1]);\n+    newLoopArgs.push_back(valueMapping[depArg][numStages - 2]);\n   }\n \n   size_t nextIVIdx = newLoopArgs.size();\n@@ -463,10 +467,12 @@ scf::ForOp LoopPipeliner::createNewForOp() {\n   DenseMap<BlockArgument, Value> depArgsMapping;\n   size_t argIdx = 0;\n   for (BlockArgument arg : depArgs) {\n-    nextMapping.map(arg,\n-                    newForOp.getRegionIterArgs()[argIdx + depArgsBeginIdx]);\n+    BlockArgument nextArg =\n+        newForOp.getRegionIterArgs()[argIdx + depArgsBeginIdx];\n+    nextMapping.map(arg, nextArg);\n     ++argIdx;\n   }\n+\n   // Special handling for iv & loop condition\n   Value nextIV = builder.create<arith::AddIOp>(\n       newForOp.getInductionVar().getLoc(),\n@@ -491,6 +497,25 @@ scf::ForOp LoopPipeliner::createNewForOp() {\n   extractSliceIndex = builder.create<arith::IndexCastOp>(\n       extractSliceIndex.getLoc(), builder.getIndexType(), extractSliceIndex);\n \n+  for (Operation *op : orderedDeps)\n+    if (!loads.contains(op->getResult(0))) {\n+      Operation *nextOp = builder.clone(*op, nextMapping);\n+\n+      auto originYield = cast<scf::YieldOp>(forOp.getBody()->getTerminator());\n+      for (unsigned dstIdx : llvm::seq(unsigned(0), op->getNumResults())) {\n+        for (OpOperand &operand : originYield->getOpOperands()) {\n+          if (operand.get() == op->getResult(dstIdx)) {\n+            size_t originIdx = operand.getOperandNumber();\n+            size_t newArgIdx = depArgsIdx[forOp.getRegionIterArgs()[originIdx]];\n+            BlockArgument newArg = newForOp.getRegionIterArgs()[newArgIdx];\n+            nextMapping.map(forOp.getRegionIterArgs()[originIdx],\n+                            nextOp->getResult(dstIdx));\n+            depArgsMapping[newArg] = nextOp->getResult(dstIdx);\n+          }\n+        }\n+      }\n+    }\n+\n   for (Operation *op : orderedDeps) {\n     Operation *nextOp = nullptr;\n     // Update loading mask\n@@ -518,6 +543,7 @@ scf::ForOp LoopPipeliner::createNewForOp() {\n           insertSliceIndex, newMask,\n           nextMapping.lookupOrDefault(loadOp.other()), loadOp.cache(),\n           loadOp.evict(), loadOp.isVolatile(), /*axis*/ 0);\n+      builder.create<triton::gpu::AsyncCommitGroupOp>(op->getLoc());\n       nextBuffers.push_back(insertAsyncOp);\n       auto sliceType = loadsMapping[loadOp].getType().cast<RankedTensorType>();\n       sliceType = RankedTensorType::get(sliceType.getShape(),\n@@ -532,19 +558,19 @@ scf::ForOp LoopPipeliner::createNewForOp() {\n                                     int_attr(sliceType.getShape()[1])},\n           SmallVector<OpFoldResult>{int_attr(1), int_attr(1), int_attr(1)});\n       extractSlices.push_back(nextOp->getResult(0));\n-    } else\n-      nextOp = builder.clone(*op, nextMapping);\n-    // Update mapping of results\n-    for (unsigned dstIdx : llvm::seq(unsigned(0), op->getNumResults())) {\n-      nextMapping.map(op->getResult(dstIdx), nextOp->getResult(dstIdx));\n-      // If this is a loop-carried value, update the mapping for yield\n-      auto originYield = cast<scf::YieldOp>(forOp.getBody()->getTerminator());\n-      for (OpOperand &operand : originYield->getOpOperands()) {\n-        if (operand.get() == op->getResult(dstIdx)) {\n-          size_t originIdx = operand.getOperandNumber();\n-          size_t newArgIdx = depArgsIdx[forOp.getRegionIterArgs()[originIdx]];\n-          BlockArgument newArg = newForOp.getRegionIterArgs()[newArgIdx];\n-          depArgsMapping[newArg] = nextOp->getResult(dstIdx);\n+\n+      // Update mapping of results\n+      for (unsigned dstIdx : llvm::seq(unsigned(0), op->getNumResults())) {\n+        nextMapping.map(op->getResult(dstIdx), nextOp->getResult(dstIdx));\n+        // If this is a loop-carried value, update the mapping for yield\n+        auto originYield = cast<scf::YieldOp>(forOp.getBody()->getTerminator());\n+        for (OpOperand &operand : originYield->getOpOperands()) {\n+          if (operand.get() == op->getResult(dstIdx)) {\n+            size_t originIdx = operand.getOperandNumber();\n+            size_t newArgIdx = depArgsIdx[forOp.getRegionIterArgs()[originIdx]];\n+            BlockArgument newArg = newForOp.getRegionIterArgs()[newArgIdx];\n+            depArgsMapping[newArg] = nextOp->getResult(dstIdx);\n+          }\n         }\n       }\n     }"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -248,13 +248,17 @@ scf::ForOp Prefetcher::createNewForOp() {\n                      prefetchWidth;\n       Operation *prevDot = firstDot;\n       while (kRem != 0) {\n-        int64_t kShape = largestPow2(kRem);\n+        // int64_t kShape = largestPow2(kRem);\n+        int64_t kShape = prefetchWidth;\n+        auto insertionPoint = builder.saveInsertionPoint();\n+        builder.setInsertionPoint(prevDot);\n         Value aRem =\n             generatePrefetch(mapping.lookup(dot2aLoopArg[dot]), 0, false,\n                              dotEncoding, builder, kOff, kShape);\n         Value bRem =\n             generatePrefetch(mapping.lookup(dot2bLoopArg[dot]), 1, false,\n                              dotEncoding, builder, kOff, kShape);\n+        builder.restoreInsertionPoint(insertionPoint);\n         newOp = builder.clone(*dot, mapping);\n         newOp->setOperand(0, aRem);\n         newOp->setOperand(1, bRem);"}, {"filename": "lib/Dialect/TritonGPU/Transforms/ReorderInstructions.cpp", "status": "modified", "additions": 10, "deletions": 2, "changes": 12, "file_content_changes": "@@ -53,6 +53,9 @@ class TritonGPUReorderInstructionsPass\n       auto user_end = op->user_end();\n       if (std::distance(user_begin, user_end) != 1)\n         return;\n+      if (user_begin->getParentOfType<scf::ForOp>() ==\n+          op->getParentOfType<scf::ForOp>())\n+        return;\n       opToMove.insert({op, *user_begin});\n     });\n     for (auto &kv : opToMove)\n@@ -89,8 +92,13 @@ class TritonGPUReorderInstructionsPass\n         return;\n       if (op->getUsers().empty())\n         return;\n-      auto user_begin = op->user_begin();\n-      op->moveBefore(*user_begin);\n+      auto dotUser = dyn_cast<triton::DotOp>(*op->user_begin());\n+      if (!dotUser)\n+        return;\n+      auto BOp = dotUser.getOperand(1).getDefiningOp();\n+      if (!BOp)\n+        return;\n+      op->moveBefore(BOp);\n     });\n     return;\n   }"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -1487,9 +1487,9 @@ def compile(fn, **kwargs):\n         import re\n         match = re.search(prototype_pattern[ir], src, re.MULTILINE)\n         name, signature = match.group(1), match.group(2)\n-        print(name, signature)\n+        # print(name, signature)\n         types = re.findall(arg_type_pattern[ir], signature)\n-        print(types)\n+        # print(types)\n         param_tys = [convert_type_repr(ty) for ty in types]\n         signature = {k: v for k, v in enumerate(param_tys)}\n         first_stage = list(stages.keys()).index(ir)\n@@ -1580,6 +1580,7 @@ def _init_handles(self):\n         if self.shared > max_shared:\n             raise OutOfResources(self.shared, max_shared, \"shared memory\")\n         mod, func, n_regs, n_spills = cuda_utils.load_binary(self.metadata[\"name\"], self.asm[\"cubin\"], self.shared, device)\n+        # print(self.shared, n_regs, n_spills)\n         self.cu_module = mod\n         self.cu_function = func\n "}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -461,6 +461,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n     // CHECK: llvm.inline_asm has_side_effects asm_dialect = att\n     // CHECK-SAME: cp.async.commit_group\n     %a = triton_gpu.insert_slice_async %a_ptr, %tensor, %index {axis = 0 : i32, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x64x!tt.ptr<f32>, #AL> -> tensor<2x16x64xf32, #A>\n+    triton_gpu.async_commit_group\n     return\n   }\n }\n@@ -506,6 +507,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: cp.async.commit_group\n     %a = triton_gpu.insert_slice_async %a_ptr, %tensor, %index {axis = 0 : i32, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x32x!tt.ptr<f32>, #AL> -> tensor<2x16x32xf32, #A>\n+    triton_gpu.async_commit_group\n     return\n   }\n }\n@@ -562,6 +564,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: cp.async.commit_group\n     %a = triton_gpu.insert_slice_async %a_ptr, %tensor, %index {axis = 0 : i32, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<32x32x!tt.ptr<f32>, #AL> -> tensor<2x32x32xf32, #A>\n+    triton_gpu.async_commit_group\n     return\n   }\n }"}, {"filename": "test/TritonGPU/prefetch.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -17,11 +17,11 @@\n // CHECK-DAG: %[[B0_PREFETCH_SMEM:.*]] = tensor.extract_slice %[[B0:.*]][0, 0] [16, 128]\n // CHECK-DAG: %[[B0_PREFETCH:.*]] = triton_gpu.convert_layout %[[B0_PREFETCH_SMEM]]\n // CHECK:     scf.for {{.*}} iter_args({{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, %[[a0_prefetch:.*]] = %[[A0_PREFETCH]], %[[b0_prefetch:.*]] = %[[B0_PREFETCH]]\n-// CHECK:       %[[D_FIRST:.*]] = tt.dot %[[a0_prefetch]], %[[b0_prefetch:.*]], {{.*}}\n // CHECK-DAG:   %[[A_REM_SMEM:.*]] = tensor.extract_slice %[[arg_a0]][0, 16] [128, 16]\n // CHECK-DAG:   %[[A_REM:.*]] = triton_gpu.convert_layout %[[A_REM_SMEM]]\n // CHECK-DAG:   %[[B_REM_SMEM:.*]] = tensor.extract_slice %[[arg_b0]][16, 0] [16, 128]\n // CHECK-DAG:   %[[B_REM:.*]] = triton_gpu.convert_layout %[[B_REM_SMEM]]\n+// CHECK:       %[[D_FIRST:.*]] = tt.dot %[[a0_prefetch]], %[[b0_prefetch:.*]], {{.*}}\n // CHECK:       tt.dot %[[A_REM]], %[[B_REM]], %[[D_FIRST:.*]]\n // CHECK-DAG:   %[[NEXT_A_PREFETCH_SMEM:.*]] = tensor.extract_slice {{.*}}[0, 0] [128, 16]\n // CHECK-DAG:   %[[NEXT_A_PREFETCH:.*]] = triton_gpu.convert_layout %[[NEXT_A_PREFETCH_SMEM]]"}]