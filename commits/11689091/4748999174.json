[{"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -21,7 +21,9 @@ namespace mlir {\n namespace triton {\n namespace gpu {\n \n-unsigned getElemsPerThread(Type type);\n+unsigned getTotalElemsPerThread(Type type);\n+\n+SmallVector<unsigned> getElemsPerThread(Type type);\n \n SmallVector<unsigned> getThreadsPerWarp(Attribute layout);\n "}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -35,7 +35,8 @@ Right now, Triton implements two classes of layouts: shared, and distributed.\n   }];\n \n   code extraBaseClassDeclaration = [{\n-    unsigned getElemsPerThread(ArrayRef<int64_t> shape, Type eltTy) const;\n+    unsigned getTotalElemsPerThread(ArrayRef<int64_t> shape, Type eltTy) const;\n+    SmallVector<unsigned> getElemsPerThread(ArrayRef<int64_t> shape, Type eltTy) const;\n     ::mlir::LogicalResult verifyLayoutForArg(::mlir::Operation* op, unsigned argNo) const;\n   }];\n }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -5,10 +5,10 @@ using ::mlir::LLVM::getSharedMemoryObjectFromStruct;\n using ::mlir::LLVM::getStridesFromShapeAndOrder;\n using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getContigPerThread;\n-using ::mlir::triton::gpu::getElemsPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n@@ -422,14 +422,14 @@ struct ConvertLayoutOpConversion\n     }\n     // Potentially we need to store for multiple CTAs in this replication\n     auto accumNumReplicates = product<unsigned>(numReplicates);\n-    // unsigned elems = getElemsPerThread(srcTy);\n+    // unsigned elems = getTotalElemsPerThread(srcTy);\n     auto vals = getTypeConverter()->unpackLLElements(loc, adaptor.getSrc(),\n                                                      rewriter, srcTy);\n     unsigned inVec = 0;\n     unsigned outVec = 0;\n     auto paddedRepShape = getScratchConfigForCvtLayout(op, inVec, outVec);\n \n-    unsigned outElems = getElemsPerThread(dstTy);\n+    unsigned outElems = getTotalElemsPerThread(dstTy);\n     auto outOrd = getOrder(dstLayout);\n     SmallVector<Value> outVals(outElems);\n \n@@ -572,7 +572,7 @@ struct ConvertLayoutOpConversion\n       // get source values\n       auto vals = getTypeConverter()->unpackLLElements(loc, adaptor.getSrc(),\n                                                        rewriter, srcTy);\n-      unsigned elems = getElemsPerThread(srcTy);\n+      unsigned elems = getTotalElemsPerThread(srcTy);\n       Type elemTy =\n           this->getTypeConverter()->convertType(srcTy.getElementType());\n       // for the destination type, we need to pack values together"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandFMA.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -6,10 +6,10 @@ using ::mlir::LLVM::getSharedMemoryObjectFromStruct;\n using ::mlir::LLVM::getStridesFromShapeAndOrder;\n using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getContigPerThread;\n-using ::mlir::triton::gpu::getElemsPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv1.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -7,10 +7,10 @@ using ::mlir::LLVM::getSharedMemoryObjectFromStruct;\n using ::mlir::LLVM::getStridesFromShapeAndOrder;\n using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getContigPerThread;\n-using ::mlir::triton::gpu::getElemsPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -6,10 +6,10 @@ using ::mlir::LLVM::getSharedMemoryObjectFromStruct;\n using ::mlir::LLVM::getStridesFromShapeAndOrder;\n using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getContigPerThread;\n-using ::mlir::triton::gpu::getElemsPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/MMAv2.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -14,7 +14,7 @@ Value loadC(Value tensor, Value llTensor,\n             ConversionPatternRewriter &rewriter) {\n   MLIRContext *ctx = tensor.getContext();\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n-  size_t fcSize = triton::gpu::getElemsPerThread(tensor.getType());\n+  size_t fcSize = triton::gpu::getTotalElemsPerThread(tensor.getType());\n \n   assert(tensorTy.getEncoding().isa<MmaEncodingAttr>() &&\n          \"Currently, we only support $c with a mma layout.\");"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -2,7 +2,7 @@\n \n using namespace mlir;\n using namespace mlir::triton;\n-using ::mlir::triton::gpu::getElemsPerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n \n struct FpToFpOpConversion\n     : public ConvertTritonGPUOpToLLVMPattern<triton::FpToFpOp> {\n@@ -499,7 +499,7 @@ struct FpToFpOpConversion\n     auto srcEltType = srcTensorType.getElementType();\n     auto dstEltType = dstTensorType.getElementType();\n     auto loc = op->getLoc();\n-    auto elems = getElemsPerThread(dstTensorType);\n+    auto elems = getTotalElemsPerThread(dstTensorType);\n     SmallVector<Value> resultVals;\n     bool isSrcFP8 =\n         srcEltType.isa<mlir::Float8E4M3FNType, mlir::Float8E5M2Type>();\n@@ -583,7 +583,7 @@ class ElementwiseOpConversionBase\n     auto resultTy = op.getType();\n     Location loc = op->getLoc();\n \n-    unsigned elems = getElemsPerThread(resultTy);\n+    unsigned elems = getTotalElemsPerThread(resultTy);\n     auto resultElementTy = getElementTypeOrSelf(resultTy);\n     Type elemTy = this->getTypeConverter()->convertType(resultElementTy);\n     SmallVector<Type> types(elems, elemTy);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "file_content_changes": "@@ -8,7 +8,7 @@ using namespace mlir;\n using namespace mlir::triton;\n \n using ::mlir::LLVM::getSharedMemoryObjectFromStruct;\n-using ::mlir::triton::gpu::getElemsPerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n // Contains some helper functions for both Load and Store conversions.\n@@ -72,7 +72,7 @@ struct LoadOpConversion\n     Type valueElemTy =\n         typeConverter->convertType(getElementTypeOrSelf(valueTy));\n     unsigned vec = getVectorSize(ptr);\n-    unsigned numElems = getElemsPerThread(ptr.getType());\n+    unsigned numElems = getTotalElemsPerThread(ptr.getType());\n     if (llMask)\n       vec = std::min<size_t>(vec, getMaskAlignment(mask));\n \n@@ -276,7 +276,7 @@ struct StoreOpConversion\n         typeConverter->convertType(getElementTypeOrSelf(valueTy));\n \n     unsigned vec = getVectorSize(ptr);\n-    unsigned elemsPerThread = getElemsPerThread(ptr.getType());\n+    unsigned elemsPerThread = getTotalElemsPerThread(ptr.getType());\n \n     auto ptrElems = getTypeConverter()->unpackLLElements(loc, llPtr, rewriter,\n                                                          ptr.getType());\n@@ -493,7 +493,7 @@ struct AtomicRMWOpConversion\n         tensorTy ? getTypeConverter()->convertType(tensorTy.getElementType())\n                  : op.getResult().getType();\n     const size_t valueElemNBits = valueElemTy.getIntOrFloatBitWidth();\n-    auto elemsPerThread = getElemsPerThread(val.getType());\n+    auto elemsPerThread = getTotalElemsPerThread(val.getType());\n     // vec = 1, numElements = 1 for scalar\n     auto vec = getVectorSize(ptr);\n     int numElems = 1;\n@@ -776,7 +776,7 @@ struct InsertSliceAsyncOpConversion\n     unsigned inVec = getContiguity(src);\n     unsigned outVec = resSharedLayout.getVec();\n     unsigned minVec = std::min(outVec, inVec);\n-    unsigned numElems = getElemsPerThread(srcTy);\n+    unsigned numElems = getTotalElemsPerThread(srcTy);\n     unsigned perPhase = resSharedLayout.getPerPhase();\n     unsigned maxPhase = resSharedLayout.getMaxPhase();\n     auto sizePerThread = srcBlockedLayout.getSizePerThread();"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -5,8 +5,8 @@ using namespace mlir::triton;\n \n using ::mlir::LLVM::shflSync;\n using ::mlir::LLVM::storeShared;\n-using ::mlir::triton::gpu::getElemsPerThread;\n using ::mlir::triton::gpu::getOrder;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n \n struct ReduceOpConversion\n     : public ConvertTritonGPUOpToLLVMPattern<triton::ReduceOp> {\n@@ -64,7 +64,7 @@ struct ReduceOpConversion\n                ConversionPatternRewriter &rewriter) const {\n     auto types = op.getInputTypes();\n     auto operands = adaptor.getOperands();\n-    unsigned srcElems = getElemsPerThread(types[0]);\n+    unsigned srcElems = getTotalElemsPerThread(types[0]);\n     SmallVector<SmallVector<Value>> srcValues(srcElems);\n     for (unsigned i = 0; i < op.getNumOperands(); ++i) {\n       auto values = getTypeConverter()->unpackLLElements(loc, operands[i],\n@@ -158,7 +158,7 @@ struct ReduceOpConversion\n                   elemPtrTys[i]);\n     }\n \n-    unsigned srcElems = getElemsPerThread(srcTys[0]);\n+    unsigned srcElems = getTotalElemsPerThread(srcTys[0]);\n     // Emits indices of the original tensor that each thread\n     // would own\n     auto srcIndices = emitIndices(loc, rewriter, srcLayout, srcTys[0]);\n@@ -263,7 +263,7 @@ struct ReduceOpConversion\n \n         auto resultLayout = resultTy.getEncoding();\n \n-        unsigned resultElems = getElemsPerThread(resultTy);\n+        unsigned resultElems = getTotalElemsPerThread(resultTy);\n         auto resultIndices = emitIndices(loc, rewriter, resultLayout, resultTy);\n         assert(resultIndices.size() == resultElems);\n \n@@ -330,7 +330,7 @@ struct ReduceOpConversion\n     unsigned sizeIntraWarps = helper.getIntraWarpSize();\n     unsigned sizeInterWarps = helper.getInterWarpSize();\n \n-    unsigned srcElems = getElemsPerThread(srcTys[0]);\n+    unsigned srcElems = getTotalElemsPerThread(srcTys[0]);\n     auto srcIndices = emitIndices(loc, rewriter, srcLayout, srcTys[0]);\n     auto srcValues = unpackInputs(loc, op, adaptor, rewriter);\n \n@@ -457,7 +457,7 @@ struct ReduceOpConversion\n               op.getResult()[i].getType().dyn_cast<RankedTensorType>()) {\n         // nd-tensor where n >= 1\n         auto resultLayout = resultTy.getEncoding().cast<SliceEncodingAttr>();\n-        unsigned resultElems = getElemsPerThread(resultTy);\n+        unsigned resultElems = getTotalElemsPerThread(resultTy);\n         auto resultIndices = emitIndices(loc, rewriter, resultLayout, resultTy);\n         assert(resultIndices.size() == resultElems);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -6,7 +6,7 @@ using namespace mlir;\n using namespace mlir::triton;\n \n using ::mlir::LLVM::getSharedMemoryObjectFromStruct;\n-using ::mlir::triton::gpu::getElemsPerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n struct ReturnOpConversion : public ConvertOpToLLVMPattern<triton::ReturnOp> {\n@@ -435,7 +435,7 @@ struct AddPtrOpConversion\n     auto ptrTy = op.getPtr().getType();\n     auto resultTensorTy = resultTy.dyn_cast<RankedTensorType>();\n     if (resultTensorTy) {\n-      unsigned elems = getElemsPerThread(resultTy);\n+      unsigned elems = getTotalElemsPerThread(resultTy);\n       Type elemTy =\n           getTypeConverter()->convertType(resultTensorTy.getElementType());\n       auto ptrs = getTypeConverter()->unpackLLElements(loc, adaptor.getPtr(),"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -275,7 +275,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n \n     auto srcEncoding = srcTy.getEncoding();\n     auto srcShape = srcTy.getShape();\n-    unsigned numElems = triton::gpu::getElemsPerThread(srcTy);\n+    unsigned numElems = triton::gpu::getTotalElemsPerThread(srcTy);\n     // swizzling params as described in TritonGPUAttrDefs.td\n     unsigned outVec = resSharedLayout.getVec();\n     unsigned perPhase = resSharedLayout.getPerPhase();\n@@ -376,7 +376,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     unsigned minVec = std::min(outVec, inVec);\n     unsigned perPhase = dstSharedLayout.getPerPhase();\n     unsigned maxPhase = dstSharedLayout.getMaxPhase();\n-    unsigned numElems = triton::gpu::getElemsPerThread(srcTy);\n+    unsigned numElems = triton::gpu::getTotalElemsPerThread(srcTy);\n     assert(numElems == srcIndices.size());\n     auto inVals =\n         getTypeConverter()->unpackLLElements(loc, llSrc, rewriter, srcTy);\n@@ -667,7 +667,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n                                   threadOffset * sizePerThread[k] + elemOffset);\n     }\n \n-    unsigned elemsPerThread = triton::gpu::getElemsPerThread(type);\n+    unsigned elemsPerThread = triton::gpu::getTotalElemsPerThread(type);\n     unsigned totalSizePerThread = product<unsigned>(sizePerThread);\n     SmallVector<SmallVector<unsigned>> reorderedOffset(elemsPerThread);\n     for (unsigned n = 0; n < elemsPerThread; ++n) {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -8,7 +8,7 @@ using namespace mlir::triton;\n \n using ::mlir::triton::gpu::BlockedEncodingAttr;\n using ::mlir::triton::gpu::DotOperandEncodingAttr;\n-using ::mlir::triton::gpu::getElemsPerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::MmaEncodingAttr;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n using ::mlir::triton::gpu::SliceEncodingAttr;\n@@ -144,7 +144,7 @@ Type TritonGPUToLLVMTypeConverter::convertTritonTensorType(\n     return LLVM::LLVMStructType::getLiteral(ctx, types);\n   }\n \n-  unsigned numElementsPerThread = getElemsPerThread(type);\n+  unsigned numElementsPerThread = getTotalElemsPerThread(type);\n   SmallVector<Type, 4> types(numElementsPerThread, eltType);\n   return LLVM::LLVMStructType::getLiteral(ctx, types);\n }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ViewOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -4,7 +4,7 @@ using namespace mlir;\n using namespace mlir::triton;\n \n using ::mlir::LLVM::getSharedMemoryObjectFromStruct;\n-using ::mlir::triton::gpu::getElemsPerThread;\n+using ::mlir::triton::gpu::getTotalElemsPerThread;\n \n struct SplatOpConversion\n     : public ConvertTritonGPUOpToLLVMPattern<triton::SplatOp> {\n@@ -24,7 +24,7 @@ struct SplatOpConversion\n     auto tensorTy = resType.cast<RankedTensorType>();\n     auto srcType = typeConverter->convertType(elemType);\n     auto llSrc = bitcast(constVal, srcType);\n-    size_t elemsPerThread = getElemsPerThread(tensorTy);\n+    size_t elemsPerThread = getTotalElemsPerThread(tensorTy);\n     llvm::SmallVector<Value> elems(elemsPerThread, llSrc);\n     return typeConverter->packLLElements(loc, elems, rewriter, resType);\n   }\n@@ -93,7 +93,7 @@ struct CatOpConversion : public ConvertTritonGPUOpToLLVMPattern<CatOp> {\n                   ConversionPatternRewriter &rewriter) const override {\n     Location loc = op->getLoc();\n     auto resultTy = op.getType().template cast<RankedTensorType>();\n-    unsigned elems = getElemsPerThread(resultTy);\n+    unsigned elems = getTotalElemsPerThread(resultTy);\n     Type elemTy =\n         this->getTypeConverter()->convertType(resultTy.getElementType());\n     SmallVector<Type> types(elems, elemTy);"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 83, "deletions": 30, "changes": 113, "file_content_changes": "@@ -22,32 +22,54 @@ namespace gpu {\n // so that all distributed layouts implement\n // these utilities\n \n-unsigned getElemsPerThread(Attribute layout, ArrayRef<int64_t> shape,\n-                           Type eltTy) {\n+unsigned getTotalElemsPerThread(Attribute layout, ArrayRef<int64_t> shape,\n+                                Type eltTy) {\n   if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n-    return blockedLayout.getElemsPerThread(shape, eltTy);\n+    return blockedLayout.getTotalElemsPerThread(shape, eltTy);\n   } else if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n-    return sliceLayout.getElemsPerThread(shape, eltTy);\n+    return sliceLayout.getTotalElemsPerThread(shape, eltTy);\n   } else if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n-    return mmaLayout.getElemsPerThread(shape, eltTy);\n+    return mmaLayout.getTotalElemsPerThread(shape, eltTy);\n   } else if (auto sharedLayout = layout.dyn_cast<SharedEncodingAttr>()) {\n-    return sharedLayout.getElemsPerThread(shape, eltTy);\n+    return sharedLayout.getTotalElemsPerThread(shape, eltTy);\n   } else if (auto dotLayout = layout.dyn_cast<DotOperandEncodingAttr>()) {\n-    return dotLayout.getElemsPerThread(shape, eltTy);\n+    return dotLayout.getTotalElemsPerThread(shape, eltTy);\n   } else {\n     assert(0 && \"getElemsPerThread not implemented\");\n     return 0;\n   }\n }\n \n-unsigned getElemsPerThread(Type type) {\n+SmallVector<unsigned> getElemsPerThread(Attribute layout,\n+                                        ArrayRef<int64_t> shape, Type eltTy) {\n+  if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n+    return blockedLayout.getElemsPerThread(shape, eltTy);\n+  } else if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n+    return sliceLayout.getElemsPerThread(shape, eltTy);\n+  } else if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n+    return mmaLayout.getElemsPerThread(shape, eltTy);\n+  } else {\n+    assert(0 && \"getElemsPerThread not implemented\");\n+    return SmallVector<unsigned>();\n+  }\n+}\n+\n+SmallVector<unsigned> getElemsPerThread(Type type) {\n   if (type.isIntOrIndexOrFloat() || type.isa<triton::PointerType>())\n-    return 1;\n+    return SmallVector<unsigned>(1, 1);\n   auto tensorType = type.cast<RankedTensorType>();\n   return getElemsPerThread(tensorType.getEncoding(), tensorType.getShape(),\n                            tensorType.getElementType());\n }\n \n+unsigned getTotalElemsPerThread(Type type) {\n+  if (type.isIntOrIndexOrFloat() || type.isa<triton::PointerType>())\n+    return 1;\n+  auto tensorType = type.cast<RankedTensorType>();\n+  return getTotalElemsPerThread(tensorType.getEncoding(), tensorType.getShape(),\n+                                tensorType.getElementType());\n+}\n+\n SmallVector<unsigned> getThreadsPerWarp(Attribute layout) {\n   if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n     return SmallVector<unsigned>(blockedLayout.getThreadsPerWarp().begin(),\n@@ -230,7 +252,7 @@ SmallVector<unsigned> getOrder(Attribute layout) {\n     assert(0 && \"Unimplemented usage of getOrder\");\n     return {};\n   }\n-};\n+}\n \n bool isaDistributedLayout(Attribute layout) {\n   return layout.isa<BlockedEncodingAttr>() || layout.isa<MmaEncodingAttr>() ||\n@@ -306,9 +328,9 @@ static LogicalResult parseUInt(AsmParser &parser, const NamedAttribute &attr,\n SliceEncodingAttr BlockedEncodingAttr::squeeze(int axis) {\n   return SliceEncodingAttr::get(getContext(), axis, *this);\n }\n-\n-unsigned BlockedEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n-                                                Type eltTy) const {\n+SmallVector<unsigned>\n+BlockedEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n+                                       Type eltTy) const {\n   size_t rank = shape.size();\n   auto sizePerThread = getSizePerThread();\n   auto warpsPerCTA = getWarpsPerCTA();\n@@ -320,7 +342,11 @@ unsigned BlockedEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n     unsigned t = sizePerThread[i] * threadsPerWarp[i] * warpsPerCTA[i];\n     elemsPerThread[i] = ceil<unsigned>(shape[i], t) * sizePerThread[i];\n   }\n-  return product<unsigned>(elemsPerThread);\n+  return elemsPerThread;\n+}\n+unsigned BlockedEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n+                                                     Type eltTy) const {\n+  return product<unsigned>(getElemsPerThread(shape, eltTy));\n }\n \n template <class T>\n@@ -343,19 +369,26 @@ SliceEncodingAttr::paddedShape<unsigned>(ArrayRef<unsigned> shape) const;\n template SmallVector<int64_t>\n SliceEncodingAttr::paddedShape<int64_t>(ArrayRef<int64_t> shape) const;\n \n-unsigned SliceEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n-                                              Type eltTy) const {\n+SmallVector<unsigned>\n+SliceEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n+                                     Type eltTy) const {\n   auto parent = getParent();\n-  return ::getElemsPerThread(parent, paddedShape(shape), eltTy);\n+  auto parentElemsPerThread =\n+      ::getElemsPerThread(parent, paddedShape(shape), eltTy);\n+  return parentElemsPerThread;\n+}\n+unsigned SliceEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n+                                                   Type eltTy) const {\n+  return product<unsigned>(getElemsPerThread(shape, eltTy));\n }\n \n-unsigned MmaEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n-                                            Type eltTy) const {\n+SmallVector<unsigned>\n+MmaEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape, Type eltTy) const {\n   size_t rank = shape.size();\n   assert(rank == 2 && \"Unexpected rank of mma layout\");\n   assert((isVolta() || isAmpere()) && \"Only version 1 and 2 is supported\");\n \n-  int res = 0;\n+  SmallVector<unsigned> elemsPerThread(rank);\n   if (isVolta()) {\n     auto [isARow, isBRow, isAVec4, isBVec4, id] = decodeVoltaLayoutStates();\n     static constexpr std::array<unsigned, 2> fpw{{2, 2}};\n@@ -369,21 +402,34 @@ unsigned MmaEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n     unsigned wptN = getWarpsPerCTA()[1];\n     unsigned resM = repM * std::max<int>(1, shape[0] / (spwM * wptM));\n     unsigned resN = 2 * repN * std::max<int>(1, shape[1] / (spwN * wptN));\n-    res = resM * resN;\n+    elemsPerThread[0] = resM;\n+    elemsPerThread[1] = resN;\n   } else if (isAmpere()) {\n-    unsigned elemsCol = ceil<unsigned>(shape[0], 16 * getWarpsPerCTA()[0]) * 2;\n-    unsigned elemsRow = ceil<unsigned>(shape[1], 8 * getWarpsPerCTA()[1]) * 2;\n-    res = elemsCol * elemsRow;\n+    unsigned elemsRow = ceil<unsigned>(shape[0], 16 * getWarpsPerCTA()[0]) * 2;\n+    unsigned elemsCol = ceil<unsigned>(shape[1], 8 * getWarpsPerCTA()[1]) * 2;\n+    elemsPerThread[0] = elemsRow;\n+    elemsPerThread[1] = elemsCol;\n   } else {\n     llvm_unreachable(\"Unexpected mma version\");\n   }\n \n-  return res;\n+  return elemsPerThread;\n+}\n+\n+unsigned MmaEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n+                                                 Type eltTy) const {\n+  return product<unsigned>(getElemsPerThread(shape, eltTy));\n }\n \n-unsigned SharedEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n-                                               Type eltTy) const {\n-  llvm_unreachable(\"Unexpected shared layout\");\n+SmallVector<unsigned>\n+SharedEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n+                                      Type eltTy) const {\n+  llvm_unreachable(\"getElemsPerThread is not supported for shared layout\");\n+  return SmallVector<unsigned>();\n+}\n+unsigned SharedEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n+                                                    Type eltTy) const {\n+  llvm_unreachable(\"getElemsPerThread is not supported for shared layout\");\n   return 0;\n }\n \n@@ -405,8 +451,15 @@ DotOperandEncodingAttr::getMMAv2Rep(ArrayRef<int64_t> shape,\n   }\n }\n \n-unsigned DotOperandEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n-                                                   Type eltTy) const {\n+SmallVector<unsigned>\n+DotOperandEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n+                                          Type eltTy) const {\n+  llvm_unreachable(\"getElemsPerThread is not supported for dot operand\");\n+  return SmallVector<unsigned>();\n+}\n+\n+unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n+                                                        Type eltTy) const {\n   if (auto mmaParent = getParent().dyn_cast<MmaEncodingAttr>()) {\n     int warpsPerCTAM = mmaParent.getWarpsPerCTA()[0];\n     int warpsPerCTAN = mmaParent.getWarpsPerCTA()[1];"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Utility.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -100,7 +100,7 @@ bool expensiveLoadOrStore(Operation *op, Attribute &targetEncoding) {\n       op->getParentOfType<ModuleOp>()->getAttrOfType<IntegerAttr>(\n           \"triton_gpu.num-warps\");\n   if (numWarps) {\n-    int sizePerThread = triton::gpu::getElemsPerThread(ptrType);\n+    int sizePerThread = triton::gpu::getTotalElemsPerThread(ptrType);\n     if (ptrType.getNumElements() < numWarps.getInt() * 32)\n       return false;\n   }"}]