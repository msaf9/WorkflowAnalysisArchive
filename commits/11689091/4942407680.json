[{"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "file_content_changes": "@@ -39,6 +39,10 @@ class ReduceOpHelper {\n \n   unsigned getIntraWarpSize();\n \n+  unsigned getInterWarpSizeWithUniqueData();\n+\n+  unsigned getIntraWarpSizeWithUniqueData();\n+\n   unsigned getThreadsReductionAxis();\n \n   SmallVector<unsigned> getScratchConfigBasic();"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 14, "deletions": 1, "changes": 15, "file_content_changes": "@@ -16,12 +16,25 @@ bool ReduceOpHelper::isFastReduction() {\n unsigned ReduceOpHelper::getInterWarpSize() {\n   auto srcReduceDimSize = static_cast<unsigned>(srcShape[axis]);\n   unsigned sizeIntraWarps = getIntraWarpSize();\n+  return std::min(srcReduceDimSize / sizeIntraWarps,\n+                  triton::gpu::getWarpsPerCTA(getSrcLayout())[axis]);\n+}\n+\n+unsigned ReduceOpHelper::getIntraWarpSize() {\n+  auto srcReduceDimSize = static_cast<unsigned>(srcShape[axis]);\n+  return std::min(srcReduceDimSize,\n+                  triton::gpu::getThreadsPerWarp(getSrcLayout())[axis]);\n+}\n+\n+unsigned ReduceOpHelper::getInterWarpSizeWithUniqueData() {\n+  auto srcReduceDimSize = static_cast<unsigned>(srcShape[axis]);\n+  unsigned sizeIntraWarps = getIntraWarpSizeWithUniqueData();\n   return std::min(srcReduceDimSize / sizeIntraWarps,\n                   triton::gpu::getWarpsPerCTAWithUniqueData(\n                       getSrcLayout(), getSrcShape())[axis]);\n }\n \n-unsigned ReduceOpHelper::getIntraWarpSize() {\n+unsigned ReduceOpHelper::getIntraWarpSizeWithUniqueData() {\n   auto srcReduceDimSize = static_cast<unsigned>(srcShape[axis]);\n   return std::min(srcReduceDimSize,\n                   triton::gpu::getThreadsPerWarpWithUniqueData("}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -336,8 +336,8 @@ struct ReduceOpConversion\n                   elemPtrTys[i]);\n     }\n \n-    unsigned sizeIntraWarps = helper.getIntraWarpSize();\n-    unsigned sizeInterWarps = helper.getInterWarpSize();\n+    unsigned sizeIntraWarps = helper.getIntraWarpSizeWithUniqueData();\n+    unsigned sizeInterWarps = helper.getInterWarpSizeWithUniqueData();\n \n     unsigned srcElems = getTotalElemsPerThread(srcTys[0]);\n     auto srcIndices = emitIndices(loc, rewriter, srcLayout, srcTys[0]);"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 60, "deletions": 62, "changes": 122, "file_content_changes": "@@ -1605,68 +1605,66 @@ def _welford_combine(mean_1, m2_1, weight_1, mean_2, m2_2, weight_2):\n     )\n \n \n-# layouts = [\n-#     BlockedLayout([1, 4], [1, 32], [4, 1], [1, 0]),\n-#     BlockedLayout([1, 4], [1, 32], [2, 2], [1, 0]),\n-#     BlockedLayout([1, 4], [1, 32], [1, 4], [1, 0]),\n-#     BlockedLayout([1, 4], [8, 4], [2, 2], [0, 1])\n-# ]\n-\n-\n-# @pytest.mark.parametrize(\"M, N\", [[32, 128], [128, 128], [128, 32]])\n-# @pytest.mark.parametrize(\"src_layout\", layouts)\n-# def test_reduce_2d(M, N, src_layout, device='cuda'):\n-#     ir = f\"\"\"\n-#     #src = {src_layout}\n-#     module attributes {{\"triton_gpu.num-warps\" = 4 : i32}} {{\n-#     tt.func public @sum_kernel_0d1d(%arg0: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}, %arg1: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}) {{\n-#         %cst = arith.constant dense<{M}> : tensor<{M}x1xi32, #src>\n-#         %0 = tt.make_range {{end = {M} : i32, start = 0 : i32}} : tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n-#         %1 = tt.expand_dims %0 {{axis = 1 : i32}} : (tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>) -> tensor<{M}x1xi32, #src>\n-#         %2 = arith.muli %1, %cst : tensor<{M}x1xi32, #src>\n-#         %3 = tt.make_range {{end = {N} : i32, start = 0 : i32}} : tensor<{N}xi32, #triton_gpu.slice<{{dim = 0, parent = #src}}>>\n-#         %4 = tt.expand_dims %3 {{axis = 0 : i32}} : (tensor<{N}xi32, #triton_gpu.slice<{{dim = 0, parent = #src}}>>) -> tensor<1x{N}xi32, #src>\n-#         %5 = tt.broadcast %2 : (tensor<{M}x1xi32, #src>) -> tensor<{M}x{N}xi32, #src>\n-#         %6 = tt.broadcast %4 : (tensor<1x{N}xi32, #src>) -> tensor<{M}x{N}xi32, #src>\n-#         %7 = arith.addi %5, %6 : tensor<{M}x{N}xi32, #src>\n-#         %8 = tt.splat %arg0 : (!tt.ptr<i32>) -> tensor<{M}x{N}x!tt.ptr<i32>, #src>\n-#         %9 = tt.addptr %8, %7 : tensor<{M}x{N}x!tt.ptr<i32>, #src>, tensor<{M}x{N}xi32, #src>\n-#         %10 = tt.load %9 {{cache = 1 : i32, evict = 1 : i32, isVolatile = false}} : tensor<{M}x{N}xi32, #src>\n-#         %11 = \"tt.reduce\"(%10) ({{\n-#         ^bb0(%arg2: i32, %arg3: i32):\n-#         %13 = arith.addi %arg2, %arg3 : i32\n-#         tt.reduce.return %13 : i32\n-#         }}) {{axis = 1 : i32}} : (tensor<{M}x{N}xi32, #src>) -> tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n-#         %12 = \"tt.reduce\"(%11) ({{\n-#         ^bb0(%arg2: i32, %arg3: i32):\n-#         %13 = arith.addi %arg2, %arg3 : i32\n-#         tt.reduce.return %13 : i32\n-#         }}) {{axis = 0 : i32}} : (tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>) -> i32\n-#         tt.store %arg1, %12 {{cache = 1 : i32, evict = 1 : i32}} : i32\n-#         tt.return\n-#     }}\n-#     }}\n-#     \"\"\"\n-#     import tempfile\n-#     with tempfile.NamedTemporaryFile(mode='w', suffix='.ttgir') as f:\n-#         f.write(ir)\n-#         f.flush()\n-#         kernel = triton.compile(f.name)\n-#\n-#     rs = RandomState(17)\n-#     x = rs.randint(0, 4, (M, N)).astype('int32')\n-#     x = (x.view('uint32') & np.uint32(0xffffe000)).view('int32')\n-#\n-#     z = np.zeros((1,)).astype('int32')\n-#\n-#     x_tri = torch.tensor(x, device=device)\n-#     z_tri = torch.tensor(z, device=device)\n-#\n-#     pgm = kernel[(1, 1, 1)](x_tri, z_tri)\n-#\n-#     z_ref = np.sum(x)\n-#\n-#     np.testing.assert_allclose(z_ref, z_tri.cpu().numpy(), rtol=0.01, atol=1e-3)\n+layouts = [\n+    BlockedLayout([1, 4], [1, 32], [4, 1], [1, 0]),\n+    BlockedLayout([1, 4], [1, 32], [2, 2], [1, 0]),\n+    BlockedLayout([1, 4], [1, 32], [1, 4], [1, 0]),\n+    BlockedLayout([1, 4], [8, 4], [2, 2], [0, 1])\n+]\n+\n+\n+@pytest.mark.parametrize(\"M, N\", [[128, 128], [256, 128], [256, 256], [128, 256]])\n+@pytest.mark.parametrize(\"src_layout\", layouts)\n+def test_chain_reduce(M, N, src_layout, device='cuda'):\n+    ir = f\"\"\"\n+    #src = {src_layout}\n+    module attributes {{\"triton_gpu.num-warps\" = 4 : i32}} {{\n+    tt.func public @sum_kernel_0d1d(%arg0: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}, %arg1: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}) {{\n+        %cst = arith.constant dense<{N}> : tensor<{M}x1xi32, #src>\n+        %0 = tt.make_range {{end = {M} : i32, start = 0 : i32}} : tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n+        %1 = tt.expand_dims %0 {{axis = 1 : i32}} : (tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>) -> tensor<{M}x1xi32, #src>\n+        %2 = arith.muli %1, %cst : tensor<{M}x1xi32, #src>\n+        %3 = tt.make_range {{end = {N} : i32, start = 0 : i32}} : tensor<{N}xi32, #triton_gpu.slice<{{dim = 0, parent = #src}}>>\n+        %4 = tt.expand_dims %3 {{axis = 0 : i32}} : (tensor<{N}xi32, #triton_gpu.slice<{{dim = 0, parent = #src}}>>) -> tensor<1x{N}xi32, #src>\n+        %5 = tt.broadcast %2 : (tensor<{M}x1xi32, #src>) -> tensor<{M}x{N}xi32, #src>\n+        %6 = tt.broadcast %4 : (tensor<1x{N}xi32, #src>) -> tensor<{M}x{N}xi32, #src>\n+        %7 = arith.addi %5, %6 : tensor<{M}x{N}xi32, #src>\n+        %8 = tt.splat %arg0 : (!tt.ptr<i32>) -> tensor<{M}x{N}x!tt.ptr<i32>, #src>\n+        %9 = tt.addptr %8, %7 : tensor<{M}x{N}x!tt.ptr<i32>, #src>, tensor<{M}x{N}xi32, #src>\n+        %10 = tt.load %9 {{cache = 1 : i32, evict = 1 : i32, isVolatile = false}} : tensor<{M}x{N}xi32, #src>\n+        %11 = \"tt.reduce\"(%10) ({{\n+        ^bb0(%arg2: i32, %arg3: i32):\n+        %13 = arith.addi %arg2, %arg3 : i32\n+        tt.reduce.return %13 : i32\n+        }}) {{axis = 1 : i32}} : (tensor<{M}x{N}xi32, #src>) -> tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n+        %12 = \"tt.reduce\"(%11) ({{\n+        ^bb0(%arg2: i32, %arg3: i32):\n+        %13 = arith.addi %arg2, %arg3 : i32\n+        tt.reduce.return %13 : i32\n+        }}) {{axis = 0 : i32}} : (tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>) -> i32\n+        tt.store %arg1, %12 {{cache = 1 : i32, evict = 1 : i32}} : i32\n+        tt.return\n+    }}\n+    }}\n+    \"\"\"\n+    import tempfile\n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.ttgir') as f:\n+        f.write(ir)\n+        f.flush()\n+        kernel = triton.compile(f.name)\n+\n+    rs = RandomState(17)\n+    x = rs.randint(0, 4, (M, N)).astype('int32')\n+\n+    z = np.zeros((1,)).astype('int32')\n+\n+    x_tri = torch.tensor(x, device=device)\n+    z_tri = torch.tensor(z, device=device)\n+\n+    pgm = kernel[(1, 1, 1)](x_tri, z_tri)\n+    z_ref = np.sum(x)\n+\n+    np.testing.assert_allclose(z_ref, z_tri.cpu().numpy(), rtol=0.01, atol=1e-3)\n \n \n def test_generic_reduction(device='cuda'):"}]