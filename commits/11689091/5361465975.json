[{"filename": "include/triton/Dialect/Triton/IR/TritonAttrDefs.td", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -3,13 +3,15 @@\n \n include \"mlir/IR/EnumAttr.td\"\n \n-// Attributes for LoadOp\n+// Attributes for LoadOp and StoreOp\n def TT_CacheModifierAttr : I32EnumAttr<\n     \"CacheModifier\", \"\",\n     [\n         I32EnumAttrCase<\"NONE\", 1, \"none\">,\n         I32EnumAttrCase<\"CA\", 2, \"ca\">,\n         I32EnumAttrCase<\"CG\", 3, \"cg\">,\n+        I32EnumAttrCase<\"WB\", 4, \"wb\">,\n+        I32EnumAttrCase<\"CS\", 5, \"cs\">,\n     ]> {\n     let cppNamespace = \"::mlir::triton\";\n }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -354,6 +354,9 @@ struct StoreOpConversion\n       auto &ptxStoreInstr =\n           ptxBuilder.create<>(\"st\")\n               ->global()\n+              .o(\"wb\", op.getCache() == triton::CacheModifier::WB)\n+              .o(\"cg\", op.getCache() == triton::CacheModifier::CG)\n+              .o(\"cs\", op.getCache() == triton::CacheModifier::CS)\n               .o(\"L1::evict_first\",\n                  op.getEvict() == triton::EvictionPolicy::EVICT_FIRST)\n               .o(\"L1::evict_last\","}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -89,6 +89,8 @@ void init_triton_ir(py::module &&m) {\n       .value(\"NONE\", mlir::triton::CacheModifier::NONE)\n       .value(\"CA\", mlir::triton::CacheModifier::CA)\n       .value(\"CG\", mlir::triton::CacheModifier::CG)\n+      .value(\"WB\", mlir::triton::CacheModifier::WB)\n+      .value(\"CS\", mlir::triton::CacheModifier::CS)\n       .export_values();\n \n   py::enum_<mlir::triton::MemSemantic>(m, \"MEM_SEMANTIC\")"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 31, "deletions": 0, "changes": 31, "file_content_changes": "@@ -2266,6 +2266,37 @@ def _kernel(dst, src, off, N, BLOCK_SIZE: tl.constexpr, HINT: tl.constexpr):\n # test store\n # ---------------\n \n+\n+@pytest.mark.parametrize(\"cache\", [\"\", \".wb\", \".cg\", \".cs\"])\n+def test_store_cache_modifier(cache):\n+    src = torch.empty(128, device='cuda')\n+    dst = torch.empty(128, device='cuda')\n+\n+    @triton.jit\n+    def _kernel(dst, src, CACHE: tl.constexpr):\n+        offsets = tl.arange(0, 128)\n+        x = tl.load(src + offsets)\n+        tl.store(dst + offsets, x, cache_modifier=CACHE)\n+\n+    pgm = _kernel[(1,)](dst, src, CACHE=cache)\n+    ptx = pgm.asm['ptx']\n+    if cache == '':\n+        assert 'st.global.wb' not in ptx\n+        assert 'st.global.cg' not in ptx\n+        assert 'st.global.cs' not in ptx\n+    if cache == '.wb':\n+        assert 'st.global.wb' in ptx\n+        assert 'st.global.cg' not in ptx\n+        assert 'st.global.cs' not in ptx\n+    if cache == '.cg':\n+        assert 'st.global.wb' not in ptx\n+        assert 'st.global.cg' in ptx\n+        assert 'st.global.cs' not in ptx\n+    if cache == '.cs':\n+        assert 'st.global.wb' not in ptx\n+        assert 'st.global.cg' not in ptx\n+        assert 'st.global.cs' in ptx\n+\n # ---------------\n # test if\n # ---------------"}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 17, "deletions": 3, "changes": 20, "file_content_changes": "@@ -775,7 +775,7 @@ def cast(input: tl.tensor,\n # ===----------------------------------------------------------------------===//\n \n \n-def _str_to_cache_modifier(cache_modifier):\n+def _str_to_load_cache_modifier(cache_modifier):\n     cache = ir.CACHE_MODIFIER.NONE  # default\n     if cache_modifier:\n         if cache_modifier == \".ca\":\n@@ -787,6 +787,20 @@ def _str_to_cache_modifier(cache_modifier):\n     return cache\n \n \n+def _str_to_store_cache_modifier(cache_modifier):\n+    cache = ir.CACHE_MODIFIER.NONE  # default\n+    if cache_modifier:\n+        if cache_modifier == \".wb\":\n+            cache = ir.CACHE_MODIFIER.WB\n+        elif cache_modifier == \".cg\":\n+            cache = ir.CACHE_MODIFIER.CG\n+        elif cache_modifier == \".cs\":\n+            cache = ir.CACHE_MODIFIER.CS\n+        else:\n+            raise ValueError(f\"Cache modifier {cache_modifier} not supported\")\n+    return cache\n+\n+\n def _str_to_eviction_policy(eviction_policy):\n     eviction = ir.EVICTION_POLICY.NORMAL  # default\n     if eviction_policy:\n@@ -929,7 +943,7 @@ def load(ptr: tl.tensor,\n          is_volatile: bool,\n          builder: ir.builder) -> tl.tensor:\n     # Cache, eviction and padding options\n-    cache = _str_to_cache_modifier(cache_modifier)\n+    cache = _str_to_load_cache_modifier(cache_modifier)\n     eviction = _str_to_eviction_policy(eviction_policy)\n     padding = _str_to_padding_option(padding_option)\n \n@@ -1018,7 +1032,7 @@ def store(ptr: tl.tensor,\n           eviction_policy: str,\n           builder: ir.builder) -> tl.tensor:\n     # Cache and eviction options\n-    cache = _str_to_cache_modifier(cache_modifier)\n+    cache = _str_to_store_cache_modifier(cache_modifier)\n     eviction = _str_to_eviction_policy(eviction_policy)\n \n     if ptr.type.is_ptr() and ptr.type.element_ty.is_block():"}]