[{"filename": "include/triton/Conversion/TritonToTritonGPU/Passes.td", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -20,7 +20,11 @@ def ConvertTritonToTritonGPU: Pass<\"convert-triton-to-tritongpu\", \"mlir::ModuleO\n    let options = [\n        Option<\"numWarps\", \"num-warps\",\n               \"int32_t\", /*default*/\"4\",\n-              \"number of warps\">\n+              \"number of warps\">,\n+\n+       Option<\"threadsPerWarp\", \"threads-per-warp\",\n+              \"int32_t\", /*default*/\"32\",\n+              \"number of threads per warp\">,\n    ];\n }\n "}, {"filename": "include/triton/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -12,12 +12,14 @@ namespace triton {\n \n constexpr static char AttrNumWarpsName[] = \"triton_gpu.num-warps\";\n \n+constexpr static char AttrNumThreadsPerWarp[] = \"triton_gpu.threads-per-warp\";\n+\n // Create the pass with numWarps passed from cl::opt.\n std::unique_ptr<OperationPass<ModuleOp>> createConvertTritonToTritonGPUPass();\n \n // Create the pass with numWarps set explicitly.\n std::unique_ptr<OperationPass<ModuleOp>>\n-createConvertTritonToTritonGPUPass(int numWarps);\n+createConvertTritonToTritonGPUPass(int numWarps, int threadsPerWarp = 32);\n \n } // namespace triton\n } // namespace mlir"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 11, "deletions": 10, "changes": 21, "file_content_changes": "@@ -229,31 +229,32 @@ for\n     AttrBuilder<(ins \"ArrayRef<int64_t>\":$shape,\n                      \"ArrayRef<unsigned>\":$sizePerThread,\n                      \"ArrayRef<unsigned>\":$order,\n-                     \"unsigned\":$numWarps), [{\n+                     \"unsigned\":$numWarps,\n+                     \"unsigned\":$threadsPerWarp), [{\n       int rank = sizePerThread.size();\n-      unsigned remainingLanes = 32;\n-      unsigned remainingThreads = numWarps*32;\n+      unsigned remainingLanes = threadsPerWarp;\n+      unsigned remainingThreads = numWarps*threadsPerWarp;\n       unsigned remainingWarps = numWarps;\n       unsigned prevLanes = 1;\n       unsigned prevWarps = 1;\n-      SmallVector<unsigned, 4> threadsPerWarp(rank);\n+      SmallVector<unsigned, 4> rankedThreadsPerWarp(rank);\n       SmallVector<unsigned, 4> warpsPerCTA(rank);\n       for (int _dim = 0; _dim < rank - 1; ++_dim) {\n         int i = order[_dim];\n         unsigned threadsPerCTA = std::clamp<unsigned>(remainingThreads, 1, shape[i] / sizePerThread[i]);\n-        threadsPerWarp[i] = std::clamp<unsigned>(threadsPerCTA, 1, remainingLanes);\n-        warpsPerCTA[i] = std::clamp<unsigned>(threadsPerCTA / threadsPerWarp[i], 1, remainingWarps);\n+        rankedThreadsPerWarp[i] = std::clamp<unsigned>(threadsPerCTA, 1, remainingLanes);\n+        warpsPerCTA[i] = std::clamp<unsigned>(threadsPerCTA / rankedThreadsPerWarp[i], 1, remainingWarps);\n         remainingWarps /= warpsPerCTA[i];\n-        remainingLanes /= threadsPerWarp[i];\n+        remainingLanes /= rankedThreadsPerWarp[i];\n         remainingThreads /= threadsPerCTA;\n-        prevLanes *= threadsPerWarp[i];\n+        prevLanes *= rankedThreadsPerWarp[i];\n         prevWarps *= warpsPerCTA[i];\n       }\n       // Expand the last dimension to fill the remaining lanes and warps\n-      threadsPerWarp[order[rank-1]] = 32 / prevLanes;\n+      rankedThreadsPerWarp[order[rank-1]] = threadsPerWarp / prevLanes;\n       warpsPerCTA[order[rank-1]] = numWarps / prevWarps;\n \n-      return $_get(context, sizePerThread, threadsPerWarp, warpsPerCTA, order);\n+      return $_get(context, sizePerThread, rankedThreadsPerWarp, warpsPerCTA, order);\n \n     }]>\n   ];"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUDialect.td", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "file_content_changes": "@@ -29,6 +29,16 @@ def TritonGPU_Dialect : Dialect {\n             \"TritonGPU module should contain a triton_gpu.num-warps attribute\");\n       return numWarps.cast<IntegerAttr>().getInt();\n     }\n+\n+    static std::string getThreadsPerWarpAttrName() { return \"triton_gpu.threads-per-warp\"; }\n+    static int getThreadsPerWarp(ModuleOp mod) {\n+      Attribute threadsPerWarp = mod->getDiscardableAttr(\"triton_gpu.threads-per-warp\");\n+      if(!threadsPerWarp) {\n+        return 32;\n+      }\n+      return threadsPerWarp.cast<IntegerAttr>().getInt();\n+    }\n+\n   }];\n \n   let useDefaultAttributePrinterParser = 1;"}, {"filename": "include/triton/Dialect/TritonGPU/Transforms/TritonGPUConversion.h", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "file_content_changes": "@@ -13,12 +13,15 @@ namespace mlir {\n \n class TritonGPUTypeConverter : public TypeConverter {\n public:\n-  TritonGPUTypeConverter(MLIRContext *context, int numWarps);\n+  TritonGPUTypeConverter(MLIRContext *context, int numWarps,\n+                         int threadsPerWarp);\n   int getNumWarps() const { return numWarps; }\n+  int getThreadsPerWarp() const { return threadsPerWarp; }\n \n private:\n   MLIRContext *context;\n   int numWarps;\n+  int threadsPerWarp;\n };\n \n class TritonGPUConversionTarget : public ConversionTarget {"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -72,7 +72,9 @@ SmallVector<SmallVector<unsigned>> ReduceOpHelper::getScratchConfigsFast() {\n   /// shared memory block1:\n   auto mod = op->getParentOfType<ModuleOp>();\n   unsigned numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n-  smemShapes[1].push_back(numWarps * 32);\n+  unsigned threadsPerWarp =\n+      triton::gpu::TritonGPUDialect::getThreadsPerWarp(mod);\n+  smemShapes[1].push_back(numWarps * threadsPerWarp);\n \n   return smemShapes;\n }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "file_content_changes": "@@ -303,9 +303,10 @@ class ConvertTritonGPUToLLVM\n     TritonGPUToLLVMTypeConverter typeConverter(context, option);\n     TritonLLVMConversionTarget target(*context, isROCM);\n     int numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n+    int threadsPerWarp = triton::gpu::TritonGPUDialect::getThreadsPerWarp(mod);\n \n     // Preprocess\n-    decomposeMmaToDotOperand(mod, numWarps);\n+    decomposeMmaToDotOperand(mod, numWarps, threadsPerWarp);\n     decomposeBlockedToDotOperand(mod);\n     decomposeInsertSliceAsyncOp(mod);\n \n@@ -432,7 +433,8 @@ class ConvertTritonGPUToLLVM\n                                         allocation.getSharedMemorySize()));\n   }\n \n-  void decomposeMmaToDotOperand(ModuleOp mod, int numWarps) const {\n+  void decomposeMmaToDotOperand(ModuleOp mod, int numWarps,\n+                                int threadsPerWarp) const {\n     // Replace `mma -> dot_op` with `mma -> blocked -> dot_op`\n     // unless certain conditions are met\n     mod.walk([&](triton::gpu::ConvertLayoutOp cvtOp) -> void {\n@@ -448,7 +450,7 @@ class ConvertTritonGPUToLLVM\n             dstType.getShape(), dstType.getElementType(),\n             triton::gpu::BlockedEncodingAttr::get(\n                 mod.getContext(), srcType.getShape(), getSizePerThread(srcMma),\n-                getOrder(srcMma), numWarps));\n+                getOrder(srcMma), numWarps, threadsPerWarp));\n         auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), tmpType, cvtOp.getOperand());\n         auto newConvert = builder.create<triton::gpu::ConvertLayoutOp>("}, {"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 16, "deletions": 7, "changes": 23, "file_content_changes": "@@ -254,15 +254,17 @@ struct TritonDotPattern : public OpConversionPattern<triton::DotOp> {\n     auto origShape = origType.getShape();\n     auto typeConverter = getTypeConverter<TritonGPUTypeConverter>();\n     int numWarps = typeConverter->getNumWarps();\n+    int threadsPerWarp = typeConverter->getThreadsPerWarp();\n \n     SmallVector<unsigned> retSizePerThread = {1, 1};\n-    if (origShape[0] * origShape[1] / (numWarps * 32) >= 4)\n+    if (origShape[0] * origShape[1] / (numWarps * threadsPerWarp) >= 4)\n       retSizePerThread = {2, 2};\n-    if (origShape[0] * origShape[1] / (numWarps * 32) >= 16)\n+    if (origShape[0] * origShape[1] / (numWarps * threadsPerWarp) >= 16)\n       retSizePerThread = {4, 4};\n     SmallVector<unsigned> retOrder = {1, 0};\n     Attribute dEncoding = triton::gpu::BlockedEncodingAttr::get(\n-        getContext(), origShape, retSizePerThread, retOrder, numWarps);\n+        getContext(), origShape, retSizePerThread, retOrder, numWarps,\n+        threadsPerWarp);\n     RankedTensorType retType =\n         RankedTensorType::get(origShape, origType.getElementType(), dEncoding);\n     // a & b must be of smem layout\n@@ -806,13 +808,16 @@ class ConvertTritonToTritonGPU\n public:\n   ConvertTritonToTritonGPU() = default;\n   // constructor with some parameters set explicitly.\n-  ConvertTritonToTritonGPU(int numWarps) { this->numWarps = numWarps; }\n+  ConvertTritonToTritonGPU(int numWarps, int threadsPerWarp) {\n+    this->numWarps = numWarps;\n+    this->threadsPerWarp = threadsPerWarp;\n+  }\n \n   void runOnOperation() override {\n     MLIRContext *context = &getContext();\n     ModuleOp mod = getOperation();\n     // type converter\n-    TritonGPUTypeConverter typeConverter(context, numWarps);\n+    TritonGPUTypeConverter typeConverter(context, numWarps, threadsPerWarp);\n     TritonGPUConversionTarget target(*context, typeConverter);\n     // rewrite patterns\n     RewritePatternSet patterns(context);\n@@ -835,6 +840,9 @@ class ConvertTritonToTritonGPU\n     mod->setAttr(\n         AttrNumWarpsName,\n         IntegerAttr::get(i32_ty, llvm::APInt(32, numWarps.getValue())));\n+    mod->setAttr(\n+        AttrNumThreadsPerWarp,\n+        IntegerAttr::get(i32_ty, llvm::APInt(32, threadsPerWarp.getValue())));\n \n     // update layouts\n     //  broadcast src => multicast, dst => broadcasted\n@@ -846,8 +854,9 @@ class ConvertTritonToTritonGPU\n } // namespace\n \n std::unique_ptr<OperationPass<ModuleOp>>\n-mlir::triton::createConvertTritonToTritonGPUPass(int numWarps) {\n-  return std::make_unique<::ConvertTritonToTritonGPU>(numWarps);\n+mlir::triton::createConvertTritonToTritonGPUPass(int numWarps,\n+                                                 int threadsPerWarp) {\n+  return std::make_unique<::ConvertTritonToTritonGPU>(numWarps, threadsPerWarp);\n }\n \n std::unique_ptr<OperationPass<ModuleOp>>"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Coalesce.cpp", "status": "modified", "additions": 11, "deletions": 6, "changes": 17, "file_content_changes": "@@ -23,7 +23,7 @@ typedef DenseMap<Value, std::function<Type(Type)>> LayoutMap;\n \n struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n   Attribute getCoalescedEncoding(ModuleAxisInfoAnalysis &axisInfoAnalysis,\n-                                 Value ptr, int numWarps) {\n+                                 Value ptr, int numWarps, int threadsPerWarp) {\n     auto origType = ptr.getType().cast<RankedTensorType>();\n     // Get the shape of the tensor.\n     size_t rank = origType.getRank();\n@@ -46,7 +46,7 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n         }\n       }\n     int numElems = product(origType.getShape());\n-    int numThreads = numWarps * 32;\n+    int numThreads = numWarps * threadsPerWarp;\n     int numElemsPerThread = std::max(numElems / numThreads, 1);\n     // Thread tile size depends on memory alignment\n     SmallVector<unsigned, 4> sizePerThread(rank, 1);\n@@ -68,14 +68,16 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     std::iota(dims.begin(), dims.end(), 0);\n     // create encoding\n     Attribute encoding = triton::gpu::BlockedEncodingAttr::get(\n-        &getContext(), origType.getShape(), sizePerThread, order, numWarps);\n+        &getContext(), origType.getShape(), sizePerThread, order, numWarps,\n+        threadsPerWarp);\n     return encoding;\n   }\n \n   std::function<Type(Type)>\n   getTypeConverter(ModuleAxisInfoAnalysis &axisInfoAnalysis, Value ptr,\n-                   int numWarps) {\n-    Attribute encoding = getCoalescedEncoding(axisInfoAnalysis, ptr, numWarps);\n+                   int numWarps, int threadsPerWarp) {\n+    Attribute encoding =\n+        getCoalescedEncoding(axisInfoAnalysis, ptr, numWarps, threadsPerWarp);\n     return [encoding](Type _type) {\n       RankedTensorType type = _type.cast<RankedTensorType>();\n       return RankedTensorType::get(type.getShape(), type.getElementType(),\n@@ -148,7 +150,10 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n         return;\n       auto mod = curr->getParentOfType<ModuleOp>();\n       int numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n-      auto convertType = getTypeConverter(axisInfoAnalysis, ptr, numWarps);\n+      int threadsPerWarp =\n+          triton::gpu::TritonGPUDialect::getThreadsPerWarp(mod);\n+      auto convertType =\n+          getTypeConverter(axisInfoAnalysis, ptr, numWarps, threadsPerWarp);\n       layoutMap[ptr] = convertType;\n     });\n "}, {"filename": "lib/Dialect/TritonGPU/Transforms/TritonGPUConversion.cpp", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "file_content_changes": "@@ -12,8 +12,8 @@ using namespace mlir::triton::gpu;\n // TypeConverter\n //\n TritonGPUTypeConverter::TritonGPUTypeConverter(MLIRContext *context,\n-                                               int numWarps)\n-    : context(context), numWarps(numWarps) {\n+                                               int numWarps, int threadsPerWarp)\n+    : context(context), numWarps(numWarps), threadsPerWarp(threadsPerWarp) {\n   addConversion([](Type type) { return type; });\n   addConversion([this](RankedTensorType tensorType) -> RankedTensorType {\n     // types with encoding are already in the right format\n@@ -29,7 +29,8 @@ TritonGPUTypeConverter::TritonGPUTypeConverter(MLIRContext *context,\n     std::iota(order.begin(), order.end(), 0);\n     llvm::SmallVector<unsigned> sizePerThread(rank, 1);\n     Attribute encoding = triton::gpu::BlockedEncodingAttr::get(\n-        this->context, shape, sizePerThread, order, this->numWarps);\n+        this->context, shape, sizePerThread, order, this->numWarps,\n+        this->threadsPerWarp);\n     return RankedTensorType::get(shape, tensorType.getElementType(), encoding);\n   });\n "}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "file_content_changes": "@@ -1532,11 +1532,13 @@ void init_triton_ir(py::module &&m) {\n              self.addPass(mlir::triton::createRewriteTensorPointerPass(\n                  computeCapability));\n            })\n-      .def(\"add_convert_triton_to_tritongpu_pass\",\n-           [](mlir::PassManager &self, int numWarps) {\n-             self.addPass(\n-                 mlir::triton::createConvertTritonToTritonGPUPass(numWarps));\n-           })\n+      .def(\n+          \"add_convert_triton_to_tritongpu_pass\",\n+          [](mlir::PassManager &self, int numWarps, int threadsPerWarp) {\n+            self.addPass(mlir::triton::createConvertTritonToTritonGPUPass(\n+                numWarps, threadsPerWarp));\n+          },\n+          py::arg(\"numWarps\") = 4, py::arg(\"threadsPerWarp\") = 32)\n       .def(\"add_tritongpu_pipeline_pass\",\n            [](mlir::PassManager &self, int numStages) {\n              self.addPass(mlir::createTritonGPUPipelinePass(numStages));"}, {"filename": "test/Conversion/triton_to_tritongpu.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1,7 +1,7 @@\n // RUN: triton-opt %s -split-input-file -convert-triton-to-tritongpu=num-warps=2 | FileCheck %s\n \n tt.func @ops() {\n-  // CHECK: module attributes {\"triton_gpu.num-warps\" = 2 : i32} {{.*}}\n+  // CHECK: module attributes {\"triton_gpu.num-warps\" = 2 : i32, \"triton_gpu.threads-per-warp\" = 32 : i32} {{.*}}\n   %a = arith.constant dense<1.00e+00> : tensor<128x32xf16>\n   %b = arith.constant dense<2.00e+00> : tensor<32x128xf16>\n   %c = arith.constant dense<3.00e+00> : tensor<128x128xf32>\n@@ -36,7 +36,7 @@ tt.func @reduce_ops(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n   // CHECK: #[[blocked0:.*]] = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [4, 8], warpsPerCTA = [1, 2], order = [0, 1]}>\n   // CHECK: #[[blocked1:.*]] = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [8, 4], warpsPerCTA = [1, 2], order = [0, 1]}>\n   // CHECK: #[[blocked2:.*]] = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [16, 2], warpsPerCTA = [1, 2], order = [0, 1]}>\n-  // CHECK: module attributes {\"triton_gpu.num-warps\" = 2 : i32} {{.*}}\n+  // CHECK: module attributes {\"triton_gpu.num-warps\" = 2 : i32, \"triton_gpu.threads-per-warp\" = 32 : i32} {{.*}}\n   %c0 = arith.constant dense<1.00e+00> : tensor<4x4xf32>\n   %c1 = arith.constant dense<2.00e+00> : tensor<8x2xf32>\n   %c2 = arith.constant dense<3.00e+00> : tensor<16x16xf32>"}]