[{"filename": "include/triton/Dialect/Triton/IR/TritonTypes.td", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -14,7 +14,7 @@ class TritonTypeDef<string name, string _mnemonic>\n }\n \n // Floating-point Type\n-def TT_Float : AnyTypeOf<[F8E4M3FN, F8E5M2, F16, BF16, F32, F64], \"floating-point\">;\n+def TT_Float : AnyTypeOf<[F8E4M3FNUZ, F8E4M3B11FNUZ, F8E5M2, F16, BF16, F32, F64], \"floating-point\">;\n def TT_FloatTensor : TensorOf<[TT_Float]>;\n def TT_FloatLike : AnyTypeOf<[TT_Float, TT_FloatTensor]>;\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 301, "deletions": 451, "changes": 752, "file_content_changes": "@@ -4,6 +4,227 @@ using namespace mlir;\n using namespace mlir::triton;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n \n+/* ----- FP8E5M2 ------ */\n+// This data-type is the standard FP8E5M2 format\n+\n+const std::string Fp16_to_Fp8E5M2 =\n+    \"{                            \\n\"\n+    \".reg .b32 a<2>;              \\n\"\n+    \"and.b32 a0, $1, 0x7fff7fff;  \\n\"           // a0 &= 0x7fff7fff\n+    \"and.b32 a1, $2, 0x7fff7fff;  \\n\"           // (strip sign)\n+    \"add.u32 a0, a0, 0x00800080;  \\n\"           // a0 += 0x00800080\n+    \"add.u32 a1, a1, 0x00800080;  \\n\"           // (round to nearest)\n+    \"lop3.b32 a0, $1, 0x80008000, a0, 0xea; \\n\" // a0 = a0|(0x80008000&in0)\n+    \"lop3.b32 a1, $2, 0x80008000, a1, 0xea; \\n\" // (restore sign)\n+    \"prmt.b32 $0, a0, a1, 0x7531; \\n\\t\"         // output = a1a0\n+    \"}\";\n+\n+const std::string Fp8E5M2_to_Fp16 = \"{                           \\n\"\n+                                    \"prmt.b32 $0, 0, $2, 0x5140; \\n\\t\"\n+                                    \"prmt.b32 $1, 0, $2, 0x7362; \\n\\t\"\n+                                    \"}\";\n+\n+const std::string Fp8E5M2_to_Bf16 =\n+    \"{                                      \\n\"\n+    \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n+    \"prmt.b32 a0, 0, $2, 0x5140;            \\n\" // a0 = 0xf300f400\n+    \"prmt.b32 a1, 0, $2, 0x7362;            \\n\" // a1 = 0xf100f200\n+    \"lop3.b32 b0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // b0 = a0 & 0x7fff7fff\n+    \"lop3.b32 b1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n+    \"shr.b32  b0, b0, 3;                    \\n\" // b0 >>= 3\n+    \"shr.b32  b1, b1, 3;                    \\n\" // shift into bf16 position\n+    \"add.u32  b0, b0, 0x38003800;           \\n\" // b0.exp += 2**7-2**4\n+                                                // exponent compensate = 112\n+    \"add.u32  b1, b1, 0x38003800;           \\n\" // b1 += 112<<7 | 112<<7<<16\n+    \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n+    \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n+    \"}\";\n+\n+const std::string Bf16_to_Fp8E5M2 =\n+    \"{                                           \\n\" // bf16=fp8>>3 + 112<<7\n+    \".reg .u32 sign, sign<2>, nosign, nosign<2>; \\n\" // fp8_min = 0b00000000\n+    \".reg .u32 fp8_min, fp8_max, rn_;            \\n\" // fp8_max = 0b11111111\n+    \"mov.u32 fp8_min, 0x38003800;                \\n\" // so bf16_min = 0x3800\n+    \"mov.u32 fp8_max, 0x57e057e0;                \\n\" // so bf16_max = 0x57e0\n+    \"mov.u32 rn_, 0x00100010;                    \\n\" // round to nearest\n+    \"and.b32 sign0, $1, 0x80008000;              \\n\" // sign0=in0&0x80008000\n+    \"and.b32 sign1, $2, 0x80008000;              \\n\" // (store sign)\n+    \"prmt.b32 sign, sign0, sign1, 0x7531;        \\n\"\n+    \"and.b32 nosign0, $1, 0x7fff7fff;            \\n\" // nosign0=in0&0x7fff7fff\n+    \"and.b32 nosign1, $2, 0x7fff7fff;            \\n\" // (strip sign)\n+\n+    // nosign = clamp(nosign, min, max)\n+    \".reg .u32 nosign_0_<2>, nosign_1_<2>;       \\n\"\n+    \"and.b32 nosign_0_0, nosign0, 0xffff0000;    \\n\"\n+    \"max.u32 nosign_0_0, nosign_0_0, 0x38000000; \\n\"\n+    \"min.u32 nosign_0_0, nosign_0_0, 0x57e00000; \\n\"\n+    \"and.b32 nosign_0_1, nosign0, 0x0000ffff;    \\n\"\n+    \"max.u32 nosign_0_1, nosign_0_1, 0x3800;     \\n\"\n+    \"min.u32 nosign_0_1, nosign_0_1, 0x57e0;     \\n\"\n+    \"or.b32 nosign0, nosign_0_0, nosign_0_1;     \\n\"\n+    \"and.b32 nosign_1_0, nosign1, 0xffff0000;    \\n\"\n+    \"max.u32 nosign_1_0, nosign_1_0, 0x38000000; \\n\"\n+    \"min.u32 nosign_1_0, nosign_1_0, 0x57e00000; \\n\"\n+    \"and.b32 nosign_1_1, nosign1, 0x0000ffff;    \\n\"\n+    \"max.u32 nosign_1_1, nosign_1_1, 0x3800;     \\n\"\n+    \"min.u32 nosign_1_1, nosign_1_1, 0x57e0;     \\n\"\n+    \"or.b32 nosign1, nosign_1_0, nosign_1_1;     \\n\"\n+\n+    \"add.u32 nosign0, nosign0, rn_;              \\n\" // nosign0 += rn_\n+    \"add.u32 nosign1, nosign1, rn_;              \\n\" // (round to nearest)\n+    \"sub.u32 nosign0, nosign0, 0x38003800;       \\n\" // nosign0-=0x38003800\n+    \"sub.u32 nosign1, nosign1, 0x38003800;       \\n\" // (compensate offset)\n+    \"shl.b32 nosign0, nosign0, 3;                \\n\" // nosign0 <<= 3\n+    \"shl.b32 nosign1, nosign1, 3;                \\n\" // shift into to fp8e4\n+    \"prmt.b32 nosign, nosign0, nosign1, 0x7531;  \\n\" // nosign0 = 0xf100f200\n+                                                     // nosign1 = 0xf300f400\n+                                                     // nosign = 0xf3f4f1f2\n+    \"or.b32 $0, nosign, sign;                    \\n\" // restore sign\n+    \"}\";\n+\n+/* ----- FP8E4M3B15 ------ */\n+// This data-type is a variant of the standard FP8E4M3 format.\n+// It was designed for fast software conversion to FP16 on\n+// nvidia GPUs that do not support it natively.\n+// Specifically, this data-type:\n+//    - has infinities\n+//    - has multiple nans (when all exponent bits are 1)\n+//    - has an exponent bias of 15 (vs. 7 for fp8e4m3)\n+\n+// Fp8E4M3B15 -> Fp16 (packed)\n+// fast conversion code provided by Scott Gray @ OpenAI\n+// $0 = (($2 << 1) & 0x80008000u) | (($2 << 7) & 0x3f803f80u);\n+// $1 = (($2 << 0) & 0x80008000u) | (($2 << 0) & 0x3f803f80u);\n+// WARN: subnormal (0bs0000xxx) are not handled\n+const std::string Fp8E4M3B15_to_Fp16 =\n+    \"{                                      \\n\"\n+    \".reg .b32 a<2>;                        \\n\"\n+    \"shl.b32 a0, $2, 1;                     \\n\"\n+    \"shl.b32 a1, $2, 7;                     \\n\"\n+    \"and.b32  $0, a0, 0x80008000;           \\n\"\n+    \"lop3.b32 $0, $0, a1, 0x3f803f80, 0xf8; \\n\"\n+    \"and.b32  $1, $2, 0x80008000;           \\n\"\n+    \"lop3.b32 $1, $1, $2, 0x3f803f80, 0xf8; \\n\"\n+    \"}\";\n+\n+// Fp16 -> Fp8E4M3B15 (packed)\n+// fast conversion code provided by Scott Gray @ OpenAI\n+// ret = ((e4.x >> 1) & (0x80008000u >> 1)) |\n+//       ((e4.x >> 7) & (0x3f803f80u >> 7)) |\n+//       ((e4.y >> 0) & (0x80008000u >> 0)) |\n+//       ((e4.y >> 0) & (0x3f803f80u >> 0)) ;\n+// WARN: subnormal (0bs0000xxx) are not handled\n+const std::string Fp16_to_Fp8E4M3B15 =\n+    \"{                                       \\n\"\n+    \".reg .b32 a<2>;                         \\n\"\n+    \"shr.b32  a0, $1, 1;                     \\n\"\n+    \"shr.b32  a1, $1, 7;                     \\n\"\n+    \"and.b32  $0,     a0, 0x40004000;        \\n\"\n+    \"lop3.b32 $0, $0, a1, 0x007f007f, 0xf8;  \\n\"\n+    \"lop3.b32 $0, $0, $2, 0x80008000, 0xf8;  \\n\"\n+    \"lop3.b32 $0, $0, $2, 0x3f803f80, 0xf8;  \\n\"\n+    \"}\";\n+\n+/* ----- FP8E4M3 ------ */\n+// Note: when handled by software, this format\n+// does not handle denormals and has\n+// more than a single NaN values.\n+\n+// Fp8E4M3 -> Fp16 (packed)\n+const std::string Fp8E4M3_to_Fp16 =\n+    \"{                                      \\n\"\n+    \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n+    \"prmt.b32 a0, 0, $2, 0x5040;            \\n\" // a0 = 0xf300f400\n+    \"prmt.b32 a1, 0, $2, 0x7060;            \\n\" // a1 = 0xf100f200\n+    \"lop3.b32 b0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // b0 = a0 & 0x7fff7fff\n+    \"lop3.b32 b1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n+    \"shr.b32  b0, b0, 1;                    \\n\" // b0 >>= 1\n+    \"shr.b32  b1, b1, 1;                    \\n\" // shift into fp16 position\n+    \"add.u32  b0, b0, 0x20002000;           \\n\" // b0.exp += 2**4-2**3\n+                                                // exponent compensate = 8\n+    \"add.u32  b1, b1, 0x20002000;           \\n\" // b1 += 8<<10 | 8<<10<<16\n+    \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n+    \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n+    \"}\";\n+\n+// Fp16 -> Fp8E4M3 (packed)\n+const std::string Fp16_to_Fp8E4M3 =\n+    \"{                                      \\n\"\n+    \".reg .b32 a<2>, b<2>;                  \\n\" // see Fp8E4M3x4ToFp16x4\n+    \"sub.u32 a0, $1, 0x20002000;            \\n\" // a0 = input0 - 0x20002000\n+                                                // (compensate offset)\n+    \"sub.u32 a1, $2, 0x20002000;            \\n\" // a1 = input1 - 0x20002000\n+                                                // (8 << 10 | 8 << 10 << 16)\n+    \"shl.b32 a0, a0, 1;                     \\n\" // a0 <<= 1\n+    \"shl.b32 a1, a1, 1;                     \\n\" // shift into fp8e4 position\n+    \"lop3.b32 a0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // a0 &= 0x7fff7fff\n+    \"lop3.b32 a1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n+    \"add.u32 a0, a0, 0x00800080;            \\n\" // a0 += 0x00800080\n+    \"add.u32 a1, a1, 0x00800080;            \\n\" // (round to nearest)\n+    \"lop3.b32 b0, $1, 0x80008000, a0, 0xea; \\n\" // b0 = a0|(0x80008000&in0)\n+    \"lop3.b32 b1, $2, 0x80008000, a1, 0xea; \\n\" // (restore sign)\n+    \"prmt.b32 $0, b0, b1, 0x7531;           \\n\" // output = b1b0\n+    \"}\";\n+\n+// WARN: subnormal (0bs0000xxx) are not handled\n+const std::string Fp8E4M3_to_Bf16 =\n+    \"{                                      \\n\"\n+    \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n+    \"prmt.b32 a0, 0, $2, 0x5040;            \\n\" // a0 = 0xf300f400\n+    \"prmt.b32 a1, 0, $2, 0x7060;            \\n\" // a1 = 0xf100f200\n+    \"and.b32 b0, a0, 0x7fff7fff;            \\n\" // b0 = a0 & 0x7fff7fff\n+    \"and.b32 b1, a1, 0x7fff7fff;            \\n\" // (strip sign)\n+    \"shr.b32 b0, b0, 4;                     \\n\" // b0 >>= 4\n+    \"shr.b32 b1, b1, 4;                     \\n\" // shift into fp16 position\n+    \"add.u32 b0, b0, 0x3c003c00;            \\n\" // b0.exp += 2**7-2**3\n+                                                // exponent compensate = 120\n+    \"add.u32 b1, b1, 0x3c003c00;            \\n\" // b1 += 120<<7 | 120<<7<<16\n+    \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n+    \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n+    \"}\";\n+\n+const std::string Bf16_to_Fp8E4M3 =\n+    \"{                                           \\n\" // bf16=fp8>>4 + 120<<7\n+    \".reg .u32 sign, sign<2>, nosign, nosign<2>; \\n\" // fp8_min = 0b00000000\n+    \".reg .u32 fp8_min, fp8_max, rn_;            \\n\" // fp8_max = 0b11111111\n+    \"mov.u32 fp8_min, 0x3c003c00;                \\n\" // so bf16_min = 0x3c00\n+    \"mov.u32 fp8_max, 0x43f043f0;                \\n\" // so bf16_max = 0x43f0\n+    \"mov.u32 rn_, 0x80008;                       \\n\" // round to nearest\n+    \"and.b32 sign0, $1, 0x80008000;              \\n\" // sign0=in0&0x80008000\n+    \"and.b32 sign1, $2, 0x80008000;              \\n\" // (store sign)\n+    \"prmt.b32 sign, sign0, sign1, 0x7531;        \\n\"\n+    \"and.b32 nosign0, $1, 0x7fff7fff;            \\n\" // nosign0=in0&0x7fff7fff\n+    \"and.b32 nosign1, $2, 0x7fff7fff;            \\n\" // (strip sign)\n+\n+    // nosign = clamp(nosign, min, max)\n+    \".reg .u32 nosign_0_<2>, nosign_1_<2>;       \\n\"\n+    \"and.b32 nosign_0_0, nosign0, 0xffff0000;    \\n\"\n+    \"max.u32 nosign_0_0, nosign_0_0, 0x3c000000; \\n\"\n+    \"min.u32 nosign_0_0, nosign_0_0, 0x43f00000; \\n\"\n+    \"and.b32 nosign_0_1, nosign0, 0x0000ffff;    \\n\"\n+    \"max.u32 nosign_0_1, nosign_0_1, 0x3c00;     \\n\"\n+    \"min.u32 nosign_0_1, nosign_0_1, 0x43f0;     \\n\"\n+    \"or.b32 nosign0, nosign_0_0, nosign_0_1;     \\n\"\n+    \"and.b32 nosign_1_0, nosign1, 0xffff0000;    \\n\"\n+    \"max.u32 nosign_1_0, nosign_1_0, 0x3c000000; \\n\"\n+    \"min.u32 nosign_1_0, nosign_1_0, 0x43f00000; \\n\"\n+    \"and.b32 nosign_1_1, nosign1, 0x0000ffff;    \\n\"\n+    \"max.u32 nosign_1_1, nosign_1_1, 0x3c00;     \\n\"\n+    \"min.u32 nosign_1_1, nosign_1_1, 0x43f0;     \\n\"\n+    \"or.b32 nosign1, nosign_1_0, nosign_1_1;     \\n\"\n+\n+    \"add.u32 nosign0, nosign0, rn_;              \\n\" // nosign0 += rn_\n+    \"add.u32 nosign1, nosign1, rn_;              \\n\" // (round to nearest)\n+    \"sub.u32 nosign0, nosign0, 0x3c003c00;       \\n\" // nosign0-=0x3c003c00\n+    \"sub.u32 nosign1, nosign1, 0x3c003c00;       \\n\" // (compensate offset)\n+    \"shr.u32 nosign0, nosign0, 4;                \\n\" // nosign0 >>= 4\n+    \"shr.u32 nosign1, nosign1, 4;                \\n\" // shift into to fp8e4\n+    \"prmt.b32 nosign, nosign0, nosign1, 0x6420;  \\n\" // nosign0 = 0x00f100f2\n+                                                     // nosign1 = 0x00f300f4\n+                                                     // nosign = 0xf3f4f1f2\n+    \"or.b32 $0, nosign, sign;                    \\n\" // restore sign\n+    \"}\";\n+\n static SmallVector<Value> reorderValues(const SmallVector<Value> &values,\n                                         Type inType, Type ouType) {\n   auto inTensorTy = inType.dyn_cast<RankedTensorType>();\n@@ -142,435 +363,57 @@ struct FpToFpOpConversion\n   // FP8 -> FP16\n   /* ------------------ */\n \n-  static SmallVector<Value>\n-  convertFp8x4ToFp16x4(Location loc, ConversionPatternRewriter &rewriter,\n-                       const char *ptxAsm, const Value &v0, const Value &v1,\n-                       const Value &v2, const Value &v3) {\n-    auto ctx = rewriter.getContext();\n-    auto fp8x4VecTy = vec_ty(i8_ty, 4);\n-    Value fp8x4Vec = undef(fp8x4VecTy);\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v0, i32_val(0));\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v1, i32_val(1));\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v2, i32_val(2));\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v3, i32_val(3));\n-    fp8x4Vec = bitcast(fp8x4Vec, i32_ty);\n-\n-    PTXBuilder builder;\n-    auto &ptxOp = *builder.create(ptxAsm);\n-\n-    auto *o0 = builder.newOperand(\"=r\");\n-    auto *o1 = builder.newOperand(\"=r\");\n-    auto *i = builder.newOperand(fp8x4Vec, \"r\");\n-    ptxOp({o0, o1, i}, /*onlyAttachMLIRArgs=*/true);\n-\n-    auto fp16x2VecTy = vec_ty(f16_ty, 2);\n-    auto fp16x2x2StructTy =\n-        struct_ty(SmallVector<Type>{fp16x2VecTy, fp16x2VecTy});\n-    auto fp16x2x2Struct =\n-        builder.launch(rewriter, loc, fp16x2x2StructTy, false);\n-    auto fp16x2Vec0 = extract_val(fp16x2VecTy, fp16x2x2Struct, 0);\n-    auto fp16x2Vec1 = extract_val(fp16x2VecTy, fp16x2x2Struct, 1);\n-    return {extract_element(f16_ty, fp16x2Vec0, i32_val(0)),\n-            extract_element(f16_ty, fp16x2Vec0, i32_val(1)),\n-            extract_element(f16_ty, fp16x2Vec1, i32_val(0)),\n-            extract_element(f16_ty, fp16x2Vec1, i32_val(1))};\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp8E4M3x4ToFp16x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto *ptxAsm = // WARN: subnormal (0bs0000xxx) are not handled\n-        \"{                                      \\n\"\n-        \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n-        \"prmt.b32 a0, 0, $2, 0x5040;            \\n\" // a0 = 0xf300f400\n-        \"prmt.b32 a1, 0, $2, 0x7060;            \\n\" // a1 = 0xf100f200\n-        \"lop3.b32 b0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // b0 = a0 & 0x7fff7fff\n-        \"lop3.b32 b1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n-        \"shr.b32  b0, b0, 1;                    \\n\" // b0 >>= 1\n-        \"shr.b32  b1, b1, 1;                    \\n\" // shift into fp16 position\n-        \"add.u32  b0, b0, 0x20002000;           \\n\" // b0.exp += 2**4-2**3\n-                                                    // exponent compensate = 8\n-        \"add.u32  b1, b1, 0x20002000;           \\n\" // b1 += 8<<10 | 8<<10<<16\n-        \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n-        \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n-        \"}\";\n-    return convertFp8x4ToFp16x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp8E5M2x4ToFp16x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    // exponent bias of Fp8E5M2 and Fp16 are the same\n-    auto *ptxAsm = \"{                           \\n\"\n-                   \"prmt.b32 $0, 0, $2, 0x5140; \\n\\t\"\n-                   \"prmt.b32 $1, 0, $2, 0x7362; \\n\\t\"\n-                   \"}\";\n-    return convertFp8x4ToFp16x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  }\n-\n-  /* ------------------ */\n-  // FP8 -> BF16\n-  /* ------------------ */\n-  static SmallVector<Value>\n-  convertFp8x4ToBf16x4(Location loc, ConversionPatternRewriter &rewriter,\n-                       const char *ptxAsm, const Value &v0, const Value &v1,\n-                       const Value &v2, const Value &v3) {\n-    auto ctx = rewriter.getContext();\n-    auto fp8x4VecTy = vec_ty(i8_ty, 4);\n-    Value fp8x4Vec = undef(fp8x4VecTy);\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v0, i32_val(0));\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v1, i32_val(1));\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v2, i32_val(2));\n-    fp8x4Vec = insert_element(fp8x4VecTy, fp8x4Vec, v3, i32_val(3));\n-    fp8x4Vec = bitcast(fp8x4Vec, i32_ty);\n-\n-    PTXBuilder builder;\n-    auto &ptxOp = *builder.create(ptxAsm);\n-\n-    auto *o0 = builder.newOperand(\"=r\");\n-    auto *o1 = builder.newOperand(\"=r\");\n-    auto *i = builder.newOperand(fp8x4Vec, \"r\");\n-    ptxOp({o0, o1, i}, /* onlyAttachMLIRArgs */ true);\n-\n-    auto bf16x2VecTy = vec_ty(i16_ty, 2);\n-    auto bf16x2x2StructTy =\n-        struct_ty(SmallVector<Type>{bf16x2VecTy, bf16x2VecTy});\n-    auto bf16x2x2Struct =\n-        builder.launch(rewriter, loc, bf16x2x2StructTy, false);\n-    auto bf16x2Vec0 = extract_val(bf16x2VecTy, bf16x2x2Struct, 0);\n-    auto bf16x2Vec1 = extract_val(bf16x2VecTy, bf16x2x2Struct, 1);\n-    return {extract_element(i16_ty, bf16x2Vec0, i32_val(0)),\n-            extract_element(i16_ty, bf16x2Vec0, i32_val(1)),\n-            extract_element(i16_ty, bf16x2Vec1, i32_val(0)),\n-            extract_element(i16_ty, bf16x2Vec1, i32_val(1))};\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp8E4M3x4ToBf16x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto *ptxAsm = // WARN: subnormal (0bs0000xxx) are not handled\n-        \"{                                      \\n\"\n-        \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n-        \"prmt.b32 a0, 0, $2, 0x5040;            \\n\" // a0 = 0xf300f400\n-        \"prmt.b32 a1, 0, $2, 0x7060;            \\n\" // a1 = 0xf100f200\n-        \"and.b32 b0, a0, 0x7fff7fff;            \\n\" // b0 = a0 & 0x7fff7fff\n-        \"and.b32 b1, a1, 0x7fff7fff;            \\n\" // (strip sign)\n-        \"shr.b32 b0, b0, 4;                     \\n\" // b0 >>= 4\n-        \"shr.b32 b1, b1, 4;                     \\n\" // shift into fp16 position\n-        \"add.u32 b0, b0, 0x3c003c00;            \\n\" // b0.exp += 2**7-2**3\n-                                                    // exponent compensate = 120\n-        \"add.u32 b1, b1, 0x3c003c00;            \\n\" // b1 += 120<<7 | 120<<7<<16\n-        \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n-        \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n-        \"}\";\n-    return convertFp8x4ToBf16x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  };\n-\n-  static SmallVector<Value>\n-  convertFp8E5M2x4ToBf16x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto *ptxAsm = // WARN: subnormal (0bs00000xx) are not handled\n-        \"{                                      \\n\"\n-        \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n-        \"prmt.b32 a0, 0, $2, 0x5140;            \\n\" // a0 = 0xf300f400\n-        \"prmt.b32 a1, 0, $2, 0x7362;            \\n\" // a1 = 0xf100f200\n-        \"lop3.b32 b0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // b0 = a0 & 0x7fff7fff\n-        \"lop3.b32 b1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n-        \"shr.b32  b0, b0, 3;                    \\n\" // b0 >>= 3\n-        \"shr.b32  b1, b1, 3;                    \\n\" // shift into bf16 position\n-        \"add.u32  b0, b0, 0x38003800;           \\n\" // b0.exp += 2**7-2**4\n-                                                    // exponent compensate = 112\n-        \"add.u32  b1, b1, 0x38003800;           \\n\" // b1 += 112<<7 | 112<<7<<16\n-        \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n-        \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n-        \"}\";\n-    return convertFp8x4ToBf16x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  };\n-\n-  /* ------------------ */\n-  // FP16 -> FP8\n-  /* ------------------ */\n-\n-  static SmallVector<Value>\n-  convertFp16x4ToFp8x4(Location loc, ConversionPatternRewriter &rewriter,\n-                       const char *ptxAsm, const Value &v0, const Value &v1,\n-                       const Value &v2, const Value &v3) {\n-    auto fp16x2VecTy = vec_ty(f16_ty, 2);\n-    Value fp16x2Vec0 = undef(fp16x2VecTy);\n-    Value fp16x2Vec1 = undef(fp16x2VecTy);\n-    fp16x2Vec0 = insert_element(fp16x2VecTy, fp16x2Vec0, v0, i32_val(0));\n-    fp16x2Vec0 = insert_element(fp16x2VecTy, fp16x2Vec0, v1, i32_val(1));\n-    fp16x2Vec1 = insert_element(fp16x2VecTy, fp16x2Vec1, v2, i32_val(0));\n-    fp16x2Vec1 = insert_element(fp16x2VecTy, fp16x2Vec1, v3, i32_val(1));\n-    fp16x2Vec0 = bitcast(fp16x2Vec0, i32_ty);\n-    fp16x2Vec1 = bitcast(fp16x2Vec1, i32_ty);\n-\n-    PTXBuilder builder;\n-    auto &ptxOp = *builder.create(ptxAsm);\n-\n-    auto *o = builder.newOperand(\"=r\");\n-    auto *i0 = builder.newOperand(fp16x2Vec0, \"r\");\n-    auto *i1 = builder.newOperand(fp16x2Vec1, \"r\");\n-    ptxOp({o, i0, i1}, /*onlyAttachMLIRArgs=*/true);\n-\n-    auto fp8x4VecTy = vec_ty(i8_ty, 4);\n-    auto fp8x4Vec = builder.launch(rewriter, loc, fp8x4VecTy, false);\n-    return {extract_element(i8_ty, fp8x4Vec, i32_val(0)),\n-            extract_element(i8_ty, fp8x4Vec, i32_val(1)),\n-            extract_element(i8_ty, fp8x4Vec, i32_val(2)),\n-            extract_element(i8_ty, fp8x4Vec, i32_val(3))};\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp16x4ToFp8E4M3x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto *ptxAsm = // WARN: subnormal Fp8s are not handled\n-        \"{                                      \\n\"\n-        \".reg .b32 a<2>, b<2>;                  \\n\" // see Fp8E4M3x4ToFp16x4\n-        \"sub.u32 a0, $1, 0x20002000;            \\n\" // a0 = input0 - 0x20002000\n-                                                    // (compensate offset)\n-        \"sub.u32 a1, $2, 0x20002000;            \\n\" // a1 = input1 - 0x20002000\n-                                                    // (8 << 10 | 8 << 10 << 16)\n-        \"shl.b32 a0, a0, 1;                     \\n\" // a0 <<= 1\n-        \"shl.b32 a1, a1, 1;                     \\n\" // shift into fp8e4 position\n-        \"lop3.b32 a0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // a0 &= 0x7fff7fff\n-        \"lop3.b32 a1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n-        \"add.u32 a0, a0, 0x00800080;            \\n\" // a0 += 0x00800080\n-        \"add.u32 a1, a1, 0x00800080;            \\n\" // (round to nearest)\n-        \"lop3.b32 b0, $1, 0x80008000, a0, 0xea; \\n\" // b0 = a0|(0x80008000&in0)\n-        \"lop3.b32 b1, $2, 0x80008000, a1, 0xea; \\n\" // (restore sign)\n-        \"prmt.b32 $0, b0, b1, 0x7531;           \\n\" // output = b1b0\n-        \"}\";\n-    return convertFp16x4ToFp8x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp16x4ToFp8E5M2x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto *ptxAsm =\n-        \"{                            \\n\"\n-        \".reg .b32 a<2>;              \\n\"\n-        \"and.b32 a0, $1, 0x7fff7fff;  \\n\"           // a0 &= 0x7fff7fff\n-        \"and.b32 a1, $2, 0x7fff7fff;  \\n\"           // (strip sign)\n-        \"add.u32 a0, a0, 0x00800080;  \\n\"           // a0 += 0x00800080\n-        \"add.u32 a1, a1, 0x00800080;  \\n\"           // (round to nearest)\n-        \"lop3.b32 a0, $1, 0x80008000, a0, 0xea; \\n\" // a0 = a0|(0x80008000&in0)\n-        \"lop3.b32 a1, $2, 0x80008000, a1, 0xea; \\n\" // (restore sign)\n-        \"prmt.b32 $0, a0, a1, 0x7531; \\n\\t\"         // output = a1a0\n-        \"}\";\n-    return convertFp16x4ToFp8x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  }\n-\n-  /* ------------------ */\n-  // FP32 -> FP8\n-  /* ------------------ */\n-\n-  static SmallVector<Value>\n-  convertFp32x4ToFp8E4M3x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto c0 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v0);\n-    auto c1 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v1);\n-    auto c2 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v2);\n-    auto c3 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v3);\n-    return convertFp16x4ToFp8E4M3x4(loc, rewriter, c0, c1, c2, c3);\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp32x4ToFp8E5M2x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto c0 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v0);\n-    auto c1 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v1);\n-    auto c2 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v2);\n-    auto c3 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v3);\n-    return convertFp16x4ToFp8E5M2x4(loc, rewriter, c0, c1, c2, c3);\n-  }\n-\n-  /* ------------------ */\n-  // BF16 -> FP8\n-  /* ------------------ */\n-\n-  static SmallVector<Value>\n-  convertBf16x4ToFp8x4(Location loc, ConversionPatternRewriter &rewriter,\n-                       const char *ptxAsm, const Value &v0, const Value &v1,\n-                       const Value &v2, const Value &v3) {\n-    auto bf16x2VecTy = vec_ty(i16_ty, 2);\n-    Value bf16x2Vec0 = undef(bf16x2VecTy);\n-    Value bf16x2Vec1 = undef(bf16x2VecTy);\n-    bf16x2Vec0 = insert_element(bf16x2VecTy, bf16x2Vec0, v0, i32_val(0));\n-    bf16x2Vec0 = insert_element(bf16x2VecTy, bf16x2Vec0, v1, i32_val(1));\n-    bf16x2Vec1 = insert_element(bf16x2VecTy, bf16x2Vec1, v2, i32_val(0));\n-    bf16x2Vec1 = insert_element(bf16x2VecTy, bf16x2Vec1, v3, i32_val(1));\n-    bf16x2Vec0 = bitcast(bf16x2Vec0, i32_ty);\n-    bf16x2Vec1 = bitcast(bf16x2Vec1, i32_ty);\n-\n-    PTXBuilder builder;\n-    auto &ptxOp = *builder.create(ptxAsm);\n-\n-    auto *o = builder.newOperand(\"=r\");\n-    auto *i0 = builder.newOperand(bf16x2Vec0, \"r\");\n-    auto *i1 = builder.newOperand(bf16x2Vec1, \"r\");\n-    ptxOp({o, i0, i1}, /*onlyAttachMLIRArgs=*/true);\n-\n-    auto fp8x4VecTy = vec_ty(i8_ty, 4);\n-    auto fp8x4Vec = builder.launch(rewriter, loc, fp8x4VecTy, false);\n-    return {extract_element(i8_ty, fp8x4Vec, i32_val(0)),\n-            extract_element(i8_ty, fp8x4Vec, i32_val(1)),\n-            extract_element(i8_ty, fp8x4Vec, i32_val(2)),\n-            extract_element(i8_ty, fp8x4Vec, i32_val(3))};\n-  }\n-\n-  static SmallVector<Value>\n-  convertBf16x4ToFp8E4M3x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto *ptxAsm = // bf16 is clamped firstly to fp8 min/max\n-        \"{                                           \\n\" // bf16=fp8>>4 + 120<<7\n-        \".reg .u32 sign, sign<2>, nosign, nosign<2>; \\n\" // fp8_min = 0b00000000\n-        \".reg .u32 fp8_min, fp8_max, rn_;            \\n\" // fp8_max = 0b11111111\n-        \"mov.u32 fp8_min, 0x3c003c00;                \\n\" // so bf16_min = 0x3c00\n-        \"mov.u32 fp8_max, 0x43f043f0;                \\n\" // so bf16_max = 0x43f0\n-        \"mov.u32 rn_, 0x80008;                       \\n\" // round to nearest\n-        \"and.b32 sign0, $1, 0x80008000;              \\n\" // sign0=in0&0x80008000\n-        \"and.b32 sign1, $2, 0x80008000;              \\n\" // (store sign)\n-        \"prmt.b32 sign, sign0, sign1, 0x7531;        \\n\"\n-        \"and.b32 nosign0, $1, 0x7fff7fff;            \\n\" // nosign0=in0&0x7fff7fff\n-        \"and.b32 nosign1, $2, 0x7fff7fff;            \\n\" // (strip sign)\n-\n-        // nosign = clamp(nosign, min, max)\n-        \".reg .u32 nosign_0_<2>, nosign_1_<2>;       \\n\"\n-        \"and.b32 nosign_0_0, nosign0, 0xffff0000;    \\n\"\n-        \"max.u32 nosign_0_0, nosign_0_0, 0x3c000000; \\n\"\n-        \"min.u32 nosign_0_0, nosign_0_0, 0x43f00000; \\n\"\n-        \"and.b32 nosign_0_1, nosign0, 0x0000ffff;    \\n\"\n-        \"max.u32 nosign_0_1, nosign_0_1, 0x3c00;     \\n\"\n-        \"min.u32 nosign_0_1, nosign_0_1, 0x43f0;     \\n\"\n-        \"or.b32 nosign0, nosign_0_0, nosign_0_1;     \\n\"\n-        \"and.b32 nosign_1_0, nosign1, 0xffff0000;    \\n\"\n-        \"max.u32 nosign_1_0, nosign_1_0, 0x3c000000; \\n\"\n-        \"min.u32 nosign_1_0, nosign_1_0, 0x43f00000; \\n\"\n-        \"and.b32 nosign_1_1, nosign1, 0x0000ffff;    \\n\"\n-        \"max.u32 nosign_1_1, nosign_1_1, 0x3c00;     \\n\"\n-        \"min.u32 nosign_1_1, nosign_1_1, 0x43f0;     \\n\"\n-        \"or.b32 nosign1, nosign_1_0, nosign_1_1;     \\n\"\n-\n-        \"add.u32 nosign0, nosign0, rn_;              \\n\" // nosign0 += rn_\n-        \"add.u32 nosign1, nosign1, rn_;              \\n\" // (round to nearest)\n-        \"sub.u32 nosign0, nosign0, 0x3c003c00;       \\n\" // nosign0-=0x3c003c00\n-        \"sub.u32 nosign1, nosign1, 0x3c003c00;       \\n\" // (compensate offset)\n-        \"shr.u32 nosign0, nosign0, 4;                \\n\" // nosign0 >>= 4\n-        \"shr.u32 nosign1, nosign1, 4;                \\n\" // shift into to fp8e4\n-        \"prmt.b32 nosign, nosign0, nosign1, 0x6420;  \\n\" // nosign0 = 0x00f100f2\n-                                                         // nosign1 = 0x00f300f4\n-                                                         // nosign = 0xf3f4f1f2\n-        \"or.b32 $0, nosign, sign;                    \\n\" // restore sign\n-        \"}\";\n-    return convertBf16x4ToFp8x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  };\n-\n-  static SmallVector<Value>\n-  convertBf16x4ToFp8E5M2x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto *ptxAsm = // bf16 is clamped firstly to fp8 min/max\n-        \"{                                           \\n\" // bf16=fp8>>3 + 112<<7\n-        \".reg .u32 sign, sign<2>, nosign, nosign<2>; \\n\" // fp8_min = 0b00000000\n-        \".reg .u32 fp8_min, fp8_max, rn_;            \\n\" // fp8_max = 0b11111111\n-        \"mov.u32 fp8_min, 0x38003800;                \\n\" // so bf16_min = 0x3800\n-        \"mov.u32 fp8_max, 0x57e057e0;                \\n\" // so bf16_max = 0x57e0\n-        \"mov.u32 rn_, 0x00100010;                    \\n\" // round to nearest\n-        \"and.b32 sign0, $1, 0x80008000;              \\n\" // sign0=in0&0x80008000\n-        \"and.b32 sign1, $2, 0x80008000;              \\n\" // (store sign)\n-        \"prmt.b32 sign, sign0, sign1, 0x7531;        \\n\"\n-        \"and.b32 nosign0, $1, 0x7fff7fff;            \\n\" // nosign0=in0&0x7fff7fff\n-        \"and.b32 nosign1, $2, 0x7fff7fff;            \\n\" // (strip sign)\n-\n-        // nosign = clamp(nosign, min, max)\n-        \".reg .u32 nosign_0_<2>, nosign_1_<2>;       \\n\"\n-        \"and.b32 nosign_0_0, nosign0, 0xffff0000;    \\n\"\n-        \"max.u32 nosign_0_0, nosign_0_0, 0x38000000; \\n\"\n-        \"min.u32 nosign_0_0, nosign_0_0, 0x57e00000; \\n\"\n-        \"and.b32 nosign_0_1, nosign0, 0x0000ffff;    \\n\"\n-        \"max.u32 nosign_0_1, nosign_0_1, 0x3800;     \\n\"\n-        \"min.u32 nosign_0_1, nosign_0_1, 0x57e0;     \\n\"\n-        \"or.b32 nosign0, nosign_0_0, nosign_0_1;     \\n\"\n-        \"and.b32 nosign_1_0, nosign1, 0xffff0000;    \\n\"\n-        \"max.u32 nosign_1_0, nosign_1_0, 0x38000000; \\n\"\n-        \"min.u32 nosign_1_0, nosign_1_0, 0x57e00000; \\n\"\n-        \"and.b32 nosign_1_1, nosign1, 0x0000ffff;    \\n\"\n-        \"max.u32 nosign_1_1, nosign_1_1, 0x3800;     \\n\"\n-        \"min.u32 nosign_1_1, nosign_1_1, 0x57e0;     \\n\"\n-        \"or.b32 nosign1, nosign_1_0, nosign_1_1;     \\n\"\n-\n-        \"add.u32 nosign0, nosign0, rn_;              \\n\" // nosign0 += rn_\n-        \"add.u32 nosign1, nosign1, rn_;              \\n\" // (round to nearest)\n-        \"sub.u32 nosign0, nosign0, 0x38003800;       \\n\" // nosign0-=0x38003800\n-        \"sub.u32 nosign1, nosign1, 0x38003800;       \\n\" // (compensate offset)\n-        \"shl.b32 nosign0, nosign0, 3;                \\n\" // nosign0 <<= 3\n-        \"shl.b32 nosign1, nosign1, 3;                \\n\" // shift into to fp8e4\n-        \"prmt.b32 nosign, nosign0, nosign1, 0x7531;  \\n\" // nosign0 = 0xf100f200\n-                                                         // nosign1 = 0xf300f400\n-                                                         // nosign = 0xf3f4f1f2\n-        \"or.b32 $0, nosign, sign;                    \\n\" // restore sign\n-        \"}\";\n-    return convertBf16x4ToFp8x4(loc, rewriter, ptxAsm, v0, v1, v2, v3);\n-  }\n-\n-  /* ------------------ */\n-  // FP8 -> FP32\n-  /* ------------------ */\n-\n-  static SmallVector<Value>\n-  convertFp8E4M3x4ToFp32x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto fp16Values = convertFp8E4M3x4ToFp16x4(loc, rewriter, v0, v1, v2, v3);\n-    return {convertFp16ToFp32(loc, rewriter, fp16Values[0]),\n-            convertFp16ToFp32(loc, rewriter, fp16Values[1]),\n-            convertFp16ToFp32(loc, rewriter, fp16Values[2]),\n-            convertFp16ToFp32(loc, rewriter, fp16Values[3])};\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp8E5M2x4ToFp32x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto fp16Values = convertFp8E5M2x4ToFp16x4(loc, rewriter, v0, v1, v2, v3);\n-    return {rewriter.create<LLVM::FPExtOp>(loc, f32_ty, fp16Values[0]),\n-            rewriter.create<LLVM::FPExtOp>(loc, f32_ty, fp16Values[1]),\n-            rewriter.create<LLVM::FPExtOp>(loc, f32_ty, fp16Values[2]),\n-            rewriter.create<LLVM::FPExtOp>(loc, f32_ty, fp16Values[3])};\n-  }\n-\n-  //\n-\n-  static SmallVector<Value>\n-  convertFp8E4M3x4ToFp64x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto fp16Values = convertFp8E4M3x4ToFp16x4(loc, rewriter, v0, v1, v2, v3);\n-    return {rewriter.create<LLVM::FPExtOp>(loc, f64_ty, fp16Values[0]),\n-            rewriter.create<LLVM::FPExtOp>(loc, f64_ty, fp16Values[1]),\n-            rewriter.create<LLVM::FPExtOp>(loc, f64_ty, fp16Values[2]),\n-            rewriter.create<LLVM::FPExtOp>(loc, f64_ty, fp16Values[3])};\n-  }\n-\n-  static SmallVector<Value>\n-  convertFp64x4ToFp8E4M3x4(Location loc, ConversionPatternRewriter &rewriter,\n-                           const Value &v0, const Value &v1, const Value &v2,\n-                           const Value &v3) {\n-    auto c0 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v0);\n-    auto c1 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v1);\n-    auto c2 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v2);\n-    auto c3 = rewriter.create<LLVM::FPTruncOp>(loc, f16_ty, v3);\n-    return convertFp16x4ToFp8E4M3x4(loc, rewriter, c0, c1, c2, c3);\n+  static ConvertorT makeConverterFromPtx(const std::string &ptxAsm, Type inType,\n+                                         Type outType) {\n+\n+    ConvertorT converter =\n+        [ptxAsm, inType,\n+         outType](Location loc, ConversionPatternRewriter &rewriter,\n+                  const Value &v0, const Value &v1, const Value &v2,\n+                  const Value &v3) -> SmallVector<Value> {\n+      SmallVector<Value> v = {v0, v1, v2, v3};\n+      auto ctx = rewriter.getContext();\n+      int inBitwidth = inType.getIntOrFloatBitWidth();\n+      int outBitwidth = outType.getIntOrFloatBitWidth();\n+      // first, we pack `v` into 32-bit ints\n+      int inVecWidth = 32 / inBitwidth;\n+      auto inVecTy = vec_ty(inType, inVecWidth);\n+      SmallVector<Value> inPacked(4 / inVecWidth, undef(inVecTy));\n+      for (size_t i = 0; i < 4; i++)\n+        inPacked[i / inVecWidth] = insert_element(\n+            inVecTy, inPacked[i / inVecWidth], v[i], i32_val(i % inVecWidth));\n+      for (size_t i = 0; i < inPacked.size(); i++)\n+        inPacked[i] = bitcast(inPacked[i], i32_ty);\n+\n+      // then, we run the provided inline PTX\n+      int outVecWidth = 32 / outBitwidth;\n+      int outNums = 4 / outVecWidth;\n+      PTXBuilder builder;\n+      SmallVector<PTXBuilder::Operand *> operands;\n+      for (int i = 0; i < outNums; i++)\n+        operands.push_back(builder.newOperand(\"=r\"));\n+      for (Value inVal : inPacked)\n+        operands.push_back(builder.newOperand(inVal, \"r\"));\n+      auto &ptxOp = *builder.create(ptxAsm);\n+      ptxOp(operands, /*onlyAttachMLIRArgs=*/true);\n+      auto outVecTy = vec_ty(outType, outVecWidth);\n+      SmallVector<Value> outPacked;\n+      if (outNums == 1)\n+        outPacked.push_back(builder.launch(rewriter, loc, outVecTy, false));\n+      else {\n+        auto outStructTy = struct_ty(SmallVector<Type>(outNums, outVecTy));\n+        auto outStruct = builder.launch(rewriter, loc, outStructTy, false);\n+        for (int i = 0; i < outNums; i++)\n+          outPacked.push_back(extract_val(outVecTy, outStruct, i));\n+      }\n+      // unpack the output\n+      SmallVector<Value> ret;\n+      for (size_t i = 0; i < 4; i++)\n+        ret.push_back(extract_element(outType, outPacked[i / outVecWidth],\n+                                      i32_val(i % outVecWidth)));\n+      return ret;\n+    };\n+    return converter;\n   }\n \n   static Value convertBf16ToFp32(Location loc,\n@@ -620,54 +463,51 @@ struct FpToFpOpConversion\n   }\n \n   ConvertorT getConversionFunc(Type srcTy, Type dstTy) const {\n-    auto F8E4M3TyID = TypeID::get<mlir::Float8E4M3FNType>();\n+    auto F8E4M3B15TyID = TypeID::get<mlir::Float8E4M3B11FNUZType>();\n+    auto F8E4M3TyID = TypeID::get<mlir::Float8E4M3FNUZType>();\n     auto F8E5M2TyID = TypeID::get<mlir::Float8E5M2Type>();\n     auto F16TyID = TypeID::get<mlir::Float16Type>();\n     auto BF16TyID = TypeID::get<mlir::BFloat16Type>();\n     auto F32TyID = TypeID::get<mlir::Float32Type>();\n     auto F64TyID = TypeID::get<mlir::Float64Type>();\n-    static DenseMap<std::pair<TypeID, TypeID>, ConvertorT> convertorMap = {\n+    static DenseMap<std::pair<TypeID, TypeID>, std::string> srcMap = {\n         // F8 -> F16\n-        {{F8E4M3TyID, F16TyID}, convertFp8E4M3x4ToFp16x4},\n-        {{F8E5M2TyID, F16TyID}, convertFp8E5M2x4ToFp16x4},\n+        {{F8E4M3B15TyID, F16TyID}, Fp8E4M3B15_to_Fp16},\n+        {{F8E4M3TyID, F16TyID}, Fp8E4M3_to_Fp16},\n+        {{F8E5M2TyID, F16TyID}, Fp8E5M2_to_Fp16},\n         // F16 -> F8\n-        {{F16TyID, F8E4M3TyID}, convertFp16x4ToFp8E4M3x4},\n-        {{F16TyID, F8E5M2TyID}, convertFp16x4ToFp8E5M2x4},\n+        {{F16TyID, F8E4M3B15TyID}, Fp16_to_Fp8E4M3B15},\n+        {{F16TyID, F8E4M3TyID}, Fp16_to_Fp8E4M3},\n+        {{F16TyID, F8E5M2TyID}, Fp16_to_Fp8E5M2},\n         // F8 -> BF16\n-        {{F8E4M3TyID, BF16TyID}, convertFp8E4M3x4ToBf16x4},\n-        {{F8E5M2TyID, BF16TyID}, convertFp8E5M2x4ToBf16x4},\n+        {{F8E4M3TyID, BF16TyID}, Fp8E4M3_to_Bf16},\n+        {{F8E5M2TyID, BF16TyID}, Fp8E5M2_to_Bf16},\n         // BF16 -> F8\n-        {{BF16TyID, F8E4M3TyID}, convertBf16x4ToFp8E4M3x4},\n-        {{BF16TyID, F8E5M2TyID}, convertBf16x4ToFp8E5M2x4},\n-        // F8 -> F32\n-        {{F8E4M3TyID, F32TyID}, convertFp8E4M3x4ToFp32x4},\n-        {{F8E5M2TyID, F32TyID}, convertFp8E5M2x4ToFp32x4},\n-        // F32 -> F8\n-        {{F32TyID, F8E4M3TyID}, convertFp32x4ToFp8E4M3x4},\n-        {{F32TyID, F8E5M2TyID}, convertFp32x4ToFp8E5M2x4},\n+        {{BF16TyID, F8E4M3TyID}, Bf16_to_Fp8E4M3},\n+        {{BF16TyID, F8E5M2TyID}, Bf16_to_Fp8E5M2},\n     };\n \n     std::pair<TypeID, TypeID> key = {srcTy.getTypeID(), dstTy.getTypeID()};\n-    if (convertorMap.count(key) == 0) {\n+    if (srcMap.count(key) == 0) {\n       llvm::errs() << \"Unsupported conversion from \" << srcTy << \" to \" << dstTy\n                    << \"\\n\";\n       llvm_unreachable(\"\");\n     }\n-    return convertorMap.lookup(key);\n+    return makeConverterFromPtx(srcMap.lookup(key),\n+                                getTypeConverter()->convertType(srcTy),\n+                                getTypeConverter()->convertType(dstTy));\n   }\n \n   LogicalResult\n   matchAndRewrite(triton::FpToFpOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    // llvm::outs() << 0 << \"\\n\";\n     auto srcTensorType = op.getFrom().getType().cast<mlir::RankedTensorType>();\n     auto dstTensorType =\n         op.getResult().getType().cast<mlir::RankedTensorType>();\n+    auto srcElementType = srcTensorType.getElementType();\n+    auto dstElementType = dstTensorType.getElementType();\n     auto loc = op->getLoc();\n     // check that the number of elements is divisible by 4\n-    // Get convertor\n-    auto cvtFunc = getConversionFunc(srcTensorType.getElementType(),\n-                                     dstTensorType.getElementType());\n     // Unpack value\n     auto inVals = getTypeConverter()->unpackLLElements(loc, adaptor.getFrom(),\n                                                        rewriter, srcTensorType);\n@@ -678,9 +518,19 @@ struct FpToFpOpConversion\n     auto elems = inVals.size();\n     assert(elems % 4 == 0 &&\n            \"FP8 casting only support tensors with 4-aligned sizes\");\n+    bool isFP32src = srcElementType.isF32();\n+    bool isFP32dst = dstElementType.isF32();\n+    auto cvtFunc = getConversionFunc(isFP32src ? f16_ty : srcElementType,\n+                                     isFP32dst ? f16_ty : dstElementType);\n+    if (isFP32src)\n+      for (Value &v : inVals)\n+        v = convertFp32ToFp16(loc, rewriter, v);\n     for (size_t i = 0; i < elems; i += 4)\n       outVals.append(cvtFunc(loc, rewriter, inVals[i], inVals[i + 1],\n                              inVals[i + 2], inVals[i + 3]));\n+    if (isFP32dst)\n+      for (Value &v : outVals)\n+        v = convertFp16ToFp32(loc, rewriter, v);\n     // Pack values\n     assert(outVals.size() == elems);\n     outVals = reorderValues(outVals, srcTensorType, dstTensorType);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM/Fp8E4M3B15.cpp", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM/Fp8E5M2.cpp", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.cpp", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "file_content_changes": "@@ -24,7 +24,10 @@ TritonGPUToLLVMTypeConverter::TritonGPUToLLVMTypeConverter(\n     return convertTritonTensorType(type);\n   });\n   // Internally store float8 as int8\n-  addConversion([&](mlir::Float8E4M3FNType type) -> std::optional<Type> {\n+  addConversion([&](mlir::Float8E4M3B11FNUZType type) -> std::optional<Type> {\n+    return IntegerType::get(type.getContext(), 8);\n+  });\n+  addConversion([&](mlir::Float8E4M3FNUZType type) -> std::optional<Type> {\n     return IntegerType::get(type.getContext(), 8);\n   });\n   addConversion([&](mlir::Float8E5M2Type type) -> std::optional<Type> {"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "file_content_changes": "@@ -643,7 +643,13 @@ void init_triton_ir(py::module &&m) {\n           [](mlir::OpBuilder &self) -> mlir::Type { return self.getI64Type(); })\n       .def(\"get_fp8e4_ty\",\n            [](mlir::OpBuilder &self) -> mlir::Type {\n-             return self.getType<mlir::Float8E4M3FNType>();\n+             return self.getType<mlir::Float8E4M3FNUZType>();\n+           })\n+      .def(\"get_fp8e4b15_ty\",\n+           [](mlir::OpBuilder &self) -> mlir::Type {\n+             // TODO: upstream FP8E4B15 into MLIR, or find a way to externally\n+             // have a float-like type compatible with float only native ops\n+             return self.getType<mlir::Float8E4M3B11FNUZType>();\n            })\n       .def(\"get_fp8e5_ty\",\n            [](mlir::OpBuilder &self) -> mlir::Type {"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 60, "deletions": 92, "changes": 152, "file_content_changes": "@@ -706,8 +706,8 @@ def test_abs(dtype_x, device):\n     _test_unary(dtype_x, 'tl.abs(x)', 'np.abs(x) ', device=device)\n \n \n-@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4, tl.float8e5])\n-def test_abs_f8(in_dtype, device):\n+@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4b15, tl.float8e4, tl.float8e5])\n+def test_abs_fp8(in_dtype, device):\n \n     @triton.jit\n     def abs_kernel(Z, X, SIZE: tl.constexpr):\n@@ -723,7 +723,6 @@ def abs_kernel(Z, X, SIZE: tl.constexpr):\n     f8 = triton.reinterpret(f8_tensor, in_dtype)\n     n_elements = f8_tensor.numel()\n     out_f8 = torch.empty_like(f8_tensor)\n-    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n     abs_kernel[(1,)](f8, triton.reinterpret(out_f8, in_dtype), n_elements)\n \n     f32_tensor = convert_float_to_float32(f8_tensor, in_dtype)\n@@ -1215,7 +1214,7 @@ def convert_float_to_float32(fp: torch.tensor, dtype=None):\n \n     fp = fp.view(getattr(torch, f\"int{dtype.primitive_bitwidth}\"))\n     exp_width = dtype.primitive_bitwidth - dtype.fp_mantissa_width - 1\n-    exp_bias = 2 ** (exp_width - 1) - 1\n+    exp_bias = dtype.exponent_bias\n     sign = ((fp >> (dtype.primitive_bitwidth - 1)) & 0x01).int()\n     exp = ((fp >> dtype.fp_mantissa_width) & ((1 << exp_width) - 1)).int()\n     frac = (fp & ((1 << dtype.fp_mantissa_width) - 1)).int()\n@@ -1228,7 +1227,7 @@ def convert_float_to_float32(fp: torch.tensor, dtype=None):\n \n     extended_exp = ((1 << (tl.float32.primitive_bitwidth - tl.float32.fp_mantissa_width - 1)) - 1) << tl.float32.fp_mantissa_width\n     # special cases, exp is 0b11..1\n-    if dtype == tl.float8e4:\n+    if dtype in [tl.float8e4, tl.float8e4b15]:\n         # float8e4m3 does not have infinities\n         output[fp == 0b01111111] = torch.nan\n         output[fp == 0b11111111] = torch.nan\n@@ -1255,52 +1254,43 @@ def test_convert_float16_to_float32(in_dtype, device):\n     assert torch.all(f16_input[other] == f32_output[other])\n \n \n-@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4, tl.float8e5])\n-@pytest.mark.parametrize(\"out_dtype\", [torch.float16, torch.bfloat16, torch.float32])\n-def test_f8_xf16_roundtrip(in_dtype, out_dtype, device):\n-    \"\"\"Tests that converting an f8 to f16 and back to f8 doesn't change its value\"\"\"\n-    check_type_supported(out_dtype, device)\n-\n-    @triton.jit\n-    def copy_kernel(input_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n-        offsets = tl.program_id(axis=0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n-        mask = offsets < n_elements\n-        input = tl.load(input_ptr + offsets, mask=mask)\n-        output = input\n-        tl.store(output_ptr + offsets, output, mask=mask)\n-\n-    f8_tensor = torch.tensor(range(-128, 128), dtype=torch.int8, device=device)\n-    # f32_to_f8 doesn't handle nan, so we make sure f8_tensor doesn't contain any nan\n-    all_exp_ones = (f8_tensor & 0b01111100) == 128 - 2**in_dtype.fp_mantissa_width\n-    f8_tensor[all_exp_ones] = 0\n-    f8 = triton.reinterpret(f8_tensor, in_dtype)\n-    n_elements = f8_tensor.numel()\n-    xf16 = torch.empty_like(f8_tensor, dtype=out_dtype)\n-    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-    copy_kernel[grid](f8, xf16, n_elements, BLOCK_SIZE=1024)\n-\n-    # exponent_mask = 0b01111100 for float8e5\n-    # exponent_mask = 0b01111000 for float8e4\n-    exponent_mask = 0b01111111 ^ ((1 << in_dtype.fp_mantissa_width) - 1)\n-    normal = torch.logical_and((f8_tensor & exponent_mask) != 0, (f8_tensor & exponent_mask) != exponent_mask)\n-    ref16 = convert_float_to_float32(f8_tensor, in_dtype)\n-    # WARN: currently only normal float8s are handled\n-    assert torch.all(xf16[normal] == ref16[normal])\n-\n-    f8_output_tensor = torch.empty_like(xf16, dtype=torch.int8)\n-    f8_output = triton.reinterpret(f8_output_tensor, in_dtype)\n-    copy_kernel[grid](xf16, f8_output, n_elements, BLOCK_SIZE=1024)\n+def serialize_fp8(np_data, in_dtype):\n+    if in_dtype == tl.float8e4b15:\n+        # triton's f8e4b15 format is optimized for software emulation\n+        # as a result, each pack of 4xfp8 values:\n+        # s0b0s1b1s2b2s3b3 (for s, b sign and bits respectively)\n+        # is actually internally stored as\n+        # s0s2b0b2s1s3b1b3\n+        # we apply the conversion here\n+        f8x4 = np_data.view(np.uint32)\n+        s = [(f8x4 & (0x80000000 >> i)) << i for i in range(0, 32, 8)]\n+        b = [(f8x4 & (0x7f000000 >> i)) << i for i in range(0, 32, 8)]\n+        signs = (s[0] >> 0) | (s[1] >> 16) | (s[2] >> 1) | (s[3] >> 17)\n+        bits = (b[0] >> 1) | (b[1] >> 17) | (b[2] >> 8) | (b[3] >> 24)\n+        # tensor of triton fp8 data\n+        return (signs | bits).view(np.int8)\n+    else:\n+        return np_data\n \n-    assert torch.all(f8_tensor == f8_output_tensor)\n \n+@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4b15, tl.float8e4, tl.float8e5])\n+@pytest.mark.parametrize(\"out_dtype\", [torch.float16, torch.bfloat16, torch.float32])\n+def test_fp8_fpN_roundtrip(in_dtype, out_dtype, device):\n+    \"\"\"\n+    For all possible float8 values (ref_fp8 = range(0, 256)), test that:\n+        - conversion tri_fp16 = convert(input=ref_fp8, out=out_dtype) matches the reference\n+        - conversion tri_fp8 = convert(input=tri_fp16, out=out_dtype) matches the original\n+    this is only possible if both conversions are correct\n+    \"\"\"\n+    check_type_supported(out_dtype, device)\n+    from contextlib import nullcontext as does_not_raise\n+    expectation = does_not_raise()\n+    err_msg = None\n+    if (in_dtype == tl.float8e4b15 and out_dtype != torch.float16) or\\\n+       (in_dtype != torch.float16 and out_dtype == tl.float8e4b15):\n+        expectation = pytest.raises(triton.CompilationError)\n+        err_msg = \"fp8e4b15 can only be converted to/from fp16\"\n \n-@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4, tl.float8e5])\n-@pytest.mark.parametrize(\"out_dtype\", [torch.float16, torch.bfloat16])\n-def test_f16_to_f8_rounding(in_dtype, out_dtype, device):\n-    \"\"\"Takes all float16s, converts them to float8 and back to float16. Checks that the absolute\n-    error is the minimum over all float8.\n-    Or the same explanation a bit mathier:\n-    for all f16 |f16 - fromf8(tof8(f16))| == min over all f8 |f16 - fromf8(f8)|\"\"\"\n     @triton.jit\n     def copy_kernel(input_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n         offsets = tl.program_id(axis=0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n@@ -1309,50 +1299,28 @@ def copy_kernel(input_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n         output = input\n         tl.store(output_ptr + offsets, output, mask=mask)\n \n-    i16_input = torch.tensor(range(-int(2 ** (16 - 1)), int(2 ** (16 - 1))), dtype=torch.int16, device=device)\n-    f16_input = i16_input.view(out_dtype)\n-    n_elements = f16_input.numel()\n-    f8_output_tensor = torch.empty_like(f16_input, dtype=torch.int8)\n-    f8_output = triton.reinterpret(f8_output_tensor, in_dtype)\n-    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-    copy_kernel[grid](f16_input, f8_output, n_elements, BLOCK_SIZE=1024)\n-\n-    f16_output = torch.empty_like(f16_input, dtype=out_dtype)\n-    copy_kernel[grid](f8_output, f16_output, n_elements, BLOCK_SIZE=1024)\n-\n-    abs_error = torch.abs(f16_input - f16_output)\n-\n-    all_f8_vals_tensor = torch.tensor(range(2 ** 8), dtype=torch.uint8, device=device)\n-    all_f8_vals = triton.reinterpret(all_f8_vals_tensor, in_dtype)\n-    all_f8_vals_in_f16 = torch.empty_like(all_f8_vals_tensor, dtype=out_dtype)\n-    copy_kernel[grid](all_f8_vals, all_f8_vals_in_f16, n_elements=256, BLOCK_SIZE=1024)\n-\n-    all_finite_f8_vals_in_f16 = all_f8_vals_in_f16[\n-        torch.isfinite(all_f8_vals_in_f16)\n-    ]\n-\n-    min_error = torch.min(\n-        torch.abs(\n-            f16_input.reshape((-1, 1))\n-            - all_finite_f8_vals_in_f16.reshape((1, -1))\n-        ),\n-        dim=1,\n-    )[0]\n-\n-    # WARN: only normalized numbers are handled\n-    f8_normal_min = 1 << in_dtype.fp_mantissa_width  # 0b00001000 for float8e4\n-    f8_normal_max = 0b01111110 if in_dtype == tl.float8e4 else 0b01111011\n-    f16_min, f16_max, f16_max_minus_1 = convert_float_to_float32(torch.tensor([f8_normal_min, f8_normal_max, f8_normal_max - 1], dtype=torch.int8), in_dtype)\n-    assert torch.all(torch.isfinite(f16_min))\n-    assert torch.all(torch.isfinite(f16_max))\n-    thres_error = f16_max - f16_max_minus_1\n-    mismatch = torch.logical_and(\n-        torch.logical_or(abs_error != min_error, abs_error > thres_error), torch.logical_and(torch.isfinite(f16_input), torch.logical_and(torch.abs(f16_input) <= f16_max, torch.abs(f16_input) >= f16_min))\n-    )\n-    assert torch.all(\n-        torch.logical_not(mismatch)\n-    ), f\"f16_input[mismatch]={f16_input[mismatch]} f16_output[mismatch]={f16_output[mismatch]} abs_error[mismatch]={abs_error[mismatch]} min_error[mismatch]={min_error[mismatch]}\"\n-\n+    # initialize array containing all possible f8 values except NaN\n+    ref_fp8 = np.array(range(-128, 128), dtype=np.int8)\n+    is_nan = (ref_fp8 & 0b01111100) == 128 - 2**in_dtype.fp_mantissa_width\n+    exp_mask = 0b01111111 ^ ((1 << in_dtype.fp_mantissa_width) - 1)\n+    is_subnormal = np.logical_or((ref_fp8 & exp_mask) == 0, (ref_fp8 & exp_mask) == exp_mask)\n+    ref_fp8[is_nan] = 0\n+    ref_fp8[is_subnormal] = 0\n+    tri_fp8 = torch.from_numpy(serialize_fp8(ref_fp8, in_dtype)).cuda()\n+    tri_fp16 = torch.empty(256, dtype=out_dtype, device=\"cuda\")\n+    with expectation as e:\n+        copy_kernel[(1,)](triton.reinterpret(tri_fp8, in_dtype), tri_fp16, tri_fp16.shape[0], BLOCK_SIZE=1024)\n+\n+        ref_fp8 = torch.from_numpy(ref_fp8).cuda()\n+        ref_fp16 = convert_float_to_float32(ref_fp8, in_dtype)\n+        assert torch.all(tri_fp16[~is_subnormal] == ref_fp16[~is_subnormal])\n+\n+        ref_fp8 = torch.empty_like(tri_fp16, dtype=torch.int8)\n+        copy_kernel[(1,)](tri_fp16, triton.reinterpret(ref_fp8, in_dtype), tri_fp16.shape[0], BLOCK_SIZE=1024)\n+        assert torch.all(tri_fp8 == ref_fp8)\n+\n+    if err_msg is not None:\n+        assert err_msg in str(e)\n \n # ---------------\n # test reduce"}, {"filename": "python/triton/compiler/code_generator.py", "status": "modified", "additions": 10, "deletions": 5, "changes": 15, "file_content_changes": "@@ -189,10 +189,11 @@ def visit_Call(self, node: ast.Call) -> bool:\n \n \n class CodeGenerator(ast.NodeVisitor):\n-    def __init__(self, context, prototype, gscope, attributes, constants, function_name,\n+    def __init__(self, context, prototype, gscope, attributes, constants, function_name, arch,\n                  module=None, is_kernel=False, function_types: Optional[Dict] = None,\n                  debug=False, noinline=False):\n         self.builder = ir.builder(context)\n+        self.builder.arch = arch\n         self.module = self.builder.create_module() if module is None else module\n         self.function_ret_types = {} if function_types is None else function_types\n         self.prototype = prototype\n@@ -868,7 +869,9 @@ def call_JitFunction(self, fn: JITFunction, args, kwargs):\n             gscope = sys.modules[fn.fn.__module__].__dict__\n             # If the callee is not set, we use the same debug setting as the caller\n             debug = self.debug if fn.debug is None else fn.debug\n-            generator = CodeGenerator(self.builder.context, prototype, gscope, attributes, constants, module=self.module, function_name=fn_name, function_types=self.function_ret_types, debug=debug, noinline=fn.noinline)\n+            generator = CodeGenerator(self.builder.context, prototype, gscope, attributes, constants, module=self.module,\n+                                      function_name=fn_name, function_types=self.function_ret_types, debug=debug, noinline=fn.noinline,\n+                                      arch=self.builder.arch)\n             generator.visit(fn.parse())\n             callee_ret_type = generator.last_ret_type\n             self.function_ret_types[fn_name] = callee_ret_type\n@@ -1016,8 +1019,9 @@ def str_to_ty(name):\n         ty = str_to_ty(name[1:])\n         return language.pointer_type(ty)\n     tys = {\n-        \"fp8e5\": language.float8e5,\n         \"fp8e4\": language.float8e4,\n+        \"fp8e5\": language.float8e5,\n+        \"fp8e4b15\": language.float8e4b15,\n         \"fp16\": language.float16,\n         \"bf16\": language.bfloat16,\n         \"fp32\": language.float32,\n@@ -1049,7 +1053,7 @@ def kernel_suffix(signature, specialization):\n     return suffix\n \n \n-def ast_to_ttir(fn, signature, specialization, constants, debug):\n+def ast_to_ttir(fn, signature, specialization, constants, debug, arch):\n     # canonicalize signature\n     if isinstance(signature, str):\n         signature = {k: v.strip() for k, v in enumerate(signature.split(\",\"))}\n@@ -1071,7 +1075,8 @@ def ast_to_ttir(fn, signature, specialization, constants, debug):\n     prototype = language.function_type([], arg_types)\n     generator = CodeGenerator(context, prototype, gscope=gscope, constants=all_constants,\n                               function_name=function_name, attributes=new_attrs,\n-                              is_kernel=True, debug=debug)\n+                              is_kernel=True, debug=debug,\n+                              arch=arch)\n     try:\n         generator.visit(fn.parse())\n     except CompilationError as e:"}, {"filename": "python/triton/compiler/compiler.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -396,7 +396,7 @@ def compile(fn, **kwargs):\n     stages = dict()\n     stages[\"ast\"] = (lambda path: fn, None)\n     stages[\"ttir\"] = (lambda path: parse_mlir_module(path, context),\n-                      lambda src: optimize_ttir(ast_to_ttir(src, signature, configs[0], constants, debug=debug), arch))\n+                      lambda src: optimize_ttir(ast_to_ttir(src, signature, configs[0], constants, debug=debug, arch=arch), arch))\n     stages[\"ttgir\"] = (lambda path: parse_mlir_module(path, context),\n                        lambda src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, arch))\n     stages[\"llir\"] = (lambda path: Path(path).read_text(),"}, {"filename": "python/triton/language/__init__.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -45,6 +45,7 @@\n     float16,\n     float32,\n     float64,\n+    float8e4b15,\n     float8e4,\n     float8e5,\n     function_type,\n@@ -137,6 +138,7 @@\n     \"float16\",\n     \"float32\",\n     \"float64\",\n+    \"float8e4b15\",\n     \"float8e4\",\n     \"float8e5\",\n     \"full\","}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 21, "deletions": 2, "changes": 23, "file_content_changes": "@@ -76,7 +76,7 @@ def _to_tensor(x, builder):\n class dtype:\n     SINT_TYPES = ['int8', 'int16', 'int32', 'int64']\n     UINT_TYPES = ['int1', 'uint8', 'uint16', 'uint32', 'uint64']\n-    FP_TYPES = ['fp8e4', 'fp8e5', 'fp16', 'bf16', 'fp32', 'fp64']\n+    FP_TYPES = ['fp8e4b15', 'fp8e4', 'fp8e5', 'fp16', 'bf16', 'fp32', 'fp64']\n     STANDARD_FP_TYPES = ['fp16', 'bf16', 'fp32', 'fp64']\n     OTHER_TYPES = ['void']\n \n@@ -96,24 +96,34 @@ def __init__(self, name):\n             self.int_bitwidth = int(name.split('int')[-1])\n             self.primitive_bitwidth = self.int_bitwidth\n         elif name in dtype.FP_TYPES:\n-            if name == 'fp8e4':\n+            if name == 'fp8e4b15':\n                 self.fp_mantissa_width = 3\n                 self.primitive_bitwidth = 8\n+                self.exponent_bias = 15\n+            elif name == 'fp8e4':\n+                self.fp_mantissa_width = 3\n+                self.primitive_bitwidth = 8\n+                self.exponent_bias = 7\n             elif name == 'fp8e5':\n                 self.fp_mantissa_width = 2\n                 self.primitive_bitwidth = 8\n+                self.exponent_bias = 15\n             elif name == 'fp16':\n                 self.fp_mantissa_width = 10\n                 self.primitive_bitwidth = 16\n+                self.exponent_bias = 15\n             elif name == 'bf16':\n                 self.fp_mantissa_width = 7\n                 self.primitive_bitwidth = 16\n+                self.exponent_bias = 127\n             elif name == 'fp32':\n                 self.fp_mantissa_width = 23\n                 self.primitive_bitwidth = 32\n+                self.exponent_bias = 127\n             elif name == 'fp64':\n                 self.fp_mantissa_width = 53\n                 self.primitive_bitwidth = 64\n+                self.exponent_bias = 1023\n             else:\n                 raise RuntimeError(f'Unsupported floating-point type {name}')\n         elif name == 'void':\n@@ -122,6 +132,12 @@ def __init__(self, name):\n     def is_fp8(self):\n         return 'fp8' in self.name\n \n+    def is_fp8e4(self):\n+        return self.name == 'fp8e4'\n+\n+    def is_fp8e4b15(self):\n+        return self.name == 'fp8e4b15'\n+\n     def is_fp16(self):\n         return self.name == 'fp16'\n \n@@ -223,6 +239,8 @@ def to_ir(self, builder: ir.builder) -> ir.type:\n             return builder.get_fp8e5_ty()\n         elif self.name == 'fp8e4':\n             return builder.get_fp8e4_ty()\n+        elif self.name == 'fp8e4b15':\n+            return builder.get_fp8e4b15_ty()\n         elif self.name == 'fp16':\n             return builder.get_half_ty()\n         elif self.name == 'bf16':\n@@ -356,6 +374,7 @@ def to_ir(self, builder: ir.builder):\n uint64 = dtype('uint64')\n float8e5 = dtype('fp8e5')\n float8e4 = dtype('fp8e4')\n+float8e4b15 = dtype('fp8e4b15')\n float16 = dtype('fp16')\n bfloat16 = dtype('bf16')\n float32 = dtype('fp32')"}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "file_content_changes": "@@ -1,5 +1,6 @@\n from __future__ import annotations  # remove after python 3.11\n \n+import warnings\n from functools import wraps\n from typing import List, Optional, Sequence, Tuple, TypeVar\n \n@@ -676,6 +677,16 @@ def cast(input: tl.tensor,\n     src_sca_ty = src_ty.scalar\n     dst_sca_ty = dst_ty.scalar\n \n+    if builder.arch < 89 and \\\n+       (src_sca_ty.is_fp8e4() or dst_sca_ty.is_fp8e4()):\n+        warnings.warn(\"Standard tl.float8e4 format will be deprecated on SM < 89. \"\n+                      \"Please use tl.float8e4b15.\", DeprecationWarning)\n+\n+    # Unsupported conversion:\n+    if (src_sca_ty.is_fp8e4b15() and not dst_sca_ty.is_fp16()) or \\\n+       (dst_sca_ty.is_fp8e4b15() and not src_sca_ty.is_fp16()):\n+        raise ValueError('fp8e4b15 can only be converted to/from fp16')\n+\n     # Casting with customized floating types involved: fp8 <=> bf16, fp16, fp32, fp64\n     if (src_sca_ty.is_fp8() and dst_sca_ty.is_floating()) or \\\n        (src_sca_ty.is_floating() and dst_sca_ty.is_fp8()):"}, {"filename": "python/triton/runtime/jit.py", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -208,8 +208,9 @@ def _type_of(key):\n         dtype_str = str(key).split(\".\")[-1]\n         tys = {\n             \"bool\": \"i1\",\n-            \"float8e5\": \"fp8e5\",\n             \"float8e4\": \"fp8e4\",\n+            \"float8e5\": \"fp8e5\",\n+            \"float8e4b15\": \"fp8e4b15\",\n             \"float16\": \"fp16\",\n             \"bfloat16\": \"bf16\",\n             \"float32\": \"fp32\","}]