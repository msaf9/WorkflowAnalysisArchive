[{"filename": "python/test/regression/test_performance.py", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "file_content_changes": "@@ -155,27 +155,27 @@ def test_elementwise(N, dtype_str):\n \n flash_attention_data = {\n     \"a100\": {\n-        (4, 48, 4096, 64, True, True, 'forward', 'float16'): 0.433,\n-        (4, 48, 4096, 64, True, True, 'forward', 'bfloat16'): 0.392,\n-        (4, 48, 1024, 16, True, True, 'forward', 'float32'): 0.106,\n+        (4, 48, 4096, 64, True, True, 'forward', 'float16'): 0.532,\n+        (4, 48, 4096, 64, True, True, 'forward', 'bfloat16'): 0.471,\n+        (4, 48, 1024, 16, True, True, 'forward', 'float32'): 0.150,\n         (4, 48, 4096, 64, True, True, 'backward', 'float16'): 0.204,\n         (4, 48, 4096, 64, True, True, 'backward', 'bfloat16'): 0.202,\n         (4, 48, 1024, 16, True, True, 'backward', 'float32'): 0.089,\n-        (4, 48, 4096, 64, True, False, 'forward', 'float16'): 0.242,\n-        (4, 48, 4096, 64, True, False, 'forward', 'bfloat16'): 0.220,\n-        (4, 48, 1024, 16, True, False, 'forward', 'float32'): 0.069,\n+        (4, 48, 4096, 64, True, False, 'forward', 'float16'): 0.298,\n+        (4, 48, 4096, 64, True, False, 'forward', 'bfloat16'): 0.263,\n+        (4, 48, 1024, 16, True, False, 'forward', 'float32'): 0.095,\n         (4, 48, 4096, 64, True, False, 'backward', 'float16'): 0.136,\n         (4, 48, 4096, 64, True, False, 'backward', 'bfloat16'): 0.135,\n         (4, 48, 1024, 16, True, False, 'backward', 'float32'): 0.052,\n-        (4, 48, 4096, 64, False, True, 'forward', 'float16'): 0.432,\n-        (4, 48, 4096, 64, False, True, 'forward', 'bfloat16'): 0.392,\n-        (4, 48, 1024, 16, False, True, 'forward', 'float32'): 0.107,\n+        (4, 48, 4096, 64, False, True, 'forward', 'float16'): 0.525,\n+        (4, 48, 4096, 64, False, True, 'forward', 'bfloat16'): 0.471,\n+        (4, 48, 1024, 16, False, True, 'forward', 'float32'): 0.150,\n         (4, 48, 4096, 64, False, True, 'backward', 'float16'): 0.265,\n         (4, 48, 4096, 64, False, True, 'backward', 'bfloat16'): 0.257,\n         (4, 48, 1024, 16, False, True, 'backward', 'float32'): 0.128,\n-        (4, 48, 4096, 64, False, False, 'forward', 'float16'): 0.251,\n-        (4, 48, 4096, 64, False, False, 'forward', 'bfloat16'): 0.220,\n-        (4, 48, 1024, 16, False, False, 'forward', 'float32'): 0.069,\n+        (4, 48, 4096, 64, False, False, 'forward', 'float16'): 0.297,\n+        (4, 48, 4096, 64, False, False, 'forward', 'bfloat16'): 0.263,\n+        (4, 48, 1024, 16, False, False, 'forward', 'float32'): 0.095,\n         (4, 48, 4096, 64, False, False, 'backward', 'float16'): 0.159,\n         (4, 48, 4096, 64, False, False, 'backward', 'bfloat16'): 0.138,\n         (4, 48, 1024, 16, False, False, 'backward', 'float32'): 0.076,"}, {"filename": "python/triton/ops/flash_attention.py", "status": "modified", "additions": 69, "deletions": 112, "changes": 181, "file_content_changes": "@@ -17,7 +17,7 @@\n @jit\n def _fwd_kernel(\n     Q, K, V, sm_scale,\n-    L, M,\n+    L,\n     Out,\n     stride_qz, stride_qh, stride_qm, stride_qk,\n     stride_kz, stride_kh, stride_kn, stride_kk,\n@@ -26,7 +26,7 @@ def _fwd_kernel(\n     Z, H, N_CTX,\n     BLOCK_M: tl.constexpr, BLOCK_DMODEL: tl.constexpr,\n     BLOCK_N: tl.constexpr,\n-    MODE: tl.constexpr,\n+    IS_CAUSAL: tl.constexpr,\n ):\n     start_m = tl.program_id(0)\n     off_hz = tl.program_id(1)\n@@ -55,37 +55,13 @@ def _fwd_kernel(\n         block_shape=(BLOCK_N, BLOCK_DMODEL),\n         order=(1, 0)\n     )\n-    O_block_ptr = tl.make_block_ptr(\n-        base=Out + qvk_offset,\n-        shape=(N_CTX, BLOCK_DMODEL),\n-        strides=(stride_om, stride_on),\n-        offsets=(start_m * BLOCK_M, 0),\n-        block_shape=(BLOCK_M, BLOCK_DMODEL),\n-        order=(1, 0)\n-    )\n     # initialize offsets\n     offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M)\n     offs_n = tl.arange(0, BLOCK_N)\n     # initialize pointer to m and l\n     m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\n     l_i = tl.zeros([BLOCK_M], dtype=tl.float32)\n     acc = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32)\n-    # causal check on every loop iteration can be expensive\n-    # and peeling the last iteration of the loop does not work well with ptxas\n-    # so we have a mode to do the causal check in a separate kernel entirely\n-    if MODE == 0:  # entire non-causal attention\n-        lo, hi = 0, N_CTX\n-    if MODE == 1:  # entire causal attention\n-        lo, hi = 0, (start_m + 1) * BLOCK_M\n-    if MODE == 2:  # off band-diagonal\n-        lo, hi = 0, start_m * BLOCK_M\n-    if MODE == 3:  # on band-diagonal\n-        l_ptrs = L + off_hz * N_CTX + offs_m\n-        m_ptrs = M + off_hz * N_CTX + offs_m\n-        m_i = tl.load(m_ptrs)\n-        l_i = tl.load(l_ptrs)\n-        acc += tl.load(O_block_ptr).to(tl.float32)\n-        lo, hi = start_m * BLOCK_M, (start_m + 1) * BLOCK_M\n     # credits to: Adam P. Goucher (https://github.com/apgoucher):\n     # scale sm_scale by 1/log_2(e) and use\n     # 2^x instead of exp in the loop because CSE and LICM\n@@ -94,70 +70,61 @@ def _fwd_kernel(\n     # load q: it will stay in SRAM throughout\n     q = tl.load(Q_block_ptr)\n     q = (q * qk_scale).to(K.dtype.element_ty)\n-    # advance block pointers to first iteration of the loop\n-    K_block_ptr = tl.advance(K_block_ptr, (0, lo))\n-    V_block_ptr = tl.advance(V_block_ptr, (lo, 0))\n-    # loop over k, v and update accumulator\n+    lo = 0\n+    hi = (start_m + 1) * BLOCK_M if IS_CAUSAL else N_CTX\n     for start_n in range(lo, hi, BLOCK_N):\n-        start_n = tl.multiple_of(start_n, BLOCK_N)\n-        # -- compute qk ----\n+        # -- load k, v --\n         k = tl.load(K_block_ptr)\n+        v = tl.load(V_block_ptr)\n+        # -- compute qk ---\n         qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n-        qk += tl.dot(q, k, allow_tf32=True)\n-        if MODE == 1 or MODE == 3:\n+        if IS_CAUSAL:\n             qk = tl.where(offs_m[:, None] >= (start_n + offs_n[None, :]), qk, float(\"-inf\"))\n-        # -- compute m_ij, p, l_ij\n-        m_ij = tl.max(qk, 1)\n-        p = tl.math.exp2(qk - m_ij[:, None])\n-        l_ij = tl.sum(p, 1)\n-        # -- update m_i and l_i\n-        m_i_new = tl.maximum(m_i, m_ij)\n+        qk += tl.dot(q, k, allow_tf32=True)\n+        # -- compute scaling constant ---\n+        m_i_new = tl.maximum(m_i, tl.max(qk, 1))\n         alpha = tl.math.exp2(m_i - m_i_new)\n-        beta = tl.math.exp2(m_ij - m_i_new)\n-        l_i *= alpha\n-        l_i_new = l_i + beta * l_ij\n-        # scale p\n-        p_scale = beta / l_i_new\n-        p = p * p_scale[:, None]\n-        # scale acc\n-        acc_scale = l_i / l_i_new\n-        acc = acc * acc_scale[:, None]\n-        # update acc\n-        v = tl.load(V_block_ptr)\n-        p = p.to(V.dtype.element_ty)\n-        acc += tl.dot(p, v, allow_tf32=True)\n-        # update m_i and l_i\n-        l_i = l_i_new\n+        p = tl.math.exp2(qk - m_i_new[:, None])\n+        # -- scale and update acc --\n+        acc_scale = l_i * 0 + alpha  # workaround some compiler bug\n+        acc *= acc_scale[:, None]\n+        acc += tl.dot(p.to(V.dtype.element_ty), v, allow_tf32=True)\n+        # -- update m_i and l_i --\n+        l_i = l_i * alpha + tl.sum(p, 1)\n         m_i = m_i_new\n         # update pointers\n         K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_N))\n         V_block_ptr = tl.advance(V_block_ptr, (BLOCK_N, 0))\n     # write back l and m\n+    acc = acc / l_i[:, None]\n     l_ptrs = L + off_hz * N_CTX + offs_m\n-    m_ptrs = M + off_hz * N_CTX + offs_m\n-    tl.store(l_ptrs, l_i)\n-    tl.store(m_ptrs, m_i)\n+    tl.store(l_ptrs, m_i + tl.math.log2(l_i))\n     # write back O\n+    O_block_ptr = tl.make_block_ptr(\n+        base=Out + qvk_offset,\n+        shape=(N_CTX, BLOCK_DMODEL),\n+        strides=(stride_om, stride_on),\n+        offsets=(start_m * BLOCK_M, 0),\n+        block_shape=(BLOCK_M, BLOCK_DMODEL),\n+        order=(1, 0)\n+    )\n     tl.store(O_block_ptr, acc.to(K.dtype.element_ty))\n \n \n @jit\n def _bwd_preprocess(\n-    Out, DO, L,\n-    NewDO, Delta,\n+    Out, DO,\n+    Delta,\n     BLOCK_M: tl.constexpr, D_HEAD: tl.constexpr,\n ):\n     off_m = tl.program_id(0) * BLOCK_M + tl.arange(0, BLOCK_M)\n     off_n = tl.arange(0, D_HEAD)\n     # load\n     o = tl.load(Out + off_m[:, None] * D_HEAD + off_n[None, :]).to(tl.float32)\n     do = tl.load(DO + off_m[:, None] * D_HEAD + off_n[None, :]).to(tl.float32)\n-    denom = tl.load(L + off_m).to(tl.float32)\n     # compute\n-    do = do / denom[:, None]\n     delta = tl.sum(o * do, axis=1)\n     # write-back\n-    tl.store(NewDO + off_m[:, None] * D_HEAD + off_n[None, :], do)\n     tl.store(Delta + off_m, delta)\n \n \n@@ -166,7 +133,7 @@ def _bwd_kernel_one_col_block(\n     Q, K, V, sm_scale, qk_scale,\n     Out, DO,\n     DQ, DK, DV,\n-    L, M,\n+    L,\n     D,\n     stride_dqa, stride_qz, stride_qh, stride_qm, stride_qk,\n     stride_kz, stride_kh, stride_kn, stride_kk,\n@@ -176,14 +143,14 @@ def _bwd_kernel_one_col_block(\n     BLOCK_M: tl.constexpr, BLOCK_DMODEL: tl.constexpr,\n     BLOCK_N: tl.constexpr,\n     SEQUENCE_PARALLEL: tl.constexpr,\n-    MODE: tl.constexpr,\n+    CAUSAL: tl.constexpr,\n ):\n     if SEQUENCE_PARALLEL:\n         DQ += stride_dqa.to(tl.int64) * start_n\n-    if MODE == 0:\n-        lo = 0\n-    else:\n+    if CAUSAL:\n         lo = start_n * BLOCK_M\n+    else:\n+        lo = 0\n     # initialize row/col offsets\n     offs_qm = lo + tl.arange(0, BLOCK_M)\n     offs_n = start_n * BLOCK_M + tl.arange(0, BLOCK_M)\n@@ -197,7 +164,7 @@ def _bwd_kernel_one_col_block(\n     dq_ptrs = DQ + (offs_qm[:, None] * stride_qm + offs_k[None, :] * stride_qk)\n     # pointer to row-wise quantities in value-like data\n     D_ptrs = D + off_hz * N_CTX\n-    m_ptrs = M + off_hz * N_CTX\n+    l_ptrs = L + off_hz * N_CTX\n     # initialize dv amd dk\n     dv = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32)\n     dk = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32)\n@@ -211,14 +178,14 @@ def _bwd_kernel_one_col_block(\n         q = tl.load(q_ptrs)\n         # recompute p = softmax(qk, dim=-1).T\n         # NOTE: `do` is pre-divided by `l`; no normalization here\n-        if MODE == 1:\n+        if CAUSAL:\n             qk = tl.where(offs_m_curr[:, None] >= (offs_n[None, :]), float(0.), float(\"-inf\"))\n         else:\n             qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n         qk += tl.dot(q, tl.trans(k))\n         qk *= qk_scale\n-        m = tl.load(m_ptrs + offs_m_curr)\n-        p = tl.math.exp2(qk - m[:, None])\n+        l_i = tl.load(l_ptrs + offs_m_curr)\n+        p = tl.math.exp2(qk - l_i[:, None])\n         # compute dv\n         do = tl.load(do_ptrs)\n         dv += tl.dot(tl.trans(p.to(Q.dtype.element_ty)), do, allow_tf32=True)\n@@ -257,7 +224,7 @@ def _bwd_kernel(\n     Q, K, V, sm_scale,\n     Out, DO,\n     DQ, DK, DV,\n-    L, M,\n+    L,\n     D,\n     stride_dqa, stride_qz, stride_qh, stride_qm, stride_qk,\n     stride_kz, stride_kh, stride_kn, stride_kk,\n@@ -266,7 +233,7 @@ def _bwd_kernel(\n     BLOCK_M: tl.constexpr, BLOCK_DMODEL: tl.constexpr,\n     BLOCK_N: tl.constexpr,\n     SEQUENCE_PARALLEL: tl.constexpr,\n-    MODE: tl.constexpr,\n+    CAUSAL: tl.constexpr,\n     # fmt: on\n ):\n     qk_scale = sm_scale * 1.44269504\n@@ -288,7 +255,7 @@ def _bwd_kernel(\n             _bwd_kernel_one_col_block(\n                 Q, K, V, sm_scale, qk_scale, Out, DO,\n                 DQ, DK, DV,\n-                L, M,\n+                L,\n                 D,\n                 stride_dqa, stride_qz, stride_qh, stride_qm, stride_qk,\n                 stride_kz, stride_kh, stride_kn, stride_kk,\n@@ -298,14 +265,14 @@ def _bwd_kernel(\n                 BLOCK_M=BLOCK_M, BLOCK_DMODEL=BLOCK_DMODEL,\n                 BLOCK_N=BLOCK_N,\n                 SEQUENCE_PARALLEL=SEQUENCE_PARALLEL,\n-                MODE=MODE,\n+                CAUSAL=CAUSAL,\n             )\n     else:\n         start_n = tl.program_id(1)\n         _bwd_kernel_one_col_block(\n             Q, K, V, sm_scale, qk_scale, Out, DO,\n             DQ, DK, DV,\n-            L, M,\n+            L,\n             D,\n             stride_dqa, stride_qz, stride_qh, stride_qm, stride_qk,\n             stride_kz, stride_kh, stride_kn, stride_kk,\n@@ -315,7 +282,7 @@ def _bwd_kernel(\n             BLOCK_M=BLOCK_M, BLOCK_DMODEL=BLOCK_DMODEL,\n             BLOCK_N=BLOCK_N,\n             SEQUENCE_PARALLEL=SEQUENCE_PARALLEL,\n-            MODE=MODE,\n+            CAUSAL=CAUSAL,\n         )\n \n \n@@ -327,36 +294,31 @@ def forward(ctx, q, k, v, causal, sm_scale, sequence_parallel=False):\n         capability = torch.cuda.get_device_capability()\n         if capability[0] < 8:\n             raise RuntimeError(\"Flash attention currently only supported for compute capability >= 80\")\n-        BLOCK = 128\n+        BLOCK_M = 128\n+        BLOCK_N = 64\n         # shape constraints\n         Lq, Lk, Lv = q.shape[-1], k.shape[-1], v.shape[-1]\n         assert Lq == Lk and Lk == Lv\n         assert Lk in {16, 32, 64, 128}\n         o = torch.empty_like(q)\n-        grid = (cdiv(q.shape[2], BLOCK), q.shape[0] * q.shape[1], 1)\n+        grid = (cdiv(q.shape[2], BLOCK_M), q.shape[0] * q.shape[1], 1)\n         L = torch.empty((q.shape[0] * q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32)\n-        m = torch.empty((q.shape[0] * q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32)\n         num_warps = 4 if Lk <= 64 else 8\n-        if causal:\n-            modes = [1] if q.shape[2] <= 2048 else [2, 3]\n-        else:\n-            modes = [0]\n-        for mode in modes:\n-            _fwd_kernel[grid](\n-                q, k, v, sm_scale,\n-                L, m,\n-                o,\n-                q.stride(0), q.stride(1), q.stride(2), q.stride(3),\n-                k.stride(0), k.stride(1), k.stride(2), k.stride(3),\n-                v.stride(0), v.stride(1), v.stride(2), v.stride(3),\n-                o.stride(0), o.stride(1), o.stride(2), o.stride(3),\n-                q.shape[0], q.shape[1], q.shape[2],\n-                BLOCK_M=128, BLOCK_N=BLOCK, BLOCK_DMODEL=Lk,\n-                MODE=mode,\n-                num_warps=num_warps,\n-                num_stages=2)\n+        _fwd_kernel[grid](\n+            q, k, v, sm_scale,\n+            L,\n+            o,\n+            q.stride(0), q.stride(1), q.stride(2), q.stride(3),\n+            k.stride(0), k.stride(1), k.stride(2), k.stride(3),\n+            v.stride(0), v.stride(1), v.stride(2), v.stride(3),\n+            o.stride(0), o.stride(1), o.stride(2), o.stride(3),\n+            q.shape[0], q.shape[1], q.shape[2],\n+            BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_DMODEL=Lk,\n+            IS_CAUSAL=causal,\n+            num_warps=num_warps,\n+            num_stages=4)\n \n-        ctx.save_for_backward(q, k, v, o, L, m)\n+        ctx.save_for_backward(q, k, v, o, L)\n         ctx.grid = grid\n         ctx.sm_scale = sm_scale\n         ctx.BLOCK_DMODEL = Lk\n@@ -367,7 +329,7 @@ def forward(ctx, q, k, v, causal, sm_scale, sequence_parallel=False):\n     @staticmethod\n     def backward(ctx, do):\n         BLOCK = 128\n-        q, k, v, o, l, m = ctx.saved_tensors\n+        q, k, v, o, L = ctx.saved_tensors\n         sequence_parallel = ctx.sequence_parallel\n         seq_len_kv = k.shape[2]\n         do = do.contiguous()\n@@ -379,22 +341,17 @@ def backward(ctx, do):\n             dq = torch.zeros_like(q, dtype=torch.float32)\n         dk = torch.empty_like(k)\n         dv = torch.empty_like(v)\n-        do_scaled = torch.empty_like(do)\n-        delta = torch.empty_like(l)\n-        if ctx.causal:\n-            mode = 1\n-        else:\n-            mode = 0\n+        delta = torch.empty_like(L)\n         _bwd_preprocess[(ctx.grid[0] * ctx.grid[1], )](\n-            o, do, l,\n-            do_scaled, delta,\n+            o, do,\n+            delta,\n             BLOCK_M=BLOCK, D_HEAD=ctx.BLOCK_DMODEL,\n         )\n         _bwd_kernel[(ctx.grid[1], cdiv(seq_len_kv, BLOCK) if sequence_parallel else 1)](\n             q, k, v, ctx.sm_scale,\n-            o, do_scaled,\n+            o, do,\n             dq, dk, dv,\n-            l, m,\n+            L,\n             delta,\n             o.numel(), q.stride(0), q.stride(1), q.stride(2), q.stride(3),\n             k.stride(0), k.stride(1), k.stride(2), k.stride(3),\n@@ -403,7 +360,7 @@ def backward(ctx, do):\n             BLOCK_M=BLOCK, BLOCK_N=BLOCK,\n             BLOCK_DMODEL=ctx.BLOCK_DMODEL,\n             SEQUENCE_PARALLEL=sequence_parallel,\n-            MODE=mode,\n+            CAUSAL=ctx.causal,\n             num_warps=8,\n             num_stages=1,\n         )"}, {"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "file_content_changes": "@@ -123,7 +123,7 @@ def _fwd_kernel(\n @triton.jit\n def _bwd_preprocess(\n     Out, DO,\n-    NewDO, Delta,\n+    Delta,\n     BLOCK_M: tl.constexpr, D_HEAD: tl.constexpr,\n ):\n     off_m = tl.program_id(0) * BLOCK_M + tl.arange(0, BLOCK_M)\n@@ -134,7 +134,6 @@ def _bwd_preprocess(\n     # compute\n     delta = tl.sum(o * do, axis=1)\n     # write-back\n-    tl.store(NewDO + off_m[:, None] * D_HEAD + off_n[None, :], do)\n     tl.store(Delta + off_m, delta)\n \n \n@@ -277,16 +276,15 @@ def backward(ctx, do):\n         dq = torch.zeros_like(q, dtype=torch.float32)\n         dk = torch.empty_like(k)\n         dv = torch.empty_like(v)\n-        do_scaled = torch.empty_like(do)\n         delta = torch.empty_like(L)\n         _bwd_preprocess[(ctx.grid[0] * ctx.grid[1], )](\n             o, do,\n-            do_scaled, delta,\n+            delta,\n             BLOCK_M=BLOCK, D_HEAD=ctx.BLOCK_DMODEL,\n         )\n         _bwd_kernel[(ctx.grid[1],)](\n             q, k, v, ctx.sm_scale,\n-            o, do_scaled,\n+            o, do,\n             dq, dk, dv,\n             L, delta,\n             q.stride(0), q.stride(1), q.stride(2), q.stride(3),"}]