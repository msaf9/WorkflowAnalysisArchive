[{"filename": "lib/codegen/analysis/align.cc", "status": "modified", "additions": 22, "deletions": 11, "changes": 33, "file_content_changes": "@@ -142,14 +142,17 @@ std::vector<align::cst_info> align::populate_is_constant_cmp(ir::cmp_inst* x) {\n   auto rhs_multiple_of = populate_starting_multiple(rhs_op);\n   for(size_t d = 0; d < x_shapes.size(); d++) {\n     cst_info ax = {1, 0};\n-    // if lhs (resp. rhs) is a range of M value starting at a multiple of N\n-    // and rhs (resp. lhs) is made of M constants that are multiples of N\n-    // then comparisons have M constants\n-    int min_multiple = std::min(lhs_multiple_of[d], rhs_multiple_of[d]);\n-    if(rhs[d].num_cst % lhs_max_contiguous[d] == 0)\n-      ax = {std::min<int>(min_multiple, lhs_max_contiguous[d]), 0};\n-    else if(lhs[d].num_cst % rhs_max_contiguous[d] == 0)\n-      ax = {std::min<int>(min_multiple, rhs_max_contiguous[d]), 0};\n+    // Examples:\n+    //   16 17 18 ... 32   <  24 24 24 ... 24 => equal in groups of 8\n+    //   16 17 18 ... 32   <  20 20 20 ... 20 => equal in groups of 4\n+    //   16 17 18 ... 32   <  16 16 16 ... 16 => equal in groups of 16\n+    //   \n+    //   if LHS is a range of N continuous (or equal) elements that starts at M,\n+    //   and RHS is a set of N constants that start at K\n+    //   then the result in constant in groups of gcd(M, K)\n+    if(rhs[d].num_cst % lhs_max_contiguous[d] == 0 ||\n+       rhs[d].num_cst % lhs[d].num_cst == 0)\n+      ax.num_cst = gcd(lhs_multiple_of[d], rhs_multiple_of[d]);\n     result.push_back(ax);\n   }\n   return add_to_cache(x, result, is_constant_);\n@@ -170,7 +173,6 @@ std::vector<align::cst_info> align::populate_is_constant_binop(ir::binary_operat\n   for(size_t d = 0; d < x_shapes.size(); d++) {\n     cst_info ax;\n     if(lhs[d].num_cst==0 && rhs[d].value && x->is_int_div()){\n-      // todo might not be entirely true\n       unsigned num_constants = gcd(lhs_max_contiguous[d], rhs[d].value);\n       ax = {num_constants, 0};\n     }\n@@ -433,7 +435,7 @@ std::vector<unsigned> align::populate_starting_multiple_binop(ir::binary_operato\n     if(x->is_int_add_sub())\n       result[d] = gcd(lhs[d], rhs[d]);\n     if(x->is_int_div())\n-      result[d] = 1;\n+      result[d] = (lhs[d] == (1 << 31)) ? 1 << 31 : 1;\n     if(x->is_int_rem() && rhs[d] > 1){\n       result[d] = gcd(lhs[d], rhs[d]);\n     }\n@@ -503,6 +505,15 @@ std::vector<unsigned> align::populate_starting_multiple_default(ir::value* v) {\n   return add_to_cache(v, {1}, starting_multiple_);\n }\n \n+unsigned get_max_multiple(int val){\n+  if(val == 0) return 1 << 31;\n+  if(val % 16 == 0) return 16;\n+  if(val % 8 == 0) return 8;\n+  if(val % 4 == 0) return 4;\n+  if(val % 2 == 0) return 2;\n+  return 1;\n+}\n+\n std::vector<unsigned> align::populate_starting_multiple(ir::value *v){\n   if(starting_multiple_.find(v) != starting_multiple_.end())\n     return starting_multiple_.at(v);\n@@ -518,7 +529,7 @@ std::vector<unsigned> align::populate_starting_multiple(ir::value *v){\n   if(auto *x = dynamic_cast<ir::constant_int*>(v))\n     return add_to_cache(x, {std::min<unsigned>(x->get_value(), 128)}, starting_multiple_);\n   if(auto *x = dynamic_cast<ir::make_range*>(v))\n-    return add_to_cache(x, {(unsigned)x->get_first()->get_value()}, starting_multiple_);\n+    return add_to_cache(x, {get_max_multiple(x->get_first()->get_value())}, starting_multiple_);\n   if(auto *x = dynamic_cast<ir::getelementptr_inst*>(v))\n     return populate_starting_multiple_gep(x);\n   if(auto *x = dynamic_cast<ir::splat_inst*>(v))"}, {"filename": "lib/codegen/selection/generator.cc", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -785,6 +785,7 @@ void generator::visit_load_inst(ir::load_inst* x){\n     int width = std::min(tot_width, max_word_width);\n     int n_words = std::max(1, tot_width / width);\n     bool has_evict_policy = (x->get_eviction_policy() != ir::load_inst::NORMAL) && tgt_->as_nvidia()->sm() >= 80;\n+    has_evict_policy = false; // currently disable until supported in `store`\n     // -----\n     // create inline asm string\n     // -----"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -937,13 +937,15 @@ def _kernel(dst, src, CACHE: tl.constexpr):\n         assert 'ld.global.ca' in ptx\n         assert 'ld.global.cg' not in ptx\n \n+\n @pytest.mark.parametrize(\"N\", [8, 10, 11, 1024])\n def test_vectorization(N):\n     src = torch.empty(1024, device='cuda')\n     dst = torch.empty(1024, device='cuda')\n+\n     @triton.jit\n     def _kernel(dst, src, N, BLOCK_SIZE: tl.constexpr):\n-        offsets = tl.program_id(0)*BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n+        offsets = tl.program_id(0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n         x = tl.load(src + offsets, mask=offsets < N)\n         tl.store(dst + offsets, x, mask=offsets < N)\n     pgm = _kernel[(1,)](dst, src, N=N, BLOCK_SIZE=src.shape[0])"}, {"filename": "python/triton/code_gen.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -942,9 +942,9 @@ def __call__(self, *wargs, grid, num_warps=4, num_stages=2, **kwargs):\n             assert _type == triton.language.constexpr, \"only constexpr annotations are supported for now\"\n             wargs[pos] = _type(wargs[pos])\n         # check that tensors are on GPU.\n-        for arg in wargs:\n-            if hasattr(arg, 'data_ptr'):\n-                assert arg.is_cuda, \"All tensors must be on GPU!\"\n+        # for arg in wargs:\n+        #     if hasattr(arg, 'data_ptr'):\n+        #         assert arg.is_cuda, \"All tensors must be on GPU!\"\n         # set device (i.e., make sure torch has the context initialized)\n         device = torch.cuda.current_device()\n         torch.cuda.set_device(device)"}]