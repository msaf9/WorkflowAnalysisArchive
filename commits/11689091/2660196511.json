[{"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -1,6 +1,7 @@\n \"\"\"\n Fused Attention\n ===============\n+This is a Triton implementation of the Flash Attention algorithm (Dao et al., https://arxiv.org/pdf/2205.14135v2.pdf)\n \"\"\"\n \n import pytest"}]