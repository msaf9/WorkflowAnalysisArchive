[{"filename": "python/test/unit/language/test_annotations.py", "status": "added", "additions": 21, "deletions": 0, "changes": 21, "file_content_changes": "@@ -0,0 +1,21 @@\n+\n+from __future__ import annotations\n+\n+import torch\n+\n+import triton\n+import triton.language as tl\n+\n+\n+def test_annotations():\n+\n+    @triton.jit\n+    def _kernel(X: torch.Tensor, N: int, BLOCK_SIZE: tl.constexpr):\n+        pass\n+\n+    x = torch.empty(1, device='cuda')\n+    _kernel[(1,)](x, x.shape[0], 32)\n+    try:\n+        _kernel[(1,)](x.shape[0], x.shape[0], 32)\n+    except AttributeError:\n+        pass"}, {"filename": "python/test/unit/runtime/test_autotuner.py", "status": "added", "additions": 22, "deletions": 0, "changes": 22, "file_content_changes": "@@ -0,0 +1,22 @@\n+import torch\n+\n+import triton\n+import triton.language as tl\n+\n+\n+def test_kwargs():\n+    N = 1024\n+    src = torch.empty(N, device='cuda')\n+    dst = torch.empty(N, device='cuda')\n+\n+    configs = [triton.Config(kwargs={'BLOCK_SIZE': 32}), triton.Config(kwargs={'BLOCK_SIZE': 128})]\n+\n+    @triton.autotune(configs=configs, key=['N'])\n+    @triton.jit\n+    def _kernel(dst, src, N, BLOCK_SIZE: tl.constexpr):\n+        offsets = tl.program_id(0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n+        x = tl.load(src + offsets, mask=offsets < N)\n+        tl.store(dst + offsets, x, mask=offsets < N)\n+    grid = lambda META: (triton.cdiv(N, META['BLOCK_SIZE']),)\n+    _kernel[grid](dst, src, N)\n+    _kernel[grid](dst=dst, src=src, N=N)"}]