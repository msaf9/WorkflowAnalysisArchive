[{"filename": "master/.buildinfo", "status": "removed", "additions": 0, "deletions": 4, "changes": 4, "file_content_changes": "@@ -1,4 +0,0 @@\n-# Sphinx build info version 1\n-# This file hashes the configuration used when building these files. When it is not found, a full rebuild will be done.\n-config: e596642ff1cf86c1376bbeb43852c411\n-tags: 645f666f9bcd5a90fca523b33c5a78b7"}, {"filename": "master/.doctrees/environment.pickle", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/installation.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/tutorials/01-vector-add.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/tutorials/02-fused-softmax.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/tutorials/03-matrix-multiplication.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/tutorials/04-low-memory-dropout.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/tutorials/05-layer-norm.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/tutorials/index.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/getting-started/tutorials/sg_execution_times.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/index.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/programming-guide/chapter-1/introduction.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/programming-guide/chapter-2/related-work.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.Config.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.autotune.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.heuristics.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.jit.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.arange.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.atomic_add.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.atomic_cas.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.atomic_max.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.atomic_min.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.atomic_xchg.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.broadcast_to.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.cos.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.dot.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.exp.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.load.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.log.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.max.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.maximum.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.min.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.minimum.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.multiple_of.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.num_programs.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.program_id.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.rand.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.randint.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.randint4x.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.randn.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.ravel.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.reshape.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.sigmoid.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.sin.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.softmax.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.sqrt.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.store.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.sum.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.where.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.language.zeros.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.testing.Benchmark.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.testing.do_bench.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/generated/triton.testing.perf_report.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/triton.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/triton.language.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/.doctrees/python-api/triton.testing.doctree", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_downloads/034d953b6214fedce6ea03803c712b89/02-fused-softmax.ipynb", "status": "removed", "additions": 0, "deletions": 161, "changes": 161, "file_content_changes": "@@ -1,161 +0,0 @@\n-{\n-  \"cells\": [\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"%matplotlib inline\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"\\n# Fused Softmax\\nIn this tutorial, you will write a fused softmax operation that is significantly faster\\nthan PyTorch's native op for a particular class of matrices: those whose rows can fit in\\nthe GPU's SRAM.\\nYou will learn about:\\n\\n- The benefits of kernel fusion for bandwidth-bound operations.\\n- Reduction operators in Triton.\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Motivations\\nCustom GPU kernels for elementwise additions are educationally valuable but won't get you very far in practice.\\nLet us consider instead the case of a simple (numerically stabilized) softmax operation:\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"import torch\\n\\nimport triton\\nimport triton.language as tl\\n\\n\\n@torch.jit.script\\ndef naive_softmax(x):\\n    \\\"\\\"\\\"Compute row-wise softmax of X using native pytorch\\n\\n    We subtract the maximum element in order to avoid overflows. Softmax is invariant to\\n    this shift.\\n    \\\"\\\"\\\"\\n    # read  MN elements ; write M  elements\\n    x_max = x.max(dim=1)[0]\\n    # read MN + M elements ; write MN elements\\n    z = x - x_max[:, None]\\n    # read  MN elements ; write MN elements\\n    numerator = torch.exp(z)\\n    # read  MN elements ; write M  elements\\n    denominator = numerator.sum(dim=1)\\n    # read MN + M elements ; write MN elements\\n    ret = numerator / denominator[:, None]\\n    # in total: read 5MN + 2M elements ; wrote 3MN + 2M elements\\n    return ret\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"When implemented naively in PyTorch, computing :code:`y = naive_softmax(x)` for $x \\\\in R^{M \\\\times N}$\\nrequires reading $5MN + 2M$ elements from DRAM and writing back $3MN + 2M$ elements.\\nThis is obviously wasteful; we'd prefer to have a custom \\\"fused\\\" kernel that only reads\\nX once and does all the necessary computations on-chip.\\nDoing so would require reading and writing back only $MN$ bytes, so we could\\nexpect a theoretical speed-up of ~4x (i.e., $(8MN + 4M) / 2MN$).\\nThe `torch.jit.script` flags aims to perform this kind of \\\"kernel fusion\\\" automatically\\nbut, as we will see later, it is still far from ideal.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Compute Kernel\\nOur softmax kernel works as follows: each program loads a row of the input matrix X,\\nnormalizes it and writes back the result to the output Y.\\nNote that one important limitation of Triton is that each block must have a\\npower-of-two number of elements, so we need to internally \\\"pad\\\" each row and guard the\\nmemory operations properly if we want to handle any possible input shapes:\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"@triton.jit\\ndef softmax_kernel(\\n    output_ptr, input_ptr, input_row_stride, output_row_stride, n_cols,\\n    BLOCK_SIZE: tl.constexpr\\n):\\n    # The rows of the softmax are independent, so we parallelize across those\\n    row_idx = tl.program_id(0)\\n    # The stride represents how much we need to increase the pointer to advance 1 row\\n    row_start_ptr = input_ptr + row_idx * input_row_stride\\n    # The block size is the next power of two greater than n_cols, so we can fit each\\n    # row in a single block\\n    col_offsets = tl.arange(0, BLOCK_SIZE)\\n    input_ptrs = row_start_ptr + col_offsets\\n    # Load the row into SRAM, using a mask since BLOCK_SIZE may be > than n_cols\\n    row = tl.load(input_ptrs, mask=col_offsets < n_cols, other=-float('inf'))\\n    # Substract maximum for numerical stability\\n    row_minus_max = row - tl.max(row, axis=0)\\n    # Note that exponentials in Triton are fast but approximate (i.e., think __expf in CUDA)\\n    numerator = tl.exp(row_minus_max)\\n    denominator = tl.sum(numerator, axis=0)\\n    softmax_output = numerator / denominator\\n    # Write back output to DRAM\\n    output_row_start_ptr = output_ptr + row_idx * output_row_stride\\n    output_ptrs = output_row_start_ptr + col_offsets\\n    tl.store(output_ptrs, softmax_output, mask=col_offsets < n_cols)\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"We can create a helper function that enqueues the kernel and its (meta-)arguments for any given input tensor.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"def softmax(x):\\n    n_rows, n_cols = x.shape\\n    # The block size is the smallest power of two greater than the number of columns in `x`\\n    BLOCK_SIZE = triton.next_power_of_2(n_cols)\\n    # Another trick we can use is to ask the compiler to use more threads per row by\\n    # increasing the number of warps (`num_warps`) over which each row is distributed.\\n    # You will see in the next tutorial how to auto-tune this value in a more natural\\n    # way so you don't have to come up with manual heuristics yourself.\\n    num_warps = 4\\n    if BLOCK_SIZE >= 2048:\\n        num_warps = 8\\n    if BLOCK_SIZE >= 4096:\\n        num_warps = 16\\n    # Allocate output\\n    y = torch.empty_like(x)\\n    # Enqueue kernel. The 1D launch grid is simple: we have one kernel instance per row o\\n    # f the input matrix\\n    softmax_kernel[(n_rows,)](\\n        y,\\n        x,\\n        x.stride(0),\\n        y.stride(0),\\n        n_cols,\\n        num_warps=num_warps,\\n        BLOCK_SIZE=BLOCK_SIZE,\\n    )\\n    return y\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Unit Test\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"We make sure that we test our kernel on a matrix with an irregular number of rows and columns.\\nThis will allow us to verify that our padding mechanism works.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"torch.manual_seed(0)\\nx = torch.randn(1823, 781, device='cuda')\\ny_triton = softmax(x)\\ny_torch = torch.softmax(x, axis=1)\\nassert torch.allclose(y_triton, y_torch), (y_triton, y_torch)\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"As expected, the results are identical.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Benchmark\\nHere we will benchmark our operation as a function of the number of columns in the input matrix -- assuming 4096 rows.\\nWe will then compare its performance against (1) :code:`torch.softmax` and (2) the :code:`naive_softmax` defined above.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"@triton.testing.perf_report(\\n    triton.testing.Benchmark(\\n        x_names=['N'],  # argument names to use as an x-axis for the plot\\n        x_vals=[\\n            128 * i for i in range(2, 100)\\n        ],  # different possible values for `x_name`\\n        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\\n        line_vals=[\\n            'triton',\\n            'torch-native',\\n            'torch-jit',\\n        ],  # possible values for `line_arg``\\n        line_names=[\\n            \\\"Triton\\\",\\n            \\\"Torch (native)\\\",\\n            \\\"Torch (jit)\\\",\\n        ],  # label name for the lines\\n        styles=[('blue', '-'), ('green', '-'), ('green', '--')],  # line styles\\n        ylabel=\\\"GB/s\\\",  # label name for the y-axis\\n        plot_name=\\\"softmax-performance\\\",  # name for the plot. Used also as a file name for saving the plot.\\n        args={'M': 4096},  # values for function arguments not in `x_names` and `y_name`\\n    )\\n)\\ndef benchmark(M, N, provider):\\n    x = torch.randn(M, N, device='cuda', dtype=torch.float32)\\n    if provider == 'torch-native':\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.softmax(x, axis=-1))\\n    if provider == 'triton':\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: softmax(x))\\n    if provider == 'torch-jit':\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: naive_softmax(x))\\n    gbps = lambda ms: 2 * x.nelement() * x.element_size() * 1e-9 / (ms * 1e-3)\\n    return gbps(ms), gbps(max_ms), gbps(min_ms)\\n\\n\\nbenchmark.run(show_plots=True, print_data=True)\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"In the above plot, we can see that:\\n\\n - Triton is 4x faster than the Torch JIT. This confirms our suspicions that the Torch JIT does not do any fusion here.\\n - Triton is noticeably faster than :code:`torch.softmax` -- in addition to being **easier to read, understand and maintain**.\\n   Note however that the PyTorch `softmax` operation is more general and will works on tensors of any shape.\\n\\n\"\n-      ]\n-    }\n-  ],\n-  \"metadata\": {\n-    \"kernelspec\": {\n-      \"display_name\": \"Python 3\",\n-      \"language\": \"python\",\n-      \"name\": \"python3\"\n-    },\n-    \"language_info\": {\n-      \"codemirror_mode\": {\n-        \"name\": \"ipython\",\n-        \"version\": 3\n-      },\n-      \"file_extension\": \".py\",\n-      \"mimetype\": \"text/x-python\",\n-      \"name\": \"python\",\n-      \"nbconvert_exporter\": \"python\",\n-      \"pygments_lexer\": \"ipython3\",\n-      \"version\": \"3.8.10\"\n-    }\n-  },\n-  \"nbformat\": 4,\n-  \"nbformat_minor\": 0\n-}\n\\ No newline at end of file"}, {"filename": "master/_downloads/62d97d49a32414049819dd8bb8378080/01-vector-add.py", "status": "removed", "additions": 0, "deletions": 131, "changes": 131, "file_content_changes": "@@ -1,131 +0,0 @@\n-\"\"\"\n-Vector Addition\n-=================\n-In this tutorial, you will write a simple vector addition using Triton and learn about:\n-\n-- The basic programming model of Triton\n-- The `triton.jit` decorator, which is used to define Triton kernels.\n-- The best practices for validating and benchmarking your custom ops against native reference implementations\n-\"\"\"\n-\n-# %%\n-# Compute Kernel\n-# --------------------------\n-\n-import torch\n-\n-import triton\n-import triton.language as tl\n-\n-\n-@triton.jit\n-def add_kernel(\n-    x_ptr,  # *Pointer* to first input vector\n-    y_ptr,  # *Pointer* to second input vector\n-    output_ptr,  # *Pointer* to output vector\n-    n_elements,  # Size of the vector\n-    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n-                 # NOTE: `constexpr` so it can be used as a shape value\n-):\n-    # There are multiple 'program's processing different data. We identify which program\n-    # we are here\n-    pid = tl.program_id(axis=0)  # We use a 1D launch grid so axis is 0\n-    # This program will process inputs that are offset from the initial data.\n-    # for instance, if you had a vector of length 256 and block_size of 64, the programs\n-    # would each access the elements [0:64, 64:128, 128:192, 192:256].\n-    # Note that offsets is a list of pointers\n-    block_start = pid * BLOCK_SIZE\n-    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n-    # Create a mask to guard memory operations against out-of-bounds accesses\n-    mask = offsets < n_elements\n-    # Load x and y from DRAM, masking out any extra elements in case the input is not a\n-    # multiple of the block size\n-    x = tl.load(x_ptr + offsets, mask=mask)\n-    y = tl.load(y_ptr + offsets, mask=mask)\n-    output = x + y\n-    # Write x + y back to DRAM\n-    tl.store(output_ptr + offsets, output, mask=mask)\n-\n-\n-# %%\n-# Let's also declare a helper function to (1) allocate the `z` tensor\n-# and (2) enqueue the above kernel with appropriate grid/block sizes.\n-\n-\n-def add(x: torch.Tensor, y: torch.Tensor):\n-    # We need to preallocate the output\n-    output = torch.empty_like(x)\n-    assert x.is_cuda and y.is_cuda and output.is_cuda\n-    n_elements = output.numel()\n-    # The SPMD launch grid denotes the number of kernel instances that run in parallel.\n-    # It is analogous to CUDA launch grids. It can be either Tuple[int], or Callable(metaparameters) -> Tuple[int]\n-    # In this case, we use a 1D grid where the size is the number of blocks\n-    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-    # NOTE:\n-    #  - each torch.tensor object is implicitly converted into a pointer to its first element.\n-    #  - `triton.jit`'ed functions can be index with a launch grid to obtain a callable GPU kernel\n-    #  - don't forget to pass meta-parameters as keywords arguments\n-    add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)\n-    # We return a handle to z but, since `torch.cuda.synchronize()` hasn't been called, the kernel is still\n-    # running asynchronously at this point.\n-    return output\n-\n-\n-# %%\n-# We can now use the above function to compute the element-wise sum of two `torch.tensor` objects and test its correctness:\n-\n-torch.manual_seed(0)\n-size = 98432\n-x = torch.rand(size, device='cuda')\n-y = torch.rand(size, device='cuda')\n-output_torch = x + y\n-output_triton = add(x, y)\n-print(output_torch)\n-print(output_triton)\n-print(\n-    f'The maximum difference between torch and triton is '\n-    f'{torch.max(torch.abs(output_torch - output_triton))}'\n-)\n-\n-# %%\n-# Seems like we're good to go!\n-\n-# %%\n-# Benchmark\n-# -----------\n-# We can now benchmark our custom op on vectors of increasing sizes to get a sense of how it does relative to PyTorch.\n-# To make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops\n-# for different problem sizes.\n-\n-\n-@triton.testing.perf_report(\n-    triton.testing.Benchmark(\n-        x_names=['size'],  # argument names to use as an x-axis for the plot\n-        x_vals=[\n-            2 ** i for i in range(12, 28, 1)\n-        ],  # different possible values for `x_name`\n-        x_log=True,  # x axis is logarithmic\n-        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n-        line_vals=['triton', 'torch'],  # possible values for `line_arg`\n-        line_names=['Triton', 'Torch'],  # label name for the lines\n-        styles=[('blue', '-'), ('green', '-')],  # line styles\n-        ylabel='GB/s',  # label name for the y-axis\n-        plot_name='vector-add-performance',  # name for the plot. Used also as a file name for saving the plot.\n-        args={},  # values for function arguments not in `x_names` and `y_name`\n-    )\n-)\n-def benchmark(size, provider):\n-    x = torch.rand(size, device='cuda', dtype=torch.float32)\n-    y = torch.rand(size, device='cuda', dtype=torch.float32)\n-    if provider == 'torch':\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: x + y)\n-    if provider == 'triton':\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: add(x, y))\n-    gbps = lambda ms: 12 * size / ms * 1e-6\n-    return gbps(ms), gbps(max_ms), gbps(min_ms)\n-\n-\n-# %%\n-# We can now run the decorated function above. Pass `print_data=True` to see the performance number, `show_plots=True` to plot them, and/or\n-# `save_path='/path/to/results/' to save them to disk along with raw CSV data\n-benchmark.run(print_data=True, show_plots=True)"}, {"filename": "master/_downloads/662999063954282841dc90b8945f85ce/tutorials_jupyter.zip", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_downloads/763344228ae6bc253ed1a6cf586aa30d/tutorials_python.zip", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_downloads/935c0dd0fbeb4b2e69588471cbb2d4b2/05-layer-norm.py", "status": "removed", "additions": 0, "deletions": 261, "changes": 261, "file_content_changes": "@@ -1,261 +0,0 @@\n-\"\"\"\n-Layer Normalization\n-====================\n-\"\"\"\n-\n-import torch\n-\n-import triton\n-import triton.language as tl\n-\n-try:\n-    # This is https://github.com/NVIDIA/apex, NOT the apex on PyPi, so it\n-    # should not be added to extras_require in setup.py.\n-    import apex\n-    HAS_APEX = True\n-except ModuleNotFoundError:\n-    HAS_APEX = False\n-\n-\n-# Forward Pass\n-@triton.jit\n-def _layer_norm_fwd_fused(X, Y, W, B, M, V, stride, N, eps,\n-                          BLOCK_SIZE: tl.constexpr):\n-    # position of elements processed by this program\n-    row = tl.program_id(0)\n-    cols = tl.arange(0, BLOCK_SIZE)\n-    mask = cols < N\n-    # offset data pointers to start at the row of interest\n-    X += row * stride\n-    Y += row * stride\n-    # load data and cast to float32\n-    x = tl.load(X + cols, mask=mask, other=0).to(tl.float32)\n-    # compute mean\n-    mean = tl.sum(x, axis=0) / N\n-    # compute std\n-    xmean = tl.where(mask, x - mean, 0.)\n-    var = tl.sum(xmean * xmean, axis=0) / N\n-    rstd = 1 / tl.sqrt(var + eps)\n-    xhat = xmean * rstd\n-    # write-back mean/rstd\n-    tl.store(M + row, mean)\n-    tl.store(V + row, rstd)\n-    # multiply by weight and add bias\n-    w = tl.load(W + cols, mask=mask)\n-    b = tl.load(B + cols, mask=mask)\n-    y = xhat * w + b\n-    # write-back\n-    tl.store(Y + cols, y, mask=mask)\n-\n-\n-# Backward pass (DX + partial DW + partial DB)\n-@triton.jit\n-def _layer_norm_bwd_dx_fused(DX, DY, DW, DB, X, W, B, M, V, Lock, stride, N, eps,\n-                             GROUP_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr):\n-    # position of elements processed by this program\n-    row = tl.program_id(0)\n-    cols = tl.arange(0, BLOCK_SIZE_N)\n-    mask = cols < N\n-    # offset data pointers to start at the row of interest\n-    X += row * stride\n-    DY += row * stride\n-    DX += row * stride\n-    # offset locks and weight/bias gradient pointer\n-    # each kernel instance accumulates partial sums for\n-    # DW and DB into one of GROUP_SIZE_M independent buffers\n-    # these buffers stay in the L2, which allow this kernel\n-    # to be fast\n-    lock_id = row % GROUP_SIZE_M\n-    Lock += lock_id\n-    Count = Lock + GROUP_SIZE_M\n-    DW = DW + lock_id * N + cols\n-    DB = DB + lock_id * N + cols\n-    # load data to SRAM\n-    x = tl.load(X + cols, mask=mask, other=0).to(tl.float32)\n-    dy = tl.load(DY + cols, mask=mask, other=0).to(tl.float32)\n-    w = tl.load(W + cols, mask=mask).to(tl.float32)\n-    mean = tl.load(M + row)\n-    rstd = tl.load(V + row)\n-    # compute dx\n-    xhat = (x - mean) * rstd\n-    wdy = w * dy\n-    xhat = tl.where(mask, xhat, 0.)\n-    wdy = tl.where(mask, wdy, 0.)\n-    mean1 = tl.sum(xhat * wdy, axis=0) / N\n-    mean2 = tl.sum(wdy, axis=0) / N\n-    dx = (wdy - (xhat * mean1 + mean2)) * rstd\n-    # write-back dx\n-    tl.store(DX + cols, dx, mask=mask)\n-    # accumulate partial sums for dw/db\n-    partial_dw = (dy * xhat).to(w.dtype)\n-    partial_db = (dy).to(w.dtype)\n-    while tl.atomic_cas(Lock, 0, 1) == 1:\n-        pass\n-    count = tl.load(Count)\n-    # first store doesn't accumulate\n-    if count == 0:\n-        tl.atomic_xchg(Count, 1)\n-    else:\n-        partial_dw += tl.load(DW, mask=mask)\n-        partial_db += tl.load(DB, mask=mask)\n-    tl.store(DW, partial_dw, mask=mask)\n-    tl.store(DB, partial_db, mask=mask)\n-    # release lock\n-    tl.atomic_xchg(Lock, 0)\n-\n-# Backward pass (total DW + total DB)\n-\n-\n-@triton.jit\n-def _layer_norm_bwd_dwdb(DW, DB, FINAL_DW, FINAL_DB, M, N,\n-                         BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr):\n-    pid = tl.program_id(0)\n-    cols = pid * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-    dw = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n-    db = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n-    for i in range(0, M, BLOCK_SIZE_M):\n-        rows = i + tl.arange(0, BLOCK_SIZE_M)\n-        mask = (rows[:, None] < M) & (cols[None, :] < N)\n-        offs = rows[:, None] * N + cols[None, :]\n-        dw += tl.load(DW + offs, mask=mask, other=0.)\n-        db += tl.load(DB + offs, mask=mask, other=0.)\n-    sum_dw = tl.sum(dw, axis=0)\n-    sum_db = tl.sum(db, axis=0)\n-    tl.store(FINAL_DW + cols, sum_dw, mask=cols < N)\n-    tl.store(FINAL_DB + cols, sum_db, mask=cols < N)\n-\n-\n-class LayerNorm(torch.autograd.Function):\n-\n-    @staticmethod\n-    def forward(ctx, x, normalized_shape, weight, bias, eps):\n-        # allocate output\n-        y = torch.empty_like(x)\n-        # reshape input data into 2D tensor\n-        x_arg = x.reshape(-1, x.shape[-1])\n-        M, N = x_arg.shape\n-        mean = torch.empty((M, ), dtype=torch.float32, device='cuda')\n-        rstd = torch.empty((M, ), dtype=torch.float32, device='cuda')\n-        # Less than 64KB per feature: enqueue fused kernel\n-        MAX_FUSED_SIZE = 65536 // x.element_size()\n-        BLOCK_SIZE = min(MAX_FUSED_SIZE, triton.next_power_of_2(N))\n-        if N > BLOCK_SIZE:\n-            raise RuntimeError(\"This layer norm doesn't support feature dim >= 64KB.\")\n-        # heuristics for number of warps\n-        num_warps = min(max(BLOCK_SIZE // 256, 1), 8)\n-        # enqueue kernel\n-        _layer_norm_fwd_fused[(M,)](x_arg, y, weight, bias, mean, rstd,\n-                                    x_arg.stride(0), N, eps,\n-                                    BLOCK_SIZE=BLOCK_SIZE, num_warps=num_warps)\n-        ctx.save_for_backward(x, weight, bias, mean, rstd)\n-        ctx.BLOCK_SIZE = BLOCK_SIZE\n-        ctx.num_warps = num_warps\n-        ctx.eps = eps\n-        return y\n-\n-    @staticmethod\n-    def backward(ctx, dy):\n-        x, w, b, m, v = ctx.saved_tensors\n-        # heuristics for amount of parallel reduction stream for DG/DB\n-        N = w.shape[0]\n-        GROUP_SIZE_M = 64\n-        if N <= 8192: GROUP_SIZE_M = 96\n-        if N <= 4096: GROUP_SIZE_M = 128\n-        if N <= 1024: GROUP_SIZE_M = 256\n-        # allocate output\n-        locks = torch.zeros(2 * GROUP_SIZE_M, dtype=torch.int32, device='cuda')\n-        _dw = torch.empty((GROUP_SIZE_M, w.shape[0]), dtype=x.dtype, device=w.device)\n-        _db = torch.empty((GROUP_SIZE_M, w.shape[0]), dtype=x.dtype, device=w.device)\n-        dw = torch.empty((w.shape[0],), dtype=w.dtype, device=w.device)\n-        db = torch.empty((w.shape[0],), dtype=w.dtype, device=w.device)\n-        dx = torch.empty_like(dy)\n-        # enqueue kernel using forward pass heuristics\n-        # also compute partial sums for DW and DB\n-        x_arg = x.reshape(-1, x.shape[-1])\n-        M, N = x_arg.shape\n-        _layer_norm_bwd_dx_fused[(M,)](dx, dy, _dw, _db, x, w, b, m, v, locks,\n-                                       x_arg.stride(0), N, ctx.eps,\n-                                       BLOCK_SIZE_N=ctx.BLOCK_SIZE,\n-                                       GROUP_SIZE_M=GROUP_SIZE_M,\n-                                       num_warps=ctx.num_warps)\n-        grid = lambda meta: [triton.cdiv(N, meta['BLOCK_SIZE_N'])]\n-        # accumulate partial sums in separate kernel\n-        _layer_norm_bwd_dwdb[grid](_dw, _db, dw, db, GROUP_SIZE_M, N,\n-                                   BLOCK_SIZE_M=32,\n-                                   BLOCK_SIZE_N=128)\n-        return dx, None, dw, db, None\n-\n-\n-layer_norm = LayerNorm.apply\n-\n-\n-def test_layer_norm(M, N, dtype, eps=1e-5, device='cuda'):\n-    # create data\n-    x_shape = (M, N)\n-    w_shape = (x_shape[-1], )\n-    weight = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-    bias = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-    x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device='cuda')\n-    dy = .1 * torch.randn_like(x)\n-    x.requires_grad_(True)\n-    # forward pass\n-    y_tri = layer_norm(x, w_shape, weight, bias, eps)\n-    y_ref = torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps).to(dtype)\n-    # backward pass (triton)\n-    y_tri.backward(dy, retain_graph=True)\n-    dx_tri, dw_tri, db_tri = [_.grad.clone() for _ in [x, weight, bias]]\n-    x.grad, weight.grad, bias.grad = None, None, None\n-    # backward pass (torch)\n-    y_ref.backward(dy, retain_graph=True)\n-    dx_ref, dw_ref, db_ref = [_.grad.clone() for _ in [x, weight, bias]]\n-    # compare\n-    triton.testing.assert_almost_equal(y_tri, y_ref)\n-    triton.testing.assert_almost_equal(dx_tri, dx_ref)\n-    triton.testing.assert_almost_equal(db_tri, db_ref, decimal=1)\n-    triton.testing.assert_almost_equal(dw_tri, dw_ref, decimal=1)\n-\n-\n-@triton.testing.perf_report(\n-    triton.testing.Benchmark(\n-        x_names=['N'],\n-        x_vals=[512 * i for i in range(2, 32)],\n-        line_arg='provider',\n-        line_vals=['triton', 'torch'] + (['apex'] if HAS_APEX else []),\n-        line_names=['Triton', 'Torch'] + (['Apex'] if HAS_APEX else []),\n-        styles=[('blue', '-'), ('green', '-'), ('orange', '-')],\n-        ylabel='GB/s',\n-        plot_name='layer-norm-backward',\n-        args={'M': 4096, 'dtype': torch.float16, 'mode': 'backward'}\n-    )\n-)\n-def bench_layer_norm(M, N, dtype, provider, mode='backward', eps=1e-5, device='cuda'):\n-    # create data\n-    x_shape = (M, N)\n-    w_shape = (x_shape[-1], )\n-    weight = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-    bias = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-    x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device='cuda')\n-    dy = .1 * torch.randn_like(x)\n-    x.requires_grad_(True)\n-    # utility functions\n-    if provider == 'triton':\n-        y_fwd = lambda: layer_norm(x, w_shape, weight, bias, eps)\n-    if provider == 'torch':\n-        y_fwd = lambda: torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps)\n-    if provider == 'apex':\n-        apex_layer_norm = apex.normalization.FusedLayerNorm(w_shape).to(x.device).to(x.dtype)\n-        y_fwd = lambda: apex_layer_norm(x)\n-    # forward pass\n-    if mode == 'forward':\n-        gbps = lambda ms: 2 * x.numel() * x.element_size() / ms * 1e-6\n-        ms, min_ms, max_ms = triton.testing.do_bench(y_fwd, rep=500)\n-    # backward pass\n-    if mode == 'backward':\n-        gbps = lambda ms: 3 * x.numel() * x.element_size() / ms * 1e-6\n-        y = y_fwd()\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: y.backward(dy, retain_graph=True),\n-                                                     grad_to_none=[x], rep=500)\n-    return gbps(ms), gbps(max_ms), gbps(min_ms)\n-\n-\n-bench_layer_norm.run(save_path='.', print_data=True)"}, {"filename": "master/_downloads/ae7fff29e1b574187bc930ed94bcc353/05-layer-norm.ipynb", "status": "removed", "additions": 0, "deletions": 54, "changes": 54, "file_content_changes": "@@ -1,54 +0,0 @@\n-{\n-  \"cells\": [\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"%matplotlib inline\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"\\n# Layer Normalization\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"import torch\\n\\nimport triton\\nimport triton.language as tl\\n\\ntry:\\n    # This is https://github.com/NVIDIA/apex, NOT the apex on PyPi, so it\\n    # should not be added to extras_require in setup.py.\\n    import apex\\n    HAS_APEX = True\\nexcept ModuleNotFoundError:\\n    HAS_APEX = False\\n\\n\\n# Forward Pass\\n@triton.jit\\ndef _layer_norm_fwd_fused(X, Y, W, B, M, V, stride, N, eps,\\n                          BLOCK_SIZE: tl.constexpr):\\n    # position of elements processed by this program\\n    row = tl.program_id(0)\\n    cols = tl.arange(0, BLOCK_SIZE)\\n    mask = cols < N\\n    # offset data pointers to start at the row of interest\\n    X += row * stride\\n    Y += row * stride\\n    # load data and cast to float32\\n    x = tl.load(X + cols, mask=mask, other=0).to(tl.float32)\\n    # compute mean\\n    mean = tl.sum(x, axis=0) / N\\n    # compute std\\n    xmean = tl.where(mask, x - mean, 0.)\\n    var = tl.sum(xmean * xmean, axis=0) / N\\n    rstd = 1 / tl.sqrt(var + eps)\\n    xhat = xmean * rstd\\n    # write-back mean/rstd\\n    tl.store(M + row, mean)\\n    tl.store(V + row, rstd)\\n    # multiply by weight and add bias\\n    w = tl.load(W + cols, mask=mask)\\n    b = tl.load(B + cols, mask=mask)\\n    y = xhat * w + b\\n    # write-back\\n    tl.store(Y + cols, y, mask=mask)\\n\\n\\n# Backward pass (DX + partial DW + partial DB)\\n@triton.jit\\ndef _layer_norm_bwd_dx_fused(DX, DY, DW, DB, X, W, B, M, V, Lock, stride, N, eps,\\n                             GROUP_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr):\\n    # position of elements processed by this program\\n    row = tl.program_id(0)\\n    cols = tl.arange(0, BLOCK_SIZE_N)\\n    mask = cols < N\\n    # offset data pointers to start at the row of interest\\n    X += row * stride\\n    DY += row * stride\\n    DX += row * stride\\n    # offset locks and weight/bias gradient pointer\\n    # each kernel instance accumulates partial sums for\\n    # DW and DB into one of GROUP_SIZE_M independent buffers\\n    # these buffers stay in the L2, which allow this kernel\\n    # to be fast\\n    lock_id = row % GROUP_SIZE_M\\n    Lock += lock_id\\n    Count = Lock + GROUP_SIZE_M\\n    DW = DW + lock_id * N + cols\\n    DB = DB + lock_id * N + cols\\n    # load data to SRAM\\n    x = tl.load(X + cols, mask=mask, other=0).to(tl.float32)\\n    dy = tl.load(DY + cols, mask=mask, other=0).to(tl.float32)\\n    w = tl.load(W + cols, mask=mask).to(tl.float32)\\n    mean = tl.load(M + row)\\n    rstd = tl.load(V + row)\\n    # compute dx\\n    xhat = (x - mean) * rstd\\n    wdy = w * dy\\n    xhat = tl.where(mask, xhat, 0.)\\n    wdy = tl.where(mask, wdy, 0.)\\n    mean1 = tl.sum(xhat * wdy, axis=0) / N\\n    mean2 = tl.sum(wdy, axis=0) / N\\n    dx = (wdy - (xhat * mean1 + mean2)) * rstd\\n    # write-back dx\\n    tl.store(DX + cols, dx, mask=mask)\\n    # accumulate partial sums for dw/db\\n    partial_dw = (dy * xhat).to(w.dtype)\\n    partial_db = (dy).to(w.dtype)\\n    while tl.atomic_cas(Lock, 0, 1) == 1:\\n        pass\\n    count = tl.load(Count)\\n    # first store doesn't accumulate\\n    if count == 0:\\n        tl.atomic_xchg(Count, 1)\\n    else:\\n        partial_dw += tl.load(DW, mask=mask)\\n        partial_db += tl.load(DB, mask=mask)\\n    tl.store(DW, partial_dw, mask=mask)\\n    tl.store(DB, partial_db, mask=mask)\\n    # release lock\\n    tl.atomic_xchg(Lock, 0)\\n\\n# Backward pass (total DW + total DB)\\n\\n\\n@triton.jit\\ndef _layer_norm_bwd_dwdb(DW, DB, FINAL_DW, FINAL_DB, M, N,\\n                         BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr):\\n    pid = tl.program_id(0)\\n    cols = pid * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\\n    dw = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\\n    db = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\\n    for i in range(0, M, BLOCK_SIZE_M):\\n        rows = i + tl.arange(0, BLOCK_SIZE_M)\\n        mask = (rows[:, None] < M) & (cols[None, :] < N)\\n        offs = rows[:, None] * N + cols[None, :]\\n        dw += tl.load(DW + offs, mask=mask, other=0.)\\n        db += tl.load(DB + offs, mask=mask, other=0.)\\n    sum_dw = tl.sum(dw, axis=0)\\n    sum_db = tl.sum(db, axis=0)\\n    tl.store(FINAL_DW + cols, sum_dw, mask=cols < N)\\n    tl.store(FINAL_DB + cols, sum_db, mask=cols < N)\\n\\n\\nclass LayerNorm(torch.autograd.Function):\\n\\n    @staticmethod\\n    def forward(ctx, x, normalized_shape, weight, bias, eps):\\n        # allocate output\\n        y = torch.empty_like(x)\\n        # reshape input data into 2D tensor\\n        x_arg = x.reshape(-1, x.shape[-1])\\n        M, N = x_arg.shape\\n        mean = torch.empty((M, ), dtype=torch.float32, device='cuda')\\n        rstd = torch.empty((M, ), dtype=torch.float32, device='cuda')\\n        # Less than 64KB per feature: enqueue fused kernel\\n        MAX_FUSED_SIZE = 65536 // x.element_size()\\n        BLOCK_SIZE = min(MAX_FUSED_SIZE, triton.next_power_of_2(N))\\n        if N > BLOCK_SIZE:\\n            raise RuntimeError(\\\"This layer norm doesn't support feature dim >= 64KB.\\\")\\n        # heuristics for number of warps\\n        num_warps = min(max(BLOCK_SIZE // 256, 1), 8)\\n        # enqueue kernel\\n        _layer_norm_fwd_fused[(M,)](x_arg, y, weight, bias, mean, rstd,\\n                                    x_arg.stride(0), N, eps,\\n                                    BLOCK_SIZE=BLOCK_SIZE, num_warps=num_warps)\\n        ctx.save_for_backward(x, weight, bias, mean, rstd)\\n        ctx.BLOCK_SIZE = BLOCK_SIZE\\n        ctx.num_warps = num_warps\\n        ctx.eps = eps\\n        return y\\n\\n    @staticmethod\\n    def backward(ctx, dy):\\n        x, w, b, m, v = ctx.saved_tensors\\n        # heuristics for amount of parallel reduction stream for DG/DB\\n        N = w.shape[0]\\n        GROUP_SIZE_M = 64\\n        if N <= 8192: GROUP_SIZE_M = 96\\n        if N <= 4096: GROUP_SIZE_M = 128\\n        if N <= 1024: GROUP_SIZE_M = 256\\n        # allocate output\\n        locks = torch.zeros(2 * GROUP_SIZE_M, dtype=torch.int32, device='cuda')\\n        _dw = torch.empty((GROUP_SIZE_M, w.shape[0]), dtype=x.dtype, device=w.device)\\n        _db = torch.empty((GROUP_SIZE_M, w.shape[0]), dtype=x.dtype, device=w.device)\\n        dw = torch.empty((w.shape[0],), dtype=w.dtype, device=w.device)\\n        db = torch.empty((w.shape[0],), dtype=w.dtype, device=w.device)\\n        dx = torch.empty_like(dy)\\n        # enqueue kernel using forward pass heuristics\\n        # also compute partial sums for DW and DB\\n        x_arg = x.reshape(-1, x.shape[-1])\\n        M, N = x_arg.shape\\n        _layer_norm_bwd_dx_fused[(M,)](dx, dy, _dw, _db, x, w, b, m, v, locks,\\n                                       x_arg.stride(0), N, ctx.eps,\\n                                       BLOCK_SIZE_N=ctx.BLOCK_SIZE,\\n                                       GROUP_SIZE_M=GROUP_SIZE_M,\\n                                       num_warps=ctx.num_warps)\\n        grid = lambda meta: [triton.cdiv(N, meta['BLOCK_SIZE_N'])]\\n        # accumulate partial sums in separate kernel\\n        _layer_norm_bwd_dwdb[grid](_dw, _db, dw, db, GROUP_SIZE_M, N,\\n                                   BLOCK_SIZE_M=32,\\n                                   BLOCK_SIZE_N=128)\\n        return dx, None, dw, db, None\\n\\n\\nlayer_norm = LayerNorm.apply\\n\\n\\ndef test_layer_norm(M, N, dtype, eps=1e-5, device='cuda'):\\n    # create data\\n    x_shape = (M, N)\\n    w_shape = (x_shape[-1], )\\n    weight = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\\n    bias = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\\n    x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device='cuda')\\n    dy = .1 * torch.randn_like(x)\\n    x.requires_grad_(True)\\n    # forward pass\\n    y_tri = layer_norm(x, w_shape, weight, bias, eps)\\n    y_ref = torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps).to(dtype)\\n    # backward pass (triton)\\n    y_tri.backward(dy, retain_graph=True)\\n    dx_tri, dw_tri, db_tri = [_.grad.clone() for _ in [x, weight, bias]]\\n    x.grad, weight.grad, bias.grad = None, None, None\\n    # backward pass (torch)\\n    y_ref.backward(dy, retain_graph=True)\\n    dx_ref, dw_ref, db_ref = [_.grad.clone() for _ in [x, weight, bias]]\\n    # compare\\n    triton.testing.assert_almost_equal(y_tri, y_ref)\\n    triton.testing.assert_almost_equal(dx_tri, dx_ref)\\n    triton.testing.assert_almost_equal(db_tri, db_ref, decimal=1)\\n    triton.testing.assert_almost_equal(dw_tri, dw_ref, decimal=1)\\n\\n\\n@triton.testing.perf_report(\\n    triton.testing.Benchmark(\\n        x_names=['N'],\\n        x_vals=[512 * i for i in range(2, 32)],\\n        line_arg='provider',\\n        line_vals=['triton', 'torch'] + (['apex'] if HAS_APEX else []),\\n        line_names=['Triton', 'Torch'] + (['Apex'] if HAS_APEX else []),\\n        styles=[('blue', '-'), ('green', '-'), ('orange', '-')],\\n        ylabel='GB/s',\\n        plot_name='layer-norm-backward',\\n        args={'M': 4096, 'dtype': torch.float16, 'mode': 'backward'}\\n    )\\n)\\ndef bench_layer_norm(M, N, dtype, provider, mode='backward', eps=1e-5, device='cuda'):\\n    # create data\\n    x_shape = (M, N)\\n    w_shape = (x_shape[-1], )\\n    weight = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\\n    bias = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\\n    x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device='cuda')\\n    dy = .1 * torch.randn_like(x)\\n    x.requires_grad_(True)\\n    # utility functions\\n    if provider == 'triton':\\n        y_fwd = lambda: layer_norm(x, w_shape, weight, bias, eps)\\n    if provider == 'torch':\\n        y_fwd = lambda: torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps)\\n    if provider == 'apex':\\n        apex_layer_norm = apex.normalization.FusedLayerNorm(w_shape).to(x.device).to(x.dtype)\\n        y_fwd = lambda: apex_layer_norm(x)\\n    # forward pass\\n    if mode == 'forward':\\n        gbps = lambda ms: 2 * x.numel() * x.element_size() / ms * 1e-6\\n        ms, min_ms, max_ms = triton.testing.do_bench(y_fwd, rep=500)\\n    # backward pass\\n    if mode == 'backward':\\n        gbps = lambda ms: 3 * x.numel() * x.element_size() / ms * 1e-6\\n        y = y_fwd()\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: y.backward(dy, retain_graph=True),\\n                                                     grad_to_none=[x], rep=500)\\n    return gbps(ms), gbps(max_ms), gbps(min_ms)\\n\\n\\nbench_layer_norm.run(save_path='.', print_data=True)\"\n-      ]\n-    }\n-  ],\n-  \"metadata\": {\n-    \"kernelspec\": {\n-      \"display_name\": \"Python 3\",\n-      \"language\": \"python\",\n-      \"name\": \"python3\"\n-    },\n-    \"language_info\": {\n-      \"codemirror_mode\": {\n-        \"name\": \"ipython\",\n-        \"version\": 3\n-      },\n-      \"file_extension\": \".py\",\n-      \"mimetype\": \"text/x-python\",\n-      \"name\": \"python\",\n-      \"nbconvert_exporter\": \"python\",\n-      \"pygments_lexer\": \"ipython3\",\n-      \"version\": \"3.8.10\"\n-    }\n-  },\n-  \"nbformat\": 4,\n-  \"nbformat_minor\": 0\n-}\n\\ No newline at end of file"}, {"filename": "master/_downloads/b51b68bc1c6b1a5e509f67800b6235af/03-matrix-multiplication.ipynb", "status": "removed", "additions": 0, "deletions": 129, "changes": 129, "file_content_changes": "@@ -1,129 +0,0 @@\n-{\n-  \"cells\": [\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"%matplotlib inline\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"\\n# Matrix Multiplication\\nIn this tutorial, you will write a 25-lines high-performance FP16 matrix multiplication\\nkernel that achieves performance on par with cuBLAS.\\nYou will specifically learn about:\\n\\n- Block-level matrix multiplications\\n- Multi-dimensional pointer arithmetic\\n- Program re-ordering for improved L2 cache hit rate\\n- Automatic performance tuning\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Motivations\\nMatrix multiplications are a key building block of most modern high-performance computing systems.\\nThey are notoriously hard to optimize, hence their implementation is generally done by\\nhardware vendors themselves as part of so-called \\\"kernel libraries\\\" (e.g., cuBLAS).\\nUnfortunately, these libraries are often proprietary and cannot be easily customized\\nto accomodate the needs of modern deep learning workloads (e.g., fused activation functions).\\nIn this tutorial, you will learn how to implement efficient matrix multiplications by\\nyourself with Triton, in a way that is easy to customize and extend.\\n\\nRoughly speaking, the kernel that we will write will implement the following blocked\\nalgorithm to multiply a (M, K) by a (K, N) matrix:\\n\\n .. code-block:: python\\n\\n   # do in parallel\\n   for m in range(0, M, BLOCK_SIZE_M):\\n     # do in parallel\\n     for n in range(0, N, BLOCK_SIZE_N):\\n       acc = zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=float32)\\n       for k in range(0, K, BLOCK_SIZE_K):\\n         a = A[m : m+BLOCK_SIZE_M, k : k+BLOCK_SIZE_K]\\n         b = B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]\\n         acc += dot(a, b)\\n       C[m : m+BLOCK_SIZE_M, n : n+BLOCK_SIZE_N] = acc;\\n\\nwhere each iteration of the doubly-nested for-loop is performed by a dedicated Triton program instance.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Compute Kernel\\n\\nThe above algorithm is, actually, fairly straightforward to implement in Triton.\\nThe main difficulty comes from the computation of the memory locations at which blocks\\nof :code:`A` and :code:`B` must be read in the inner loop. For that, we need\\nmulti-dimensional pointer arithmetics.\\n\\n### Pointer Arithmetics\\n\\nFor a row-major 2D tensor :code:`X`, the memory location of :code:`X[i, j]` is given b\\ny :code:`&X[i, j] = X + i*stride_xi + j*stride_xj`.\\nTherefore, blocks of pointers for :code:`A[m : m+BLOCK_SIZE_M, k:k+BLOCK_SIZE_K]` and\\n:code:`B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]` can be defined in pseudo-code as:\\n\\n .. code-block:: python\\n\\n   &A[m : m+BLOCK_SIZE_M, k:k+BLOCK_SIZE_K] =  a_ptr + (m : m+BLOCK_SIZE_M)[:, None]*A.stride(0) + (k : k+BLOCK_SIZE_K)[None, :]*A.stride(1);\\n   &B[k : k+BLOCK_SIZE_K, n:n+BLOCK_SIZE_N] =  b_ptr + (k : k+BLOCK_SIZE_K)[:, None]*B.stride(0) + (n : n+BLOCK_SIZE_N)[None, :]*B.stride(1);\\n\\nWhich means that pointers for blocks of A and B can be initialized (i.e., :code:`k=0`) in Triton as:\\n\\n .. code-block:: python\\n\\n   offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\\n   offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\\n   offs_k = tl.arange(0, BLOCK_SIZE_K)\\n   a_ptrs = a_ptr + (offs_am[:, None]*stride_am + offs_k [None, :]*stride_ak)\\n   b_ptrs = b_ptr + (offs_k [:, None]*stride_bk + offs_bn[None, :]*stride_bn)\\n\\nAnd then updated in the inner loop as follows:\\n\\n .. code-block:: python\\n\\n   pa += BLOCK_SIZE_K * stride_ak;\\n   pb += BLOCK_SIZE_K * stride_bk;\\n\\n\\n### L2 Cache Optimizations\\n\\nAs mentioned above, each program instance computes a :code:`[BLOCK_SIZE_M, BLOCK_SIZE_N]`\\nblock of :code:`C`.\\nIt is important to remember that the order in which these blocks are computed does\\nmatter, since it affects the L2 cache hit rate of our program. and unfortunately, a\\na simple row-major ordering\\n\\n .. code-block:: Python\\n\\n   pid = triton.program_id(0);\\n   grid_m = (M + BLOCK_SIZE_M - 1) // BLOCK_SIZE_M;\\n   grid_n = (N + BLOCK_SIZE_N - 1) // BLOCK_SIZE_N;\\n   pid_m = pid / grid_n;\\n   pid_n = pid % grid_n;\\n\\nis just not going to cut it.\\n\\nOne possible solution is to launch blocks in an order that promotes data reuse.\\nThis can be done by 'super-grouping' blocks in groups of :code:`GROUP_M` rows before\\nswitching to the next column:\\n\\n .. code-block:: python\\n\\n   # program ID\\n   pid = tl.program_id(axis=0)\\n   # number of program ids along the M axis\\n   num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\\n   # number of programs ids along the N axis\\n   num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\\n   # number of programs in group\\n   num_pid_in_group = GROUP_SIZE_M * num_pid_n\\n   # id of the group this program is in\\n   group_id = pid // num_pid_in_group\\n   # row-id of the first program in the group\\n   first_pid_m = group_id * GROUP_SIZE_M\\n   # if `num_pid_m` isn't divisible by `GROUP_SIZE_M`, the last group is smaller\\n   group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\\n   # *within groups*, programs are ordered in a column-major order\\n   # row-id of the program in the *launch grid*\\n   pid_m = first_pid_m + (pid % group_size_m)\\n   # col-id of the program in the *launch grid*\\n   pid_n = (pid % num_pid_in_group) // group_size_m\\n\\nFor example, in the following matmul where each matrix is 9 blocks by 9 blocks,\\nwe can see that if we compute the output in row-major ordering, we need to load 90\\nblocks into SRAM to compute the first 9 output blocks, but if we do it in grouped\\nordering, we only need to load 54 blocks.\\n  .. image:: grouped_vs_row_major_ordering.png\\n\\nIn practice, this can improve the performance of our matrix multiplication kernel by\\nmore than 10\\\\% on some hardware architecture (e.g., 220 to 245 TFLOPS on A100).\\n\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Final Result\\n\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"import torch\\n\\nimport triton\\nimport triton.language as tl\\n\\n# %\\n# :code:`triton.jit`'ed functions can be auto-tuned by using the `triton.autotune`\\n# decorator, which consumes:\\n#   - A list of :code:`triton.Config` objects that define different configurations of\\n#       meta-parameters (e.g., BLOCK_SIZE_M) and compilation options (e.g., num_warps) to try\\n#   - An autotuning *key* whose change in values will trigger evaluation of all the\\n#       provided configs\\n\\n\\n@triton.autotune(\\n    configs=[\\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\\n        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\\n        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\\n        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\\n    ],\\n    key=['M', 'N', 'K'],\\n)\\n@triton.jit\\ndef matmul_kernel(\\n    # Pointers to matrices\\n    a_ptr, b_ptr, c_ptr,\\n    # Matrix dimensions\\n    M, N, K,\\n    # The stride variables represent how much to increase the ptr by when moving by 1\\n    # element in a particular dimension. E.g. stride_am is how much to increase a_ptr\\n    # by to get the element one row down (A has M rows)\\n    stride_am, stride_ak,\\n    stride_bk, stride_bn,\\n    stride_cm, stride_cn,\\n    # Meta-parameters\\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\\n    GROUP_SIZE_M: tl.constexpr,\\n    ACTIVATION: tl.constexpr,\\n):\\n    \\\"\\\"\\\"Kernel for computing the matmul C = A x B.\\n    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\\n    \\\"\\\"\\\"\\n    # -----------------------------------------------------------\\n    # Map program ids `pid` to the block of C it should compute.\\n    # This is done in a grouped ordering to promote L2 data reuse\\n    # See above `L2 Cache Optimizations` section for details\\n    pid = tl.program_id(axis=0)\\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\\n    num_pid_in_group = GROUP_SIZE_M * num_pid_n\\n    group_id = pid // num_pid_in_group\\n    first_pid_m = group_id * GROUP_SIZE_M\\n    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\\n    pid_m = first_pid_m + (pid % group_size_m)\\n    pid_n = (pid % num_pid_in_group) // group_size_m\\n\\n    # ----------------------------------------------------------\\n    # Create pointers for the first blocks of A and B.\\n    # We will advance this pointer as we move in the K direction\\n    # and accumulate\\n    # a_ptrs is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\\n    # b_ptrs is a block of [BLOCK_SIZE_K, BLOCK_SIZE_n] pointers\\n    # see above `Pointer Arithmetics` section for details\\n    offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\\n    offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\\n    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\\n    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\\n\\n    # -----------------------------------------------------------\\n    # Iterate to compute a block of the C matrix\\n    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\\n    # of fp32 values for higher accuracy.\\n    # `accumulator` will be converted back to fp16 after the loop\\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\\n    for k in range(0, K, BLOCK_SIZE_K):\\n        # Note that for simplicity, we don't apply a mask here.\\n        # This means that if K is not a multiple of BLOCK_SIZE_K,\\n        # this will access out-of-bounds memory and produce an\\n        # error or (worse!) incorrect results.\\n        a = tl.load(a_ptrs)\\n        b = tl.load(b_ptrs)\\n        # We accumulate along the K dimension\\n        accumulator += tl.dot(a, b)\\n        # Advance the ptrs to the next K block\\n        a_ptrs += BLOCK_SIZE_K * stride_ak\\n        b_ptrs += BLOCK_SIZE_K * stride_bk\\n    # you can fuse arbitrary activation functions here\\n    # while the accumulator is still in FP32!\\n    if ACTIVATION:\\n        accumulator = ACTIVATION(accumulator)\\n    c = accumulator.to(tl.float16)\\n\\n    # -----------------------------------------------------------\\n    # Write back the block of the output matrix C\\n    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\\n    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\\n    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\\n    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\\n    tl.store(c_ptrs, c, mask=c_mask)\\n\\n\\n# we can fuse `leaky_relu` by providing it as an `ACTIVATION` meta-parameter in `_matmul`\\n@triton.jit\\ndef leaky_relu(x):\\n    return tl.where(x >= 0, x, 0.01 * x)\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"We can now create a convenience wrapper function that only takes two input tensors\\nand (1) checks any shape constraint; (2) allocates the output; (3) launches the above kernel\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"def matmul(a, b, activation=None):\\n    # checks constraints\\n    assert a.shape[1] == b.shape[0], \\\"incompatible dimensions\\\"\\n    assert a.is_contiguous(), \\\"matrix A must be contiguous\\\"\\n    assert b.is_contiguous(), \\\"matrix B must be contiguous\\\"\\n    M, K = a.shape\\n    K, N = b.shape\\n    assert (\\n        K % 32 == 0\\n    ), \\\"We don't check memory-out-of-bounds with K so K must be divisible by BLOCK_SIZE_K\\\"\\n    # allocates output\\n    c = torch.empty((M, N), device=a.device, dtype=a.dtype)\\n    # 1D launch kernel where each block gets its own program.\\n    grid = lambda META: (\\n        triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\\n    )\\n    matmul_kernel[grid](\\n        a, b, c,\\n        M, N, K,\\n        a.stride(0), a.stride(1),\\n        b.stride(0), b.stride(1),\\n        c.stride(0), c.stride(1),\\n        ACTIVATION=activation,\\n    )\\n    return c\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Unit Test\\n\\nWe can test our custom matrix multiplication operation against a native torch implementation (i.e., cuBLAS)\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"torch.manual_seed(0)\\na = torch.randn((512, 512), device='cuda', dtype=torch.float16)\\nb = torch.randn((512, 512), device='cuda', dtype=torch.float16)\\ntriton_output = matmul(a, b, activation=None)\\ntorch_output = torch.matmul(a, b)\\nprint(f\\\"triton_output={triton_output}\\\")\\nprint(f\\\"torch_output={torch_output}\\\")\\nif triton.testing.allclose(triton_output, torch_output):\\n    print(\\\"\\u2705 Triton and Torch match\\\")\\nelse:\\n    print(\\\"\\u274c Triton and Torch differ\\\")\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Benchmark\\n\\n### Square Matrix Performance\\nWe can now compare the performance of our kernel against that of cuBLAS. Here we focus on square matrices, but feel free to arrange this script as you wish to benchmark any other matrix shape.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"@triton.testing.perf_report(\\n    triton.testing.Benchmark(\\n        x_names=['M', 'N', 'K'],  # argument names to use as an x-axis for the plot\\n        x_vals=[\\n            128 * i for i in range(2, 33)\\n        ],  # different possible values for `x_name`\\n        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\\n        # possible values for `line_arg``\\n        line_vals=['cublas', 'cublas + relu', 'triton', 'triton + relu'],\\n        # label name for the lines\\n        line_names=[\\\"cuBLAS\\\", \\\"cuBLAS (+ torch.nn.LeakyReLU)\\\", \\\"Triton\\\", \\\"Triton (+ LeakyReLU)\\\"],\\n        # line styles\\n        styles=[('green', '-'), ('green', '--'), ('blue', '-'), ('blue', '--')],\\n        ylabel=\\\"TFLOPS\\\",  # label name for the y-axis\\n        plot_name=\\\"matmul-performance\\\",  # name for the plot. Used also as a file name for saving the plot.\\n        args={},\\n    )\\n)\\ndef benchmark(M, N, K, provider):\\n    a = torch.randn((M, K), device='cuda', dtype=torch.float16)\\n    b = torch.randn((K, N), device='cuda', dtype=torch.float16)\\n    if provider == 'cublas':\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(a, b))\\n    if provider == 'triton':\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul(a, b))\\n    if provider == 'cublas + relu':\\n        torch_relu = torch.nn.ReLU(inplace=True)\\n        ms, min_ms, max_ms = triton.testing.do_bench(\\n            lambda: torch_relu(torch.matmul(a, b))\\n        )\\n    if provider == 'triton + relu':\\n        ms, min_ms, max_ms = triton.testing.do_bench(\\n            lambda: matmul(a, b, activation=leaky_relu)\\n        )\\n    perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\\n    return perf(ms), perf(max_ms), perf(min_ms)\\n\\n\\nbenchmark.run(show_plots=True, print_data=True)\"\n-      ]\n-    }\n-  ],\n-  \"metadata\": {\n-    \"kernelspec\": {\n-      \"display_name\": \"Python 3\",\n-      \"language\": \"python\",\n-      \"name\": \"python3\"\n-    },\n-    \"language_info\": {\n-      \"codemirror_mode\": {\n-        \"name\": \"ipython\",\n-        \"version\": 3\n-      },\n-      \"file_extension\": \".py\",\n-      \"mimetype\": \"text/x-python\",\n-      \"name\": \"python\",\n-      \"nbconvert_exporter\": \"python\",\n-      \"pygments_lexer\": \"ipython3\",\n-      \"version\": \"3.8.10\"\n-    }\n-  },\n-  \"nbformat\": 4,\n-  \"nbformat_minor\": 0\n-}\n\\ No newline at end of file"}, {"filename": "master/_downloads/bc847dec325798bdc436c4ef5ac8b78a/04-low-memory-dropout.ipynb", "status": "removed", "additions": 0, "deletions": 100, "changes": 100, "file_content_changes": "@@ -1,100 +0,0 @@\n-{\n-  \"cells\": [\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"%matplotlib inline\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"\\n# Low-Memory Dropout\\n\\nIn this tutorial, you will write a memory-efficient implementation of dropout whose state\\nwill be composed of a single int32 seed. This differs from more traditional implementations of dropout,\\nwhose state is generally composed of a bit mask tensor of the same shape as the input. You will learn about:\\n\\n- The limitations of naive implementations of Dropout with PyTorch\\n- Parallel pseudo-random number generation in Triton\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Baseline\\nThe *dropout* operator was first introduced in [SRIVASTAVA2014]_ as a way to improve the performance\\nof deep neural networks in low-data regime (i.e. regularization).\\n\\nIt takes a vector as input and produces a vector of the same shape as output. Each scalar in the\\noutput has a probability $p$ of being changed to zero and otherwise it is copied from the input.\\nThis forces the network to perform well even when only $1 - p$ scalars from the input are available.\\n\\nAt evaluation time we want to use the full power of the network so we set $p=0$. Naively this would\\nincrease the norm of the output (which can be a bad thing, e.g. it can lead to artificial decrease\\nin the output softmax temperature). To prevent this we multiply the output by $\\\\frac{1}{1 - p}$, which\\nkeeps the norm consistent regardless of the dropout probability.\\n\\nLet's first take a look at the baseline implementation.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"import tabulate\\nimport torch\\n\\nimport triton\\nimport triton.language as tl\\n\\n\\n@triton.jit\\ndef _dropout(\\n        x_ptr,  # pointer to the input\\n        x_keep_ptr,  # pointer to a mask of 0s and 1s\\n        output_ptr,  # pointer to the output\\n        n_elements,  # number of elements in the `x` tensor\\n        p,  # probability that an element of `x` is changed to zero\\n        BLOCK_SIZE: tl.constexpr,\\n):\\n    pid = tl.program_id(axis=0)\\n    block_start = pid * BLOCK_SIZE\\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\\n    mask = offsets < n_elements\\n    # Load data\\n    x = tl.load(x_ptr + offsets, mask=mask)\\n    x_keep = tl.load(x_keep_ptr + offsets, mask=mask)\\n    # The line below is the crucial part, described in the paragraph above!\\n    output = tl.where(x_keep, x / (1 - p), 0.0)\\n    # Write-back output\\n    tl.store(output_ptr + offsets, output, mask=mask)\\n\\n\\ndef dropout(x, x_keep, p):\\n    output = torch.empty_like(x)\\n    assert x.is_contiguous()\\n    n_elements = x.numel()\\n    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\\n    _dropout[grid](x, x_keep, output, n_elements, p, BLOCK_SIZE=1024)\\n    return output\\n\\n\\n# Input tensor\\nx = torch.randn(size=(10,)).cuda()\\n# Dropout mask\\np = 0.5\\nx_keep = (torch.rand(size=(10,)) > p).to(torch.int32).cuda()\\n#\\noutput = dropout(x, x_keep=x_keep, p=p)\\nprint(tabulate.tabulate([\\n    [\\\"input\\\"] + x.tolist(),\\n    [\\\"keep mask\\\"] + x_keep.tolist(),\\n    [\\\"output\\\"] + output.tolist()\\n]))\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Seeded dropout\\nAbove implementation of dropout works fine, but it can be a bit awkward to deal with. Firstly\\nwe need to store the dropout mask for backpropagation. Secondly, dropout state management can get\\nvery tricky when using recompute/checkpointing (e.g. see all the notes about `preserve_rng_state` in\\nhttps://pytorch.org/docs/1.9.0/checkpoint.html). In this tutorial we'll describe an alternative implementation\\nthat (1) has a smaller memory footprint; (2) requires less data movement; and (3) simplifies the management\\nof persisting randomness across multiple invocations of the kernel.\\n\\nPseudorandom number generation in Triton is simple! In this tutorial we will use the\\n:code:`triton.language.rand` function which generates a block of uniformly distributed :code:`float32`\\nvalues in [0, 1), given a seed and a block of :code:`int32` offsets. But if you need it, Triton also provides\\nother `random number generation strategies <Random Number Generation>`.\\n\\n<div class=\\\"alert alert-info\\\"><h4>Note</h4><p>Triton's implementation of PRNG is based on the Philox algorithm (described on [SALMON2011]_).</p></div>\\n\\nLet's put it all together.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"@triton.jit\\ndef _seeded_dropout(\\n        x_ptr,\\n        output_ptr,\\n        n_elements,\\n        p,\\n        seed,\\n        BLOCK_SIZE: tl.constexpr,\\n):\\n    # compute memory offsets of elements handled by this instance\\n    pid = tl.program_id(axis=0)\\n    block_start = pid * BLOCK_SIZE\\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\\n    # load data from x\\n    mask = offsets < n_elements\\n    x = tl.load(x_ptr + offsets, mask=mask)\\n    # randomly prune it\\n    random = tl.rand(seed, offsets)\\n    x_keep = random > p\\n    # write-back\\n    output = tl.where(x_keep, x / (1 - p), 0.0)\\n    tl.store(output_ptr + offsets, output, mask=mask)\\n\\n\\ndef seeded_dropout(x, p, seed):\\n    output = torch.empty_like(x)\\n    assert x.is_contiguous()\\n    n_elements = x.numel()\\n    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\\n    _seeded_dropout[grid](x, output, n_elements, p, seed, BLOCK_SIZE=1024)\\n    return output\\n\\n\\nx = torch.randn(size=(10,)).cuda()\\n# Compare this to the baseline - dropout mask is never instantiated!\\noutput = seeded_dropout(x, p=0.5, seed=123)\\noutput2 = seeded_dropout(x, p=0.5, seed=123)\\noutput3 = seeded_dropout(x, p=0.5, seed=512)\\n\\nprint(tabulate.tabulate([\\n    [\\\"input\\\"] + x.tolist(),\\n    [\\\"output (seed = 123)\\\"] + output.tolist(),\\n    [\\\"output (seed = 123)\\\"] + output2.tolist(),\\n    [\\\"output (seed = 512)\\\"] + output3.tolist()\\n]))\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"Et Voil\\u00e0! We have a triton kernel that applies the same dropout mask provided the seed is the same!\\nIf you'd like explore further applications of pseudorandomness in GPU programming, we encourage you\\nto explore the `triton/language/random` folder!\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Exercises\\n1. Extend the kernel to operate over a matrix and use a vector of seeds - one per row.\\n2. Add support for striding.\\n3. (challenge) Implement a kernel for sparse Johnson-Lindenstrauss transform which generates the projection matrix one the fly each time using a seed.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## References\\n\\n.. [SALMON2011] John K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw, \\\"Parallel Random Numbers: As Easy as 1, 2, 3\\\", 2011\\n.. [SRIVASTAVA2014] Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov, \\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\", JMLR 2014\\n\\n\"\n-      ]\n-    }\n-  ],\n-  \"metadata\": {\n-    \"kernelspec\": {\n-      \"display_name\": \"Python 3\",\n-      \"language\": \"python\",\n-      \"name\": \"python3\"\n-    },\n-    \"language_info\": {\n-      \"codemirror_mode\": {\n-        \"name\": \"ipython\",\n-        \"version\": 3\n-      },\n-      \"file_extension\": \".py\",\n-      \"mimetype\": \"text/x-python\",\n-      \"name\": \"python\",\n-      \"nbconvert_exporter\": \"python\",\n-      \"pygments_lexer\": \"ipython3\",\n-      \"version\": \"3.8.10\"\n-    }\n-  },\n-  \"nbformat\": 4,\n-  \"nbformat_minor\": 0\n-}\n\\ No newline at end of file"}, {"filename": "master/_downloads/c9aed78977a4c05741d675a38dde3d7d/04-low-memory-dropout.py", "status": "removed", "additions": 0, "deletions": 166, "changes": 166, "file_content_changes": "@@ -1,166 +0,0 @@\n-\"\"\"\n-Low-Memory Dropout\n-=================\n-\n-In this tutorial, you will write a memory-efficient implementation of dropout whose state\n-will be composed of a single int32 seed. This differs from more traditional implementations of dropout,\n-whose state is generally composed of a bit mask tensor of the same shape as the input. You will learn about:\n-\n-- The limitations of naive implementations of Dropout with PyTorch\n-- Parallel pseudo-random number generation in Triton\n-\"\"\"\n-\n-# %%\n-# Baseline\n-# -------------\n-# The *dropout* operator was first introduced in [SRIVASTAVA2014]_ as a way to improve the performance\n-# of deep neural networks in low-data regime (i.e. regularization).\n-#\n-# It takes a vector as input and produces a vector of the same shape as output. Each scalar in the\n-# output has a probability :math:`p` of being changed to zero and otherwise it is copied from the input.\n-# This forces the network to perform well even when only :math:`1 - p` scalars from the input are available.\n-#\n-# At evaluation time we want to use the full power of the network so we set :math:`p=0`. Naively this would\n-# increase the norm of the output (which can be a bad thing, e.g. it can lead to artificial decrease\n-# in the output softmax temperature). To prevent this we multiply the output by :math:`\\frac{1}{1 - p}`, which\n-# keeps the norm consistent regardless of the dropout probability.\n-#\n-# Let's first take a look at the baseline implementation.\n-\n-\n-import tabulate\n-import torch\n-\n-import triton\n-import triton.language as tl\n-\n-\n-@triton.jit\n-def _dropout(\n-        x_ptr,  # pointer to the input\n-        x_keep_ptr,  # pointer to a mask of 0s and 1s\n-        output_ptr,  # pointer to the output\n-        n_elements,  # number of elements in the `x` tensor\n-        p,  # probability that an element of `x` is changed to zero\n-        BLOCK_SIZE: tl.constexpr,\n-):\n-    pid = tl.program_id(axis=0)\n-    block_start = pid * BLOCK_SIZE\n-    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n-    mask = offsets < n_elements\n-    # Load data\n-    x = tl.load(x_ptr + offsets, mask=mask)\n-    x_keep = tl.load(x_keep_ptr + offsets, mask=mask)\n-    # The line below is the crucial part, described in the paragraph above!\n-    output = tl.where(x_keep, x / (1 - p), 0.0)\n-    # Write-back output\n-    tl.store(output_ptr + offsets, output, mask=mask)\n-\n-\n-def dropout(x, x_keep, p):\n-    output = torch.empty_like(x)\n-    assert x.is_contiguous()\n-    n_elements = x.numel()\n-    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-    _dropout[grid](x, x_keep, output, n_elements, p, BLOCK_SIZE=1024)\n-    return output\n-\n-\n-# Input tensor\n-x = torch.randn(size=(10,)).cuda()\n-# Dropout mask\n-p = 0.5\n-x_keep = (torch.rand(size=(10,)) > p).to(torch.int32).cuda()\n-#\n-output = dropout(x, x_keep=x_keep, p=p)\n-print(tabulate.tabulate([\n-    [\"input\"] + x.tolist(),\n-    [\"keep mask\"] + x_keep.tolist(),\n-    [\"output\"] + output.tolist()\n-]))\n-\n-# %%\n-# Seeded dropout\n-# -------------\n-# Above implementation of dropout works fine, but it can be a bit awkward to deal with. Firstly\n-# we need to store the dropout mask for backpropagation. Secondly, dropout state management can get\n-# very tricky when using recompute/checkpointing (e.g. see all the notes about `preserve_rng_state` in\n-# https://pytorch.org/docs/1.9.0/checkpoint.html). In this tutorial we'll describe an alternative implementation\n-# that (1) has a smaller memory footprint; (2) requires less data movement; and (3) simplifies the management\n-# of persisting randomness across multiple invocations of the kernel.\n-#\n-# Pseudorandom number generation in Triton is simple! In this tutorial we will use the\n-# :code:`triton.language.rand` function which generates a block of uniformly distributed :code:`float32`\n-# values in [0, 1), given a seed and a block of :code:`int32` offsets. But if you need it, Triton also provides\n-# other :ref:`random number generation strategies <Random Number Generation>`.\n-#\n-# .. note::\n-#    Triton's implementation of PRNG is based on the Philox algorithm (described on [SALMON2011]_).\n-#\n-# Let's put it all together.\n-\n-\n-@triton.jit\n-def _seeded_dropout(\n-        x_ptr,\n-        output_ptr,\n-        n_elements,\n-        p,\n-        seed,\n-        BLOCK_SIZE: tl.constexpr,\n-):\n-    # compute memory offsets of elements handled by this instance\n-    pid = tl.program_id(axis=0)\n-    block_start = pid * BLOCK_SIZE\n-    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n-    # load data from x\n-    mask = offsets < n_elements\n-    x = tl.load(x_ptr + offsets, mask=mask)\n-    # randomly prune it\n-    random = tl.rand(seed, offsets)\n-    x_keep = random > p\n-    # write-back\n-    output = tl.where(x_keep, x / (1 - p), 0.0)\n-    tl.store(output_ptr + offsets, output, mask=mask)\n-\n-\n-def seeded_dropout(x, p, seed):\n-    output = torch.empty_like(x)\n-    assert x.is_contiguous()\n-    n_elements = x.numel()\n-    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-    _seeded_dropout[grid](x, output, n_elements, p, seed, BLOCK_SIZE=1024)\n-    return output\n-\n-\n-x = torch.randn(size=(10,)).cuda()\n-# Compare this to the baseline - dropout mask is never instantiated!\n-output = seeded_dropout(x, p=0.5, seed=123)\n-output2 = seeded_dropout(x, p=0.5, seed=123)\n-output3 = seeded_dropout(x, p=0.5, seed=512)\n-\n-print(tabulate.tabulate([\n-    [\"input\"] + x.tolist(),\n-    [\"output (seed = 123)\"] + output.tolist(),\n-    [\"output (seed = 123)\"] + output2.tolist(),\n-    [\"output (seed = 512)\"] + output3.tolist()\n-]))\n-\n-# %%\n-# Et Voil\u00e0! We have a triton kernel that applies the same dropout mask provided the seed is the same!\n-# If you'd like explore further applications of pseudorandomness in GPU programming, we encourage you\n-# to explore the `triton/language/random` folder!\n-\n-# %%\n-# Exercises\n-# -------------\n-# 1. Extend the kernel to operate over a matrix and use a vector of seeds - one per row.\n-# 2. Add support for striding.\n-# 3. (challenge) Implement a kernel for sparse Johnson-Lindenstrauss transform which generates the projection matrix one the fly each time using a seed.\n-\n-# %%\n-# References\n-# --------------\n-#\n-# .. [SALMON2011] John K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw, \"Parallel Random Numbers: As Easy as 1, 2, 3\", 2011\n-# .. [SRIVASTAVA2014] Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov, \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\", JMLR 2014"}, {"filename": "master/_downloads/d5fee5b55a64e47f1b5724ec39adf171/03-matrix-multiplication.py", "status": "removed", "additions": 0, "deletions": 355, "changes": 355, "file_content_changes": "@@ -1,355 +0,0 @@\n-\"\"\"\n-Matrix Multiplication\n-======================\n-In this tutorial, you will write a 25-lines high-performance FP16 matrix multiplication\n-kernel that achieves performance on par with cuBLAS.\n-You will specifically learn about:\n-\n-- Block-level matrix multiplications\n-- Multi-dimensional pointer arithmetic\n-- Program re-ordering for improved L2 cache hit rate\n-- Automatic performance tuning\n-\"\"\"\n-\n-# %%\n-# Motivations\n-# -------------\n-# Matrix multiplications are a key building block of most modern high-performance computing systems.\n-# They are notoriously hard to optimize, hence their implementation is generally done by\n-# hardware vendors themselves as part of so-called \"kernel libraries\" (e.g., cuBLAS).\n-# Unfortunately, these libraries are often proprietary and cannot be easily customized\n-# to accomodate the needs of modern deep learning workloads (e.g., fused activation functions).\n-# In this tutorial, you will learn how to implement efficient matrix multiplications by\n-# yourself with Triton, in a way that is easy to customize and extend.\n-#\n-# Roughly speaking, the kernel that we will write will implement the following blocked\n-# algorithm to multiply a (M, K) by a (K, N) matrix:\n-#\n-#  .. code-block:: python\n-#\n-#    # do in parallel\n-#    for m in range(0, M, BLOCK_SIZE_M):\n-#      # do in parallel\n-#      for n in range(0, N, BLOCK_SIZE_N):\n-#        acc = zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=float32)\n-#        for k in range(0, K, BLOCK_SIZE_K):\n-#          a = A[m : m+BLOCK_SIZE_M, k : k+BLOCK_SIZE_K]\n-#          b = B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]\n-#          acc += dot(a, b)\n-#        C[m : m+BLOCK_SIZE_M, n : n+BLOCK_SIZE_N] = acc;\n-#\n-# where each iteration of the doubly-nested for-loop is performed by a dedicated Triton program instance.\n-\n-# %%\n-# Compute Kernel\n-# ----------------\n-#\n-# The above algorithm is, actually, fairly straightforward to implement in Triton.\n-# The main difficulty comes from the computation of the memory locations at which blocks\n-# of :code:`A` and :code:`B` must be read in the inner loop. For that, we need\n-# multi-dimensional pointer arithmetics.\n-#\n-# Pointer Arithmetics\n-# ~~~~~~~~~~~~~~~~~~~~\n-#\n-# For a row-major 2D tensor :code:`X`, the memory location of :code:`X[i, j]` is given b\n-# y :code:`&X[i, j] = X + i*stride_xi + j*stride_xj`.\n-# Therefore, blocks of pointers for :code:`A[m : m+BLOCK_SIZE_M, k:k+BLOCK_SIZE_K]` and\n-# :code:`B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]` can be defined in pseudo-code as:\n-#\n-#  .. code-block:: python\n-#\n-#    &A[m : m+BLOCK_SIZE_M, k:k+BLOCK_SIZE_K] =  a_ptr + (m : m+BLOCK_SIZE_M)[:, None]*A.stride(0) + (k : k+BLOCK_SIZE_K)[None, :]*A.stride(1);\n-#    &B[k : k+BLOCK_SIZE_K, n:n+BLOCK_SIZE_N] =  b_ptr + (k : k+BLOCK_SIZE_K)[:, None]*B.stride(0) + (n : n+BLOCK_SIZE_N)[None, :]*B.stride(1);\n-#\n-# Which means that pointers for blocks of A and B can be initialized (i.e., :code:`k=0`) in Triton as:\n-#\n-#  .. code-block:: python\n-#\n-#    offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n-#    offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-#    offs_k = tl.arange(0, BLOCK_SIZE_K)\n-#    a_ptrs = a_ptr + (offs_am[:, None]*stride_am + offs_k [None, :]*stride_ak)\n-#    b_ptrs = b_ptr + (offs_k [:, None]*stride_bk + offs_bn[None, :]*stride_bn)\n-#\n-# And then updated in the inner loop as follows:\n-#\n-#  .. code-block:: python\n-#\n-#    pa += BLOCK_SIZE_K * stride_ak;\n-#    pb += BLOCK_SIZE_K * stride_bk;\n-#\n-#\n-# L2 Cache Optimizations\n-# ~~~~~~~~~~~~~~~~~~~~~~~~\n-#\n-# As mentioned above, each program instance computes a :code:`[BLOCK_SIZE_M, BLOCK_SIZE_N]`\n-# block of :code:`C`.\n-# It is important to remember that the order in which these blocks are computed does\n-# matter, since it affects the L2 cache hit rate of our program. and unfortunately, a\n-# a simple row-major ordering\n-#\n-#  .. code-block:: Python\n-#\n-#    pid = triton.program_id(0);\n-#    grid_m = (M + BLOCK_SIZE_M - 1) // BLOCK_SIZE_M;\n-#    grid_n = (N + BLOCK_SIZE_N - 1) // BLOCK_SIZE_N;\n-#    pid_m = pid / grid_n;\n-#    pid_n = pid % grid_n;\n-#\n-# is just not going to cut it.\n-#\n-# One possible solution is to launch blocks in an order that promotes data reuse.\n-# This can be done by 'super-grouping' blocks in groups of :code:`GROUP_M` rows before\n-# switching to the next column:\n-#\n-#  .. code-block:: python\n-#\n-#    # program ID\n-#    pid = tl.program_id(axis=0)\n-#    # number of program ids along the M axis\n-#    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n-#    # number of programs ids along the N axis\n-#    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n-#    # number of programs in group\n-#    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n-#    # id of the group this program is in\n-#    group_id = pid // num_pid_in_group\n-#    # row-id of the first program in the group\n-#    first_pid_m = group_id * GROUP_SIZE_M\n-#    # if `num_pid_m` isn't divisible by `GROUP_SIZE_M`, the last group is smaller\n-#    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n-#    # *within groups*, programs are ordered in a column-major order\n-#    # row-id of the program in the *launch grid*\n-#    pid_m = first_pid_m + (pid % group_size_m)\n-#    # col-id of the program in the *launch grid*\n-#    pid_n = (pid % num_pid_in_group) // group_size_m\n-#\n-# For example, in the following matmul where each matrix is 9 blocks by 9 blocks,\n-# we can see that if we compute the output in row-major ordering, we need to load 90\n-# blocks into SRAM to compute the first 9 output blocks, but if we do it in grouped\n-# ordering, we only need to load 54 blocks.\n-#   .. image:: grouped_vs_row_major_ordering.png\n-#\n-# In practice, this can improve the performance of our matrix multiplication kernel by\n-# more than 10\\% on some hardware architecture (e.g., 220 to 245 TFLOPS on A100).\n-#\n-\n-# %%\n-# Final Result\n-# -------------\n-#\n-\n-import torch\n-\n-import triton\n-import triton.language as tl\n-\n-# %\n-# :code:`triton.jit`'ed functions can be auto-tuned by using the `triton.autotune`\n-# decorator, which consumes:\n-#   - A list of :code:`triton.Config` objects that define different configurations of\n-#       meta-parameters (e.g., BLOCK_SIZE_M) and compilation options (e.g., num_warps) to try\n-#   - An autotuning *key* whose change in values will trigger evaluation of all the\n-#       provided configs\n-\n-\n-@triton.autotune(\n-    configs=[\n-        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n-        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n-        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n-        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n-    ],\n-    key=['M', 'N', 'K'],\n-)\n-@triton.jit\n-def matmul_kernel(\n-    # Pointers to matrices\n-    a_ptr, b_ptr, c_ptr,\n-    # Matrix dimensions\n-    M, N, K,\n-    # The stride variables represent how much to increase the ptr by when moving by 1\n-    # element in a particular dimension. E.g. stride_am is how much to increase a_ptr\n-    # by to get the element one row down (A has M rows)\n-    stride_am, stride_ak,\n-    stride_bk, stride_bn,\n-    stride_cm, stride_cn,\n-    # Meta-parameters\n-    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n-    GROUP_SIZE_M: tl.constexpr,\n-    ACTIVATION: tl.constexpr,\n-):\n-    \"\"\"Kernel for computing the matmul C = A x B.\n-    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n-    \"\"\"\n-    # -----------------------------------------------------------\n-    # Map program ids `pid` to the block of C it should compute.\n-    # This is done in a grouped ordering to promote L2 data reuse\n-    # See above `L2 Cache Optimizations` section for details\n-    pid = tl.program_id(axis=0)\n-    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n-    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n-    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n-    group_id = pid // num_pid_in_group\n-    first_pid_m = group_id * GROUP_SIZE_M\n-    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n-    pid_m = first_pid_m + (pid % group_size_m)\n-    pid_n = (pid % num_pid_in_group) // group_size_m\n-\n-    # ----------------------------------------------------------\n-    # Create pointers for the first blocks of A and B.\n-    # We will advance this pointer as we move in the K direction\n-    # and accumulate\n-    # a_ptrs is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\n-    # b_ptrs is a block of [BLOCK_SIZE_K, BLOCK_SIZE_n] pointers\n-    # see above `Pointer Arithmetics` section for details\n-    offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n-    offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-    offs_k = tl.arange(0, BLOCK_SIZE_K)\n-    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n-    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n-\n-    # -----------------------------------------------------------\n-    # Iterate to compute a block of the C matrix\n-    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n-    # of fp32 values for higher accuracy.\n-    # `accumulator` will be converted back to fp16 after the loop\n-    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n-    for k in range(0, K, BLOCK_SIZE_K):\n-        # Note that for simplicity, we don't apply a mask here.\n-        # This means that if K is not a multiple of BLOCK_SIZE_K,\n-        # this will access out-of-bounds memory and produce an\n-        # error or (worse!) incorrect results.\n-        a = tl.load(a_ptrs)\n-        b = tl.load(b_ptrs)\n-        # We accumulate along the K dimension\n-        accumulator += tl.dot(a, b)\n-        # Advance the ptrs to the next K block\n-        a_ptrs += BLOCK_SIZE_K * stride_ak\n-        b_ptrs += BLOCK_SIZE_K * stride_bk\n-    # you can fuse arbitrary activation functions here\n-    # while the accumulator is still in FP32!\n-    if ACTIVATION:\n-        accumulator = ACTIVATION(accumulator)\n-    c = accumulator.to(tl.float16)\n-\n-    # -----------------------------------------------------------\n-    # Write back the block of the output matrix C\n-    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n-    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n-    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n-    tl.store(c_ptrs, c, mask=c_mask)\n-\n-\n-# we can fuse `leaky_relu` by providing it as an `ACTIVATION` meta-parameter in `_matmul`\n-@triton.jit\n-def leaky_relu(x):\n-    return tl.where(x >= 0, x, 0.01 * x)\n-\n-\n-# %%\n-# We can now create a convenience wrapper function that only takes two input tensors\n-# and (1) checks any shape constraint; (2) allocates the output; (3) launches the above kernel\n-\n-\n-def matmul(a, b, activation=None):\n-    # checks constraints\n-    assert a.shape[1] == b.shape[0], \"incompatible dimensions\"\n-    assert a.is_contiguous(), \"matrix A must be contiguous\"\n-    assert b.is_contiguous(), \"matrix B must be contiguous\"\n-    M, K = a.shape\n-    K, N = b.shape\n-    assert (\n-        K % 32 == 0\n-    ), \"We don't check memory-out-of-bounds with K so K must be divisible by BLOCK_SIZE_K\"\n-    # allocates output\n-    c = torch.empty((M, N), device=a.device, dtype=a.dtype)\n-    # 1D launch kernel where each block gets its own program.\n-    grid = lambda META: (\n-        triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\n-    )\n-    matmul_kernel[grid](\n-        a, b, c,\n-        M, N, K,\n-        a.stride(0), a.stride(1),\n-        b.stride(0), b.stride(1),\n-        c.stride(0), c.stride(1),\n-        ACTIVATION=activation,\n-    )\n-    return c\n-\n-\n-# %%\n-# Unit Test\n-# -----------\n-#\n-# We can test our custom matrix multiplication operation against a native torch implementation (i.e., cuBLAS)\n-\n-torch.manual_seed(0)\n-a = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n-b = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n-triton_output = matmul(a, b, activation=None)\n-torch_output = torch.matmul(a, b)\n-print(f\"triton_output={triton_output}\")\n-print(f\"torch_output={torch_output}\")\n-if triton.testing.allclose(triton_output, torch_output):\n-    print(\"\u2705 Triton and Torch match\")\n-else:\n-    print(\"\u274c Triton and Torch differ\")\n-\n-# %%\n-# Benchmark\n-# --------------\n-#\n-# Square Matrix Performance\n-# ~~~~~~~~~~~~~~~~~~~~~~~~~~\n-# We can now compare the performance of our kernel against that of cuBLAS. Here we focus on square matrices, but feel free to arrange this script as you wish to benchmark any other matrix shape.\n-\n-\n-@triton.testing.perf_report(\n-    triton.testing.Benchmark(\n-        x_names=['M', 'N', 'K'],  # argument names to use as an x-axis for the plot\n-        x_vals=[\n-            128 * i for i in range(2, 33)\n-        ],  # different possible values for `x_name`\n-        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n-        # possible values for `line_arg``\n-        line_vals=['cublas', 'cublas + relu', 'triton', 'triton + relu'],\n-        # label name for the lines\n-        line_names=[\"cuBLAS\", \"cuBLAS (+ torch.nn.LeakyReLU)\", \"Triton\", \"Triton (+ LeakyReLU)\"],\n-        # line styles\n-        styles=[('green', '-'), ('green', '--'), ('blue', '-'), ('blue', '--')],\n-        ylabel=\"TFLOPS\",  # label name for the y-axis\n-        plot_name=\"matmul-performance\",  # name for the plot. Used also as a file name for saving the plot.\n-        args={},\n-    )\n-)\n-def benchmark(M, N, K, provider):\n-    a = torch.randn((M, K), device='cuda', dtype=torch.float16)\n-    b = torch.randn((K, N), device='cuda', dtype=torch.float16)\n-    if provider == 'cublas':\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(a, b))\n-    if provider == 'triton':\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul(a, b))\n-    if provider == 'cublas + relu':\n-        torch_relu = torch.nn.ReLU(inplace=True)\n-        ms, min_ms, max_ms = triton.testing.do_bench(\n-            lambda: torch_relu(torch.matmul(a, b))\n-        )\n-    if provider == 'triton + relu':\n-        ms, min_ms, max_ms = triton.testing.do_bench(\n-            lambda: matmul(a, b, activation=leaky_relu)\n-        )\n-    perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n-    return perf(ms), perf(max_ms), perf(min_ms)\n-\n-\n-benchmark.run(show_plots=True, print_data=True)"}, {"filename": "master/_downloads/d91442ac2982c4e0cc3ab0f43534afbc/02-fused-softmax.py", "status": "removed", "additions": 0, "deletions": 191, "changes": 191, "file_content_changes": "@@ -1,191 +0,0 @@\n-\"\"\"\n-Fused Softmax\n-=================\n-In this tutorial, you will write a fused softmax operation that is significantly faster\n-than PyTorch's native op for a particular class of matrices: those whose rows can fit in\n-the GPU's SRAM.\n-You will learn about:\n-\n-- The benefits of kernel fusion for bandwidth-bound operations.\n-- Reduction operators in Triton.\n-\"\"\"\n-\n-# %%\n-# Motivations\n-# ------------\n-# Custom GPU kernels for elementwise additions are educationally valuable but won't get you very far in practice.\n-# Let us consider instead the case of a simple (numerically stabilized) softmax operation:\n-\n-import torch\n-\n-import triton\n-import triton.language as tl\n-\n-\n-@torch.jit.script\n-def naive_softmax(x):\n-    \"\"\"Compute row-wise softmax of X using native pytorch\n-\n-    We subtract the maximum element in order to avoid overflows. Softmax is invariant to\n-    this shift.\n-    \"\"\"\n-    # read  MN elements ; write M  elements\n-    x_max = x.max(dim=1)[0]\n-    # read MN + M elements ; write MN elements\n-    z = x - x_max[:, None]\n-    # read  MN elements ; write MN elements\n-    numerator = torch.exp(z)\n-    # read  MN elements ; write M  elements\n-    denominator = numerator.sum(dim=1)\n-    # read MN + M elements ; write MN elements\n-    ret = numerator / denominator[:, None]\n-    # in total: read 5MN + 2M elements ; wrote 3MN + 2M elements\n-    return ret\n-\n-\n-# %%\n-# When implemented naively in PyTorch, computing :code:`y = naive_softmax(x)` for :math:`x \\in R^{M \\times N}`\n-# requires reading :math:`5MN + 2M` elements from DRAM and writing back :math:`3MN + 2M` elements.\n-# This is obviously wasteful; we'd prefer to have a custom \"fused\" kernel that only reads\n-# X once and does all the necessary computations on-chip.\n-# Doing so would require reading and writing back only :math:`MN` bytes, so we could\n-# expect a theoretical speed-up of ~4x (i.e., :math:`(8MN + 4M) / 2MN`).\n-# The `torch.jit.script` flags aims to perform this kind of \"kernel fusion\" automatically\n-# but, as we will see later, it is still far from ideal.\n-\n-# %%\n-# Compute Kernel\n-# ----------------\n-# Our softmax kernel works as follows: each program loads a row of the input matrix X,\n-# normalizes it and writes back the result to the output Y.\n-# Note that one important limitation of Triton is that each block must have a\n-# power-of-two number of elements, so we need to internally \"pad\" each row and guard the\n-# memory operations properly if we want to handle any possible input shapes:\n-\n-\n-@triton.jit\n-def softmax_kernel(\n-    output_ptr, input_ptr, input_row_stride, output_row_stride, n_cols,\n-    BLOCK_SIZE: tl.constexpr\n-):\n-    # The rows of the softmax are independent, so we parallelize across those\n-    row_idx = tl.program_id(0)\n-    # The stride represents how much we need to increase the pointer to advance 1 row\n-    row_start_ptr = input_ptr + row_idx * input_row_stride\n-    # The block size is the next power of two greater than n_cols, so we can fit each\n-    # row in a single block\n-    col_offsets = tl.arange(0, BLOCK_SIZE)\n-    input_ptrs = row_start_ptr + col_offsets\n-    # Load the row into SRAM, using a mask since BLOCK_SIZE may be > than n_cols\n-    row = tl.load(input_ptrs, mask=col_offsets < n_cols, other=-float('inf'))\n-    # Substract maximum for numerical stability\n-    row_minus_max = row - tl.max(row, axis=0)\n-    # Note that exponentials in Triton are fast but approximate (i.e., think __expf in CUDA)\n-    numerator = tl.exp(row_minus_max)\n-    denominator = tl.sum(numerator, axis=0)\n-    softmax_output = numerator / denominator\n-    # Write back output to DRAM\n-    output_row_start_ptr = output_ptr + row_idx * output_row_stride\n-    output_ptrs = output_row_start_ptr + col_offsets\n-    tl.store(output_ptrs, softmax_output, mask=col_offsets < n_cols)\n-\n-\n-# %%\n-# We can create a helper function that enqueues the kernel and its (meta-)arguments for any given input tensor.\n-\n-def softmax(x):\n-    n_rows, n_cols = x.shape\n-    # The block size is the smallest power of two greater than the number of columns in `x`\n-    BLOCK_SIZE = triton.next_power_of_2(n_cols)\n-    # Another trick we can use is to ask the compiler to use more threads per row by\n-    # increasing the number of warps (`num_warps`) over which each row is distributed.\n-    # You will see in the next tutorial how to auto-tune this value in a more natural\n-    # way so you don't have to come up with manual heuristics yourself.\n-    num_warps = 4\n-    if BLOCK_SIZE >= 2048:\n-        num_warps = 8\n-    if BLOCK_SIZE >= 4096:\n-        num_warps = 16\n-    # Allocate output\n-    y = torch.empty_like(x)\n-    # Enqueue kernel. The 1D launch grid is simple: we have one kernel instance per row o\n-    # f the input matrix\n-    softmax_kernel[(n_rows,)](\n-        y,\n-        x,\n-        x.stride(0),\n-        y.stride(0),\n-        n_cols,\n-        num_warps=num_warps,\n-        BLOCK_SIZE=BLOCK_SIZE,\n-    )\n-    return y\n-\n-\n-# %%\n-# Unit Test\n-# ----------\n-\n-# %%\n-# We make sure that we test our kernel on a matrix with an irregular number of rows and columns.\n-# This will allow us to verify that our padding mechanism works.\n-\n-torch.manual_seed(0)\n-x = torch.randn(1823, 781, device='cuda')\n-y_triton = softmax(x)\n-y_torch = torch.softmax(x, axis=1)\n-assert torch.allclose(y_triton, y_torch), (y_triton, y_torch)\n-\n-# %%\n-# As expected, the results are identical.\n-\n-# %%\n-# Benchmark\n-# -------------\n-# Here we will benchmark our operation as a function of the number of columns in the input matrix -- assuming 4096 rows.\n-# We will then compare its performance against (1) :code:`torch.softmax` and (2) the :code:`naive_softmax` defined above.\n-\n-\n-@triton.testing.perf_report(\n-    triton.testing.Benchmark(\n-        x_names=['N'],  # argument names to use as an x-axis for the plot\n-        x_vals=[\n-            128 * i for i in range(2, 100)\n-        ],  # different possible values for `x_name`\n-        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n-        line_vals=[\n-            'triton',\n-            'torch-native',\n-            'torch-jit',\n-        ],  # possible values for `line_arg``\n-        line_names=[\n-            \"Triton\",\n-            \"Torch (native)\",\n-            \"Torch (jit)\",\n-        ],  # label name for the lines\n-        styles=[('blue', '-'), ('green', '-'), ('green', '--')],  # line styles\n-        ylabel=\"GB/s\",  # label name for the y-axis\n-        plot_name=\"softmax-performance\",  # name for the plot. Used also as a file name for saving the plot.\n-        args={'M': 4096},  # values for function arguments not in `x_names` and `y_name`\n-    )\n-)\n-def benchmark(M, N, provider):\n-    x = torch.randn(M, N, device='cuda', dtype=torch.float32)\n-    if provider == 'torch-native':\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.softmax(x, axis=-1))\n-    if provider == 'triton':\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: softmax(x))\n-    if provider == 'torch-jit':\n-        ms, min_ms, max_ms = triton.testing.do_bench(lambda: naive_softmax(x))\n-    gbps = lambda ms: 2 * x.nelement() * x.element_size() * 1e-9 / (ms * 1e-3)\n-    return gbps(ms), gbps(max_ms), gbps(min_ms)\n-\n-\n-benchmark.run(show_plots=True, print_data=True)\n-\n-# %%\n-# In the above plot, we can see that:\n-#\n-#  - Triton is 4x faster than the Torch JIT. This confirms our suspicions that the Torch JIT does not do any fusion here.\n-#  - Triton is noticeably faster than :code:`torch.softmax` -- in addition to being **easier to read, understand and maintain**.\n-#    Note however that the PyTorch `softmax` operation is more general and will works on tensors of any shape."}, {"filename": "master/_downloads/f191ee1e78dc52eb5f7cba88f71cef2f/01-vector-add.ipynb", "status": "removed", "additions": 0, "deletions": 140, "changes": 140, "file_content_changes": "@@ -1,140 +0,0 @@\n-{\n-  \"cells\": [\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"%matplotlib inline\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"\\n# Vector Addition\\nIn this tutorial, you will write a simple vector addition using Triton and learn about:\\n\\n- The basic programming model of Triton\\n- The `triton.jit` decorator, which is used to define Triton kernels.\\n- The best practices for validating and benchmarking your custom ops against native reference implementations\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Compute Kernel\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"import torch\\n\\nimport triton\\nimport triton.language as tl\\n\\n\\n@triton.jit\\ndef add_kernel(\\n    x_ptr,  # *Pointer* to first input vector\\n    y_ptr,  # *Pointer* to second input vector\\n    output_ptr,  # *Pointer* to output vector\\n    n_elements,  # Size of the vector\\n    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\\n                 # NOTE: `constexpr` so it can be used as a shape value\\n):\\n    # There are multiple 'program's processing different data. We identify which program\\n    # we are here\\n    pid = tl.program_id(axis=0)  # We use a 1D launch grid so axis is 0\\n    # This program will process inputs that are offset from the initial data.\\n    # for instance, if you had a vector of length 256 and block_size of 64, the programs\\n    # would each access the elements [0:64, 64:128, 128:192, 192:256].\\n    # Note that offsets is a list of pointers\\n    block_start = pid * BLOCK_SIZE\\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\\n    # Create a mask to guard memory operations against out-of-bounds accesses\\n    mask = offsets < n_elements\\n    # Load x and y from DRAM, masking out any extra elements in case the input is not a\\n    # multiple of the block size\\n    x = tl.load(x_ptr + offsets, mask=mask)\\n    y = tl.load(y_ptr + offsets, mask=mask)\\n    output = x + y\\n    # Write x + y back to DRAM\\n    tl.store(output_ptr + offsets, output, mask=mask)\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"Let's also declare a helper function to (1) allocate the `z` tensor\\nand (2) enqueue the above kernel with appropriate grid/block sizes.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"def add(x: torch.Tensor, y: torch.Tensor):\\n    # We need to preallocate the output\\n    output = torch.empty_like(x)\\n    assert x.is_cuda and y.is_cuda and output.is_cuda\\n    n_elements = output.numel()\\n    # The SPMD launch grid denotes the number of kernel instances that run in parallel.\\n    # It is analogous to CUDA launch grids. It can be either Tuple[int], or Callable(metaparameters) -> Tuple[int]\\n    # In this case, we use a 1D grid where the size is the number of blocks\\n    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\\n    # NOTE:\\n    #  - each torch.tensor object is implicitly converted into a pointer to its first element.\\n    #  - `triton.jit`'ed functions can be index with a launch grid to obtain a callable GPU kernel\\n    #  - don't forget to pass meta-parameters as keywords arguments\\n    add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)\\n    # We return a handle to z but, since `torch.cuda.synchronize()` hasn't been called, the kernel is still\\n    # running asynchronously at this point.\\n    return output\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"We can now use the above function to compute the element-wise sum of two `torch.tensor` objects and test its correctness:\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"torch.manual_seed(0)\\nsize = 98432\\nx = torch.rand(size, device='cuda')\\ny = torch.rand(size, device='cuda')\\noutput_torch = x + y\\noutput_triton = add(x, y)\\nprint(output_torch)\\nprint(output_triton)\\nprint(\\n    f'The maximum difference between torch and triton is '\\n    f'{torch.max(torch.abs(output_torch - output_triton))}'\\n)\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"Seems like we're good to go!\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"## Benchmark\\nWe can now benchmark our custom op on vectors of increasing sizes to get a sense of how it does relative to PyTorch.\\nTo make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops\\nfor different problem sizes.\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"@triton.testing.perf_report(\\n    triton.testing.Benchmark(\\n        x_names=['size'],  # argument names to use as an x-axis for the plot\\n        x_vals=[\\n            2 ** i for i in range(12, 28, 1)\\n        ],  # different possible values for `x_name`\\n        x_log=True,  # x axis is logarithmic\\n        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\\n        line_vals=['triton', 'torch'],  # possible values for `line_arg`\\n        line_names=['Triton', 'Torch'],  # label name for the lines\\n        styles=[('blue', '-'), ('green', '-')],  # line styles\\n        ylabel='GB/s',  # label name for the y-axis\\n        plot_name='vector-add-performance',  # name for the plot. Used also as a file name for saving the plot.\\n        args={},  # values for function arguments not in `x_names` and `y_name`\\n    )\\n)\\ndef benchmark(size, provider):\\n    x = torch.rand(size, device='cuda', dtype=torch.float32)\\n    y = torch.rand(size, device='cuda', dtype=torch.float32)\\n    if provider == 'torch':\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: x + y)\\n    if provider == 'triton':\\n        ms, min_ms, max_ms = triton.testing.do_bench(lambda: add(x, y))\\n    gbps = lambda ms: 12 * size / ms * 1e-6\\n    return gbps(ms), gbps(max_ms), gbps(min_ms)\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"markdown\",\n-      \"metadata\": {},\n-      \"source\": [\n-        \"We can now run the decorated function above. Pass `print_data=True` to see the performance number, `show_plots=True` to plot them, and/or\\n`save_path='/path/to/results/' to save them to disk along with raw CSV data\\n\\n\"\n-      ]\n-    },\n-    {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": null,\n-      \"metadata\": {\n-        \"collapsed\": false\n-      },\n-      \"outputs\": [],\n-      \"source\": [\n-        \"benchmark.run(print_data=True, show_plots=True)\"\n-      ]\n-    }\n-  ],\n-  \"metadata\": {\n-    \"kernelspec\": {\n-      \"display_name\": \"Python 3\",\n-      \"language\": \"python\",\n-      \"name\": \"python3\"\n-    },\n-    \"language_info\": {\n-      \"codemirror_mode\": {\n-        \"name\": \"ipython\",\n-        \"version\": 3\n-      },\n-      \"file_extension\": \".py\",\n-      \"mimetype\": \"text/x-python\",\n-      \"name\": \"python\",\n-      \"nbconvert_exporter\": \"python\",\n-      \"pygments_lexer\": \"ipython3\",\n-      \"version\": \"3.8.10\"\n-    }\n-  },\n-  \"nbformat\": 4,\n-  \"nbformat_minor\": 0\n-}\n\\ No newline at end of file"}, {"filename": "master/_images/cuda-parallel-matmul.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/grouped_vs_row_major_ordering.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/halide-iteration.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/polyhedral-iteration.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_01-vector-add_001.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_01-vector-add_thumb.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_02-fused-softmax_001.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_02-fused-softmax_thumb.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_03-matrix-multiplication_001.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_03-matrix-multiplication_thumb.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_04-low-memory-dropout_thumb.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_05-layer-norm_001.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/sphx_glr_05-layer-norm_thumb.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_images/triton-parallel-matmul.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_sources/getting-started/installation.rst.txt", "status": "removed", "additions": 0, "deletions": 55, "changes": 55, "file_content_changes": "@@ -1,55 +0,0 @@\n-==============\n-Installation\n-==============\n-\n----------------------\n-Binary Distributions\n----------------------\n-\n-You can install the latest stable release of Triton from pip:\n-\n-.. code-block:: bash\n-\n-      pip install triton\n-\n-Binary wheels are available for CPython 3.6-3.9 and PyPy 3.6-3.7.\n-\n-And the latest nightly release:\n-\n-.. code-block:: bash\n-  \n-      pip install -U --pre triton\n-\n-\n---------------\n-From Source\n---------------\n-\n-+++++++++++++++\n-Python Package\n-+++++++++++++++\n-\n-You can install the Python package from source by running the following commands:\n-\n-.. code-block:: bash\n-\n-      git clone https://github.com/openai/triton.git;\n-      cd triton/python;\n-      pip install cmake; # build time dependency\n-      pip install -e .\n-\n-Note that, if llvm-11 is not present on your system, the setup.py script will download the official LLVM11 static libraries link against that.\n-\n-You can then test your installation by running the unit tests:\n-\n-.. code-block:: bash\n-\n-      pip install -e '.[tests]'\n-      pytest -vs test/unit/\n-\n-and the benchmarks\n-\n-.. code-block:: bash\n-      \n-      cd bench/\n-      python -m run --with-plots --result-dir /tmp/triton-bench"}, {"filename": "master/_sources/getting-started/tutorials/01-vector-add.rst.txt", "status": "removed", "additions": 0, "deletions": 286, "changes": 286, "file_content_changes": "@@ -1,286 +0,0 @@\n-\n-.. DO NOT EDIT.\n-.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.\n-.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:\n-.. \"getting-started/tutorials/01-vector-add.py\"\n-.. LINE NUMBERS ARE GIVEN BELOW.\n-\n-.. only:: html\n-\n-    .. note::\n-        :class: sphx-glr-download-link-note\n-\n-        Click :ref:`here <sphx_glr_download_getting-started_tutorials_01-vector-add.py>`\n-        to download the full example code\n-\n-.. rst-class:: sphx-glr-example-title\n-\n-.. _sphx_glr_getting-started_tutorials_01-vector-add.py:\n-\n-\n-Vector Addition\n-=================\n-In this tutorial, you will write a simple vector addition using Triton and learn about:\n-\n-- The basic programming model of Triton\n-- The `triton.jit` decorator, which is used to define Triton kernels.\n-- The best practices for validating and benchmarking your custom ops against native reference implementations\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 12-14\n-\n-Compute Kernel\n---------------------------\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 14-50\n-\n-.. code-block:: default\n-\n-\n-    import torch\n-\n-    import triton\n-    import triton.language as tl\n-\n-\n-    @triton.jit\n-    def add_kernel(\n-        x_ptr,  # *Pointer* to first input vector\n-        y_ptr,  # *Pointer* to second input vector\n-        output_ptr,  # *Pointer* to output vector\n-        n_elements,  # Size of the vector\n-        BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n-                     # NOTE: `constexpr` so it can be used as a shape value\n-    ):\n-        # There are multiple 'program's processing different data. We identify which program\n-        # we are here\n-        pid = tl.program_id(axis=0)  # We use a 1D launch grid so axis is 0\n-        # This program will process inputs that are offset from the initial data.\n-        # for instance, if you had a vector of length 256 and block_size of 64, the programs\n-        # would each access the elements [0:64, 64:128, 128:192, 192:256].\n-        # Note that offsets is a list of pointers\n-        block_start = pid * BLOCK_SIZE\n-        offsets = block_start + tl.arange(0, BLOCK_SIZE)\n-        # Create a mask to guard memory operations against out-of-bounds accesses\n-        mask = offsets < n_elements\n-        # Load x and y from DRAM, masking out any extra elements in case the input is not a\n-        # multiple of the block size\n-        x = tl.load(x_ptr + offsets, mask=mask)\n-        y = tl.load(y_ptr + offsets, mask=mask)\n-        output = x + y\n-        # Write x + y back to DRAM\n-        tl.store(output_ptr + offsets, output, mask=mask)\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 51-53\n-\n-Let's also declare a helper function to (1) allocate the `z` tensor\n-and (2) enqueue the above kernel with appropriate grid/block sizes.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 53-74\n-\n-.. code-block:: default\n-\n-\n-\n-    def add(x: torch.Tensor, y: torch.Tensor):\n-        # We need to preallocate the output\n-        output = torch.empty_like(x)\n-        assert x.is_cuda and y.is_cuda and output.is_cuda\n-        n_elements = output.numel()\n-        # The SPMD launch grid denotes the number of kernel instances that run in parallel.\n-        # It is analogous to CUDA launch grids. It can be either Tuple[int], or Callable(metaparameters) -> Tuple[int]\n-        # In this case, we use a 1D grid where the size is the number of blocks\n-        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-        # NOTE:\n-        #  - each torch.tensor object is implicitly converted into a pointer to its first element.\n-        #  - `triton.jit`'ed functions can be index with a launch grid to obtain a callable GPU kernel\n-        #  - don't forget to pass meta-parameters as keywords arguments\n-        add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)\n-        # We return a handle to z but, since `torch.cuda.synchronize()` hasn't been called, the kernel is still\n-        # running asynchronously at this point.\n-        return output\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 75-76\n-\n-We can now use the above function to compute the element-wise sum of two `torch.tensor` objects and test its correctness:\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 76-90\n-\n-.. code-block:: default\n-\n-\n-    torch.manual_seed(0)\n-    size = 98432\n-    x = torch.rand(size, device='cuda')\n-    y = torch.rand(size, device='cuda')\n-    output_torch = x + y\n-    output_triton = add(x, y)\n-    print(output_torch)\n-    print(output_triton)\n-    print(\n-        f'The maximum difference between torch and triton is '\n-        f'{torch.max(torch.abs(output_torch - output_triton))}'\n-    )\n-\n-\n-\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    tensor([1.3713, 1.3076, 0.4940,  ..., 0.6724, 1.2141, 0.9733], device='cuda:0')\n-    tensor([1.3713, 1.3076, 0.4940,  ..., 0.6724, 1.2141, 0.9733], device='cuda:0')\n-    The maximum difference between torch and triton is 0.0\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 91-92\n-\n-Seems like we're good to go!\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 94-99\n-\n-Benchmark\n------------\n-We can now benchmark our custom op on vectors of increasing sizes to get a sense of how it does relative to PyTorch.\n-To make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops\n-for different problem sizes.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 99-128\n-\n-.. code-block:: default\n-\n-\n-\n-    @triton.testing.perf_report(\n-        triton.testing.Benchmark(\n-            x_names=['size'],  # argument names to use as an x-axis for the plot\n-            x_vals=[\n-                2 ** i for i in range(12, 28, 1)\n-            ],  # different possible values for `x_name`\n-            x_log=True,  # x axis is logarithmic\n-            line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n-            line_vals=['triton', 'torch'],  # possible values for `line_arg`\n-            line_names=['Triton', 'Torch'],  # label name for the lines\n-            styles=[('blue', '-'), ('green', '-')],  # line styles\n-            ylabel='GB/s',  # label name for the y-axis\n-            plot_name='vector-add-performance',  # name for the plot. Used also as a file name for saving the plot.\n-            args={},  # values for function arguments not in `x_names` and `y_name`\n-        )\n-    )\n-    def benchmark(size, provider):\n-        x = torch.rand(size, device='cuda', dtype=torch.float32)\n-        y = torch.rand(size, device='cuda', dtype=torch.float32)\n-        if provider == 'torch':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: x + y)\n-        if provider == 'triton':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: add(x, y))\n-        gbps = lambda ms: 12 * size / ms * 1e-6\n-        return gbps(ms), gbps(max_ms), gbps(min_ms)\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 129-131\n-\n-We can now run the decorated function above. Pass `print_data=True` to see the performance number, `show_plots=True` to plot them, and/or\n-`save_path='/path/to/results/' to save them to disk along with raw CSV data\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 131-132\n-\n-.. code-block:: default\n-\n-    benchmark.run(print_data=True, show_plots=True)\n-\n-\n-\n-.. image:: /getting-started/tutorials/images/sphx_glr_01-vector-add_001.png\n-    :alt: 01 vector add\n-    :class: sphx-glr-single-img\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    vector-add-performance:\n-               size      Triton       Torch\n-    0        4096.0    9.600000    9.600000\n-    1        8192.0   19.200000   19.200000\n-    2       16384.0   38.400001   38.400001\n-    3       32768.0   76.800002   76.800002\n-    4       65536.0  127.999995  127.999995\n-    5      131072.0  219.428568  219.428568\n-    6      262144.0  341.333321  384.000001\n-    7      524288.0  472.615390  472.615390\n-    8     1048576.0  614.400016  614.400016\n-    9     2097152.0  722.823517  722.823517\n-    10    4194304.0  780.190482  780.190482\n-    11    8388608.0  812.429770  812.429770\n-    12   16777216.0  833.084721  833.084721\n-    13   33554432.0  842.004273  842.004273\n-    14   67108864.0  847.448255  848.362445\n-    15  134217728.0  849.737435  850.656574\n-\n-\n-\n-\n-\n-.. rst-class:: sphx-glr-timing\n-\n-   **Total running time of the script:** ( 1 minutes  38.189 seconds)\n-\n-\n-.. _sphx_glr_download_getting-started_tutorials_01-vector-add.py:\n-\n-\n-.. only :: html\n-\n- .. container:: sphx-glr-footer\n-    :class: sphx-glr-footer-example\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-python\n-\n-     :download:`Download Python source code: 01-vector-add.py <01-vector-add.py>`\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-jupyter\n-\n-     :download:`Download Jupyter notebook: 01-vector-add.ipynb <01-vector-add.ipynb>`\n-\n-\n-.. only:: html\n-\n- .. rst-class:: sphx-glr-signature\n-\n-    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"}, {"filename": "master/_sources/getting-started/tutorials/02-fused-softmax.rst.txt", "status": "removed", "additions": 0, "deletions": 337, "changes": 337, "file_content_changes": "@@ -1,337 +0,0 @@\n-\n-.. DO NOT EDIT.\n-.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.\n-.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:\n-.. \"getting-started/tutorials/02-fused-softmax.py\"\n-.. LINE NUMBERS ARE GIVEN BELOW.\n-\n-.. only:: html\n-\n-    .. note::\n-        :class: sphx-glr-download-link-note\n-\n-        Click :ref:`here <sphx_glr_download_getting-started_tutorials_02-fused-softmax.py>`\n-        to download the full example code\n-\n-.. rst-class:: sphx-glr-example-title\n-\n-.. _sphx_glr_getting-started_tutorials_02-fused-softmax.py:\n-\n-\n-Fused Softmax\n-=================\n-In this tutorial, you will write a fused softmax operation that is significantly faster\n-than PyTorch's native op for a particular class of matrices: those whose rows can fit in\n-the GPU's SRAM.\n-You will learn about:\n-\n-- The benefits of kernel fusion for bandwidth-bound operations.\n-- Reduction operators in Triton.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 14-18\n-\n-Motivations\n-------------\n-Custom GPU kernels for elementwise additions are educationally valuable but won't get you very far in practice.\n-Let us consider instead the case of a simple (numerically stabilized) softmax operation:\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 18-46\n-\n-.. code-block:: default\n-\n-\n-    import torch\n-\n-    import triton\n-    import triton.language as tl\n-\n-\n-    @torch.jit.script\n-    def naive_softmax(x):\n-        \"\"\"Compute row-wise softmax of X using native pytorch\n-\n-        We subtract the maximum element in order to avoid overflows. Softmax is invariant to\n-        this shift.\n-        \"\"\"\n-        # read  MN elements ; write M  elements\n-        x_max = x.max(dim=1)[0]\n-        # read MN + M elements ; write MN elements\n-        z = x - x_max[:, None]\n-        # read  MN elements ; write MN elements\n-        numerator = torch.exp(z)\n-        # read  MN elements ; write M  elements\n-        denominator = numerator.sum(dim=1)\n-        # read MN + M elements ; write MN elements\n-        ret = numerator / denominator[:, None]\n-        # in total: read 5MN + 2M elements ; wrote 3MN + 2M elements\n-        return ret\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 47-55\n-\n-When implemented naively in PyTorch, computing :code:`y = naive_softmax(x)` for :math:`x \\in R^{M \\times N}`\n-requires reading :math:`5MN + 2M` elements from DRAM and writing back :math:`3MN + 2M` elements.\n-This is obviously wasteful; we'd prefer to have a custom \"fused\" kernel that only reads\n-X once and does all the necessary computations on-chip.\n-Doing so would require reading and writing back only :math:`MN` bytes, so we could\n-expect a theoretical speed-up of ~4x (i.e., :math:`(8MN + 4M) / 2MN`).\n-The `torch.jit.script` flags aims to perform this kind of \"kernel fusion\" automatically\n-but, as we will see later, it is still far from ideal.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 57-64\n-\n-Compute Kernel\n-----------------\n-Our softmax kernel works as follows: each program loads a row of the input matrix X,\n-normalizes it and writes back the result to the output Y.\n-Note that one important limitation of Triton is that each block must have a\n-power-of-two number of elements, so we need to internally \"pad\" each row and guard the\n-memory operations properly if we want to handle any possible input shapes:\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 64-93\n-\n-.. code-block:: default\n-\n-\n-\n-    @triton.jit\n-    def softmax_kernel(\n-        output_ptr, input_ptr, input_row_stride, output_row_stride, n_cols,\n-        BLOCK_SIZE: tl.constexpr\n-    ):\n-        # The rows of the softmax are independent, so we parallelize across those\n-        row_idx = tl.program_id(0)\n-        # The stride represents how much we need to increase the pointer to advance 1 row\n-        row_start_ptr = input_ptr + row_idx * input_row_stride\n-        # The block size is the next power of two greater than n_cols, so we can fit each\n-        # row in a single block\n-        col_offsets = tl.arange(0, BLOCK_SIZE)\n-        input_ptrs = row_start_ptr + col_offsets\n-        # Load the row into SRAM, using a mask since BLOCK_SIZE may be > than n_cols\n-        row = tl.load(input_ptrs, mask=col_offsets < n_cols, other=-float('inf'))\n-        # Substract maximum for numerical stability\n-        row_minus_max = row - tl.max(row, axis=0)\n-        # Note that exponentials in Triton are fast but approximate (i.e., think __expf in CUDA)\n-        numerator = tl.exp(row_minus_max)\n-        denominator = tl.sum(numerator, axis=0)\n-        softmax_output = numerator / denominator\n-        # Write back output to DRAM\n-        output_row_start_ptr = output_ptr + row_idx * output_row_stride\n-        output_ptrs = output_row_start_ptr + col_offsets\n-        tl.store(output_ptrs, softmax_output, mask=col_offsets < n_cols)\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 94-95\n-\n-We can create a helper function that enqueues the kernel and its (meta-)arguments for any given input tensor.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 95-125\n-\n-.. code-block:: default\n-\n-\n-    def softmax(x):\n-        n_rows, n_cols = x.shape\n-        # The block size is the smallest power of two greater than the number of columns in `x`\n-        BLOCK_SIZE = triton.next_power_of_2(n_cols)\n-        # Another trick we can use is to ask the compiler to use more threads per row by\n-        # increasing the number of warps (`num_warps`) over which each row is distributed.\n-        # You will see in the next tutorial how to auto-tune this value in a more natural\n-        # way so you don't have to come up with manual heuristics yourself.\n-        num_warps = 4\n-        if BLOCK_SIZE >= 2048:\n-            num_warps = 8\n-        if BLOCK_SIZE >= 4096:\n-            num_warps = 16\n-        # Allocate output\n-        y = torch.empty_like(x)\n-        # Enqueue kernel. The 1D launch grid is simple: we have one kernel instance per row o\n-        # f the input matrix\n-        softmax_kernel[(n_rows,)](\n-            y,\n-            x,\n-            x.stride(0),\n-            y.stride(0),\n-            n_cols,\n-            num_warps=num_warps,\n-            BLOCK_SIZE=BLOCK_SIZE,\n-        )\n-        return y\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 126-128\n-\n-Unit Test\n-----------\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 130-132\n-\n-We make sure that we test our kernel on a matrix with an irregular number of rows and columns.\n-This will allow us to verify that our padding mechanism works.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 132-139\n-\n-.. code-block:: default\n-\n-\n-    torch.manual_seed(0)\n-    x = torch.randn(1823, 781, device='cuda')\n-    y_triton = softmax(x)\n-    y_torch = torch.softmax(x, axis=1)\n-    assert torch.allclose(y_triton, y_torch), (y_triton, y_torch)\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 140-141\n-\n-As expected, the results are identical.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 143-147\n-\n-Benchmark\n--------------\n-Here we will benchmark our operation as a function of the number of columns in the input matrix -- assuming 4096 rows.\n-We will then compare its performance against (1) :code:`torch.softmax` and (2) the :code:`naive_softmax` defined above.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 147-186\n-\n-.. code-block:: default\n-\n-\n-\n-    @triton.testing.perf_report(\n-        triton.testing.Benchmark(\n-            x_names=['N'],  # argument names to use as an x-axis for the plot\n-            x_vals=[\n-                128 * i for i in range(2, 100)\n-            ],  # different possible values for `x_name`\n-            line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n-            line_vals=[\n-                'triton',\n-                'torch-native',\n-                'torch-jit',\n-            ],  # possible values for `line_arg``\n-            line_names=[\n-                \"Triton\",\n-                \"Torch (native)\",\n-                \"Torch (jit)\",\n-            ],  # label name for the lines\n-            styles=[('blue', '-'), ('green', '-'), ('green', '--')],  # line styles\n-            ylabel=\"GB/s\",  # label name for the y-axis\n-            plot_name=\"softmax-performance\",  # name for the plot. Used also as a file name for saving the plot.\n-            args={'M': 4096},  # values for function arguments not in `x_names` and `y_name`\n-        )\n-    )\n-    def benchmark(M, N, provider):\n-        x = torch.randn(M, N, device='cuda', dtype=torch.float32)\n-        if provider == 'torch-native':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.softmax(x, axis=-1))\n-        if provider == 'triton':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: softmax(x))\n-        if provider == 'torch-jit':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: naive_softmax(x))\n-        gbps = lambda ms: 2 * x.nelement() * x.element_size() * 1e-9 / (ms * 1e-3)\n-        return gbps(ms), gbps(max_ms), gbps(min_ms)\n-\n-\n-    benchmark.run(show_plots=True, print_data=True)\n-\n-\n-\n-\n-.. image:: /getting-started/tutorials/images/sphx_glr_02-fused-softmax_001.png\n-    :alt: 02 fused softmax\n-    :class: sphx-glr-single-img\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    softmax-performance:\n-              N      Triton  Torch (native)  Torch (jit)\n-    0     256.0  546.133347      546.133347   188.321838\n-    1     384.0  585.142862      585.142862   151.703707\n-    2     512.0  655.360017      606.814814   154.566038\n-    3     640.0  682.666684      640.000002   158.759699\n-    4     768.0  722.823517      664.216187   163.839992\n-    ..      ...         ...             ...          ...\n-    93  12160.0  814.058574      405.755985   198.631953\n-    94  12288.0  814.111783      415.661740   198.794749\n-    95  12416.0  814.163950      412.149375   198.457532\n-    96  12544.0  814.214963      412.971190   198.716830\n-    97  12672.0  814.265046      411.679167   198.776477\n-\n-    [98 rows x 4 columns]\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 187-192\n-\n-In the above plot, we can see that:\n-\n- - Triton is 4x faster than the Torch JIT. This confirms our suspicions that the Torch JIT does not do any fusion here.\n- - Triton is noticeably faster than :code:`torch.softmax` -- in addition to being **easier to read, understand and maintain**.\n-   Note however that the PyTorch `softmax` operation is more general and will works on tensors of any shape.\n-\n-\n-.. rst-class:: sphx-glr-timing\n-\n-   **Total running time of the script:** ( 3 minutes  22.664 seconds)\n-\n-\n-.. _sphx_glr_download_getting-started_tutorials_02-fused-softmax.py:\n-\n-\n-.. only :: html\n-\n- .. container:: sphx-glr-footer\n-    :class: sphx-glr-footer-example\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-python\n-\n-     :download:`Download Python source code: 02-fused-softmax.py <02-fused-softmax.py>`\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-jupyter\n-\n-     :download:`Download Jupyter notebook: 02-fused-softmax.ipynb <02-fused-softmax.ipynb>`\n-\n-\n-.. only:: html\n-\n- .. rst-class:: sphx-glr-signature\n-\n-    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"}, {"filename": "master/_sources/getting-started/tutorials/03-matrix-multiplication.rst.txt", "status": "removed", "additions": 0, "deletions": 529, "changes": 529, "file_content_changes": "@@ -1,529 +0,0 @@\n-\n-.. DO NOT EDIT.\n-.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.\n-.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:\n-.. \"getting-started/tutorials/03-matrix-multiplication.py\"\n-.. LINE NUMBERS ARE GIVEN BELOW.\n-\n-.. only:: html\n-\n-    .. note::\n-        :class: sphx-glr-download-link-note\n-\n-        Click :ref:`here <sphx_glr_download_getting-started_tutorials_03-matrix-multiplication.py>`\n-        to download the full example code\n-\n-.. rst-class:: sphx-glr-example-title\n-\n-.. _sphx_glr_getting-started_tutorials_03-matrix-multiplication.py:\n-\n-\n-Matrix Multiplication\n-======================\n-In this tutorial, you will write a 25-lines high-performance FP16 matrix multiplication\n-kernel that achieves performance on par with cuBLAS.\n-You will specifically learn about:\n-\n-- Block-level matrix multiplications\n-- Multi-dimensional pointer arithmetic\n-- Program re-ordering for improved L2 cache hit rate\n-- Automatic performance tuning\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 15-42\n-\n-Motivations\n--------------\n-Matrix multiplications are a key building block of most modern high-performance computing systems.\n-They are notoriously hard to optimize, hence their implementation is generally done by\n-hardware vendors themselves as part of so-called \"kernel libraries\" (e.g., cuBLAS).\n-Unfortunately, these libraries are often proprietary and cannot be easily customized\n-to accomodate the needs of modern deep learning workloads (e.g., fused activation functions).\n-In this tutorial, you will learn how to implement efficient matrix multiplications by\n-yourself with Triton, in a way that is easy to customize and extend.\n-\n-Roughly speaking, the kernel that we will write will implement the following blocked\n-algorithm to multiply a (M, K) by a (K, N) matrix:\n-\n- .. code-block:: python\n-\n-   # do in parallel\n-   for m in range(0, M, BLOCK_SIZE_M):\n-     # do in parallel\n-     for n in range(0, N, BLOCK_SIZE_N):\n-       acc = zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=float32)\n-       for k in range(0, K, BLOCK_SIZE_K):\n-         a = A[m : m+BLOCK_SIZE_M, k : k+BLOCK_SIZE_K]\n-         b = B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]\n-         acc += dot(a, b)\n-       C[m : m+BLOCK_SIZE_M, n : n+BLOCK_SIZE_N] = acc;\n-\n-where each iteration of the doubly-nested for-loop is performed by a dedicated Triton program instance.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 44-137\n-\n-Compute Kernel\n-----------------\n-\n-The above algorithm is, actually, fairly straightforward to implement in Triton.\n-The main difficulty comes from the computation of the memory locations at which blocks\n-of :code:`A` and :code:`B` must be read in the inner loop. For that, we need\n-multi-dimensional pointer arithmetics.\n-\n-Pointer Arithmetics\n-~~~~~~~~~~~~~~~~~~~~\n-\n-For a row-major 2D tensor :code:`X`, the memory location of :code:`X[i, j]` is given b\n-y :code:`&X[i, j] = X + i*stride_xi + j*stride_xj`.\n-Therefore, blocks of pointers for :code:`A[m : m+BLOCK_SIZE_M, k:k+BLOCK_SIZE_K]` and\n-:code:`B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]` can be defined in pseudo-code as:\n-\n- .. code-block:: python\n-\n-   &A[m : m+BLOCK_SIZE_M, k:k+BLOCK_SIZE_K] =  a_ptr + (m : m+BLOCK_SIZE_M)[:, None]*A.stride(0) + (k : k+BLOCK_SIZE_K)[None, :]*A.stride(1);\n-   &B[k : k+BLOCK_SIZE_K, n:n+BLOCK_SIZE_N] =  b_ptr + (k : k+BLOCK_SIZE_K)[:, None]*B.stride(0) + (n : n+BLOCK_SIZE_N)[None, :]*B.stride(1);\n-\n-Which means that pointers for blocks of A and B can be initialized (i.e., :code:`k=0`) in Triton as:\n-\n- .. code-block:: python\n-\n-   offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n-   offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-   offs_k = tl.arange(0, BLOCK_SIZE_K)\n-   a_ptrs = a_ptr + (offs_am[:, None]*stride_am + offs_k [None, :]*stride_ak)\n-   b_ptrs = b_ptr + (offs_k [:, None]*stride_bk + offs_bn[None, :]*stride_bn)\n-\n-And then updated in the inner loop as follows:\n-\n- .. code-block:: python\n-\n-   pa += BLOCK_SIZE_K * stride_ak;\n-   pb += BLOCK_SIZE_K * stride_bk;\n-\n-\n-L2 Cache Optimizations\n-~~~~~~~~~~~~~~~~~~~~~~~~\n-\n-As mentioned above, each program instance computes a :code:`[BLOCK_SIZE_M, BLOCK_SIZE_N]`\n-block of :code:`C`.\n-It is important to remember that the order in which these blocks are computed does\n-matter, since it affects the L2 cache hit rate of our program. and unfortunately, a\n-a simple row-major ordering\n-\n- .. code-block:: Python\n-\n-   pid = triton.program_id(0);\n-   grid_m = (M + BLOCK_SIZE_M - 1) // BLOCK_SIZE_M;\n-   grid_n = (N + BLOCK_SIZE_N - 1) // BLOCK_SIZE_N;\n-   pid_m = pid / grid_n;\n-   pid_n = pid % grid_n;\n-\n-is just not going to cut it.\n-\n-One possible solution is to launch blocks in an order that promotes data reuse.\n-This can be done by 'super-grouping' blocks in groups of :code:`GROUP_M` rows before\n-switching to the next column:\n-\n- .. code-block:: python\n-\n-   # program ID\n-   pid = tl.program_id(axis=0)\n-   # number of program ids along the M axis\n-   num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n-   # number of programs ids along the N axis\n-   num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n-   # number of programs in group\n-   num_pid_in_group = GROUP_SIZE_M * num_pid_n\n-   # id of the group this program is in\n-   group_id = pid // num_pid_in_group\n-   # row-id of the first program in the group\n-   first_pid_m = group_id * GROUP_SIZE_M\n-   # if `num_pid_m` isn't divisible by `GROUP_SIZE_M`, the last group is smaller\n-   group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n-   # *within groups*, programs are ordered in a column-major order\n-   # row-id of the program in the *launch grid*\n-   pid_m = first_pid_m + (pid % group_size_m)\n-   # col-id of the program in the *launch grid*\n-   pid_n = (pid % num_pid_in_group) // group_size_m\n-\n-For example, in the following matmul where each matrix is 9 blocks by 9 blocks,\n-we can see that if we compute the output in row-major ordering, we need to load 90\n-blocks into SRAM to compute the first 9 output blocks, but if we do it in grouped\n-ordering, we only need to load 54 blocks.\n-  .. image:: grouped_vs_row_major_ordering.png\n-\n-In practice, this can improve the performance of our matrix multiplication kernel by\n-more than 10\\% on some hardware architecture (e.g., 220 to 245 TFLOPS on A100).\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 139-142\n-\n-Final Result\n--------------\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 142-258\n-\n-.. code-block:: default\n-\n-\n-    import torch\n-\n-    import triton\n-    import triton.language as tl\n-\n-    # %\n-    # :code:`triton.jit`'ed functions can be auto-tuned by using the `triton.autotune`\n-    # decorator, which consumes:\n-    #   - A list of :code:`triton.Config` objects that define different configurations of\n-    #       meta-parameters (e.g., BLOCK_SIZE_M) and compilation options (e.g., num_warps) to try\n-    #   - An autotuning *key* whose change in values will trigger evaluation of all the\n-    #       provided configs\n-\n-\n-    @triton.autotune(\n-        configs=[\n-            triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n-            triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n-            triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-            triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-            triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-            triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-            triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-            triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n-            triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n-            triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n-        ],\n-        key=['M', 'N', 'K'],\n-    )\n-    @triton.jit\n-    def matmul_kernel(\n-        # Pointers to matrices\n-        a_ptr, b_ptr, c_ptr,\n-        # Matrix dimensions\n-        M, N, K,\n-        # The stride variables represent how much to increase the ptr by when moving by 1\n-        # element in a particular dimension. E.g. stride_am is how much to increase a_ptr\n-        # by to get the element one row down (A has M rows)\n-        stride_am, stride_ak,\n-        stride_bk, stride_bn,\n-        stride_cm, stride_cn,\n-        # Meta-parameters\n-        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n-        GROUP_SIZE_M: tl.constexpr,\n-        ACTIVATION: tl.constexpr,\n-    ):\n-        \"\"\"Kernel for computing the matmul C = A x B.\n-        A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n-        \"\"\"\n-        # -----------------------------------------------------------\n-        # Map program ids `pid` to the block of C it should compute.\n-        # This is done in a grouped ordering to promote L2 data reuse\n-        # See above `L2 Cache Optimizations` section for details\n-        pid = tl.program_id(axis=0)\n-        num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n-        num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n-        num_pid_in_group = GROUP_SIZE_M * num_pid_n\n-        group_id = pid // num_pid_in_group\n-        first_pid_m = group_id * GROUP_SIZE_M\n-        group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n-        pid_m = first_pid_m + (pid % group_size_m)\n-        pid_n = (pid % num_pid_in_group) // group_size_m\n-\n-        # ----------------------------------------------------------\n-        # Create pointers for the first blocks of A and B.\n-        # We will advance this pointer as we move in the K direction\n-        # and accumulate\n-        # a_ptrs is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\n-        # b_ptrs is a block of [BLOCK_SIZE_K, BLOCK_SIZE_n] pointers\n-        # see above `Pointer Arithmetics` section for details\n-        offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n-        offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-        offs_k = tl.arange(0, BLOCK_SIZE_K)\n-        a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n-        b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n-\n-        # -----------------------------------------------------------\n-        # Iterate to compute a block of the C matrix\n-        # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n-        # of fp32 values for higher accuracy.\n-        # `accumulator` will be converted back to fp16 after the loop\n-        accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n-        for k in range(0, K, BLOCK_SIZE_K):\n-            # Note that for simplicity, we don't apply a mask here.\n-            # This means that if K is not a multiple of BLOCK_SIZE_K,\n-            # this will access out-of-bounds memory and produce an\n-            # error or (worse!) incorrect results.\n-            a = tl.load(a_ptrs)\n-            b = tl.load(b_ptrs)\n-            # We accumulate along the K dimension\n-            accumulator += tl.dot(a, b)\n-            # Advance the ptrs to the next K block\n-            a_ptrs += BLOCK_SIZE_K * stride_ak\n-            b_ptrs += BLOCK_SIZE_K * stride_bk\n-        # you can fuse arbitrary activation functions here\n-        # while the accumulator is still in FP32!\n-        if ACTIVATION:\n-            accumulator = ACTIVATION(accumulator)\n-        c = accumulator.to(tl.float16)\n-\n-        # -----------------------------------------------------------\n-        # Write back the block of the output matrix C\n-        offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n-        offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-        c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n-        c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n-        tl.store(c_ptrs, c, mask=c_mask)\n-\n-\n-    # we can fuse `leaky_relu` by providing it as an `ACTIVATION` meta-parameter in `_matmul`\n-    @triton.jit\n-    def leaky_relu(x):\n-        return tl.where(x >= 0, x, 0.01 * x)\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 259-261\n-\n-We can now create a convenience wrapper function that only takes two input tensors\n-and (1) checks any shape constraint; (2) allocates the output; (3) launches the above kernel\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 261-290\n-\n-.. code-block:: default\n-\n-\n-\n-    def matmul(a, b, activation=None):\n-        # checks constraints\n-        assert a.shape[1] == b.shape[0], \"incompatible dimensions\"\n-        assert a.is_contiguous(), \"matrix A must be contiguous\"\n-        assert b.is_contiguous(), \"matrix B must be contiguous\"\n-        M, K = a.shape\n-        K, N = b.shape\n-        assert (\n-            K % 32 == 0\n-        ), \"We don't check memory-out-of-bounds with K so K must be divisible by BLOCK_SIZE_K\"\n-        # allocates output\n-        c = torch.empty((M, N), device=a.device, dtype=a.dtype)\n-        # 1D launch kernel where each block gets its own program.\n-        grid = lambda META: (\n-            triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\n-        )\n-        matmul_kernel[grid](\n-            a, b, c,\n-            M, N, K,\n-            a.stride(0), a.stride(1),\n-            b.stride(0), b.stride(1),\n-            c.stride(0), c.stride(1),\n-            ACTIVATION=activation,\n-        )\n-        return c\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 291-295\n-\n-Unit Test\n------------\n-\n-We can test our custom matrix multiplication operation against a native torch implementation (i.e., cuBLAS)\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 295-308\n-\n-.. code-block:: default\n-\n-\n-    torch.manual_seed(0)\n-    a = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n-    b = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n-    triton_output = matmul(a, b, activation=None)\n-    torch_output = torch.matmul(a, b)\n-    print(f\"triton_output={triton_output}\")\n-    print(f\"torch_output={torch_output}\")\n-    if triton.testing.allclose(triton_output, torch_output):\n-        print(\"\u2705 Triton and Torch match\")\n-    else:\n-        print(\"\u274c Triton and Torch differ\")\n-\n-\n-\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    triton_output=tensor([[  1.1045, -36.9688,  31.4688,  ..., -11.3984,  24.4531, -32.3438],\n-            [  6.3555, -19.6094,  34.0938,  ...,  -5.8945,   5.2891,   6.8867],\n-            [-32.0625,   5.9492,  15.3984,  ..., -21.3906, -23.9844, -10.1328],\n-            ...,\n-            [ -5.7031,   7.4492,   8.2656,  ..., -10.6953, -40.0000,  17.7500],\n-            [ 25.5000,  24.3281,  -8.4688,  ..., -18.9375,  32.5312, -29.9219],\n-            [ -5.3477,   4.9844,  11.8906,  ...,   5.5898,   6.4023, -17.3125]],\n-           device='cuda:0', dtype=torch.float16)\n-    torch_output=tensor([[  1.1045, -36.9688,  31.4688,  ..., -11.3906,  24.4531, -32.3438],\n-            [  6.3516, -19.6094,  34.0938,  ...,  -5.8906,   5.2812,   6.8828],\n-            [-32.0625,   5.9531,  15.3984,  ..., -21.4062, -23.9844, -10.1328],\n-            ...,\n-            [ -5.7070,   7.4492,   8.2656,  ..., -10.6953, -40.0000,  17.7500],\n-            [ 25.5000,  24.3438,  -8.4609,  ..., -18.9375,  32.5312, -29.9219],\n-            [ -5.3477,   4.9805,  11.8828,  ...,   5.5859,   6.4023, -17.3125]],\n-           device='cuda:0', dtype=torch.float16)\n-    \u2705 Triton and Torch match\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 309-315\n-\n-Benchmark\n---------------\n-\n-Square Matrix Performance\n-~~~~~~~~~~~~~~~~~~~~~~~~~~\n-We can now compare the performance of our kernel against that of cuBLAS. Here we focus on square matrices, but feel free to arrange this script as you wish to benchmark any other matrix shape.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 315-356\n-\n-.. code-block:: default\n-\n-\n-\n-    @triton.testing.perf_report(\n-        triton.testing.Benchmark(\n-            x_names=['M', 'N', 'K'],  # argument names to use as an x-axis for the plot\n-            x_vals=[\n-                128 * i for i in range(2, 33)\n-            ],  # different possible values for `x_name`\n-            line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n-            # possible values for `line_arg``\n-            line_vals=['cublas', 'cublas + relu', 'triton', 'triton + relu'],\n-            # label name for the lines\n-            line_names=[\"cuBLAS\", \"cuBLAS (+ torch.nn.LeakyReLU)\", \"Triton\", \"Triton (+ LeakyReLU)\"],\n-            # line styles\n-            styles=[('green', '-'), ('green', '--'), ('blue', '-'), ('blue', '--')],\n-            ylabel=\"TFLOPS\",  # label name for the y-axis\n-            plot_name=\"matmul-performance\",  # name for the plot. Used also as a file name for saving the plot.\n-            args={},\n-        )\n-    )\n-    def benchmark(M, N, K, provider):\n-        a = torch.randn((M, K), device='cuda', dtype=torch.float16)\n-        b = torch.randn((K, N), device='cuda', dtype=torch.float16)\n-        if provider == 'cublas':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(a, b))\n-        if provider == 'triton':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul(a, b))\n-        if provider == 'cublas + relu':\n-            torch_relu = torch.nn.ReLU(inplace=True)\n-            ms, min_ms, max_ms = triton.testing.do_bench(\n-                lambda: torch_relu(torch.matmul(a, b))\n-            )\n-        if provider == 'triton + relu':\n-            ms, min_ms, max_ms = triton.testing.do_bench(\n-                lambda: matmul(a, b, activation=leaky_relu)\n-            )\n-        perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n-        return perf(ms), perf(max_ms), perf(min_ms)\n-\n-\n-    benchmark.run(show_plots=True, print_data=True)\n-\n-\n-\n-.. image:: /getting-started/tutorials/images/sphx_glr_03-matrix-multiplication_001.png\n-    :alt: 03 matrix multiplication\n-    :class: sphx-glr-single-img\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    matmul-performance:\n-             M     cuBLAS  ...     Triton  Triton (+ LeakyReLU)\n-    0    256.0   2.978909  ...   3.276800              2.978909\n-    1    384.0   7.372800  ...   7.899428              8.507077\n-    2    512.0  14.563555  ...  16.384000             16.384000\n-    3    640.0  22.260869  ...  24.380953             24.380953\n-    4    768.0  32.768000  ...  35.389441             34.028308\n-    5    896.0  37.971025  ...  40.140799             39.025776\n-    6   1024.0  49.932191  ...  53.773130             52.428801\n-    7   1152.0  45.242181  ...  48.161033             47.396572\n-    8   1280.0  51.200001  ...  57.690139             57.690139\n-    9   1408.0  64.138541  ...  68.147202             67.305878\n-    10  1536.0  79.526831  ...  79.526831             79.526831\n-    11  1664.0  62.929456  ...  63.372618             62.929456\n-    12  1792.0  72.512412  ...  63.142831             62.790080\n-    13  1920.0  69.120002  ...  71.257735             70.892307\n-    14  2048.0  73.262953  ...  78.033565             77.672296\n-    15  2176.0  83.155572  ...  87.115360             86.739860\n-    16  2304.0  68.251065  ...  77.810656             77.810656\n-    17  2432.0  71.305746  ...  75.522751             75.320281\n-    18  2560.0  77.833728  ...  82.539044             82.125311\n-    19  2688.0  83.737433  ...  91.185232             90.748936\n-    20  2816.0  84.523664  ...  81.445766             84.523664\n-    21  2944.0  81.298583  ...  83.899046             84.040530\n-    22  3072.0  82.540970  ...  90.164177             89.735509\n-    23  3200.0  84.656085  ...  96.385543             96.240602\n-    24  3328.0  83.226931  ...  85.602017             84.249616\n-    25  3456.0  81.849303  ...  85.133652             84.864807\n-    26  3584.0  87.466332  ...  99.684470             99.354022\n-    27  3712.0  81.548851  ...  84.159518             87.706180\n-    28  3840.0  84.874902  ...  86.535214             91.398346\n-    29  3968.0  88.040360  ...  92.442373             86.480463\n-    30  4096.0  93.760204  ...  91.992956             90.871857\n-\n-    [31 rows x 5 columns]\n-\n-\n-\n-\n-\n-.. rst-class:: sphx-glr-timing\n-\n-   **Total running time of the script:** ( 6 minutes  30.096 seconds)\n-\n-\n-.. _sphx_glr_download_getting-started_tutorials_03-matrix-multiplication.py:\n-\n-\n-.. only :: html\n-\n- .. container:: sphx-glr-footer\n-    :class: sphx-glr-footer-example\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-python\n-\n-     :download:`Download Python source code: 03-matrix-multiplication.py <03-matrix-multiplication.py>`\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-jupyter\n-\n-     :download:`Download Jupyter notebook: 03-matrix-multiplication.ipynb <03-matrix-multiplication.ipynb>`\n-\n-\n-.. only:: html\n-\n- .. rst-class:: sphx-glr-signature\n-\n-    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"}, {"filename": "master/_sources/getting-started/tutorials/04-low-memory-dropout.rst.txt", "status": "removed", "additions": 0, "deletions": 271, "changes": 271, "file_content_changes": "@@ -1,271 +0,0 @@\n-\n-.. DO NOT EDIT.\n-.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.\n-.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:\n-.. \"getting-started/tutorials/04-low-memory-dropout.py\"\n-.. LINE NUMBERS ARE GIVEN BELOW.\n-\n-.. only:: html\n-\n-    .. note::\n-        :class: sphx-glr-download-link-note\n-\n-        Click :ref:`here <sphx_glr_download_getting-started_tutorials_04-low-memory-dropout.py>`\n-        to download the full example code\n-\n-.. rst-class:: sphx-glr-example-title\n-\n-.. _sphx_glr_getting-started_tutorials_04-low-memory-dropout.py:\n-\n-\n-Low-Memory Dropout\n-=================\n-\n-In this tutorial, you will write a memory-efficient implementation of dropout whose state\n-will be composed of a single int32 seed. This differs from more traditional implementations of dropout,\n-whose state is generally composed of a bit mask tensor of the same shape as the input. You will learn about:\n-\n-- The limitations of naive implementations of Dropout with PyTorch\n-- Parallel pseudo-random number generation in Triton\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 14-29\n-\n-Baseline\n--------------\n-The *dropout* operator was first introduced in [SRIVASTAVA2014]_ as a way to improve the performance\n-of deep neural networks in low-data regime (i.e. regularization).\n-\n-It takes a vector as input and produces a vector of the same shape as output. Each scalar in the\n-output has a probability :math:`p` of being changed to zero and otherwise it is copied from the input.\n-This forces the network to perform well even when only :math:`1 - p` scalars from the input are available.\n-\n-At evaluation time we want to use the full power of the network so we set :math:`p=0`. Naively this would\n-increase the norm of the output (which can be a bad thing, e.g. it can lead to artificial decrease\n-in the output softmax temperature). To prevent this we multiply the output by :math:`\\frac{1}{1 - p}`, which\n-keeps the norm consistent regardless of the dropout probability.\n-\n-Let's first take a look at the baseline implementation.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 29-82\n-\n-.. code-block:: default\n-\n-\n-\n-    import tabulate\n-    import torch\n-\n-    import triton\n-    import triton.language as tl\n-\n-\n-    @triton.jit\n-    def _dropout(\n-            x_ptr,  # pointer to the input\n-            x_keep_ptr,  # pointer to a mask of 0s and 1s\n-            output_ptr,  # pointer to the output\n-            n_elements,  # number of elements in the `x` tensor\n-            p,  # probability that an element of `x` is changed to zero\n-            BLOCK_SIZE: tl.constexpr,\n-    ):\n-        pid = tl.program_id(axis=0)\n-        block_start = pid * BLOCK_SIZE\n-        offsets = block_start + tl.arange(0, BLOCK_SIZE)\n-        mask = offsets < n_elements\n-        # Load data\n-        x = tl.load(x_ptr + offsets, mask=mask)\n-        x_keep = tl.load(x_keep_ptr + offsets, mask=mask)\n-        # The line below is the crucial part, described in the paragraph above!\n-        output = tl.where(x_keep, x / (1 - p), 0.0)\n-        # Write-back output\n-        tl.store(output_ptr + offsets, output, mask=mask)\n-\n-\n-    def dropout(x, x_keep, p):\n-        output = torch.empty_like(x)\n-        assert x.is_contiguous()\n-        n_elements = x.numel()\n-        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-        _dropout[grid](x, x_keep, output, n_elements, p, BLOCK_SIZE=1024)\n-        return output\n-\n-\n-    # Input tensor\n-    x = torch.randn(size=(10,)).cuda()\n-    # Dropout mask\n-    p = 0.5\n-    x_keep = (torch.rand(size=(10,)) > p).to(torch.int32).cuda()\n-    #\n-    output = dropout(x, x_keep=x_keep, p=p)\n-    print(tabulate.tabulate([\n-        [\"input\"] + x.tolist(),\n-        [\"keep mask\"] + x_keep.tolist(),\n-        [\"output\"] + output.tolist()\n-    ]))\n-\n-\n-\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    ---------  -------  ---------  --------  --------  --------  --------  --------  --------  ---------  ---------\n-    input      1.541    -0.293429  -2.17879  0.568431  -1.08452  -1.3986   0.403347  0.838026  -0.719258  -0.403344\n-    keep mask  1         1          0        1          0         1        1         0          0          0\n-    output     3.08199  -0.586858   0        1.13686    0        -2.79719  0.806694  0          0          0\n-    ---------  -------  ---------  --------  --------  --------  --------  --------  --------  ---------  ---------\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 83-101\n-\n-Seeded dropout\n--------------\n-Above implementation of dropout works fine, but it can be a bit awkward to deal with. Firstly\n-we need to store the dropout mask for backpropagation. Secondly, dropout state management can get\n-very tricky when using recompute/checkpointing (e.g. see all the notes about `preserve_rng_state` in\n-https://pytorch.org/docs/1.9.0/checkpoint.html). In this tutorial we'll describe an alternative implementation\n-that (1) has a smaller memory footprint; (2) requires less data movement; and (3) simplifies the management\n-of persisting randomness across multiple invocations of the kernel.\n-\n-Pseudorandom number generation in Triton is simple! In this tutorial we will use the\n-:code:`triton.language.rand` function which generates a block of uniformly distributed :code:`float32`\n-values in [0, 1), given a seed and a block of :code:`int32` offsets. But if you need it, Triton also provides\n-other :ref:`random number generation strategies <Random Number Generation>`.\n-\n-.. note::\n-   Triton's implementation of PRNG is based on the Philox algorithm (described on [SALMON2011]_).\n-\n-Let's put it all together.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 101-149\n-\n-.. code-block:: default\n-\n-\n-\n-    @triton.jit\n-    def _seeded_dropout(\n-            x_ptr,\n-            output_ptr,\n-            n_elements,\n-            p,\n-            seed,\n-            BLOCK_SIZE: tl.constexpr,\n-    ):\n-        # compute memory offsets of elements handled by this instance\n-        pid = tl.program_id(axis=0)\n-        block_start = pid * BLOCK_SIZE\n-        offsets = block_start + tl.arange(0, BLOCK_SIZE)\n-        # load data from x\n-        mask = offsets < n_elements\n-        x = tl.load(x_ptr + offsets, mask=mask)\n-        # randomly prune it\n-        random = tl.rand(seed, offsets)\n-        x_keep = random > p\n-        # write-back\n-        output = tl.where(x_keep, x / (1 - p), 0.0)\n-        tl.store(output_ptr + offsets, output, mask=mask)\n-\n-\n-    def seeded_dropout(x, p, seed):\n-        output = torch.empty_like(x)\n-        assert x.is_contiguous()\n-        n_elements = x.numel()\n-        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-        _seeded_dropout[grid](x, output, n_elements, p, seed, BLOCK_SIZE=1024)\n-        return output\n-\n-\n-    x = torch.randn(size=(10,)).cuda()\n-    # Compare this to the baseline - dropout mask is never instantiated!\n-    output = seeded_dropout(x, p=0.5, seed=123)\n-    output2 = seeded_dropout(x, p=0.5, seed=123)\n-    output3 = seeded_dropout(x, p=0.5, seed=512)\n-\n-    print(tabulate.tabulate([\n-        [\"input\"] + x.tolist(),\n-        [\"output (seed = 123)\"] + output.tolist(),\n-        [\"output (seed = 123)\"] + output2.tolist(),\n-        [\"output (seed = 512)\"] + output3.tolist()\n-    ]))\n-\n-\n-\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    -------------------  ---------  --------  --------  -------  --------  --------  ---------  ---------  ---------  ---------\n-    input                -0.952835  0.371721  0.408716  1.42142  0.149397  -0.67086  -0.214186  -0.431969  -0.707878  -0.106434\n-    output (seed = 123)   0         0.743443  0         0        0         -1.34172   0          0         -1.41576   -0.212868\n-    output (seed = 123)   0         0.743443  0         0        0         -1.34172   0          0         -1.41576   -0.212868\n-    output (seed = 512)   0         0         0.817432  2.84284  0         -1.34172  -0.428372   0          0          0\n-    -------------------  ---------  --------  --------  -------  --------  --------  ---------  ---------  ---------  ---------\n-\n-\n-\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 150-153\n-\n-Et Voil\u00e0! We have a triton kernel that applies the same dropout mask provided the seed is the same!\n-If you'd like explore further applications of pseudorandomness in GPU programming, we encourage you\n-to explore the `triton/language/random` folder!\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 155-160\n-\n-Exercises\n--------------\n-1. Extend the kernel to operate over a matrix and use a vector of seeds - one per row.\n-2. Add support for striding.\n-3. (challenge) Implement a kernel for sparse Johnson-Lindenstrauss transform which generates the projection matrix one the fly each time using a seed.\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 162-167\n-\n-References\n---------------\n-\n-.. [SALMON2011] John K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw, \"Parallel Random Numbers: As Easy as 1, 2, 3\", 2011\n-.. [SRIVASTAVA2014] Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov, \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\", JMLR 2014\n-\n-\n-.. rst-class:: sphx-glr-timing\n-\n-   **Total running time of the script:** ( 0 minutes  0.324 seconds)\n-\n-\n-.. _sphx_glr_download_getting-started_tutorials_04-low-memory-dropout.py:\n-\n-\n-.. only :: html\n-\n- .. container:: sphx-glr-footer\n-    :class: sphx-glr-footer-example\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-python\n-\n-     :download:`Download Python source code: 04-low-memory-dropout.py <04-low-memory-dropout.py>`\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-jupyter\n-\n-     :download:`Download Jupyter notebook: 04-low-memory-dropout.ipynb <04-low-memory-dropout.ipynb>`\n-\n-\n-.. only:: html\n-\n- .. rst-class:: sphx-glr-signature\n-\n-    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"}, {"filename": "master/_sources/getting-started/tutorials/05-layer-norm.rst.txt", "status": "removed", "additions": 0, "deletions": 370, "changes": 370, "file_content_changes": "@@ -1,370 +0,0 @@\n-\n-.. DO NOT EDIT.\n-.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.\n-.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:\n-.. \"getting-started/tutorials/05-layer-norm.py\"\n-.. LINE NUMBERS ARE GIVEN BELOW.\n-\n-.. only:: html\n-\n-    .. note::\n-        :class: sphx-glr-download-link-note\n-\n-        Click :ref:`here <sphx_glr_download_getting-started_tutorials_05-layer-norm.py>`\n-        to download the full example code\n-\n-.. rst-class:: sphx-glr-example-title\n-\n-.. _sphx_glr_getting-started_tutorials_05-layer-norm.py:\n-\n-\n-Layer Normalization\n-====================\n-\n-.. GENERATED FROM PYTHON SOURCE LINES 5-262\n-\n-\n-\n-.. image:: /getting-started/tutorials/images/sphx_glr_05-layer-norm_001.png\n-    :alt: 05 layer norm\n-    :class: sphx-glr-single-img\n-\n-\n-.. rst-class:: sphx-glr-script-out\n-\n- Out:\n-\n- .. code-block:: none\n-\n-    layer-norm-backward:\n-              N      Triton       Torch        Apex\n-    0    1024.0  361.411758   97.912354  303.407414\n-    1    1536.0  409.599994  134.540150  341.333333\n-    2    2048.0  491.520012  161.154101  323.368435\n-    3    2560.0  461.954908  181.238943  326.808501\n-    4    3072.0  515.580429  192.501302  320.556515\n-    5    3584.0  554.941930  208.271186  311.652167\n-    6    4096.0  561.737163  220.907859  294.323343\n-    7    4608.0  502.690905  232.825259  291.799469\n-    8    5120.0  525.128191  242.366855  289.129408\n-    9    5632.0  540.671974  243.107920  288.820505\n-    10   6144.0  546.133354  248.661056  286.322318\n-    11   6656.0  527.207907  256.000009  285.257135\n-    12   7168.0  503.017523  260.063480  285.293536\n-    13   7680.0  483.779539  262.938666  275.928134\n-    14   8192.0  463.698115  266.767970  284.526763\n-    15   8704.0  413.655443  267.472468  284.987724\n-    16   9216.0  427.822068  271.724806  288.375482\n-    17   9728.0  436.396262  280.615388  289.667485\n-    18  10240.0  446.025405  286.433562  290.153487\n-    19  10752.0  428.651173  246.935876  290.267711\n-    20  11264.0  426.397479  245.536784  286.980888\n-    21  11776.0  420.571432  249.667843  288.981596\n-    22  12288.0  416.542386  254.673582  294.617366\n-    23  12800.0  410.695192  253.884294  288.180121\n-    24  13312.0  409.075539  252.959629  290.443638\n-    25  13824.0  404.604870  257.390218  292.056329\n-    26  14336.0  394.116833  254.862216  286.959121\n-    27  14848.0  385.662341  257.852379  289.952797\n-    28  15360.0  380.433442  257.970599  286.433562\n-    29  15872.0  370.192407  261.626369  290.562936\n-\n-\n-\n-\n-\n-\n-|\n-\n-.. code-block:: default\n-\n-\n-    import torch\n-\n-    import triton\n-    import triton.language as tl\n-\n-    try:\n-        # This is https://github.com/NVIDIA/apex, NOT the apex on PyPi, so it\n-        # should not be added to extras_require in setup.py.\n-        import apex\n-        HAS_APEX = True\n-    except ModuleNotFoundError:\n-        HAS_APEX = False\n-\n-\n-    # Forward Pass\n-    @triton.jit\n-    def _layer_norm_fwd_fused(X, Y, W, B, M, V, stride, N, eps,\n-                              BLOCK_SIZE: tl.constexpr):\n-        # position of elements processed by this program\n-        row = tl.program_id(0)\n-        cols = tl.arange(0, BLOCK_SIZE)\n-        mask = cols < N\n-        # offset data pointers to start at the row of interest\n-        X += row * stride\n-        Y += row * stride\n-        # load data and cast to float32\n-        x = tl.load(X + cols, mask=mask, other=0).to(tl.float32)\n-        # compute mean\n-        mean = tl.sum(x, axis=0) / N\n-        # compute std\n-        xmean = tl.where(mask, x - mean, 0.)\n-        var = tl.sum(xmean * xmean, axis=0) / N\n-        rstd = 1 / tl.sqrt(var + eps)\n-        xhat = xmean * rstd\n-        # write-back mean/rstd\n-        tl.store(M + row, mean)\n-        tl.store(V + row, rstd)\n-        # multiply by weight and add bias\n-        w = tl.load(W + cols, mask=mask)\n-        b = tl.load(B + cols, mask=mask)\n-        y = xhat * w + b\n-        # write-back\n-        tl.store(Y + cols, y, mask=mask)\n-\n-\n-    # Backward pass (DX + partial DW + partial DB)\n-    @triton.jit\n-    def _layer_norm_bwd_dx_fused(DX, DY, DW, DB, X, W, B, M, V, Lock, stride, N, eps,\n-                                 GROUP_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr):\n-        # position of elements processed by this program\n-        row = tl.program_id(0)\n-        cols = tl.arange(0, BLOCK_SIZE_N)\n-        mask = cols < N\n-        # offset data pointers to start at the row of interest\n-        X += row * stride\n-        DY += row * stride\n-        DX += row * stride\n-        # offset locks and weight/bias gradient pointer\n-        # each kernel instance accumulates partial sums for\n-        # DW and DB into one of GROUP_SIZE_M independent buffers\n-        # these buffers stay in the L2, which allow this kernel\n-        # to be fast\n-        lock_id = row % GROUP_SIZE_M\n-        Lock += lock_id\n-        Count = Lock + GROUP_SIZE_M\n-        DW = DW + lock_id * N + cols\n-        DB = DB + lock_id * N + cols\n-        # load data to SRAM\n-        x = tl.load(X + cols, mask=mask, other=0).to(tl.float32)\n-        dy = tl.load(DY + cols, mask=mask, other=0).to(tl.float32)\n-        w = tl.load(W + cols, mask=mask).to(tl.float32)\n-        mean = tl.load(M + row)\n-        rstd = tl.load(V + row)\n-        # compute dx\n-        xhat = (x - mean) * rstd\n-        wdy = w * dy\n-        xhat = tl.where(mask, xhat, 0.)\n-        wdy = tl.where(mask, wdy, 0.)\n-        mean1 = tl.sum(xhat * wdy, axis=0) / N\n-        mean2 = tl.sum(wdy, axis=0) / N\n-        dx = (wdy - (xhat * mean1 + mean2)) * rstd\n-        # write-back dx\n-        tl.store(DX + cols, dx, mask=mask)\n-        # accumulate partial sums for dw/db\n-        partial_dw = (dy * xhat).to(w.dtype)\n-        partial_db = (dy).to(w.dtype)\n-        while tl.atomic_cas(Lock, 0, 1) == 1:\n-            pass\n-        count = tl.load(Count)\n-        # first store doesn't accumulate\n-        if count == 0:\n-            tl.atomic_xchg(Count, 1)\n-        else:\n-            partial_dw += tl.load(DW, mask=mask)\n-            partial_db += tl.load(DB, mask=mask)\n-        tl.store(DW, partial_dw, mask=mask)\n-        tl.store(DB, partial_db, mask=mask)\n-        # release lock\n-        tl.atomic_xchg(Lock, 0)\n-\n-    # Backward pass (total DW + total DB)\n-\n-\n-    @triton.jit\n-    def _layer_norm_bwd_dwdb(DW, DB, FINAL_DW, FINAL_DB, M, N,\n-                             BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr):\n-        pid = tl.program_id(0)\n-        cols = pid * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-        dw = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n-        db = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n-        for i in range(0, M, BLOCK_SIZE_M):\n-            rows = i + tl.arange(0, BLOCK_SIZE_M)\n-            mask = (rows[:, None] < M) & (cols[None, :] < N)\n-            offs = rows[:, None] * N + cols[None, :]\n-            dw += tl.load(DW + offs, mask=mask, other=0.)\n-            db += tl.load(DB + offs, mask=mask, other=0.)\n-        sum_dw = tl.sum(dw, axis=0)\n-        sum_db = tl.sum(db, axis=0)\n-        tl.store(FINAL_DW + cols, sum_dw, mask=cols < N)\n-        tl.store(FINAL_DB + cols, sum_db, mask=cols < N)\n-\n-\n-    class LayerNorm(torch.autograd.Function):\n-\n-        @staticmethod\n-        def forward(ctx, x, normalized_shape, weight, bias, eps):\n-            # allocate output\n-            y = torch.empty_like(x)\n-            # reshape input data into 2D tensor\n-            x_arg = x.reshape(-1, x.shape[-1])\n-            M, N = x_arg.shape\n-            mean = torch.empty((M, ), dtype=torch.float32, device='cuda')\n-            rstd = torch.empty((M, ), dtype=torch.float32, device='cuda')\n-            # Less than 64KB per feature: enqueue fused kernel\n-            MAX_FUSED_SIZE = 65536 // x.element_size()\n-            BLOCK_SIZE = min(MAX_FUSED_SIZE, triton.next_power_of_2(N))\n-            if N > BLOCK_SIZE:\n-                raise RuntimeError(\"This layer norm doesn't support feature dim >= 64KB.\")\n-            # heuristics for number of warps\n-            num_warps = min(max(BLOCK_SIZE // 256, 1), 8)\n-            # enqueue kernel\n-            _layer_norm_fwd_fused[(M,)](x_arg, y, weight, bias, mean, rstd,\n-                                        x_arg.stride(0), N, eps,\n-                                        BLOCK_SIZE=BLOCK_SIZE, num_warps=num_warps)\n-            ctx.save_for_backward(x, weight, bias, mean, rstd)\n-            ctx.BLOCK_SIZE = BLOCK_SIZE\n-            ctx.num_warps = num_warps\n-            ctx.eps = eps\n-            return y\n-\n-        @staticmethod\n-        def backward(ctx, dy):\n-            x, w, b, m, v = ctx.saved_tensors\n-            # heuristics for amount of parallel reduction stream for DG/DB\n-            N = w.shape[0]\n-            GROUP_SIZE_M = 64\n-            if N <= 8192: GROUP_SIZE_M = 96\n-            if N <= 4096: GROUP_SIZE_M = 128\n-            if N <= 1024: GROUP_SIZE_M = 256\n-            # allocate output\n-            locks = torch.zeros(2 * GROUP_SIZE_M, dtype=torch.int32, device='cuda')\n-            _dw = torch.empty((GROUP_SIZE_M, w.shape[0]), dtype=x.dtype, device=w.device)\n-            _db = torch.empty((GROUP_SIZE_M, w.shape[0]), dtype=x.dtype, device=w.device)\n-            dw = torch.empty((w.shape[0],), dtype=w.dtype, device=w.device)\n-            db = torch.empty((w.shape[0],), dtype=w.dtype, device=w.device)\n-            dx = torch.empty_like(dy)\n-            # enqueue kernel using forward pass heuristics\n-            # also compute partial sums for DW and DB\n-            x_arg = x.reshape(-1, x.shape[-1])\n-            M, N = x_arg.shape\n-            _layer_norm_bwd_dx_fused[(M,)](dx, dy, _dw, _db, x, w, b, m, v, locks,\n-                                           x_arg.stride(0), N, ctx.eps,\n-                                           BLOCK_SIZE_N=ctx.BLOCK_SIZE,\n-                                           GROUP_SIZE_M=GROUP_SIZE_M,\n-                                           num_warps=ctx.num_warps)\n-            grid = lambda meta: [triton.cdiv(N, meta['BLOCK_SIZE_N'])]\n-            # accumulate partial sums in separate kernel\n-            _layer_norm_bwd_dwdb[grid](_dw, _db, dw, db, GROUP_SIZE_M, N,\n-                                       BLOCK_SIZE_M=32,\n-                                       BLOCK_SIZE_N=128)\n-            return dx, None, dw, db, None\n-\n-\n-    layer_norm = LayerNorm.apply\n-\n-\n-    def test_layer_norm(M, N, dtype, eps=1e-5, device='cuda'):\n-        # create data\n-        x_shape = (M, N)\n-        w_shape = (x_shape[-1], )\n-        weight = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-        bias = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-        x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device='cuda')\n-        dy = .1 * torch.randn_like(x)\n-        x.requires_grad_(True)\n-        # forward pass\n-        y_tri = layer_norm(x, w_shape, weight, bias, eps)\n-        y_ref = torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps).to(dtype)\n-        # backward pass (triton)\n-        y_tri.backward(dy, retain_graph=True)\n-        dx_tri, dw_tri, db_tri = [_.grad.clone() for _ in [x, weight, bias]]\n-        x.grad, weight.grad, bias.grad = None, None, None\n-        # backward pass (torch)\n-        y_ref.backward(dy, retain_graph=True)\n-        dx_ref, dw_ref, db_ref = [_.grad.clone() for _ in [x, weight, bias]]\n-        # compare\n-        triton.testing.assert_almost_equal(y_tri, y_ref)\n-        triton.testing.assert_almost_equal(dx_tri, dx_ref)\n-        triton.testing.assert_almost_equal(db_tri, db_ref, decimal=1)\n-        triton.testing.assert_almost_equal(dw_tri, dw_ref, decimal=1)\n-\n-\n-    @triton.testing.perf_report(\n-        triton.testing.Benchmark(\n-            x_names=['N'],\n-            x_vals=[512 * i for i in range(2, 32)],\n-            line_arg='provider',\n-            line_vals=['triton', 'torch'] + (['apex'] if HAS_APEX else []),\n-            line_names=['Triton', 'Torch'] + (['Apex'] if HAS_APEX else []),\n-            styles=[('blue', '-'), ('green', '-'), ('orange', '-')],\n-            ylabel='GB/s',\n-            plot_name='layer-norm-backward',\n-            args={'M': 4096, 'dtype': torch.float16, 'mode': 'backward'}\n-        )\n-    )\n-    def bench_layer_norm(M, N, dtype, provider, mode='backward', eps=1e-5, device='cuda'):\n-        # create data\n-        x_shape = (M, N)\n-        w_shape = (x_shape[-1], )\n-        weight = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-        bias = torch.rand(w_shape, dtype=dtype, device='cuda', requires_grad=True)\n-        x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device='cuda')\n-        dy = .1 * torch.randn_like(x)\n-        x.requires_grad_(True)\n-        # utility functions\n-        if provider == 'triton':\n-            y_fwd = lambda: layer_norm(x, w_shape, weight, bias, eps)\n-        if provider == 'torch':\n-            y_fwd = lambda: torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps)\n-        if provider == 'apex':\n-            apex_layer_norm = apex.normalization.FusedLayerNorm(w_shape).to(x.device).to(x.dtype)\n-            y_fwd = lambda: apex_layer_norm(x)\n-        # forward pass\n-        if mode == 'forward':\n-            gbps = lambda ms: 2 * x.numel() * x.element_size() / ms * 1e-6\n-            ms, min_ms, max_ms = triton.testing.do_bench(y_fwd, rep=500)\n-        # backward pass\n-        if mode == 'backward':\n-            gbps = lambda ms: 3 * x.numel() * x.element_size() / ms * 1e-6\n-            y = y_fwd()\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: y.backward(dy, retain_graph=True),\n-                                                         grad_to_none=[x], rep=500)\n-        return gbps(ms), gbps(max_ms), gbps(min_ms)\n-\n-\n-    bench_layer_norm.run(save_path='.', print_data=True)\n-\n-\n-.. rst-class:: sphx-glr-timing\n-\n-   **Total running time of the script:** ( 2 minutes  14.541 seconds)\n-\n-\n-.. _sphx_glr_download_getting-started_tutorials_05-layer-norm.py:\n-\n-\n-.. only :: html\n-\n- .. container:: sphx-glr-footer\n-    :class: sphx-glr-footer-example\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-python\n-\n-     :download:`Download Python source code: 05-layer-norm.py <05-layer-norm.py>`\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-jupyter\n-\n-     :download:`Download Jupyter notebook: 05-layer-norm.ipynb <05-layer-norm.ipynb>`\n-\n-\n-.. only:: html\n-\n- .. rst-class:: sphx-glr-signature\n-\n-    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"}, {"filename": "master/_sources/getting-started/tutorials/index.rst.txt", "status": "removed", "additions": 0, "deletions": 152, "changes": 152, "file_content_changes": "@@ -1,152 +0,0 @@\n-:orphan:\n-\n-\n-\n-.. _sphx_glr_getting-started_tutorials:\n-\n-Tutorials\n-==================\n-\n-Below is a gallery of tutorials for writing various basic operations with Triton. It is recommended that you read through the tutorials in order, starting with the simplest one.\n-\n-To install the dependencies for the tutorials:\n-\n-.. code-block:: bash\n-\n-    cd triton\n-    pip install -e './python[tutorials]'\n-\n-\n-\n-.. raw:: html\n-\n-    <div class=\"sphx-glr-thumbcontainer\" tooltip=\"- The basic programming model of Triton - The triton.jit decorator, which is used to define Tri...\">\n-\n-.. only:: html\n-\n- .. figure:: /getting-started/tutorials/images/thumb/sphx_glr_01-vector-add_thumb.png\n-     :alt: Vector Addition\n-\n-     :ref:`sphx_glr_getting-started_tutorials_01-vector-add.py`\n-\n-.. raw:: html\n-\n-    </div>\n-\n-\n-.. toctree::\n-   :hidden:\n-\n-   /getting-started/tutorials/01-vector-add\n-\n-.. raw:: html\n-\n-    <div class=\"sphx-glr-thumbcontainer\" tooltip=\"- The benefits of kernel fusion for bandwidth-bound operations. - Reduction operators in Triton...\">\n-\n-.. only:: html\n-\n- .. figure:: /getting-started/tutorials/images/thumb/sphx_glr_02-fused-softmax_thumb.png\n-     :alt: Fused Softmax\n-\n-     :ref:`sphx_glr_getting-started_tutorials_02-fused-softmax.py`\n-\n-.. raw:: html\n-\n-    </div>\n-\n-\n-.. toctree::\n-   :hidden:\n-\n-   /getting-started/tutorials/02-fused-softmax\n-\n-.. raw:: html\n-\n-    <div class=\"sphx-glr-thumbcontainer\" tooltip=\"- Block-level matrix multiplications - Multi-dimensional pointer arithmetic - Program re-orderi...\">\n-\n-.. only:: html\n-\n- .. figure:: /getting-started/tutorials/images/thumb/sphx_glr_03-matrix-multiplication_thumb.png\n-     :alt: Matrix Multiplication\n-\n-     :ref:`sphx_glr_getting-started_tutorials_03-matrix-multiplication.py`\n-\n-.. raw:: html\n-\n-    </div>\n-\n-\n-.. toctree::\n-   :hidden:\n-\n-   /getting-started/tutorials/03-matrix-multiplication\n-\n-.. raw:: html\n-\n-    <div class=\"sphx-glr-thumbcontainer\" tooltip=\"In this tutorial, you will write a memory-efficient implementation of dropout whose state will ...\">\n-\n-.. only:: html\n-\n- .. figure:: /getting-started/tutorials/images/thumb/sphx_glr_04-low-memory-dropout_thumb.png\n-     :alt: Low-Memory Dropout\n-\n-     :ref:`sphx_glr_getting-started_tutorials_04-low-memory-dropout.py`\n-\n-.. raw:: html\n-\n-    </div>\n-\n-\n-.. toctree::\n-   :hidden:\n-\n-   /getting-started/tutorials/04-low-memory-dropout\n-\n-.. raw:: html\n-\n-    <div class=\"sphx-glr-thumbcontainer\" tooltip=\"Layer Normalization\">\n-\n-.. only:: html\n-\n- .. figure:: /getting-started/tutorials/images/thumb/sphx_glr_05-layer-norm_thumb.png\n-     :alt: Layer Normalization\n-\n-     :ref:`sphx_glr_getting-started_tutorials_05-layer-norm.py`\n-\n-.. raw:: html\n-\n-    </div>\n-\n-\n-.. toctree::\n-   :hidden:\n-\n-   /getting-started/tutorials/05-layer-norm\n-.. raw:: html\n-\n-    <div class=\"sphx-glr-clear\"></div>\n-\n-\n-\n-.. only :: html\n-\n- .. container:: sphx-glr-footer\n-    :class: sphx-glr-footer-gallery\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-python\n-\n-    :download:`Download all examples in Python source code: tutorials_python.zip </getting-started/tutorials/tutorials_python.zip>`\n-\n-\n-\n-  .. container:: sphx-glr-download sphx-glr-download-jupyter\n-\n-    :download:`Download all examples in Jupyter notebooks: tutorials_jupyter.zip </getting-started/tutorials/tutorials_jupyter.zip>`\n-\n-\n-.. only:: html\n-\n- .. rst-class:: sphx-glr-signature\n-\n-    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"}, {"filename": "master/_sources/getting-started/tutorials/sg_execution_times.rst.txt", "status": "removed", "additions": 0, "deletions": 20, "changes": 20, "file_content_changes": "@@ -1,20 +0,0 @@\n-\n-:orphan:\n-\n-.. _sphx_glr_getting-started_tutorials_sg_execution_times:\n-\n-Computation times\n-=================\n-**13:45.813** total execution time for **getting-started_tutorials** files:\n-\n-+---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_03-matrix-multiplication.py` (``03-matrix-multiplication.py``) | 06:30.096 | 0.0 MB |\n-+---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_02-fused-softmax.py` (``02-fused-softmax.py``)                 | 03:22.664 | 0.0 MB |\n-+---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_05-layer-norm.py` (``05-layer-norm.py``)                       | 02:14.541 | 0.0 MB |\n-+---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_01-vector-add.py` (``01-vector-add.py``)                       | 01:38.189 | 0.0 MB |\n-+---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_04-low-memory-dropout.py` (``04-low-memory-dropout.py``)       | 00:00.324 | 0.0 MB |\n-+---------------------------------------------------------------------------------------------------------+-----------+--------+"}, {"filename": "master/_sources/index.rst.txt", "status": "removed", "additions": 0, "deletions": 52, "changes": 52, "file_content_changes": "@@ -1,52 +0,0 @@\n-Welcome to Triton's documentation!\n-==================================\n-\n-Triton is a language and compiler for parallel programming. It aims to provide a Python-based programming environment for productively writing custom DNN compute kernels capable of running at maximal throughput on modern GPU hardware.\n-\n-Getting Started\n----------------\n-\n-- Follow the :doc:`installation instructions <getting-started/installation>` for your platform of choice.\n-- Take a look at the :doc:`tutorials <getting-started/tutorials/index>` to learn how to write your first Triton program.\n-\n-.. toctree::\n-   :maxdepth: 1\n-   :caption: Getting Started\n-   :hidden:\n-\n-   getting-started/installation\n-   getting-started/tutorials/index\n-\n-Python API\n--------------------\n-\n-- :doc:`triton <python-api/triton>`\n-- :doc:`triton.language <python-api/triton.language>`\n-- :doc:`triton.testing <python-api/triton.testing>`\n-\n-\n-.. toctree::\n-   :maxdepth: 1\n-   :caption: Python API\n-   :hidden:\n-\n-   python-api/triton\n-   python-api/triton.language\n-   python-api/triton.testing\n-\n-   \n-Going Further\n-------------------\n-\n-Check out the following documents to learn more about Triton and how it compares against other DSLs for DNNs:\n-\n-- Chapter 1: :doc:`Introduction <programming-guide/chapter-1/introduction>`\n-- Chapter 2: :doc:`Related Work <programming-guide/chapter-2/related-work>`\n-\n-.. toctree::\n-   :maxdepth: 1\n-   :caption: Programming Guide\n-   :hidden:\n-\n-   programming-guide/chapter-1/introduction\n-   programming-guide/chapter-2/related-work"}, {"filename": "master/_sources/programming-guide/chapter-1/introduction.rst.txt", "status": "removed", "additions": 0, "deletions": 69, "changes": 69, "file_content_changes": "@@ -1,69 +0,0 @@\n-==============\n-Introduction\n-==============\n-\n---------------\n-Motivations\n---------------\n-\n-Over the past decade, Deep Neural Networks (DNNs) have emerged as an important class of Machine Learning (ML) models, capable of  achieving state-of-the-art performance across many domains ranging from natural language processing [SUTSKEVER2014]_ to computer vision [REDMON2016]_ to computational neuroscience [LEE2017]_. The strength of these models lies in their hierarchical structure, composed of a sequence of parametric (e.g., convolutional) and non-parametric (e.g., rectified linearity) *layers*. This pattern, though notoriously computationally expensive, also generates a large amount of highly parallelizable work particularly well suited for multi- and many- core processors.\n-\n-As a consequence, Graphics Processing Units (GPUs) have become a cheap and accessible resource for exploring and/or deploying novel research ideas in the field. This trend has been accelerated by the release of several frameworks for General-Purpose GPU (GPGPU) computing, such as CUDA and OpenCL, which have made the development of high-performance programs easier. Yet, GPUs remain incredibly challenging to optimize for locality and parallelism, especially for computations that cannot be efficiently implemented using a combination of pre-existing optimized primitives. To make matters worse, GPU architectures are also rapidly evolving and specializing, as evidenced by the addition of tensor cores to NVIDIA (and more recently AMD) micro-architectures.\n-\n-This tension between the computational opportunities offered by DNNs and the practical difficulty of GPU programming has created substantial academic and industrial interest for Domain-Specific Languages (DSLs) and compilers. Regrettably, these systems -- whether they be based on  polyhedral machinery (*e.g.*, Tiramisu [BAGHDADI2021]_, Tensor Comprehensions [VASILACHE2018]_) or scheduling languages (*e.g.*, Halide [JRK2013]_, TVM [CHEN2018]_) -- remain less flexible and (for the same algorithm) markedly slower than the best handwritten compute kernels available in libraries like `cuBLAS <https://docs.nvidia.com/cuda/cublas/index.html>`_, `cuDNN <https://docs.nvidia.com/deeplearning/cudnn/api/index.html>`_ or `TensorRT <https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html>`_.\n-\n-The main premise of this project is the following: programming paradigms based on blocked algorithms [LAM1991]_ can facilitate the construction of high-performance compute kernels for neural networks.  We specifically revisit traditional \"Single Program, Multiple Data\" (SPMD [AUGUIN1983]_) execution models for GPUs, and propose a variant in which programs -- rather than threads -- are blocked. For example, in the case of matrix multiplication, CUDA and Triton differ as follows:\n-\n-.. table::\n-    :widths: 50 50\n-\n-    +-----------------------------------------------------+-----------------------------------------------------+\n-    | CUDA Programming Model                              | Triton Programming Model                            |\n-    |                                                     |                                                     |\n-    | (Scalar Program, Blocked Threads)                   | (Blocked Program, Scalar Threads)                   |\n-    +=====================================================+=====================================================+\n-    |                                                     |                                                     |\n-    |.. code-block:: C                                    |.. code-block:: C                                    |\n-    |                                                     |   :force:                                           |\n-    |                                                     |                                                     |\n-    |   #pragma parallel                                  |   #pragma parallel                                  |\n-    |   for(int m = 0; i < M; m++)                        |   for(int m = 0; m < M; m += MB)                    |\n-    |   #pragma parallel                                  |   #pragma parallel                                  |\n-    |   for(int n = 0; j < N; n++){                       |   for(int n = 0; n < N; n += NB){                   |\n-    |     float acc = 0;                                  |     float acc[MB, NB] = 0;                          |\n-    |     for(int k = 0; k < K;k ++)                      |     for(int k = 0; k < K; k += KB)                  |\n-    |       acc += A[i, k]* B[k, j];                      |       acc +=  A[m:m+MB, k:k+KB]                     |\n-    |                                                     |             @ B[k:k+KB, n:n+NB];                    |\n-    |     C[i, j] = acc;                                  |     C[m:m+MB, n:n+NB] = acc;                        |\n-    |   }                                                 |   }                                                 |\n-    |                                                     |                                                     |\n-    +-----------------------------------------------------+-----------------------------------------------------+\n-    | |pic1|                                              | |pic2|                                              |\n-    +-----------------------------------------------------+-----------------------------------------------------+\n-\n-\n-.. |pic1| image:: cuda-parallel-matmul.png\n-\n-.. |pic2| image:: triton-parallel-matmul.png\n-\n-A key benefit of this approach is that it leads to block-structured iteration spaces that offer programmers more flexibility than existing DSLs when implementing sparse operations, all while allowing compilers to aggressively optimize programs for data locality and parallelism.\n-\n---------------\n-Challenges\n---------------\n-\n-The main challenge posed by our proposed paradigm is that of work scheduling, i.e., how the work done by each program instance should be partitioned for efficient execution on modern GPUs. To address this issue, the Triton compiler makes heavy use of *block-level data-flow analysis*, a technique for scheduling iteration blocks statically based on the control- and data-flow structure of the target program. The resulting system actually works surprisingly well: our compiler manages to apply a broad range of interesting optimization automatically (e.g., automatic coalescing, thread swizzling, pre-fetching, automatic vectorization, tensor core-aware instruction selection, shared memory allocation/synchronization, asynchronous copy scheduling). Of course doing all this is not trivial; one of the purposes of this guide is to give you a sense of how it works.\n-\n---------------\n-References\n---------------\n-\n-.. [SUTSKEVER2014] I. Sutskever et al., \"Sequence to Sequence Learning with Neural Networks\", NIPS 2014\n-.. [REDMON2016] J. Redmon et al., \"You Only Look Once: Unified, Real-Time Object Detection\", CVPR 2016\n-.. [LEE2017] K. Lee et al., \"Superhuman Accuracy on the SNEMI3D Connectomics Challenge\", ArXiV 2017\n-.. [BAGHDADI2021] R. Baghdadi et al., \"Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code\", CGO 2021\n-.. [VASILACHE2018] N. Vasilache et al., \"Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions\", ArXiV 2018\n-.. [JRK2013] J. Ragan-Kelley et al., \"Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines\", PLDI 2013\n-.. [CHEN2018] T. Chen et al., \"TVM: An Automated End-to-End Optimizing Compiler for Deep Learning\", OSDI 2018\n-.. [LAM1991] M. Lam et al., \"The Cache Performance and Optimizations of Blocked Algorithms\", ASPLOS 1991\n-.. [AUGUIN1983] M. Auguin et al., \"Opsila: an advanced SIMD for numerical analysis and signal processing\", EUROMICRO 1983\n\\ No newline at end of file"}, {"filename": "master/_sources/programming-guide/chapter-2/related-work.rst.txt", "status": "removed", "additions": 0, "deletions": 210, "changes": 210, "file_content_changes": "@@ -1,210 +0,0 @@\n-==============\n-Related Work\n-==============\n-\n-At first sight, Triton may seem like just yet another DSL for DNNs. The purpose of this section is to contextualize Triton and highlight its differences with the two leading approaches in this domain: polyhedral compilation and scheduling languages.\n-\n------------------------\n-Polyhedral Compilation\n------------------------\n-\n-Traditional compilers typically rely on intermediate representations, such as LLVM-IR [LATTNER2004]_, that encode control flow information using (un)conditional branches. This relatively low-level format makes it difficult to statically analyze the runtime behavior (e.g., cache misses) of input programs, and to  automatically optimize loops accordingly through the use of tiling [WOLFE1989]_, fusion [DARTE1999]_ and interchange [ALLEN1984]_. To solve this issue, polyhedral compilers [ANCOURT1991]_ rely on program representations that have statically predictable control flow, thereby enabling aggressive compile-time program transformations for data locality and parallelism. Though this strategy has been adopted by many languages and compilers for DNNs such as Tiramisu [BAGHDADI2021]_, Tensor Comprehensions [VASILACHE2018]_, Diesel [ELANGO2018]_ and the Affine dialect in MLIR [LATTNER2019]_, it also comes with a number of limitations that will be described later in this section.\n-\n-+++++++++++++++++++++++\n-Program Representation\n-+++++++++++++++++++++++\n-\n-Polyhedral compilation is a vast area of research. In this section we only outline the most basic aspects of this topic, but readers interested in the solid mathematical foundations underneath may refer to the ample litterature on linear and integer programming.\n-\n-.. table::\n-    :widths: 50 50\n-\n-    +-----------------------------------------------------+-----------------------------------------------------+\n-    |                                                     |                                                     |\n-    |.. code-block:: C                                    | |pic1|                                              |\n-    |                                                     |                                                     |\n-    |   for(int i = 0; i < 3; i++)                        |                                                     |\n-    |   for(int j = i; j < 5; j++)                        |                                                     |\n-    |     A[i][j] = 0;                                    |                                                     |\n-    +-----------------------------------------------------+-----------------------------------------------------+\n-\n-.. |pic1| image:: polyhedral-iteration.png\n-    :width: 300\n-\n-Polyhedral compilers focus on a class of programs commonly known as **Static Control Parts** (SCoP), *i.e.*, maximal sets of consecutive statements in which conditionals and loop bounds are affine functions of surrounding loop indices and global invariant parameters. As shown above, programs in this format always lead to iteration domains that are bounded by affine inequalities, i.e., polyhedral. These polyhedra can also be defined algebraically; for the above example:\n-\n-.. math::\n-\n-  \\mathcal{P} = \\{ i, j \\in \\mathbb{Z}^2\n-  ~|~\n-  \\begin{pmatrix}\n-  1 & 0 \\\\\n-  -1 & 0 \\\\\n-  -1 & 1 \\\\\n-  0 & -1 \\\\\n-  \\end{pmatrix}\n-  \\begin{pmatrix}\n-  i \\\\\n-  j\n-  \\end{pmatrix}\n-  +\n-  \\begin{pmatrix}\n-  0 \\\\\n-  2 \\\\\n-  0 \\\\\n-  4\n-  \\end{pmatrix}\n-  \\geq\n-  0\n-  \\}\n-\n-\n-Each point :math:`(i, j)` in :math:`\\mathcal{P}` represents a *polyhedral statement*, that is a program statement which (1) does not induce control-flow side effects (e.g., :code:`for`, :code:`if`, :code:`break`) and (2) contains only affine functions of loop indices and global parameters in array accesses. To facilitate alias analysis, array accesses are also mathematically abstracted, using so-called *access function*. In other words, :code:`A[i][j]` is simply :code:`A[f(i,j)]` where the access function :math:`f` is defined by:\n-\n-.. math::\n-\n-  f(i, j) = \\begin{pmatrix}\n-  1 & 0\\\\\n-  0 & 1\\\\\n-  \\end{pmatrix}\n-  \\begin{pmatrix}\n-  i\\\\\n-  j\n-  \\end{pmatrix}\n-  =\n-  (i, j)\n-\n-\n-Note that the iteration domains of an SCoP does not specify the order in which its statements shall execute. In fact, this iteration domain may be traversed in many different possible legal orders, i.e. *schedules*. Formally, a schedule is defined as a p-dimensional affine transformation :math:`\\Theta` of loop indices :math:`\\mathbf{x}` and global invariant parameters :math:`\\mathbf{g}`:\n-\n-.. math::\n-  \\Theta_S(\\mathbf{x}) = T_S \\begin{pmatrix}\n-  \\vec{x}\\\\\n-  \\vec{g}\\\\\n-  1\n-  \\end{pmatrix}\n-  \\qquad\n-  T_S \\in \\mathbb{Z} ^{p \\times (\\text{dim}(\\mathbf{x}) + \\text{dim}(\\mathbf{g}) + 1)}\n-\n-\n-Where :math:`\\Theta_S(\\mathbf{x})` is a p-dimensional vector representing the slowest to fastest growing indices (from left to right) when traversing the loop nest surrounding :math:`S`. For the code shown above, the original schedule defined by the loop nest in C can be retrieved by using:\n-\n-.. math::\n-  \\Theta_S(\\mathbf{x}) = \\begin{pmatrix}\n-  1 & 0 \\\\\n-  0 & 1 \\\\\n-  \\end{pmatrix}\n-  \\begin{pmatrix}\n-  i & j\n-  \\end{pmatrix}^T\n-  =\n-  \\begin{pmatrix}\n-  i & j\n-  \\end{pmatrix}^T\n-\n-\n-where :math:`i` and :math:`j` are respectively the slowest and fastest growing loop indices in the nest. If :math:`T_S` is a vector (resp. tensor), then :math:`\\Theta_S` is a said to be one-dimensional (resp. multi-dimensional).\n-\n-+++++++++++\n-Advantages\n-+++++++++++\n-\n-Programs amenable to polyhedral compilation can be aggressively transformed and optimized. Most of these transformations actually boil down to the production of  schedules and iteration domains that enable loop transformations promoting parallelism and spatial/temporal data locality (e.g., fusion, interchange, tiling, parallelization).\n-\n-Polyhedral compilers can also automatically go through complex verification processes to ensure that the semantics of their input program is preserved throughout this optimization phase. Note that polyhedral optimizers are not incompatible with more standard optimization techniques. In fact, it is not uncommon for these systems to be implemented as a set of LLVM passes that can be run ahead of more traditional compilation techniques [GROSSER2012]_.\n-\n-All in all, polyhedral machinery is extremely powerful, when applicable. It has been shown to support most common loop transformations, and has indeed achieved performance comparable to state-of-the-art GPU libraries for dense matrix multiplication [ELANGO2018]_. Additionally, it is also fully automatic and doesn't require any hint from programmers apart from source-code in a C-like format. \n-\n-++++++++++++\n-Limitations\n-++++++++++++\n-\n-Unfortunately, polyhedral compilers suffer from two major limitations that have prevented its adoption as a universal method for code generation in neural networks.\n-\n-First, the set of possible program transformations :math:`\\Omega = \\{ \\Theta_S ~|~ S \\in \\text{program} \\}` is large, and grows with the number of statements in the program as well as with the size of their iteration domain. Verifying the legality of each transformation can also require the resolution of complex integer linear programs, making polyhedral compilation very computationally expensive. To make matters worse, hardware properties (e.g., cache size, number of SMs) and contextual characteristics (e.g., input tensor shapes) also have to be taken into account by this framework, leading to expensive auto-tuning procedures [SATO2019]_.\n-\n-Second, the polyhedral framework is not very generally applicable; SCoPs are relatively common [GIRBAL2006]_ but require loop bounds and array subscripts to be affine functions of loop indices, which typically only occurs in regular, dense computations. For this reason, this framework still has to be successfully applied to sparse -- or even structured-sparse -- neural networks, whose importance has been rapidly rising over the past few years.\n-\n-On the other hand, blocked program representations advocated by this dissertation are less restricted in scope and can achieve close to peak performance using standard dataflow analysis.\n-\n------------------------\n-Scheduling Languages\n------------------------\n-\n-Separation of concerns [DIJKSTRA82]_ is a well-known design principle in computer science: programs should be decomposed into modular layers of abstraction that separate the semantics of their algorithms from the details of their implementation. Systems like Halide and TVM push this philosophy one step further, and enforce this separation at the grammatical level through the use of a  **scheduling language**. The benefits of this methodology are particularly visible in the case of matrix multiplication, where, as one can see below, the definition of the algorithm (Line 1-7) is completely disjoint from its implementation (Line 8-16), meaning that both can be maintained, optimized and distributed independently. \n-\n-.. code-block:: python\n-  :linenos:\n-\n-  // algorithm\n-  Var x(\"x\"), y(\"y\");\n-  Func matmul(\"matmul\"); \n-  RDom k(0, matrix_size); \n-  RVar ki; \n-  matmul(x, y) = 0.0f; \n-  matmul(x, y) += A(k, y) * B(x, k); \n-  // schedule\n-  Var xi(\"xi\"), xo(\"xo\"), yo(\"yo\"), yi(\"yo\"), yii(\"yii\"), xii(\"xii\"); \n-  matmul.vectorize(x, 8); \n-  matmul.update(0) \n-      .split(x, x, xi, block_size).split(xi, xi, xii, 8) \n-      .split(y, y, yi, block_size).split(yi, yi, yii, 4) \n-      .split(k, k, ki, block_size) \n-      .reorder(xii, yii, xi, ki, yi, k, x, y) \n-      .parallel(y).vectorize(xii).unroll(xi).unroll(yii);\n-\n-\n-The resulting code may however not be completely portable, as schedules can sometimes rely on execution models (e.g., SPMD) or hardware intrinsics (e.g., matrix-multiply-accumulate) that are not widely available. This issue can be mitigated by auto-scheduling mechanisms [MULLAPUDI2016]_.\n-\n-+++++++++++\n-Advantages\n-+++++++++++\n-\n-The main advantage of this approach is that it allows programmers to write an algorithm *only once*, and focus on performance optimization separately. It makes it possible to manually specify optimizations that a polyhedral compiler wouldn't be able to figure out automatically using static data-flow analysis.\n-\n-Scheduling languages are, without a doubt, one of the most popular approaches for neural network code generation. The most popular system for this purpose is probably TVM, which provides good performance across a wide range of platforms as well as built-in automatic scheduling mechanisms.\n-\n-++++++++++++\n-Limitations\n-++++++++++++\n-\n-This ease-of-development comes at a cost. First of all, existing systems that follow this paradigm tend to be noticeably slower than Triton on modern hardware when applicable (e.g., V100/A100 tensor cores w/ equal tile sizes). I do believe that this is not a fundamental issue of scheduling languages -- in the sense that it could probably be solved with more efforts -- but it could mean that these systems are harder to engineer. More importantly, existing scheduling languages generate loops whose bounds and increments cannot depend on surrounding loop indice without at least imposing severe constraints on possible schedules -- if not breaking the system entirely. This is problematic for sparse computations, whose iteration spaces may be irregular.\n-\n-.. table::\n-    :widths: 50 50\n-\n-    +-----------------------------------------------------+-----------------------------------------------------+\n-    |                                                     |                                                     |\n-    |.. code-block:: C                                    | |pic2|                                              |\n-    |                                                     |                                                     |\n-    |   for(int i = 0; i < 4; i++)                        |                                                     |\n-    |   for(int j = 0; j < 4; j++)                        |                                                     |\n-    |     float acc = 0;                                  |                                                     |\n-    |     for(int k = 0; k < K[i]; k++)                   |                                                     |\n-    |       acc += A[i][col[i,k]]*B[k][j]                 |                                                     |\n-    |     C[i][j] = acc;                                  |                                                     |\n-    +-----------------------------------------------------+-----------------------------------------------------+\n-\n-.. |pic2| image:: halide-iteration.png\n-    :width: 300\n-\n-On the other hand, the block-based program representation that we advocate for through this work allows for block-structured iteration spaces and allows programmers to manually handle load-balancing as they wish.\n-\n---------------\n-References\n---------------\n-\n-.. [LATTNER2004] C. Lattner et al., \"LLVM: a compilation framework for lifelong program analysis transformation\", CGO 2004\n-.. [WOLFE1989] M. Wolfe, \"More Iteration Space Tiling\", SC 1989\n-.. [DARTE1999] A. Darte, \"On the Complexity of Loop Fusion\", PACT 1999\n-.. [ALLEN1984] J. Allen et al., \"Automatic Loop Interchange\", SIGPLAN Notices 1984\n-.. [ANCOURT1991] C. Ancourt et al., \"Scanning Polyhedra with DO Loops\", PPoPP 1991\n-.. [BAGHDADI2021] R. Baghdadi et al., \"Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code\", CGO 2021\n-.. [VASILACHE2018] N. Vasilache et al., \"Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions\", ArXiV 2018\n-.. [ELANGO2018] V. Elango et al. \"Diesel: DSL for Linear Algebra and Neural Net Computations on GPUs\", MAPL 2018\n-.. [LATTNER2019] C. Lattner et al., \"MLIR Primer: A Compiler Infrastructure for the End of Moore\u2019s Law\", Arxiv 2019\n-.. [GROSSER2012] T. Grosser et al., \"Polly - Performing Polyhedral Optimizations on a Low-Level Intermediate Representation\", Parallel Processing Letters 2012\n-.. [SATO2019] Y. Sato et al., \"An Autotuning Framework for Scalable Execution of Tiled Code via Iterative Polyhedral Compilation\", TACO 2019\n-.. [GIRBAL2006] S. Girbal et al., \"Semi-Automatic Composition of Loop Transformations for Deep Parallelism and Memory Hierarchies\", International Journal of Parallel Programming 2006\n-.. [DIJKSTRA82] E. W. Dijkstra et al., \"On the role of scientific thought\", Selected writings on computing: a personal perspective 1982\n-.. [MULLAPUDI2016] R. Mullapudi et al., \"Automatically scheduling halide image processing pipelines\", TOG 2016"}, {"filename": "master/_sources/python-api/generated/triton.Config.rst.txt", "status": "removed", "additions": 0, "deletions": 22, "changes": 22, "file_content_changes": "@@ -1,22 +0,0 @@\n-\ufefftriton.Config\n-=============\n-\n-.. currentmodule:: triton\n-\n-.. autoclass:: Config\n-\n-   \n-   .. automethod:: __init__\n-\n-   \n-   .. rubric:: Methods\n-\n-   .. autosummary::\n-   \n-      ~Config.__init__\n-   \n-   \n-\n-   \n-   \n-   \n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.autotune.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.autotune\n-===============\n-\n-.. currentmodule:: triton\n-\n-.. autofunction:: autotune\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.heuristics.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.heuristics\n-=================\n-\n-.. currentmodule:: triton\n-\n-.. autofunction:: heuristics\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.jit.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.jit\n-==========\n-\n-.. currentmodule:: triton\n-\n-.. autofunction:: jit\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.arange.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.arange\n-======================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: arange\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.atomic_add.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.atomic\\_add\n-===========================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: atomic_add\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.atomic_cas.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.atomic\\_cas\n-===========================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: atomic_cas\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.atomic_max.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.atomic\\_max\n-===========================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: atomic_max\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.atomic_min.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.atomic\\_min\n-===========================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: atomic_min\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.atomic_xchg.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.atomic\\_xchg\n-============================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: atomic_xchg\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.broadcast_to.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.broadcast\\_to\n-=============================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: broadcast_to\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.cos.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.cos\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: cos\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.dot.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.dot\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: dot\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.exp.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.exp\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: exp\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.load.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.load\n-====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: load\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.log.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.log\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: log\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.max.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.max\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: max\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.maximum.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.maximum\n-=======================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: maximum\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.min.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.min\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: min\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.minimum.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.minimum\n-=======================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: minimum\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.multiple_of.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.multiple\\_of\n-============================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: multiple_of\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.num_programs.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.num\\_programs\n-=============================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: num_programs\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.program_id.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.program\\_id\n-===========================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: program_id\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.rand.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.rand\n-====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: rand\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.randint.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.randint\n-=======================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: randint\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.randint4x.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.randint4x\n-=========================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: randint4x\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.randn.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.randn\n-=====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: randn\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.ravel.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.ravel\n-=====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: ravel\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.reshape.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.reshape\n-=======================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: reshape\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.sigmoid.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.sigmoid\n-=======================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: sigmoid\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.sin.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.sin\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: sin\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.softmax.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.softmax\n-=======================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: softmax\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.sqrt.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.sqrt\n-====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: sqrt\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.store.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.store\n-=====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: store\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.sum.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.sum\n-===================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: sum\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.where.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.where\n-=====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: where\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.language.zeros.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.language.zeros\n-=====================\n-\n-.. currentmodule:: triton.language\n-\n-.. autofunction:: zeros\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.testing.Benchmark.rst.txt", "status": "removed", "additions": 0, "deletions": 22, "changes": 22, "file_content_changes": "@@ -1,22 +0,0 @@\n-\ufefftriton.testing.Benchmark\n-========================\n-\n-.. currentmodule:: triton.testing\n-\n-.. autoclass:: Benchmark\n-\n-   \n-   .. automethod:: __init__\n-\n-   \n-   .. rubric:: Methods\n-\n-   .. autosummary::\n-   \n-      ~Benchmark.__init__\n-   \n-   \n-\n-   \n-   \n-   \n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.testing.do_bench.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.testing.do\\_bench\n-========================\n-\n-.. currentmodule:: triton.testing\n-\n-.. autofunction:: do_bench\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/generated/triton.testing.perf_report.rst.txt", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-\ufefftriton.testing.perf\\_report\n-===========================\n-\n-.. currentmodule:: triton.testing\n-\n-.. autofunction:: perf_report\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/triton.language.rst.txt", "status": "removed", "additions": 0, "deletions": 145, "changes": 145, "file_content_changes": "@@ -1,145 +0,0 @@\n-triton.language\n-================\n-\n-.. currentmodule:: triton.language\n-\n-\n-Programming Model\n--------------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    program_id\n-    num_programs\n-\n-\n-Creation Ops\n--------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    arange\n-    zeros\n-\n-\n-Shape Manipulation Ops\n------------------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    broadcast_to\n-    reshape\n-    ravel\n-\n-\n-\n-Linear Algebra Ops\n--------------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    dot\n-\n-Memory Ops\n---------------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    load\n-    store\n-    atomic_cas\n-    atomic_xchg\n-\n-\n-Indexing Ops\n---------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    where\n-\n-\n-Math Ops\n-----------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    exp\n-    log\n-    cos\n-    sin\n-    sqrt\n-    sigmoid\n-    softmax\n-\n-\n-Reduction Ops\n----------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    max\n-    min\n-    sum\n-\n-Atomic Ops\n----------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    atomic_cas\n-    atomic_add\n-    atomic_max\n-    atomic_min\n-\n-\n-Comparison ops\n----------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    minimum\n-    maximum\n-\n-.. _Random Number Generation:\n-\n-Random Number Generation\n--------------------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    randint4x\n-    randint\n-    rand\n-    randn\n-\n-Compiler Hint Ops\n--------------------\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    multiple_of\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/triton.rst.txt", "status": "removed", "additions": 0, "deletions": 13, "changes": 13, "file_content_changes": "@@ -1,13 +0,0 @@\n-triton\n-========\n-\n-.. currentmodule:: triton\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    jit\n-    autotune\n-    heuristics\n-    Config\n\\ No newline at end of file"}, {"filename": "master/_sources/python-api/triton.testing.rst.txt", "status": "removed", "additions": 0, "deletions": 12, "changes": 12, "file_content_changes": "@@ -1,12 +0,0 @@\n-triton.testing\n-================\n-\n-.. currentmodule:: triton.testing\n-\n-.. autosummary::\n-    :toctree: generated\n-    :nosignatures:\n-\n-    do_bench\n-    Benchmark\n-    perf_report\n\\ No newline at end of file"}, {"filename": "master/_static/basic.css", "status": "removed", "additions": 0, "deletions": 904, "changes": 904, "file_content_changes": "@@ -1,904 +0,0 @@\n-/*\n- * basic.css\n- * ~~~~~~~~~\n- *\n- * Sphinx stylesheet -- basic theme.\n- *\n- * :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n- * :license: BSD, see LICENSE for details.\n- *\n- */\n-\n-/* -- main layout ----------------------------------------------------------- */\n-\n-div.clearer {\n-    clear: both;\n-}\n-\n-div.section::after {\n-    display: block;\n-    content: '';\n-    clear: left;\n-}\n-\n-/* -- relbar ---------------------------------------------------------------- */\n-\n-div.related {\n-    width: 100%;\n-    font-size: 90%;\n-}\n-\n-div.related h3 {\n-    display: none;\n-}\n-\n-div.related ul {\n-    margin: 0;\n-    padding: 0 0 0 10px;\n-    list-style: none;\n-}\n-\n-div.related li {\n-    display: inline;\n-}\n-\n-div.related li.right {\n-    float: right;\n-    margin-right: 5px;\n-}\n-\n-/* -- sidebar --------------------------------------------------------------- */\n-\n-div.sphinxsidebarwrapper {\n-    padding: 10px 5px 0 10px;\n-}\n-\n-div.sphinxsidebar {\n-    float: left;\n-    width: 230px;\n-    margin-left: -100%;\n-    font-size: 90%;\n-    word-wrap: break-word;\n-    overflow-wrap : break-word;\n-}\n-\n-div.sphinxsidebar ul {\n-    list-style: none;\n-}\n-\n-div.sphinxsidebar ul ul,\n-div.sphinxsidebar ul.want-points {\n-    margin-left: 20px;\n-    list-style: square;\n-}\n-\n-div.sphinxsidebar ul ul {\n-    margin-top: 0;\n-    margin-bottom: 0;\n-}\n-\n-div.sphinxsidebar form {\n-    margin-top: 10px;\n-}\n-\n-div.sphinxsidebar input {\n-    border: 1px solid #98dbcc;\n-    font-family: sans-serif;\n-    font-size: 1em;\n-}\n-\n-div.sphinxsidebar #searchbox form.search {\n-    overflow: hidden;\n-}\n-\n-div.sphinxsidebar #searchbox input[type=\"text\"] {\n-    float: left;\n-    width: 80%;\n-    padding: 0.25em;\n-    box-sizing: border-box;\n-}\n-\n-div.sphinxsidebar #searchbox input[type=\"submit\"] {\n-    float: left;\n-    width: 20%;\n-    border-left: none;\n-    padding: 0.25em;\n-    box-sizing: border-box;\n-}\n-\n-\n-img {\n-    border: 0;\n-    max-width: 100%;\n-}\n-\n-/* -- search page ----------------------------------------------------------- */\n-\n-ul.search {\n-    margin: 10px 0 0 20px;\n-    padding: 0;\n-}\n-\n-ul.search li {\n-    padding: 5px 0 5px 20px;\n-    background-image: url(file.png);\n-    background-repeat: no-repeat;\n-    background-position: 0 7px;\n-}\n-\n-ul.search li a {\n-    font-weight: bold;\n-}\n-\n-ul.search li p.context {\n-    color: #888;\n-    margin: 2px 0 0 30px;\n-    text-align: left;\n-}\n-\n-ul.keywordmatches li.goodmatch a {\n-    font-weight: bold;\n-}\n-\n-/* -- index page ------------------------------------------------------------ */\n-\n-table.contentstable {\n-    width: 90%;\n-    margin-left: auto;\n-    margin-right: auto;\n-}\n-\n-table.contentstable p.biglink {\n-    line-height: 150%;\n-}\n-\n-a.biglink {\n-    font-size: 1.3em;\n-}\n-\n-span.linkdescr {\n-    font-style: italic;\n-    padding-top: 5px;\n-    font-size: 90%;\n-}\n-\n-/* -- general index --------------------------------------------------------- */\n-\n-table.indextable {\n-    width: 100%;\n-}\n-\n-table.indextable td {\n-    text-align: left;\n-    vertical-align: top;\n-}\n-\n-table.indextable ul {\n-    margin-top: 0;\n-    margin-bottom: 0;\n-    list-style-type: none;\n-}\n-\n-table.indextable > tbody > tr > td > ul {\n-    padding-left: 0em;\n-}\n-\n-table.indextable tr.pcap {\n-    height: 10px;\n-}\n-\n-table.indextable tr.cap {\n-    margin-top: 10px;\n-    background-color: #f2f2f2;\n-}\n-\n-img.toggler {\n-    margin-right: 3px;\n-    margin-top: 3px;\n-    cursor: pointer;\n-}\n-\n-div.modindex-jumpbox {\n-    border-top: 1px solid #ddd;\n-    border-bottom: 1px solid #ddd;\n-    margin: 1em 0 1em 0;\n-    padding: 0.4em;\n-}\n-\n-div.genindex-jumpbox {\n-    border-top: 1px solid #ddd;\n-    border-bottom: 1px solid #ddd;\n-    margin: 1em 0 1em 0;\n-    padding: 0.4em;\n-}\n-\n-/* -- domain module index --------------------------------------------------- */\n-\n-table.modindextable td {\n-    padding: 2px;\n-    border-collapse: collapse;\n-}\n-\n-/* -- general body styles --------------------------------------------------- */\n-\n-div.body {\n-    min-width: 450px;\n-    max-width: 800px;\n-}\n-\n-div.body p, div.body dd, div.body li, div.body blockquote {\n-    -moz-hyphens: auto;\n-    -ms-hyphens: auto;\n-    -webkit-hyphens: auto;\n-    hyphens: auto;\n-}\n-\n-a.headerlink {\n-    visibility: hidden;\n-}\n-\n-a.brackets:before,\n-span.brackets > a:before{\n-    content: \"[\";\n-}\n-\n-a.brackets:after,\n-span.brackets > a:after {\n-    content: \"]\";\n-}\n-\n-h1:hover > a.headerlink,\n-h2:hover > a.headerlink,\n-h3:hover > a.headerlink,\n-h4:hover > a.headerlink,\n-h5:hover > a.headerlink,\n-h6:hover > a.headerlink,\n-dt:hover > a.headerlink,\n-caption:hover > a.headerlink,\n-p.caption:hover > a.headerlink,\n-div.code-block-caption:hover > a.headerlink {\n-    visibility: visible;\n-}\n-\n-div.body p.caption {\n-    text-align: inherit;\n-}\n-\n-div.body td {\n-    text-align: left;\n-}\n-\n-.first {\n-    margin-top: 0 !important;\n-}\n-\n-p.rubric {\n-    margin-top: 30px;\n-    font-weight: bold;\n-}\n-\n-img.align-left, figure.align-left, .figure.align-left, object.align-left {\n-    clear: left;\n-    float: left;\n-    margin-right: 1em;\n-}\n-\n-img.align-right, figure.align-right, .figure.align-right, object.align-right {\n-    clear: right;\n-    float: right;\n-    margin-left: 1em;\n-}\n-\n-img.align-center, figure.align-center, .figure.align-center, object.align-center {\n-  display: block;\n-  margin-left: auto;\n-  margin-right: auto;\n-}\n-\n-img.align-default, figure.align-default, .figure.align-default {\n-  display: block;\n-  margin-left: auto;\n-  margin-right: auto;\n-}\n-\n-.align-left {\n-    text-align: left;\n-}\n-\n-.align-center {\n-    text-align: center;\n-}\n-\n-.align-default {\n-    text-align: center;\n-}\n-\n-.align-right {\n-    text-align: right;\n-}\n-\n-/* -- sidebars -------------------------------------------------------------- */\n-\n-div.sidebar,\n-aside.sidebar {\n-    margin: 0 0 0.5em 1em;\n-    border: 1px solid #ddb;\n-    padding: 7px;\n-    background-color: #ffe;\n-    width: 40%;\n-    float: right;\n-    clear: right;\n-    overflow-x: auto;\n-}\n-\n-p.sidebar-title {\n-    font-weight: bold;\n-}\n-\n-div.admonition, div.topic, blockquote {\n-    clear: left;\n-}\n-\n-/* -- topics ---------------------------------------------------------------- */\n-\n-div.topic {\n-    border: 1px solid #ccc;\n-    padding: 7px;\n-    margin: 10px 0 10px 0;\n-}\n-\n-p.topic-title {\n-    font-size: 1.1em;\n-    font-weight: bold;\n-    margin-top: 10px;\n-}\n-\n-/* -- admonitions ----------------------------------------------------------- */\n-\n-div.admonition {\n-    margin-top: 10px;\n-    margin-bottom: 10px;\n-    padding: 7px;\n-}\n-\n-div.admonition dt {\n-    font-weight: bold;\n-}\n-\n-p.admonition-title {\n-    margin: 0px 10px 5px 0px;\n-    font-weight: bold;\n-}\n-\n-div.body p.centered {\n-    text-align: center;\n-    margin-top: 25px;\n-}\n-\n-/* -- content of sidebars/topics/admonitions -------------------------------- */\n-\n-div.sidebar > :last-child,\n-aside.sidebar > :last-child,\n-div.topic > :last-child,\n-div.admonition > :last-child {\n-    margin-bottom: 0;\n-}\n-\n-div.sidebar::after,\n-aside.sidebar::after,\n-div.topic::after,\n-div.admonition::after,\n-blockquote::after {\n-    display: block;\n-    content: '';\n-    clear: both;\n-}\n-\n-/* -- tables ---------------------------------------------------------------- */\n-\n-table.docutils {\n-    margin-top: 10px;\n-    margin-bottom: 10px;\n-    border: 0;\n-    border-collapse: collapse;\n-}\n-\n-table.align-center {\n-    margin-left: auto;\n-    margin-right: auto;\n-}\n-\n-table.align-default {\n-    margin-left: auto;\n-    margin-right: auto;\n-}\n-\n-table caption span.caption-number {\n-    font-style: italic;\n-}\n-\n-table caption span.caption-text {\n-}\n-\n-table.docutils td, table.docutils th {\n-    padding: 1px 8px 1px 5px;\n-    border-top: 0;\n-    border-left: 0;\n-    border-right: 0;\n-    border-bottom: 1px solid #aaa;\n-}\n-\n-table.footnote td, table.footnote th {\n-    border: 0 !important;\n-}\n-\n-th {\n-    text-align: left;\n-    padding-right: 5px;\n-}\n-\n-table.citation {\n-    border-left: solid 1px gray;\n-    margin-left: 1px;\n-}\n-\n-table.citation td {\n-    border-bottom: none;\n-}\n-\n-th > :first-child,\n-td > :first-child {\n-    margin-top: 0px;\n-}\n-\n-th > :last-child,\n-td > :last-child {\n-    margin-bottom: 0px;\n-}\n-\n-/* -- figures --------------------------------------------------------------- */\n-\n-div.figure, figure {\n-    margin: 0.5em;\n-    padding: 0.5em;\n-}\n-\n-div.figure p.caption, figcaption {\n-    padding: 0.3em;\n-}\n-\n-div.figure p.caption span.caption-number,\n-figcaption span.caption-number {\n-    font-style: italic;\n-}\n-\n-div.figure p.caption span.caption-text,\n-figcaption span.caption-text {\n-}\n-\n-/* -- field list styles ----------------------------------------------------- */\n-\n-table.field-list td, table.field-list th {\n-    border: 0 !important;\n-}\n-\n-.field-list ul {\n-    margin: 0;\n-    padding-left: 1em;\n-}\n-\n-.field-list p {\n-    margin: 0;\n-}\n-\n-.field-name {\n-    -moz-hyphens: manual;\n-    -ms-hyphens: manual;\n-    -webkit-hyphens: manual;\n-    hyphens: manual;\n-}\n-\n-/* -- hlist styles ---------------------------------------------------------- */\n-\n-table.hlist {\n-    margin: 1em 0;\n-}\n-\n-table.hlist td {\n-    vertical-align: top;\n-}\n-\n-/* -- object description styles --------------------------------------------- */\n-\n-.sig {\n-\tfont-family: 'Consolas', 'Menlo', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', monospace;\n-}\n-\n-.sig-name, code.descname {\n-    background-color: transparent;\n-    font-weight: bold;\n-}\n-\n-.sig-name {\n-\tfont-size: 1.1em;\n-}\n-\n-code.descname {\n-    font-size: 1.2em;\n-}\n-\n-.sig-prename, code.descclassname {\n-    background-color: transparent;\n-}\n-\n-.optional {\n-    font-size: 1.3em;\n-}\n-\n-.sig-paren {\n-    font-size: larger;\n-}\n-\n-.sig-param.n {\n-\tfont-style: italic;\n-}\n-\n-/* C++ specific styling */\n-\n-.sig-inline.c-texpr,\n-.sig-inline.cpp-texpr {\n-\tfont-family: unset;\n-}\n-\n-.sig.c   .k, .sig.c   .kt,\n-.sig.cpp .k, .sig.cpp .kt {\n-\tcolor: #0033B3;\n-}\n-\n-.sig.c   .m,\n-.sig.cpp .m {\n-\tcolor: #1750EB;\n-}\n-\n-.sig.c   .s, .sig.c   .sc,\n-.sig.cpp .s, .sig.cpp .sc {\n-\tcolor: #067D17;\n-}\n-\n-\n-/* -- other body styles ----------------------------------------------------- */\n-\n-ol.arabic {\n-    list-style: decimal;\n-}\n-\n-ol.loweralpha {\n-    list-style: lower-alpha;\n-}\n-\n-ol.upperalpha {\n-    list-style: upper-alpha;\n-}\n-\n-ol.lowerroman {\n-    list-style: lower-roman;\n-}\n-\n-ol.upperroman {\n-    list-style: upper-roman;\n-}\n-\n-:not(li) > ol > li:first-child > :first-child,\n-:not(li) > ul > li:first-child > :first-child {\n-    margin-top: 0px;\n-}\n-\n-:not(li) > ol > li:last-child > :last-child,\n-:not(li) > ul > li:last-child > :last-child {\n-    margin-bottom: 0px;\n-}\n-\n-ol.simple ol p,\n-ol.simple ul p,\n-ul.simple ol p,\n-ul.simple ul p {\n-    margin-top: 0;\n-}\n-\n-ol.simple > li:not(:first-child) > p,\n-ul.simple > li:not(:first-child) > p {\n-    margin-top: 0;\n-}\n-\n-ol.simple p,\n-ul.simple p {\n-    margin-bottom: 0;\n-}\n-\n-dl.footnote > dt,\n-dl.citation > dt {\n-    float: left;\n-    margin-right: 0.5em;\n-}\n-\n-dl.footnote > dd,\n-dl.citation > dd {\n-    margin-bottom: 0em;\n-}\n-\n-dl.footnote > dd:after,\n-dl.citation > dd:after {\n-    content: \"\";\n-    clear: both;\n-}\n-\n-dl.field-list {\n-    display: grid;\n-    grid-template-columns: fit-content(30%) auto;\n-}\n-\n-dl.field-list > dt {\n-    font-weight: bold;\n-    word-break: break-word;\n-    padding-left: 0.5em;\n-    padding-right: 5px;\n-}\n-\n-dl.field-list > dt:after {\n-    content: \":\";\n-}\n-\n-dl.field-list > dd {\n-    padding-left: 0.5em;\n-    margin-top: 0em;\n-    margin-left: 0em;\n-    margin-bottom: 0em;\n-}\n-\n-dl {\n-    margin-bottom: 15px;\n-}\n-\n-dd > :first-child {\n-    margin-top: 0px;\n-}\n-\n-dd ul, dd table {\n-    margin-bottom: 10px;\n-}\n-\n-dd {\n-    margin-top: 3px;\n-    margin-bottom: 10px;\n-    margin-left: 30px;\n-}\n-\n-dl > dd:last-child,\n-dl > dd:last-child > :last-child {\n-    margin-bottom: 0;\n-}\n-\n-dt:target, span.highlighted {\n-    background-color: #fbe54e;\n-}\n-\n-rect.highlighted {\n-    fill: #fbe54e;\n-}\n-\n-dl.glossary dt {\n-    font-weight: bold;\n-    font-size: 1.1em;\n-}\n-\n-.versionmodified {\n-    font-style: italic;\n-}\n-\n-.system-message {\n-    background-color: #fda;\n-    padding: 5px;\n-    border: 3px solid red;\n-}\n-\n-.footnote:target  {\n-    background-color: #ffa;\n-}\n-\n-.line-block {\n-    display: block;\n-    margin-top: 1em;\n-    margin-bottom: 1em;\n-}\n-\n-.line-block .line-block {\n-    margin-top: 0;\n-    margin-bottom: 0;\n-    margin-left: 1.5em;\n-}\n-\n-.guilabel, .menuselection {\n-    font-family: sans-serif;\n-}\n-\n-.accelerator {\n-    text-decoration: underline;\n-}\n-\n-.classifier {\n-    font-style: oblique;\n-}\n-\n-.classifier:before {\n-    font-style: normal;\n-    margin: 0.5em;\n-    content: \":\";\n-}\n-\n-abbr, acronym {\n-    border-bottom: dotted 1px;\n-    cursor: help;\n-}\n-\n-/* -- code displays --------------------------------------------------------- */\n-\n-pre {\n-    overflow: auto;\n-    overflow-y: hidden;  /* fixes display issues on Chrome browsers */\n-}\n-\n-pre, div[class*=\"highlight-\"] {\n-    clear: both;\n-}\n-\n-span.pre {\n-    -moz-hyphens: none;\n-    -ms-hyphens: none;\n-    -webkit-hyphens: none;\n-    hyphens: none;\n-}\n-\n-div[class*=\"highlight-\"] {\n-    margin: 1em 0;\n-}\n-\n-td.linenos pre {\n-    border: 0;\n-    background-color: transparent;\n-    color: #aaa;\n-}\n-\n-table.highlighttable {\n-    display: block;\n-}\n-\n-table.highlighttable tbody {\n-    display: block;\n-}\n-\n-table.highlighttable tr {\n-    display: flex;\n-}\n-\n-table.highlighttable td {\n-    margin: 0;\n-    padding: 0;\n-}\n-\n-table.highlighttable td.linenos {\n-    padding-right: 0.5em;\n-}\n-\n-table.highlighttable td.code {\n-    flex: 1;\n-    overflow: hidden;\n-}\n-\n-.highlight .hll {\n-    display: block;\n-}\n-\n-div.highlight pre,\n-table.highlighttable pre {\n-    margin: 0;\n-}\n-\n-div.code-block-caption + div {\n-    margin-top: 0;\n-}\n-\n-div.code-block-caption {\n-    margin-top: 1em;\n-    padding: 2px 5px;\n-    font-size: small;\n-}\n-\n-div.code-block-caption code {\n-    background-color: transparent;\n-}\n-\n-table.highlighttable td.linenos,\n-span.linenos,\n-div.highlight span.gp {  /* gp: Generic.Prompt */\n-  user-select: none;\n-  -webkit-user-select: text; /* Safari fallback only */\n-  -webkit-user-select: none; /* Chrome/Safari */\n-  -moz-user-select: none; /* Firefox */\n-  -ms-user-select: none; /* IE10+ */\n-}\n-\n-div.code-block-caption span.caption-number {\n-    padding: 0.1em 0.3em;\n-    font-style: italic;\n-}\n-\n-div.code-block-caption span.caption-text {\n-}\n-\n-div.literal-block-wrapper {\n-    margin: 1em 0;\n-}\n-\n-code.xref, a code {\n-    background-color: transparent;\n-    font-weight: bold;\n-}\n-\n-h1 code, h2 code, h3 code, h4 code, h5 code, h6 code {\n-    background-color: transparent;\n-}\n-\n-.viewcode-link {\n-    float: right;\n-}\n-\n-.viewcode-back {\n-    float: right;\n-    font-family: sans-serif;\n-}\n-\n-div.viewcode-block:target {\n-    margin: -1px -10px;\n-    padding: 0 10px;\n-}\n-\n-/* -- math display ---------------------------------------------------------- */\n-\n-img.math {\n-    vertical-align: middle;\n-}\n-\n-div.body div.math p {\n-    text-align: center;\n-}\n-\n-span.eqno {\n-    float: right;\n-}\n-\n-span.eqno a.headerlink {\n-    position: absolute;\n-    z-index: 1;\n-}\n-\n-div.math:hover a.headerlink {\n-    visibility: visible;\n-}\n-\n-/* -- printout stylesheet --------------------------------------------------- */\n-\n-@media print {\n-    div.document,\n-    div.documentwrapper,\n-    div.bodywrapper {\n-        margin: 0 !important;\n-        width: 100%;\n-    }\n-\n-    div.sphinxsidebar,\n-    div.related,\n-    div.footer,\n-    #top-link {\n-        display: none;\n-    }\n-}\n\\ No newline at end of file"}, {"filename": "master/_static/binder_badge_logo.svg", "status": "removed", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -1 +0,0 @@\n-<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"109\" height=\"20\"><linearGradient id=\"b\" x2=\"0\" y2=\"100%\"><stop offset=\"0\" stop-color=\"#bbb\" stop-opacity=\".1\"/><stop offset=\"1\" stop-opacity=\".1\"/></linearGradient><clipPath id=\"a\"><rect width=\"109\" height=\"20\" rx=\"3\" fill=\"#fff\"/></clipPath><g clip-path=\"url(#a)\"><path fill=\"#555\" d=\"M0 0h64v20H0z\"/><path fill=\"#579aca\" d=\"M64 0h45v20H64z\"/><path fill=\"url(#b)\" d=\"M0 0h109v20H0z\"/></g><g fill=\"#fff\" text-anchor=\"middle\" font-family=\"DejaVu Sans,Verdana,Geneva,sans-serif\" font-size=\"110\"><image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/png;base64,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\"/> <text x=\"415\" y=\"150\" fill=\"#010101\" fill-opacity=\".3\" transform=\"scale(.1)\" textLength=\"370\">launch</text><text x=\"415\" y=\"140\" transform=\"scale(.1)\" textLength=\"370\">launch</text><text x=\"855\" y=\"150\" fill=\"#010101\" fill-opacity=\".3\" transform=\"scale(.1)\" textLength=\"350\">binder</text><text x=\"855\" y=\"140\" transform=\"scale(.1)\" textLength=\"350\">binder</text></g> </svg>\n\\ No newline at end of file"}, {"filename": "master/_static/broken_example.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/badge_only.css", "status": "removed", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -1 +0,0 @@\n-.fa:before{-webkit-font-smoothing:antialiased}.clearfix{*zoom:1}.clearfix:after,.clearfix:before{display:table;content:\"\"}.clearfix:after{clear:both}@font-face{font-family:FontAwesome;font-style:normal;font-weight:400;src:url(fonts/fontawesome-webfont.eot?674f50d287a8c48dc19ba404d20fe713?#iefix) format(\"embedded-opentype\"),url(fonts/fontawesome-webfont.woff2?af7ae505a9eed503f8b8e6982036873e) format(\"woff2\"),url(fonts/fontawesome-webfont.woff?fee66e712a8a08eef5805a46892932ad) format(\"woff\"),url(fonts/fontawesome-webfont.ttf?b06871f281fee6b241d60582ae9369b9) format(\"truetype\"),url(fonts/fontawesome-webfont.svg?912ec66d7572ff821749319396470bde#FontAwesome) format(\"svg\")}.fa:before{font-family:FontAwesome;font-style:normal;font-weight:400;line-height:1}.fa:before,a .fa{text-decoration:inherit}.fa:before,a .fa,li .fa{display:inline-block}li .fa-large:before{width:1.875em}ul.fas{list-style-type:none;margin-left:2em;text-indent:-.8em}ul.fas li .fa{width:.8em}ul.fas li .fa-large:before{vertical-align:baseline}.fa-book:before,.icon-book:before{content:\"\\f02d\"}.fa-caret-down:before,.icon-caret-down:before{content:\"\\f0d7\"}.fa-caret-up:before,.icon-caret-up:before{content:\"\\f0d8\"}.fa-caret-left:before,.icon-caret-left:before{content:\"\\f0d9\"}.fa-caret-right:before,.icon-caret-right:before{content:\"\\f0da\"}.rst-versions{position:fixed;bottom:0;left:0;width:300px;color:#fcfcfc;background:#1f1d1d;font-family:Lato,proxima-nova,Helvetica Neue,Arial,sans-serif;z-index:400}.rst-versions a{color:#2980b9;text-decoration:none}.rst-versions .rst-badge-small{display:none}.rst-versions .rst-current-version{padding:12px;background-color:#272525;display:block;text-align:right;font-size:90%;cursor:pointer;color:#27ae60}.rst-versions .rst-current-version:after{clear:both;content:\"\";display:block}.rst-versions .rst-current-version .fa{color:#fcfcfc}.rst-versions .rst-current-version .fa-book,.rst-versions .rst-current-version .icon-book{float:left}.rst-versions .rst-current-version.rst-out-of-date{background-color:#e74c3c;color:#fff}.rst-versions .rst-current-version.rst-active-old-version{background-color:#f1c40f;color:#000}.rst-versions.shift-up{height:auto;max-height:100%;overflow-y:scroll}.rst-versions.shift-up .rst-other-versions{display:block}.rst-versions .rst-other-versions{font-size:90%;padding:12px;color:grey;display:none}.rst-versions .rst-other-versions hr{display:block;height:1px;border:0;margin:20px 0;padding:0;border-top:1px solid #413d3d}.rst-versions .rst-other-versions dd{display:inline-block;margin:0}.rst-versions .rst-other-versions dd a{display:inline-block;padding:6px;color:#fcfcfc}.rst-versions.rst-badge{width:auto;bottom:20px;right:20px;left:auto;border:none;max-width:300px;max-height:90%}.rst-versions.rst-badge .fa-book,.rst-versions.rst-badge .icon-book{float:none;line-height:30px}.rst-versions.rst-badge.shift-up .rst-current-version{text-align:right}.rst-versions.rst-badge.shift-up .rst-current-version .fa-book,.rst-versions.rst-badge.shift-up .rst-current-version .icon-book{float:left}.rst-versions.rst-badge>.rst-current-version{width:auto;height:30px;line-height:30px;padding:0 6px;display:block;text-align:center}@media screen and (max-width:768px){.rst-versions{width:85%;display:none}.rst-versions.shift{display:block}}\n\\ No newline at end of file"}, {"filename": "master/_static/css/fonts/Roboto-Slab-Bold.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/Roboto-Slab-Bold.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/Roboto-Slab-Regular.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/Roboto-Slab-Regular.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/fontawesome-webfont.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/fontawesome-webfont.svg", "status": "removed", "additions": 0, "deletions": 2671, "changes": 2671, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/fontawesome-webfont.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/fontawesome-webfont.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/fontawesome-webfont.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-bold-italic.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-bold-italic.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-bold.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-bold.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-normal-italic.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-normal-italic.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-normal.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/fonts/lato-normal.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/css/theme.css", "status": "removed", "additions": 0, "deletions": 4, "changes": 4, "file_content_changes": "N/A"}, {"filename": "master/_static/doctools.js", "status": "removed", "additions": 0, "deletions": 323, "changes": 323, "file_content_changes": "@@ -1,323 +0,0 @@\n-/*\n- * doctools.js\n- * ~~~~~~~~~~~\n- *\n- * Sphinx JavaScript utilities for all documentation.\n- *\n- * :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n- * :license: BSD, see LICENSE for details.\n- *\n- */\n-\n-/**\n- * select a different prefix for underscore\n- */\n-$u = _.noConflict();\n-\n-/**\n- * make the code below compatible with browsers without\n- * an installed firebug like debugger\n-if (!window.console || !console.firebug) {\n-  var names = [\"log\", \"debug\", \"info\", \"warn\", \"error\", \"assert\", \"dir\",\n-    \"dirxml\", \"group\", \"groupEnd\", \"time\", \"timeEnd\", \"count\", \"trace\",\n-    \"profile\", \"profileEnd\"];\n-  window.console = {};\n-  for (var i = 0; i < names.length; ++i)\n-    window.console[names[i]] = function() {};\n-}\n- */\n-\n-/**\n- * small helper function to urldecode strings\n- *\n- * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/decodeURIComponent#Decoding_query_parameters_from_a_URL\n- */\n-jQuery.urldecode = function(x) {\n-  if (!x) {\n-    return x\n-  }\n-  return decodeURIComponent(x.replace(/\\+/g, ' '));\n-};\n-\n-/**\n- * small helper function to urlencode strings\n- */\n-jQuery.urlencode = encodeURIComponent;\n-\n-/**\n- * This function returns the parsed url parameters of the\n- * current request. Multiple values per key are supported,\n- * it will always return arrays of strings for the value parts.\n- */\n-jQuery.getQueryParameters = function(s) {\n-  if (typeof s === 'undefined')\n-    s = document.location.search;\n-  var parts = s.substr(s.indexOf('?') + 1).split('&');\n-  var result = {};\n-  for (var i = 0; i < parts.length; i++) {\n-    var tmp = parts[i].split('=', 2);\n-    var key = jQuery.urldecode(tmp[0]);\n-    var value = jQuery.urldecode(tmp[1]);\n-    if (key in result)\n-      result[key].push(value);\n-    else\n-      result[key] = [value];\n-  }\n-  return result;\n-};\n-\n-/**\n- * highlight a given string on a jquery object by wrapping it in\n- * span elements with the given class name.\n- */\n-jQuery.fn.highlightText = function(text, className) {\n-  function highlight(node, addItems) {\n-    if (node.nodeType === 3) {\n-      var val = node.nodeValue;\n-      var pos = val.toLowerCase().indexOf(text);\n-      if (pos >= 0 &&\n-          !jQuery(node.parentNode).hasClass(className) &&\n-          !jQuery(node.parentNode).hasClass(\"nohighlight\")) {\n-        var span;\n-        var isInSVG = jQuery(node).closest(\"body, svg, foreignObject\").is(\"svg\");\n-        if (isInSVG) {\n-          span = document.createElementNS(\"http://www.w3.org/2000/svg\", \"tspan\");\n-        } else {\n-          span = document.createElement(\"span\");\n-          span.className = className;\n-        }\n-        span.appendChild(document.createTextNode(val.substr(pos, text.length)));\n-        node.parentNode.insertBefore(span, node.parentNode.insertBefore(\n-          document.createTextNode(val.substr(pos + text.length)),\n-          node.nextSibling));\n-        node.nodeValue = val.substr(0, pos);\n-        if (isInSVG) {\n-          var rect = document.createElementNS(\"http://www.w3.org/2000/svg\", \"rect\");\n-          var bbox = node.parentElement.getBBox();\n-          rect.x.baseVal.value = bbox.x;\n-          rect.y.baseVal.value = bbox.y;\n-          rect.width.baseVal.value = bbox.width;\n-          rect.height.baseVal.value = bbox.height;\n-          rect.setAttribute('class', className);\n-          addItems.push({\n-              \"parent\": node.parentNode,\n-              \"target\": rect});\n-        }\n-      }\n-    }\n-    else if (!jQuery(node).is(\"button, select, textarea\")) {\n-      jQuery.each(node.childNodes, function() {\n-        highlight(this, addItems);\n-      });\n-    }\n-  }\n-  var addItems = [];\n-  var result = this.each(function() {\n-    highlight(this, addItems);\n-  });\n-  for (var i = 0; i < addItems.length; ++i) {\n-    jQuery(addItems[i].parent).before(addItems[i].target);\n-  }\n-  return result;\n-};\n-\n-/*\n- * backward compatibility for jQuery.browser\n- * This will be supported until firefox bug is fixed.\n- */\n-if (!jQuery.browser) {\n-  jQuery.uaMatch = function(ua) {\n-    ua = ua.toLowerCase();\n-\n-    var match = /(chrome)[ \\/]([\\w.]+)/.exec(ua) ||\n-      /(webkit)[ \\/]([\\w.]+)/.exec(ua) ||\n-      /(opera)(?:.*version|)[ \\/]([\\w.]+)/.exec(ua) ||\n-      /(msie) ([\\w.]+)/.exec(ua) ||\n-      ua.indexOf(\"compatible\") < 0 && /(mozilla)(?:.*? rv:([\\w.]+)|)/.exec(ua) ||\n-      [];\n-\n-    return {\n-      browser: match[ 1 ] || \"\",\n-      version: match[ 2 ] || \"0\"\n-    };\n-  };\n-  jQuery.browser = {};\n-  jQuery.browser[jQuery.uaMatch(navigator.userAgent).browser] = true;\n-}\n-\n-/**\n- * Small JavaScript module for the documentation.\n- */\n-var Documentation = {\n-\n-  init : function() {\n-    this.fixFirefoxAnchorBug();\n-    this.highlightSearchWords();\n-    this.initIndexTable();\n-    if (DOCUMENTATION_OPTIONS.NAVIGATION_WITH_KEYS) {\n-      this.initOnKeyListeners();\n-    }\n-  },\n-\n-  /**\n-   * i18n support\n-   */\n-  TRANSLATIONS : {},\n-  PLURAL_EXPR : function(n) { return n === 1 ? 0 : 1; },\n-  LOCALE : 'unknown',\n-\n-  // gettext and ngettext don't access this so that the functions\n-  // can safely bound to a different name (_ = Documentation.gettext)\n-  gettext : function(string) {\n-    var translated = Documentation.TRANSLATIONS[string];\n-    if (typeof translated === 'undefined')\n-      return string;\n-    return (typeof translated === 'string') ? translated : translated[0];\n-  },\n-\n-  ngettext : function(singular, plural, n) {\n-    var translated = Documentation.TRANSLATIONS[singular];\n-    if (typeof translated === 'undefined')\n-      return (n == 1) ? singular : plural;\n-    return translated[Documentation.PLURALEXPR(n)];\n-  },\n-\n-  addTranslations : function(catalog) {\n-    for (var key in catalog.messages)\n-      this.TRANSLATIONS[key] = catalog.messages[key];\n-    this.PLURAL_EXPR = new Function('n', 'return +(' + catalog.plural_expr + ')');\n-    this.LOCALE = catalog.locale;\n-  },\n-\n-  /**\n-   * add context elements like header anchor links\n-   */\n-  addContextElements : function() {\n-    $('div[id] > :header:first').each(function() {\n-      $('<a class=\"headerlink\">\\u00B6</a>').\n-      attr('href', '#' + this.id).\n-      attr('title', _('Permalink to this headline')).\n-      appendTo(this);\n-    });\n-    $('dt[id]').each(function() {\n-      $('<a class=\"headerlink\">\\u00B6</a>').\n-      attr('href', '#' + this.id).\n-      attr('title', _('Permalink to this definition')).\n-      appendTo(this);\n-    });\n-  },\n-\n-  /**\n-   * workaround a firefox stupidity\n-   * see: https://bugzilla.mozilla.org/show_bug.cgi?id=645075\n-   */\n-  fixFirefoxAnchorBug : function() {\n-    if (document.location.hash && $.browser.mozilla)\n-      window.setTimeout(function() {\n-        document.location.href += '';\n-      }, 10);\n-  },\n-\n-  /**\n-   * highlight the search words provided in the url in the text\n-   */\n-  highlightSearchWords : function() {\n-    var params = $.getQueryParameters();\n-    var terms = (params.highlight) ? params.highlight[0].split(/\\s+/) : [];\n-    if (terms.length) {\n-      var body = $('div.body');\n-      if (!body.length) {\n-        body = $('body');\n-      }\n-      window.setTimeout(function() {\n-        $.each(terms, function() {\n-          body.highlightText(this.toLowerCase(), 'highlighted');\n-        });\n-      }, 10);\n-      $('<p class=\"highlight-link\"><a href=\"javascript:Documentation.' +\n-        'hideSearchWords()\">' + _('Hide Search Matches') + '</a></p>')\n-          .appendTo($('#searchbox'));\n-    }\n-  },\n-\n-  /**\n-   * init the domain index toggle buttons\n-   */\n-  initIndexTable : function() {\n-    var togglers = $('img.toggler').click(function() {\n-      var src = $(this).attr('src');\n-      var idnum = $(this).attr('id').substr(7);\n-      $('tr.cg-' + idnum).toggle();\n-      if (src.substr(-9) === 'minus.png')\n-        $(this).attr('src', src.substr(0, src.length-9) + 'plus.png');\n-      else\n-        $(this).attr('src', src.substr(0, src.length-8) + 'minus.png');\n-    }).css('display', '');\n-    if (DOCUMENTATION_OPTIONS.COLLAPSE_INDEX) {\n-        togglers.click();\n-    }\n-  },\n-\n-  /**\n-   * helper function to hide the search marks again\n-   */\n-  hideSearchWords : function() {\n-    $('#searchbox .highlight-link').fadeOut(300);\n-    $('span.highlighted').removeClass('highlighted');\n-  },\n-\n-  /**\n-   * make the url absolute\n-   */\n-  makeURL : function(relativeURL) {\n-    return DOCUMENTATION_OPTIONS.URL_ROOT + '/' + relativeURL;\n-  },\n-\n-  /**\n-   * get the current relative url\n-   */\n-  getCurrentURL : function() {\n-    var path = document.location.pathname;\n-    var parts = path.split(/\\//);\n-    $.each(DOCUMENTATION_OPTIONS.URL_ROOT.split(/\\//), function() {\n-      if (this === '..')\n-        parts.pop();\n-    });\n-    var url = parts.join('/');\n-    return path.substring(url.lastIndexOf('/') + 1, path.length - 1);\n-  },\n-\n-  initOnKeyListeners: function() {\n-    $(document).keydown(function(event) {\n-      var activeElementType = document.activeElement.tagName;\n-      // don't navigate when in search box, textarea, dropdown or button\n-      if (activeElementType !== 'TEXTAREA' && activeElementType !== 'INPUT' && activeElementType !== 'SELECT'\n-          && activeElementType !== 'BUTTON' && !event.altKey && !event.ctrlKey && !event.metaKey\n-          && !event.shiftKey) {\n-        switch (event.keyCode) {\n-          case 37: // left\n-            var prevHref = $('link[rel=\"prev\"]').prop('href');\n-            if (prevHref) {\n-              window.location.href = prevHref;\n-              return false;\n-            }\n-            break;\n-          case 39: // right\n-            var nextHref = $('link[rel=\"next\"]').prop('href');\n-            if (nextHref) {\n-              window.location.href = nextHref;\n-              return false;\n-            }\n-            break;\n-        }\n-      }\n-    });\n-  }\n-};\n-\n-// quick alias for translations\n-_ = Documentation.gettext;\n-\n-$(document).ready(function() {\n-  Documentation.init();\n-});"}, {"filename": "master/_static/documentation_options.js", "status": "removed", "additions": 0, "deletions": 12, "changes": 12, "file_content_changes": "@@ -1,12 +0,0 @@\n-var DOCUMENTATION_OPTIONS = {\n-    URL_ROOT: document.getElementById(\"documentation_options\").getAttribute('data-url_root'),\n-    VERSION: '',\n-    LANGUAGE: 'None',\n-    COLLAPSE_INDEX: false,\n-    BUILDER: 'html',\n-    FILE_SUFFIX: '.html',\n-    LINK_SUFFIX: '.html',\n-    HAS_SOURCE: true,\n-    SOURCELINK_SUFFIX: '.txt',\n-    NAVIGATION_WITH_KEYS: false\n-};\n\\ No newline at end of file"}, {"filename": "master/_static/file.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Inconsolata-Bold.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Inconsolata-Regular.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Inconsolata.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato-Bold.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato-Regular.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bold.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bold.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bold.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bold.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bolditalic.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bolditalic.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bolditalic.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-bolditalic.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-italic.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-italic.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-italic.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-italic.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-regular.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-regular.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-regular.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/Lato/lato-regular.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab-Bold.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab-Regular.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-bold.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-bold.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-bold.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-bold.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-regular.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-regular.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-regular.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/RobotoSlab/roboto-slab-v7-regular.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/fontawesome-webfont.eot", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/fontawesome-webfont.svg", "status": "removed", "additions": 0, "deletions": 2671, "changes": 2671, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/fontawesome-webfont.ttf", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/fontawesome-webfont.woff", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/fonts/fontawesome-webfont.woff2", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/gallery-binder.css", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-/* CSS for binder integration */\n-\n-div.binder-badge {\n-  margin: 1em auto;\n-  vertical-align: middle;\n-}"}, {"filename": "master/_static/gallery-dataframe.css", "status": "removed", "additions": 0, "deletions": 36, "changes": 36, "file_content_changes": "@@ -1,36 +0,0 @@\n-/* Pandas dataframe css */\n-/* Taken from: https://github.com/spatialaudio/nbsphinx/blob/fb3ba670fc1ba5f54d4c487573dbc1b4ecf7e9ff/src/nbsphinx.py#L587-L619 */\n-\n-table.dataframe {\n-  border: none !important;\n-  border-collapse: collapse;\n-  border-spacing: 0;\n-  border-color: transparent;\n-  color: black;\n-  font-size: 12px;\n-  table-layout: fixed;\n-}\n-table.dataframe thead {\n-  border-bottom: 1px solid black;\n-  vertical-align: bottom;\n-}\n-table.dataframe tr,\n-table.dataframe th,\n-table.dataframe td {\n-  text-align: right;\n-  vertical-align: middle;\n-  padding: 0.5em 0.5em;\n-  line-height: normal;\n-  white-space: normal;\n-  max-width: none;\n-  border: none;\n-}\n-table.dataframe th {\n-  font-weight: bold;\n-}\n-table.dataframe tbody tr:nth-child(odd) {\n-  background: #f5f5f5;\n-}\n-table.dataframe tbody tr:hover {\n-  background: rgba(66, 165, 245, 0.2);\n-}"}, {"filename": "master/_static/gallery-rendered-html.css", "status": "removed", "additions": 0, "deletions": 209, "changes": 209, "file_content_changes": "@@ -1,209 +0,0 @@\n-/* Adapted from notebook/static/style/style.min.css */\n-\n-.rendered_html {\n-  color: #000;\n-  /* any extras will just be numbers: */\n-}\n-.rendered_html em {\n-  font-style: italic;\n-}\n-.rendered_html strong {\n-  font-weight: bold;\n-}\n-.rendered_html u {\n-  text-decoration: underline;\n-}\n-.rendered_html :link {\n-  text-decoration: underline;\n-}\n-.rendered_html :visited {\n-  text-decoration: underline;\n-}\n-.rendered_html h1 {\n-  font-size: 185.7%;\n-  margin: 1.08em 0 0 0;\n-  font-weight: bold;\n-  line-height: 1.0;\n-}\n-.rendered_html h2 {\n-  font-size: 157.1%;\n-  margin: 1.27em 0 0 0;\n-  font-weight: bold;\n-  line-height: 1.0;\n-}\n-.rendered_html h3 {\n-  font-size: 128.6%;\n-  margin: 1.55em 0 0 0;\n-  font-weight: bold;\n-  line-height: 1.0;\n-}\n-.rendered_html h4 {\n-  font-size: 100%;\n-  margin: 2em 0 0 0;\n-  font-weight: bold;\n-  line-height: 1.0;\n-}\n-.rendered_html h5 {\n-  font-size: 100%;\n-  margin: 2em 0 0 0;\n-  font-weight: bold;\n-  line-height: 1.0;\n-  font-style: italic;\n-}\n-.rendered_html h6 {\n-  font-size: 100%;\n-  margin: 2em 0 0 0;\n-  font-weight: bold;\n-  line-height: 1.0;\n-  font-style: italic;\n-}\n-.rendered_html h1:first-child {\n-  margin-top: 0.538em;\n-}\n-.rendered_html h2:first-child {\n-  margin-top: 0.636em;\n-}\n-.rendered_html h3:first-child {\n-  margin-top: 0.777em;\n-}\n-.rendered_html h4:first-child {\n-  margin-top: 1em;\n-}\n-.rendered_html h5:first-child {\n-  margin-top: 1em;\n-}\n-.rendered_html h6:first-child {\n-  margin-top: 1em;\n-}\n-.rendered_html ul:not(.list-inline),\n-.rendered_html ol:not(.list-inline) {\n-  padding-left: 2em;\n-}\n-.rendered_html ul {\n-  list-style: disc;\n-}\n-.rendered_html ul ul {\n-  list-style: square;\n-  margin-top: 0;\n-}\n-.rendered_html ul ul ul {\n-  list-style: circle;\n-}\n-.rendered_html ol {\n-  list-style: decimal;\n-}\n-.rendered_html ol ol {\n-  list-style: upper-alpha;\n-  margin-top: 0;\n-}\n-.rendered_html ol ol ol {\n-  list-style: lower-alpha;\n-}\n-.rendered_html ol ol ol ol {\n-  list-style: lower-roman;\n-}\n-.rendered_html ol ol ol ol ol {\n-  list-style: decimal;\n-}\n-.rendered_html * + ul {\n-  margin-top: 1em;\n-}\n-.rendered_html * + ol {\n-  margin-top: 1em;\n-}\n-.rendered_html hr {\n-  color: black;\n-  background-color: black;\n-}\n-.rendered_html pre {\n-  margin: 1em 2em;\n-  padding: 0px;\n-  background-color: #fff;\n-}\n-.rendered_html code {\n-  background-color: #eff0f1;\n-}\n-.rendered_html p code {\n-  padding: 1px 5px;\n-}\n-.rendered_html pre code {\n-  background-color: #fff;\n-}\n-.rendered_html pre,\n-.rendered_html code {\n-  border: 0;\n-  color: #000;\n-  font-size: 100%;\n-}\n-.rendered_html blockquote {\n-  margin: 1em 2em;\n-}\n-.rendered_html table {\n-  margin-left: auto;\n-  margin-right: auto;\n-  border: none;\n-  border-collapse: collapse;\n-  border-spacing: 0;\n-  color: black;\n-  font-size: 12px;\n-  table-layout: fixed;\n-}\n-.rendered_html thead {\n-  border-bottom: 1px solid black;\n-  vertical-align: bottom;\n-}\n-.rendered_html tr,\n-.rendered_html th,\n-.rendered_html td {\n-  text-align: right;\n-  vertical-align: middle;\n-  padding: 0.5em 0.5em;\n-  line-height: normal;\n-  white-space: normal;\n-  max-width: none;\n-  border: none;\n-}\n-.rendered_html th {\n-  font-weight: bold;\n-}\n-.rendered_html tbody tr:nth-child(odd) {\n-  background: #f5f5f5;\n-}\n-.rendered_html tbody tr:hover {\n-  background: rgba(66, 165, 245, 0.2);\n-}\n-.rendered_html * + table {\n-  margin-top: 1em;\n-}\n-.rendered_html p {\n-  text-align: left;\n-}\n-.rendered_html * + p {\n-  margin-top: 1em;\n-}\n-.rendered_html img {\n-  display: block;\n-  margin-left: auto;\n-  margin-right: auto;\n-}\n-.rendered_html * + img {\n-  margin-top: 1em;\n-}\n-.rendered_html img,\n-.rendered_html svg {\n-  max-width: 100%;\n-  height: auto;\n-}\n-.rendered_html img.unconfined,\n-.rendered_html svg.unconfined {\n-  max-width: none;\n-}\n-.rendered_html .alert {\n-  margin-bottom: initial;\n-}\n-.rendered_html * + .alert {\n-  margin-top: 1em;\n-}\n-[dir=\"rtl\"] .rendered_html p {\n-  text-align: right;\n-}"}, {"filename": "master/_static/gallery.css", "status": "removed", "additions": 0, "deletions": 204, "changes": 204, "file_content_changes": "@@ -1,204 +0,0 @@\n-/*\n-Sphinx-Gallery has compatible CSS to fix default sphinx themes\n-Tested for Sphinx 1.3.1 for all themes: default, alabaster, sphinxdoc,\n-scrolls, agogo, traditional, nature, haiku, pyramid\n-Tested for Read the Docs theme 0.1.7 */\n-.sphx-glr-thumbcontainer {\n-  background: #fff;\n-  border: solid #fff 1px;\n-  -moz-border-radius: 5px;\n-  -webkit-border-radius: 5px;\n-  border-radius: 5px;\n-  box-shadow: none;\n-  float: left;\n-  margin: 5px;\n-  min-height: 230px;\n-  padding-top: 5px;\n-  position: relative;\n-}\n-.sphx-glr-thumbcontainer:hover {\n-  border: solid #b4ddfc 1px;\n-  box-shadow: 0 0 15px rgba(142, 176, 202, 0.5);\n-}\n-.sphx-glr-thumbcontainer a.internal {\n-  bottom: 0;\n-  display: block;\n-  left: 0;\n-  padding: 150px 10px 0;\n-  position: absolute;\n-  right: 0;\n-  top: 0;\n-}\n-/* Next one is to avoid Sphinx traditional theme to cover all the\n-thumbnail with its default link Background color */\n-.sphx-glr-thumbcontainer a.internal:hover {\n-  background-color: transparent;\n-}\n-\n-.sphx-glr-thumbcontainer p {\n-  margin: 0 0 .1em 0;\n-}\n-.sphx-glr-thumbcontainer .figure {\n-  margin: 10px;\n-  width: 160px;\n-}\n-.sphx-glr-thumbcontainer img {\n-  display: inline;\n-  max-height: 112px;\n-  max-width: 160px;\n-}\n-.sphx-glr-thumbcontainer[tooltip]:hover:after {\n-  background: rgba(0, 0, 0, 0.8);\n-  -webkit-border-radius: 5px;\n-  -moz-border-radius: 5px;\n-  border-radius: 5px;\n-  color: #fff;\n-  content: attr(tooltip);\n-  left: 95%;\n-  padding: 5px 15px;\n-  position: absolute;\n-  z-index: 98;\n-  width: 220px;\n-  bottom: 52%;\n-}\n-.sphx-glr-thumbcontainer[tooltip]:hover:before {\n-  border: solid;\n-  border-color: #333 transparent;\n-  border-width: 18px 0 0 20px;\n-  bottom: 58%;\n-  content: '';\n-  left: 85%;\n-  position: absolute;\n-  z-index: 99;\n-}\n-\n-.sphx-glr-script-out {\n-  color: #888;\n-  margin: 0;\n-}\n-p.sphx-glr-script-out {\n-    padding-top: 0.7em;\n-}\n-.sphx-glr-script-out .highlight {\n-  background-color: transparent;\n-  margin-left: 2.5em;\n-  margin-top: -2.1em;\n-}\n-.sphx-glr-script-out .highlight pre {\n-  background-color: #fafae2;\n-  border: 0;\n-  max-height: 30em;\n-  overflow: auto;\n-  padding-left: 1ex;\n-  margin: 0px;\n-  word-break: break-word;\n-}\n-.sphx-glr-script-out + p {\n-  margin-top: 1.8em;\n-}\n-blockquote.sphx-glr-script-out {\n-  margin-left: 0pt;\n-}\n-.sphx-glr-script-out.highlight-pytb .highlight pre {\n-  color: #000;\n-  background-color: #ffe4e4;\n-  border: 1px solid #f66;\n-  margin-top: 10px;\n-  padding: 7px;\n-}\n-\n-div.sphx-glr-footer {\n-    text-align: center;\n-}\n-\n-div.sphx-glr-download {\n-  margin: 1em auto;\n-  vertical-align: middle;\n-}\n-\n-div.sphx-glr-download a {\n-  background-color: #ffc;\n-  background-image: linear-gradient(to bottom, #FFC, #d5d57e);\n-  border-radius: 4px;\n-  border: 1px solid #c2c22d;\n-  color: #000;\n-  display: inline-block;\n-  font-weight: bold;\n-  padding: 1ex;\n-  text-align: center;\n-}\n-\n-div.sphx-glr-download code.download {\n-  display: inline-block;\n-  white-space: normal;\n-  word-break: normal;\n-  overflow-wrap: break-word;\n-  /* border and background are given by the enclosing 'a' */\n-  border: none;\n-  background: none;\n-}\n-\n-div.sphx-glr-download a:hover {\n-  box-shadow: inset 0 1px 0 rgba(255,255,255,.1), 0 1px 5px rgba(0,0,0,.25);\n-  text-decoration: none;\n-  background-image: none;\n-  background-color: #d5d57e;\n-}\n-\n-.sphx-glr-example-title:target::before {\n-  display: block;\n-  content: \"\";\n-  margin-top: -50px;\n-  height: 50px;\n-  visibility: hidden;\n-}\n-\n-ul.sphx-glr-horizontal {\n-  list-style: none;\n-  padding: 0;\n-}\n-ul.sphx-glr-horizontal li {\n-  display: inline;\n-}\n-ul.sphx-glr-horizontal img {\n-  height: auto !important;\n-}\n-\n-.sphx-glr-single-img {\n-  margin: auto;\n-  display: block;\n-  max-width: 100%;\n-}\n-\n-.sphx-glr-multi-img {\n-  max-width: 42%;\n-  height: auto;\n-}\n-\n-div.sphx-glr-animation {\n-  margin: auto;\n-  display: block;\n-  max-width: 100%;\n-}\n-div.sphx-glr-animation .animation{\n-  display: block;\n-}\n-\n-p.sphx-glr-signature a.reference.external {\n-  -moz-border-radius: 5px;\n-  -webkit-border-radius: 5px;\n-  border-radius: 5px;\n-  padding: 3px;\n-  font-size: 75%;\n-  text-align: right;\n-  margin-left: auto;\n-  display: table;\n-}\n-\n-.sphx-glr-clear{\n-  clear: both;\n-}\n-\n-a.sphx-glr-backref-instance {\n-  text-decoration: none;\n-}"}, {"filename": "master/_static/jquery-3.5.1.js", "status": "removed", "additions": 0, "deletions": 10872, "changes": 10872, "file_content_changes": "N/A"}, {"filename": "master/_static/jquery.js", "status": "removed", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -1,2 +0,0 @@\n-/*! jQuery v3.5.1 | (c) JS Foundation and other contributors | jquery.org/license */\n-!function(e,t){\"use strict\";\"object\"==typeof module&&\"object\"==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(\"jQuery requires a window with a document\");return t(e)}:t(e)}(\"undefined\"!=typeof window?window:this,function(C,e){\"use strict\";var t=[],r=Object.getPrototypeOf,s=t.slice,g=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},u=t.push,i=t.indexOf,n={},o=n.toString,v=n.hasOwnProperty,a=v.toString,l=a.call(Object),y={},m=function(e){return\"function\"==typeof e&&\"number\"!=typeof e.nodeType},x=function(e){return null!=e&&e===e.window},E=C.document,c={type:!0,src:!0,nonce:!0,noModule:!0};function b(e,t,n){var r,i,o=(n=n||E).createElement(\"script\");if(o.text=e,t)for(r in c)(i=t[r]||t.getAttribute&&t.getAttribute(r))&&o.setAttribute(r,i);n.head.appendChild(o).parentNode.removeChild(o)}function w(e){return null==e?e+\"\":\"object\"==typeof e||\"function\"==typeof e?n[o.call(e)]||\"object\":typeof e}var f=\"3.5.1\",S=function(e,t){return new S.fn.init(e,t)};function p(e){var t=!!e&&\"length\"in e&&e.length,n=w(e);return!m(e)&&!x(e)&&(\"array\"===n||0===t||\"number\"==typeof t&&0<t&&t-1 in e)}S.fn=S.prototype={jquery:f,constructor:S,length:0,toArray:function(){return s.call(this)},get:function(e){return null==e?s.call(this):e<0?this[e+this.length]:this[e]},pushStack:function(e){var t=S.merge(this.constructor(),e);return t.prevObject=this,t},each:function(e){return S.each(this,e)},map:function(n){return this.pushStack(S.map(this,function(e,t){return n.call(e,t,e)}))},slice:function(){return this.pushStack(s.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},even:function(){return this.pushStack(S.grep(this,function(e,t){return(t+1)%2}))},odd:function(){return this.pushStack(S.grep(this,function(e,t){return t%2}))},eq:function(e){var t=this.length,n=+e+(e<0?t:0);return this.pushStack(0<=n&&n<t?[this[n]]:[])},end:function(){return this.prevObject||this.constructor()},push:u,sort:t.sort,splice:t.splice},S.extend=S.fn.extend=function(){var e,t,n,r,i,o,a=arguments[0]||{},s=1,u=arguments.length,l=!1;for(\"boolean\"==typeof a&&(l=a,a=arguments[s]||{},s++),\"object\"==typeof a||m(a)||(a={}),s===u&&(a=this,s--);s<u;s++)if(null!=(e=arguments[s]))for(t in e)r=e[t],\"__proto__\"!==t&&a!==r&&(l&&r&&(S.isPlainObject(r)||(i=Array.isArray(r)))?(n=a[t],o=i&&!Array.isArray(n)?[]:i||S.isPlainObject(n)?n:{},i=!1,a[t]=S.extend(l,o,r)):void 0!==r&&(a[t]=r));return a},S.extend({expando:\"jQuery\"+(f+Math.random()).replace(/\\D/g,\"\"),isReady:!0,error:function(e){throw new Error(e)},noop:function(){},isPlainObject:function(e){var t,n;return!(!e||\"[object Object]\"!==o.call(e))&&(!(t=r(e))||\"function\"==typeof(n=v.call(t,\"constructor\")&&t.constructor)&&a.call(n)===l)},isEmptyObject:function(e){var t;for(t in e)return!1;return!0},globalEval:function(e,t,n){b(e,{nonce:t&&t.nonce},n)},each:function(e,t){var n,r=0;if(p(e)){for(n=e.length;r<n;r++)if(!1===t.call(e[r],r,e[r]))break}else for(r in e)if(!1===t.call(e[r],r,e[r]))break;return e},makeArray:function(e,t){var n=t||[];return null!=e&&(p(Object(e))?S.merge(n,\"string\"==typeof e?[e]:e):u.call(n,e)),n},inArray:function(e,t,n){return null==t?-1:i.call(t,e,n)},merge:function(e,t){for(var n=+t.length,r=0,i=e.length;r<n;r++)e[i++]=t[r];return e.length=i,e},grep:function(e,t,n){for(var r=[],i=0,o=e.length,a=!n;i<o;i++)!t(e[i],i)!==a&&r.push(e[i]);return r},map:function(e,t,n){var r,i,o=0,a=[];if(p(e))for(r=e.length;o<r;o++)null!=(i=t(e[o],o,n))&&a.push(i);else for(o in e)null!=(i=t(e[o],o,n))&&a.push(i);return g(a)},guid:1,support:y}),\"function\"==typeof Symbol&&(S.fn[Symbol.iterator]=t[Symbol.iterator]),S.each(\"Boolean Number String Function Array Date RegExp Object Error Symbol\".split(\" \"),function(e,t){n[\"[object \"+t+\"]\"]=t.toLowerCase()});var d=function(n){var e,d,b,o,i,h,f,g,w,u,l,T,C,a,E,v,s,c,y,S=\"sizzle\"+1*new Date,p=n.document,k=0,r=0,m=ue(),x=ue(),A=ue(),N=ue(),D=function(e,t){return e===t&&(l=!0),0},j={}.hasOwnProperty,t=[],q=t.pop,L=t.push,H=t.push,O=t.slice,P=function(e,t){for(var n=0,r=e.length;n<r;n++)if(e[n]===t)return n;return-1},R=\"checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped\",M=\"[\\\\x20\\\\t\\\\r\\\\n\\\\f]\",I=\"(?:\\\\\\\\[\\\\da-fA-F]{1,6}\"+M+\"?|\\\\\\\\[^\\\\r\\\\n\\\\f]|[\\\\w-]|[^\\0-\\\\x7f])+\",W=\"\\\\[\"+M+\"*(\"+I+\")(?:\"+M+\"*([*^$|!~]?=)\"+M+\"*(?:'((?:\\\\\\\\.|[^\\\\\\\\'])*)'|\\\"((?:\\\\\\\\.|[^\\\\\\\\\\\"])*)\\\"|(\"+I+\"))|)\"+M+\"*\\\\]\",F=\":(\"+I+\")(?:\\\\((('((?:\\\\\\\\.|[^\\\\\\\\'])*)'|\\\"((?:\\\\\\\\.|[^\\\\\\\\\\\"])*)\\\")|((?:\\\\\\\\.|[^\\\\\\\\()[\\\\]]|\"+W+\")*)|.*)\\\\)|)\",B=new RegExp(M+\"+\",\"g\"),$=new RegExp(\"^\"+M+\"+|((?:^|[^\\\\\\\\])(?:\\\\\\\\.)*)\"+M+\"+$\",\"g\"),_=new RegExp(\"^\"+M+\"*,\"+M+\"*\"),z=new RegExp(\"^\"+M+\"*([>+~]|\"+M+\")\"+M+\"*\"),U=new RegExp(M+\"|>\"),X=new RegExp(F),V=new RegExp(\"^\"+I+\"$\"),G={ID:new RegExp(\"^#(\"+I+\")\"),CLASS:new RegExp(\"^\\\\.(\"+I+\")\"),TAG:new RegExp(\"^(\"+I+\"|[*])\"),ATTR:new RegExp(\"^\"+W),PSEUDO:new RegExp(\"^\"+F),CHILD:new RegExp(\"^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\\\(\"+M+\"*(even|odd|(([+-]|)(\\\\d*)n|)\"+M+\"*(?:([+-]|)\"+M+\"*(\\\\d+)|))\"+M+\"*\\\\)|)\",\"i\"),bool:new RegExp(\"^(?:\"+R+\")$\",\"i\"),needsContext:new RegExp(\"^\"+M+\"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\\\(\"+M+\"*((?:-\\\\d)?\\\\d*)\"+M+\"*\\\\)|)(?=[^-]|$)\",\"i\")},Y=/HTML$/i,Q=/^(?:input|select|textarea|button)$/i,J=/^h\\d$/i,K=/^[^{]+\\{\\s*\\[native \\w/,Z=/^(?:#([\\w-]+)|(\\w+)|\\.([\\w-]+))$/,ee=/[+~]/,te=new RegExp(\"\\\\\\\\[\\\\da-fA-F]{1,6}\"+M+\"?|\\\\\\\\([^\\\\r\\\\n\\\\f])\",\"g\"),ne=function(e,t){var n=\"0x\"+e.slice(1)-65536;return t||(n<0?String.fromCharCode(n+65536):String.fromCharCode(n>>10|55296,1023&n|56320))},re=/([\\0-\\x1f\\x7f]|^-?\\d)|^-$|[^\\0-\\x1f\\x7f-\\uFFFF\\w-]/g,ie=function(e,t){return t?\"\\0\"===e?\"\\ufffd\":e.slice(0,-1)+\"\\\\\"+e.charCodeAt(e.length-1).toString(16)+\" \":\"\\\\\"+e},oe=function(){T()},ae=be(function(e){return!0===e.disabled&&\"fieldset\"===e.nodeName.toLowerCase()},{dir:\"parentNode\",next:\"legend\"});try{H.apply(t=O.call(p.childNodes),p.childNodes),t[p.childNodes.length].nodeType}catch(e){H={apply:t.length?function(e,t){L.apply(e,O.call(t))}:function(e,t){var n=e.length,r=0;while(e[n++]=t[r++]);e.length=n-1}}}function se(t,e,n,r){var i,o,a,s,u,l,c,f=e&&e.ownerDocument,p=e?e.nodeType:9;if(n=n||[],\"string\"!=typeof t||!t||1!==p&&9!==p&&11!==p)return n;if(!r&&(T(e),e=e||C,E)){if(11!==p&&(u=Z.exec(t)))if(i=u[1]){if(9===p){if(!(a=e.getElementById(i)))return n;if(a.id===i)return n.push(a),n}else if(f&&(a=f.getElementById(i))&&y(e,a)&&a.id===i)return n.push(a),n}else{if(u[2])return H.apply(n,e.getElementsByTagName(t)),n;if((i=u[3])&&d.getElementsByClassName&&e.getElementsByClassName)return H.apply(n,e.getElementsByClassName(i)),n}if(d.qsa&&!N[t+\" \"]&&(!v||!v.test(t))&&(1!==p||\"object\"!==e.nodeName.toLowerCase())){if(c=t,f=e,1===p&&(U.test(t)||z.test(t))){(f=ee.test(t)&&ye(e.parentNode)||e)===e&&d.scope||((s=e.getAttribute(\"id\"))?s=s.replace(re,ie):e.setAttribute(\"id\",s=S)),o=(l=h(t)).length;while(o--)l[o]=(s?\"#\"+s:\":scope\")+\" \"+xe(l[o]);c=l.join(\",\")}try{return H.apply(n,f.querySelectorAll(c)),n}catch(e){N(t,!0)}finally{s===S&&e.removeAttribute(\"id\")}}}return g(t.replace($,\"$1\"),e,n,r)}function ue(){var r=[];return function e(t,n){return r.push(t+\" \")>b.cacheLength&&delete e[r.shift()],e[t+\" \"]=n}}function le(e){return e[S]=!0,e}function ce(e){var t=C.createElement(\"fieldset\");try{return!!e(t)}catch(e){return!1}finally{t.parentNode&&t.parentNode.removeChild(t),t=null}}function fe(e,t){var n=e.split(\"|\"),r=n.length;while(r--)b.attrHandle[n[r]]=t}function pe(e,t){var n=t&&e,r=n&&1===e.nodeType&&1===t.nodeType&&e.sourceIndex-t.sourceIndex;if(r)return r;if(n)while(n=n.nextSibling)if(n===t)return-1;return e?1:-1}function de(t){return function(e){return\"input\"===e.nodeName.toLowerCase()&&e.type===t}}function he(n){return function(e){var t=e.nodeName.toLowerCase();return(\"input\"===t||\"button\"===t)&&e.type===n}}function ge(t){return function(e){return\"form\"in e?e.parentNode&&!1===e.disabled?\"label\"in e?\"label\"in e.parentNode?e.parentNode.disabled===t:e.disabled===t:e.isDisabled===t||e.isDisabled!==!t&&ae(e)===t:e.disabled===t:\"label\"in e&&e.disabled===t}}function ve(a){return le(function(o){return o=+o,le(function(e,t){var n,r=a([],e.length,o),i=r.length;while(i--)e[n=r[i]]&&(e[n]=!(t[n]=e[n]))})})}function ye(e){return e&&\"undefined\"!=typeof e.getElementsByTagName&&e}for(e in d=se.support={},i=se.isXML=function(e){var t=e.namespaceURI,n=(e.ownerDocument||e).documentElement;return!Y.test(t||n&&n.nodeName||\"HTML\")},T=se.setDocument=function(e){var t,n,r=e?e.ownerDocument||e:p;return r!=C&&9===r.nodeType&&r.documentElement&&(a=(C=r).documentElement,E=!i(C),p!=C&&(n=C.defaultView)&&n.top!==n&&(n.addEventListener?n.addEventListener(\"unload\",oe,!1):n.attachEvent&&n.attachEvent(\"onunload\",oe)),d.scope=ce(function(e){return a.appendChild(e).appendChild(C.createElement(\"div\")),\"undefined\"!=typeof e.querySelectorAll&&!e.querySelectorAll(\":scope fieldset div\").length}),d.attributes=ce(function(e){return e.className=\"i\",!e.getAttribute(\"className\")}),d.getElementsByTagName=ce(function(e){return e.appendChild(C.createComment(\"\")),!e.getElementsByTagName(\"*\").length}),d.getElementsByClassName=K.test(C.getElementsByClassName),d.getById=ce(function(e){return a.appendChild(e).id=S,!C.getElementsByName||!C.getElementsByName(S).length}),d.getById?(b.filter.ID=function(e){var t=e.replace(te,ne);return function(e){return e.getAttribute(\"id\")===t}},b.find.ID=function(e,t){if(\"undefined\"!=typeof t.getElementById&&E){var n=t.getElementById(e);return n?[n]:[]}}):(b.filter.ID=function(e){var n=e.replace(te,ne);return function(e){var t=\"undefined\"!=typeof e.getAttributeNode&&e.getAttributeNode(\"id\");return t&&t.value===n}},b.find.ID=function(e,t){if(\"undefined\"!=typeof t.getElementById&&E){var n,r,i,o=t.getElementById(e);if(o){if((n=o.getAttributeNode(\"id\"))&&n.value===e)return[o];i=t.getElementsByName(e),r=0;while(o=i[r++])if((n=o.getAttributeNode(\"id\"))&&n.value===e)return[o]}return[]}}),b.find.TAG=d.getElementsByTagName?function(e,t){return\"undefined\"!=typeof t.getElementsByTagName?t.getElementsByTagName(e):d.qsa?t.querySelectorAll(e):void 0}:function(e,t){var n,r=[],i=0,o=t.getElementsByTagName(e);if(\"*\"===e){while(n=o[i++])1===n.nodeType&&r.push(n);return r}return o},b.find.CLASS=d.getElementsByClassName&&function(e,t){if(\"undefined\"!=typeof t.getElementsByClassName&&E)return t.getElementsByClassName(e)},s=[],v=[],(d.qsa=K.test(C.querySelectorAll))&&(ce(function(e){var t;a.appendChild(e).innerHTML=\"<a id='\"+S+\"'></a><select id='\"+S+\"-\\r\\\\' msallowcapture=''><option selected=''></option></select>\",e.querySelectorAll(\"[msallowcapture^='']\").length&&v.push(\"[*^$]=\"+M+\"*(?:''|\\\"\\\")\"),e.querySelectorAll(\"[selected]\").length||v.push(\"\\\\[\"+M+\"*(?:value|\"+R+\")\"),e.querySelectorAll(\"[id~=\"+S+\"-]\").length||v.push(\"~=\"),(t=C.createElement(\"input\")).setAttribute(\"name\",\"\"),e.appendChild(t),e.querySelectorAll(\"[name='']\").length||v.push(\"\\\\[\"+M+\"*name\"+M+\"*=\"+M+\"*(?:''|\\\"\\\")\"),e.querySelectorAll(\":checked\").length||v.push(\":checked\"),e.querySelectorAll(\"a#\"+S+\"+*\").length||v.push(\".#.+[+~]\"),e.querySelectorAll(\"\\\\\\f\"),v.push(\"[\\\\r\\\\n\\\\f]\")}),ce(function(e){e.innerHTML=\"<a href='' disabled='disabled'></a><select disabled='disabled'><option/></select>\";var t=C.createElement(\"input\");t.setAttribute(\"type\",\"hidden\"),e.appendChild(t).setAttribute(\"name\",\"D\"),e.querySelectorAll(\"[name=d]\").length&&v.push(\"name\"+M+\"*[*^$|!~]?=\"),2!==e.querySelectorAll(\":enabled\").length&&v.push(\":enabled\",\":disabled\"),a.appendChild(e).disabled=!0,2!==e.querySelectorAll(\":disabled\").length&&v.push(\":enabled\",\":disabled\"),e.querySelectorAll(\"*,:x\"),v.push(\",.*:\")})),(d.matchesSelector=K.test(c=a.matches||a.webkitMatchesSelector||a.mozMatchesSelector||a.oMatchesSelector||a.msMatchesSelector))&&ce(function(e){d.disconnectedMatch=c.call(e,\"*\"),c.call(e,\"[s!='']:x\"),s.push(\"!=\",F)}),v=v.length&&new RegExp(v.join(\"|\")),s=s.length&&new RegExp(s.join(\"|\")),t=K.test(a.compareDocumentPosition),y=t||K.test(a.contains)?function(e,t){var n=9===e.nodeType?e.documentElement:e,r=t&&t.parentNode;return e===r||!(!r||1!==r.nodeType||!(n.contains?n.contains(r):e.compareDocumentPosition&&16&e.compareDocumentPosition(r)))}:function(e,t){if(t)while(t=t.parentNode)if(t===e)return!0;return!1},D=t?function(e,t){if(e===t)return l=!0,0;var n=!e.compareDocumentPosition-!t.compareDocumentPosition;return n||(1&(n=(e.ownerDocument||e)==(t.ownerDocument||t)?e.compareDocumentPosition(t):1)||!d.sortDetached&&t.compareDocumentPosition(e)===n?e==C||e.ownerDocument==p&&y(p,e)?-1:t==C||t.ownerDocument==p&&y(p,t)?1:u?P(u,e)-P(u,t):0:4&n?-1:1)}:function(e,t){if(e===t)return l=!0,0;var n,r=0,i=e.parentNode,o=t.parentNode,a=[e],s=[t];if(!i||!o)return e==C?-1:t==C?1:i?-1:o?1:u?P(u,e)-P(u,t):0;if(i===o)return pe(e,t);n=e;while(n=n.parentNode)a.unshift(n);n=t;while(n=n.parentNode)s.unshift(n);while(a[r]===s[r])r++;return r?pe(a[r],s[r]):a[r]==p?-1:s[r]==p?1:0}),C},se.matches=function(e,t){return se(e,null,null,t)},se.matchesSelector=function(e,t){if(T(e),d.matchesSelector&&E&&!N[t+\" \"]&&(!s||!s.test(t))&&(!v||!v.test(t)))try{var n=c.call(e,t);if(n||d.disconnectedMatch||e.document&&11!==e.document.nodeType)return n}catch(e){N(t,!0)}return 0<se(t,C,null,[e]).length},se.contains=function(e,t){return(e.ownerDocument||e)!=C&&T(e),y(e,t)},se.attr=function(e,t){(e.ownerDocument||e)!=C&&T(e);var n=b.attrHandle[t.toLowerCase()],r=n&&j.call(b.attrHandle,t.toLowerCase())?n(e,t,!E):void 0;return void 0!==r?r:d.attributes||!E?e.getAttribute(t):(r=e.getAttributeNode(t))&&r.specified?r.value:null},se.escape=function(e){return(e+\"\").replace(re,ie)},se.error=function(e){throw new Error(\"Syntax error, unrecognized expression: \"+e)},se.uniqueSort=function(e){var t,n=[],r=0,i=0;if(l=!d.detectDuplicates,u=!d.sortStable&&e.slice(0),e.sort(D),l){while(t=e[i++])t===e[i]&&(r=n.push(i));while(r--)e.splice(n[r],1)}return u=null,e},o=se.getText=function(e){var t,n=\"\",r=0,i=e.nodeType;if(i){if(1===i||9===i||11===i){if(\"string\"==typeof e.textContent)return e.textContent;for(e=e.firstChild;e;e=e.nextSibling)n+=o(e)}else if(3===i||4===i)return e.nodeValue}else while(t=e[r++])n+=o(t);return n},(b=se.selectors={cacheLength:50,createPseudo:le,match:G,attrHandle:{},find:{},relative:{\">\":{dir:\"parentNode\",first:!0},\" \":{dir:\"parentNode\"},\"+\":{dir:\"previousSibling\",first:!0},\"~\":{dir:\"previousSibling\"}},preFilter:{ATTR:function(e){return e[1]=e[1].replace(te,ne),e[3]=(e[3]||e[4]||e[5]||\"\").replace(te,ne),\"~=\"===e[2]&&(e[3]=\" \"+e[3]+\" \"),e.slice(0,4)},CHILD:function(e){return e[1]=e[1].toLowerCase(),\"nth\"===e[1].slice(0,3)?(e[3]||se.error(e[0]),e[4]=+(e[4]?e[5]+(e[6]||1):2*(\"even\"===e[3]||\"odd\"===e[3])),e[5]=+(e[7]+e[8]||\"odd\"===e[3])):e[3]&&se.error(e[0]),e},PSEUDO:function(e){var t,n=!e[6]&&e[2];return G.CHILD.test(e[0])?null:(e[3]?e[2]=e[4]||e[5]||\"\":n&&X.test(n)&&(t=h(n,!0))&&(t=n.indexOf(\")\",n.length-t)-n.length)&&(e[0]=e[0].slice(0,t),e[2]=n.slice(0,t)),e.slice(0,3))}},filter:{TAG:function(e){var t=e.replace(te,ne).toLowerCase();return\"*\"===e?function(){return!0}:function(e){return e.nodeName&&e.nodeName.toLowerCase()===t}},CLASS:function(e){var t=m[e+\" \"];return t||(t=new RegExp(\"(^|\"+M+\")\"+e+\"(\"+M+\"|$)\"))&&m(e,function(e){return t.test(\"string\"==typeof e.className&&e.className||\"undefined\"!=typeof e.getAttribute&&e.getAttribute(\"class\")||\"\")})},ATTR:function(n,r,i){return function(e){var t=se.attr(e,n);return null==t?\"!=\"===r:!r||(t+=\"\",\"=\"===r?t===i:\"!=\"===r?t!==i:\"^=\"===r?i&&0===t.indexOf(i):\"*=\"===r?i&&-1<t.indexOf(i):\"$=\"===r?i&&t.slice(-i.length)===i:\"~=\"===r?-1<(\" \"+t.replace(B,\" \")+\" \").indexOf(i):\"|=\"===r&&(t===i||t.slice(0,i.length+1)===i+\"-\"))}},CHILD:function(h,e,t,g,v){var y=\"nth\"!==h.slice(0,3),m=\"last\"!==h.slice(-4),x=\"of-type\"===e;return 1===g&&0===v?function(e){return!!e.parentNode}:function(e,t,n){var r,i,o,a,s,u,l=y!==m?\"nextSibling\":\"previousSibling\",c=e.parentNode,f=x&&e.nodeName.toLowerCase(),p=!n&&!x,d=!1;if(c){if(y){while(l){a=e;while(a=a[l])if(x?a.nodeName.toLowerCase()===f:1===a.nodeType)return!1;u=l=\"only\"===h&&!u&&\"nextSibling\"}return!0}if(u=[m?c.firstChild:c.lastChild],m&&p){d=(s=(r=(i=(o=(a=c)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===k&&r[1])&&r[2],a=s&&c.childNodes[s];while(a=++s&&a&&a[l]||(d=s=0)||u.pop())if(1===a.nodeType&&++d&&a===e){i[h]=[k,s,d];break}}else if(p&&(d=s=(r=(i=(o=(a=e)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===k&&r[1]),!1===d)while(a=++s&&a&&a[l]||(d=s=0)||u.pop())if((x?a.nodeName.toLowerCase()===f:1===a.nodeType)&&++d&&(p&&((i=(o=a[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]=[k,d]),a===e))break;return(d-=v)===g||d%g==0&&0<=d/g}}},PSEUDO:function(e,o){var t,a=b.pseudos[e]||b.setFilters[e.toLowerCase()]||se.error(\"unsupported pseudo: \"+e);return a[S]?a(o):1<a.length?(t=[e,e,\"\",o],b.setFilters.hasOwnProperty(e.toLowerCase())?le(function(e,t){var n,r=a(e,o),i=r.length;while(i--)e[n=P(e,r[i])]=!(t[n]=r[i])}):function(e){return a(e,0,t)}):a}},pseudos:{not:le(function(e){var r=[],i=[],s=f(e.replace($,\"$1\"));return s[S]?le(function(e,t,n,r){var i,o=s(e,null,r,[]),a=e.length;while(a--)(i=o[a])&&(e[a]=!(t[a]=i))}):function(e,t,n){return r[0]=e,s(r,null,n,i),r[0]=null,!i.pop()}}),has:le(function(t){return function(e){return 0<se(t,e).length}}),contains:le(function(t){return t=t.replace(te,ne),function(e){return-1<(e.textContent||o(e)).indexOf(t)}}),lang:le(function(n){return V.test(n||\"\")||se.error(\"unsupported lang: \"+n),n=n.replace(te,ne).toLowerCase(),function(e){var t;do{if(t=E?e.lang:e.getAttribute(\"xml:lang\")||e.getAttribute(\"lang\"))return(t=t.toLowerCase())===n||0===t.indexOf(n+\"-\")}while((e=e.parentNode)&&1===e.nodeType);return!1}}),target:function(e){var t=n.location&&n.location.hash;return t&&t.slice(1)===e.id},root:function(e){return e===a},focus:function(e){return e===C.activeElement&&(!C.hasFocus||C.hasFocus())&&!!(e.type||e.href||~e.tabIndex)},enabled:ge(!1),disabled:ge(!0),checked:function(e){var t=e.nodeName.toLowerCase();return\"input\"===t&&!!e.checked||\"option\"===t&&!!e.selected},selected:function(e){return e.parentNode&&e.parentNode.selectedIndex,!0===e.selected},empty:function(e){for(e=e.firstChild;e;e=e.nextSibling)if(e.nodeType<6)return!1;return!0},parent:function(e){return!b.pseudos.empty(e)},header:function(e){return J.test(e.nodeName)},input:function(e){return Q.test(e.nodeName)},button:function(e){var t=e.nodeName.toLowerCase();return\"input\"===t&&\"button\"===e.type||\"button\"===t},text:function(e){var t;return\"input\"===e.nodeName.toLowerCase()&&\"text\"===e.type&&(null==(t=e.getAttribute(\"type\"))||\"text\"===t.toLowerCase())},first:ve(function(){return[0]}),last:ve(function(e,t){return[t-1]}),eq:ve(function(e,t,n){return[n<0?n+t:n]}),even:ve(function(e,t){for(var n=0;n<t;n+=2)e.push(n);return e}),odd:ve(function(e,t){for(var n=1;n<t;n+=2)e.push(n);return e}),lt:ve(function(e,t,n){for(var r=n<0?n+t:t<n?t:n;0<=--r;)e.push(r);return e}),gt:ve(function(e,t,n){for(var r=n<0?n+t:n;++r<t;)e.push(r);return e})}}).pseudos.nth=b.pseudos.eq,{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})b.pseudos[e]=de(e);for(e in{submit:!0,reset:!0})b.pseudos[e]=he(e);function me(){}function xe(e){for(var t=0,n=e.length,r=\"\";t<n;t++)r+=e[t].value;return r}function be(s,e,t){var u=e.dir,l=e.next,c=l||u,f=t&&\"parentNode\"===c,p=r++;return e.first?function(e,t,n){while(e=e[u])if(1===e.nodeType||f)return s(e,t,n);return!1}:function(e,t,n){var r,i,o,a=[k,p];if(n){while(e=e[u])if((1===e.nodeType||f)&&s(e,t,n))return!0}else while(e=e[u])if(1===e.nodeType||f)if(i=(o=e[S]||(e[S]={}))[e.uniqueID]||(o[e.uniqueID]={}),l&&l===e.nodeName.toLowerCase())e=e[u]||e;else{if((r=i[c])&&r[0]===k&&r[1]===p)return a[2]=r[2];if((i[c]=a)[2]=s(e,t,n))return!0}return!1}}function we(i){return 1<i.length?function(e,t,n){var r=i.length;while(r--)if(!i[r](e,t,n))return!1;return!0}:i[0]}function Te(e,t,n,r,i){for(var o,a=[],s=0,u=e.length,l=null!=t;s<u;s++)(o=e[s])&&(n&&!n(o,r,i)||(a.push(o),l&&t.push(s)));return a}function Ce(d,h,g,v,y,e){return v&&!v[S]&&(v=Ce(v)),y&&!y[S]&&(y=Ce(y,e)),le(function(e,t,n,r){var i,o,a,s=[],u=[],l=t.length,c=e||function(e,t,n){for(var r=0,i=t.length;r<i;r++)se(e,t[r],n);return n}(h||\"*\",n.nodeType?[n]:n,[]),f=!d||!e&&h?c:Te(c,s,d,n,r),p=g?y||(e?d:l||v)?[]:t:f;if(g&&g(f,p,n,r),v){i=Te(p,u),v(i,[],n,r),o=i.length;while(o--)(a=i[o])&&(p[u[o]]=!(f[u[o]]=a))}if(e){if(y||d){if(y){i=[],o=p.length;while(o--)(a=p[o])&&i.push(f[o]=a);y(null,p=[],i,r)}o=p.length;while(o--)(a=p[o])&&-1<(i=y?P(e,a):s[o])&&(e[i]=!(t[i]=a))}}else p=Te(p===t?p.splice(l,p.length):p),y?y(null,t,p,r):H.apply(t,p)})}function Ee(e){for(var i,t,n,r=e.length,o=b.relative[e[0].type],a=o||b.relative[\" \"],s=o?1:0,u=be(function(e){return e===i},a,!0),l=be(function(e){return-1<P(i,e)},a,!0),c=[function(e,t,n){var r=!o&&(n||t!==w)||((i=t).nodeType?u(e,t,n):l(e,t,n));return i=null,r}];s<r;s++)if(t=b.relative[e[s].type])c=[be(we(c),t)];else{if((t=b.filter[e[s].type].apply(null,e[s].matches))[S]){for(n=++s;n<r;n++)if(b.relative[e[n].type])break;return Ce(1<s&&we(c),1<s&&xe(e.slice(0,s-1).concat({value:\" \"===e[s-2].type?\"*\":\"\"})).replace($,\"$1\"),t,s<n&&Ee(e.slice(s,n)),n<r&&Ee(e=e.slice(n)),n<r&&xe(e))}c.push(t)}return we(c)}return me.prototype=b.filters=b.pseudos,b.setFilters=new me,h=se.tokenize=function(e,t){var n,r,i,o,a,s,u,l=x[e+\" \"];if(l)return t?0:l.slice(0);a=e,s=[],u=b.preFilter;while(a){for(o in n&&!(r=_.exec(a))||(r&&(a=a.slice(r[0].length)||a),s.push(i=[])),n=!1,(r=z.exec(a))&&(n=r.shift(),i.push({value:n,type:r[0].replace($,\" \")}),a=a.slice(n.length)),b.filter)!(r=G[o].exec(a))||u[o]&&!(r=u[o](r))||(n=r.shift(),i.push({value:n,type:o,matches:r}),a=a.slice(n.length));if(!n)break}return t?a.length:a?se.error(e):x(e,s).slice(0)},f=se.compile=function(e,t){var n,v,y,m,x,r,i=[],o=[],a=A[e+\" \"];if(!a){t||(t=h(e)),n=t.length;while(n--)(a=Ee(t[n]))[S]?i.push(a):o.push(a);(a=A(e,(v=o,m=0<(y=i).length,x=0<v.length,r=function(e,t,n,r,i){var o,a,s,u=0,l=\"0\",c=e&&[],f=[],p=w,d=e||x&&b.find.TAG(\"*\",i),h=k+=null==p?1:Math.random()||.1,g=d.length;for(i&&(w=t==C||t||i);l!==g&&null!=(o=d[l]);l++){if(x&&o){a=0,t||o.ownerDocument==C||(T(o),n=!E);while(s=v[a++])if(s(o,t||C,n)){r.push(o);break}i&&(k=h)}m&&((o=!s&&o)&&u--,e&&c.push(o))}if(u+=l,m&&l!==u){a=0;while(s=y[a++])s(c,f,t,n);if(e){if(0<u)while(l--)c[l]||f[l]||(f[l]=q.call(r));f=Te(f)}H.apply(r,f),i&&!e&&0<f.length&&1<u+y.length&&se.uniqueSort(r)}return i&&(k=h,w=p),c},m?le(r):r))).selector=e}return a},g=se.select=function(e,t,n,r){var i,o,a,s,u,l=\"function\"==typeof e&&e,c=!r&&h(e=l.selector||e);if(n=n||[],1===c.length){if(2<(o=c[0]=c[0].slice(0)).length&&\"ID\"===(a=o[0]).type&&9===t.nodeType&&E&&b.relative[o[1].type]){if(!(t=(b.find.ID(a.matches[0].replace(te,ne),t)||[])[0]))return n;l&&(t=t.parentNode),e=e.slice(o.shift().value.length)}i=G.needsContext.test(e)?0:o.length;while(i--){if(a=o[i],b.relative[s=a.type])break;if((u=b.find[s])&&(r=u(a.matches[0].replace(te,ne),ee.test(o[0].type)&&ye(t.parentNode)||t))){if(o.splice(i,1),!(e=r.length&&xe(o)))return H.apply(n,r),n;break}}}return(l||f(e,c))(r,t,!E,n,!t||ee.test(e)&&ye(t.parentNode)||t),n},d.sortStable=S.split(\"\").sort(D).join(\"\")===S,d.detectDuplicates=!!l,T(),d.sortDetached=ce(function(e){return 1&e.compareDocumentPosition(C.createElement(\"fieldset\"))}),ce(function(e){return e.innerHTML=\"<a href='#'></a>\",\"#\"===e.firstChild.getAttribute(\"href\")})||fe(\"type|href|height|width\",function(e,t,n){if(!n)return e.getAttribute(t,\"type\"===t.toLowerCase()?1:2)}),d.attributes&&ce(function(e){return e.innerHTML=\"<input/>\",e.firstChild.setAttribute(\"value\",\"\"),\"\"===e.firstChild.getAttribute(\"value\")})||fe(\"value\",function(e,t,n){if(!n&&\"input\"===e.nodeName.toLowerCase())return e.defaultValue}),ce(function(e){return null==e.getAttribute(\"disabled\")})||fe(R,function(e,t,n){var r;if(!n)return!0===e[t]?t.toLowerCase():(r=e.getAttributeNode(t))&&r.specified?r.value:null}),se}(C);S.find=d,S.expr=d.selectors,S.expr[\":\"]=S.expr.pseudos,S.uniqueSort=S.unique=d.uniqueSort,S.text=d.getText,S.isXMLDoc=d.isXML,S.contains=d.contains,S.escapeSelector=d.escape;var h=function(e,t,n){var r=[],i=void 0!==n;while((e=e[t])&&9!==e.nodeType)if(1===e.nodeType){if(i&&S(e).is(n))break;r.push(e)}return r},T=function(e,t){for(var n=[];e;e=e.nextSibling)1===e.nodeType&&e!==t&&n.push(e);return n},k=S.expr.match.needsContext;function A(e,t){return e.nodeName&&e.nodeName.toLowerCase()===t.toLowerCase()}var N=/^<([a-z][^\\/\\0>:\\x20\\t\\r\\n\\f]*)[\\x20\\t\\r\\n\\f]*\\/?>(?:<\\/\\1>|)$/i;function D(e,n,r){return m(n)?S.grep(e,function(e,t){return!!n.call(e,t,e)!==r}):n.nodeType?S.grep(e,function(e){return e===n!==r}):\"string\"!=typeof n?S.grep(e,function(e){return-1<i.call(n,e)!==r}):S.filter(n,e,r)}S.filter=function(e,t,n){var r=t[0];return n&&(e=\":not(\"+e+\")\"),1===t.length&&1===r.nodeType?S.find.matchesSelector(r,e)?[r]:[]:S.find.matches(e,S.grep(t,function(e){return 1===e.nodeType}))},S.fn.extend({find:function(e){var t,n,r=this.length,i=this;if(\"string\"!=typeof e)return this.pushStack(S(e).filter(function(){for(t=0;t<r;t++)if(S.contains(i[t],this))return!0}));for(n=this.pushStack([]),t=0;t<r;t++)S.find(e,i[t],n);return 1<r?S.uniqueSort(n):n},filter:function(e){return this.pushStack(D(this,e||[],!1))},not:function(e){return this.pushStack(D(this,e||[],!0))},is:function(e){return!!D(this,\"string\"==typeof e&&k.test(e)?S(e):e||[],!1).length}});var j,q=/^(?:\\s*(<[\\w\\W]+>)[^>]*|#([\\w-]+))$/;(S.fn.init=function(e,t,n){var r,i;if(!e)return this;if(n=n||j,\"string\"==typeof e){if(!(r=\"<\"===e[0]&&\">\"===e[e.length-1]&&3<=e.length?[null,e,null]:q.exec(e))||!r[1]&&t)return!t||t.jquery?(t||n).find(e):this.constructor(t).find(e);if(r[1]){if(t=t instanceof S?t[0]:t,S.merge(this,S.parseHTML(r[1],t&&t.nodeType?t.ownerDocument||t:E,!0)),N.test(r[1])&&S.isPlainObject(t))for(r in t)m(this[r])?this[r](t[r]):this.attr(r,t[r]);return this}return(i=E.getElementById(r[2]))&&(this[0]=i,this.length=1),this}return e.nodeType?(this[0]=e,this.length=1,this):m(e)?void 0!==n.ready?n.ready(e):e(S):S.makeArray(e,this)}).prototype=S.fn,j=S(E);var L=/^(?:parents|prev(?:Until|All))/,H={children:!0,contents:!0,next:!0,prev:!0};function O(e,t){while((e=e[t])&&1!==e.nodeType);return e}S.fn.extend({has:function(e){var t=S(e,this),n=t.length;return this.filter(function(){for(var e=0;e<n;e++)if(S.contains(this,t[e]))return!0})},closest:function(e,t){var n,r=0,i=this.length,o=[],a=\"string\"!=typeof e&&S(e);if(!k.test(e))for(;r<i;r++)for(n=this[r];n&&n!==t;n=n.parentNode)if(n.nodeType<11&&(a?-1<a.index(n):1===n.nodeType&&S.find.matchesSelector(n,e))){o.push(n);break}return this.pushStack(1<o.length?S.uniqueSort(o):o)},index:function(e){return e?\"string\"==typeof e?i.call(S(e),this[0]):i.call(this,e.jquery?e[0]:e):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(e,t){return this.pushStack(S.uniqueSort(S.merge(this.get(),S(e,t))))},addBack:function(e){return this.add(null==e?this.prevObject:this.prevObject.filter(e))}}),S.each({parent:function(e){var t=e.parentNode;return t&&11!==t.nodeType?t:null},parents:function(e){return h(e,\"parentNode\")},parentsUntil:function(e,t,n){return h(e,\"parentNode\",n)},next:function(e){return O(e,\"nextSibling\")},prev:function(e){return O(e,\"previousSibling\")},nextAll:function(e){return h(e,\"nextSibling\")},prevAll:function(e){return h(e,\"previousSibling\")},nextUntil:function(e,t,n){return h(e,\"nextSibling\",n)},prevUntil:function(e,t,n){return h(e,\"previousSibling\",n)},siblings:function(e){return T((e.parentNode||{}).firstChild,e)},children:function(e){return T(e.firstChild)},contents:function(e){return null!=e.contentDocument&&r(e.contentDocument)?e.contentDocument:(A(e,\"template\")&&(e=e.content||e),S.merge([],e.childNodes))}},function(r,i){S.fn[r]=function(e,t){var n=S.map(this,i,e);return\"Until\"!==r.slice(-5)&&(t=e),t&&\"string\"==typeof t&&(n=S.filter(t,n)),1<this.length&&(H[r]||S.uniqueSort(n),L.test(r)&&n.reverse()),this.pushStack(n)}});var P=/[^\\x20\\t\\r\\n\\f]+/g;function R(e){return e}function M(e){throw e}function I(e,t,n,r){var i;try{e&&m(i=e.promise)?i.call(e).done(t).fail(n):e&&m(i=e.then)?i.call(e,t,n):t.apply(void 0,[e].slice(r))}catch(e){n.apply(void 0,[e])}}S.Callbacks=function(r){var e,n;r=\"string\"==typeof r?(e=r,n={},S.each(e.match(P)||[],function(e,t){n[t]=!0}),n):S.extend({},r);var i,t,o,a,s=[],u=[],l=-1,c=function(){for(a=a||r.once,o=i=!0;u.length;l=-1){t=u.shift();while(++l<s.length)!1===s[l].apply(t[0],t[1])&&r.stopOnFalse&&(l=s.length,t=!1)}r.memory||(t=!1),i=!1,a&&(s=t?[]:\"\")},f={add:function(){return s&&(t&&!i&&(l=s.length-1,u.push(t)),function n(e){S.each(e,function(e,t){m(t)?r.unique&&f.has(t)||s.push(t):t&&t.length&&\"string\"!==w(t)&&n(t)})}(arguments),t&&!i&&c()),this},remove:function(){return S.each(arguments,function(e,t){var n;while(-1<(n=S.inArray(t,s,n)))s.splice(n,1),n<=l&&l--}),this},has:function(e){return e?-1<S.inArray(e,s):0<s.length},empty:function(){return s&&(s=[]),this},disable:function(){return a=u=[],s=t=\"\",this},disabled:function(){return!s},lock:function(){return a=u=[],t||i||(s=t=\"\"),this},locked:function(){return!!a},fireWith:function(e,t){return a||(t=[e,(t=t||[]).slice?t.slice():t],u.push(t),i||c()),this},fire:function(){return f.fireWith(this,arguments),this},fired:function(){return!!o}};return f},S.extend({Deferred:function(e){var o=[[\"notify\",\"progress\",S.Callbacks(\"memory\"),S.Callbacks(\"memory\"),2],[\"resolve\",\"done\",S.Callbacks(\"once memory\"),S.Callbacks(\"once memory\"),0,\"resolved\"],[\"reject\",\"fail\",S.Callbacks(\"once memory\"),S.Callbacks(\"once memory\"),1,\"rejected\"]],i=\"pending\",a={state:function(){return i},always:function(){return s.done(arguments).fail(arguments),this},\"catch\":function(e){return a.then(null,e)},pipe:function(){var i=arguments;return S.Deferred(function(r){S.each(o,function(e,t){var n=m(i[t[4]])&&i[t[4]];s[t[1]](function(){var e=n&&n.apply(this,arguments);e&&m(e.promise)?e.promise().progress(r.notify).done(r.resolve).fail(r.reject):r[t[0]+\"With\"](this,n?[e]:arguments)})}),i=null}).promise()},then:function(t,n,r){var u=0;function l(i,o,a,s){return function(){var n=this,r=arguments,e=function(){var e,t;if(!(i<u)){if((e=a.apply(n,r))===o.promise())throw new TypeError(\"Thenable self-resolution\");t=e&&(\"object\"==typeof e||\"function\"==typeof e)&&e.then,m(t)?s?t.call(e,l(u,o,R,s),l(u,o,M,s)):(u++,t.call(e,l(u,o,R,s),l(u,o,M,s),l(u,o,R,o.notifyWith))):(a!==R&&(n=void 0,r=[e]),(s||o.resolveWith)(n,r))}},t=s?e:function(){try{e()}catch(e){S.Deferred.exceptionHook&&S.Deferred.exceptionHook(e,t.stackTrace),u<=i+1&&(a!==M&&(n=void 0,r=[e]),o.rejectWith(n,r))}};i?t():(S.Deferred.getStackHook&&(t.stackTrace=S.Deferred.getStackHook()),C.setTimeout(t))}}return S.Deferred(function(e){o[0][3].add(l(0,e,m(r)?r:R,e.notifyWith)),o[1][3].add(l(0,e,m(t)?t:R)),o[2][3].add(l(0,e,m(n)?n:M))}).promise()},promise:function(e){return null!=e?S.extend(e,a):a}},s={};return S.each(o,function(e,t){var n=t[2],r=t[5];a[t[1]]=n.add,r&&n.add(function(){i=r},o[3-e][2].disable,o[3-e][3].disable,o[0][2].lock,o[0][3].lock),n.add(t[3].fire),s[t[0]]=function(){return s[t[0]+\"With\"](this===s?void 0:this,arguments),this},s[t[0]+\"With\"]=n.fireWith}),a.promise(s),e&&e.call(s,s),s},when:function(e){var n=arguments.length,t=n,r=Array(t),i=s.call(arguments),o=S.Deferred(),a=function(t){return function(e){r[t]=this,i[t]=1<arguments.length?s.call(arguments):e,--n||o.resolveWith(r,i)}};if(n<=1&&(I(e,o.done(a(t)).resolve,o.reject,!n),\"pending\"===o.state()||m(i[t]&&i[t].then)))return o.then();while(t--)I(i[t],a(t),o.reject);return o.promise()}});var W=/^(Eval|Internal|Range|Reference|Syntax|Type|URI)Error$/;S.Deferred.exceptionHook=function(e,t){C.console&&C.console.warn&&e&&W.test(e.name)&&C.console.warn(\"jQuery.Deferred exception: \"+e.message,e.stack,t)},S.readyException=function(e){C.setTimeout(function(){throw e})};var F=S.Deferred();function B(){E.removeEventListener(\"DOMContentLoaded\",B),C.removeEventListener(\"load\",B),S.ready()}S.fn.ready=function(e){return F.then(e)[\"catch\"](function(e){S.readyException(e)}),this},S.extend({isReady:!1,readyWait:1,ready:function(e){(!0===e?--S.readyWait:S.isReady)||(S.isReady=!0)!==e&&0<--S.readyWait||F.resolveWith(E,[S])}}),S.ready.then=F.then,\"complete\"===E.readyState||\"loading\"!==E.readyState&&!E.documentElement.doScroll?C.setTimeout(S.ready):(E.addEventListener(\"DOMContentLoaded\",B),C.addEventListener(\"load\",B));var $=function(e,t,n,r,i,o,a){var s=0,u=e.length,l=null==n;if(\"object\"===w(n))for(s in i=!0,n)$(e,t,s,n[s],!0,o,a);else if(void 0!==r&&(i=!0,m(r)||(a=!0),l&&(a?(t.call(e,r),t=null):(l=t,t=function(e,t,n){return l.call(S(e),n)})),t))for(;s<u;s++)t(e[s],n,a?r:r.call(e[s],s,t(e[s],n)));return i?e:l?t.call(e):u?t(e[0],n):o},_=/^-ms-/,z=/-([a-z])/g;function U(e,t){return t.toUpperCase()}function X(e){return e.replace(_,\"ms-\").replace(z,U)}var V=function(e){return 1===e.nodeType||9===e.nodeType||!+e.nodeType};function G(){this.expando=S.expando+G.uid++}G.uid=1,G.prototype={cache:function(e){var t=e[this.expando];return t||(t={},V(e)&&(e.nodeType?e[this.expando]=t:Object.defineProperty(e,this.expando,{value:t,configurable:!0}))),t},set:function(e,t,n){var r,i=this.cache(e);if(\"string\"==typeof t)i[X(t)]=n;else for(r in t)i[X(r)]=t[r];return i},get:function(e,t){return void 0===t?this.cache(e):e[this.expando]&&e[this.expando][X(t)]},access:function(e,t,n){return void 0===t||t&&\"string\"==typeof t&&void 0===n?this.get(e,t):(this.set(e,t,n),void 0!==n?n:t)},remove:function(e,t){var n,r=e[this.expando];if(void 0!==r){if(void 0!==t){n=(t=Array.isArray(t)?t.map(X):(t=X(t))in r?[t]:t.match(P)||[]).length;while(n--)delete r[t[n]]}(void 0===t||S.isEmptyObject(r))&&(e.nodeType?e[this.expando]=void 0:delete e[this.expando])}},hasData:function(e){var t=e[this.expando];return void 0!==t&&!S.isEmptyObject(t)}};var Y=new G,Q=new G,J=/^(?:\\{[\\w\\W]*\\}|\\[[\\w\\W]*\\])$/,K=/[A-Z]/g;function Z(e,t,n){var r,i;if(void 0===n&&1===e.nodeType)if(r=\"data-\"+t.replace(K,\"-$&\").toLowerCase(),\"string\"==typeof(n=e.getAttribute(r))){try{n=\"true\"===(i=n)||\"false\"!==i&&(\"null\"===i?null:i===+i+\"\"?+i:J.test(i)?JSON.parse(i):i)}catch(e){}Q.set(e,t,n)}else n=void 0;return n}S.extend({hasData:function(e){return Q.hasData(e)||Y.hasData(e)},data:function(e,t,n){return Q.access(e,t,n)},removeData:function(e,t){Q.remove(e,t)},_data:function(e,t,n){return Y.access(e,t,n)},_removeData:function(e,t){Y.remove(e,t)}}),S.fn.extend({data:function(n,e){var t,r,i,o=this[0],a=o&&o.attributes;if(void 0===n){if(this.length&&(i=Q.get(o),1===o.nodeType&&!Y.get(o,\"hasDataAttrs\"))){t=a.length;while(t--)a[t]&&0===(r=a[t].name).indexOf(\"data-\")&&(r=X(r.slice(5)),Z(o,r,i[r]));Y.set(o,\"hasDataAttrs\",!0)}return i}return\"object\"==typeof n?this.each(function(){Q.set(this,n)}):$(this,function(e){var t;if(o&&void 0===e)return void 0!==(t=Q.get(o,n))?t:void 0!==(t=Z(o,n))?t:void 0;this.each(function(){Q.set(this,n,e)})},null,e,1<arguments.length,null,!0)},removeData:function(e){return this.each(function(){Q.remove(this,e)})}}),S.extend({queue:function(e,t,n){var r;if(e)return t=(t||\"fx\")+\"queue\",r=Y.get(e,t),n&&(!r||Array.isArray(n)?r=Y.access(e,t,S.makeArray(n)):r.push(n)),r||[]},dequeue:function(e,t){t=t||\"fx\";var n=S.queue(e,t),r=n.length,i=n.shift(),o=S._queueHooks(e,t);\"inprogress\"===i&&(i=n.shift(),r--),i&&(\"fx\"===t&&n.unshift(\"inprogress\"),delete o.stop,i.call(e,function(){S.dequeue(e,t)},o)),!r&&o&&o.empty.fire()},_queueHooks:function(e,t){var n=t+\"queueHooks\";return Y.get(e,n)||Y.access(e,n,{empty:S.Callbacks(\"once memory\").add(function(){Y.remove(e,[t+\"queue\",n])})})}}),S.fn.extend({queue:function(t,n){var e=2;return\"string\"!=typeof t&&(n=t,t=\"fx\",e--),arguments.length<e?S.queue(this[0],t):void 0===n?this:this.each(function(){var e=S.queue(this,t,n);S._queueHooks(this,t),\"fx\"===t&&\"inprogress\"!==e[0]&&S.dequeue(this,t)})},dequeue:function(e){return this.each(function(){S.dequeue(this,e)})},clearQueue:function(e){return this.queue(e||\"fx\",[])},promise:function(e,t){var n,r=1,i=S.Deferred(),o=this,a=this.length,s=function(){--r||i.resolveWith(o,[o])};\"string\"!=typeof e&&(t=e,e=void 0),e=e||\"fx\";while(a--)(n=Y.get(o[a],e+\"queueHooks\"))&&n.empty&&(r++,n.empty.add(s));return s(),i.promise(t)}});var ee=/[+-]?(?:\\d*\\.|)\\d+(?:[eE][+-]?\\d+|)/.source,te=new RegExp(\"^(?:([+-])=|)(\"+ee+\")([a-z%]*)$\",\"i\"),ne=[\"Top\",\"Right\",\"Bottom\",\"Left\"],re=E.documentElement,ie=function(e){return S.contains(e.ownerDocument,e)},oe={composed:!0};re.getRootNode&&(ie=function(e){return S.contains(e.ownerDocument,e)||e.getRootNode(oe)===e.ownerDocument});var ae=function(e,t){return\"none\"===(e=t||e).style.display||\"\"===e.style.display&&ie(e)&&\"none\"===S.css(e,\"display\")};function se(e,t,n,r){var i,o,a=20,s=r?function(){return r.cur()}:function(){return S.css(e,t,\"\")},u=s(),l=n&&n[3]||(S.cssNumber[t]?\"\":\"px\"),c=e.nodeType&&(S.cssNumber[t]||\"px\"!==l&&+u)&&te.exec(S.css(e,t));if(c&&c[3]!==l){u/=2,l=l||c[3],c=+u||1;while(a--)S.style(e,t,c+l),(1-o)*(1-(o=s()/u||.5))<=0&&(a=0),c/=o;c*=2,S.style(e,t,c+l),n=n||[]}return n&&(c=+c||+u||0,i=n[1]?c+(n[1]+1)*n[2]:+n[2],r&&(r.unit=l,r.start=c,r.end=i)),i}var ue={};function le(e,t){for(var n,r,i,o,a,s,u,l=[],c=0,f=e.length;c<f;c++)(r=e[c]).style&&(n=r.style.display,t?(\"none\"===n&&(l[c]=Y.get(r,\"display\")||null,l[c]||(r.style.display=\"\")),\"\"===r.style.display&&ae(r)&&(l[c]=(u=a=o=void 0,a=(i=r).ownerDocument,s=i.nodeName,(u=ue[s])||(o=a.body.appendChild(a.createElement(s)),u=S.css(o,\"display\"),o.parentNode.removeChild(o),\"none\"===u&&(u=\"block\"),ue[s]=u)))):\"none\"!==n&&(l[c]=\"none\",Y.set(r,\"display\",n)));for(c=0;c<f;c++)null!=l[c]&&(e[c].style.display=l[c]);return e}S.fn.extend({show:function(){return le(this,!0)},hide:function(){return le(this)},toggle:function(e){return\"boolean\"==typeof e?e?this.show():this.hide():this.each(function(){ae(this)?S(this).show():S(this).hide()})}});var ce,fe,pe=/^(?:checkbox|radio)$/i,de=/<([a-z][^\\/\\0>\\x20\\t\\r\\n\\f]*)/i,he=/^$|^module$|\\/(?:java|ecma)script/i;ce=E.createDocumentFragment().appendChild(E.createElement(\"div\")),(fe=E.createElement(\"input\")).setAttribute(\"type\",\"radio\"),fe.setAttribute(\"checked\",\"checked\"),fe.setAttribute(\"name\",\"t\"),ce.appendChild(fe),y.checkClone=ce.cloneNode(!0).cloneNode(!0).lastChild.checked,ce.innerHTML=\"<textarea>x</textarea>\",y.noCloneChecked=!!ce.cloneNode(!0).lastChild.defaultValue,ce.innerHTML=\"<option></option>\",y.option=!!ce.lastChild;var ge={thead:[1,\"<table>\",\"</table>\"],col:[2,\"<table><colgroup>\",\"</colgroup></table>\"],tr:[2,\"<table><tbody>\",\"</tbody></table>\"],td:[3,\"<table><tbody><tr>\",\"</tr></tbody></table>\"],_default:[0,\"\",\"\"]};function ve(e,t){var n;return n=\"undefined\"!=typeof e.getElementsByTagName?e.getElementsByTagName(t||\"*\"):\"undefined\"!=typeof e.querySelectorAll?e.querySelectorAll(t||\"*\"):[],void 0===t||t&&A(e,t)?S.merge([e],n):n}function ye(e,t){for(var n=0,r=e.length;n<r;n++)Y.set(e[n],\"globalEval\",!t||Y.get(t[n],\"globalEval\"))}ge.tbody=ge.tfoot=ge.colgroup=ge.caption=ge.thead,ge.th=ge.td,y.option||(ge.optgroup=ge.option=[1,\"<select multiple='multiple'>\",\"</select>\"]);var me=/<|&#?\\w+;/;function xe(e,t,n,r,i){for(var o,a,s,u,l,c,f=t.createDocumentFragment(),p=[],d=0,h=e.length;d<h;d++)if((o=e[d])||0===o)if(\"object\"===w(o))S.merge(p,o.nodeType?[o]:o);else if(me.test(o)){a=a||f.appendChild(t.createElement(\"div\")),s=(de.exec(o)||[\"\",\"\"])[1].toLowerCase(),u=ge[s]||ge._default,a.innerHTML=u[1]+S.htmlPrefilter(o)+u[2],c=u[0];while(c--)a=a.lastChild;S.merge(p,a.childNodes),(a=f.firstChild).textContent=\"\"}else p.push(t.createTextNode(o));f.textContent=\"\",d=0;while(o=p[d++])if(r&&-1<S.inArray(o,r))i&&i.push(o);else if(l=ie(o),a=ve(f.appendChild(o),\"script\"),l&&ye(a),n){c=0;while(o=a[c++])he.test(o.type||\"\")&&n.push(o)}return f}var be=/^key/,we=/^(?:mouse|pointer|contextmenu|drag|drop)|click/,Te=/^([^.]*)(?:\\.(.+)|)/;function Ce(){return!0}function Ee(){return!1}function Se(e,t){return e===function(){try{return E.activeElement}catch(e){}}()==(\"focus\"===t)}function ke(e,t,n,r,i,o){var a,s;if(\"object\"==typeof t){for(s in\"string\"!=typeof n&&(r=r||n,n=void 0),t)ke(e,s,n,r,t[s],o);return e}if(null==r&&null==i?(i=n,r=n=void 0):null==i&&(\"string\"==typeof n?(i=r,r=void 0):(i=r,r=n,n=void 0)),!1===i)i=Ee;else if(!i)return e;return 1===o&&(a=i,(i=function(e){return S().off(e),a.apply(this,arguments)}).guid=a.guid||(a.guid=S.guid++)),e.each(function(){S.event.add(this,t,i,r,n)})}function Ae(e,i,o){o?(Y.set(e,i,!1),S.event.add(e,i,{namespace:!1,handler:function(e){var t,n,r=Y.get(this,i);if(1&e.isTrigger&&this[i]){if(r.length)(S.event.special[i]||{}).delegateType&&e.stopPropagation();else if(r=s.call(arguments),Y.set(this,i,r),t=o(this,i),this[i](),r!==(n=Y.get(this,i))||t?Y.set(this,i,!1):n={},r!==n)return e.stopImmediatePropagation(),e.preventDefault(),n.value}else r.length&&(Y.set(this,i,{value:S.event.trigger(S.extend(r[0],S.Event.prototype),r.slice(1),this)}),e.stopImmediatePropagation())}})):void 0===Y.get(e,i)&&S.event.add(e,i,Ce)}S.event={global:{},add:function(t,e,n,r,i){var o,a,s,u,l,c,f,p,d,h,g,v=Y.get(t);if(V(t)){n.handler&&(n=(o=n).handler,i=o.selector),i&&S.find.matchesSelector(re,i),n.guid||(n.guid=S.guid++),(u=v.events)||(u=v.events=Object.create(null)),(a=v.handle)||(a=v.handle=function(e){return\"undefined\"!=typeof S&&S.event.triggered!==e.type?S.event.dispatch.apply(t,arguments):void 0}),l=(e=(e||\"\").match(P)||[\"\"]).length;while(l--)d=g=(s=Te.exec(e[l])||[])[1],h=(s[2]||\"\").split(\".\").sort(),d&&(f=S.event.special[d]||{},d=(i?f.delegateType:f.bindType)||d,f=S.event.special[d]||{},c=S.extend({type:d,origType:g,data:r,handler:n,guid:n.guid,selector:i,needsContext:i&&S.expr.match.needsContext.test(i),namespace:h.join(\".\")},o),(p=u[d])||((p=u[d]=[]).delegateCount=0,f.setup&&!1!==f.setup.call(t,r,h,a)||t.addEventListener&&t.addEventListener(d,a)),f.add&&(f.add.call(t,c),c.handler.guid||(c.handler.guid=n.guid)),i?p.splice(p.delegateCount++,0,c):p.push(c),S.event.global[d]=!0)}},remove:function(e,t,n,r,i){var o,a,s,u,l,c,f,p,d,h,g,v=Y.hasData(e)&&Y.get(e);if(v&&(u=v.events)){l=(t=(t||\"\").match(P)||[\"\"]).length;while(l--)if(d=g=(s=Te.exec(t[l])||[])[1],h=(s[2]||\"\").split(\".\").sort(),d){f=S.event.special[d]||{},p=u[d=(r?f.delegateType:f.bindType)||d]||[],s=s[2]&&new RegExp(\"(^|\\\\.)\"+h.join(\"\\\\.(?:.*\\\\.|)\")+\"(\\\\.|$)\"),a=o=p.length;while(o--)c=p[o],!i&&g!==c.origType||n&&n.guid!==c.guid||s&&!s.test(c.namespace)||r&&r!==c.selector&&(\"**\"!==r||!c.selector)||(p.splice(o,1),c.selector&&p.delegateCount--,f.remove&&f.remove.call(e,c));a&&!p.length&&(f.teardown&&!1!==f.teardown.call(e,h,v.handle)||S.removeEvent(e,d,v.handle),delete u[d])}else for(d in u)S.event.remove(e,d+t[l],n,r,!0);S.isEmptyObject(u)&&Y.remove(e,\"handle events\")}},dispatch:function(e){var t,n,r,i,o,a,s=new Array(arguments.length),u=S.event.fix(e),l=(Y.get(this,\"events\")||Object.create(null))[u.type]||[],c=S.event.special[u.type]||{};for(s[0]=u,t=1;t<arguments.length;t++)s[t]=arguments[t];if(u.delegateTarget=this,!c.preDispatch||!1!==c.preDispatch.call(this,u)){a=S.event.handlers.call(this,u,l),t=0;while((i=a[t++])&&!u.isPropagationStopped()){u.currentTarget=i.elem,n=0;while((o=i.handlers[n++])&&!u.isImmediatePropagationStopped())u.rnamespace&&!1!==o.namespace&&!u.rnamespace.test(o.namespace)||(u.handleObj=o,u.data=o.data,void 0!==(r=((S.event.special[o.origType]||{}).handle||o.handler).apply(i.elem,s))&&!1===(u.result=r)&&(u.preventDefault(),u.stopPropagation()))}return c.postDispatch&&c.postDispatch.call(this,u),u.result}},handlers:function(e,t){var n,r,i,o,a,s=[],u=t.delegateCount,l=e.target;if(u&&l.nodeType&&!(\"click\"===e.type&&1<=e.button))for(;l!==this;l=l.parentNode||this)if(1===l.nodeType&&(\"click\"!==e.type||!0!==l.disabled)){for(o=[],a={},n=0;n<u;n++)void 0===a[i=(r=t[n]).selector+\" \"]&&(a[i]=r.needsContext?-1<S(i,this).index(l):S.find(i,this,null,[l]).length),a[i]&&o.push(r);o.length&&s.push({elem:l,handlers:o})}return l=this,u<t.length&&s.push({elem:l,handlers:t.slice(u)}),s},addProp:function(t,e){Object.defineProperty(S.Event.prototype,t,{enumerable:!0,configurable:!0,get:m(e)?function(){if(this.originalEvent)return e(this.originalEvent)}:function(){if(this.originalEvent)return this.originalEvent[t]},set:function(e){Object.defineProperty(this,t,{enumerable:!0,configurable:!0,writable:!0,value:e})}})},fix:function(e){return e[S.expando]?e:new S.Event(e)},special:{load:{noBubble:!0},click:{setup:function(e){var t=this||e;return pe.test(t.type)&&t.click&&A(t,\"input\")&&Ae(t,\"click\",Ce),!1},trigger:function(e){var t=this||e;return pe.test(t.type)&&t.click&&A(t,\"input\")&&Ae(t,\"click\"),!0},_default:function(e){var t=e.target;return pe.test(t.type)&&t.click&&A(t,\"input\")&&Y.get(t,\"click\")||A(t,\"a\")}},beforeunload:{postDispatch:function(e){void 0!==e.result&&e.originalEvent&&(e.originalEvent.returnValue=e.result)}}}},S.removeEvent=function(e,t,n){e.removeEventListener&&e.removeEventListener(t,n)},S.Event=function(e,t){if(!(this instanceof S.Event))return new S.Event(e,t);e&&e.type?(this.originalEvent=e,this.type=e.type,this.isDefaultPrevented=e.defaultPrevented||void 0===e.defaultPrevented&&!1===e.returnValue?Ce:Ee,this.target=e.target&&3===e.target.nodeType?e.target.parentNode:e.target,this.currentTarget=e.currentTarget,this.relatedTarget=e.relatedTarget):this.type=e,t&&S.extend(this,t),this.timeStamp=e&&e.timeStamp||Date.now(),this[S.expando]=!0},S.Event.prototype={constructor:S.Event,isDefaultPrevented:Ee,isPropagationStopped:Ee,isImmediatePropagationStopped:Ee,isSimulated:!1,preventDefault:function(){var e=this.originalEvent;this.isDefaultPrevented=Ce,e&&!this.isSimulated&&e.preventDefault()},stopPropagation:function(){var e=this.originalEvent;this.isPropagationStopped=Ce,e&&!this.isSimulated&&e.stopPropagation()},stopImmediatePropagation:function(){var e=this.originalEvent;this.isImmediatePropagationStopped=Ce,e&&!this.isSimulated&&e.stopImmediatePropagation(),this.stopPropagation()}},S.each({altKey:!0,bubbles:!0,cancelable:!0,changedTouches:!0,ctrlKey:!0,detail:!0,eventPhase:!0,metaKey:!0,pageX:!0,pageY:!0,shiftKey:!0,view:!0,\"char\":!0,code:!0,charCode:!0,key:!0,keyCode:!0,button:!0,buttons:!0,clientX:!0,clientY:!0,offsetX:!0,offsetY:!0,pointerId:!0,pointerType:!0,screenX:!0,screenY:!0,targetTouches:!0,toElement:!0,touches:!0,which:function(e){var t=e.button;return null==e.which&&be.test(e.type)?null!=e.charCode?e.charCode:e.keyCode:!e.which&&void 0!==t&&we.test(e.type)?1&t?1:2&t?3:4&t?2:0:e.which}},S.event.addProp),S.each({focus:\"focusin\",blur:\"focusout\"},function(e,t){S.event.special[e]={setup:function(){return Ae(this,e,Se),!1},trigger:function(){return Ae(this,e),!0},delegateType:t}}),S.each({mouseenter:\"mouseover\",mouseleave:\"mouseout\",pointerenter:\"pointerover\",pointerleave:\"pointerout\"},function(e,i){S.event.special[e]={delegateType:i,bindType:i,handle:function(e){var t,n=e.relatedTarget,r=e.handleObj;return n&&(n===this||S.contains(this,n))||(e.type=r.origType,t=r.handler.apply(this,arguments),e.type=i),t}}}),S.fn.extend({on:function(e,t,n,r){return ke(this,e,t,n,r)},one:function(e,t,n,r){return ke(this,e,t,n,r,1)},off:function(e,t,n){var r,i;if(e&&e.preventDefault&&e.handleObj)return r=e.handleObj,S(e.delegateTarget).off(r.namespace?r.origType+\".\"+r.namespace:r.origType,r.selector,r.handler),this;if(\"object\"==typeof e){for(i in e)this.off(i,t,e[i]);return this}return!1!==t&&\"function\"!=typeof t||(n=t,t=void 0),!1===n&&(n=Ee),this.each(function(){S.event.remove(this,e,n,t)})}});var Ne=/<script|<style|<link/i,De=/checked\\s*(?:[^=]|=\\s*.checked.)/i,je=/^\\s*<!(?:\\[CDATA\\[|--)|(?:\\]\\]|--)>\\s*$/g;function qe(e,t){return A(e,\"table\")&&A(11!==t.nodeType?t:t.firstChild,\"tr\")&&S(e).children(\"tbody\")[0]||e}function Le(e){return e.type=(null!==e.getAttribute(\"type\"))+\"/\"+e.type,e}function He(e){return\"true/\"===(e.type||\"\").slice(0,5)?e.type=e.type.slice(5):e.removeAttribute(\"type\"),e}function Oe(e,t){var n,r,i,o,a,s;if(1===t.nodeType){if(Y.hasData(e)&&(s=Y.get(e).events))for(i in Y.remove(t,\"handle events\"),s)for(n=0,r=s[i].length;n<r;n++)S.event.add(t,i,s[i][n]);Q.hasData(e)&&(o=Q.access(e),a=S.extend({},o),Q.set(t,a))}}function Pe(n,r,i,o){r=g(r);var e,t,a,s,u,l,c=0,f=n.length,p=f-1,d=r[0],h=m(d);if(h||1<f&&\"string\"==typeof d&&!y.checkClone&&De.test(d))return n.each(function(e){var t=n.eq(e);h&&(r[0]=d.call(this,e,t.html())),Pe(t,r,i,o)});if(f&&(t=(e=xe(r,n[0].ownerDocument,!1,n,o)).firstChild,1===e.childNodes.length&&(e=t),t||o)){for(s=(a=S.map(ve(e,\"script\"),Le)).length;c<f;c++)u=e,c!==p&&(u=S.clone(u,!0,!0),s&&S.merge(a,ve(u,\"script\"))),i.call(n[c],u,c);if(s)for(l=a[a.length-1].ownerDocument,S.map(a,He),c=0;c<s;c++)u=a[c],he.test(u.type||\"\")&&!Y.access(u,\"globalEval\")&&S.contains(l,u)&&(u.src&&\"module\"!==(u.type||\"\").toLowerCase()?S._evalUrl&&!u.noModule&&S._evalUrl(u.src,{nonce:u.nonce||u.getAttribute(\"nonce\")},l):b(u.textContent.replace(je,\"\"),u,l))}return n}function Re(e,t,n){for(var r,i=t?S.filter(t,e):e,o=0;null!=(r=i[o]);o++)n||1!==r.nodeType||S.cleanData(ve(r)),r.parentNode&&(n&&ie(r)&&ye(ve(r,\"script\")),r.parentNode.removeChild(r));return e}S.extend({htmlPrefilter:function(e){return e},clone:function(e,t,n){var r,i,o,a,s,u,l,c=e.cloneNode(!0),f=ie(e);if(!(y.noCloneChecked||1!==e.nodeType&&11!==e.nodeType||S.isXMLDoc(e)))for(a=ve(c),r=0,i=(o=ve(e)).length;r<i;r++)s=o[r],u=a[r],void 0,\"input\"===(l=u.nodeName.toLowerCase())&&pe.test(s.type)?u.checked=s.checked:\"input\"!==l&&\"textarea\"!==l||(u.defaultValue=s.defaultValue);if(t)if(n)for(o=o||ve(e),a=a||ve(c),r=0,i=o.length;r<i;r++)Oe(o[r],a[r]);else Oe(e,c);return 0<(a=ve(c,\"script\")).length&&ye(a,!f&&ve(e,\"script\")),c},cleanData:function(e){for(var t,n,r,i=S.event.special,o=0;void 0!==(n=e[o]);o++)if(V(n)){if(t=n[Y.expando]){if(t.events)for(r in t.events)i[r]?S.event.remove(n,r):S.removeEvent(n,r,t.handle);n[Y.expando]=void 0}n[Q.expando]&&(n[Q.expando]=void 0)}}}),S.fn.extend({detach:function(e){return Re(this,e,!0)},remove:function(e){return Re(this,e)},text:function(e){return $(this,function(e){return void 0===e?S.text(this):this.empty().each(function(){1!==this.nodeType&&11!==this.nodeType&&9!==this.nodeType||(this.textContent=e)})},null,e,arguments.length)},append:function(){return Pe(this,arguments,function(e){1!==this.nodeType&&11!==this.nodeType&&9!==this.nodeType||qe(this,e).appendChild(e)})},prepend:function(){return Pe(this,arguments,function(e){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var t=qe(this,e);t.insertBefore(e,t.firstChild)}})},before:function(){return Pe(this,arguments,function(e){this.parentNode&&this.parentNode.insertBefore(e,this)})},after:function(){return Pe(this,arguments,function(e){this.parentNode&&this.parentNode.insertBefore(e,this.nextSibling)})},empty:function(){for(var e,t=0;null!=(e=this[t]);t++)1===e.nodeType&&(S.cleanData(ve(e,!1)),e.textContent=\"\");return this},clone:function(e,t){return e=null!=e&&e,t=null==t?e:t,this.map(function(){return S.clone(this,e,t)})},html:function(e){return $(this,function(e){var t=this[0]||{},n=0,r=this.length;if(void 0===e&&1===t.nodeType)return t.innerHTML;if(\"string\"==typeof e&&!Ne.test(e)&&!ge[(de.exec(e)||[\"\",\"\"])[1].toLowerCase()]){e=S.htmlPrefilter(e);try{for(;n<r;n++)1===(t=this[n]||{}).nodeType&&(S.cleanData(ve(t,!1)),t.innerHTML=e);t=0}catch(e){}}t&&this.empty().append(e)},null,e,arguments.length)},replaceWith:function(){var n=[];return Pe(this,arguments,function(e){var t=this.parentNode;S.inArray(this,n)<0&&(S.cleanData(ve(this)),t&&t.replaceChild(e,this))},n)}}),S.each({appendTo:\"append\",prependTo:\"prepend\",insertBefore:\"before\",insertAfter:\"after\",replaceAll:\"replaceWith\"},function(e,a){S.fn[e]=function(e){for(var t,n=[],r=S(e),i=r.length-1,o=0;o<=i;o++)t=o===i?this:this.clone(!0),S(r[o])[a](t),u.apply(n,t.get());return this.pushStack(n)}});var Me=new RegExp(\"^(\"+ee+\")(?!px)[a-z%]+$\",\"i\"),Ie=function(e){var t=e.ownerDocument.defaultView;return t&&t.opener||(t=C),t.getComputedStyle(e)},We=function(e,t,n){var r,i,o={};for(i in t)o[i]=e.style[i],e.style[i]=t[i];for(i in r=n.call(e),t)e.style[i]=o[i];return r},Fe=new RegExp(ne.join(\"|\"),\"i\");function Be(e,t,n){var r,i,o,a,s=e.style;return(n=n||Ie(e))&&(\"\"!==(a=n.getPropertyValue(t)||n[t])||ie(e)||(a=S.style(e,t)),!y.pixelBoxStyles()&&Me.test(a)&&Fe.test(t)&&(r=s.width,i=s.minWidth,o=s.maxWidth,s.minWidth=s.maxWidth=s.width=a,a=n.width,s.width=r,s.minWidth=i,s.maxWidth=o)),void 0!==a?a+\"\":a}function $e(e,t){return{get:function(){if(!e())return(this.get=t).apply(this,arguments);delete this.get}}}!function(){function e(){if(l){u.style.cssText=\"position:absolute;left:-11111px;width:60px;margin-top:1px;padding:0;border:0\",l.style.cssText=\"position:relative;display:block;box-sizing:border-box;overflow:scroll;margin:auto;border:1px;padding:1px;width:60%;top:1%\",re.appendChild(u).appendChild(l);var e=C.getComputedStyle(l);n=\"1%\"!==e.top,s=12===t(e.marginLeft),l.style.right=\"60%\",o=36===t(e.right),r=36===t(e.width),l.style.position=\"absolute\",i=12===t(l.offsetWidth/3),re.removeChild(u),l=null}}function t(e){return Math.round(parseFloat(e))}var n,r,i,o,a,s,u=E.createElement(\"div\"),l=E.createElement(\"div\");l.style&&(l.style.backgroundClip=\"content-box\",l.cloneNode(!0).style.backgroundClip=\"\",y.clearCloneStyle=\"content-box\"===l.style.backgroundClip,S.extend(y,{boxSizingReliable:function(){return e(),r},pixelBoxStyles:function(){return e(),o},pixelPosition:function(){return e(),n},reliableMarginLeft:function(){return e(),s},scrollboxSize:function(){return e(),i},reliableTrDimensions:function(){var e,t,n,r;return null==a&&(e=E.createElement(\"table\"),t=E.createElement(\"tr\"),n=E.createElement(\"div\"),e.style.cssText=\"position:absolute;left:-11111px\",t.style.height=\"1px\",n.style.height=\"9px\",re.appendChild(e).appendChild(t).appendChild(n),r=C.getComputedStyle(t),a=3<parseInt(r.height),re.removeChild(e)),a}}))}();var _e=[\"Webkit\",\"Moz\",\"ms\"],ze=E.createElement(\"div\").style,Ue={};function Xe(e){var t=S.cssProps[e]||Ue[e];return t||(e in ze?e:Ue[e]=function(e){var t=e[0].toUpperCase()+e.slice(1),n=_e.length;while(n--)if((e=_e[n]+t)in ze)return e}(e)||e)}var Ve=/^(none|table(?!-c[ea]).+)/,Ge=/^--/,Ye={position:\"absolute\",visibility:\"hidden\",display:\"block\"},Qe={letterSpacing:\"0\",fontWeight:\"400\"};function Je(e,t,n){var r=te.exec(t);return r?Math.max(0,r[2]-(n||0))+(r[3]||\"px\"):t}function Ke(e,t,n,r,i,o){var a=\"width\"===t?1:0,s=0,u=0;if(n===(r?\"border\":\"content\"))return 0;for(;a<4;a+=2)\"margin\"===n&&(u+=S.css(e,n+ne[a],!0,i)),r?(\"content\"===n&&(u-=S.css(e,\"padding\"+ne[a],!0,i)),\"margin\"!==n&&(u-=S.css(e,\"border\"+ne[a]+\"Width\",!0,i))):(u+=S.css(e,\"padding\"+ne[a],!0,i),\"padding\"!==n?u+=S.css(e,\"border\"+ne[a]+\"Width\",!0,i):s+=S.css(e,\"border\"+ne[a]+\"Width\",!0,i));return!r&&0<=o&&(u+=Math.max(0,Math.ceil(e[\"offset\"+t[0].toUpperCase()+t.slice(1)]-o-u-s-.5))||0),u}function Ze(e,t,n){var r=Ie(e),i=(!y.boxSizingReliable()||n)&&\"border-box\"===S.css(e,\"boxSizing\",!1,r),o=i,a=Be(e,t,r),s=\"offset\"+t[0].toUpperCase()+t.slice(1);if(Me.test(a)){if(!n)return a;a=\"auto\"}return(!y.boxSizingReliable()&&i||!y.reliableTrDimensions()&&A(e,\"tr\")||\"auto\"===a||!parseFloat(a)&&\"inline\"===S.css(e,\"display\",!1,r))&&e.getClientRects().length&&(i=\"border-box\"===S.css(e,\"boxSizing\",!1,r),(o=s in e)&&(a=e[s])),(a=parseFloat(a)||0)+Ke(e,t,n||(i?\"border\":\"content\"),o,r,a)+\"px\"}function et(e,t,n,r,i){return new et.prototype.init(e,t,n,r,i)}S.extend({cssHooks:{opacity:{get:function(e,t){if(t){var n=Be(e,\"opacity\");return\"\"===n?\"1\":n}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,gridArea:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnStart:!0,gridRow:!0,gridRowEnd:!0,gridRowStart:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{},style:function(e,t,n,r){if(e&&3!==e.nodeType&&8!==e.nodeType&&e.style){var i,o,a,s=X(t),u=Ge.test(t),l=e.style;if(u||(t=Xe(s)),a=S.cssHooks[t]||S.cssHooks[s],void 0===n)return a&&\"get\"in a&&void 0!==(i=a.get(e,!1,r))?i:l[t];\"string\"===(o=typeof n)&&(i=te.exec(n))&&i[1]&&(n=se(e,t,i),o=\"number\"),null!=n&&n==n&&(\"number\"!==o||u||(n+=i&&i[3]||(S.cssNumber[s]?\"\":\"px\")),y.clearCloneStyle||\"\"!==n||0!==t.indexOf(\"background\")||(l[t]=\"inherit\"),a&&\"set\"in a&&void 0===(n=a.set(e,n,r))||(u?l.setProperty(t,n):l[t]=n))}},css:function(e,t,n,r){var i,o,a,s=X(t);return Ge.test(t)||(t=Xe(s)),(a=S.cssHooks[t]||S.cssHooks[s])&&\"get\"in a&&(i=a.get(e,!0,n)),void 0===i&&(i=Be(e,t,r)),\"normal\"===i&&t in Qe&&(i=Qe[t]),\"\"===n||n?(o=parseFloat(i),!0===n||isFinite(o)?o||0:i):i}}),S.each([\"height\",\"width\"],function(e,u){S.cssHooks[u]={get:function(e,t,n){if(t)return!Ve.test(S.css(e,\"display\"))||e.getClientRects().length&&e.getBoundingClientRect().width?Ze(e,u,n):We(e,Ye,function(){return Ze(e,u,n)})},set:function(e,t,n){var r,i=Ie(e),o=!y.scrollboxSize()&&\"absolute\"===i.position,a=(o||n)&&\"border-box\"===S.css(e,\"boxSizing\",!1,i),s=n?Ke(e,u,n,a,i):0;return a&&o&&(s-=Math.ceil(e[\"offset\"+u[0].toUpperCase()+u.slice(1)]-parseFloat(i[u])-Ke(e,u,\"border\",!1,i)-.5)),s&&(r=te.exec(t))&&\"px\"!==(r[3]||\"px\")&&(e.style[u]=t,t=S.css(e,u)),Je(0,t,s)}}}),S.cssHooks.marginLeft=$e(y.reliableMarginLeft,function(e,t){if(t)return(parseFloat(Be(e,\"marginLeft\"))||e.getBoundingClientRect().left-We(e,{marginLeft:0},function(){return e.getBoundingClientRect().left}))+\"px\"}),S.each({margin:\"\",padding:\"\",border:\"Width\"},function(i,o){S.cssHooks[i+o]={expand:function(e){for(var t=0,n={},r=\"string\"==typeof e?e.split(\" \"):[e];t<4;t++)n[i+ne[t]+o]=r[t]||r[t-2]||r[0];return n}},\"margin\"!==i&&(S.cssHooks[i+o].set=Je)}),S.fn.extend({css:function(e,t){return $(this,function(e,t,n){var r,i,o={},a=0;if(Array.isArray(t)){for(r=Ie(e),i=t.length;a<i;a++)o[t[a]]=S.css(e,t[a],!1,r);return o}return void 0!==n?S.style(e,t,n):S.css(e,t)},e,t,1<arguments.length)}}),((S.Tween=et).prototype={constructor:et,init:function(e,t,n,r,i,o){this.elem=e,this.prop=n,this.easing=i||S.easing._default,this.options=t,this.start=this.now=this.cur(),this.end=r,this.unit=o||(S.cssNumber[n]?\"\":\"px\")},cur:function(){var e=et.propHooks[this.prop];return e&&e.get?e.get(this):et.propHooks._default.get(this)},run:function(e){var t,n=et.propHooks[this.prop];return this.options.duration?this.pos=t=S.easing[this.easing](e,this.options.duration*e,0,1,this.options.duration):this.pos=t=e,this.now=(this.end-this.start)*t+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),n&&n.set?n.set(this):et.propHooks._default.set(this),this}}).init.prototype=et.prototype,(et.propHooks={_default:{get:function(e){var t;return 1!==e.elem.nodeType||null!=e.elem[e.prop]&&null==e.elem.style[e.prop]?e.elem[e.prop]:(t=S.css(e.elem,e.prop,\"\"))&&\"auto\"!==t?t:0},set:function(e){S.fx.step[e.prop]?S.fx.step[e.prop](e):1!==e.elem.nodeType||!S.cssHooks[e.prop]&&null==e.elem.style[Xe(e.prop)]?e.elem[e.prop]=e.now:S.style(e.elem,e.prop,e.now+e.unit)}}}).scrollTop=et.propHooks.scrollLeft={set:function(e){e.elem.nodeType&&e.elem.parentNode&&(e.elem[e.prop]=e.now)}},S.easing={linear:function(e){return e},swing:function(e){return.5-Math.cos(e*Math.PI)/2},_default:\"swing\"},S.fx=et.prototype.init,S.fx.step={};var tt,nt,rt,it,ot=/^(?:toggle|show|hide)$/,at=/queueHooks$/;function st(){nt&&(!1===E.hidden&&C.requestAnimationFrame?C.requestAnimationFrame(st):C.setTimeout(st,S.fx.interval),S.fx.tick())}function ut(){return C.setTimeout(function(){tt=void 0}),tt=Date.now()}function lt(e,t){var n,r=0,i={height:e};for(t=t?1:0;r<4;r+=2-t)i[\"margin\"+(n=ne[r])]=i[\"padding\"+n]=e;return t&&(i.opacity=i.width=e),i}function ct(e,t,n){for(var r,i=(ft.tweeners[t]||[]).concat(ft.tweeners[\"*\"]),o=0,a=i.length;o<a;o++)if(r=i[o].call(n,t,e))return r}function ft(o,e,t){var n,a,r=0,i=ft.prefilters.length,s=S.Deferred().always(function(){delete u.elem}),u=function(){if(a)return!1;for(var e=tt||ut(),t=Math.max(0,l.startTime+l.duration-e),n=1-(t/l.duration||0),r=0,i=l.tweens.length;r<i;r++)l.tweens[r].run(n);return s.notifyWith(o,[l,n,t]),n<1&&i?t:(i||s.notifyWith(o,[l,1,0]),s.resolveWith(o,[l]),!1)},l=s.promise({elem:o,props:S.extend({},e),opts:S.extend(!0,{specialEasing:{},easing:S.easing._default},t),originalProperties:e,originalOptions:t,startTime:tt||ut(),duration:t.duration,tweens:[],createTween:function(e,t){var n=S.Tween(o,l.opts,e,t,l.opts.specialEasing[e]||l.opts.easing);return l.tweens.push(n),n},stop:function(e){var t=0,n=e?l.tweens.length:0;if(a)return this;for(a=!0;t<n;t++)l.tweens[t].run(1);return e?(s.notifyWith(o,[l,1,0]),s.resolveWith(o,[l,e])):s.rejectWith(o,[l,e]),this}}),c=l.props;for(!function(e,t){var n,r,i,o,a;for(n in e)if(i=t[r=X(n)],o=e[n],Array.isArray(o)&&(i=o[1],o=e[n]=o[0]),n!==r&&(e[r]=o,delete e[n]),(a=S.cssHooks[r])&&\"expand\"in a)for(n in o=a.expand(o),delete e[r],o)n in e||(e[n]=o[n],t[n]=i);else t[r]=i}(c,l.opts.specialEasing);r<i;r++)if(n=ft.prefilters[r].call(l,o,c,l.opts))return m(n.stop)&&(S._queueHooks(l.elem,l.opts.queue).stop=n.stop.bind(n)),n;return S.map(c,ct,l),m(l.opts.start)&&l.opts.start.call(o,l),l.progress(l.opts.progress).done(l.opts.done,l.opts.complete).fail(l.opts.fail).always(l.opts.always),S.fx.timer(S.extend(u,{elem:o,anim:l,queue:l.opts.queue})),l}S.Animation=S.extend(ft,{tweeners:{\"*\":[function(e,t){var n=this.createTween(e,t);return se(n.elem,e,te.exec(t),n),n}]},tweener:function(e,t){m(e)?(t=e,e=[\"*\"]):e=e.match(P);for(var n,r=0,i=e.length;r<i;r++)n=e[r],ft.tweeners[n]=ft.tweeners[n]||[],ft.tweeners[n].unshift(t)},prefilters:[function(e,t,n){var r,i,o,a,s,u,l,c,f=\"width\"in t||\"height\"in t,p=this,d={},h=e.style,g=e.nodeType&&ae(e),v=Y.get(e,\"fxshow\");for(r in n.queue||(null==(a=S._queueHooks(e,\"fx\")).unqueued&&(a.unqueued=0,s=a.empty.fire,a.empty.fire=function(){a.unqueued||s()}),a.unqueued++,p.always(function(){p.always(function(){a.unqueued--,S.queue(e,\"fx\").length||a.empty.fire()})})),t)if(i=t[r],ot.test(i)){if(delete t[r],o=o||\"toggle\"===i,i===(g?\"hide\":\"show\")){if(\"show\"!==i||!v||void 0===v[r])continue;g=!0}d[r]=v&&v[r]||S.style(e,r)}if((u=!S.isEmptyObject(t))||!S.isEmptyObject(d))for(r in f&&1===e.nodeType&&(n.overflow=[h.overflow,h.overflowX,h.overflowY],null==(l=v&&v.display)&&(l=Y.get(e,\"display\")),\"none\"===(c=S.css(e,\"display\"))&&(l?c=l:(le([e],!0),l=e.style.display||l,c=S.css(e,\"display\"),le([e]))),(\"inline\"===c||\"inline-block\"===c&&null!=l)&&\"none\"===S.css(e,\"float\")&&(u||(p.done(function(){h.display=l}),null==l&&(c=h.display,l=\"none\"===c?\"\":c)),h.display=\"inline-block\")),n.overflow&&(h.overflow=\"hidden\",p.always(function(){h.overflow=n.overflow[0],h.overflowX=n.overflow[1],h.overflowY=n.overflow[2]})),u=!1,d)u||(v?\"hidden\"in v&&(g=v.hidden):v=Y.access(e,\"fxshow\",{display:l}),o&&(v.hidden=!g),g&&le([e],!0),p.done(function(){for(r in g||le([e]),Y.remove(e,\"fxshow\"),d)S.style(e,r,d[r])})),u=ct(g?v[r]:0,r,p),r in v||(v[r]=u.start,g&&(u.end=u.start,u.start=0))}],prefilter:function(e,t){t?ft.prefilters.unshift(e):ft.prefilters.push(e)}}),S.speed=function(e,t,n){var r=e&&\"object\"==typeof e?S.extend({},e):{complete:n||!n&&t||m(e)&&e,duration:e,easing:n&&t||t&&!m(t)&&t};return S.fx.off?r.duration=0:\"number\"!=typeof r.duration&&(r.duration in S.fx.speeds?r.duration=S.fx.speeds[r.duration]:r.duration=S.fx.speeds._default),null!=r.queue&&!0!==r.queue||(r.queue=\"fx\"),r.old=r.complete,r.complete=function(){m(r.old)&&r.old.call(this),r.queue&&S.dequeue(this,r.queue)},r},S.fn.extend({fadeTo:function(e,t,n,r){return this.filter(ae).css(\"opacity\",0).show().end().animate({opacity:t},e,n,r)},animate:function(t,e,n,r){var i=S.isEmptyObject(t),o=S.speed(e,n,r),a=function(){var e=ft(this,S.extend({},t),o);(i||Y.get(this,\"finish\"))&&e.stop(!0)};return a.finish=a,i||!1===o.queue?this.each(a):this.queue(o.queue,a)},stop:function(i,e,o){var a=function(e){var t=e.stop;delete e.stop,t(o)};return\"string\"!=typeof i&&(o=e,e=i,i=void 0),e&&this.queue(i||\"fx\",[]),this.each(function(){var e=!0,t=null!=i&&i+\"queueHooks\",n=S.timers,r=Y.get(this);if(t)r[t]&&r[t].stop&&a(r[t]);else for(t in r)r[t]&&r[t].stop&&at.test(t)&&a(r[t]);for(t=n.length;t--;)n[t].elem!==this||null!=i&&n[t].queue!==i||(n[t].anim.stop(o),e=!1,n.splice(t,1));!e&&o||S.dequeue(this,i)})},finish:function(a){return!1!==a&&(a=a||\"fx\"),this.each(function(){var e,t=Y.get(this),n=t[a+\"queue\"],r=t[a+\"queueHooks\"],i=S.timers,o=n?n.length:0;for(t.finish=!0,S.queue(this,a,[]),r&&r.stop&&r.stop.call(this,!0),e=i.length;e--;)i[e].elem===this&&i[e].queue===a&&(i[e].anim.stop(!0),i.splice(e,1));for(e=0;e<o;e++)n[e]&&n[e].finish&&n[e].finish.call(this);delete t.finish})}}),S.each([\"toggle\",\"show\",\"hide\"],function(e,r){var i=S.fn[r];S.fn[r]=function(e,t,n){return null==e||\"boolean\"==typeof e?i.apply(this,arguments):this.animate(lt(r,!0),e,t,n)}}),S.each({slideDown:lt(\"show\"),slideUp:lt(\"hide\"),slideToggle:lt(\"toggle\"),fadeIn:{opacity:\"show\"},fadeOut:{opacity:\"hide\"},fadeToggle:{opacity:\"toggle\"}},function(e,r){S.fn[e]=function(e,t,n){return this.animate(r,e,t,n)}}),S.timers=[],S.fx.tick=function(){var e,t=0,n=S.timers;for(tt=Date.now();t<n.length;t++)(e=n[t])()||n[t]!==e||n.splice(t--,1);n.length||S.fx.stop(),tt=void 0},S.fx.timer=function(e){S.timers.push(e),S.fx.start()},S.fx.interval=13,S.fx.start=function(){nt||(nt=!0,st())},S.fx.stop=function(){nt=null},S.fx.speeds={slow:600,fast:200,_default:400},S.fn.delay=function(r,e){return r=S.fx&&S.fx.speeds[r]||r,e=e||\"fx\",this.queue(e,function(e,t){var n=C.setTimeout(e,r);t.stop=function(){C.clearTimeout(n)}})},rt=E.createElement(\"input\"),it=E.createElement(\"select\").appendChild(E.createElement(\"option\")),rt.type=\"checkbox\",y.checkOn=\"\"!==rt.value,y.optSelected=it.selected,(rt=E.createElement(\"input\")).value=\"t\",rt.type=\"radio\",y.radioValue=\"t\"===rt.value;var pt,dt=S.expr.attrHandle;S.fn.extend({attr:function(e,t){return $(this,S.attr,e,t,1<arguments.length)},removeAttr:function(e){return this.each(function(){S.removeAttr(this,e)})}}),S.extend({attr:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&&8!==o&&2!==o)return\"undefined\"==typeof e.getAttribute?S.prop(e,t,n):(1===o&&S.isXMLDoc(e)||(i=S.attrHooks[t.toLowerCase()]||(S.expr.match.bool.test(t)?pt:void 0)),void 0!==n?null===n?void S.removeAttr(e,t):i&&\"set\"in i&&void 0!==(r=i.set(e,n,t))?r:(e.setAttribute(t,n+\"\"),n):i&&\"get\"in i&&null!==(r=i.get(e,t))?r:null==(r=S.find.attr(e,t))?void 0:r)},attrHooks:{type:{set:function(e,t){if(!y.radioValue&&\"radio\"===t&&A(e,\"input\")){var n=e.value;return e.setAttribute(\"type\",t),n&&(e.value=n),t}}}},removeAttr:function(e,t){var n,r=0,i=t&&t.match(P);if(i&&1===e.nodeType)while(n=i[r++])e.removeAttribute(n)}}),pt={set:function(e,t,n){return!1===t?S.removeAttr(e,n):e.setAttribute(n,n),n}},S.each(S.expr.match.bool.source.match(/\\w+/g),function(e,t){var a=dt[t]||S.find.attr;dt[t]=function(e,t,n){var r,i,o=t.toLowerCase();return n||(i=dt[o],dt[o]=r,r=null!=a(e,t,n)?o:null,dt[o]=i),r}});var ht=/^(?:input|select|textarea|button)$/i,gt=/^(?:a|area)$/i;function vt(e){return(e.match(P)||[]).join(\" \")}function yt(e){return e.getAttribute&&e.getAttribute(\"class\")||\"\"}function mt(e){return Array.isArray(e)?e:\"string\"==typeof e&&e.match(P)||[]}S.fn.extend({prop:function(e,t){return $(this,S.prop,e,t,1<arguments.length)},removeProp:function(e){return this.each(function(){delete this[S.propFix[e]||e]})}}),S.extend({prop:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&&8!==o&&2!==o)return 1===o&&S.isXMLDoc(e)||(t=S.propFix[t]||t,i=S.propHooks[t]),void 0!==n?i&&\"set\"in i&&void 0!==(r=i.set(e,n,t))?r:e[t]=n:i&&\"get\"in i&&null!==(r=i.get(e,t))?r:e[t]},propHooks:{tabIndex:{get:function(e){var t=S.find.attr(e,\"tabindex\");return t?parseInt(t,10):ht.test(e.nodeName)||gt.test(e.nodeName)&&e.href?0:-1}}},propFix:{\"for\":\"htmlFor\",\"class\":\"className\"}}),y.optSelected||(S.propHooks.selected={get:function(e){var t=e.parentNode;return t&&t.parentNode&&t.parentNode.selectedIndex,null},set:function(e){var t=e.parentNode;t&&(t.selectedIndex,t.parentNode&&t.parentNode.selectedIndex)}}),S.each([\"tabIndex\",\"readOnly\",\"maxLength\",\"cellSpacing\",\"cellPadding\",\"rowSpan\",\"colSpan\",\"useMap\",\"frameBorder\",\"contentEditable\"],function(){S.propFix[this.toLowerCase()]=this}),S.fn.extend({addClass:function(t){var e,n,r,i,o,a,s,u=0;if(m(t))return this.each(function(e){S(this).addClass(t.call(this,e,yt(this)))});if((e=mt(t)).length)while(n=this[u++])if(i=yt(n),r=1===n.nodeType&&\" \"+vt(i)+\" \"){a=0;while(o=e[a++])r.indexOf(\" \"+o+\" \")<0&&(r+=o+\" \");i!==(s=vt(r))&&n.setAttribute(\"class\",s)}return this},removeClass:function(t){var e,n,r,i,o,a,s,u=0;if(m(t))return this.each(function(e){S(this).removeClass(t.call(this,e,yt(this)))});if(!arguments.length)return this.attr(\"class\",\"\");if((e=mt(t)).length)while(n=this[u++])if(i=yt(n),r=1===n.nodeType&&\" \"+vt(i)+\" \"){a=0;while(o=e[a++])while(-1<r.indexOf(\" \"+o+\" \"))r=r.replace(\" \"+o+\" \",\" \");i!==(s=vt(r))&&n.setAttribute(\"class\",s)}return this},toggleClass:function(i,t){var o=typeof i,a=\"string\"===o||Array.isArray(i);return\"boolean\"==typeof t&&a?t?this.addClass(i):this.removeClass(i):m(i)?this.each(function(e){S(this).toggleClass(i.call(this,e,yt(this),t),t)}):this.each(function(){var e,t,n,r;if(a){t=0,n=S(this),r=mt(i);while(e=r[t++])n.hasClass(e)?n.removeClass(e):n.addClass(e)}else void 0!==i&&\"boolean\"!==o||((e=yt(this))&&Y.set(this,\"__className__\",e),this.setAttribute&&this.setAttribute(\"class\",e||!1===i?\"\":Y.get(this,\"__className__\")||\"\"))})},hasClass:function(e){var t,n,r=0;t=\" \"+e+\" \";while(n=this[r++])if(1===n.nodeType&&-1<(\" \"+vt(yt(n))+\" \").indexOf(t))return!0;return!1}});var xt=/\\r/g;S.fn.extend({val:function(n){var r,e,i,t=this[0];return arguments.length?(i=m(n),this.each(function(e){var t;1===this.nodeType&&(null==(t=i?n.call(this,e,S(this).val()):n)?t=\"\":\"number\"==typeof t?t+=\"\":Array.isArray(t)&&(t=S.map(t,function(e){return null==e?\"\":e+\"\"})),(r=S.valHooks[this.type]||S.valHooks[this.nodeName.toLowerCase()])&&\"set\"in r&&void 0!==r.set(this,t,\"value\")||(this.value=t))})):t?(r=S.valHooks[t.type]||S.valHooks[t.nodeName.toLowerCase()])&&\"get\"in r&&void 0!==(e=r.get(t,\"value\"))?e:\"string\"==typeof(e=t.value)?e.replace(xt,\"\"):null==e?\"\":e:void 0}}),S.extend({valHooks:{option:{get:function(e){var t=S.find.attr(e,\"value\");return null!=t?t:vt(S.text(e))}},select:{get:function(e){var t,n,r,i=e.options,o=e.selectedIndex,a=\"select-one\"===e.type,s=a?null:[],u=a?o+1:i.length;for(r=o<0?u:a?o:0;r<u;r++)if(((n=i[r]).selected||r===o)&&!n.disabled&&(!n.parentNode.disabled||!A(n.parentNode,\"optgroup\"))){if(t=S(n).val(),a)return t;s.push(t)}return s},set:function(e,t){var n,r,i=e.options,o=S.makeArray(t),a=i.length;while(a--)((r=i[a]).selected=-1<S.inArray(S.valHooks.option.get(r),o))&&(n=!0);return n||(e.selectedIndex=-1),o}}}}),S.each([\"radio\",\"checkbox\"],function(){S.valHooks[this]={set:function(e,t){if(Array.isArray(t))return e.checked=-1<S.inArray(S(e).val(),t)}},y.checkOn||(S.valHooks[this].get=function(e){return null===e.getAttribute(\"value\")?\"on\":e.value})}),y.focusin=\"onfocusin\"in C;var bt=/^(?:focusinfocus|focusoutblur)$/,wt=function(e){e.stopPropagation()};S.extend(S.event,{trigger:function(e,t,n,r){var i,o,a,s,u,l,c,f,p=[n||E],d=v.call(e,\"type\")?e.type:e,h=v.call(e,\"namespace\")?e.namespace.split(\".\"):[];if(o=f=a=n=n||E,3!==n.nodeType&&8!==n.nodeType&&!bt.test(d+S.event.triggered)&&(-1<d.indexOf(\".\")&&(d=(h=d.split(\".\")).shift(),h.sort()),u=d.indexOf(\":\")<0&&\"on\"+d,(e=e[S.expando]?e:new S.Event(d,\"object\"==typeof e&&e)).isTrigger=r?2:3,e.namespace=h.join(\".\"),e.rnamespace=e.namespace?new RegExp(\"(^|\\\\.)\"+h.join(\"\\\\.(?:.*\\\\.|)\")+\"(\\\\.|$)\"):null,e.result=void 0,e.target||(e.target=n),t=null==t?[e]:S.makeArray(t,[e]),c=S.event.special[d]||{},r||!c.trigger||!1!==c.trigger.apply(n,t))){if(!r&&!c.noBubble&&!x(n)){for(s=c.delegateType||d,bt.test(s+d)||(o=o.parentNode);o;o=o.parentNode)p.push(o),a=o;a===(n.ownerDocument||E)&&p.push(a.defaultView||a.parentWindow||C)}i=0;while((o=p[i++])&&!e.isPropagationStopped())f=o,e.type=1<i?s:c.bindType||d,(l=(Y.get(o,\"events\")||Object.create(null))[e.type]&&Y.get(o,\"handle\"))&&l.apply(o,t),(l=u&&o[u])&&l.apply&&V(o)&&(e.result=l.apply(o,t),!1===e.result&&e.preventDefault());return e.type=d,r||e.isDefaultPrevented()||c._default&&!1!==c._default.apply(p.pop(),t)||!V(n)||u&&m(n[d])&&!x(n)&&((a=n[u])&&(n[u]=null),S.event.triggered=d,e.isPropagationStopped()&&f.addEventListener(d,wt),n[d](),e.isPropagationStopped()&&f.removeEventListener(d,wt),S.event.triggered=void 0,a&&(n[u]=a)),e.result}},simulate:function(e,t,n){var r=S.extend(new S.Event,n,{type:e,isSimulated:!0});S.event.trigger(r,null,t)}}),S.fn.extend({trigger:function(e,t){return this.each(function(){S.event.trigger(e,t,this)})},triggerHandler:function(e,t){var n=this[0];if(n)return S.event.trigger(e,t,n,!0)}}),y.focusin||S.each({focus:\"focusin\",blur:\"focusout\"},function(n,r){var i=function(e){S.event.simulate(r,e.target,S.event.fix(e))};S.event.special[r]={setup:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r);t||e.addEventListener(n,i,!0),Y.access(e,r,(t||0)+1)},teardown:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r)-1;t?Y.access(e,r,t):(e.removeEventListener(n,i,!0),Y.remove(e,r))}}});var Tt=C.location,Ct={guid:Date.now()},Et=/\\?/;S.parseXML=function(e){var t;if(!e||\"string\"!=typeof e)return null;try{t=(new C.DOMParser).parseFromString(e,\"text/xml\")}catch(e){t=void 0}return t&&!t.getElementsByTagName(\"parsererror\").length||S.error(\"Invalid XML: \"+e),t};var St=/\\[\\]$/,kt=/\\r?\\n/g,At=/^(?:submit|button|image|reset|file)$/i,Nt=/^(?:input|select|textarea|keygen)/i;function Dt(n,e,r,i){var t;if(Array.isArray(e))S.each(e,function(e,t){r||St.test(n)?i(n,t):Dt(n+\"[\"+(\"object\"==typeof t&&null!=t?e:\"\")+\"]\",t,r,i)});else if(r||\"object\"!==w(e))i(n,e);else for(t in e)Dt(n+\"[\"+t+\"]\",e[t],r,i)}S.param=function(e,t){var n,r=[],i=function(e,t){var n=m(t)?t():t;r[r.length]=encodeURIComponent(e)+\"=\"+encodeURIComponent(null==n?\"\":n)};if(null==e)return\"\";if(Array.isArray(e)||e.jquery&&!S.isPlainObject(e))S.each(e,function(){i(this.name,this.value)});else for(n in e)Dt(n,e[n],t,i);return r.join(\"&\")},S.fn.extend({serialize:function(){return S.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var e=S.prop(this,\"elements\");return e?S.makeArray(e):this}).filter(function(){var e=this.type;return this.name&&!S(this).is(\":disabled\")&&Nt.test(this.nodeName)&&!At.test(e)&&(this.checked||!pe.test(e))}).map(function(e,t){var n=S(this).val();return null==n?null:Array.isArray(n)?S.map(n,function(e){return{name:t.name,value:e.replace(kt,\"\\r\\n\")}}):{name:t.name,value:n.replace(kt,\"\\r\\n\")}}).get()}});var jt=/%20/g,qt=/#.*$/,Lt=/([?&])_=[^&]*/,Ht=/^(.*?):[ \\t]*([^\\r\\n]*)$/gm,Ot=/^(?:GET|HEAD)$/,Pt=/^\\/\\//,Rt={},Mt={},It=\"*/\".concat(\"*\"),Wt=E.createElement(\"a\");function Ft(o){return function(e,t){\"string\"!=typeof e&&(t=e,e=\"*\");var n,r=0,i=e.toLowerCase().match(P)||[];if(m(t))while(n=i[r++])\"+\"===n[0]?(n=n.slice(1)||\"*\",(o[n]=o[n]||[]).unshift(t)):(o[n]=o[n]||[]).push(t)}}function Bt(t,i,o,a){var s={},u=t===Mt;function l(e){var r;return s[e]=!0,S.each(t[e]||[],function(e,t){var n=t(i,o,a);return\"string\"!=typeof n||u||s[n]?u?!(r=n):void 0:(i.dataTypes.unshift(n),l(n),!1)}),r}return l(i.dataTypes[0])||!s[\"*\"]&&l(\"*\")}function $t(e,t){var n,r,i=S.ajaxSettings.flatOptions||{};for(n in t)void 0!==t[n]&&((i[n]?e:r||(r={}))[n]=t[n]);return r&&S.extend(!0,e,r),e}Wt.href=Tt.href,S.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:Tt.href,type:\"GET\",isLocal:/^(?:about|app|app-storage|.+-extension|file|res|widget):$/.test(Tt.protocol),global:!0,processData:!0,async:!0,contentType:\"application/x-www-form-urlencoded; charset=UTF-8\",accepts:{\"*\":It,text:\"text/plain\",html:\"text/html\",xml:\"application/xml, text/xml\",json:\"application/json, text/javascript\"},contents:{xml:/\\bxml\\b/,html:/\\bhtml/,json:/\\bjson\\b/},responseFields:{xml:\"responseXML\",text:\"responseText\",json:\"responseJSON\"},converters:{\"* text\":String,\"text html\":!0,\"text json\":JSON.parse,\"text xml\":S.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(e,t){return t?$t($t(e,S.ajaxSettings),t):$t(S.ajaxSettings,e)},ajaxPrefilter:Ft(Rt),ajaxTransport:Ft(Mt),ajax:function(e,t){\"object\"==typeof e&&(t=e,e=void 0),t=t||{};var c,f,p,n,d,r,h,g,i,o,v=S.ajaxSetup({},t),y=v.context||v,m=v.context&&(y.nodeType||y.jquery)?S(y):S.event,x=S.Deferred(),b=S.Callbacks(\"once memory\"),w=v.statusCode||{},a={},s={},u=\"canceled\",T={readyState:0,getResponseHeader:function(e){var t;if(h){if(!n){n={};while(t=Ht.exec(p))n[t[1].toLowerCase()+\" \"]=(n[t[1].toLowerCase()+\" \"]||[]).concat(t[2])}t=n[e.toLowerCase()+\" \"]}return null==t?null:t.join(\", \")},getAllResponseHeaders:function(){return h?p:null},setRequestHeader:function(e,t){return null==h&&(e=s[e.toLowerCase()]=s[e.toLowerCase()]||e,a[e]=t),this},overrideMimeType:function(e){return null==h&&(v.mimeType=e),this},statusCode:function(e){var t;if(e)if(h)T.always(e[T.status]);else for(t in e)w[t]=[w[t],e[t]];return this},abort:function(e){var t=e||u;return c&&c.abort(t),l(0,t),this}};if(x.promise(T),v.url=((e||v.url||Tt.href)+\"\").replace(Pt,Tt.protocol+\"//\"),v.type=t.method||t.type||v.method||v.type,v.dataTypes=(v.dataType||\"*\").toLowerCase().match(P)||[\"\"],null==v.crossDomain){r=E.createElement(\"a\");try{r.href=v.url,r.href=r.href,v.crossDomain=Wt.protocol+\"//\"+Wt.host!=r.protocol+\"//\"+r.host}catch(e){v.crossDomain=!0}}if(v.data&&v.processData&&\"string\"!=typeof v.data&&(v.data=S.param(v.data,v.traditional)),Bt(Rt,v,t,T),h)return T;for(i in(g=S.event&&v.global)&&0==S.active++&&S.event.trigger(\"ajaxStart\"),v.type=v.type.toUpperCase(),v.hasContent=!Ot.test(v.type),f=v.url.replace(qt,\"\"),v.hasContent?v.data&&v.processData&&0===(v.contentType||\"\").indexOf(\"application/x-www-form-urlencoded\")&&(v.data=v.data.replace(jt,\"+\")):(o=v.url.slice(f.length),v.data&&(v.processData||\"string\"==typeof v.data)&&(f+=(Et.test(f)?\"&\":\"?\")+v.data,delete v.data),!1===v.cache&&(f=f.replace(Lt,\"$1\"),o=(Et.test(f)?\"&\":\"?\")+\"_=\"+Ct.guid+++o),v.url=f+o),v.ifModified&&(S.lastModified[f]&&T.setRequestHeader(\"If-Modified-Since\",S.lastModified[f]),S.etag[f]&&T.setRequestHeader(\"If-None-Match\",S.etag[f])),(v.data&&v.hasContent&&!1!==v.contentType||t.contentType)&&T.setRequestHeader(\"Content-Type\",v.contentType),T.setRequestHeader(\"Accept\",v.dataTypes[0]&&v.accepts[v.dataTypes[0]]?v.accepts[v.dataTypes[0]]+(\"*\"!==v.dataTypes[0]?\", \"+It+\"; q=0.01\":\"\"):v.accepts[\"*\"]),v.headers)T.setRequestHeader(i,v.headers[i]);if(v.beforeSend&&(!1===v.beforeSend.call(y,T,v)||h))return T.abort();if(u=\"abort\",b.add(v.complete),T.done(v.success),T.fail(v.error),c=Bt(Mt,v,t,T)){if(T.readyState=1,g&&m.trigger(\"ajaxSend\",[T,v]),h)return T;v.async&&0<v.timeout&&(d=C.setTimeout(function(){T.abort(\"timeout\")},v.timeout));try{h=!1,c.send(a,l)}catch(e){if(h)throw e;l(-1,e)}}else l(-1,\"No Transport\");function l(e,t,n,r){var i,o,a,s,u,l=t;h||(h=!0,d&&C.clearTimeout(d),c=void 0,p=r||\"\",T.readyState=0<e?4:0,i=200<=e&&e<300||304===e,n&&(s=function(e,t,n){var r,i,o,a,s=e.contents,u=e.dataTypes;while(\"*\"===u[0])u.shift(),void 0===r&&(r=e.mimeType||t.getResponseHeader(\"Content-Type\"));if(r)for(i in s)if(s[i]&&s[i].test(r)){u.unshift(i);break}if(u[0]in n)o=u[0];else{for(i in n){if(!u[0]||e.converters[i+\" \"+u[0]]){o=i;break}a||(a=i)}o=o||a}if(o)return o!==u[0]&&u.unshift(o),n[o]}(v,T,n)),!i&&-1<S.inArray(\"script\",v.dataTypes)&&(v.converters[\"text script\"]=function(){}),s=function(e,t,n,r){var i,o,a,s,u,l={},c=e.dataTypes.slice();if(c[1])for(a in e.converters)l[a.toLowerCase()]=e.converters[a];o=c.shift();while(o)if(e.responseFields[o]&&(n[e.responseFields[o]]=t),!u&&r&&e.dataFilter&&(t=e.dataFilter(t,e.dataType)),u=o,o=c.shift())if(\"*\"===o)o=u;else if(\"*\"!==u&&u!==o){if(!(a=l[u+\" \"+o]||l[\"* \"+o]))for(i in l)if((s=i.split(\" \"))[1]===o&&(a=l[u+\" \"+s[0]]||l[\"* \"+s[0]])){!0===a?a=l[i]:!0!==l[i]&&(o=s[0],c.unshift(s[1]));break}if(!0!==a)if(a&&e[\"throws\"])t=a(t);else try{t=a(t)}catch(e){return{state:\"parsererror\",error:a?e:\"No conversion from \"+u+\" to \"+o}}}return{state:\"success\",data:t}}(v,s,T,i),i?(v.ifModified&&((u=T.getResponseHeader(\"Last-Modified\"))&&(S.lastModified[f]=u),(u=T.getResponseHeader(\"etag\"))&&(S.etag[f]=u)),204===e||\"HEAD\"===v.type?l=\"nocontent\":304===e?l=\"notmodified\":(l=s.state,o=s.data,i=!(a=s.error))):(a=l,!e&&l||(l=\"error\",e<0&&(e=0))),T.status=e,T.statusText=(t||l)+\"\",i?x.resolveWith(y,[o,l,T]):x.rejectWith(y,[T,l,a]),T.statusCode(w),w=void 0,g&&m.trigger(i?\"ajaxSuccess\":\"ajaxError\",[T,v,i?o:a]),b.fireWith(y,[T,l]),g&&(m.trigger(\"ajaxComplete\",[T,v]),--S.active||S.event.trigger(\"ajaxStop\")))}return T},getJSON:function(e,t,n){return S.get(e,t,n,\"json\")},getScript:function(e,t){return S.get(e,void 0,t,\"script\")}}),S.each([\"get\",\"post\"],function(e,i){S[i]=function(e,t,n,r){return m(t)&&(r=r||n,n=t,t=void 0),S.ajax(S.extend({url:e,type:i,dataType:r,data:t,success:n},S.isPlainObject(e)&&e))}}),S.ajaxPrefilter(function(e){var t;for(t in e.headers)\"content-type\"===t.toLowerCase()&&(e.contentType=e.headers[t]||\"\")}),S._evalUrl=function(e,t,n){return S.ajax({url:e,type:\"GET\",dataType:\"script\",cache:!0,async:!1,global:!1,converters:{\"text script\":function(){}},dataFilter:function(e){S.globalEval(e,t,n)}})},S.fn.extend({wrapAll:function(e){var t;return this[0]&&(m(e)&&(e=e.call(this[0])),t=S(e,this[0].ownerDocument).eq(0).clone(!0),this[0].parentNode&&t.insertBefore(this[0]),t.map(function(){var e=this;while(e.firstElementChild)e=e.firstElementChild;return e}).append(this)),this},wrapInner:function(n){return m(n)?this.each(function(e){S(this).wrapInner(n.call(this,e))}):this.each(function(){var e=S(this),t=e.contents();t.length?t.wrapAll(n):e.append(n)})},wrap:function(t){var n=m(t);return this.each(function(e){S(this).wrapAll(n?t.call(this,e):t)})},unwrap:function(e){return this.parent(e).not(\"body\").each(function(){S(this).replaceWith(this.childNodes)}),this}}),S.expr.pseudos.hidden=function(e){return!S.expr.pseudos.visible(e)},S.expr.pseudos.visible=function(e){return!!(e.offsetWidth||e.offsetHeight||e.getClientRects().length)},S.ajaxSettings.xhr=function(){try{return new C.XMLHttpRequest}catch(e){}};var _t={0:200,1223:204},zt=S.ajaxSettings.xhr();y.cors=!!zt&&\"withCredentials\"in zt,y.ajax=zt=!!zt,S.ajaxTransport(function(i){var o,a;if(y.cors||zt&&!i.crossDomain)return{send:function(e,t){var n,r=i.xhr();if(r.open(i.type,i.url,i.async,i.username,i.password),i.xhrFields)for(n in i.xhrFields)r[n]=i.xhrFields[n];for(n in i.mimeType&&r.overrideMimeType&&r.overrideMimeType(i.mimeType),i.crossDomain||e[\"X-Requested-With\"]||(e[\"X-Requested-With\"]=\"XMLHttpRequest\"),e)r.setRequestHeader(n,e[n]);o=function(e){return function(){o&&(o=a=r.onload=r.onerror=r.onabort=r.ontimeout=r.onreadystatechange=null,\"abort\"===e?r.abort():\"error\"===e?\"number\"!=typeof r.status?t(0,\"error\"):t(r.status,r.statusText):t(_t[r.status]||r.status,r.statusText,\"text\"!==(r.responseType||\"text\")||\"string\"!=typeof r.responseText?{binary:r.response}:{text:r.responseText},r.getAllResponseHeaders()))}},r.onload=o(),a=r.onerror=r.ontimeout=o(\"error\"),void 0!==r.onabort?r.onabort=a:r.onreadystatechange=function(){4===r.readyState&&C.setTimeout(function(){o&&a()})},o=o(\"abort\");try{r.send(i.hasContent&&i.data||null)}catch(e){if(o)throw e}},abort:function(){o&&o()}}}),S.ajaxPrefilter(function(e){e.crossDomain&&(e.contents.script=!1)}),S.ajaxSetup({accepts:{script:\"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript\"},contents:{script:/\\b(?:java|ecma)script\\b/},converters:{\"text script\":function(e){return S.globalEval(e),e}}}),S.ajaxPrefilter(\"script\",function(e){void 0===e.cache&&(e.cache=!1),e.crossDomain&&(e.type=\"GET\")}),S.ajaxTransport(\"script\",function(n){var r,i;if(n.crossDomain||n.scriptAttrs)return{send:function(e,t){r=S(\"<script>\").attr(n.scriptAttrs||{}).prop({charset:n.scriptCharset,src:n.url}).on(\"load error\",i=function(e){r.remove(),i=null,e&&t(\"error\"===e.type?404:200,e.type)}),E.head.appendChild(r[0])},abort:function(){i&&i()}}});var Ut,Xt=[],Vt=/(=)\\?(?=&|$)|\\?\\?/;S.ajaxSetup({jsonp:\"callback\",jsonpCallback:function(){var e=Xt.pop()||S.expando+\"_\"+Ct.guid++;return this[e]=!0,e}}),S.ajaxPrefilter(\"json jsonp\",function(e,t,n){var r,i,o,a=!1!==e.jsonp&&(Vt.test(e.url)?\"url\":\"string\"==typeof e.data&&0===(e.contentType||\"\").indexOf(\"application/x-www-form-urlencoded\")&&Vt.test(e.data)&&\"data\");if(a||\"jsonp\"===e.dataTypes[0])return r=e.jsonpCallback=m(e.jsonpCallback)?e.jsonpCallback():e.jsonpCallback,a?e[a]=e[a].replace(Vt,\"$1\"+r):!1!==e.jsonp&&(e.url+=(Et.test(e.url)?\"&\":\"?\")+e.jsonp+\"=\"+r),e.converters[\"script json\"]=function(){return o||S.error(r+\" was not called\"),o[0]},e.dataTypes[0]=\"json\",i=C[r],C[r]=function(){o=arguments},n.always(function(){void 0===i?S(C).removeProp(r):C[r]=i,e[r]&&(e.jsonpCallback=t.jsonpCallback,Xt.push(r)),o&&m(i)&&i(o[0]),o=i=void 0}),\"script\"}),y.createHTMLDocument=((Ut=E.implementation.createHTMLDocument(\"\").body).innerHTML=\"<form></form><form></form>\",2===Ut.childNodes.length),S.parseHTML=function(e,t,n){return\"string\"!=typeof e?[]:(\"boolean\"==typeof t&&(n=t,t=!1),t||(y.createHTMLDocument?((r=(t=E.implementation.createHTMLDocument(\"\")).createElement(\"base\")).href=E.location.href,t.head.appendChild(r)):t=E),o=!n&&[],(i=N.exec(e))?[t.createElement(i[1])]:(i=xe([e],t,o),o&&o.length&&S(o).remove(),S.merge([],i.childNodes)));var r,i,o},S.fn.load=function(e,t,n){var r,i,o,a=this,s=e.indexOf(\" \");return-1<s&&(r=vt(e.slice(s)),e=e.slice(0,s)),m(t)?(n=t,t=void 0):t&&\"object\"==typeof t&&(i=\"POST\"),0<a.length&&S.ajax({url:e,type:i||\"GET\",dataType:\"html\",data:t}).done(function(e){o=arguments,a.html(r?S(\"<div>\").append(S.parseHTML(e)).find(r):e)}).always(n&&function(e,t){a.each(function(){n.apply(this,o||[e.responseText,t,e])})}),this},S.expr.pseudos.animated=function(t){return S.grep(S.timers,function(e){return t===e.elem}).length},S.offset={setOffset:function(e,t,n){var r,i,o,a,s,u,l=S.css(e,\"position\"),c=S(e),f={};\"static\"===l&&(e.style.position=\"relative\"),s=c.offset(),o=S.css(e,\"top\"),u=S.css(e,\"left\"),(\"absolute\"===l||\"fixed\"===l)&&-1<(o+u).indexOf(\"auto\")?(a=(r=c.position()).top,i=r.left):(a=parseFloat(o)||0,i=parseFloat(u)||0),m(t)&&(t=t.call(e,n,S.extend({},s))),null!=t.top&&(f.top=t.top-s.top+a),null!=t.left&&(f.left=t.left-s.left+i),\"using\"in t?t.using.call(e,f):(\"number\"==typeof f.top&&(f.top+=\"px\"),\"number\"==typeof f.left&&(f.left+=\"px\"),c.css(f))}},S.fn.extend({offset:function(t){if(arguments.length)return void 0===t?this:this.each(function(e){S.offset.setOffset(this,t,e)});var e,n,r=this[0];return r?r.getClientRects().length?(e=r.getBoundingClientRect(),n=r.ownerDocument.defaultView,{top:e.top+n.pageYOffset,left:e.left+n.pageXOffset}):{top:0,left:0}:void 0},position:function(){if(this[0]){var e,t,n,r=this[0],i={top:0,left:0};if(\"fixed\"===S.css(r,\"position\"))t=r.getBoundingClientRect();else{t=this.offset(),n=r.ownerDocument,e=r.offsetParent||n.documentElement;while(e&&(e===n.body||e===n.documentElement)&&\"static\"===S.css(e,\"position\"))e=e.parentNode;e&&e!==r&&1===e.nodeType&&((i=S(e).offset()).top+=S.css(e,\"borderTopWidth\",!0),i.left+=S.css(e,\"borderLeftWidth\",!0))}return{top:t.top-i.top-S.css(r,\"marginTop\",!0),left:t.left-i.left-S.css(r,\"marginLeft\",!0)}}},offsetParent:function(){return this.map(function(){var e=this.offsetParent;while(e&&\"static\"===S.css(e,\"position\"))e=e.offsetParent;return e||re})}}),S.each({scrollLeft:\"pageXOffset\",scrollTop:\"pageYOffset\"},function(t,i){var o=\"pageYOffset\"===i;S.fn[t]=function(e){return $(this,function(e,t,n){var r;if(x(e)?r=e:9===e.nodeType&&(r=e.defaultView),void 0===n)return r?r[i]:e[t];r?r.scrollTo(o?r.pageXOffset:n,o?n:r.pageYOffset):e[t]=n},t,e,arguments.length)}}),S.each([\"top\",\"left\"],function(e,n){S.cssHooks[n]=$e(y.pixelPosition,function(e,t){if(t)return t=Be(e,n),Me.test(t)?S(e).position()[n]+\"px\":t})}),S.each({Height:\"height\",Width:\"width\"},function(a,s){S.each({padding:\"inner\"+a,content:s,\"\":\"outer\"+a},function(r,o){S.fn[o]=function(e,t){var n=arguments.length&&(r||\"boolean\"!=typeof e),i=r||(!0===e||!0===t?\"margin\":\"border\");return $(this,function(e,t,n){var r;return x(e)?0===o.indexOf(\"outer\")?e[\"inner\"+a]:e.document.documentElement[\"client\"+a]:9===e.nodeType?(r=e.documentElement,Math.max(e.body[\"scroll\"+a],r[\"scroll\"+a],e.body[\"offset\"+a],r[\"offset\"+a],r[\"client\"+a])):void 0===n?S.css(e,t,i):S.style(e,t,n,i)},s,n?e:void 0,n)}})}),S.each([\"ajaxStart\",\"ajaxStop\",\"ajaxComplete\",\"ajaxError\",\"ajaxSuccess\",\"ajaxSend\"],function(e,t){S.fn[t]=function(e){return this.on(t,e)}}),S.fn.extend({bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return 1===arguments.length?this.off(e,\"**\"):this.off(t,e||\"**\",n)},hover:function(e,t){return this.mouseenter(e).mouseleave(t||e)}}),S.each(\"blur focus focusin focusout resize scroll click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup contextmenu\".split(\" \"),function(e,n){S.fn[n]=function(e,t){return 0<arguments.length?this.on(n,null,e,t):this.trigger(n)}});var Gt=/^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g;S.proxy=function(e,t){var n,r,i;if(\"string\"==typeof t&&(n=e[t],t=e,e=n),m(e))return r=s.call(arguments,2),(i=function(){return e.apply(t||this,r.concat(s.call(arguments)))}).guid=e.guid=e.guid||S.guid++,i},S.holdReady=function(e){e?S.readyWait++:S.ready(!0)},S.isArray=Array.isArray,S.parseJSON=JSON.parse,S.nodeName=A,S.isFunction=m,S.isWindow=x,S.camelCase=X,S.type=w,S.now=Date.now,S.isNumeric=function(e){var t=S.type(e);return(\"number\"===t||\"string\"===t)&&!isNaN(e-parseFloat(e))},S.trim=function(e){return null==e?\"\":(e+\"\").replace(Gt,\"\")},\"function\"==typeof define&&define.amd&&define(\"jquery\",[],function(){return S});var Yt=C.jQuery,Qt=C.$;return S.noConflict=function(e){return C.$===S&&(C.$=Qt),e&&C.jQuery===S&&(C.jQuery=Yt),S},\"undefined\"==typeof e&&(C.jQuery=C.$=S),S});"}, {"filename": "master/_static/js/badge_only.js", "status": "removed", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -1 +0,0 @@\n-!function(e){var t={};function r(n){if(t[n])return t[n].exports;var o=t[n]={i:n,l:!1,exports:{}};return e[n].call(o.exports,o,o.exports,r),o.l=!0,o.exports}r.m=e,r.c=t,r.d=function(e,t,n){r.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:n})},r.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},r.t=function(e,t){if(1&t&&(e=r(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var n=Object.create(null);if(r.r(n),Object.defineProperty(n,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var o in e)r.d(n,o,function(t){return e[t]}.bind(null,o));return n},r.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(t,\"a\",t),t},r.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},r.p=\"\",r(r.s=4)}({4:function(e,t,r){}});\n\\ No newline at end of file"}, {"filename": "master/_static/js/html5shiv-printshiv.min.js", "status": "removed", "additions": 0, "deletions": 4, "changes": 4, "file_content_changes": "@@ -1,4 +0,0 @@\n-/**\n-* @preserve HTML5 Shiv 3.7.3-pre | @afarkas @jdalton @jon_neal @rem | MIT/GPL2 Licensed\n-*/\n-!function(a,b){function c(a,b){var c=a.createElement(\"p\"),d=a.getElementsByTagName(\"head\")[0]||a.documentElement;return c.innerHTML=\"x<style>\"+b+\"</style>\",d.insertBefore(c.lastChild,d.firstChild)}function d(){var a=y.elements;return\"string\"==typeof a?a.split(\" \"):a}function e(a,b){var c=y.elements;\"string\"!=typeof c&&(c=c.join(\" \")),\"string\"!=typeof a&&(a=a.join(\" \")),y.elements=c+\" \"+a,j(b)}function f(a){var b=x[a[v]];return b||(b={},w++,a[v]=w,x[w]=b),b}function g(a,c,d){if(c||(c=b),q)return c.createElement(a);d||(d=f(c));var e;return e=d.cache[a]?d.cache[a].cloneNode():u.test(a)?(d.cache[a]=d.createElem(a)).cloneNode():d.createElem(a),!e.canHaveChildren||t.test(a)||e.tagUrn?e:d.frag.appendChild(e)}function h(a,c){if(a||(a=b),q)return a.createDocumentFragment();c=c||f(a);for(var e=c.frag.cloneNode(),g=0,h=d(),i=h.length;i>g;g++)e.createElement(h[g]);return e}function i(a,b){b.cache||(b.cache={},b.createElem=a.createElement,b.createFrag=a.createDocumentFragment,b.frag=b.createFrag()),a.createElement=function(c){return y.shivMethods?g(c,a,b):b.createElem(c)},a.createDocumentFragment=Function(\"h,f\",\"return function(){var n=f.cloneNode(),c=n.createElement;h.shivMethods&&(\"+d().join().replace(/[\\w\\-:]+/g,function(a){return b.createElem(a),b.frag.createElement(a),'c(\"'+a+'\")'})+\");return n}\")(y,b.frag)}function j(a){a||(a=b);var d=f(a);return!y.shivCSS||p||d.hasCSS||(d.hasCSS=!!c(a,\"article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}mark{background:#FF0;color:#000}template{display:none}\")),q||i(a,d),a}function k(a){for(var b,c=a.getElementsByTagName(\"*\"),e=c.length,f=RegExp(\"^(?:\"+d().join(\"|\")+\")$\",\"i\"),g=[];e--;)b=c[e],f.test(b.nodeName)&&g.push(b.applyElement(l(b)));return g}function l(a){for(var b,c=a.attributes,d=c.length,e=a.ownerDocument.createElement(A+\":\"+a.nodeName);d--;)b=c[d],b.specified&&e.setAttribute(b.nodeName,b.nodeValue);return e.style.cssText=a.style.cssText,e}function m(a){for(var b,c=a.split(\"{\"),e=c.length,f=RegExp(\"(^|[\\\\s,>+~])(\"+d().join(\"|\")+\")(?=[[\\\\s,>+~#.:]|$)\",\"gi\"),g=\"$1\"+A+\"\\\\:$2\";e--;)b=c[e]=c[e].split(\"}\"),b[b.length-1]=b[b.length-1].replace(f,g),c[e]=b.join(\"}\");return c.join(\"{\")}function n(a){for(var b=a.length;b--;)a[b].removeNode()}function o(a){function b(){clearTimeout(g._removeSheetTimer),d&&d.removeNode(!0),d=null}var d,e,g=f(a),h=a.namespaces,i=a.parentWindow;return!B||a.printShived?a:(\"undefined\"==typeof h[A]&&h.add(A),i.attachEvent(\"onbeforeprint\",function(){b();for(var f,g,h,i=a.styleSheets,j=[],l=i.length,n=Array(l);l--;)n[l]=i[l];for(;h=n.pop();)if(!h.disabled&&z.test(h.media)){try{f=h.imports,g=f.length}catch(o){g=0}for(l=0;g>l;l++)n.push(f[l]);try{j.push(h.cssText)}catch(o){}}j=m(j.reverse().join(\"\")),e=k(a),d=c(a,j)}),i.attachEvent(\"onafterprint\",function(){n(e),clearTimeout(g._removeSheetTimer),g._removeSheetTimer=setTimeout(b,500)}),a.printShived=!0,a)}var p,q,r=\"3.7.3\",s=a.html5||{},t=/^<|^(?:button|map|select|textarea|object|iframe|option|optgroup)$/i,u=/^(?:a|b|code|div|fieldset|h1|h2|h3|h4|h5|h6|i|label|li|ol|p|q|span|strong|style|table|tbody|td|th|tr|ul)$/i,v=\"_html5shiv\",w=0,x={};!function(){try{var a=b.createElement(\"a\");a.innerHTML=\"<xyz></xyz>\",p=\"hidden\"in a,q=1==a.childNodes.length||function(){b.createElement(\"a\");var a=b.createDocumentFragment();return\"undefined\"==typeof a.cloneNode||\"undefined\"==typeof a.createDocumentFragment||\"undefined\"==typeof a.createElement}()}catch(c){p=!0,q=!0}}();var y={elements:s.elements||\"abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time video\",version:r,shivCSS:s.shivCSS!==!1,supportsUnknownElements:q,shivMethods:s.shivMethods!==!1,type:\"default\",shivDocument:j,createElement:g,createDocumentFragment:h,addElements:e};a.html5=y,j(b);var z=/^$|\\b(?:all|print)\\b/,A=\"html5shiv\",B=!q&&function(){var c=b.documentElement;return!(\"undefined\"==typeof b.namespaces||\"undefined\"==typeof b.parentWindow||\"undefined\"==typeof c.applyElement||\"undefined\"==typeof c.removeNode||\"undefined\"==typeof a.attachEvent)}();y.type+=\" print\",y.shivPrint=o,o(b),\"object\"==typeof module&&module.exports&&(module.exports=y)}(\"undefined\"!=typeof window?window:this,document);\n\\ No newline at end of file"}, {"filename": "master/_static/js/html5shiv.min.js", "status": "removed", "additions": 0, "deletions": 4, "changes": 4, "file_content_changes": "@@ -1,4 +0,0 @@\n-/**\n-* @preserve HTML5 Shiv 3.7.3 | @afarkas @jdalton @jon_neal @rem | MIT/GPL2 Licensed\n-*/\n-!function(a,b){function c(a,b){var c=a.createElement(\"p\"),d=a.getElementsByTagName(\"head\")[0]||a.documentElement;return c.innerHTML=\"x<style>\"+b+\"</style>\",d.insertBefore(c.lastChild,d.firstChild)}function d(){var a=t.elements;return\"string\"==typeof a?a.split(\" \"):a}function e(a,b){var c=t.elements;\"string\"!=typeof c&&(c=c.join(\" \")),\"string\"!=typeof a&&(a=a.join(\" \")),t.elements=c+\" \"+a,j(b)}function f(a){var b=s[a[q]];return b||(b={},r++,a[q]=r,s[r]=b),b}function g(a,c,d){if(c||(c=b),l)return c.createElement(a);d||(d=f(c));var e;return e=d.cache[a]?d.cache[a].cloneNode():p.test(a)?(d.cache[a]=d.createElem(a)).cloneNode():d.createElem(a),!e.canHaveChildren||o.test(a)||e.tagUrn?e:d.frag.appendChild(e)}function h(a,c){if(a||(a=b),l)return a.createDocumentFragment();c=c||f(a);for(var e=c.frag.cloneNode(),g=0,h=d(),i=h.length;i>g;g++)e.createElement(h[g]);return e}function i(a,b){b.cache||(b.cache={},b.createElem=a.createElement,b.createFrag=a.createDocumentFragment,b.frag=b.createFrag()),a.createElement=function(c){return t.shivMethods?g(c,a,b):b.createElem(c)},a.createDocumentFragment=Function(\"h,f\",\"return function(){var n=f.cloneNode(),c=n.createElement;h.shivMethods&&(\"+d().join().replace(/[\\w\\-:]+/g,function(a){return b.createElem(a),b.frag.createElement(a),'c(\"'+a+'\")'})+\");return n}\")(t,b.frag)}function j(a){a||(a=b);var d=f(a);return!t.shivCSS||k||d.hasCSS||(d.hasCSS=!!c(a,\"article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}mark{background:#FF0;color:#000}template{display:none}\")),l||i(a,d),a}var k,l,m=\"3.7.3-pre\",n=a.html5||{},o=/^<|^(?:button|map|select|textarea|object|iframe|option|optgroup)$/i,p=/^(?:a|b|code|div|fieldset|h1|h2|h3|h4|h5|h6|i|label|li|ol|p|q|span|strong|style|table|tbody|td|th|tr|ul)$/i,q=\"_html5shiv\",r=0,s={};!function(){try{var a=b.createElement(\"a\");a.innerHTML=\"<xyz></xyz>\",k=\"hidden\"in a,l=1==a.childNodes.length||function(){b.createElement(\"a\");var a=b.createDocumentFragment();return\"undefined\"==typeof a.cloneNode||\"undefined\"==typeof a.createDocumentFragment||\"undefined\"==typeof a.createElement}()}catch(c){k=!0,l=!0}}();var t={elements:n.elements||\"abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time video\",version:m,shivCSS:n.shivCSS!==!1,supportsUnknownElements:l,shivMethods:n.shivMethods!==!1,type:\"default\",shivDocument:j,createElement:g,createDocumentFragment:h,addElements:e};a.html5=t,j(b),\"object\"==typeof module&&module.exports&&(module.exports=t)}(\"undefined\"!=typeof window?window:this,document);\n\\ No newline at end of file"}, {"filename": "master/_static/js/modernizr.min.js", "status": "removed", "additions": 0, "deletions": 4, "changes": 4, "file_content_changes": "@@ -1,4 +0,0 @@\n-/* Modernizr 2.6.2 (Custom Build) | MIT & BSD\n- * Build: http://modernizr.com/download/#-fontface-backgroundsize-borderimage-borderradius-boxshadow-flexbox-hsla-multiplebgs-opacity-rgba-textshadow-cssanimations-csscolumns-generatedcontent-cssgradients-cssreflections-csstransforms-csstransforms3d-csstransitions-applicationcache-canvas-canvastext-draganddrop-hashchange-history-audio-video-indexeddb-input-inputtypes-localstorage-postmessage-sessionstorage-websockets-websqldatabase-webworkers-geolocation-inlinesvg-smil-svg-svgclippaths-touch-webgl-shiv-mq-cssclasses-addtest-prefixed-teststyles-testprop-testallprops-hasevent-prefixes-domprefixes-load\n- */\n-;window.Modernizr=function(a,b,c){function D(a){j.cssText=a}function E(a,b){return D(n.join(a+\";\")+(b||\"\"))}function F(a,b){return typeof a===b}function G(a,b){return!!~(\"\"+a).indexOf(b)}function H(a,b){for(var d in a){var e=a[d];if(!G(e,\"-\")&&j[e]!==c)return b==\"pfx\"?e:!0}return!1}function I(a,b,d){for(var e in a){var f=b[a[e]];if(f!==c)return d===!1?a[e]:F(f,\"function\")?f.bind(d||b):f}return!1}function J(a,b,c){var d=a.charAt(0).toUpperCase()+a.slice(1),e=(a+\" \"+p.join(d+\" \")+d).split(\" \");return F(b,\"string\")||F(b,\"undefined\")?H(e,b):(e=(a+\" \"+q.join(d+\" \")+d).split(\" \"),I(e,b,c))}function K(){e.input=function(c){for(var d=0,e=c.length;d<e;d++)u[c[d]]=c[d]in k;return u.list&&(u.list=!!b.createElement(\"datalist\")&&!!a.HTMLDataListElement),u}(\"autocomplete autofocus list placeholder max min multiple pattern required step\".split(\" \")),e.inputtypes=function(a){for(var d=0,e,f,h,i=a.length;d<i;d++)k.setAttribute(\"type\",f=a[d]),e=k.type!==\"text\",e&&(k.value=l,k.style.cssText=\"position:absolute;visibility:hidden;\",/^range$/.test(f)&&k.style.WebkitAppearance!==c?(g.appendChild(k),h=b.defaultView,e=h.getComputedStyle&&h.getComputedStyle(k,null).WebkitAppearance!==\"textfield\"&&k.offsetHeight!==0,g.removeChild(k)):/^(search|tel)$/.test(f)||(/^(url|email)$/.test(f)?e=k.checkValidity&&k.checkValidity()===!1:e=k.value!=l)),t[a[d]]=!!e;return t}(\"search tel url email datetime date month week time datetime-local number range color\".split(\" \"))}var d=\"2.6.2\",e={},f=!0,g=b.documentElement,h=\"modernizr\",i=b.createElement(h),j=i.style,k=b.createElement(\"input\"),l=\":)\",m={}.toString,n=\" -webkit- -moz- -o- -ms- \".split(\" \"),o=\"Webkit Moz O ms\",p=o.split(\" \"),q=o.toLowerCase().split(\" \"),r={svg:\"http://www.w3.org/2000/svg\"},s={},t={},u={},v=[],w=v.slice,x,y=function(a,c,d,e){var f,i,j,k,l=b.createElement(\"div\"),m=b.body,n=m||b.createElement(\"body\");if(parseInt(d,10))while(d--)j=b.createElement(\"div\"),j.id=e?e[d]:h+(d+1),l.appendChild(j);return f=[\"&#173;\",'<style id=\"s',h,'\">',a,\"</style>\"].join(\"\"),l.id=h,(m?l:n).innerHTML+=f,n.appendChild(l),m||(n.style.background=\"\",n.style.overflow=\"hidden\",k=g.style.overflow,g.style.overflow=\"hidden\",g.appendChild(n)),i=c(l,a),m?l.parentNode.removeChild(l):(n.parentNode.removeChild(n),g.style.overflow=k),!!i},z=function(b){var c=a.matchMedia||a.msMatchMedia;if(c)return c(b).matches;var d;return y(\"@media \"+b+\" { #\"+h+\" { position: absolute; } }\",function(b){d=(a.getComputedStyle?getComputedStyle(b,null):b.currentStyle)[\"position\"]==\"absolute\"}),d},A=function(){function d(d,e){e=e||b.createElement(a[d]||\"div\"),d=\"on\"+d;var f=d in e;return f||(e.setAttribute||(e=b.createElement(\"div\")),e.setAttribute&&e.removeAttribute&&(e.setAttribute(d,\"\"),f=F(e[d],\"function\"),F(e[d],\"undefined\")||(e[d]=c),e.removeAttribute(d))),e=null,f}var a={select:\"input\",change:\"input\",submit:\"form\",reset:\"form\",error:\"img\",load:\"img\",abort:\"img\"};return d}(),B={}.hasOwnProperty,C;!F(B,\"undefined\")&&!F(B.call,\"undefined\")?C=function(a,b){return B.call(a,b)}:C=function(a,b){return b in a&&F(a.constructor.prototype[b],\"undefined\")},Function.prototype.bind||(Function.prototype.bind=function(b){var c=this;if(typeof c!=\"function\")throw new TypeError;var d=w.call(arguments,1),e=function(){if(this instanceof e){var a=function(){};a.prototype=c.prototype;var f=new a,g=c.apply(f,d.concat(w.call(arguments)));return Object(g)===g?g:f}return c.apply(b,d.concat(w.call(arguments)))};return e}),s.flexbox=function(){return J(\"flexWrap\")},s.canvas=function(){var a=b.createElement(\"canvas\");return!!a.getContext&&!!a.getContext(\"2d\")},s.canvastext=function(){return!!e.canvas&&!!F(b.createElement(\"canvas\").getContext(\"2d\").fillText,\"function\")},s.webgl=function(){return!!a.WebGLRenderingContext},s.touch=function(){var c;return\"ontouchstart\"in a||a.DocumentTouch&&b instanceof DocumentTouch?c=!0:y([\"@media (\",n.join(\"touch-enabled),(\"),h,\")\",\"{#modernizr{top:9px;position:absolute}}\"].join(\"\"),function(a){c=a.offsetTop===9}),c},s.geolocation=function(){return\"geolocation\"in navigator},s.postmessage=function(){return!!a.postMessage},s.websqldatabase=function(){return!!a.openDatabase},s.indexedDB=function(){return!!J(\"indexedDB\",a)},s.hashchange=function(){return A(\"hashchange\",a)&&(b.documentMode===c||b.documentMode>7)},s.history=function(){return!!a.history&&!!history.pushState},s.draganddrop=function(){var a=b.createElement(\"div\");return\"draggable\"in a||\"ondragstart\"in a&&\"ondrop\"in a},s.websockets=function(){return\"WebSocket\"in a||\"MozWebSocket\"in a},s.rgba=function(){return D(\"background-color:rgba(150,255,150,.5)\"),G(j.backgroundColor,\"rgba\")},s.hsla=function(){return D(\"background-color:hsla(120,40%,100%,.5)\"),G(j.backgroundColor,\"rgba\")||G(j.backgroundColor,\"hsla\")},s.multiplebgs=function(){return D(\"background:url(https://),url(https://),red url(https://)\"),/(url\\s*\\(.*?){3}/.test(j.background)},s.backgroundsize=function(){return J(\"backgroundSize\")},s.borderimage=function(){return J(\"borderImage\")},s.borderradius=function(){return J(\"borderRadius\")},s.boxshadow=function(){return J(\"boxShadow\")},s.textshadow=function(){return b.createElement(\"div\").style.textShadow===\"\"},s.opacity=function(){return E(\"opacity:.55\"),/^0.55$/.test(j.opacity)},s.cssanimations=function(){return J(\"animationName\")},s.csscolumns=function(){return J(\"columnCount\")},s.cssgradients=function(){var a=\"background-image:\",b=\"gradient(linear,left top,right bottom,from(#9f9),to(white));\",c=\"linear-gradient(left top,#9f9, white);\";return D((a+\"-webkit- \".split(\" \").join(b+a)+n.join(c+a)).slice(0,-a.length)),G(j.backgroundImage,\"gradient\")},s.cssreflections=function(){return J(\"boxReflect\")},s.csstransforms=function(){return!!J(\"transform\")},s.csstransforms3d=function(){var a=!!J(\"perspective\");return a&&\"webkitPerspective\"in g.style&&y(\"@media (transform-3d),(-webkit-transform-3d){#modernizr{left:9px;position:absolute;height:3px;}}\",function(b,c){a=b.offsetLeft===9&&b.offsetHeight===3}),a},s.csstransitions=function(){return J(\"transition\")},s.fontface=function(){var a;return y('@font-face {font-family:\"font\";src:url(\"https://\")}',function(c,d){var e=b.getElementById(\"smodernizr\"),f=e.sheet||e.styleSheet,g=f?f.cssRules&&f.cssRules[0]?f.cssRules[0].cssText:f.cssText||\"\":\"\";a=/src/i.test(g)&&g.indexOf(d.split(\" \")[0])===0}),a},s.generatedcontent=function(){var a;return y([\"#\",h,\"{font:0/0 a}#\",h,':after{content:\"',l,'\";visibility:hidden;font:3px/1 a}'].join(\"\"),function(b){a=b.offsetHeight>=3}),a},s.video=function(){var a=b.createElement(\"video\"),c=!1;try{if(c=!!a.canPlayType)c=new Boolean(c),c.ogg=a.canPlayType('video/ogg; codecs=\"theora\"').replace(/^no$/,\"\"),c.h264=a.canPlayType('video/mp4; codecs=\"avc1.42E01E\"').replace(/^no$/,\"\"),c.webm=a.canPlayType('video/webm; codecs=\"vp8, vorbis\"').replace(/^no$/,\"\")}catch(d){}return c},s.audio=function(){var a=b.createElement(\"audio\"),c=!1;try{if(c=!!a.canPlayType)c=new Boolean(c),c.ogg=a.canPlayType('audio/ogg; codecs=\"vorbis\"').replace(/^no$/,\"\"),c.mp3=a.canPlayType(\"audio/mpeg;\").replace(/^no$/,\"\"),c.wav=a.canPlayType('audio/wav; codecs=\"1\"').replace(/^no$/,\"\"),c.m4a=(a.canPlayType(\"audio/x-m4a;\")||a.canPlayType(\"audio/aac;\")).replace(/^no$/,\"\")}catch(d){}return c},s.localstorage=function(){try{return localStorage.setItem(h,h),localStorage.removeItem(h),!0}catch(a){return!1}},s.sessionstorage=function(){try{return sessionStorage.setItem(h,h),sessionStorage.removeItem(h),!0}catch(a){return!1}},s.webworkers=function(){return!!a.Worker},s.applicationcache=function(){return!!a.applicationCache},s.svg=function(){return!!b.createElementNS&&!!b.createElementNS(r.svg,\"svg\").createSVGRect},s.inlinesvg=function(){var a=b.createElement(\"div\");return a.innerHTML=\"<svg/>\",(a.firstChild&&a.firstChild.namespaceURI)==r.svg},s.smil=function(){return!!b.createElementNS&&/SVGAnimate/.test(m.call(b.createElementNS(r.svg,\"animate\")))},s.svgclippaths=function(){return!!b.createElementNS&&/SVGClipPath/.test(m.call(b.createElementNS(r.svg,\"clipPath\")))};for(var L in s)C(s,L)&&(x=L.toLowerCase(),e[x]=s[L](),v.push((e[x]?\"\":\"no-\")+x));return e.input||K(),e.addTest=function(a,b){if(typeof a==\"object\")for(var d in a)C(a,d)&&e.addTest(d,a[d]);else{a=a.toLowerCase();if(e[a]!==c)return e;b=typeof b==\"function\"?b():b,typeof f!=\"undefined\"&&f&&(g.className+=\" \"+(b?\"\":\"no-\")+a),e[a]=b}return e},D(\"\"),i=k=null,function(a,b){function k(a,b){var c=a.createElement(\"p\"),d=a.getElementsByTagName(\"head\")[0]||a.documentElement;return c.innerHTML=\"x<style>\"+b+\"</style>\",d.insertBefore(c.lastChild,d.firstChild)}function l(){var a=r.elements;return typeof a==\"string\"?a.split(\" \"):a}function m(a){var b=i[a[g]];return b||(b={},h++,a[g]=h,i[h]=b),b}function n(a,c,f){c||(c=b);if(j)return c.createElement(a);f||(f=m(c));var g;return f.cache[a]?g=f.cache[a].cloneNode():e.test(a)?g=(f.cache[a]=f.createElem(a)).cloneNode():g=f.createElem(a),g.canHaveChildren&&!d.test(a)?f.frag.appendChild(g):g}function o(a,c){a||(a=b);if(j)return a.createDocumentFragment();c=c||m(a);var d=c.frag.cloneNode(),e=0,f=l(),g=f.length;for(;e<g;e++)d.createElement(f[e]);return d}function p(a,b){b.cache||(b.cache={},b.createElem=a.createElement,b.createFrag=a.createDocumentFragment,b.frag=b.createFrag()),a.createElement=function(c){return r.shivMethods?n(c,a,b):b.createElem(c)},a.createDocumentFragment=Function(\"h,f\",\"return function(){var n=f.cloneNode(),c=n.createElement;h.shivMethods&&(\"+l().join().replace(/\\w+/g,function(a){return b.createElem(a),b.frag.createElement(a),'c(\"'+a+'\")'})+\");return n}\")(r,b.frag)}function q(a){a||(a=b);var c=m(a);return r.shivCSS&&!f&&!c.hasCSS&&(c.hasCSS=!!k(a,\"article,aside,figcaption,figure,footer,header,hgroup,nav,section{display:block}mark{background:#FF0;color:#000}\")),j||p(a,c),a}var c=a.html5||{},d=/^<|^(?:button|map|select|textarea|object|iframe|option|optgroup)$/i,e=/^(?:a|b|code|div|fieldset|h1|h2|h3|h4|h5|h6|i|label|li|ol|p|q|span|strong|style|table|tbody|td|th|tr|ul)$/i,f,g=\"_html5shiv\",h=0,i={},j;(function(){try{var a=b.createElement(\"a\");a.innerHTML=\"<xyz></xyz>\",f=\"hidden\"in a,j=a.childNodes.length==1||function(){b.createElement(\"a\");var a=b.createDocumentFragment();return typeof a.cloneNode==\"undefined\"||typeof a.createDocumentFragment==\"undefined\"||typeof a.createElement==\"undefined\"}()}catch(c){f=!0,j=!0}})();var r={elements:c.elements||\"abbr article aside audio bdi canvas data datalist details figcaption figure footer header hgroup mark meter nav output progress section summary time video\",shivCSS:c.shivCSS!==!1,supportsUnknownElements:j,shivMethods:c.shivMethods!==!1,type:\"default\",shivDocument:q,createElement:n,createDocumentFragment:o};a.html5=r,q(b)}(this,b),e._version=d,e._prefixes=n,e._domPrefixes=q,e._cssomPrefixes=p,e.mq=z,e.hasEvent=A,e.testProp=function(a){return H([a])},e.testAllProps=J,e.testStyles=y,e.prefixed=function(a,b,c){return b?J(a,b,c):J(a,\"pfx\")},g.className=g.className.replace(/(^|\\s)no-js(\\s|$)/,\"$1$2\")+(f?\" js \"+v.join(\" \"):\"\"),e}(this,this.document),function(a,b,c){function d(a){return\"[object Function]\"==o.call(a)}function e(a){return\"string\"==typeof a}function f(){}function g(a){return!a||\"loaded\"==a||\"complete\"==a||\"uninitialized\"==a}function h(){var a=p.shift();q=1,a?a.t?m(function(){(\"c\"==a.t?B.injectCss:B.injectJs)(a.s,0,a.a,a.x,a.e,1)},0):(a(),h()):q=0}function i(a,c,d,e,f,i,j){function k(b){if(!o&&g(l.readyState)&&(u.r=o=1,!q&&h(),l.onload=l.onreadystatechange=null,b)){\"img\"!=a&&m(function(){t.removeChild(l)},50);for(var d in y[c])y[c].hasOwnProperty(d)&&y[c][d].onload()}}var j=j||B.errorTimeout,l=b.createElement(a),o=0,r=0,u={t:d,s:c,e:f,a:i,x:j};1===y[c]&&(r=1,y[c]=[]),\"object\"==a?l.data=c:(l.src=c,l.type=a),l.width=l.height=\"0\",l.onerror=l.onload=l.onreadystatechange=function(){k.call(this,r)},p.splice(e,0,u),\"img\"!=a&&(r||2===y[c]?(t.insertBefore(l,s?null:n),m(k,j)):y[c].push(l))}function j(a,b,c,d,f){return q=0,b=b||\"j\",e(a)?i(\"c\"==b?v:u,a,b,this.i++,c,d,f):(p.splice(this.i++,0,a),1==p.length&&h()),this}function k(){var a=B;return a.loader={load:j,i:0},a}var l=b.documentElement,m=a.setTimeout,n=b.getElementsByTagName(\"script\")[0],o={}.toString,p=[],q=0,r=\"MozAppearance\"in l.style,s=r&&!!b.createRange().compareNode,t=s?l:n.parentNode,l=a.opera&&\"[object Opera]\"==o.call(a.opera),l=!!b.attachEvent&&!l,u=r?\"object\":l?\"script\":\"img\",v=l?\"script\":u,w=Array.isArray||function(a){return\"[object Array]\"==o.call(a)},x=[],y={},z={timeout:function(a,b){return b.length&&(a.timeout=b[0]),a}},A,B;B=function(a){function b(a){var a=a.split(\"!\"),b=x.length,c=a.pop(),d=a.length,c={url:c,origUrl:c,prefixes:a},e,f,g;for(f=0;f<d;f++)g=a[f].split(\"=\"),(e=z[g.shift()])&&(c=e(c,g));for(f=0;f<b;f++)c=x[f](c);return c}function g(a,e,f,g,h){var i=b(a),j=i.autoCallback;i.url.split(\".\").pop().split(\"?\").shift(),i.bypass||(e&&(e=d(e)?e:e[a]||e[g]||e[a.split(\"/\").pop().split(\"?\")[0]]),i.instead?i.instead(a,e,f,g,h):(y[i.url]?i.noexec=!0:y[i.url]=1,f.load(i.url,i.forceCSS||!i.forceJS&&\"css\"==i.url.split(\".\").pop().split(\"?\").shift()?\"c\":c,i.noexec,i.attrs,i.timeout),(d(e)||d(j))&&f.load(function(){k(),e&&e(i.origUrl,h,g),j&&j(i.origUrl,h,g),y[i.url]=2})))}function h(a,b){function c(a,c){if(a){if(e(a))c||(j=function(){var a=[].slice.call(arguments);k.apply(this,a),l()}),g(a,j,b,0,h);else if(Object(a)===a)for(n in m=function(){var b=0,c;for(c in a)a.hasOwnProperty(c)&&b++;return b}(),a)a.hasOwnProperty(n)&&(!c&&!--m&&(d(j)?j=function(){var a=[].slice.call(arguments);k.apply(this,a),l()}:j[n]=function(a){return function(){var b=[].slice.call(arguments);a&&a.apply(this,b),l()}}(k[n])),g(a[n],j,b,n,h))}else!c&&l()}var h=!!a.test,i=a.load||a.both,j=a.callback||f,k=j,l=a.complete||f,m,n;c(h?a.yep:a.nope,!!i),i&&c(i)}var i,j,l=this.yepnope.loader;if(e(a))g(a,0,l,0);else if(w(a))for(i=0;i<a.length;i++)j=a[i],e(j)?g(j,0,l,0):w(j)?B(j):Object(j)===j&&h(j,l);else Object(a)===a&&h(a,l)},B.addPrefix=function(a,b){z[a]=b},B.addFilter=function(a){x.push(a)},B.errorTimeout=1e4,null==b.readyState&&b.addEventListener&&(b.readyState=\"loading\",b.addEventListener(\"DOMContentLoaded\",A=function(){b.removeEventListener(\"DOMContentLoaded\",A,0),b.readyState=\"complete\"},0)),a.yepnope=k(),a.yepnope.executeStack=h,a.yepnope.injectJs=function(a,c,d,e,i,j){var k=b.createElement(\"script\"),l,o,e=e||B.errorTimeout;k.src=a;for(o in d)k.setAttribute(o,d[o]);c=j?h:c||f,k.onreadystatechange=k.onload=function(){!l&&g(k.readyState)&&(l=1,c(),k.onload=k.onreadystatechange=null)},m(function(){l||(l=1,c(1))},e),i?k.onload():n.parentNode.insertBefore(k,n)},a.yepnope.injectCss=function(a,c,d,e,g,i){var e=b.createElement(\"link\"),j,c=i?h:c||f;e.href=a,e.rel=\"stylesheet\",e.type=\"text/css\";for(j in d)e.setAttribute(j,d[j]);g||(n.parentNode.insertBefore(e,n),m(c,0))}}(this,document),Modernizr.load=function(){yepnope.apply(window,[].slice.call(arguments,0))};"}, {"filename": "master/_static/js/theme.js", "status": "removed", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -1 +0,0 @@\n-!function(n){var e={};function t(i){if(e[i])return e[i].exports;var o=e[i]={i:i,l:!1,exports:{}};return n[i].call(o.exports,o,o.exports,t),o.l=!0,o.exports}t.m=n,t.c=e,t.d=function(n,e,i){t.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:i})},t.r=function(n){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(n,\"__esModule\",{value:!0})},t.t=function(n,e){if(1&e&&(n=t(n)),8&e)return n;if(4&e&&\"object\"==typeof n&&n&&n.__esModule)return n;var i=Object.create(null);if(t.r(i),Object.defineProperty(i,\"default\",{enumerable:!0,value:n}),2&e&&\"string\"!=typeof n)for(var o in n)t.d(i,o,function(e){return n[e]}.bind(null,o));return i},t.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return t.d(e,\"a\",e),e},t.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},t.p=\"\",t(t.s=0)}([function(n,e,t){t(1),n.exports=t(3)},function(n,e,t){(function(){var e=\"undefined\"!=typeof window?window.jQuery:t(2);n.exports.ThemeNav={navBar:null,win:null,winScroll:!1,winResize:!1,linkScroll:!1,winPosition:0,winHeight:null,docHeight:null,isRunning:!1,enable:function(n){var t=this;void 0===n&&(n=!0),t.isRunning||(t.isRunning=!0,e((function(e){t.init(e),t.reset(),t.win.on(\"hashchange\",t.reset),n&&t.win.on(\"scroll\",(function(){t.linkScroll||t.winScroll||(t.winScroll=!0,requestAnimationFrame((function(){t.onScroll()})))})),t.win.on(\"resize\",(function(){t.winResize||(t.winResize=!0,requestAnimationFrame((function(){t.onResize()})))})),t.onResize()})))},enableSticky:function(){this.enable(!0)},init:function(n){n(document);var e=this;this.navBar=n(\"div.wy-side-scroll:first\"),this.win=n(window),n(document).on(\"click\",\"[data-toggle='wy-nav-top']\",(function(){n(\"[data-toggle='wy-nav-shift']\").toggleClass(\"shift\"),n(\"[data-toggle='rst-versions']\").toggleClass(\"shift\")})).on(\"click\",\".wy-menu-vertical .current ul li a\",(function(){var t=n(this);n(\"[data-toggle='wy-nav-shift']\").removeClass(\"shift\"),n(\"[data-toggle='rst-versions']\").toggleClass(\"shift\"),e.toggleCurrent(t),e.hashChange()})).on(\"click\",\"[data-toggle='rst-current-version']\",(function(){n(\"[data-toggle='rst-versions']\").toggleClass(\"shift-up\")})),n(\"table.docutils:not(.field-list,.footnote,.citation)\").wrap(\"<div class='wy-table-responsive'></div>\"),n(\"table.docutils.footnote\").wrap(\"<div class='wy-table-responsive footnote'></div>\"),n(\"table.docutils.citation\").wrap(\"<div class='wy-table-responsive citation'></div>\"),n(\".wy-menu-vertical ul\").not(\".simple\").siblings(\"a\").each((function(){var t=n(this);expand=n('<span class=\"toctree-expand\"></span>'),expand.on(\"click\",(function(n){return e.toggleCurrent(t),n.stopPropagation(),!1})),t.prepend(expand)}))},reset:function(){var n=encodeURI(window.location.hash)||\"#\";try{var e=$(\".wy-menu-vertical\"),t=e.find('[href=\"'+n+'\"]');if(0===t.length){var i=$('.document [id=\"'+n.substring(1)+'\"]').closest(\"div.section\");0===(t=e.find('[href=\"#'+i.attr(\"id\")+'\"]')).length&&(t=e.find('[href=\"#\"]'))}t.length>0&&($(\".wy-menu-vertical .current\").removeClass(\"current\"),t.addClass(\"current\"),t.closest(\"li.toctree-l1\").addClass(\"current\"),t.closest(\"li.toctree-l1\").parent().addClass(\"current\"),t.closest(\"li.toctree-l1\").addClass(\"current\"),t.closest(\"li.toctree-l2\").addClass(\"current\"),t.closest(\"li.toctree-l3\").addClass(\"current\"),t.closest(\"li.toctree-l4\").addClass(\"current\"),t.closest(\"li.toctree-l5\").addClass(\"current\"),t[0].scrollIntoView())}catch(n){console.log(\"Error expanding nav for anchor\",n)}},onScroll:function(){this.winScroll=!1;var n=this.win.scrollTop(),e=n+this.winHeight,t=this.navBar.scrollTop()+(n-this.winPosition);n<0||e>this.docHeight||(this.navBar.scrollTop(t),this.winPosition=n)},onResize:function(){this.winResize=!1,this.winHeight=this.win.height(),this.docHeight=$(document).height()},hashChange:function(){this.linkScroll=!0,this.win.one(\"hashchange\",(function(){this.linkScroll=!1}))},toggleCurrent:function(n){var e=n.closest(\"li\");e.siblings(\"li.current\").removeClass(\"current\"),e.siblings().find(\"li.current\").removeClass(\"current\"),e.find(\"> ul li.current\").removeClass(\"current\"),e.toggleClass(\"current\")}},\"undefined\"!=typeof window&&(window.SphinxRtdTheme={Navigation:n.exports.ThemeNav,StickyNav:n.exports.ThemeNav}),function(){for(var n=0,e=[\"ms\",\"moz\",\"webkit\",\"o\"],t=0;t<e.length&&!window.requestAnimationFrame;++t)window.requestAnimationFrame=window[e[t]+\"RequestAnimationFrame\"],window.cancelAnimationFrame=window[e[t]+\"CancelAnimationFrame\"]||window[e[t]+\"CancelRequestAnimationFrame\"];window.requestAnimationFrame||(window.requestAnimationFrame=function(e,t){var i=(new Date).getTime(),o=Math.max(0,16-(i-n)),r=window.setTimeout((function(){e(i+o)}),o);return n=i+o,r}),window.cancelAnimationFrame||(window.cancelAnimationFrame=function(n){clearTimeout(n)})}()}).call(window)},function(n,e){n.exports=jQuery},function(n,e,t){}]);\n\\ No newline at end of file"}, {"filename": "master/_static/language_data.js", "status": "removed", "additions": 0, "deletions": 297, "changes": 297, "file_content_changes": "@@ -1,297 +0,0 @@\n-/*\n- * language_data.js\n- * ~~~~~~~~~~~~~~~~\n- *\n- * This script contains the language-specific data used by searchtools.js,\n- * namely the list of stopwords, stemmer, scorer and splitter.\n- *\n- * :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n- * :license: BSD, see LICENSE for details.\n- *\n- */\n-\n-var stopwords = [\"a\",\"and\",\"are\",\"as\",\"at\",\"be\",\"but\",\"by\",\"for\",\"if\",\"in\",\"into\",\"is\",\"it\",\"near\",\"no\",\"not\",\"of\",\"on\",\"or\",\"such\",\"that\",\"the\",\"their\",\"then\",\"there\",\"these\",\"they\",\"this\",\"to\",\"was\",\"will\",\"with\"];\n-\n-\n-/* Non-minified version is copied as a separate JS file, is available */\n-\n-/**\n- * Porter Stemmer\n- */\n-var Stemmer = function() {\n-\n-  var step2list = {\n-    ational: 'ate',\n-    tional: 'tion',\n-    enci: 'ence',\n-    anci: 'ance',\n-    izer: 'ize',\n-    bli: 'ble',\n-    alli: 'al',\n-    entli: 'ent',\n-    eli: 'e',\n-    ousli: 'ous',\n-    ization: 'ize',\n-    ation: 'ate',\n-    ator: 'ate',\n-    alism: 'al',\n-    iveness: 'ive',\n-    fulness: 'ful',\n-    ousness: 'ous',\n-    aliti: 'al',\n-    iviti: 'ive',\n-    biliti: 'ble',\n-    logi: 'log'\n-  };\n-\n-  var step3list = {\n-    icate: 'ic',\n-    ative: '',\n-    alize: 'al',\n-    iciti: 'ic',\n-    ical: 'ic',\n-    ful: '',\n-    ness: ''\n-  };\n-\n-  var c = \"[^aeiou]\";          // consonant\n-  var v = \"[aeiouy]\";          // vowel\n-  var C = c + \"[^aeiouy]*\";    // consonant sequence\n-  var V = v + \"[aeiou]*\";      // vowel sequence\n-\n-  var mgr0 = \"^(\" + C + \")?\" + V + C;                      // [C]VC... is m>0\n-  var meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\";    // [C]VC[V] is m=1\n-  var mgr1 = \"^(\" + C + \")?\" + V + C + V + C;              // [C]VCVC... is m>1\n-  var s_v   = \"^(\" + C + \")?\" + v;                         // vowel in stem\n-\n-  this.stemWord = function (w) {\n-    var stem;\n-    var suffix;\n-    var firstch;\n-    var origword = w;\n-\n-    if (w.length < 3)\n-      return w;\n-\n-    var re;\n-    var re2;\n-    var re3;\n-    var re4;\n-\n-    firstch = w.substr(0,1);\n-    if (firstch == \"y\")\n-      w = firstch.toUpperCase() + w.substr(1);\n-\n-    // Step 1a\n-    re = /^(.+?)(ss|i)es$/;\n-    re2 = /^(.+?)([^s])s$/;\n-\n-    if (re.test(w))\n-      w = w.replace(re,\"$1$2\");\n-    else if (re2.test(w))\n-      w = w.replace(re2,\"$1$2\");\n-\n-    // Step 1b\n-    re = /^(.+?)eed$/;\n-    re2 = /^(.+?)(ed|ing)$/;\n-    if (re.test(w)) {\n-      var fp = re.exec(w);\n-      re = new RegExp(mgr0);\n-      if (re.test(fp[1])) {\n-        re = /.$/;\n-        w = w.replace(re,\"\");\n-      }\n-    }\n-    else if (re2.test(w)) {\n-      var fp = re2.exec(w);\n-      stem = fp[1];\n-      re2 = new RegExp(s_v);\n-      if (re2.test(stem)) {\n-        w = stem;\n-        re2 = /(at|bl|iz)$/;\n-        re3 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n-        re4 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n-        if (re2.test(w))\n-          w = w + \"e\";\n-        else if (re3.test(w)) {\n-          re = /.$/;\n-          w = w.replace(re,\"\");\n-        }\n-        else if (re4.test(w))\n-          w = w + \"e\";\n-      }\n-    }\n-\n-    // Step 1c\n-    re = /^(.+?)y$/;\n-    if (re.test(w)) {\n-      var fp = re.exec(w);\n-      stem = fp[1];\n-      re = new RegExp(s_v);\n-      if (re.test(stem))\n-        w = stem + \"i\";\n-    }\n-\n-    // Step 2\n-    re = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n-    if (re.test(w)) {\n-      var fp = re.exec(w);\n-      stem = fp[1];\n-      suffix = fp[2];\n-      re = new RegExp(mgr0);\n-      if (re.test(stem))\n-        w = stem + step2list[suffix];\n-    }\n-\n-    // Step 3\n-    re = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n-    if (re.test(w)) {\n-      var fp = re.exec(w);\n-      stem = fp[1];\n-      suffix = fp[2];\n-      re = new RegExp(mgr0);\n-      if (re.test(stem))\n-        w = stem + step3list[suffix];\n-    }\n-\n-    // Step 4\n-    re = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n-    re2 = /^(.+?)(s|t)(ion)$/;\n-    if (re.test(w)) {\n-      var fp = re.exec(w);\n-      stem = fp[1];\n-      re = new RegExp(mgr1);\n-      if (re.test(stem))\n-        w = stem;\n-    }\n-    else if (re2.test(w)) {\n-      var fp = re2.exec(w);\n-      stem = fp[1] + fp[2];\n-      re2 = new RegExp(mgr1);\n-      if (re2.test(stem))\n-        w = stem;\n-    }\n-\n-    // Step 5\n-    re = /^(.+?)e$/;\n-    if (re.test(w)) {\n-      var fp = re.exec(w);\n-      stem = fp[1];\n-      re = new RegExp(mgr1);\n-      re2 = new RegExp(meq1);\n-      re3 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n-      if (re.test(stem) || (re2.test(stem) && !(re3.test(stem))))\n-        w = stem;\n-    }\n-    re = /ll$/;\n-    re2 = new RegExp(mgr1);\n-    if (re.test(w) && re2.test(w)) {\n-      re = /.$/;\n-      w = w.replace(re,\"\");\n-    }\n-\n-    // and turn initial Y back to y\n-    if (firstch == \"y\")\n-      w = firstch.toLowerCase() + w.substr(1);\n-    return w;\n-  }\n-}\n-\n-\n-\n-\n-var splitChars = (function() {\n-    var result = {};\n-    var singles = [96, 180, 187, 191, 215, 247, 749, 885, 903, 907, 909, 930, 1014, 1648,\n-         1748, 1809, 2416, 2473, 2481, 2526, 2601, 2609, 2612, 2615, 2653, 2702,\n-         2706, 2729, 2737, 2740, 2857, 2865, 2868, 2910, 2928, 2948, 2961, 2971,\n-         2973, 3085, 3089, 3113, 3124, 3213, 3217, 3241, 3252, 3295, 3341, 3345,\n-         3369, 3506, 3516, 3633, 3715, 3721, 3736, 3744, 3748, 3750, 3756, 3761,\n-         3781, 3912, 4239, 4347, 4681, 4695, 4697, 4745, 4785, 4799, 4801, 4823,\n-         4881, 5760, 5901, 5997, 6313, 7405, 8024, 8026, 8028, 8030, 8117, 8125,\n-         8133, 8181, 8468, 8485, 8487, 8489, 8494, 8527, 11311, 11359, 11687, 11695,\n-         11703, 11711, 11719, 11727, 11735, 12448, 12539, 43010, 43014, 43019, 43587,\n-         43696, 43713, 64286, 64297, 64311, 64317, 64319, 64322, 64325, 65141];\n-    var i, j, start, end;\n-    for (i = 0; i < singles.length; i++) {\n-        result[singles[i]] = true;\n-    }\n-    var ranges = [[0, 47], [58, 64], [91, 94], [123, 169], [171, 177], [182, 184], [706, 709],\n-         [722, 735], [741, 747], [751, 879], [888, 889], [894, 901], [1154, 1161],\n-         [1318, 1328], [1367, 1368], [1370, 1376], [1416, 1487], [1515, 1519], [1523, 1568],\n-         [1611, 1631], [1642, 1645], [1750, 1764], [1767, 1773], [1789, 1790], [1792, 1807],\n-         [1840, 1868], [1958, 1968], [1970, 1983], [2027, 2035], [2038, 2041], [2043, 2047],\n-         [2070, 2073], [2075, 2083], [2085, 2087], [2089, 2307], [2362, 2364], [2366, 2383],\n-         [2385, 2391], [2402, 2405], [2419, 2424], [2432, 2436], [2445, 2446], [2449, 2450],\n-         [2483, 2485], [2490, 2492], [2494, 2509], [2511, 2523], [2530, 2533], [2546, 2547],\n-         [2554, 2564], [2571, 2574], [2577, 2578], [2618, 2648], [2655, 2661], [2672, 2673],\n-         [2677, 2692], [2746, 2748], [2750, 2767], [2769, 2783], [2786, 2789], [2800, 2820],\n-         [2829, 2830], [2833, 2834], [2874, 2876], [2878, 2907], [2914, 2917], [2930, 2946],\n-         [2955, 2957], [2966, 2968], [2976, 2978], [2981, 2983], [2987, 2989], [3002, 3023],\n-         [3025, 3045], [3059, 3076], [3130, 3132], [3134, 3159], [3162, 3167], [3170, 3173],\n-         [3184, 3191], [3199, 3204], [3258, 3260], [3262, 3293], [3298, 3301], [3312, 3332],\n-         [3386, 3388], [3390, 3423], [3426, 3429], [3446, 3449], [3456, 3460], [3479, 3481],\n-         [3518, 3519], [3527, 3584], [3636, 3647], [3655, 3663], [3674, 3712], [3717, 3718],\n-         [3723, 3724], [3726, 3731], [3752, 3753], [3764, 3772], [3774, 3775], [3783, 3791],\n-         [3802, 3803], [3806, 3839], [3841, 3871], [3892, 3903], [3949, 3975], [3980, 4095],\n-         [4139, 4158], [4170, 4175], [4182, 4185], [4190, 4192], [4194, 4196], [4199, 4205],\n-         [4209, 4212], [4226, 4237], [4250, 4255], [4294, 4303], [4349, 4351], [4686, 4687],\n-         [4702, 4703], [4750, 4751], [4790, 4791], [4806, 4807], [4886, 4887], [4955, 4968],\n-         [4989, 4991], [5008, 5023], [5109, 5120], [5741, 5742], [5787, 5791], [5867, 5869],\n-         [5873, 5887], [5906, 5919], [5938, 5951], [5970, 5983], [6001, 6015], [6068, 6102],\n-         [6104, 6107], [6109, 6111], [6122, 6127], [6138, 6159], [6170, 6175], [6264, 6271],\n-         [6315, 6319], [6390, 6399], [6429, 6469], [6510, 6511], [6517, 6527], [6572, 6592],\n-         [6600, 6607], [6619, 6655], [6679, 6687], [6741, 6783], [6794, 6799], [6810, 6822],\n-         [6824, 6916], [6964, 6980], [6988, 6991], [7002, 7042], [7073, 7085], [7098, 7167],\n-         [7204, 7231], [7242, 7244], [7294, 7400], [7410, 7423], [7616, 7679], [7958, 7959],\n-         [7966, 7967], [8006, 8007], [8014, 8015], [8062, 8063], [8127, 8129], [8141, 8143],\n-         [8148, 8149], [8156, 8159], [8173, 8177], [8189, 8303], [8306, 8307], [8314, 8318],\n-         [8330, 8335], [8341, 8449], [8451, 8454], [8456, 8457], [8470, 8472], [8478, 8483],\n-         [8506, 8507], [8512, 8516], [8522, 8525], [8586, 9311], [9372, 9449], [9472, 10101],\n-         [10132, 11263], [11493, 11498], [11503, 11516], [11518, 11519], [11558, 11567],\n-         [11622, 11630], [11632, 11647], [11671, 11679], [11743, 11822], [11824, 12292],\n-         [12296, 12320], [12330, 12336], [12342, 12343], [12349, 12352], [12439, 12444],\n-         [12544, 12548], [12590, 12592], [12687, 12689], [12694, 12703], [12728, 12783],\n-         [12800, 12831], [12842, 12880], [12896, 12927], [12938, 12976], [12992, 13311],\n-         [19894, 19967], [40908, 40959], [42125, 42191], [42238, 42239], [42509, 42511],\n-         [42540, 42559], [42592, 42593], [42607, 42622], [42648, 42655], [42736, 42774],\n-         [42784, 42785], [42889, 42890], [42893, 43002], [43043, 43055], [43062, 43071],\n-         [43124, 43137], [43188, 43215], [43226, 43249], [43256, 43258], [43260, 43263],\n-         [43302, 43311], [43335, 43359], [43389, 43395], [43443, 43470], [43482, 43519],\n-         [43561, 43583], [43596, 43599], [43610, 43615], [43639, 43641], [43643, 43647],\n-         [43698, 43700], [43703, 43704], [43710, 43711], [43715, 43738], [43742, 43967],\n-         [44003, 44015], [44026, 44031], [55204, 55215], [55239, 55242], [55292, 55295],\n-         [57344, 63743], [64046, 64047], [64110, 64111], [64218, 64255], [64263, 64274],\n-         [64280, 64284], [64434, 64466], [64830, 64847], [64912, 64913], [64968, 65007],\n-         [65020, 65135], [65277, 65295], [65306, 65312], [65339, 65344], [65371, 65381],\n-         [65471, 65473], [65480, 65481], [65488, 65489], [65496, 65497]];\n-    for (i = 0; i < ranges.length; i++) {\n-        start = ranges[i][0];\n-        end = ranges[i][1];\n-        for (j = start; j <= end; j++) {\n-            result[j] = true;\n-        }\n-    }\n-    return result;\n-})();\n-\n-function splitQuery(query) {\n-    var result = [];\n-    var start = -1;\n-    for (var i = 0; i < query.length; i++) {\n-        if (splitChars[query.charCodeAt(i)]) {\n-            if (start !== -1) {\n-                result.push(query.slice(start, i));\n-                start = -1;\n-            }\n-        } else if (start === -1) {\n-            start = i;\n-        }\n-    }\n-    if (start !== -1) {\n-        result.push(query.slice(start));\n-    }\n-    return result;\n-}\n-\n-"}, {"filename": "master/_static/minus.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/no_image.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/plus.png", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/_static/pygments.css", "status": "removed", "additions": 0, "deletions": 74, "changes": 74, "file_content_changes": "@@ -1,74 +0,0 @@\n-pre { line-height: 125%; }\n-td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n-span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n-td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n-span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n-.highlight .hll { background-color: #ffffcc }\n-.highlight { background: #eeffcc; }\n-.highlight .c { color: #408090; font-style: italic } /* Comment */\n-.highlight .err { border: 1px solid #FF0000 } /* Error */\n-.highlight .k { color: #007020; font-weight: bold } /* Keyword */\n-.highlight .o { color: #666666 } /* Operator */\n-.highlight .ch { color: #408090; font-style: italic } /* Comment.Hashbang */\n-.highlight .cm { color: #408090; font-style: italic } /* Comment.Multiline */\n-.highlight .cp { color: #007020 } /* Comment.Preproc */\n-.highlight .cpf { color: #408090; font-style: italic } /* Comment.PreprocFile */\n-.highlight .c1 { color: #408090; font-style: italic } /* Comment.Single */\n-.highlight .cs { color: #408090; background-color: #fff0f0 } /* Comment.Special */\n-.highlight .gd { color: #A00000 } /* Generic.Deleted */\n-.highlight .ge { font-style: italic } /* Generic.Emph */\n-.highlight .gr { color: #FF0000 } /* Generic.Error */\n-.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n-.highlight .gi { color: #00A000 } /* Generic.Inserted */\n-.highlight .go { color: #333333 } /* Generic.Output */\n-.highlight .gp { color: #c65d09; font-weight: bold } /* Generic.Prompt */\n-.highlight .gs { font-weight: bold } /* Generic.Strong */\n-.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n-.highlight .gt { color: #0044DD } /* Generic.Traceback */\n-.highlight .kc { color: #007020; font-weight: bold } /* Keyword.Constant */\n-.highlight .kd { color: #007020; font-weight: bold } /* Keyword.Declaration */\n-.highlight .kn { color: #007020; font-weight: bold } /* Keyword.Namespace */\n-.highlight .kp { color: #007020 } /* Keyword.Pseudo */\n-.highlight .kr { color: #007020; font-weight: bold } /* Keyword.Reserved */\n-.highlight .kt { color: #902000 } /* Keyword.Type */\n-.highlight .m { color: #208050 } /* Literal.Number */\n-.highlight .s { color: #4070a0 } /* Literal.String */\n-.highlight .na { color: #4070a0 } /* Name.Attribute */\n-.highlight .nb { color: #007020 } /* Name.Builtin */\n-.highlight .nc { color: #0e84b5; font-weight: bold } /* Name.Class */\n-.highlight .no { color: #60add5 } /* Name.Constant */\n-.highlight .nd { color: #555555; font-weight: bold } /* Name.Decorator */\n-.highlight .ni { color: #d55537; font-weight: bold } /* Name.Entity */\n-.highlight .ne { color: #007020 } /* Name.Exception */\n-.highlight .nf { color: #06287e } /* Name.Function */\n-.highlight .nl { color: #002070; font-weight: bold } /* Name.Label */\n-.highlight .nn { color: #0e84b5; font-weight: bold } /* Name.Namespace */\n-.highlight .nt { color: #062873; font-weight: bold } /* Name.Tag */\n-.highlight .nv { color: #bb60d5 } /* Name.Variable */\n-.highlight .ow { color: #007020; font-weight: bold } /* Operator.Word */\n-.highlight .w { color: #bbbbbb } /* Text.Whitespace */\n-.highlight .mb { color: #208050 } /* Literal.Number.Bin */\n-.highlight .mf { color: #208050 } /* Literal.Number.Float */\n-.highlight .mh { color: #208050 } /* Literal.Number.Hex */\n-.highlight .mi { color: #208050 } /* Literal.Number.Integer */\n-.highlight .mo { color: #208050 } /* Literal.Number.Oct */\n-.highlight .sa { color: #4070a0 } /* Literal.String.Affix */\n-.highlight .sb { color: #4070a0 } /* Literal.String.Backtick */\n-.highlight .sc { color: #4070a0 } /* Literal.String.Char */\n-.highlight .dl { color: #4070a0 } /* Literal.String.Delimiter */\n-.highlight .sd { color: #4070a0; font-style: italic } /* Literal.String.Doc */\n-.highlight .s2 { color: #4070a0 } /* Literal.String.Double */\n-.highlight .se { color: #4070a0; font-weight: bold } /* Literal.String.Escape */\n-.highlight .sh { color: #4070a0 } /* Literal.String.Heredoc */\n-.highlight .si { color: #70a0d0; font-style: italic } /* Literal.String.Interpol */\n-.highlight .sx { color: #c65d09 } /* Literal.String.Other */\n-.highlight .sr { color: #235388 } /* Literal.String.Regex */\n-.highlight .s1 { color: #4070a0 } /* Literal.String.Single */\n-.highlight .ss { color: #517918 } /* Literal.String.Symbol */\n-.highlight .bp { color: #007020 } /* Name.Builtin.Pseudo */\n-.highlight .fm { color: #06287e } /* Name.Function.Magic */\n-.highlight .vc { color: #bb60d5 } /* Name.Variable.Class */\n-.highlight .vg { color: #bb60d5 } /* Name.Variable.Global */\n-.highlight .vi { color: #bb60d5 } /* Name.Variable.Instance */\n-.highlight .vm { color: #bb60d5 } /* Name.Variable.Magic */\n-.highlight .il { color: #208050 } /* Literal.Number.Integer.Long */\n\\ No newline at end of file"}, {"filename": "master/_static/searchtools.js", "status": "removed", "additions": 0, "deletions": 516, "changes": 516, "file_content_changes": "@@ -1,516 +0,0 @@\n-/*\n- * searchtools.js\n- * ~~~~~~~~~~~~~~~~\n- *\n- * Sphinx JavaScript utilities for the full-text search.\n- *\n- * :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n- * :license: BSD, see LICENSE for details.\n- *\n- */\n-\n-if (!Scorer) {\n-  /**\n-   * Simple result scoring code.\n-   */\n-  var Scorer = {\n-    // Implement the following function to further tweak the score for each result\n-    // The function takes a result array [filename, title, anchor, descr, score]\n-    // and returns the new score.\n-    /*\n-    score: function(result) {\n-      return result[4];\n-    },\n-    */\n-\n-    // query matches the full name of an object\n-    objNameMatch: 11,\n-    // or matches in the last dotted part of the object name\n-    objPartialMatch: 6,\n-    // Additive scores depending on the priority of the object\n-    objPrio: {0:  15,   // used to be importantResults\n-              1:  5,   // used to be objectResults\n-              2: -5},  // used to be unimportantResults\n-    //  Used when the priority is not in the mapping.\n-    objPrioDefault: 0,\n-\n-    // query found in title\n-    title: 15,\n-    partialTitle: 7,\n-    // query found in terms\n-    term: 5,\n-    partialTerm: 2\n-  };\n-}\n-\n-if (!splitQuery) {\n-  function splitQuery(query) {\n-    return query.split(/\\s+/);\n-  }\n-}\n-\n-/**\n- * Search Module\n- */\n-var Search = {\n-\n-  _index : null,\n-  _queued_query : null,\n-  _pulse_status : -1,\n-\n-  htmlToText : function(htmlString) {\n-      var virtualDocument = document.implementation.createHTMLDocument('virtual');\n-      var htmlElement = $(htmlString, virtualDocument);\n-      htmlElement.find('.headerlink').remove();\n-      docContent = htmlElement.find('[role=main]')[0];\n-      if(docContent === undefined) {\n-          console.warn(\"Content block not found. Sphinx search tries to obtain it \" +\n-                       \"via '[role=main]'. Could you check your theme or template.\");\n-          return \"\";\n-      }\n-      return docContent.textContent || docContent.innerText;\n-  },\n-\n-  init : function() {\n-      var params = $.getQueryParameters();\n-      if (params.q) {\n-          var query = params.q[0];\n-          $('input[name=\"q\"]')[0].value = query;\n-          this.performSearch(query);\n-      }\n-  },\n-\n-  loadIndex : function(url) {\n-    $.ajax({type: \"GET\", url: url, data: null,\n-            dataType: \"script\", cache: true,\n-            complete: function(jqxhr, textstatus) {\n-              if (textstatus != \"success\") {\n-                document.getElementById(\"searchindexloader\").src = url;\n-              }\n-            }});\n-  },\n-\n-  setIndex : function(index) {\n-    var q;\n-    this._index = index;\n-    if ((q = this._queued_query) !== null) {\n-      this._queued_query = null;\n-      Search.query(q);\n-    }\n-  },\n-\n-  hasIndex : function() {\n-      return this._index !== null;\n-  },\n-\n-  deferQuery : function(query) {\n-      this._queued_query = query;\n-  },\n-\n-  stopPulse : function() {\n-      this._pulse_status = 0;\n-  },\n-\n-  startPulse : function() {\n-    if (this._pulse_status >= 0)\n-        return;\n-    function pulse() {\n-      var i;\n-      Search._pulse_status = (Search._pulse_status + 1) % 4;\n-      var dotString = '';\n-      for (i = 0; i < Search._pulse_status; i++)\n-        dotString += '.';\n-      Search.dots.text(dotString);\n-      if (Search._pulse_status > -1)\n-        window.setTimeout(pulse, 500);\n-    }\n-    pulse();\n-  },\n-\n-  /**\n-   * perform a search for something (or wait until index is loaded)\n-   */\n-  performSearch : function(query) {\n-    // create the required interface elements\n-    this.out = $('#search-results');\n-    this.title = $('<h2>' + _('Searching') + '</h2>').appendTo(this.out);\n-    this.dots = $('<span></span>').appendTo(this.title);\n-    this.status = $('<p class=\"search-summary\">&nbsp;</p>').appendTo(this.out);\n-    this.output = $('<ul class=\"search\"/>').appendTo(this.out);\n-\n-    $('#search-progress').text(_('Preparing search...'));\n-    this.startPulse();\n-\n-    // index already loaded, the browser was quick!\n-    if (this.hasIndex())\n-      this.query(query);\n-    else\n-      this.deferQuery(query);\n-  },\n-\n-  /**\n-   * execute search (requires search index to be loaded)\n-   */\n-  query : function(query) {\n-    var i;\n-\n-    // stem the searchterms and add them to the correct list\n-    var stemmer = new Stemmer();\n-    var searchterms = [];\n-    var excluded = [];\n-    var hlterms = [];\n-    var tmp = splitQuery(query);\n-    var objectterms = [];\n-    for (i = 0; i < tmp.length; i++) {\n-      if (tmp[i] !== \"\") {\n-          objectterms.push(tmp[i].toLowerCase());\n-      }\n-\n-      if ($u.indexOf(stopwords, tmp[i].toLowerCase()) != -1 || tmp[i] === \"\") {\n-        // skip this \"word\"\n-        continue;\n-      }\n-      // stem the word\n-      var word = stemmer.stemWord(tmp[i].toLowerCase());\n-      // prevent stemmer from cutting word smaller than two chars\n-      if(word.length < 3 && tmp[i].length >= 3) {\n-        word = tmp[i];\n-      }\n-      var toAppend;\n-      // select the correct list\n-      if (word[0] == '-') {\n-        toAppend = excluded;\n-        word = word.substr(1);\n-      }\n-      else {\n-        toAppend = searchterms;\n-        hlterms.push(tmp[i].toLowerCase());\n-      }\n-      // only add if not already in the list\n-      if (!$u.contains(toAppend, word))\n-        toAppend.push(word);\n-    }\n-    var highlightstring = '?highlight=' + $.urlencode(hlterms.join(\" \"));\n-\n-    // console.debug('SEARCH: searching for:');\n-    // console.info('required: ', searchterms);\n-    // console.info('excluded: ', excluded);\n-\n-    // prepare search\n-    var terms = this._index.terms;\n-    var titleterms = this._index.titleterms;\n-\n-    // array of [filename, title, anchor, descr, score]\n-    var results = [];\n-    $('#search-progress').empty();\n-\n-    // lookup as object\n-    for (i = 0; i < objectterms.length; i++) {\n-      var others = [].concat(objectterms.slice(0, i),\n-                             objectterms.slice(i+1, objectterms.length));\n-      results = results.concat(this.performObjectSearch(objectterms[i], others));\n-    }\n-\n-    // lookup as search terms in fulltext\n-    results = results.concat(this.performTermsSearch(searchterms, excluded, terms, titleterms));\n-\n-    // let the scorer override scores with a custom scoring function\n-    if (Scorer.score) {\n-      for (i = 0; i < results.length; i++)\n-        results[i][4] = Scorer.score(results[i]);\n-    }\n-\n-    // now sort the results by score (in opposite order of appearance, since the\n-    // display function below uses pop() to retrieve items) and then\n-    // alphabetically\n-    results.sort(function(a, b) {\n-      var left = a[4];\n-      var right = b[4];\n-      if (left > right) {\n-        return 1;\n-      } else if (left < right) {\n-        return -1;\n-      } else {\n-        // same score: sort alphabetically\n-        left = a[1].toLowerCase();\n-        right = b[1].toLowerCase();\n-        return (left > right) ? -1 : ((left < right) ? 1 : 0);\n-      }\n-    });\n-\n-    // for debugging\n-    //Search.lastresults = results.slice();  // a copy\n-    //console.info('search results:', Search.lastresults);\n-\n-    // print the results\n-    var resultCount = results.length;\n-    function displayNextItem() {\n-      // results left, load the summary and display it\n-      if (results.length) {\n-        var item = results.pop();\n-        var listItem = $('<li></li>');\n-        var requestUrl = \"\";\n-        var linkUrl = \"\";\n-        if (DOCUMENTATION_OPTIONS.BUILDER === 'dirhtml') {\n-          // dirhtml builder\n-          var dirname = item[0] + '/';\n-          if (dirname.match(/\\/index\\/$/)) {\n-            dirname = dirname.substring(0, dirname.length-6);\n-          } else if (dirname == 'index/') {\n-            dirname = '';\n-          }\n-          requestUrl = DOCUMENTATION_OPTIONS.URL_ROOT + dirname;\n-          linkUrl = requestUrl;\n-\n-        } else {\n-          // normal html builders\n-          requestUrl = DOCUMENTATION_OPTIONS.URL_ROOT + item[0] + DOCUMENTATION_OPTIONS.FILE_SUFFIX;\n-          linkUrl = item[0] + DOCUMENTATION_OPTIONS.LINK_SUFFIX;\n-        }\n-        listItem.append($('<a/>').attr('href',\n-            linkUrl +\n-            highlightstring + item[2]).html(item[1]));\n-        if (item[3]) {\n-          listItem.append($('<span> (' + item[3] + ')</span>'));\n-          Search.output.append(listItem);\n-          setTimeout(function() {\n-            displayNextItem();\n-          }, 5);\n-        } else {\n-          $.ajax({url: requestUrl,\n-                  dataType: \"text\",\n-                  complete: function(jqxhr, textstatus) {\n-                    var data = jqxhr.responseText;\n-                    if (data !== '' && data !== undefined) {\n-                      listItem.append(Search.makeSearchSummary(data, searchterms, hlterms));\n-                    }\n-                    Search.output.append(listItem);\n-                    setTimeout(function() {\n-                      displayNextItem();\n-                    }, 5);\n-                  }});\n-        }\n-      }\n-      // search finished, update title and status message\n-      else {\n-        Search.stopPulse();\n-        Search.title.text(_('Search Results'));\n-        if (!resultCount)\n-          Search.status.text(_('Your search did not match any documents. Please make sure that all words are spelled correctly and that you\\'ve selected enough categories.'));\n-        else\n-            Search.status.text(_('Search finished, found %s page(s) matching the search query.').replace('%s', resultCount));\n-        Search.status.fadeIn(500);\n-      }\n-    }\n-    displayNextItem();\n-  },\n-\n-  /**\n-   * search for object names\n-   */\n-  performObjectSearch : function(object, otherterms) {\n-    var filenames = this._index.filenames;\n-    var docnames = this._index.docnames;\n-    var objects = this._index.objects;\n-    var objnames = this._index.objnames;\n-    var titles = this._index.titles;\n-\n-    var i;\n-    var results = [];\n-\n-    for (var prefix in objects) {\n-      for (var name in objects[prefix]) {\n-        var fullname = (prefix ? prefix + '.' : '') + name;\n-        var fullnameLower = fullname.toLowerCase()\n-        if (fullnameLower.indexOf(object) > -1) {\n-          var score = 0;\n-          var parts = fullnameLower.split('.');\n-          // check for different match types: exact matches of full name or\n-          // \"last name\" (i.e. last dotted part)\n-          if (fullnameLower == object || parts[parts.length - 1] == object) {\n-            score += Scorer.objNameMatch;\n-          // matches in last name\n-          } else if (parts[parts.length - 1].indexOf(object) > -1) {\n-            score += Scorer.objPartialMatch;\n-          }\n-          var match = objects[prefix][name];\n-          var objname = objnames[match[1]][2];\n-          var title = titles[match[0]];\n-          // If more than one term searched for, we require other words to be\n-          // found in the name/title/description\n-          if (otherterms.length > 0) {\n-            var haystack = (prefix + ' ' + name + ' ' +\n-                            objname + ' ' + title).toLowerCase();\n-            var allfound = true;\n-            for (i = 0; i < otherterms.length; i++) {\n-              if (haystack.indexOf(otherterms[i]) == -1) {\n-                allfound = false;\n-                break;\n-              }\n-            }\n-            if (!allfound) {\n-              continue;\n-            }\n-          }\n-          var descr = objname + _(', in ') + title;\n-\n-          var anchor = match[3];\n-          if (anchor === '')\n-            anchor = fullname;\n-          else if (anchor == '-')\n-            anchor = objnames[match[1]][1] + '-' + fullname;\n-          // add custom score for some objects according to scorer\n-          if (Scorer.objPrio.hasOwnProperty(match[2])) {\n-            score += Scorer.objPrio[match[2]];\n-          } else {\n-            score += Scorer.objPrioDefault;\n-          }\n-          results.push([docnames[match[0]], fullname, '#'+anchor, descr, score, filenames[match[0]]]);\n-        }\n-      }\n-    }\n-\n-    return results;\n-  },\n-\n-  /**\n-   * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions\n-   */\n-  escapeRegExp : function(string) {\n-    return string.replace(/[.*+\\-?^${}()|[\\]\\\\]/g, '\\\\$&'); // $& means the whole matched string\n-  },\n-\n-  /**\n-   * search for full-text terms in the index\n-   */\n-  performTermsSearch : function(searchterms, excluded, terms, titleterms) {\n-    var docnames = this._index.docnames;\n-    var filenames = this._index.filenames;\n-    var titles = this._index.titles;\n-\n-    var i, j, file;\n-    var fileMap = {};\n-    var scoreMap = {};\n-    var results = [];\n-\n-    // perform the search on the required terms\n-    for (i = 0; i < searchterms.length; i++) {\n-      var word = searchterms[i];\n-      var files = [];\n-      var _o = [\n-        {files: terms[word], score: Scorer.term},\n-        {files: titleterms[word], score: Scorer.title}\n-      ];\n-      // add support for partial matches\n-      if (word.length > 2) {\n-        var word_regex = this.escapeRegExp(word);\n-        for (var w in terms) {\n-          if (w.match(word_regex) && !terms[word]) {\n-            _o.push({files: terms[w], score: Scorer.partialTerm})\n-          }\n-        }\n-        for (var w in titleterms) {\n-          if (w.match(word_regex) && !titleterms[word]) {\n-              _o.push({files: titleterms[w], score: Scorer.partialTitle})\n-          }\n-        }\n-      }\n-\n-      // no match but word was a required one\n-      if ($u.every(_o, function(o){return o.files === undefined;})) {\n-        break;\n-      }\n-      // found search word in contents\n-      $u.each(_o, function(o) {\n-        var _files = o.files;\n-        if (_files === undefined)\n-          return\n-\n-        if (_files.length === undefined)\n-          _files = [_files];\n-        files = files.concat(_files);\n-\n-        // set score for the word in each file to Scorer.term\n-        for (j = 0; j < _files.length; j++) {\n-          file = _files[j];\n-          if (!(file in scoreMap))\n-            scoreMap[file] = {};\n-          scoreMap[file][word] = o.score;\n-        }\n-      });\n-\n-      // create the mapping\n-      for (j = 0; j < files.length; j++) {\n-        file = files[j];\n-        if (file in fileMap && fileMap[file].indexOf(word) === -1)\n-          fileMap[file].push(word);\n-        else\n-          fileMap[file] = [word];\n-      }\n-    }\n-\n-    // now check if the files don't contain excluded terms\n-    for (file in fileMap) {\n-      var valid = true;\n-\n-      // check if all requirements are matched\n-      var filteredTermCount = // as search terms with length < 3 are discarded: ignore\n-        searchterms.filter(function(term){return term.length > 2}).length\n-      if (\n-        fileMap[file].length != searchterms.length &&\n-        fileMap[file].length != filteredTermCount\n-      ) continue;\n-\n-      // ensure that none of the excluded terms is in the search result\n-      for (i = 0; i < excluded.length; i++) {\n-        if (terms[excluded[i]] == file ||\n-            titleterms[excluded[i]] == file ||\n-            $u.contains(terms[excluded[i]] || [], file) ||\n-            $u.contains(titleterms[excluded[i]] || [], file)) {\n-          valid = false;\n-          break;\n-        }\n-      }\n-\n-      // if we have still a valid result we can add it to the result list\n-      if (valid) {\n-        // select one (max) score for the file.\n-        // for better ranking, we should calculate ranking by using words statistics like basic tf-idf...\n-        var score = $u.max($u.map(fileMap[file], function(w){return scoreMap[file][w]}));\n-        results.push([docnames[file], titles[file], '', null, score, filenames[file]]);\n-      }\n-    }\n-    return results;\n-  },\n-\n-  /**\n-   * helper function to return a node containing the\n-   * search summary for a given text. keywords is a list\n-   * of stemmed words, hlwords is the list of normal, unstemmed\n-   * words. the first one is used to find the occurrence, the\n-   * latter for highlighting it.\n-   */\n-  makeSearchSummary : function(htmlText, keywords, hlwords) {\n-    var text = Search.htmlToText(htmlText);\n-    var textLower = text.toLowerCase();\n-    var start = 0;\n-    $.each(keywords, function() {\n-      var i = textLower.indexOf(this.toLowerCase());\n-      if (i > -1)\n-        start = i;\n-    });\n-    start = Math.max(start - 120, 0);\n-    var excerpt = ((start > 0) ? '...' : '') +\n-      $.trim(text.substr(start, 240)) +\n-      ((start + 240 - text.length) ? '...' : '');\n-    var rv = $('<p class=\"context\"></p>').text(excerpt);\n-    $.each(hlwords, function() {\n-      rv = rv.highlightText(this, 'highlighted');\n-    });\n-    return rv;\n-  }\n-};\n-\n-$(document).ready(function() {\n-  Search.init();\n-});"}, {"filename": "master/_static/underscore-1.13.1.js", "status": "removed", "additions": 0, "deletions": 2042, "changes": 2042, "file_content_changes": "@@ -1,2042 +0,0 @@\n-(function (global, factory) {\n-  typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :\n-  typeof define === 'function' && define.amd ? define('underscore', factory) :\n-  (global = typeof globalThis !== 'undefined' ? globalThis : global || self, (function () {\n-    var current = global._;\n-    var exports = global._ = factory();\n-    exports.noConflict = function () { global._ = current; return exports; };\n-  }()));\n-}(this, (function () {\n-  //     Underscore.js 1.13.1\n-  //     https://underscorejs.org\n-  //     (c) 2009-2021 Jeremy Ashkenas, Julian Gonggrijp, and DocumentCloud and Investigative Reporters & Editors\n-  //     Underscore may be freely distributed under the MIT license.\n-\n-  // Current version.\n-  var VERSION = '1.13.1';\n-\n-  // Establish the root object, `window` (`self`) in the browser, `global`\n-  // on the server, or `this` in some virtual machines. We use `self`\n-  // instead of `window` for `WebWorker` support.\n-  var root = typeof self == 'object' && self.self === self && self ||\n-            typeof global == 'object' && global.global === global && global ||\n-            Function('return this')() ||\n-            {};\n-\n-  // Save bytes in the minified (but not gzipped) version:\n-  var ArrayProto = Array.prototype, ObjProto = Object.prototype;\n-  var SymbolProto = typeof Symbol !== 'undefined' ? Symbol.prototype : null;\n-\n-  // Create quick reference variables for speed access to core prototypes.\n-  var push = ArrayProto.push,\n-      slice = ArrayProto.slice,\n-      toString = ObjProto.toString,\n-      hasOwnProperty = ObjProto.hasOwnProperty;\n-\n-  // Modern feature detection.\n-  var supportsArrayBuffer = typeof ArrayBuffer !== 'undefined',\n-      supportsDataView = typeof DataView !== 'undefined';\n-\n-  // All **ECMAScript 5+** native function implementations that we hope to use\n-  // are declared here.\n-  var nativeIsArray = Array.isArray,\n-      nativeKeys = Object.keys,\n-      nativeCreate = Object.create,\n-      nativeIsView = supportsArrayBuffer && ArrayBuffer.isView;\n-\n-  // Create references to these builtin functions because we override them.\n-  var _isNaN = isNaN,\n-      _isFinite = isFinite;\n-\n-  // Keys in IE < 9 that won't be iterated by `for key in ...` and thus missed.\n-  var hasEnumBug = !{toString: null}.propertyIsEnumerable('toString');\n-  var nonEnumerableProps = ['valueOf', 'isPrototypeOf', 'toString',\n-    'propertyIsEnumerable', 'hasOwnProperty', 'toLocaleString'];\n-\n-  // The largest integer that can be represented exactly.\n-  var MAX_ARRAY_INDEX = Math.pow(2, 53) - 1;\n-\n-  // Some functions take a variable number of arguments, or a few expected\n-  // arguments at the beginning and then a variable number of values to operate\n-  // on. This helper accumulates all remaining arguments past the function\u2019s\n-  // argument length (or an explicit `startIndex`), into an array that becomes\n-  // the last argument. Similar to ES6\u2019s \"rest parameter\".\n-  function restArguments(func, startIndex) {\n-    startIndex = startIndex == null ? func.length - 1 : +startIndex;\n-    return function() {\n-      var length = Math.max(arguments.length - startIndex, 0),\n-          rest = Array(length),\n-          index = 0;\n-      for (; index < length; index++) {\n-        rest[index] = arguments[index + startIndex];\n-      }\n-      switch (startIndex) {\n-        case 0: return func.call(this, rest);\n-        case 1: return func.call(this, arguments[0], rest);\n-        case 2: return func.call(this, arguments[0], arguments[1], rest);\n-      }\n-      var args = Array(startIndex + 1);\n-      for (index = 0; index < startIndex; index++) {\n-        args[index] = arguments[index];\n-      }\n-      args[startIndex] = rest;\n-      return func.apply(this, args);\n-    };\n-  }\n-\n-  // Is a given variable an object?\n-  function isObject(obj) {\n-    var type = typeof obj;\n-    return type === 'function' || type === 'object' && !!obj;\n-  }\n-\n-  // Is a given value equal to null?\n-  function isNull(obj) {\n-    return obj === null;\n-  }\n-\n-  // Is a given variable undefined?\n-  function isUndefined(obj) {\n-    return obj === void 0;\n-  }\n-\n-  // Is a given value a boolean?\n-  function isBoolean(obj) {\n-    return obj === true || obj === false || toString.call(obj) === '[object Boolean]';\n-  }\n-\n-  // Is a given value a DOM element?\n-  function isElement(obj) {\n-    return !!(obj && obj.nodeType === 1);\n-  }\n-\n-  // Internal function for creating a `toString`-based type tester.\n-  function tagTester(name) {\n-    var tag = '[object ' + name + ']';\n-    return function(obj) {\n-      return toString.call(obj) === tag;\n-    };\n-  }\n-\n-  var isString = tagTester('String');\n-\n-  var isNumber = tagTester('Number');\n-\n-  var isDate = tagTester('Date');\n-\n-  var isRegExp = tagTester('RegExp');\n-\n-  var isError = tagTester('Error');\n-\n-  var isSymbol = tagTester('Symbol');\n-\n-  var isArrayBuffer = tagTester('ArrayBuffer');\n-\n-  var isFunction = tagTester('Function');\n-\n-  // Optimize `isFunction` if appropriate. Work around some `typeof` bugs in old\n-  // v8, IE 11 (#1621), Safari 8 (#1929), and PhantomJS (#2236).\n-  var nodelist = root.document && root.document.childNodes;\n-  if (typeof /./ != 'function' && typeof Int8Array != 'object' && typeof nodelist != 'function') {\n-    isFunction = function(obj) {\n-      return typeof obj == 'function' || false;\n-    };\n-  }\n-\n-  var isFunction$1 = isFunction;\n-\n-  var hasObjectTag = tagTester('Object');\n-\n-  // In IE 10 - Edge 13, `DataView` has string tag `'[object Object]'`.\n-  // In IE 11, the most common among them, this problem also applies to\n-  // `Map`, `WeakMap` and `Set`.\n-  var hasStringTagBug = (\n-        supportsDataView && hasObjectTag(new DataView(new ArrayBuffer(8)))\n-      ),\n-      isIE11 = (typeof Map !== 'undefined' && hasObjectTag(new Map));\n-\n-  var isDataView = tagTester('DataView');\n-\n-  // In IE 10 - Edge 13, we need a different heuristic\n-  // to determine whether an object is a `DataView`.\n-  function ie10IsDataView(obj) {\n-    return obj != null && isFunction$1(obj.getInt8) && isArrayBuffer(obj.buffer);\n-  }\n-\n-  var isDataView$1 = (hasStringTagBug ? ie10IsDataView : isDataView);\n-\n-  // Is a given value an array?\n-  // Delegates to ECMA5's native `Array.isArray`.\n-  var isArray = nativeIsArray || tagTester('Array');\n-\n-  // Internal function to check whether `key` is an own property name of `obj`.\n-  function has$1(obj, key) {\n-    return obj != null && hasOwnProperty.call(obj, key);\n-  }\n-\n-  var isArguments = tagTester('Arguments');\n-\n-  // Define a fallback version of the method in browsers (ahem, IE < 9), where\n-  // there isn't any inspectable \"Arguments\" type.\n-  (function() {\n-    if (!isArguments(arguments)) {\n-      isArguments = function(obj) {\n-        return has$1(obj, 'callee');\n-      };\n-    }\n-  }());\n-\n-  var isArguments$1 = isArguments;\n-\n-  // Is a given object a finite number?\n-  function isFinite$1(obj) {\n-    return !isSymbol(obj) && _isFinite(obj) && !isNaN(parseFloat(obj));\n-  }\n-\n-  // Is the given value `NaN`?\n-  function isNaN$1(obj) {\n-    return isNumber(obj) && _isNaN(obj);\n-  }\n-\n-  // Predicate-generating function. Often useful outside of Underscore.\n-  function constant(value) {\n-    return function() {\n-      return value;\n-    };\n-  }\n-\n-  // Common internal logic for `isArrayLike` and `isBufferLike`.\n-  function createSizePropertyCheck(getSizeProperty) {\n-    return function(collection) {\n-      var sizeProperty = getSizeProperty(collection);\n-      return typeof sizeProperty == 'number' && sizeProperty >= 0 && sizeProperty <= MAX_ARRAY_INDEX;\n-    }\n-  }\n-\n-  // Internal helper to generate a function to obtain property `key` from `obj`.\n-  function shallowProperty(key) {\n-    return function(obj) {\n-      return obj == null ? void 0 : obj[key];\n-    };\n-  }\n-\n-  // Internal helper to obtain the `byteLength` property of an object.\n-  var getByteLength = shallowProperty('byteLength');\n-\n-  // Internal helper to determine whether we should spend extensive checks against\n-  // `ArrayBuffer` et al.\n-  var isBufferLike = createSizePropertyCheck(getByteLength);\n-\n-  // Is a given value a typed array?\n-  var typedArrayPattern = /\\[object ((I|Ui)nt(8|16|32)|Float(32|64)|Uint8Clamped|Big(I|Ui)nt64)Array\\]/;\n-  function isTypedArray(obj) {\n-    // `ArrayBuffer.isView` is the most future-proof, so use it when available.\n-    // Otherwise, fall back on the above regular expression.\n-    return nativeIsView ? (nativeIsView(obj) && !isDataView$1(obj)) :\n-                  isBufferLike(obj) && typedArrayPattern.test(toString.call(obj));\n-  }\n-\n-  var isTypedArray$1 = supportsArrayBuffer ? isTypedArray : constant(false);\n-\n-  // Internal helper to obtain the `length` property of an object.\n-  var getLength = shallowProperty('length');\n-\n-  // Internal helper to create a simple lookup structure.\n-  // `collectNonEnumProps` used to depend on `_.contains`, but this led to\n-  // circular imports. `emulatedSet` is a one-off solution that only works for\n-  // arrays of strings.\n-  function emulatedSet(keys) {\n-    var hash = {};\n-    for (var l = keys.length, i = 0; i < l; ++i) hash[keys[i]] = true;\n-    return {\n-      contains: function(key) { return hash[key]; },\n-      push: function(key) {\n-        hash[key] = true;\n-        return keys.push(key);\n-      }\n-    };\n-  }\n-\n-  // Internal helper. Checks `keys` for the presence of keys in IE < 9 that won't\n-  // be iterated by `for key in ...` and thus missed. Extends `keys` in place if\n-  // needed.\n-  function collectNonEnumProps(obj, keys) {\n-    keys = emulatedSet(keys);\n-    var nonEnumIdx = nonEnumerableProps.length;\n-    var constructor = obj.constructor;\n-    var proto = isFunction$1(constructor) && constructor.prototype || ObjProto;\n-\n-    // Constructor is a special case.\n-    var prop = 'constructor';\n-    if (has$1(obj, prop) && !keys.contains(prop)) keys.push(prop);\n-\n-    while (nonEnumIdx--) {\n-      prop = nonEnumerableProps[nonEnumIdx];\n-      if (prop in obj && obj[prop] !== proto[prop] && !keys.contains(prop)) {\n-        keys.push(prop);\n-      }\n-    }\n-  }\n-\n-  // Retrieve the names of an object's own properties.\n-  // Delegates to **ECMAScript 5**'s native `Object.keys`.\n-  function keys(obj) {\n-    if (!isObject(obj)) return [];\n-    if (nativeKeys) return nativeKeys(obj);\n-    var keys = [];\n-    for (var key in obj) if (has$1(obj, key)) keys.push(key);\n-    // Ahem, IE < 9.\n-    if (hasEnumBug) collectNonEnumProps(obj, keys);\n-    return keys;\n-  }\n-\n-  // Is a given array, string, or object empty?\n-  // An \"empty\" object has no enumerable own-properties.\n-  function isEmpty(obj) {\n-    if (obj == null) return true;\n-    // Skip the more expensive `toString`-based type checks if `obj` has no\n-    // `.length`.\n-    var length = getLength(obj);\n-    if (typeof length == 'number' && (\n-      isArray(obj) || isString(obj) || isArguments$1(obj)\n-    )) return length === 0;\n-    return getLength(keys(obj)) === 0;\n-  }\n-\n-  // Returns whether an object has a given set of `key:value` pairs.\n-  function isMatch(object, attrs) {\n-    var _keys = keys(attrs), length = _keys.length;\n-    if (object == null) return !length;\n-    var obj = Object(object);\n-    for (var i = 0; i < length; i++) {\n-      var key = _keys[i];\n-      if (attrs[key] !== obj[key] || !(key in obj)) return false;\n-    }\n-    return true;\n-  }\n-\n-  // If Underscore is called as a function, it returns a wrapped object that can\n-  // be used OO-style. This wrapper holds altered versions of all functions added\n-  // through `_.mixin`. Wrapped objects may be chained.\n-  function _$1(obj) {\n-    if (obj instanceof _$1) return obj;\n-    if (!(this instanceof _$1)) return new _$1(obj);\n-    this._wrapped = obj;\n-  }\n-\n-  _$1.VERSION = VERSION;\n-\n-  // Extracts the result from a wrapped and chained object.\n-  _$1.prototype.value = function() {\n-    return this._wrapped;\n-  };\n-\n-  // Provide unwrapping proxies for some methods used in engine operations\n-  // such as arithmetic and JSON stringification.\n-  _$1.prototype.valueOf = _$1.prototype.toJSON = _$1.prototype.value;\n-\n-  _$1.prototype.toString = function() {\n-    return String(this._wrapped);\n-  };\n-\n-  // Internal function to wrap or shallow-copy an ArrayBuffer,\n-  // typed array or DataView to a new view, reusing the buffer.\n-  function toBufferView(bufferSource) {\n-    return new Uint8Array(\n-      bufferSource.buffer || bufferSource,\n-      bufferSource.byteOffset || 0,\n-      getByteLength(bufferSource)\n-    );\n-  }\n-\n-  // We use this string twice, so give it a name for minification.\n-  var tagDataView = '[object DataView]';\n-\n-  // Internal recursive comparison function for `_.isEqual`.\n-  function eq(a, b, aStack, bStack) {\n-    // Identical objects are equal. `0 === -0`, but they aren't identical.\n-    // See the [Harmony `egal` proposal](https://wiki.ecmascript.org/doku.php?id=harmony:egal).\n-    if (a === b) return a !== 0 || 1 / a === 1 / b;\n-    // `null` or `undefined` only equal to itself (strict comparison).\n-    if (a == null || b == null) return false;\n-    // `NaN`s are equivalent, but non-reflexive.\n-    if (a !== a) return b !== b;\n-    // Exhaust primitive checks\n-    var type = typeof a;\n-    if (type !== 'function' && type !== 'object' && typeof b != 'object') return false;\n-    return deepEq(a, b, aStack, bStack);\n-  }\n-\n-  // Internal recursive comparison function for `_.isEqual`.\n-  function deepEq(a, b, aStack, bStack) {\n-    // Unwrap any wrapped objects.\n-    if (a instanceof _$1) a = a._wrapped;\n-    if (b instanceof _$1) b = b._wrapped;\n-    // Compare `[[Class]]` names.\n-    var className = toString.call(a);\n-    if (className !== toString.call(b)) return false;\n-    // Work around a bug in IE 10 - Edge 13.\n-    if (hasStringTagBug && className == '[object Object]' && isDataView$1(a)) {\n-      if (!isDataView$1(b)) return false;\n-      className = tagDataView;\n-    }\n-    switch (className) {\n-      // These types are compared by value.\n-      case '[object RegExp]':\n-        // RegExps are coerced to strings for comparison (Note: '' + /a/i === '/a/i')\n-      case '[object String]':\n-        // Primitives and their corresponding object wrappers are equivalent; thus, `\"5\"` is\n-        // equivalent to `new String(\"5\")`.\n-        return '' + a === '' + b;\n-      case '[object Number]':\n-        // `NaN`s are equivalent, but non-reflexive.\n-        // Object(NaN) is equivalent to NaN.\n-        if (+a !== +a) return +b !== +b;\n-        // An `egal` comparison is performed for other numeric values.\n-        return +a === 0 ? 1 / +a === 1 / b : +a === +b;\n-      case '[object Date]':\n-      case '[object Boolean]':\n-        // Coerce dates and booleans to numeric primitive values. Dates are compared by their\n-        // millisecond representations. Note that invalid dates with millisecond representations\n-        // of `NaN` are not equivalent.\n-        return +a === +b;\n-      case '[object Symbol]':\n-        return SymbolProto.valueOf.call(a) === SymbolProto.valueOf.call(b);\n-      case '[object ArrayBuffer]':\n-      case tagDataView:\n-        // Coerce to typed array so we can fall through.\n-        return deepEq(toBufferView(a), toBufferView(b), aStack, bStack);\n-    }\n-\n-    var areArrays = className === '[object Array]';\n-    if (!areArrays && isTypedArray$1(a)) {\n-        var byteLength = getByteLength(a);\n-        if (byteLength !== getByteLength(b)) return false;\n-        if (a.buffer === b.buffer && a.byteOffset === b.byteOffset) return true;\n-        areArrays = true;\n-    }\n-    if (!areArrays) {\n-      if (typeof a != 'object' || typeof b != 'object') return false;\n-\n-      // Objects with different constructors are not equivalent, but `Object`s or `Array`s\n-      // from different frames are.\n-      var aCtor = a.constructor, bCtor = b.constructor;\n-      if (aCtor !== bCtor && !(isFunction$1(aCtor) && aCtor instanceof aCtor &&\n-                               isFunction$1(bCtor) && bCtor instanceof bCtor)\n-                          && ('constructor' in a && 'constructor' in b)) {\n-        return false;\n-      }\n-    }\n-    // Assume equality for cyclic structures. The algorithm for detecting cyclic\n-    // structures is adapted from ES 5.1 section 15.12.3, abstract operation `JO`.\n-\n-    // Initializing stack of traversed objects.\n-    // It's done here since we only need them for objects and arrays comparison.\n-    aStack = aStack || [];\n-    bStack = bStack || [];\n-    var length = aStack.length;\n-    while (length--) {\n-      // Linear search. Performance is inversely proportional to the number of\n-      // unique nested structures.\n-      if (aStack[length] === a) return bStack[length] === b;\n-    }\n-\n-    // Add the first object to the stack of traversed objects.\n-    aStack.push(a);\n-    bStack.push(b);\n-\n-    // Recursively compare objects and arrays.\n-    if (areArrays) {\n-      // Compare array lengths to determine if a deep comparison is necessary.\n-      length = a.length;\n-      if (length !== b.length) return false;\n-      // Deep compare the contents, ignoring non-numeric properties.\n-      while (length--) {\n-        if (!eq(a[length], b[length], aStack, bStack)) return false;\n-      }\n-    } else {\n-      // Deep compare objects.\n-      var _keys = keys(a), key;\n-      length = _keys.length;\n-      // Ensure that both objects contain the same number of properties before comparing deep equality.\n-      if (keys(b).length !== length) return false;\n-      while (length--) {\n-        // Deep compare each member\n-        key = _keys[length];\n-        if (!(has$1(b, key) && eq(a[key], b[key], aStack, bStack))) return false;\n-      }\n-    }\n-    // Remove the first object from the stack of traversed objects.\n-    aStack.pop();\n-    bStack.pop();\n-    return true;\n-  }\n-\n-  // Perform a deep comparison to check if two objects are equal.\n-  function isEqual(a, b) {\n-    return eq(a, b);\n-  }\n-\n-  // Retrieve all the enumerable property names of an object.\n-  function allKeys(obj) {\n-    if (!isObject(obj)) return [];\n-    var keys = [];\n-    for (var key in obj) keys.push(key);\n-    // Ahem, IE < 9.\n-    if (hasEnumBug) collectNonEnumProps(obj, keys);\n-    return keys;\n-  }\n-\n-  // Since the regular `Object.prototype.toString` type tests don't work for\n-  // some types in IE 11, we use a fingerprinting heuristic instead, based\n-  // on the methods. It's not great, but it's the best we got.\n-  // The fingerprint method lists are defined below.\n-  function ie11fingerprint(methods) {\n-    var length = getLength(methods);\n-    return function(obj) {\n-      if (obj == null) return false;\n-      // `Map`, `WeakMap` and `Set` have no enumerable keys.\n-      var keys = allKeys(obj);\n-      if (getLength(keys)) return false;\n-      for (var i = 0; i < length; i++) {\n-        if (!isFunction$1(obj[methods[i]])) return false;\n-      }\n-      // If we are testing against `WeakMap`, we need to ensure that\n-      // `obj` doesn't have a `forEach` method in order to distinguish\n-      // it from a regular `Map`.\n-      return methods !== weakMapMethods || !isFunction$1(obj[forEachName]);\n-    };\n-  }\n-\n-  // In the interest of compact minification, we write\n-  // each string in the fingerprints only once.\n-  var forEachName = 'forEach',\n-      hasName = 'has',\n-      commonInit = ['clear', 'delete'],\n-      mapTail = ['get', hasName, 'set'];\n-\n-  // `Map`, `WeakMap` and `Set` each have slightly different\n-  // combinations of the above sublists.\n-  var mapMethods = commonInit.concat(forEachName, mapTail),\n-      weakMapMethods = commonInit.concat(mapTail),\n-      setMethods = ['add'].concat(commonInit, forEachName, hasName);\n-\n-  var isMap = isIE11 ? ie11fingerprint(mapMethods) : tagTester('Map');\n-\n-  var isWeakMap = isIE11 ? ie11fingerprint(weakMapMethods) : tagTester('WeakMap');\n-\n-  var isSet = isIE11 ? ie11fingerprint(setMethods) : tagTester('Set');\n-\n-  var isWeakSet = tagTester('WeakSet');\n-\n-  // Retrieve the values of an object's properties.\n-  function values(obj) {\n-    var _keys = keys(obj);\n-    var length = _keys.length;\n-    var values = Array(length);\n-    for (var i = 0; i < length; i++) {\n-      values[i] = obj[_keys[i]];\n-    }\n-    return values;\n-  }\n-\n-  // Convert an object into a list of `[key, value]` pairs.\n-  // The opposite of `_.object` with one argument.\n-  function pairs(obj) {\n-    var _keys = keys(obj);\n-    var length = _keys.length;\n-    var pairs = Array(length);\n-    for (var i = 0; i < length; i++) {\n-      pairs[i] = [_keys[i], obj[_keys[i]]];\n-    }\n-    return pairs;\n-  }\n-\n-  // Invert the keys and values of an object. The values must be serializable.\n-  function invert(obj) {\n-    var result = {};\n-    var _keys = keys(obj);\n-    for (var i = 0, length = _keys.length; i < length; i++) {\n-      result[obj[_keys[i]]] = _keys[i];\n-    }\n-    return result;\n-  }\n-\n-  // Return a sorted list of the function names available on the object.\n-  function functions(obj) {\n-    var names = [];\n-    for (var key in obj) {\n-      if (isFunction$1(obj[key])) names.push(key);\n-    }\n-    return names.sort();\n-  }\n-\n-  // An internal function for creating assigner functions.\n-  function createAssigner(keysFunc, defaults) {\n-    return function(obj) {\n-      var length = arguments.length;\n-      if (defaults) obj = Object(obj);\n-      if (length < 2 || obj == null) return obj;\n-      for (var index = 1; index < length; index++) {\n-        var source = arguments[index],\n-            keys = keysFunc(source),\n-            l = keys.length;\n-        for (var i = 0; i < l; i++) {\n-          var key = keys[i];\n-          if (!defaults || obj[key] === void 0) obj[key] = source[key];\n-        }\n-      }\n-      return obj;\n-    };\n-  }\n-\n-  // Extend a given object with all the properties in passed-in object(s).\n-  var extend = createAssigner(allKeys);\n-\n-  // Assigns a given object with all the own properties in the passed-in\n-  // object(s).\n-  // (https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object/assign)\n-  var extendOwn = createAssigner(keys);\n-\n-  // Fill in a given object with default properties.\n-  var defaults = createAssigner(allKeys, true);\n-\n-  // Create a naked function reference for surrogate-prototype-swapping.\n-  function ctor() {\n-    return function(){};\n-  }\n-\n-  // An internal function for creating a new object that inherits from another.\n-  function baseCreate(prototype) {\n-    if (!isObject(prototype)) return {};\n-    if (nativeCreate) return nativeCreate(prototype);\n-    var Ctor = ctor();\n-    Ctor.prototype = prototype;\n-    var result = new Ctor;\n-    Ctor.prototype = null;\n-    return result;\n-  }\n-\n-  // Creates an object that inherits from the given prototype object.\n-  // If additional properties are provided then they will be added to the\n-  // created object.\n-  function create(prototype, props) {\n-    var result = baseCreate(prototype);\n-    if (props) extendOwn(result, props);\n-    return result;\n-  }\n-\n-  // Create a (shallow-cloned) duplicate of an object.\n-  function clone(obj) {\n-    if (!isObject(obj)) return obj;\n-    return isArray(obj) ? obj.slice() : extend({}, obj);\n-  }\n-\n-  // Invokes `interceptor` with the `obj` and then returns `obj`.\n-  // The primary purpose of this method is to \"tap into\" a method chain, in\n-  // order to perform operations on intermediate results within the chain.\n-  function tap(obj, interceptor) {\n-    interceptor(obj);\n-    return obj;\n-  }\n-\n-  // Normalize a (deep) property `path` to array.\n-  // Like `_.iteratee`, this function can be customized.\n-  function toPath$1(path) {\n-    return isArray(path) ? path : [path];\n-  }\n-  _$1.toPath = toPath$1;\n-\n-  // Internal wrapper for `_.toPath` to enable minification.\n-  // Similar to `cb` for `_.iteratee`.\n-  function toPath(path) {\n-    return _$1.toPath(path);\n-  }\n-\n-  // Internal function to obtain a nested property in `obj` along `path`.\n-  function deepGet(obj, path) {\n-    var length = path.length;\n-    for (var i = 0; i < length; i++) {\n-      if (obj == null) return void 0;\n-      obj = obj[path[i]];\n-    }\n-    return length ? obj : void 0;\n-  }\n-\n-  // Get the value of the (deep) property on `path` from `object`.\n-  // If any property in `path` does not exist or if the value is\n-  // `undefined`, return `defaultValue` instead.\n-  // The `path` is normalized through `_.toPath`.\n-  function get(object, path, defaultValue) {\n-    var value = deepGet(object, toPath(path));\n-    return isUndefined(value) ? defaultValue : value;\n-  }\n-\n-  // Shortcut function for checking if an object has a given property directly on\n-  // itself (in other words, not on a prototype). Unlike the internal `has`\n-  // function, this public version can also traverse nested properties.\n-  function has(obj, path) {\n-    path = toPath(path);\n-    var length = path.length;\n-    for (var i = 0; i < length; i++) {\n-      var key = path[i];\n-      if (!has$1(obj, key)) return false;\n-      obj = obj[key];\n-    }\n-    return !!length;\n-  }\n-\n-  // Keep the identity function around for default iteratees.\n-  function identity(value) {\n-    return value;\n-  }\n-\n-  // Returns a predicate for checking whether an object has a given set of\n-  // `key:value` pairs.\n-  function matcher(attrs) {\n-    attrs = extendOwn({}, attrs);\n-    return function(obj) {\n-      return isMatch(obj, attrs);\n-    };\n-  }\n-\n-  // Creates a function that, when passed an object, will traverse that object\u2019s\n-  // properties down the given `path`, specified as an array of keys or indices.\n-  function property(path) {\n-    path = toPath(path);\n-    return function(obj) {\n-      return deepGet(obj, path);\n-    };\n-  }\n-\n-  // Internal function that returns an efficient (for current engines) version\n-  // of the passed-in callback, to be repeatedly applied in other Underscore\n-  // functions.\n-  function optimizeCb(func, context, argCount) {\n-    if (context === void 0) return func;\n-    switch (argCount == null ? 3 : argCount) {\n-      case 1: return function(value) {\n-        return func.call(context, value);\n-      };\n-      // The 2-argument case is omitted because we\u2019re not using it.\n-      case 3: return function(value, index, collection) {\n-        return func.call(context, value, index, collection);\n-      };\n-      case 4: return function(accumulator, value, index, collection) {\n-        return func.call(context, accumulator, value, index, collection);\n-      };\n-    }\n-    return function() {\n-      return func.apply(context, arguments);\n-    };\n-  }\n-\n-  // An internal function to generate callbacks that can be applied to each\n-  // element in a collection, returning the desired result \u2014 either `_.identity`,\n-  // an arbitrary callback, a property matcher, or a property accessor.\n-  function baseIteratee(value, context, argCount) {\n-    if (value == null) return identity;\n-    if (isFunction$1(value)) return optimizeCb(value, context, argCount);\n-    if (isObject(value) && !isArray(value)) return matcher(value);\n-    return property(value);\n-  }\n-\n-  // External wrapper for our callback generator. Users may customize\n-  // `_.iteratee` if they want additional predicate/iteratee shorthand styles.\n-  // This abstraction hides the internal-only `argCount` argument.\n-  function iteratee(value, context) {\n-    return baseIteratee(value, context, Infinity);\n-  }\n-  _$1.iteratee = iteratee;\n-\n-  // The function we call internally to generate a callback. It invokes\n-  // `_.iteratee` if overridden, otherwise `baseIteratee`.\n-  function cb(value, context, argCount) {\n-    if (_$1.iteratee !== iteratee) return _$1.iteratee(value, context);\n-    return baseIteratee(value, context, argCount);\n-  }\n-\n-  // Returns the results of applying the `iteratee` to each element of `obj`.\n-  // In contrast to `_.map` it returns an object.\n-  function mapObject(obj, iteratee, context) {\n-    iteratee = cb(iteratee, context);\n-    var _keys = keys(obj),\n-        length = _keys.length,\n-        results = {};\n-    for (var index = 0; index < length; index++) {\n-      var currentKey = _keys[index];\n-      results[currentKey] = iteratee(obj[currentKey], currentKey, obj);\n-    }\n-    return results;\n-  }\n-\n-  // Predicate-generating function. Often useful outside of Underscore.\n-  function noop(){}\n-\n-  // Generates a function for a given object that returns a given property.\n-  function propertyOf(obj) {\n-    if (obj == null) return noop;\n-    return function(path) {\n-      return get(obj, path);\n-    };\n-  }\n-\n-  // Run a function **n** times.\n-  function times(n, iteratee, context) {\n-    var accum = Array(Math.max(0, n));\n-    iteratee = optimizeCb(iteratee, context, 1);\n-    for (var i = 0; i < n; i++) accum[i] = iteratee(i);\n-    return accum;\n-  }\n-\n-  // Return a random integer between `min` and `max` (inclusive).\n-  function random(min, max) {\n-    if (max == null) {\n-      max = min;\n-      min = 0;\n-    }\n-    return min + Math.floor(Math.random() * (max - min + 1));\n-  }\n-\n-  // A (possibly faster) way to get the current timestamp as an integer.\n-  var now = Date.now || function() {\n-    return new Date().getTime();\n-  };\n-\n-  // Internal helper to generate functions for escaping and unescaping strings\n-  // to/from HTML interpolation.\n-  function createEscaper(map) {\n-    var escaper = function(match) {\n-      return map[match];\n-    };\n-    // Regexes for identifying a key that needs to be escaped.\n-    var source = '(?:' + keys(map).join('|') + ')';\n-    var testRegexp = RegExp(source);\n-    var replaceRegexp = RegExp(source, 'g');\n-    return function(string) {\n-      string = string == null ? '' : '' + string;\n-      return testRegexp.test(string) ? string.replace(replaceRegexp, escaper) : string;\n-    };\n-  }\n-\n-  // Internal list of HTML entities for escaping.\n-  var escapeMap = {\n-    '&': '&amp;',\n-    '<': '&lt;',\n-    '>': '&gt;',\n-    '\"': '&quot;',\n-    \"'\": '&#x27;',\n-    '`': '&#x60;'\n-  };\n-\n-  // Function for escaping strings to HTML interpolation.\n-  var _escape = createEscaper(escapeMap);\n-\n-  // Internal list of HTML entities for unescaping.\n-  var unescapeMap = invert(escapeMap);\n-\n-  // Function for unescaping strings from HTML interpolation.\n-  var _unescape = createEscaper(unescapeMap);\n-\n-  // By default, Underscore uses ERB-style template delimiters. Change the\n-  // following template settings to use alternative delimiters.\n-  var templateSettings = _$1.templateSettings = {\n-    evaluate: /<%([\\s\\S]+?)%>/g,\n-    interpolate: /<%=([\\s\\S]+?)%>/g,\n-    escape: /<%-([\\s\\S]+?)%>/g\n-  };\n-\n-  // When customizing `_.templateSettings`, if you don't want to define an\n-  // interpolation, evaluation or escaping regex, we need one that is\n-  // guaranteed not to match.\n-  var noMatch = /(.)^/;\n-\n-  // Certain characters need to be escaped so that they can be put into a\n-  // string literal.\n-  var escapes = {\n-    \"'\": \"'\",\n-    '\\\\': '\\\\',\n-    '\\r': 'r',\n-    '\\n': 'n',\n-    '\\u2028': 'u2028',\n-    '\\u2029': 'u2029'\n-  };\n-\n-  var escapeRegExp = /\\\\|'|\\r|\\n|\\u2028|\\u2029/g;\n-\n-  function escapeChar(match) {\n-    return '\\\\' + escapes[match];\n-  }\n-\n-  // In order to prevent third-party code injection through\n-  // `_.templateSettings.variable`, we test it against the following regular\n-  // expression. It is intentionally a bit more liberal than just matching valid\n-  // identifiers, but still prevents possible loopholes through defaults or\n-  // destructuring assignment.\n-  var bareIdentifier = /^\\s*(\\w|\\$)+\\s*$/;\n-\n-  // JavaScript micro-templating, similar to John Resig's implementation.\n-  // Underscore templating handles arbitrary delimiters, preserves whitespace,\n-  // and correctly escapes quotes within interpolated code.\n-  // NB: `oldSettings` only exists for backwards compatibility.\n-  function template(text, settings, oldSettings) {\n-    if (!settings && oldSettings) settings = oldSettings;\n-    settings = defaults({}, settings, _$1.templateSettings);\n-\n-    // Combine delimiters into one regular expression via alternation.\n-    var matcher = RegExp([\n-      (settings.escape || noMatch).source,\n-      (settings.interpolate || noMatch).source,\n-      (settings.evaluate || noMatch).source\n-    ].join('|') + '|$', 'g');\n-\n-    // Compile the template source, escaping string literals appropriately.\n-    var index = 0;\n-    var source = \"__p+='\";\n-    text.replace(matcher, function(match, escape, interpolate, evaluate, offset) {\n-      source += text.slice(index, offset).replace(escapeRegExp, escapeChar);\n-      index = offset + match.length;\n-\n-      if (escape) {\n-        source += \"'+\\n((__t=(\" + escape + \"))==null?'':_.escape(__t))+\\n'\";\n-      } else if (interpolate) {\n-        source += \"'+\\n((__t=(\" + interpolate + \"))==null?'':__t)+\\n'\";\n-      } else if (evaluate) {\n-        source += \"';\\n\" + evaluate + \"\\n__p+='\";\n-      }\n-\n-      // Adobe VMs need the match returned to produce the correct offset.\n-      return match;\n-    });\n-    source += \"';\\n\";\n-\n-    var argument = settings.variable;\n-    if (argument) {\n-      // Insure against third-party code injection. (CVE-2021-23358)\n-      if (!bareIdentifier.test(argument)) throw new Error(\n-        'variable is not a bare identifier: ' + argument\n-      );\n-    } else {\n-      // If a variable is not specified, place data values in local scope.\n-      source = 'with(obj||{}){\\n' + source + '}\\n';\n-      argument = 'obj';\n-    }\n-\n-    source = \"var __t,__p='',__j=Array.prototype.join,\" +\n-      \"print=function(){__p+=__j.call(arguments,'');};\\n\" +\n-      source + 'return __p;\\n';\n-\n-    var render;\n-    try {\n-      render = new Function(argument, '_', source);\n-    } catch (e) {\n-      e.source = source;\n-      throw e;\n-    }\n-\n-    var template = function(data) {\n-      return render.call(this, data, _$1);\n-    };\n-\n-    // Provide the compiled source as a convenience for precompilation.\n-    template.source = 'function(' + argument + '){\\n' + source + '}';\n-\n-    return template;\n-  }\n-\n-  // Traverses the children of `obj` along `path`. If a child is a function, it\n-  // is invoked with its parent as context. Returns the value of the final\n-  // child, or `fallback` if any child is undefined.\n-  function result(obj, path, fallback) {\n-    path = toPath(path);\n-    var length = path.length;\n-    if (!length) {\n-      return isFunction$1(fallback) ? fallback.call(obj) : fallback;\n-    }\n-    for (var i = 0; i < length; i++) {\n-      var prop = obj == null ? void 0 : obj[path[i]];\n-      if (prop === void 0) {\n-        prop = fallback;\n-        i = length; // Ensure we don't continue iterating.\n-      }\n-      obj = isFunction$1(prop) ? prop.call(obj) : prop;\n-    }\n-    return obj;\n-  }\n-\n-  // Generate a unique integer id (unique within the entire client session).\n-  // Useful for temporary DOM ids.\n-  var idCounter = 0;\n-  function uniqueId(prefix) {\n-    var id = ++idCounter + '';\n-    return prefix ? prefix + id : id;\n-  }\n-\n-  // Start chaining a wrapped Underscore object.\n-  function chain(obj) {\n-    var instance = _$1(obj);\n-    instance._chain = true;\n-    return instance;\n-  }\n-\n-  // Internal function to execute `sourceFunc` bound to `context` with optional\n-  // `args`. Determines whether to execute a function as a constructor or as a\n-  // normal function.\n-  function executeBound(sourceFunc, boundFunc, context, callingContext, args) {\n-    if (!(callingContext instanceof boundFunc)) return sourceFunc.apply(context, args);\n-    var self = baseCreate(sourceFunc.prototype);\n-    var result = sourceFunc.apply(self, args);\n-    if (isObject(result)) return result;\n-    return self;\n-  }\n-\n-  // Partially apply a function by creating a version that has had some of its\n-  // arguments pre-filled, without changing its dynamic `this` context. `_` acts\n-  // as a placeholder by default, allowing any combination of arguments to be\n-  // pre-filled. Set `_.partial.placeholder` for a custom placeholder argument.\n-  var partial = restArguments(function(func, boundArgs) {\n-    var placeholder = partial.placeholder;\n-    var bound = function() {\n-      var position = 0, length = boundArgs.length;\n-      var args = Array(length);\n-      for (var i = 0; i < length; i++) {\n-        args[i] = boundArgs[i] === placeholder ? arguments[position++] : boundArgs[i];\n-      }\n-      while (position < arguments.length) args.push(arguments[position++]);\n-      return executeBound(func, bound, this, this, args);\n-    };\n-    return bound;\n-  });\n-\n-  partial.placeholder = _$1;\n-\n-  // Create a function bound to a given object (assigning `this`, and arguments,\n-  // optionally).\n-  var bind = restArguments(function(func, context, args) {\n-    if (!isFunction$1(func)) throw new TypeError('Bind must be called on a function');\n-    var bound = restArguments(function(callArgs) {\n-      return executeBound(func, bound, context, this, args.concat(callArgs));\n-    });\n-    return bound;\n-  });\n-\n-  // Internal helper for collection methods to determine whether a collection\n-  // should be iterated as an array or as an object.\n-  // Related: https://people.mozilla.org/~jorendorff/es6-draft.html#sec-tolength\n-  // Avoids a very nasty iOS 8 JIT bug on ARM-64. #2094\n-  var isArrayLike = createSizePropertyCheck(getLength);\n-\n-  // Internal implementation of a recursive `flatten` function.\n-  function flatten$1(input, depth, strict, output) {\n-    output = output || [];\n-    if (!depth && depth !== 0) {\n-      depth = Infinity;\n-    } else if (depth <= 0) {\n-      return output.concat(input);\n-    }\n-    var idx = output.length;\n-    for (var i = 0, length = getLength(input); i < length; i++) {\n-      var value = input[i];\n-      if (isArrayLike(value) && (isArray(value) || isArguments$1(value))) {\n-        // Flatten current level of array or arguments object.\n-        if (depth > 1) {\n-          flatten$1(value, depth - 1, strict, output);\n-          idx = output.length;\n-        } else {\n-          var j = 0, len = value.length;\n-          while (j < len) output[idx++] = value[j++];\n-        }\n-      } else if (!strict) {\n-        output[idx++] = value;\n-      }\n-    }\n-    return output;\n-  }\n-\n-  // Bind a number of an object's methods to that object. Remaining arguments\n-  // are the method names to be bound. Useful for ensuring that all callbacks\n-  // defined on an object belong to it.\n-  var bindAll = restArguments(function(obj, keys) {\n-    keys = flatten$1(keys, false, false);\n-    var index = keys.length;\n-    if (index < 1) throw new Error('bindAll must be passed function names');\n-    while (index--) {\n-      var key = keys[index];\n-      obj[key] = bind(obj[key], obj);\n-    }\n-    return obj;\n-  });\n-\n-  // Memoize an expensive function by storing its results.\n-  function memoize(func, hasher) {\n-    var memoize = function(key) {\n-      var cache = memoize.cache;\n-      var address = '' + (hasher ? hasher.apply(this, arguments) : key);\n-      if (!has$1(cache, address)) cache[address] = func.apply(this, arguments);\n-      return cache[address];\n-    };\n-    memoize.cache = {};\n-    return memoize;\n-  }\n-\n-  // Delays a function for the given number of milliseconds, and then calls\n-  // it with the arguments supplied.\n-  var delay = restArguments(function(func, wait, args) {\n-    return setTimeout(function() {\n-      return func.apply(null, args);\n-    }, wait);\n-  });\n-\n-  // Defers a function, scheduling it to run after the current call stack has\n-  // cleared.\n-  var defer = partial(delay, _$1, 1);\n-\n-  // Returns a function, that, when invoked, will only be triggered at most once\n-  // during a given window of time. Normally, the throttled function will run\n-  // as much as it can, without ever going more than once per `wait` duration;\n-  // but if you'd like to disable the execution on the leading edge, pass\n-  // `{leading: false}`. To disable execution on the trailing edge, ditto.\n-  function throttle(func, wait, options) {\n-    var timeout, context, args, result;\n-    var previous = 0;\n-    if (!options) options = {};\n-\n-    var later = function() {\n-      previous = options.leading === false ? 0 : now();\n-      timeout = null;\n-      result = func.apply(context, args);\n-      if (!timeout) context = args = null;\n-    };\n-\n-    var throttled = function() {\n-      var _now = now();\n-      if (!previous && options.leading === false) previous = _now;\n-      var remaining = wait - (_now - previous);\n-      context = this;\n-      args = arguments;\n-      if (remaining <= 0 || remaining > wait) {\n-        if (timeout) {\n-          clearTimeout(timeout);\n-          timeout = null;\n-        }\n-        previous = _now;\n-        result = func.apply(context, args);\n-        if (!timeout) context = args = null;\n-      } else if (!timeout && options.trailing !== false) {\n-        timeout = setTimeout(later, remaining);\n-      }\n-      return result;\n-    };\n-\n-    throttled.cancel = function() {\n-      clearTimeout(timeout);\n-      previous = 0;\n-      timeout = context = args = null;\n-    };\n-\n-    return throttled;\n-  }\n-\n-  // When a sequence of calls of the returned function ends, the argument\n-  // function is triggered. The end of a sequence is defined by the `wait`\n-  // parameter. If `immediate` is passed, the argument function will be\n-  // triggered at the beginning of the sequence instead of at the end.\n-  function debounce(func, wait, immediate) {\n-    var timeout, previous, args, result, context;\n-\n-    var later = function() {\n-      var passed = now() - previous;\n-      if (wait > passed) {\n-        timeout = setTimeout(later, wait - passed);\n-      } else {\n-        timeout = null;\n-        if (!immediate) result = func.apply(context, args);\n-        // This check is needed because `func` can recursively invoke `debounced`.\n-        if (!timeout) args = context = null;\n-      }\n-    };\n-\n-    var debounced = restArguments(function(_args) {\n-      context = this;\n-      args = _args;\n-      previous = now();\n-      if (!timeout) {\n-        timeout = setTimeout(later, wait);\n-        if (immediate) result = func.apply(context, args);\n-      }\n-      return result;\n-    });\n-\n-    debounced.cancel = function() {\n-      clearTimeout(timeout);\n-      timeout = args = context = null;\n-    };\n-\n-    return debounced;\n-  }\n-\n-  // Returns the first function passed as an argument to the second,\n-  // allowing you to adjust arguments, run code before and after, and\n-  // conditionally execute the original function.\n-  function wrap(func, wrapper) {\n-    return partial(wrapper, func);\n-  }\n-\n-  // Returns a negated version of the passed-in predicate.\n-  function negate(predicate) {\n-    return function() {\n-      return !predicate.apply(this, arguments);\n-    };\n-  }\n-\n-  // Returns a function that is the composition of a list of functions, each\n-  // consuming the return value of the function that follows.\n-  function compose() {\n-    var args = arguments;\n-    var start = args.length - 1;\n-    return function() {\n-      var i = start;\n-      var result = args[start].apply(this, arguments);\n-      while (i--) result = args[i].call(this, result);\n-      return result;\n-    };\n-  }\n-\n-  // Returns a function that will only be executed on and after the Nth call.\n-  function after(times, func) {\n-    return function() {\n-      if (--times < 1) {\n-        return func.apply(this, arguments);\n-      }\n-    };\n-  }\n-\n-  // Returns a function that will only be executed up to (but not including) the\n-  // Nth call.\n-  function before(times, func) {\n-    var memo;\n-    return function() {\n-      if (--times > 0) {\n-        memo = func.apply(this, arguments);\n-      }\n-      if (times <= 1) func = null;\n-      return memo;\n-    };\n-  }\n-\n-  // Returns a function that will be executed at most one time, no matter how\n-  // often you call it. Useful for lazy initialization.\n-  var once = partial(before, 2);\n-\n-  // Returns the first key on an object that passes a truth test.\n-  function findKey(obj, predicate, context) {\n-    predicate = cb(predicate, context);\n-    var _keys = keys(obj), key;\n-    for (var i = 0, length = _keys.length; i < length; i++) {\n-      key = _keys[i];\n-      if (predicate(obj[key], key, obj)) return key;\n-    }\n-  }\n-\n-  // Internal function to generate `_.findIndex` and `_.findLastIndex`.\n-  function createPredicateIndexFinder(dir) {\n-    return function(array, predicate, context) {\n-      predicate = cb(predicate, context);\n-      var length = getLength(array);\n-      var index = dir > 0 ? 0 : length - 1;\n-      for (; index >= 0 && index < length; index += dir) {\n-        if (predicate(array[index], index, array)) return index;\n-      }\n-      return -1;\n-    };\n-  }\n-\n-  // Returns the first index on an array-like that passes a truth test.\n-  var findIndex = createPredicateIndexFinder(1);\n-\n-  // Returns the last index on an array-like that passes a truth test.\n-  var findLastIndex = createPredicateIndexFinder(-1);\n-\n-  // Use a comparator function to figure out the smallest index at which\n-  // an object should be inserted so as to maintain order. Uses binary search.\n-  function sortedIndex(array, obj, iteratee, context) {\n-    iteratee = cb(iteratee, context, 1);\n-    var value = iteratee(obj);\n-    var low = 0, high = getLength(array);\n-    while (low < high) {\n-      var mid = Math.floor((low + high) / 2);\n-      if (iteratee(array[mid]) < value) low = mid + 1; else high = mid;\n-    }\n-    return low;\n-  }\n-\n-  // Internal function to generate the `_.indexOf` and `_.lastIndexOf` functions.\n-  function createIndexFinder(dir, predicateFind, sortedIndex) {\n-    return function(array, item, idx) {\n-      var i = 0, length = getLength(array);\n-      if (typeof idx == 'number') {\n-        if (dir > 0) {\n-          i = idx >= 0 ? idx : Math.max(idx + length, i);\n-        } else {\n-          length = idx >= 0 ? Math.min(idx + 1, length) : idx + length + 1;\n-        }\n-      } else if (sortedIndex && idx && length) {\n-        idx = sortedIndex(array, item);\n-        return array[idx] === item ? idx : -1;\n-      }\n-      if (item !== item) {\n-        idx = predicateFind(slice.call(array, i, length), isNaN$1);\n-        return idx >= 0 ? idx + i : -1;\n-      }\n-      for (idx = dir > 0 ? i : length - 1; idx >= 0 && idx < length; idx += dir) {\n-        if (array[idx] === item) return idx;\n-      }\n-      return -1;\n-    };\n-  }\n-\n-  // Return the position of the first occurrence of an item in an array,\n-  // or -1 if the item is not included in the array.\n-  // If the array is large and already in sort order, pass `true`\n-  // for **isSorted** to use binary search.\n-  var indexOf = createIndexFinder(1, findIndex, sortedIndex);\n-\n-  // Return the position of the last occurrence of an item in an array,\n-  // or -1 if the item is not included in the array.\n-  var lastIndexOf = createIndexFinder(-1, findLastIndex);\n-\n-  // Return the first value which passes a truth test.\n-  function find(obj, predicate, context) {\n-    var keyFinder = isArrayLike(obj) ? findIndex : findKey;\n-    var key = keyFinder(obj, predicate, context);\n-    if (key !== void 0 && key !== -1) return obj[key];\n-  }\n-\n-  // Convenience version of a common use case of `_.find`: getting the first\n-  // object containing specific `key:value` pairs.\n-  function findWhere(obj, attrs) {\n-    return find(obj, matcher(attrs));\n-  }\n-\n-  // The cornerstone for collection functions, an `each`\n-  // implementation, aka `forEach`.\n-  // Handles raw objects in addition to array-likes. Treats all\n-  // sparse array-likes as if they were dense.\n-  function each(obj, iteratee, context) {\n-    iteratee = optimizeCb(iteratee, context);\n-    var i, length;\n-    if (isArrayLike(obj)) {\n-      for (i = 0, length = obj.length; i < length; i++) {\n-        iteratee(obj[i], i, obj);\n-      }\n-    } else {\n-      var _keys = keys(obj);\n-      for (i = 0, length = _keys.length; i < length; i++) {\n-        iteratee(obj[_keys[i]], _keys[i], obj);\n-      }\n-    }\n-    return obj;\n-  }\n-\n-  // Return the results of applying the iteratee to each element.\n-  function map(obj, iteratee, context) {\n-    iteratee = cb(iteratee, context);\n-    var _keys = !isArrayLike(obj) && keys(obj),\n-        length = (_keys || obj).length,\n-        results = Array(length);\n-    for (var index = 0; index < length; index++) {\n-      var currentKey = _keys ? _keys[index] : index;\n-      results[index] = iteratee(obj[currentKey], currentKey, obj);\n-    }\n-    return results;\n-  }\n-\n-  // Internal helper to create a reducing function, iterating left or right.\n-  function createReduce(dir) {\n-    // Wrap code that reassigns argument variables in a separate function than\n-    // the one that accesses `arguments.length` to avoid a perf hit. (#1991)\n-    var reducer = function(obj, iteratee, memo, initial) {\n-      var _keys = !isArrayLike(obj) && keys(obj),\n-          length = (_keys || obj).length,\n-          index = dir > 0 ? 0 : length - 1;\n-      if (!initial) {\n-        memo = obj[_keys ? _keys[index] : index];\n-        index += dir;\n-      }\n-      for (; index >= 0 && index < length; index += dir) {\n-        var currentKey = _keys ? _keys[index] : index;\n-        memo = iteratee(memo, obj[currentKey], currentKey, obj);\n-      }\n-      return memo;\n-    };\n-\n-    return function(obj, iteratee, memo, context) {\n-      var initial = arguments.length >= 3;\n-      return reducer(obj, optimizeCb(iteratee, context, 4), memo, initial);\n-    };\n-  }\n-\n-  // **Reduce** builds up a single result from a list of values, aka `inject`,\n-  // or `foldl`.\n-  var reduce = createReduce(1);\n-\n-  // The right-associative version of reduce, also known as `foldr`.\n-  var reduceRight = createReduce(-1);\n-\n-  // Return all the elements that pass a truth test.\n-  function filter(obj, predicate, context) {\n-    var results = [];\n-    predicate = cb(predicate, context);\n-    each(obj, function(value, index, list) {\n-      if (predicate(value, index, list)) results.push(value);\n-    });\n-    return results;\n-  }\n-\n-  // Return all the elements for which a truth test fails.\n-  function reject(obj, predicate, context) {\n-    return filter(obj, negate(cb(predicate)), context);\n-  }\n-\n-  // Determine whether all of the elements pass a truth test.\n-  function every(obj, predicate, context) {\n-    predicate = cb(predicate, context);\n-    var _keys = !isArrayLike(obj) && keys(obj),\n-        length = (_keys || obj).length;\n-    for (var index = 0; index < length; index++) {\n-      var currentKey = _keys ? _keys[index] : index;\n-      if (!predicate(obj[currentKey], currentKey, obj)) return false;\n-    }\n-    return true;\n-  }\n-\n-  // Determine if at least one element in the object passes a truth test.\n-  function some(obj, predicate, context) {\n-    predicate = cb(predicate, context);\n-    var _keys = !isArrayLike(obj) && keys(obj),\n-        length = (_keys || obj).length;\n-    for (var index = 0; index < length; index++) {\n-      var currentKey = _keys ? _keys[index] : index;\n-      if (predicate(obj[currentKey], currentKey, obj)) return true;\n-    }\n-    return false;\n-  }\n-\n-  // Determine if the array or object contains a given item (using `===`).\n-  function contains(obj, item, fromIndex, guard) {\n-    if (!isArrayLike(obj)) obj = values(obj);\n-    if (typeof fromIndex != 'number' || guard) fromIndex = 0;\n-    return indexOf(obj, item, fromIndex) >= 0;\n-  }\n-\n-  // Invoke a method (with arguments) on every item in a collection.\n-  var invoke = restArguments(function(obj, path, args) {\n-    var contextPath, func;\n-    if (isFunction$1(path)) {\n-      func = path;\n-    } else {\n-      path = toPath(path);\n-      contextPath = path.slice(0, -1);\n-      path = path[path.length - 1];\n-    }\n-    return map(obj, function(context) {\n-      var method = func;\n-      if (!method) {\n-        if (contextPath && contextPath.length) {\n-          context = deepGet(context, contextPath);\n-        }\n-        if (context == null) return void 0;\n-        method = context[path];\n-      }\n-      return method == null ? method : method.apply(context, args);\n-    });\n-  });\n-\n-  // Convenience version of a common use case of `_.map`: fetching a property.\n-  function pluck(obj, key) {\n-    return map(obj, property(key));\n-  }\n-\n-  // Convenience version of a common use case of `_.filter`: selecting only\n-  // objects containing specific `key:value` pairs.\n-  function where(obj, attrs) {\n-    return filter(obj, matcher(attrs));\n-  }\n-\n-  // Return the maximum element (or element-based computation).\n-  function max(obj, iteratee, context) {\n-    var result = -Infinity, lastComputed = -Infinity,\n-        value, computed;\n-    if (iteratee == null || typeof iteratee == 'number' && typeof obj[0] != 'object' && obj != null) {\n-      obj = isArrayLike(obj) ? obj : values(obj);\n-      for (var i = 0, length = obj.length; i < length; i++) {\n-        value = obj[i];\n-        if (value != null && value > result) {\n-          result = value;\n-        }\n-      }\n-    } else {\n-      iteratee = cb(iteratee, context);\n-      each(obj, function(v, index, list) {\n-        computed = iteratee(v, index, list);\n-        if (computed > lastComputed || computed === -Infinity && result === -Infinity) {\n-          result = v;\n-          lastComputed = computed;\n-        }\n-      });\n-    }\n-    return result;\n-  }\n-\n-  // Return the minimum element (or element-based computation).\n-  function min(obj, iteratee, context) {\n-    var result = Infinity, lastComputed = Infinity,\n-        value, computed;\n-    if (iteratee == null || typeof iteratee == 'number' && typeof obj[0] != 'object' && obj != null) {\n-      obj = isArrayLike(obj) ? obj : values(obj);\n-      for (var i = 0, length = obj.length; i < length; i++) {\n-        value = obj[i];\n-        if (value != null && value < result) {\n-          result = value;\n-        }\n-      }\n-    } else {\n-      iteratee = cb(iteratee, context);\n-      each(obj, function(v, index, list) {\n-        computed = iteratee(v, index, list);\n-        if (computed < lastComputed || computed === Infinity && result === Infinity) {\n-          result = v;\n-          lastComputed = computed;\n-        }\n-      });\n-    }\n-    return result;\n-  }\n-\n-  // Sample **n** random values from a collection using the modern version of the\n-  // [Fisher-Yates shuffle](https://en.wikipedia.org/wiki/Fisher\u2013Yates_shuffle).\n-  // If **n** is not specified, returns a single random element.\n-  // The internal `guard` argument allows it to work with `_.map`.\n-  function sample(obj, n, guard) {\n-    if (n == null || guard) {\n-      if (!isArrayLike(obj)) obj = values(obj);\n-      return obj[random(obj.length - 1)];\n-    }\n-    var sample = isArrayLike(obj) ? clone(obj) : values(obj);\n-    var length = getLength(sample);\n-    n = Math.max(Math.min(n, length), 0);\n-    var last = length - 1;\n-    for (var index = 0; index < n; index++) {\n-      var rand = random(index, last);\n-      var temp = sample[index];\n-      sample[index] = sample[rand];\n-      sample[rand] = temp;\n-    }\n-    return sample.slice(0, n);\n-  }\n-\n-  // Shuffle a collection.\n-  function shuffle(obj) {\n-    return sample(obj, Infinity);\n-  }\n-\n-  // Sort the object's values by a criterion produced by an iteratee.\n-  function sortBy(obj, iteratee, context) {\n-    var index = 0;\n-    iteratee = cb(iteratee, context);\n-    return pluck(map(obj, function(value, key, list) {\n-      return {\n-        value: value,\n-        index: index++,\n-        criteria: iteratee(value, key, list)\n-      };\n-    }).sort(function(left, right) {\n-      var a = left.criteria;\n-      var b = right.criteria;\n-      if (a !== b) {\n-        if (a > b || a === void 0) return 1;\n-        if (a < b || b === void 0) return -1;\n-      }\n-      return left.index - right.index;\n-    }), 'value');\n-  }\n-\n-  // An internal function used for aggregate \"group by\" operations.\n-  function group(behavior, partition) {\n-    return function(obj, iteratee, context) {\n-      var result = partition ? [[], []] : {};\n-      iteratee = cb(iteratee, context);\n-      each(obj, function(value, index) {\n-        var key = iteratee(value, index, obj);\n-        behavior(result, value, key);\n-      });\n-      return result;\n-    };\n-  }\n-\n-  // Groups the object's values by a criterion. Pass either a string attribute\n-  // to group by, or a function that returns the criterion.\n-  var groupBy = group(function(result, value, key) {\n-    if (has$1(result, key)) result[key].push(value); else result[key] = [value];\n-  });\n-\n-  // Indexes the object's values by a criterion, similar to `_.groupBy`, but for\n-  // when you know that your index values will be unique.\n-  var indexBy = group(function(result, value, key) {\n-    result[key] = value;\n-  });\n-\n-  // Counts instances of an object that group by a certain criterion. Pass\n-  // either a string attribute to count by, or a function that returns the\n-  // criterion.\n-  var countBy = group(function(result, value, key) {\n-    if (has$1(result, key)) result[key]++; else result[key] = 1;\n-  });\n-\n-  // Split a collection into two arrays: one whose elements all pass the given\n-  // truth test, and one whose elements all do not pass the truth test.\n-  var partition = group(function(result, value, pass) {\n-    result[pass ? 0 : 1].push(value);\n-  }, true);\n-\n-  // Safely create a real, live array from anything iterable.\n-  var reStrSymbol = /[^\\ud800-\\udfff]|[\\ud800-\\udbff][\\udc00-\\udfff]|[\\ud800-\\udfff]/g;\n-  function toArray(obj) {\n-    if (!obj) return [];\n-    if (isArray(obj)) return slice.call(obj);\n-    if (isString(obj)) {\n-      // Keep surrogate pair characters together.\n-      return obj.match(reStrSymbol);\n-    }\n-    if (isArrayLike(obj)) return map(obj, identity);\n-    return values(obj);\n-  }\n-\n-  // Return the number of elements in a collection.\n-  function size(obj) {\n-    if (obj == null) return 0;\n-    return isArrayLike(obj) ? obj.length : keys(obj).length;\n-  }\n-\n-  // Internal `_.pick` helper function to determine whether `key` is an enumerable\n-  // property name of `obj`.\n-  function keyInObj(value, key, obj) {\n-    return key in obj;\n-  }\n-\n-  // Return a copy of the object only containing the allowed properties.\n-  var pick = restArguments(function(obj, keys) {\n-    var result = {}, iteratee = keys[0];\n-    if (obj == null) return result;\n-    if (isFunction$1(iteratee)) {\n-      if (keys.length > 1) iteratee = optimizeCb(iteratee, keys[1]);\n-      keys = allKeys(obj);\n-    } else {\n-      iteratee = keyInObj;\n-      keys = flatten$1(keys, false, false);\n-      obj = Object(obj);\n-    }\n-    for (var i = 0, length = keys.length; i < length; i++) {\n-      var key = keys[i];\n-      var value = obj[key];\n-      if (iteratee(value, key, obj)) result[key] = value;\n-    }\n-    return result;\n-  });\n-\n-  // Return a copy of the object without the disallowed properties.\n-  var omit = restArguments(function(obj, keys) {\n-    var iteratee = keys[0], context;\n-    if (isFunction$1(iteratee)) {\n-      iteratee = negate(iteratee);\n-      if (keys.length > 1) context = keys[1];\n-    } else {\n-      keys = map(flatten$1(keys, false, false), String);\n-      iteratee = function(value, key) {\n-        return !contains(keys, key);\n-      };\n-    }\n-    return pick(obj, iteratee, context);\n-  });\n-\n-  // Returns everything but the last entry of the array. Especially useful on\n-  // the arguments object. Passing **n** will return all the values in\n-  // the array, excluding the last N.\n-  function initial(array, n, guard) {\n-    return slice.call(array, 0, Math.max(0, array.length - (n == null || guard ? 1 : n)));\n-  }\n-\n-  // Get the first element of an array. Passing **n** will return the first N\n-  // values in the array. The **guard** check allows it to work with `_.map`.\n-  function first(array, n, guard) {\n-    if (array == null || array.length < 1) return n == null || guard ? void 0 : [];\n-    if (n == null || guard) return array[0];\n-    return initial(array, array.length - n);\n-  }\n-\n-  // Returns everything but the first entry of the `array`. Especially useful on\n-  // the `arguments` object. Passing an **n** will return the rest N values in the\n-  // `array`.\n-  function rest(array, n, guard) {\n-    return slice.call(array, n == null || guard ? 1 : n);\n-  }\n-\n-  // Get the last element of an array. Passing **n** will return the last N\n-  // values in the array.\n-  function last(array, n, guard) {\n-    if (array == null || array.length < 1) return n == null || guard ? void 0 : [];\n-    if (n == null || guard) return array[array.length - 1];\n-    return rest(array, Math.max(0, array.length - n));\n-  }\n-\n-  // Trim out all falsy values from an array.\n-  function compact(array) {\n-    return filter(array, Boolean);\n-  }\n-\n-  // Flatten out an array, either recursively (by default), or up to `depth`.\n-  // Passing `true` or `false` as `depth` means `1` or `Infinity`, respectively.\n-  function flatten(array, depth) {\n-    return flatten$1(array, depth, false);\n-  }\n-\n-  // Take the difference between one array and a number of other arrays.\n-  // Only the elements present in just the first array will remain.\n-  var difference = restArguments(function(array, rest) {\n-    rest = flatten$1(rest, true, true);\n-    return filter(array, function(value){\n-      return !contains(rest, value);\n-    });\n-  });\n-\n-  // Return a version of the array that does not contain the specified value(s).\n-  var without = restArguments(function(array, otherArrays) {\n-    return difference(array, otherArrays);\n-  });\n-\n-  // Produce a duplicate-free version of the array. If the array has already\n-  // been sorted, you have the option of using a faster algorithm.\n-  // The faster algorithm will not work with an iteratee if the iteratee\n-  // is not a one-to-one function, so providing an iteratee will disable\n-  // the faster algorithm.\n-  function uniq(array, isSorted, iteratee, context) {\n-    if (!isBoolean(isSorted)) {\n-      context = iteratee;\n-      iteratee = isSorted;\n-      isSorted = false;\n-    }\n-    if (iteratee != null) iteratee = cb(iteratee, context);\n-    var result = [];\n-    var seen = [];\n-    for (var i = 0, length = getLength(array); i < length; i++) {\n-      var value = array[i],\n-          computed = iteratee ? iteratee(value, i, array) : value;\n-      if (isSorted && !iteratee) {\n-        if (!i || seen !== computed) result.push(value);\n-        seen = computed;\n-      } else if (iteratee) {\n-        if (!contains(seen, computed)) {\n-          seen.push(computed);\n-          result.push(value);\n-        }\n-      } else if (!contains(result, value)) {\n-        result.push(value);\n-      }\n-    }\n-    return result;\n-  }\n-\n-  // Produce an array that contains the union: each distinct element from all of\n-  // the passed-in arrays.\n-  var union = restArguments(function(arrays) {\n-    return uniq(flatten$1(arrays, true, true));\n-  });\n-\n-  // Produce an array that contains every item shared between all the\n-  // passed-in arrays.\n-  function intersection(array) {\n-    var result = [];\n-    var argsLength = arguments.length;\n-    for (var i = 0, length = getLength(array); i < length; i++) {\n-      var item = array[i];\n-      if (contains(result, item)) continue;\n-      var j;\n-      for (j = 1; j < argsLength; j++) {\n-        if (!contains(arguments[j], item)) break;\n-      }\n-      if (j === argsLength) result.push(item);\n-    }\n-    return result;\n-  }\n-\n-  // Complement of zip. Unzip accepts an array of arrays and groups\n-  // each array's elements on shared indices.\n-  function unzip(array) {\n-    var length = array && max(array, getLength).length || 0;\n-    var result = Array(length);\n-\n-    for (var index = 0; index < length; index++) {\n-      result[index] = pluck(array, index);\n-    }\n-    return result;\n-  }\n-\n-  // Zip together multiple lists into a single array -- elements that share\n-  // an index go together.\n-  var zip = restArguments(unzip);\n-\n-  // Converts lists into objects. Pass either a single array of `[key, value]`\n-  // pairs, or two parallel arrays of the same length -- one of keys, and one of\n-  // the corresponding values. Passing by pairs is the reverse of `_.pairs`.\n-  function object(list, values) {\n-    var result = {};\n-    for (var i = 0, length = getLength(list); i < length; i++) {\n-      if (values) {\n-        result[list[i]] = values[i];\n-      } else {\n-        result[list[i][0]] = list[i][1];\n-      }\n-    }\n-    return result;\n-  }\n-\n-  // Generate an integer Array containing an arithmetic progression. A port of\n-  // the native Python `range()` function. See\n-  // [the Python documentation](https://docs.python.org/library/functions.html#range).\n-  function range(start, stop, step) {\n-    if (stop == null) {\n-      stop = start || 0;\n-      start = 0;\n-    }\n-    if (!step) {\n-      step = stop < start ? -1 : 1;\n-    }\n-\n-    var length = Math.max(Math.ceil((stop - start) / step), 0);\n-    var range = Array(length);\n-\n-    for (var idx = 0; idx < length; idx++, start += step) {\n-      range[idx] = start;\n-    }\n-\n-    return range;\n-  }\n-\n-  // Chunk a single array into multiple arrays, each containing `count` or fewer\n-  // items.\n-  function chunk(array, count) {\n-    if (count == null || count < 1) return [];\n-    var result = [];\n-    var i = 0, length = array.length;\n-    while (i < length) {\n-      result.push(slice.call(array, i, i += count));\n-    }\n-    return result;\n-  }\n-\n-  // Helper function to continue chaining intermediate results.\n-  function chainResult(instance, obj) {\n-    return instance._chain ? _$1(obj).chain() : obj;\n-  }\n-\n-  // Add your own custom functions to the Underscore object.\n-  function mixin(obj) {\n-    each(functions(obj), function(name) {\n-      var func = _$1[name] = obj[name];\n-      _$1.prototype[name] = function() {\n-        var args = [this._wrapped];\n-        push.apply(args, arguments);\n-        return chainResult(this, func.apply(_$1, args));\n-      };\n-    });\n-    return _$1;\n-  }\n-\n-  // Add all mutator `Array` functions to the wrapper.\n-  each(['pop', 'push', 'reverse', 'shift', 'sort', 'splice', 'unshift'], function(name) {\n-    var method = ArrayProto[name];\n-    _$1.prototype[name] = function() {\n-      var obj = this._wrapped;\n-      if (obj != null) {\n-        method.apply(obj, arguments);\n-        if ((name === 'shift' || name === 'splice') && obj.length === 0) {\n-          delete obj[0];\n-        }\n-      }\n-      return chainResult(this, obj);\n-    };\n-  });\n-\n-  // Add all accessor `Array` functions to the wrapper.\n-  each(['concat', 'join', 'slice'], function(name) {\n-    var method = ArrayProto[name];\n-    _$1.prototype[name] = function() {\n-      var obj = this._wrapped;\n-      if (obj != null) obj = method.apply(obj, arguments);\n-      return chainResult(this, obj);\n-    };\n-  });\n-\n-  // Named Exports\n-\n-  var allExports = {\n-    __proto__: null,\n-    VERSION: VERSION,\n-    restArguments: restArguments,\n-    isObject: isObject,\n-    isNull: isNull,\n-    isUndefined: isUndefined,\n-    isBoolean: isBoolean,\n-    isElement: isElement,\n-    isString: isString,\n-    isNumber: isNumber,\n-    isDate: isDate,\n-    isRegExp: isRegExp,\n-    isError: isError,\n-    isSymbol: isSymbol,\n-    isArrayBuffer: isArrayBuffer,\n-    isDataView: isDataView$1,\n-    isArray: isArray,\n-    isFunction: isFunction$1,\n-    isArguments: isArguments$1,\n-    isFinite: isFinite$1,\n-    isNaN: isNaN$1,\n-    isTypedArray: isTypedArray$1,\n-    isEmpty: isEmpty,\n-    isMatch: isMatch,\n-    isEqual: isEqual,\n-    isMap: isMap,\n-    isWeakMap: isWeakMap,\n-    isSet: isSet,\n-    isWeakSet: isWeakSet,\n-    keys: keys,\n-    allKeys: allKeys,\n-    values: values,\n-    pairs: pairs,\n-    invert: invert,\n-    functions: functions,\n-    methods: functions,\n-    extend: extend,\n-    extendOwn: extendOwn,\n-    assign: extendOwn,\n-    defaults: defaults,\n-    create: create,\n-    clone: clone,\n-    tap: tap,\n-    get: get,\n-    has: has,\n-    mapObject: mapObject,\n-    identity: identity,\n-    constant: constant,\n-    noop: noop,\n-    toPath: toPath$1,\n-    property: property,\n-    propertyOf: propertyOf,\n-    matcher: matcher,\n-    matches: matcher,\n-    times: times,\n-    random: random,\n-    now: now,\n-    escape: _escape,\n-    unescape: _unescape,\n-    templateSettings: templateSettings,\n-    template: template,\n-    result: result,\n-    uniqueId: uniqueId,\n-    chain: chain,\n-    iteratee: iteratee,\n-    partial: partial,\n-    bind: bind,\n-    bindAll: bindAll,\n-    memoize: memoize,\n-    delay: delay,\n-    defer: defer,\n-    throttle: throttle,\n-    debounce: debounce,\n-    wrap: wrap,\n-    negate: negate,\n-    compose: compose,\n-    after: after,\n-    before: before,\n-    once: once,\n-    findKey: findKey,\n-    findIndex: findIndex,\n-    findLastIndex: findLastIndex,\n-    sortedIndex: sortedIndex,\n-    indexOf: indexOf,\n-    lastIndexOf: lastIndexOf,\n-    find: find,\n-    detect: find,\n-    findWhere: findWhere,\n-    each: each,\n-    forEach: each,\n-    map: map,\n-    collect: map,\n-    reduce: reduce,\n-    foldl: reduce,\n-    inject: reduce,\n-    reduceRight: reduceRight,\n-    foldr: reduceRight,\n-    filter: filter,\n-    select: filter,\n-    reject: reject,\n-    every: every,\n-    all: every,\n-    some: some,\n-    any: some,\n-    contains: contains,\n-    includes: contains,\n-    include: contains,\n-    invoke: invoke,\n-    pluck: pluck,\n-    where: where,\n-    max: max,\n-    min: min,\n-    shuffle: shuffle,\n-    sample: sample,\n-    sortBy: sortBy,\n-    groupBy: groupBy,\n-    indexBy: indexBy,\n-    countBy: countBy,\n-    partition: partition,\n-    toArray: toArray,\n-    size: size,\n-    pick: pick,\n-    omit: omit,\n-    first: first,\n-    head: first,\n-    take: first,\n-    initial: initial,\n-    last: last,\n-    rest: rest,\n-    tail: rest,\n-    drop: rest,\n-    compact: compact,\n-    flatten: flatten,\n-    without: without,\n-    uniq: uniq,\n-    unique: uniq,\n-    union: union,\n-    intersection: intersection,\n-    difference: difference,\n-    unzip: unzip,\n-    transpose: unzip,\n-    zip: zip,\n-    object: object,\n-    range: range,\n-    chunk: chunk,\n-    mixin: mixin,\n-    'default': _$1\n-  };\n-\n-  // Default Export\n-\n-  // Add all of the Underscore functions to the wrapper object.\n-  var _ = mixin(allExports);\n-  // Legacy Node.js API.\n-  _._ = _;\n-\n-  return _;\n-\n-})));\n-//# sourceMappingURL=underscore-umd.js.map"}, {"filename": "master/_static/underscore.js", "status": "removed", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -1,6 +0,0 @@\n-!function(n,r){\"object\"==typeof exports&&\"undefined\"!=typeof module?module.exports=r():\"function\"==typeof define&&define.amd?define(\"underscore\",r):(n=\"undefined\"!=typeof globalThis?globalThis:n||self,function(){var t=n._,e=n._=r();e.noConflict=function(){return n._=t,e}}())}(this,(function(){\n-//     Underscore.js 1.13.1\n-//     https://underscorejs.org\n-//     (c) 2009-2021 Jeremy Ashkenas, Julian Gonggrijp, and DocumentCloud and Investigative Reporters & Editors\n-//     Underscore may be freely distributed under the MIT license.\n-var n=\"1.13.1\",r=\"object\"==typeof self&&self.self===self&&self||\"object\"==typeof global&&global.global===global&&global||Function(\"return this\")()||{},t=Array.prototype,e=Object.prototype,u=\"undefined\"!=typeof Symbol?Symbol.prototype:null,o=t.push,i=t.slice,a=e.toString,f=e.hasOwnProperty,c=\"undefined\"!=typeof ArrayBuffer,l=\"undefined\"!=typeof DataView,s=Array.isArray,p=Object.keys,v=Object.create,h=c&&ArrayBuffer.isView,y=isNaN,d=isFinite,g=!{toString:null}.propertyIsEnumerable(\"toString\"),b=[\"valueOf\",\"isPrototypeOf\",\"toString\",\"propertyIsEnumerable\",\"hasOwnProperty\",\"toLocaleString\"],m=Math.pow(2,53)-1;function j(n,r){return r=null==r?n.length-1:+r,function(){for(var t=Math.max(arguments.length-r,0),e=Array(t),u=0;u<t;u++)e[u]=arguments[u+r];switch(r){case 0:return n.call(this,e);case 1:return n.call(this,arguments[0],e);case 2:return n.call(this,arguments[0],arguments[1],e)}var o=Array(r+1);for(u=0;u<r;u++)o[u]=arguments[u];return o[r]=e,n.apply(this,o)}}function _(n){var r=typeof n;return\"function\"===r||\"object\"===r&&!!n}function w(n){return void 0===n}function A(n){return!0===n||!1===n||\"[object Boolean]\"===a.call(n)}function x(n){var r=\"[object \"+n+\"]\";return function(n){return a.call(n)===r}}var S=x(\"String\"),O=x(\"Number\"),M=x(\"Date\"),E=x(\"RegExp\"),B=x(\"Error\"),N=x(\"Symbol\"),I=x(\"ArrayBuffer\"),T=x(\"Function\"),k=r.document&&r.document.childNodes;\"function\"!=typeof/./&&\"object\"!=typeof Int8Array&&\"function\"!=typeof k&&(T=function(n){return\"function\"==typeof n||!1});var D=T,R=x(\"Object\"),F=l&&R(new DataView(new ArrayBuffer(8))),V=\"undefined\"!=typeof Map&&R(new Map),P=x(\"DataView\");var q=F?function(n){return null!=n&&D(n.getInt8)&&I(n.buffer)}:P,U=s||x(\"Array\");function W(n,r){return null!=n&&f.call(n,r)}var z=x(\"Arguments\");!function(){z(arguments)||(z=function(n){return W(n,\"callee\")})}();var L=z;function $(n){return O(n)&&y(n)}function C(n){return function(){return n}}function K(n){return function(r){var t=n(r);return\"number\"==typeof t&&t>=0&&t<=m}}function J(n){return function(r){return null==r?void 0:r[n]}}var G=J(\"byteLength\"),H=K(G),Q=/\\[object ((I|Ui)nt(8|16|32)|Float(32|64)|Uint8Clamped|Big(I|Ui)nt64)Array\\]/;var X=c?function(n){return h?h(n)&&!q(n):H(n)&&Q.test(a.call(n))}:C(!1),Y=J(\"length\");function Z(n,r){r=function(n){for(var r={},t=n.length,e=0;e<t;++e)r[n[e]]=!0;return{contains:function(n){return r[n]},push:function(t){return r[t]=!0,n.push(t)}}}(r);var t=b.length,u=n.constructor,o=D(u)&&u.prototype||e,i=\"constructor\";for(W(n,i)&&!r.contains(i)&&r.push(i);t--;)(i=b[t])in n&&n[i]!==o[i]&&!r.contains(i)&&r.push(i)}function nn(n){if(!_(n))return[];if(p)return p(n);var r=[];for(var t in n)W(n,t)&&r.push(t);return g&&Z(n,r),r}function rn(n,r){var t=nn(r),e=t.length;if(null==n)return!e;for(var u=Object(n),o=0;o<e;o++){var i=t[o];if(r[i]!==u[i]||!(i in u))return!1}return!0}function tn(n){return n instanceof tn?n:this instanceof tn?void(this._wrapped=n):new tn(n)}function en(n){return new Uint8Array(n.buffer||n,n.byteOffset||0,G(n))}tn.VERSION=n,tn.prototype.value=function(){return this._wrapped},tn.prototype.valueOf=tn.prototype.toJSON=tn.prototype.value,tn.prototype.toString=function(){return String(this._wrapped)};var un=\"[object DataView]\";function on(n,r,t,e){if(n===r)return 0!==n||1/n==1/r;if(null==n||null==r)return!1;if(n!=n)return r!=r;var o=typeof n;return(\"function\"===o||\"object\"===o||\"object\"==typeof r)&&function n(r,t,e,o){r instanceof tn&&(r=r._wrapped);t instanceof tn&&(t=t._wrapped);var i=a.call(r);if(i!==a.call(t))return!1;if(F&&\"[object Object]\"==i&&q(r)){if(!q(t))return!1;i=un}switch(i){case\"[object RegExp]\":case\"[object String]\":return\"\"+r==\"\"+t;case\"[object Number]\":return+r!=+r?+t!=+t:0==+r?1/+r==1/t:+r==+t;case\"[object Date]\":case\"[object Boolean]\":return+r==+t;case\"[object Symbol]\":return u.valueOf.call(r)===u.valueOf.call(t);case\"[object ArrayBuffer]\":case un:return n(en(r),en(t),e,o)}var f=\"[object Array]\"===i;if(!f&&X(r)){if(G(r)!==G(t))return!1;if(r.buffer===t.buffer&&r.byteOffset===t.byteOffset)return!0;f=!0}if(!f){if(\"object\"!=typeof r||\"object\"!=typeof t)return!1;var c=r.constructor,l=t.constructor;if(c!==l&&!(D(c)&&c instanceof c&&D(l)&&l instanceof l)&&\"constructor\"in r&&\"constructor\"in t)return!1}o=o||[];var s=(e=e||[]).length;for(;s--;)if(e[s]===r)return o[s]===t;if(e.push(r),o.push(t),f){if((s=r.length)!==t.length)return!1;for(;s--;)if(!on(r[s],t[s],e,o))return!1}else{var p,v=nn(r);if(s=v.length,nn(t).length!==s)return!1;for(;s--;)if(p=v[s],!W(t,p)||!on(r[p],t[p],e,o))return!1}return e.pop(),o.pop(),!0}(n,r,t,e)}function an(n){if(!_(n))return[];var r=[];for(var t in n)r.push(t);return g&&Z(n,r),r}function fn(n){var r=Y(n);return function(t){if(null==t)return!1;var e=an(t);if(Y(e))return!1;for(var u=0;u<r;u++)if(!D(t[n[u]]))return!1;return n!==hn||!D(t[cn])}}var cn=\"forEach\",ln=\"has\",sn=[\"clear\",\"delete\"],pn=[\"get\",ln,\"set\"],vn=sn.concat(cn,pn),hn=sn.concat(pn),yn=[\"add\"].concat(sn,cn,ln),dn=V?fn(vn):x(\"Map\"),gn=V?fn(hn):x(\"WeakMap\"),bn=V?fn(yn):x(\"Set\"),mn=x(\"WeakSet\");function jn(n){for(var r=nn(n),t=r.length,e=Array(t),u=0;u<t;u++)e[u]=n[r[u]];return e}function _n(n){for(var r={},t=nn(n),e=0,u=t.length;e<u;e++)r[n[t[e]]]=t[e];return r}function wn(n){var r=[];for(var t in n)D(n[t])&&r.push(t);return r.sort()}function An(n,r){return function(t){var e=arguments.length;if(r&&(t=Object(t)),e<2||null==t)return t;for(var u=1;u<e;u++)for(var o=arguments[u],i=n(o),a=i.length,f=0;f<a;f++){var c=i[f];r&&void 0!==t[c]||(t[c]=o[c])}return t}}var xn=An(an),Sn=An(nn),On=An(an,!0);function Mn(n){if(!_(n))return{};if(v)return v(n);var r=function(){};r.prototype=n;var t=new r;return r.prototype=null,t}function En(n){return _(n)?U(n)?n.slice():xn({},n):n}function Bn(n){return U(n)?n:[n]}function Nn(n){return tn.toPath(n)}function In(n,r){for(var t=r.length,e=0;e<t;e++){if(null==n)return;n=n[r[e]]}return t?n:void 0}function Tn(n,r,t){var e=In(n,Nn(r));return w(e)?t:e}function kn(n){return n}function Dn(n){return n=Sn({},n),function(r){return rn(r,n)}}function Rn(n){return n=Nn(n),function(r){return In(r,n)}}function Fn(n,r,t){if(void 0===r)return n;switch(null==t?3:t){case 1:return function(t){return n.call(r,t)};case 3:return function(t,e,u){return n.call(r,t,e,u)};case 4:return function(t,e,u,o){return n.call(r,t,e,u,o)}}return function(){return n.apply(r,arguments)}}function Vn(n,r,t){return null==n?kn:D(n)?Fn(n,r,t):_(n)&&!U(n)?Dn(n):Rn(n)}function Pn(n,r){return Vn(n,r,1/0)}function qn(n,r,t){return tn.iteratee!==Pn?tn.iteratee(n,r):Vn(n,r,t)}function Un(){}function Wn(n,r){return null==r&&(r=n,n=0),n+Math.floor(Math.random()*(r-n+1))}tn.toPath=Bn,tn.iteratee=Pn;var zn=Date.now||function(){return(new Date).getTime()};function Ln(n){var r=function(r){return n[r]},t=\"(?:\"+nn(n).join(\"|\")+\")\",e=RegExp(t),u=RegExp(t,\"g\");return function(n){return n=null==n?\"\":\"\"+n,e.test(n)?n.replace(u,r):n}}var $n={\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\",'\"':\"&quot;\",\"'\":\"&#x27;\",\"`\":\"&#x60;\"},Cn=Ln($n),Kn=Ln(_n($n)),Jn=tn.templateSettings={evaluate:/<%([\\s\\S]+?)%>/g,interpolate:/<%=([\\s\\S]+?)%>/g,escape:/<%-([\\s\\S]+?)%>/g},Gn=/(.)^/,Hn={\"'\":\"'\",\"\\\\\":\"\\\\\",\"\\r\":\"r\",\"\\n\":\"n\",\"\\u2028\":\"u2028\",\"\\u2029\":\"u2029\"},Qn=/\\\\|'|\\r|\\n|\\u2028|\\u2029/g;function Xn(n){return\"\\\\\"+Hn[n]}var Yn=/^\\s*(\\w|\\$)+\\s*$/;var Zn=0;function nr(n,r,t,e,u){if(!(e instanceof r))return n.apply(t,u);var o=Mn(n.prototype),i=n.apply(o,u);return _(i)?i:o}var rr=j((function(n,r){var t=rr.placeholder,e=function(){for(var u=0,o=r.length,i=Array(o),a=0;a<o;a++)i[a]=r[a]===t?arguments[u++]:r[a];for(;u<arguments.length;)i.push(arguments[u++]);return nr(n,e,this,this,i)};return e}));rr.placeholder=tn;var tr=j((function(n,r,t){if(!D(n))throw new TypeError(\"Bind must be called on a function\");var e=j((function(u){return nr(n,e,r,this,t.concat(u))}));return e})),er=K(Y);function ur(n,r,t,e){if(e=e||[],r||0===r){if(r<=0)return e.concat(n)}else r=1/0;for(var u=e.length,o=0,i=Y(n);o<i;o++){var a=n[o];if(er(a)&&(U(a)||L(a)))if(r>1)ur(a,r-1,t,e),u=e.length;else for(var f=0,c=a.length;f<c;)e[u++]=a[f++];else t||(e[u++]=a)}return e}var or=j((function(n,r){var t=(r=ur(r,!1,!1)).length;if(t<1)throw new Error(\"bindAll must be passed function names\");for(;t--;){var e=r[t];n[e]=tr(n[e],n)}return n}));var ir=j((function(n,r,t){return setTimeout((function(){return n.apply(null,t)}),r)})),ar=rr(ir,tn,1);function fr(n){return function(){return!n.apply(this,arguments)}}function cr(n,r){var t;return function(){return--n>0&&(t=r.apply(this,arguments)),n<=1&&(r=null),t}}var lr=rr(cr,2);function sr(n,r,t){r=qn(r,t);for(var e,u=nn(n),o=0,i=u.length;o<i;o++)if(r(n[e=u[o]],e,n))return e}function pr(n){return function(r,t,e){t=qn(t,e);for(var u=Y(r),o=n>0?0:u-1;o>=0&&o<u;o+=n)if(t(r[o],o,r))return o;return-1}}var vr=pr(1),hr=pr(-1);function yr(n,r,t,e){for(var u=(t=qn(t,e,1))(r),o=0,i=Y(n);o<i;){var a=Math.floor((o+i)/2);t(n[a])<u?o=a+1:i=a}return o}function dr(n,r,t){return function(e,u,o){var a=0,f=Y(e);if(\"number\"==typeof o)n>0?a=o>=0?o:Math.max(o+f,a):f=o>=0?Math.min(o+1,f):o+f+1;else if(t&&o&&f)return e[o=t(e,u)]===u?o:-1;if(u!=u)return(o=r(i.call(e,a,f),$))>=0?o+a:-1;for(o=n>0?a:f-1;o>=0&&o<f;o+=n)if(e[o]===u)return o;return-1}}var gr=dr(1,vr,yr),br=dr(-1,hr);function mr(n,r,t){var e=(er(n)?vr:sr)(n,r,t);if(void 0!==e&&-1!==e)return n[e]}function jr(n,r,t){var e,u;if(r=Fn(r,t),er(n))for(e=0,u=n.length;e<u;e++)r(n[e],e,n);else{var o=nn(n);for(e=0,u=o.length;e<u;e++)r(n[o[e]],o[e],n)}return n}function _r(n,r,t){r=qn(r,t);for(var e=!er(n)&&nn(n),u=(e||n).length,o=Array(u),i=0;i<u;i++){var a=e?e[i]:i;o[i]=r(n[a],a,n)}return o}function wr(n){var r=function(r,t,e,u){var o=!er(r)&&nn(r),i=(o||r).length,a=n>0?0:i-1;for(u||(e=r[o?o[a]:a],a+=n);a>=0&&a<i;a+=n){var f=o?o[a]:a;e=t(e,r[f],f,r)}return e};return function(n,t,e,u){var o=arguments.length>=3;return r(n,Fn(t,u,4),e,o)}}var Ar=wr(1),xr=wr(-1);function Sr(n,r,t){var e=[];return r=qn(r,t),jr(n,(function(n,t,u){r(n,t,u)&&e.push(n)})),e}function Or(n,r,t){r=qn(r,t);for(var e=!er(n)&&nn(n),u=(e||n).length,o=0;o<u;o++){var i=e?e[o]:o;if(!r(n[i],i,n))return!1}return!0}function Mr(n,r,t){r=qn(r,t);for(var e=!er(n)&&nn(n),u=(e||n).length,o=0;o<u;o++){var i=e?e[o]:o;if(r(n[i],i,n))return!0}return!1}function Er(n,r,t,e){return er(n)||(n=jn(n)),(\"number\"!=typeof t||e)&&(t=0),gr(n,r,t)>=0}var Br=j((function(n,r,t){var e,u;return D(r)?u=r:(r=Nn(r),e=r.slice(0,-1),r=r[r.length-1]),_r(n,(function(n){var o=u;if(!o){if(e&&e.length&&(n=In(n,e)),null==n)return;o=n[r]}return null==o?o:o.apply(n,t)}))}));function Nr(n,r){return _r(n,Rn(r))}function Ir(n,r,t){var e,u,o=-1/0,i=-1/0;if(null==r||\"number\"==typeof r&&\"object\"!=typeof n[0]&&null!=n)for(var a=0,f=(n=er(n)?n:jn(n)).length;a<f;a++)null!=(e=n[a])&&e>o&&(o=e);else r=qn(r,t),jr(n,(function(n,t,e){((u=r(n,t,e))>i||u===-1/0&&o===-1/0)&&(o=n,i=u)}));return o}function Tr(n,r,t){if(null==r||t)return er(n)||(n=jn(n)),n[Wn(n.length-1)];var e=er(n)?En(n):jn(n),u=Y(e);r=Math.max(Math.min(r,u),0);for(var o=u-1,i=0;i<r;i++){var a=Wn(i,o),f=e[i];e[i]=e[a],e[a]=f}return e.slice(0,r)}function kr(n,r){return function(t,e,u){var o=r?[[],[]]:{};return e=qn(e,u),jr(t,(function(r,u){var i=e(r,u,t);n(o,r,i)})),o}}var Dr=kr((function(n,r,t){W(n,t)?n[t].push(r):n[t]=[r]})),Rr=kr((function(n,r,t){n[t]=r})),Fr=kr((function(n,r,t){W(n,t)?n[t]++:n[t]=1})),Vr=kr((function(n,r,t){n[t?0:1].push(r)}),!0),Pr=/[^\\ud800-\\udfff]|[\\ud800-\\udbff][\\udc00-\\udfff]|[\\ud800-\\udfff]/g;function qr(n,r,t){return r in t}var Ur=j((function(n,r){var t={},e=r[0];if(null==n)return t;D(e)?(r.length>1&&(e=Fn(e,r[1])),r=an(n)):(e=qr,r=ur(r,!1,!1),n=Object(n));for(var u=0,o=r.length;u<o;u++){var i=r[u],a=n[i];e(a,i,n)&&(t[i]=a)}return t})),Wr=j((function(n,r){var t,e=r[0];return D(e)?(e=fr(e),r.length>1&&(t=r[1])):(r=_r(ur(r,!1,!1),String),e=function(n,t){return!Er(r,t)}),Ur(n,e,t)}));function zr(n,r,t){return i.call(n,0,Math.max(0,n.length-(null==r||t?1:r)))}function Lr(n,r,t){return null==n||n.length<1?null==r||t?void 0:[]:null==r||t?n[0]:zr(n,n.length-r)}function $r(n,r,t){return i.call(n,null==r||t?1:r)}var Cr=j((function(n,r){return r=ur(r,!0,!0),Sr(n,(function(n){return!Er(r,n)}))})),Kr=j((function(n,r){return Cr(n,r)}));function Jr(n,r,t,e){A(r)||(e=t,t=r,r=!1),null!=t&&(t=qn(t,e));for(var u=[],o=[],i=0,a=Y(n);i<a;i++){var f=n[i],c=t?t(f,i,n):f;r&&!t?(i&&o===c||u.push(f),o=c):t?Er(o,c)||(o.push(c),u.push(f)):Er(u,f)||u.push(f)}return u}var Gr=j((function(n){return Jr(ur(n,!0,!0))}));function Hr(n){for(var r=n&&Ir(n,Y).length||0,t=Array(r),e=0;e<r;e++)t[e]=Nr(n,e);return t}var Qr=j(Hr);function Xr(n,r){return n._chain?tn(r).chain():r}function Yr(n){return jr(wn(n),(function(r){var t=tn[r]=n[r];tn.prototype[r]=function(){var n=[this._wrapped];return o.apply(n,arguments),Xr(this,t.apply(tn,n))}})),tn}jr([\"pop\",\"push\",\"reverse\",\"shift\",\"sort\",\"splice\",\"unshift\"],(function(n){var r=t[n];tn.prototype[n]=function(){var t=this._wrapped;return null!=t&&(r.apply(t,arguments),\"shift\"!==n&&\"splice\"!==n||0!==t.length||delete t[0]),Xr(this,t)}})),jr([\"concat\",\"join\",\"slice\"],(function(n){var r=t[n];tn.prototype[n]=function(){var n=this._wrapped;return null!=n&&(n=r.apply(n,arguments)),Xr(this,n)}}));var Zr=Yr({__proto__:null,VERSION:n,restArguments:j,isObject:_,isNull:function(n){return null===n},isUndefined:w,isBoolean:A,isElement:function(n){return!(!n||1!==n.nodeType)},isString:S,isNumber:O,isDate:M,isRegExp:E,isError:B,isSymbol:N,isArrayBuffer:I,isDataView:q,isArray:U,isFunction:D,isArguments:L,isFinite:function(n){return!N(n)&&d(n)&&!isNaN(parseFloat(n))},isNaN:$,isTypedArray:X,isEmpty:function(n){if(null==n)return!0;var r=Y(n);return\"number\"==typeof r&&(U(n)||S(n)||L(n))?0===r:0===Y(nn(n))},isMatch:rn,isEqual:function(n,r){return on(n,r)},isMap:dn,isWeakMap:gn,isSet:bn,isWeakSet:mn,keys:nn,allKeys:an,values:jn,pairs:function(n){for(var r=nn(n),t=r.length,e=Array(t),u=0;u<t;u++)e[u]=[r[u],n[r[u]]];return e},invert:_n,functions:wn,methods:wn,extend:xn,extendOwn:Sn,assign:Sn,defaults:On,create:function(n,r){var t=Mn(n);return r&&Sn(t,r),t},clone:En,tap:function(n,r){return r(n),n},get:Tn,has:function(n,r){for(var t=(r=Nn(r)).length,e=0;e<t;e++){var u=r[e];if(!W(n,u))return!1;n=n[u]}return!!t},mapObject:function(n,r,t){r=qn(r,t);for(var e=nn(n),u=e.length,o={},i=0;i<u;i++){var a=e[i];o[a]=r(n[a],a,n)}return o},identity:kn,constant:C,noop:Un,toPath:Bn,property:Rn,propertyOf:function(n){return null==n?Un:function(r){return Tn(n,r)}},matcher:Dn,matches:Dn,times:function(n,r,t){var e=Array(Math.max(0,n));r=Fn(r,t,1);for(var u=0;u<n;u++)e[u]=r(u);return e},random:Wn,now:zn,escape:Cn,unescape:Kn,templateSettings:Jn,template:function(n,r,t){!r&&t&&(r=t),r=On({},r,tn.templateSettings);var e=RegExp([(r.escape||Gn).source,(r.interpolate||Gn).source,(r.evaluate||Gn).source].join(\"|\")+\"|$\",\"g\"),u=0,o=\"__p+='\";n.replace(e,(function(r,t,e,i,a){return o+=n.slice(u,a).replace(Qn,Xn),u=a+r.length,t?o+=\"'+\\n((__t=(\"+t+\"))==null?'':_.escape(__t))+\\n'\":e?o+=\"'+\\n((__t=(\"+e+\"))==null?'':__t)+\\n'\":i&&(o+=\"';\\n\"+i+\"\\n__p+='\"),r})),o+=\"';\\n\";var i,a=r.variable;if(a){if(!Yn.test(a))throw new Error(\"variable is not a bare identifier: \"+a)}else o=\"with(obj||{}){\\n\"+o+\"}\\n\",a=\"obj\";o=\"var __t,__p='',__j=Array.prototype.join,\"+\"print=function(){__p+=__j.call(arguments,'');};\\n\"+o+\"return __p;\\n\";try{i=new Function(a,\"_\",o)}catch(n){throw n.source=o,n}var f=function(n){return i.call(this,n,tn)};return f.source=\"function(\"+a+\"){\\n\"+o+\"}\",f},result:function(n,r,t){var e=(r=Nn(r)).length;if(!e)return D(t)?t.call(n):t;for(var u=0;u<e;u++){var o=null==n?void 0:n[r[u]];void 0===o&&(o=t,u=e),n=D(o)?o.call(n):o}return n},uniqueId:function(n){var r=++Zn+\"\";return n?n+r:r},chain:function(n){var r=tn(n);return r._chain=!0,r},iteratee:Pn,partial:rr,bind:tr,bindAll:or,memoize:function(n,r){var t=function(e){var u=t.cache,o=\"\"+(r?r.apply(this,arguments):e);return W(u,o)||(u[o]=n.apply(this,arguments)),u[o]};return t.cache={},t},delay:ir,defer:ar,throttle:function(n,r,t){var e,u,o,i,a=0;t||(t={});var f=function(){a=!1===t.leading?0:zn(),e=null,i=n.apply(u,o),e||(u=o=null)},c=function(){var c=zn();a||!1!==t.leading||(a=c);var l=r-(c-a);return u=this,o=arguments,l<=0||l>r?(e&&(clearTimeout(e),e=null),a=c,i=n.apply(u,o),e||(u=o=null)):e||!1===t.trailing||(e=setTimeout(f,l)),i};return c.cancel=function(){clearTimeout(e),a=0,e=u=o=null},c},debounce:function(n,r,t){var e,u,o,i,a,f=function(){var c=zn()-u;r>c?e=setTimeout(f,r-c):(e=null,t||(i=n.apply(a,o)),e||(o=a=null))},c=j((function(c){return a=this,o=c,u=zn(),e||(e=setTimeout(f,r),t&&(i=n.apply(a,o))),i}));return c.cancel=function(){clearTimeout(e),e=o=a=null},c},wrap:function(n,r){return rr(r,n)},negate:fr,compose:function(){var n=arguments,r=n.length-1;return function(){for(var t=r,e=n[r].apply(this,arguments);t--;)e=n[t].call(this,e);return e}},after:function(n,r){return function(){if(--n<1)return r.apply(this,arguments)}},before:cr,once:lr,findKey:sr,findIndex:vr,findLastIndex:hr,sortedIndex:yr,indexOf:gr,lastIndexOf:br,find:mr,detect:mr,findWhere:function(n,r){return mr(n,Dn(r))},each:jr,forEach:jr,map:_r,collect:_r,reduce:Ar,foldl:Ar,inject:Ar,reduceRight:xr,foldr:xr,filter:Sr,select:Sr,reject:function(n,r,t){return Sr(n,fr(qn(r)),t)},every:Or,all:Or,some:Mr,any:Mr,contains:Er,includes:Er,include:Er,invoke:Br,pluck:Nr,where:function(n,r){return Sr(n,Dn(r))},max:Ir,min:function(n,r,t){var e,u,o=1/0,i=1/0;if(null==r||\"number\"==typeof r&&\"object\"!=typeof n[0]&&null!=n)for(var a=0,f=(n=er(n)?n:jn(n)).length;a<f;a++)null!=(e=n[a])&&e<o&&(o=e);else r=qn(r,t),jr(n,(function(n,t,e){((u=r(n,t,e))<i||u===1/0&&o===1/0)&&(o=n,i=u)}));return o},shuffle:function(n){return Tr(n,1/0)},sample:Tr,sortBy:function(n,r,t){var e=0;return r=qn(r,t),Nr(_r(n,(function(n,t,u){return{value:n,index:e++,criteria:r(n,t,u)}})).sort((function(n,r){var t=n.criteria,e=r.criteria;if(t!==e){if(t>e||void 0===t)return 1;if(t<e||void 0===e)return-1}return n.index-r.index})),\"value\")},groupBy:Dr,indexBy:Rr,countBy:Fr,partition:Vr,toArray:function(n){return n?U(n)?i.call(n):S(n)?n.match(Pr):er(n)?_r(n,kn):jn(n):[]},size:function(n){return null==n?0:er(n)?n.length:nn(n).length},pick:Ur,omit:Wr,first:Lr,head:Lr,take:Lr,initial:zr,last:function(n,r,t){return null==n||n.length<1?null==r||t?void 0:[]:null==r||t?n[n.length-1]:$r(n,Math.max(0,n.length-r))},rest:$r,tail:$r,drop:$r,compact:function(n){return Sr(n,Boolean)},flatten:function(n,r){return ur(n,r,!1)},without:Kr,uniq:Jr,unique:Jr,union:Gr,intersection:function(n){for(var r=[],t=arguments.length,e=0,u=Y(n);e<u;e++){var o=n[e];if(!Er(r,o)){var i;for(i=1;i<t&&Er(arguments[i],o);i++);i===t&&r.push(o)}}return r},difference:Cr,unzip:Hr,transpose:Hr,zip:Qr,object:function(n,r){for(var t={},e=0,u=Y(n);e<u;e++)r?t[n[e]]=r[e]:t[n[e][0]]=n[e][1];return t},range:function(n,r,t){null==r&&(r=n||0,n=0),t||(t=r<n?-1:1);for(var e=Math.max(Math.ceil((r-n)/t),0),u=Array(e),o=0;o<e;o++,n+=t)u[o]=n;return u},chunk:function(n,r){if(null==r||r<1)return[];for(var t=[],e=0,u=n.length;e<u;)t.push(i.call(n,e,e+=r));return t},mixin:Yr,default:tn});return Zr._=Zr,Zr}));\n\\ No newline at end of file"}, {"filename": "master/genindex.html", "status": "removed", "additions": 0, "deletions": 457, "changes": 457, "file_content_changes": "@@ -1,457 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Index &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"./\" src=\"_static/documentation_options.js\"></script>\n-        <script data-url_root=\"./\" id=\"documentation_options\" src=\"_static/documentation_options.js\"></script>\n-        <script src=\"_static/jquery.js\"></script>\n-        <script src=\"_static/underscore.js\"></script>\n-        <script src=\"_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"#\" />\n-    <link rel=\"search\" title=\"Search\" href=\"search.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-      <li>Index</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-\n-<h1 id=\"index\">Index</h1>\n-\n-<div class=\"genindex-jumpbox\">\n- <a href=\"#_\"><strong>_</strong></a>\n- | <a href=\"#A\"><strong>A</strong></a>\n- | <a href=\"#B\"><strong>B</strong></a>\n- | <a href=\"#C\"><strong>C</strong></a>\n- | <a href=\"#D\"><strong>D</strong></a>\n- | <a href=\"#E\"><strong>E</strong></a>\n- | <a href=\"#H\"><strong>H</strong></a>\n- | <a href=\"#J\"><strong>J</strong></a>\n- | <a href=\"#L\"><strong>L</strong></a>\n- | <a href=\"#M\"><strong>M</strong></a>\n- | <a href=\"#N\"><strong>N</strong></a>\n- | <a href=\"#P\"><strong>P</strong></a>\n- | <a href=\"#R\"><strong>R</strong></a>\n- | <a href=\"#S\"><strong>S</strong></a>\n- | <a href=\"#W\"><strong>W</strong></a>\n- | <a href=\"#Z\"><strong>Z</strong></a>\n- \n-</div>\n-<h2 id=\"_\">_</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.Config.html#triton.Config.__init__\">__init__() (triton.Config method)</a>\n-\n-      <ul>\n-        <li><a href=\"python-api/generated/triton.testing.Benchmark.html#triton.testing.Benchmark.__init__\">(triton.testing.Benchmark method)</a>\n-</li>\n-      </ul></li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"A\">A</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.arange.html#triton.language.arange\">arange() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.atomic_add.html#triton.language.atomic_add\">atomic_add() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.atomic_cas.html#triton.language.atomic_cas\">atomic_cas() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.atomic_max.html#triton.language.atomic_max\">atomic_max() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.atomic_min.html#triton.language.atomic_min\">atomic_min() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.atomic_xchg.html#triton.language.atomic_xchg\">atomic_xchg() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.autotune.html#triton.autotune\">autotune() (in module triton)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"B\">B</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.testing.Benchmark.html#triton.testing.Benchmark\">Benchmark (class in triton.testing)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.broadcast_to.html#triton.language.broadcast_to\">broadcast_to() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"C\">C</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.Config.html#triton.Config\">Config (class in triton)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.cos.html#triton.language.cos\">cos() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"D\">D</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.testing.do_bench.html#triton.testing.do_bench\">do_bench() (in module triton.testing)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.dot.html#triton.language.dot\">dot() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"E\">E</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.exp.html#triton.language.exp\">exp() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"H\">H</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.heuristics.html#triton.heuristics\">heuristics() (in module triton)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"J\">J</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.jit.html#triton.jit\">jit() (in module triton)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"L\">L</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.load.html#triton.language.load\">load() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.log.html#triton.language.log\">log() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"M\">M</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.max.html#triton.language.max\">max() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.maximum.html#triton.language.maximum\">maximum() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.min.html#triton.language.min\">min() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.minimum.html#triton.language.minimum\">minimum() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.multiple_of.html#triton.language.multiple_of\">multiple_of() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"N\">N</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.num_programs.html#triton.language.num_programs\">num_programs() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"P\">P</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.testing.perf_report.html#triton.testing.perf_report\">perf_report() (in module triton.testing)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.program_id.html#triton.language.program_id\">program_id() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"R\">R</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.rand.html#triton.language.rand\">rand() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.randint.html#triton.language.randint\">randint() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.randint4x.html#triton.language.randint4x\">randint4x() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.randn.html#triton.language.randn\">randn() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.ravel.html#triton.language.ravel\">ravel() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.reshape.html#triton.language.reshape\">reshape() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"S\">S</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.sigmoid.html#triton.language.sigmoid\">sigmoid() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.sin.html#triton.language.sin\">sin() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.softmax.html#triton.language.softmax\">softmax() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.sqrt.html#triton.language.sqrt\">sqrt() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.store.html#triton.language.store\">store() (in module triton.language)</a>\n-</li>\n-      <li><a href=\"python-api/generated/triton.language.sum.html#triton.language.sum\">sum() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"W\">W</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.where.html#triton.language.where\">where() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-<h2 id=\"Z\">Z</h2>\n-<table style=\"width: 100%\" class=\"indextable genindextable\"><tr>\n-  <td style=\"width: 33%; vertical-align: top;\"><ul>\n-      <li><a href=\"python-api/generated/triton.language.zeros.html#triton.language.zeros\">zeros() (in module triton.language)</a>\n-</li>\n-  </ul></td>\n-</tr></table>\n-\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"genindex.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/installation.html", "status": "removed", "additions": 0, "deletions": 289, "changes": 289, "file_content_changes": "@@ -1,289 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Installation &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../\" src=\"../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../\" id=\"documentation_options\" src=\"../_static/documentation_options.js\"></script>\n-        <script src=\"../_static/jquery.js\"></script>\n-        <script src=\"../_static/underscore.js\"></script>\n-        <script src=\"../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../search.html\" />\n-    <link rel=\"next\" title=\"Tutorials\" href=\"tutorials/index.html\" />\n-    <link rel=\"prev\" title=\"Welcome to Triton\u2019s documentation!\" href=\"../index.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1 current\"><a class=\"current reference internal\" href=\"#\">Installation</a><ul>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#binary-distributions\">Binary Distributions</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#from-source\">From Source</a><ul>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#python-package\">Python Package</a></li>\n-</ul>\n-</li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-      <li>Installation</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../_sources/getting-started/installation.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"installation\">\n-<h1>Installation<a class=\"headerlink\" href=\"#installation\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<div class=\"section\" id=\"binary-distributions\">\n-<h2>Binary Distributions<a class=\"headerlink\" href=\"#binary-distributions\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>You can install the latest stable release of Triton from pip:</p>\n-<div class=\"highlight-bash notranslate\"><div class=\"highlight\"><pre><span></span>pip install triton\n-</pre></div>\n-</div>\n-<p>Binary wheels are available for CPython 3.6-3.9 and PyPy 3.6-3.7.</p>\n-<p>And the latest nightly release:</p>\n-<div class=\"highlight-bash notranslate\"><div class=\"highlight\"><pre><span></span>pip install -U --pre triton\n-</pre></div>\n-</div>\n-</div>\n-<div class=\"section\" id=\"from-source\">\n-<h2>From Source<a class=\"headerlink\" href=\"#from-source\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<div class=\"section\" id=\"python-package\">\n-<h3>Python Package<a class=\"headerlink\" href=\"#python-package\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>You can install the Python package from source by running the following commands:</p>\n-<div class=\"highlight-bash notranslate\"><div class=\"highlight\"><pre><span></span>git clone https://github.com/openai/triton.git<span class=\"p\">;</span>\n-<span class=\"nb\">cd</span> triton/python<span class=\"p\">;</span>\n-pip install cmake<span class=\"p\">;</span> <span class=\"c1\"># build time dependency</span>\n-pip install -e .\n-</pre></div>\n-</div>\n-<p>Note that, if llvm-11 is not present on your system, the setup.py script will download the official LLVM11 static libraries link against that.</p>\n-<p>You can then test your installation by running the unit tests:</p>\n-<div class=\"highlight-bash notranslate\"><div class=\"highlight\"><pre><span></span>pip install -e <span class=\"s1\">&#39;.[tests]&#39;</span>\n-pytest -vs test/unit/\n-</pre></div>\n-</div>\n-<p>and the benchmarks</p>\n-<div class=\"highlight-bash notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nb\">cd</span> bench/\n-python -m run --with-plots --result-dir /tmp/triton-bench\n-</pre></div>\n-</div>\n-</div>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"tutorials/index.html\" class=\"btn btn-neutral float-right\" title=\"Tutorials\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"../index.html\" class=\"btn btn-neutral float-left\" title=\"Welcome to Triton\u2019s documentation!\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../v1.1.2/getting-started/installation.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"installation.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/tutorials/01-vector-add.html", "status": "removed", "additions": 0, "deletions": 421, "changes": 421, "file_content_changes": "@@ -1,421 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Vector Addition &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"Fused Softmax\" href=\"02-fused-softmax.html\" />\n-    <link rel=\"prev\" title=\"Tutorials\" href=\"index.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../installation.html\">Installation</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"index.html\">Tutorials</a><ul class=\"current\">\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">Vector Addition</a><ul>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#compute-kernel\">Compute Kernel</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#benchmark\">Benchmark</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"02-fused-softmax.html\">Fused Softmax</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"03-matrix-multiplication.html\">Matrix Multiplication</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"04-low-memory-dropout.html\">Low-Memory Dropout</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"05-layer-norm.html\">Layer Normalization</a></li>\n-</ul>\n-</li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"index.html\">Tutorials</a> &raquo;</li>\n-        \n-      <li>Vector Addition</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/getting-started/tutorials/01-vector-add.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"sphx-glr-download-link-note admonition note\">\n-<p class=\"admonition-title\">Note</p>\n-<p>Click <a class=\"reference internal\" href=\"#sphx-glr-download-getting-started-tutorials-01-vector-add-py\"><span class=\"std std-ref\">here</span></a>\n-to download the full example code</p>\n-</div>\n-<div class=\"sphx-glr-example-title section\" id=\"vector-addition\">\n-<span id=\"sphx-glr-getting-started-tutorials-01-vector-add-py\"></span><h1>Vector Addition<a class=\"headerlink\" href=\"#vector-addition\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p>In this tutorial, you will write a simple vector addition using Triton and learn about:</p>\n-<ul class=\"simple\">\n-<li><p>The basic programming model of Triton</p></li>\n-<li><p>The <cite>triton.jit</cite> decorator, which is used to define Triton kernels.</p></li>\n-<li><p>The best practices for validating and benchmarking your custom ops against native reference implementations</p></li>\n-</ul>\n-<div class=\"section\" id=\"compute-kernel\">\n-<h2>Compute Kernel<a class=\"headerlink\" href=\"#compute-kernel\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n-\n-<span class=\"kn\">import</span> <span class=\"nn\">triton</span>\n-<span class=\"kn\">import</span> <span class=\"nn\">triton.language</span> <span class=\"k\">as</span> <span class=\"nn\">tl</span>\n-\n-\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">add_kernel</span><span class=\"p\">(</span>\n-    <span class=\"n\">x_ptr</span><span class=\"p\">,</span>  <span class=\"c1\"># *Pointer* to first input vector</span>\n-    <span class=\"n\">y_ptr</span><span class=\"p\">,</span>  <span class=\"c1\"># *Pointer* to second input vector</span>\n-    <span class=\"n\">output_ptr</span><span class=\"p\">,</span>  <span class=\"c1\"># *Pointer* to output vector</span>\n-    <span class=\"n\">n_elements</span><span class=\"p\">,</span>  <span class=\"c1\"># Size of the vector</span>\n-    <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span>  <span class=\"c1\"># Number of elements each program should process</span>\n-                 <span class=\"c1\"># NOTE: `constexpr` so it can be used as a shape value</span>\n-<span class=\"p\">):</span>\n-    <span class=\"c1\"># There are multiple &#39;program&#39;s processing different data. We identify which program</span>\n-    <span class=\"c1\"># we are here</span>\n-    <span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>  <span class=\"c1\"># We use a 1D launch grid so axis is 0</span>\n-    <span class=\"c1\"># This program will process inputs that are offset from the initial data.</span>\n-    <span class=\"c1\"># for instance, if you had a vector of length 256 and block_size of 64, the programs</span>\n-    <span class=\"c1\"># would each access the elements [0:64, 64:128, 128:192, 192:256].</span>\n-    <span class=\"c1\"># Note that offsets is a list of pointers</span>\n-    <span class=\"n\">block_start</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE</span>\n-    <span class=\"n\">offsets</span> <span class=\"o\">=</span> <span class=\"n\">block_start</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># Create a mask to guard memory operations against out-of-bounds accesses</span>\n-    <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">offsets</span> <span class=\"o\">&lt;</span> <span class=\"n\">n_elements</span>\n-    <span class=\"c1\"># Load x and y from DRAM, masking out any extra elements in case the input is not a</span>\n-    <span class=\"c1\"># multiple of the block size</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">x_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">y_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span>\n-    <span class=\"c1\"># Write x + y back to DRAM</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">output_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p>Let\u2019s also declare a helper function to (1) allocate the <cite>z</cite> tensor\n-and (2) enqueue the above kernel with appropriate grid/block sizes.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">):</span>\n-    <span class=\"c1\"># We need to preallocate the output</span>\n-    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty_like</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-    <span class=\"k\">assert</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">is_cuda</span> <span class=\"ow\">and</span> <span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">is_cuda</span> <span class=\"ow\">and</span> <span class=\"n\">output</span><span class=\"o\">.</span><span class=\"n\">is_cuda</span>\n-    <span class=\"n\">n_elements</span> <span class=\"o\">=</span> <span class=\"n\">output</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span>\n-    <span class=\"c1\"># The SPMD launch grid denotes the number of kernel instances that run in parallel.</span>\n-    <span class=\"c1\"># It is analogous to CUDA launch grids. It can be either Tuple[int], or Callable(metaparameters) -&gt; Tuple[int]</span>\n-    <span class=\"c1\"># In this case, we use a 1D grid where the size is the number of blocks</span>\n-    <span class=\"n\">grid</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">meta</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">n_elements</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">]),)</span>\n-    <span class=\"c1\"># NOTE:</span>\n-    <span class=\"c1\">#  - each torch.tensor object is implicitly converted into a pointer to its first element.</span>\n-    <span class=\"c1\">#  - `triton.jit`&#39;ed functions can be index with a launch grid to obtain a callable GPU kernel</span>\n-    <span class=\"c1\">#  - don&#39;t forget to pass meta-parameters as keywords arguments</span>\n-    <span class=\"n\">add_kernel</span><span class=\"p\">[</span><span class=\"n\">grid</span><span class=\"p\">](</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">n_elements</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># We return a handle to z but, since `torch.cuda.synchronize()` hasn&#39;t been called, the kernel is still</span>\n-    <span class=\"c1\"># running asynchronously at this point.</span>\n-    <span class=\"k\">return</span> <span class=\"n\">output</span>\n-</pre></div>\n-</div>\n-<p>We can now use the above function to compute the element-wise sum of two <cite>torch.tensor</cite> objects and test its correctness:</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">manual_seed</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-<span class=\"n\">size</span> <span class=\"o\">=</span> <span class=\"mi\">98432</span>\n-<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-<span class=\"n\">output_torch</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span>\n-<span class=\"n\">output_triton</span> <span class=\"o\">=</span> <span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n-<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">output_torch</span><span class=\"p\">)</span>\n-<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">output_triton</span><span class=\"p\">)</span>\n-<span class=\"nb\">print</span><span class=\"p\">(</span>\n-    <span class=\"sa\">f</span><span class=\"s1\">&#39;The maximum difference between torch and triton is &#39;</span>\n-    <span class=\"sa\">f</span><span class=\"s1\">&#39;</span><span class=\"si\">{</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">abs</span><span class=\"p\">(</span><span class=\"n\">output_torch</span> <span class=\"o\">-</span> <span class=\"n\">output_triton</span><span class=\"p\">))</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span>\n-<span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>tensor([1.3713, 1.3076, 0.4940,  ..., 0.6724, 1.2141, 0.9733], device=&#39;cuda:0&#39;)\n-tensor([1.3713, 1.3076, 0.4940,  ..., 0.6724, 1.2141, 0.9733], device=&#39;cuda:0&#39;)\n-The maximum difference between torch and triton is 0.0\n-</pre></div>\n-</div>\n-<p>Seems like we\u2019re good to go!</p>\n-</div>\n-<div class=\"section\" id=\"benchmark\">\n-<h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>We can now benchmark our custom op on vectors of increasing sizes to get a sense of how it does relative to PyTorch.\n-To make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops\n-for different problem sizes.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">perf_report</span><span class=\"p\">(</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">Benchmark</span><span class=\"p\">(</span>\n-        <span class=\"n\">x_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;size&#39;</span><span class=\"p\">],</span>  <span class=\"c1\"># argument names to use as an x-axis for the plot</span>\n-        <span class=\"n\">x_vals</span><span class=\"o\">=</span><span class=\"p\">[</span>\n-            <span class=\"mi\">2</span> <span class=\"o\">**</span> <span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n-        <span class=\"p\">],</span>  <span class=\"c1\"># different possible values for `x_name`</span>\n-        <span class=\"n\">x_log</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>  <span class=\"c1\"># x axis is logarithmic</span>\n-        <span class=\"n\">line_arg</span><span class=\"o\">=</span><span class=\"s1\">&#39;provider&#39;</span><span class=\"p\">,</span>  <span class=\"c1\"># argument name whose value corresponds to a different line in the plot</span>\n-        <span class=\"n\">line_vals</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;torch&#39;</span><span class=\"p\">],</span>  <span class=\"c1\"># possible values for `line_arg`</span>\n-        <span class=\"n\">line_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;Triton&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Torch&#39;</span><span class=\"p\">],</span>  <span class=\"c1\"># label name for the lines</span>\n-        <span class=\"n\">styles</span><span class=\"o\">=</span><span class=\"p\">[(</span><span class=\"s1\">&#39;blue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;green&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">)],</span>  <span class=\"c1\"># line styles</span>\n-        <span class=\"n\">ylabel</span><span class=\"o\">=</span><span class=\"s1\">&#39;GB/s&#39;</span><span class=\"p\">,</span>  <span class=\"c1\"># label name for the y-axis</span>\n-        <span class=\"n\">plot_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;vector-add-performance&#39;</span><span class=\"p\">,</span>  <span class=\"c1\"># name for the plot. Used also as a file name for saving the plot.</span>\n-        <span class=\"n\">args</span><span class=\"o\">=</span><span class=\"p\">{},</span>  <span class=\"c1\"># values for function arguments not in `x_names` and `y_name`</span>\n-    <span class=\"p\">)</span>\n-<span class=\"p\">)</span>\n-<span class=\"k\">def</span> <span class=\"nf\">benchmark</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">provider</span><span class=\"p\">):</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;torch&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">))</span>\n-    <span class=\"n\">gbps</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">ms</span><span class=\"p\">:</span> <span class=\"mi\">12</span> <span class=\"o\">*</span> <span class=\"n\">size</span> <span class=\"o\">/</span> <span class=\"n\">ms</span> <span class=\"o\">*</span> <span class=\"mf\">1e-6</span>\n-    <span class=\"k\">return</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">ms</span><span class=\"p\">),</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">max_ms</span><span class=\"p\">),</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">min_ms</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p>We can now run the decorated function above. Pass <cite>print_data=True</cite> to see the performance number, <cite>show_plots=True</cite> to plot them, and/or\n-<a href=\"#id1\"><span class=\"problematic\" id=\"id2\">`</span></a>save_path=\u2019/path/to/results/\u2019 to save them to disk along with raw CSV data</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">benchmark</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">print_data</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">show_plots</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<img alt=\"01 vector add\" class=\"sphx-glr-single-img\" src=\"../../_images/sphx_glr_01-vector-add_001.png\" />\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>vector-add-performance:\n-           size      Triton       Torch\n-0        4096.0    9.600000    9.600000\n-1        8192.0   19.200000   19.200000\n-2       16384.0   38.400001   38.400001\n-3       32768.0   76.800002   76.800002\n-4       65536.0  127.999995  127.999995\n-5      131072.0  219.428568  219.428568\n-6      262144.0  341.333321  384.000001\n-7      524288.0  472.615390  472.615390\n-8     1048576.0  614.400016  614.400016\n-9     2097152.0  722.823517  722.823517\n-10    4194304.0  780.190482  780.190482\n-11    8388608.0  812.429770  812.429770\n-12   16777216.0  833.084721  833.084721\n-13   33554432.0  842.004273  842.004273\n-14   67108864.0  847.448255  848.362445\n-15  134217728.0  849.737435  850.656574\n-</pre></div>\n-</div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 1 minutes  38.189 seconds)</p>\n-<div class=\"sphx-glr-footer class sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-01-vector-add-py\">\n-<div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/62d97d49a32414049819dd8bb8378080/01-vector-add.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">01-vector-add.py</span></code></a></p>\n-</div>\n-<div class=\"sphx-glr-download sphx-glr-download-jupyter docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/f191ee1e78dc52eb5f7cba88f71cef2f/01-vector-add.ipynb\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Jupyter</span> <span class=\"pre\">notebook:</span> <span class=\"pre\">01-vector-add.ipynb</span></code></a></p>\n-</div>\n-</div>\n-<p class=\"sphx-glr-signature\"><a class=\"reference external\" href=\"https://sphinx-gallery.github.io\">Gallery generated by Sphinx-Gallery</a></p>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"02-fused-softmax.html\" class=\"btn btn-neutral float-right\" title=\"Fused Softmax\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"index.html\" class=\"btn btn-neutral float-left\" title=\"Tutorials\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"01-vector-add.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/tutorials/02-fused-softmax.html", "status": "removed", "additions": 0, "deletions": 473, "changes": 473, "file_content_changes": "@@ -1,473 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Fused Softmax &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"Matrix Multiplication\" href=\"03-matrix-multiplication.html\" />\n-    <link rel=\"prev\" title=\"Vector Addition\" href=\"01-vector-add.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../installation.html\">Installation</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"index.html\">Tutorials</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"01-vector-add.html\">Vector Addition</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">Fused Softmax</a><ul>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#motivations\">Motivations</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#compute-kernel\">Compute Kernel</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#unit-test\">Unit Test</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#benchmark\">Benchmark</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"03-matrix-multiplication.html\">Matrix Multiplication</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"04-low-memory-dropout.html\">Low-Memory Dropout</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"05-layer-norm.html\">Layer Normalization</a></li>\n-</ul>\n-</li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"index.html\">Tutorials</a> &raquo;</li>\n-        \n-      <li>Fused Softmax</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/getting-started/tutorials/02-fused-softmax.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"sphx-glr-download-link-note admonition note\">\n-<p class=\"admonition-title\">Note</p>\n-<p>Click <a class=\"reference internal\" href=\"#sphx-glr-download-getting-started-tutorials-02-fused-softmax-py\"><span class=\"std std-ref\">here</span></a>\n-to download the full example code</p>\n-</div>\n-<div class=\"sphx-glr-example-title section\" id=\"fused-softmax\">\n-<span id=\"sphx-glr-getting-started-tutorials-02-fused-softmax-py\"></span><h1>Fused Softmax<a class=\"headerlink\" href=\"#fused-softmax\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p>In this tutorial, you will write a fused softmax operation that is significantly faster\n-than PyTorch\u2019s native op for a particular class of matrices: those whose rows can fit in\n-the GPU\u2019s SRAM.\n-You will learn about:</p>\n-<ul class=\"simple\">\n-<li><p>The benefits of kernel fusion for bandwidth-bound operations.</p></li>\n-<li><p>Reduction operators in Triton.</p></li>\n-</ul>\n-<div class=\"section\" id=\"motivations\">\n-<h2>Motivations<a class=\"headerlink\" href=\"#motivations\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Custom GPU kernels for elementwise additions are educationally valuable but won\u2019t get you very far in practice.\n-Let us consider instead the case of a simple (numerically stabilized) softmax operation:</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n-\n-<span class=\"kn\">import</span> <span class=\"nn\">triton</span>\n-<span class=\"kn\">import</span> <span class=\"nn\">triton.language</span> <span class=\"k\">as</span> <span class=\"nn\">tl</span>\n-\n-\n-<span class=\"nd\">@torch</span><span class=\"o\">.</span><span class=\"n\">jit</span><span class=\"o\">.</span><span class=\"n\">script</span>\n-<span class=\"k\">def</span> <span class=\"nf\">naive_softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n-    <span class=\"sd\">&quot;&quot;&quot;Compute row-wise softmax of X using native pytorch</span>\n-\n-<span class=\"sd\">    We subtract the maximum element in order to avoid overflows. Softmax is invariant to</span>\n-<span class=\"sd\">    this shift.</span>\n-<span class=\"sd\">    &quot;&quot;&quot;</span>\n-    <span class=\"c1\"># read  MN elements ; write M  elements</span>\n-    <span class=\"n\">x_max</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n-    <span class=\"c1\"># read MN + M elements ; write MN elements</span>\n-    <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">-</span> <span class=\"n\">x_max</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span>\n-    <span class=\"c1\"># read  MN elements ; write MN elements</span>\n-    <span class=\"n\">numerator</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">exp</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># read  MN elements ; write M  elements</span>\n-    <span class=\"n\">denominator</span> <span class=\"o\">=</span> <span class=\"n\">numerator</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># read MN + M elements ; write MN elements</span>\n-    <span class=\"n\">ret</span> <span class=\"o\">=</span> <span class=\"n\">numerator</span> <span class=\"o\">/</span> <span class=\"n\">denominator</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span>\n-    <span class=\"c1\"># in total: read 5MN + 2M elements ; wrote 3MN + 2M elements</span>\n-    <span class=\"k\">return</span> <span class=\"n\">ret</span>\n-</pre></div>\n-</div>\n-<p>When implemented naively in PyTorch, computing <code class=\"code docutils literal notranslate\"><span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">naive_softmax(x)</span></code> for <span class=\"math notranslate nohighlight\">\\(x \\in R^{M \\times N}\\)</span>\n-requires reading <span class=\"math notranslate nohighlight\">\\(5MN + 2M\\)</span> elements from DRAM and writing back <span class=\"math notranslate nohighlight\">\\(3MN + 2M\\)</span> elements.\n-This is obviously wasteful; we\u2019d prefer to have a custom \u201cfused\u201d kernel that only reads\n-X once and does all the necessary computations on-chip.\n-Doing so would require reading and writing back only <span class=\"math notranslate nohighlight\">\\(MN\\)</span> bytes, so we could\n-expect a theoretical speed-up of ~4x (i.e., <span class=\"math notranslate nohighlight\">\\((8MN + 4M) / 2MN\\)</span>).\n-The <cite>torch.jit.script</cite> flags aims to perform this kind of \u201ckernel fusion\u201d automatically\n-but, as we will see later, it is still far from ideal.</p>\n-</div>\n-<div class=\"section\" id=\"compute-kernel\">\n-<h2>Compute Kernel<a class=\"headerlink\" href=\"#compute-kernel\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Our softmax kernel works as follows: each program loads a row of the input matrix X,\n-normalizes it and writes back the result to the output Y.\n-Note that one important limitation of Triton is that each block must have a\n-power-of-two number of elements, so we need to internally \u201cpad\u201d each row and guard the\n-memory operations properly if we want to handle any possible input shapes:</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">softmax_kernel</span><span class=\"p\">(</span>\n-    <span class=\"n\">output_ptr</span><span class=\"p\">,</span> <span class=\"n\">input_ptr</span><span class=\"p\">,</span> <span class=\"n\">input_row_stride</span><span class=\"p\">,</span> <span class=\"n\">output_row_stride</span><span class=\"p\">,</span> <span class=\"n\">n_cols</span><span class=\"p\">,</span>\n-    <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span>\n-<span class=\"p\">):</span>\n-    <span class=\"c1\"># The rows of the softmax are independent, so we parallelize across those</span>\n-    <span class=\"n\">row_idx</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># The stride represents how much we need to increase the pointer to advance 1 row</span>\n-    <span class=\"n\">row_start_ptr</span> <span class=\"o\">=</span> <span class=\"n\">input_ptr</span> <span class=\"o\">+</span> <span class=\"n\">row_idx</span> <span class=\"o\">*</span> <span class=\"n\">input_row_stride</span>\n-    <span class=\"c1\"># The block size is the next power of two greater than n_cols, so we can fit each</span>\n-    <span class=\"c1\"># row in a single block</span>\n-    <span class=\"n\">col_offsets</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">)</span>\n-    <span class=\"n\">input_ptrs</span> <span class=\"o\">=</span> <span class=\"n\">row_start_ptr</span> <span class=\"o\">+</span> <span class=\"n\">col_offsets</span>\n-    <span class=\"c1\"># Load the row into SRAM, using a mask since BLOCK_SIZE may be &gt; than n_cols</span>\n-    <span class=\"n\">row</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">input_ptrs</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">col_offsets</span> <span class=\"o\">&lt;</span> <span class=\"n\">n_cols</span><span class=\"p\">,</span> <span class=\"n\">other</span><span class=\"o\">=-</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"s1\">&#39;inf&#39;</span><span class=\"p\">))</span>\n-    <span class=\"c1\"># Substract maximum for numerical stability</span>\n-    <span class=\"n\">row_minus_max</span> <span class=\"o\">=</span> <span class=\"n\">row</span> <span class=\"o\">-</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># Note that exponentials in Triton are fast but approximate (i.e., think __expf in CUDA)</span>\n-    <span class=\"n\">numerator</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">exp</span><span class=\"p\">(</span><span class=\"n\">row_minus_max</span><span class=\"p\">)</span>\n-    <span class=\"n\">denominator</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">numerator</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">softmax_output</span> <span class=\"o\">=</span> <span class=\"n\">numerator</span> <span class=\"o\">/</span> <span class=\"n\">denominator</span>\n-    <span class=\"c1\"># Write back output to DRAM</span>\n-    <span class=\"n\">output_row_start_ptr</span> <span class=\"o\">=</span> <span class=\"n\">output_ptr</span> <span class=\"o\">+</span> <span class=\"n\">row_idx</span> <span class=\"o\">*</span> <span class=\"n\">output_row_stride</span>\n-    <span class=\"n\">output_ptrs</span> <span class=\"o\">=</span> <span class=\"n\">output_row_start_ptr</span> <span class=\"o\">+</span> <span class=\"n\">col_offsets</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">output_ptrs</span><span class=\"p\">,</span> <span class=\"n\">softmax_output</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">col_offsets</span> <span class=\"o\">&lt;</span> <span class=\"n\">n_cols</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p>We can create a helper function that enqueues the kernel and its (meta-)arguments for any given input tensor.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n-    <span class=\"n\">n_rows</span><span class=\"p\">,</span> <span class=\"n\">n_cols</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n-    <span class=\"c1\"># The block size is the smallest power of two greater than the number of columns in `x`</span>\n-    <span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">next_power_of_2</span><span class=\"p\">(</span><span class=\"n\">n_cols</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># Another trick we can use is to ask the compiler to use more threads per row by</span>\n-    <span class=\"c1\"># increasing the number of warps (`num_warps`) over which each row is distributed.</span>\n-    <span class=\"c1\"># You will see in the next tutorial how to auto-tune this value in a more natural</span>\n-    <span class=\"c1\"># way so you don&#39;t have to come up with manual heuristics yourself.</span>\n-    <span class=\"n\">num_warps</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>\n-    <span class=\"k\">if</span> <span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">2048</span><span class=\"p\">:</span>\n-        <span class=\"n\">num_warps</span> <span class=\"o\">=</span> <span class=\"mi\">8</span>\n-    <span class=\"k\">if</span> <span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">4096</span><span class=\"p\">:</span>\n-        <span class=\"n\">num_warps</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>\n-    <span class=\"c1\"># Allocate output</span>\n-    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty_like</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># Enqueue kernel. The 1D launch grid is simple: we have one kernel instance per row o</span>\n-    <span class=\"c1\"># f the input matrix</span>\n-    <span class=\"n\">softmax_kernel</span><span class=\"p\">[(</span><span class=\"n\">n_rows</span><span class=\"p\">,)](</span>\n-        <span class=\"n\">y</span><span class=\"p\">,</span>\n-        <span class=\"n\">x</span><span class=\"p\">,</span>\n-        <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span>\n-        <span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span>\n-        <span class=\"n\">n_cols</span><span class=\"p\">,</span>\n-        <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"n\">num_warps</span><span class=\"p\">,</span>\n-        <span class=\"n\">BLOCK_SIZE</span><span class=\"o\">=</span><span class=\"n\">BLOCK_SIZE</span><span class=\"p\">,</span>\n-    <span class=\"p\">)</span>\n-    <span class=\"k\">return</span> <span class=\"n\">y</span>\n-</pre></div>\n-</div>\n-</div>\n-<div class=\"section\" id=\"unit-test\">\n-<h2>Unit Test<a class=\"headerlink\" href=\"#unit-test\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>We make sure that we test our kernel on a matrix with an irregular number of rows and columns.\n-This will allow us to verify that our padding mechanism works.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">manual_seed</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1823</span><span class=\"p\">,</span> <span class=\"mi\">781</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-<span class=\"n\">y_triton</span> <span class=\"o\">=</span> <span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-<span class=\"n\">y_torch</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n-<span class=\"k\">assert</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">allclose</span><span class=\"p\">(</span><span class=\"n\">y_triton</span><span class=\"p\">,</span> <span class=\"n\">y_torch</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">y_triton</span><span class=\"p\">,</span> <span class=\"n\">y_torch</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p>As expected, the results are identical.</p>\n-</div>\n-<div class=\"section\" id=\"benchmark\">\n-<h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Here we will benchmark our operation as a function of the number of columns in the input matrix \u2013 assuming 4096 rows.\n-We will then compare its performance against (1) <code class=\"code docutils literal notranslate\"><span class=\"pre\">torch.softmax</span></code> and (2) the <code class=\"code docutils literal notranslate\"><span class=\"pre\">naive_softmax</span></code> defined above.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">perf_report</span><span class=\"p\">(</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">Benchmark</span><span class=\"p\">(</span>\n-        <span class=\"n\">x_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;N&#39;</span><span class=\"p\">],</span>  <span class=\"c1\"># argument names to use as an x-axis for the plot</span>\n-        <span class=\"n\">x_vals</span><span class=\"o\">=</span><span class=\"p\">[</span>\n-            <span class=\"mi\">128</span> <span class=\"o\">*</span> <span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">)</span>\n-        <span class=\"p\">],</span>  <span class=\"c1\"># different possible values for `x_name`</span>\n-        <span class=\"n\">line_arg</span><span class=\"o\">=</span><span class=\"s1\">&#39;provider&#39;</span><span class=\"p\">,</span>  <span class=\"c1\"># argument name whose value corresponds to a different line in the plot</span>\n-        <span class=\"n\">line_vals</span><span class=\"o\">=</span><span class=\"p\">[</span>\n-            <span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">,</span>\n-            <span class=\"s1\">&#39;torch-native&#39;</span><span class=\"p\">,</span>\n-            <span class=\"s1\">&#39;torch-jit&#39;</span><span class=\"p\">,</span>\n-        <span class=\"p\">],</span>  <span class=\"c1\"># possible values for `line_arg``</span>\n-        <span class=\"n\">line_names</span><span class=\"o\">=</span><span class=\"p\">[</span>\n-            <span class=\"s2\">&quot;Triton&quot;</span><span class=\"p\">,</span>\n-            <span class=\"s2\">&quot;Torch (native)&quot;</span><span class=\"p\">,</span>\n-            <span class=\"s2\">&quot;Torch (jit)&quot;</span><span class=\"p\">,</span>\n-        <span class=\"p\">],</span>  <span class=\"c1\"># label name for the lines</span>\n-        <span class=\"n\">styles</span><span class=\"o\">=</span><span class=\"p\">[(</span><span class=\"s1\">&#39;blue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;green&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;green&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;--&#39;</span><span class=\"p\">)],</span>  <span class=\"c1\"># line styles</span>\n-        <span class=\"n\">ylabel</span><span class=\"o\">=</span><span class=\"s2\">&quot;GB/s&quot;</span><span class=\"p\">,</span>  <span class=\"c1\"># label name for the y-axis</span>\n-        <span class=\"n\">plot_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;softmax-performance&quot;</span><span class=\"p\">,</span>  <span class=\"c1\"># name for the plot. Used also as a file name for saving the plot.</span>\n-        <span class=\"n\">args</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">4096</span><span class=\"p\">},</span>  <span class=\"c1\"># values for function arguments not in `x_names` and `y_name`</span>\n-    <span class=\"p\">)</span>\n-<span class=\"p\">)</span>\n-<span class=\"k\">def</span> <span class=\"nf\">benchmark</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">provider</span><span class=\"p\">):</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;torch-native&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;torch-jit&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">naive_softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n-    <span class=\"n\">gbps</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">ms</span><span class=\"p\">:</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">nelement</span><span class=\"p\">()</span> <span class=\"o\">*</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">element_size</span><span class=\"p\">()</span> <span class=\"o\">*</span> <span class=\"mf\">1e-9</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">ms</span> <span class=\"o\">*</span> <span class=\"mf\">1e-3</span><span class=\"p\">)</span>\n-    <span class=\"k\">return</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">ms</span><span class=\"p\">),</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">max_ms</span><span class=\"p\">),</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">min_ms</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"n\">benchmark</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">show_plots</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">print_data</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<img alt=\"02 fused softmax\" class=\"sphx-glr-single-img\" src=\"../../_images/sphx_glr_02-fused-softmax_001.png\" />\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>softmax-performance:\n-          N      Triton  Torch (native)  Torch (jit)\n-0     256.0  546.133347      546.133347   188.321838\n-1     384.0  585.142862      585.142862   151.703707\n-2     512.0  655.360017      606.814814   154.566038\n-3     640.0  682.666684      640.000002   158.759699\n-4     768.0  722.823517      664.216187   163.839992\n-..      ...         ...             ...          ...\n-93  12160.0  814.058574      405.755985   198.631953\n-94  12288.0  814.111783      415.661740   198.794749\n-95  12416.0  814.163950      412.149375   198.457532\n-96  12544.0  814.214963      412.971190   198.716830\n-97  12672.0  814.265046      411.679167   198.776477\n-\n-[98 rows x 4 columns]\n-</pre></div>\n-</div>\n-<p>In the above plot, we can see that:</p>\n-<blockquote>\n-<div><ul class=\"simple\">\n-<li><p>Triton is 4x faster than the Torch JIT. This confirms our suspicions that the Torch JIT does not do any fusion here.</p></li>\n-<li><p>Triton is noticeably faster than <code class=\"code docutils literal notranslate\"><span class=\"pre\">torch.softmax</span></code> \u2013 in addition to being <strong>easier to read, understand and maintain</strong>.\n-Note however that the PyTorch <cite>softmax</cite> operation is more general and will works on tensors of any shape.</p></li>\n-</ul>\n-</div></blockquote>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 3 minutes  22.664 seconds)</p>\n-<div class=\"sphx-glr-footer class sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-02-fused-softmax-py\">\n-<div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/d91442ac2982c4e0cc3ab0f43534afbc/02-fused-softmax.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">02-fused-softmax.py</span></code></a></p>\n-</div>\n-<div class=\"sphx-glr-download sphx-glr-download-jupyter docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/034d953b6214fedce6ea03803c712b89/02-fused-softmax.ipynb\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Jupyter</span> <span class=\"pre\">notebook:</span> <span class=\"pre\">02-fused-softmax.ipynb</span></code></a></p>\n-</div>\n-</div>\n-<p class=\"sphx-glr-signature\"><a class=\"reference external\" href=\"https://sphinx-gallery.github.io\">Gallery generated by Sphinx-Gallery</a></p>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"03-matrix-multiplication.html\" class=\"btn btn-neutral float-right\" title=\"Matrix Multiplication\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"01-vector-add.html\" class=\"btn btn-neutral float-left\" title=\"Vector Addition\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"02-fused-softmax.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/tutorials/03-matrix-multiplication.html", "status": "removed", "additions": 0, "deletions": 681, "changes": 681, "file_content_changes": "@@ -1,681 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Matrix Multiplication &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"Low-Memory Dropout\" href=\"04-low-memory-dropout.html\" />\n-    <link rel=\"prev\" title=\"Fused Softmax\" href=\"02-fused-softmax.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../installation.html\">Installation</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"index.html\">Tutorials</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"01-vector-add.html\">Vector Addition</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"02-fused-softmax.html\">Fused Softmax</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">Matrix Multiplication</a><ul>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#motivations\">Motivations</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#compute-kernel\">Compute Kernel</a><ul>\n-<li class=\"toctree-l4\"><a class=\"reference internal\" href=\"#pointer-arithmetics\">Pointer Arithmetics</a></li>\n-<li class=\"toctree-l4\"><a class=\"reference internal\" href=\"#l2-cache-optimizations\">L2 Cache Optimizations</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#final-result\">Final Result</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#unit-test\">Unit Test</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#benchmark\">Benchmark</a><ul>\n-<li class=\"toctree-l4\"><a class=\"reference internal\" href=\"#square-matrix-performance\">Square Matrix Performance</a></li>\n-</ul>\n-</li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"04-low-memory-dropout.html\">Low-Memory Dropout</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"05-layer-norm.html\">Layer Normalization</a></li>\n-</ul>\n-</li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"index.html\">Tutorials</a> &raquo;</li>\n-        \n-      <li>Matrix Multiplication</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/getting-started/tutorials/03-matrix-multiplication.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"sphx-glr-download-link-note admonition note\">\n-<p class=\"admonition-title\">Note</p>\n-<p>Click <a class=\"reference internal\" href=\"#sphx-glr-download-getting-started-tutorials-03-matrix-multiplication-py\"><span class=\"std std-ref\">here</span></a>\n-to download the full example code</p>\n-</div>\n-<div class=\"sphx-glr-example-title section\" id=\"matrix-multiplication\">\n-<span id=\"sphx-glr-getting-started-tutorials-03-matrix-multiplication-py\"></span><h1>Matrix Multiplication<a class=\"headerlink\" href=\"#matrix-multiplication\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p>In this tutorial, you will write a 25-lines high-performance FP16 matrix multiplication\n-kernel that achieves performance on par with cuBLAS.\n-You will specifically learn about:</p>\n-<ul class=\"simple\">\n-<li><p>Block-level matrix multiplications</p></li>\n-<li><p>Multi-dimensional pointer arithmetic</p></li>\n-<li><p>Program re-ordering for improved L2 cache hit rate</p></li>\n-<li><p>Automatic performance tuning</p></li>\n-</ul>\n-<div class=\"section\" id=\"motivations\">\n-<h2>Motivations<a class=\"headerlink\" href=\"#motivations\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Matrix multiplications are a key building block of most modern high-performance computing systems.\n-They are notoriously hard to optimize, hence their implementation is generally done by\n-hardware vendors themselves as part of so-called \u201ckernel libraries\u201d (e.g., cuBLAS).\n-Unfortunately, these libraries are often proprietary and cannot be easily customized\n-to accomodate the needs of modern deep learning workloads (e.g., fused activation functions).\n-In this tutorial, you will learn how to implement efficient matrix multiplications by\n-yourself with Triton, in a way that is easy to customize and extend.</p>\n-<p>Roughly speaking, the kernel that we will write will implement the following blocked\n-algorithm to multiply a (M, K) by a (K, N) matrix:</p>\n-<blockquote>\n-<div><div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># do in parallel</span>\n-<span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">):</span>\n-  <span class=\"c1\"># do in parallel</span>\n-  <span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">):</span>\n-    <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"k\">for</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">K</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">):</span>\n-      <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">m</span> <span class=\"p\">:</span> <span class=\"n\">m</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"p\">:</span> <span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">]</span>\n-      <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">k</span> <span class=\"p\">:</span> <span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">,</span> <span class=\"n\">n</span> <span class=\"p\">:</span> <span class=\"n\">n</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">]</span>\n-      <span class=\"n\">acc</span> <span class=\"o\">+=</span> <span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n-    <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">m</span> <span class=\"p\">:</span> <span class=\"n\">m</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">n</span> <span class=\"p\">:</span> <span class=\"n\">n</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc</span><span class=\"p\">;</span>\n-</pre></div>\n-</div>\n-</div></blockquote>\n-<p>where each iteration of the doubly-nested for-loop is performed by a dedicated Triton program instance.</p>\n-</div>\n-<div class=\"section\" id=\"compute-kernel\">\n-<h2>Compute Kernel<a class=\"headerlink\" href=\"#compute-kernel\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>The above algorithm is, actually, fairly straightforward to implement in Triton.\n-The main difficulty comes from the computation of the memory locations at which blocks\n-of <code class=\"code docutils literal notranslate\"><span class=\"pre\">A</span></code> and <code class=\"code docutils literal notranslate\"><span class=\"pre\">B</span></code> must be read in the inner loop. For that, we need\n-multi-dimensional pointer arithmetics.</p>\n-<div class=\"section\" id=\"pointer-arithmetics\">\n-<h3>Pointer Arithmetics<a class=\"headerlink\" href=\"#pointer-arithmetics\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>For a row-major 2D tensor <code class=\"code docutils literal notranslate\"><span class=\"pre\">X</span></code>, the memory location of <code class=\"code docutils literal notranslate\"><span class=\"pre\">X[i,</span> <span class=\"pre\">j]</span></code> is given b\n-y <code class=\"code docutils literal notranslate\"><span class=\"pre\">&amp;X[i,</span> <span class=\"pre\">j]</span> <span class=\"pre\">=</span> <span class=\"pre\">X</span> <span class=\"pre\">+</span> <span class=\"pre\">i*stride_xi</span> <span class=\"pre\">+</span> <span class=\"pre\">j*stride_xj</span></code>.\n-Therefore, blocks of pointers for <code class=\"code docutils literal notranslate\"><span class=\"pre\">A[m</span> <span class=\"pre\">:</span> <span class=\"pre\">m+BLOCK_SIZE_M,</span> <span class=\"pre\">k:k+BLOCK_SIZE_K]</span></code> and\n-<code class=\"code docutils literal notranslate\"><span class=\"pre\">B[k</span> <span class=\"pre\">:</span> <span class=\"pre\">k+BLOCK_SIZE_K,</span> <span class=\"pre\">n</span> <span class=\"pre\">:</span> <span class=\"pre\">n+BLOCK_SIZE_N]</span></code> can be defined in pseudo-code as:</p>\n-<blockquote>\n-<div><div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"o\">&amp;</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">m</span> <span class=\"p\">:</span> <span class=\"n\">m</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">:</span><span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">]</span> <span class=\"o\">=</span>  <span class=\"n\">a_ptr</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">m</span> <span class=\"p\">:</span> <span class=\"n\">m</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">)[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span><span class=\"o\">*</span><span class=\"n\">A</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">k</span> <span class=\"p\">:</span> <span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">)[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span><span class=\"o\">*</span><span class=\"n\">A</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n-<span class=\"o\">&amp;</span><span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">k</span> <span class=\"p\">:</span> <span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">:</span><span class=\"n\">n</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">]</span> <span class=\"o\">=</span>  <span class=\"n\">b_ptr</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">k</span> <span class=\"p\">:</span> <span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">)[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span><span class=\"o\">*</span><span class=\"n\">B</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">n</span> <span class=\"p\">:</span> <span class=\"n\">n</span><span class=\"o\">+</span><span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span><span class=\"o\">*</span><span class=\"n\">B</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n-</pre></div>\n-</div>\n-</div></blockquote>\n-<p>Which means that pointers for blocks of A and B can be initialized (i.e., <code class=\"code docutils literal notranslate\"><span class=\"pre\">k=0</span></code>) in Triton as:</p>\n-<blockquote>\n-<div><div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">offs_am</span> <span class=\"o\">=</span> <span class=\"n\">pid_m</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE_M</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">)</span>\n-<span class=\"n\">offs_bn</span> <span class=\"o\">=</span> <span class=\"n\">pid_n</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE_N</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)</span>\n-<span class=\"n\">offs_k</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">)</span>\n-<span class=\"n\">a_ptrs</span> <span class=\"o\">=</span> <span class=\"n\">a_ptr</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">offs_am</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span><span class=\"o\">*</span><span class=\"n\">stride_am</span> <span class=\"o\">+</span> <span class=\"n\">offs_k</span> <span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span><span class=\"o\">*</span><span class=\"n\">stride_ak</span><span class=\"p\">)</span>\n-<span class=\"n\">b_ptrs</span> <span class=\"o\">=</span> <span class=\"n\">b_ptr</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">offs_k</span> <span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span><span class=\"o\">*</span><span class=\"n\">stride_bk</span> <span class=\"o\">+</span> <span class=\"n\">offs_bn</span><span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span><span class=\"o\">*</span><span class=\"n\">stride_bn</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-</div></blockquote>\n-<p>And then updated in the inner loop as follows:</p>\n-<blockquote>\n-<div><div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">pa</span> <span class=\"o\">+=</span> <span class=\"n\">BLOCK_SIZE_K</span> <span class=\"o\">*</span> <span class=\"n\">stride_ak</span><span class=\"p\">;</span>\n-<span class=\"n\">pb</span> <span class=\"o\">+=</span> <span class=\"n\">BLOCK_SIZE_K</span> <span class=\"o\">*</span> <span class=\"n\">stride_bk</span><span class=\"p\">;</span>\n-</pre></div>\n-</div>\n-</div></blockquote>\n-</div>\n-<div class=\"section\" id=\"l2-cache-optimizations\">\n-<h3>L2 Cache Optimizations<a class=\"headerlink\" href=\"#l2-cache-optimizations\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>As mentioned above, each program instance computes a <code class=\"code docutils literal notranslate\"><span class=\"pre\">[BLOCK_SIZE_M,</span> <span class=\"pre\">BLOCK_SIZE_N]</span></code>\n-block of <code class=\"code docutils literal notranslate\"><span class=\"pre\">C</span></code>.\n-It is important to remember that the order in which these blocks are computed does\n-matter, since it affects the L2 cache hit rate of our program. and unfortunately, a\n-a simple row-major ordering</p>\n-<blockquote>\n-<div><div class=\"highlight-Python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n-<span class=\"n\">grid_m</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">M</span> <span class=\"o\">+</span> <span class=\"n\">BLOCK_SIZE_M</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">;</span>\n-<span class=\"n\">grid_n</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">N</span> <span class=\"o\">+</span> <span class=\"n\">BLOCK_SIZE_N</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">;</span>\n-<span class=\"n\">pid_m</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">/</span> <span class=\"n\">grid_n</span><span class=\"p\">;</span>\n-<span class=\"n\">pid_n</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">%</span> <span class=\"n\">grid_n</span><span class=\"p\">;</span>\n-</pre></div>\n-</div>\n-</div></blockquote>\n-<p>is just not going to cut it.</p>\n-<p>One possible solution is to launch blocks in an order that promotes data reuse.\n-This can be done by \u2018super-grouping\u2019 blocks in groups of <code class=\"code docutils literal notranslate\"><span class=\"pre\">GROUP_M</span></code> rows before\n-switching to the next column:</p>\n-<blockquote>\n-<div><div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># program ID</span>\n-<span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-<span class=\"c1\"># number of program ids along the M axis</span>\n-<span class=\"n\">num_pid_m</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">)</span>\n-<span class=\"c1\"># number of programs ids along the N axis</span>\n-<span class=\"n\">num_pid_n</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)</span>\n-<span class=\"c1\"># number of programs in group</span>\n-<span class=\"n\">num_pid_in_group</span> <span class=\"o\">=</span> <span class=\"n\">GROUP_SIZE_M</span> <span class=\"o\">*</span> <span class=\"n\">num_pid_n</span>\n-<span class=\"c1\"># id of the group this program is in</span>\n-<span class=\"n\">group_id</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">//</span> <span class=\"n\">num_pid_in_group</span>\n-<span class=\"c1\"># row-id of the first program in the group</span>\n-<span class=\"n\">first_pid_m</span> <span class=\"o\">=</span> <span class=\"n\">group_id</span> <span class=\"o\">*</span> <span class=\"n\">GROUP_SIZE_M</span>\n-<span class=\"c1\"># if `num_pid_m` isn&#39;t divisible by `GROUP_SIZE_M`, the last group is smaller</span>\n-<span class=\"n\">group_size_m</span> <span class=\"o\">=</span> <span class=\"nb\">min</span><span class=\"p\">(</span><span class=\"n\">num_pid_m</span> <span class=\"o\">-</span> <span class=\"n\">first_pid_m</span><span class=\"p\">,</span> <span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">)</span>\n-<span class=\"c1\"># *within groups*, programs are ordered in a column-major order</span>\n-<span class=\"c1\"># row-id of the program in the *launch grid*</span>\n-<span class=\"n\">pid_m</span> <span class=\"o\">=</span> <span class=\"n\">first_pid_m</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">pid</span> <span class=\"o\">%</span> <span class=\"n\">group_size_m</span><span class=\"p\">)</span>\n-<span class=\"c1\"># col-id of the program in the *launch grid*</span>\n-<span class=\"n\">pid_n</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">pid</span> <span class=\"o\">%</span> <span class=\"n\">num_pid_in_group</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"n\">group_size_m</span>\n-</pre></div>\n-</div>\n-</div></blockquote>\n-<p>For example, in the following matmul where each matrix is 9 blocks by 9 blocks,\n-we can see that if we compute the output in row-major ordering, we need to load 90\n-blocks into SRAM to compute the first 9 output blocks, but if we do it in grouped\n-ordering, we only need to load 54 blocks.</p>\n-<blockquote>\n-<div><img alt=\"../../_images/grouped_vs_row_major_ordering.png\" src=\"../../_images/grouped_vs_row_major_ordering.png\" />\n-</div></blockquote>\n-<p>In practice, this can improve the performance of our matrix multiplication kernel by\n-more than 10% on some hardware architecture (e.g., 220 to 245 TFLOPS on A100).</p>\n-</div>\n-</div>\n-<div class=\"section\" id=\"final-result\">\n-<h2>Final Result<a class=\"headerlink\" href=\"#final-result\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n-\n-<span class=\"kn\">import</span> <span class=\"nn\">triton</span>\n-<span class=\"kn\">import</span> <span class=\"nn\">triton.language</span> <span class=\"k\">as</span> <span class=\"nn\">tl</span>\n-\n-<span class=\"c1\"># %</span>\n-<span class=\"c1\"># :code:`triton.jit`&#39;ed functions can be auto-tuned by using the `triton.autotune`</span>\n-<span class=\"c1\"># decorator, which consumes:</span>\n-<span class=\"c1\">#   - A list of :code:`triton.Config` objects that define different configurations of</span>\n-<span class=\"c1\">#       meta-parameters (e.g., BLOCK_SIZE_M) and compilation options (e.g., num_warps) to try</span>\n-<span class=\"c1\">#   - An autotuning *key* whose change in values will trigger evaluation of all the</span>\n-<span class=\"c1\">#       provided configs</span>\n-\n-\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">autotune</span><span class=\"p\">(</span>\n-    <span class=\"n\">configs</span><span class=\"o\">=</span><span class=\"p\">[</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">),</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"s1\">&#39;BLOCK_SIZE_K&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GROUP_SIZE_M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">},</span> <span class=\"n\">num_stages</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">),</span>\n-    <span class=\"p\">],</span>\n-    <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;M&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;N&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;K&#39;</span><span class=\"p\">],</span>\n-<span class=\"p\">)</span>\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">matmul_kernel</span><span class=\"p\">(</span>\n-    <span class=\"c1\"># Pointers to matrices</span>\n-    <span class=\"n\">a_ptr</span><span class=\"p\">,</span> <span class=\"n\">b_ptr</span><span class=\"p\">,</span> <span class=\"n\">c_ptr</span><span class=\"p\">,</span>\n-    <span class=\"c1\"># Matrix dimensions</span>\n-    <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">K</span><span class=\"p\">,</span>\n-    <span class=\"c1\"># The stride variables represent how much to increase the ptr by when moving by 1</span>\n-    <span class=\"c1\"># element in a particular dimension. E.g. stride_am is how much to increase a_ptr</span>\n-    <span class=\"c1\"># by to get the element one row down (A has M rows)</span>\n-    <span class=\"n\">stride_am</span><span class=\"p\">,</span> <span class=\"n\">stride_ak</span><span class=\"p\">,</span>\n-    <span class=\"n\">stride_bk</span><span class=\"p\">,</span> <span class=\"n\">stride_bn</span><span class=\"p\">,</span>\n-    <span class=\"n\">stride_cm</span><span class=\"p\">,</span> <span class=\"n\">stride_cn</span><span class=\"p\">,</span>\n-    <span class=\"c1\"># Meta-parameters</span>\n-    <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span>\n-    <span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span>\n-    <span class=\"n\">ACTIVATION</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span>\n-<span class=\"p\">):</span>\n-    <span class=\"sd\">&quot;&quot;&quot;Kernel for computing the matmul C = A x B.</span>\n-<span class=\"sd\">    A has shape (M, K), B has shape (K, N) and C has shape (M, N)</span>\n-<span class=\"sd\">    &quot;&quot;&quot;</span>\n-    <span class=\"c1\"># -----------------------------------------------------------</span>\n-    <span class=\"c1\"># Map program ids `pid` to the block of C it should compute.</span>\n-    <span class=\"c1\"># This is done in a grouped ordering to promote L2 data reuse</span>\n-    <span class=\"c1\"># See above `L2 Cache Optimizations` section for details</span>\n-    <span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">num_pid_m</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">)</span>\n-    <span class=\"n\">num_pid_n</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)</span>\n-    <span class=\"n\">num_pid_in_group</span> <span class=\"o\">=</span> <span class=\"n\">GROUP_SIZE_M</span> <span class=\"o\">*</span> <span class=\"n\">num_pid_n</span>\n-    <span class=\"n\">group_id</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">//</span> <span class=\"n\">num_pid_in_group</span>\n-    <span class=\"n\">first_pid_m</span> <span class=\"o\">=</span> <span class=\"n\">group_id</span> <span class=\"o\">*</span> <span class=\"n\">GROUP_SIZE_M</span>\n-    <span class=\"n\">group_size_m</span> <span class=\"o\">=</span> <span class=\"nb\">min</span><span class=\"p\">(</span><span class=\"n\">num_pid_m</span> <span class=\"o\">-</span> <span class=\"n\">first_pid_m</span><span class=\"p\">,</span> <span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">)</span>\n-    <span class=\"n\">pid_m</span> <span class=\"o\">=</span> <span class=\"n\">first_pid_m</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">pid</span> <span class=\"o\">%</span> <span class=\"n\">group_size_m</span><span class=\"p\">)</span>\n-    <span class=\"n\">pid_n</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">pid</span> <span class=\"o\">%</span> <span class=\"n\">num_pid_in_group</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"n\">group_size_m</span>\n-\n-    <span class=\"c1\"># ----------------------------------------------------------</span>\n-    <span class=\"c1\"># Create pointers for the first blocks of A and B.</span>\n-    <span class=\"c1\"># We will advance this pointer as we move in the K direction</span>\n-    <span class=\"c1\"># and accumulate</span>\n-    <span class=\"c1\"># a_ptrs is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers</span>\n-    <span class=\"c1\"># b_ptrs is a block of [BLOCK_SIZE_K, BLOCK_SIZE_n] pointers</span>\n-    <span class=\"c1\"># see above `Pointer Arithmetics` section for details</span>\n-    <span class=\"n\">offs_am</span> <span class=\"o\">=</span> <span class=\"n\">pid_m</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE_M</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">)</span>\n-    <span class=\"n\">offs_bn</span> <span class=\"o\">=</span> <span class=\"n\">pid_n</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE_N</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)</span>\n-    <span class=\"n\">offs_k</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">)</span>\n-    <span class=\"n\">a_ptrs</span> <span class=\"o\">=</span> <span class=\"n\">a_ptr</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">offs_am</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">stride_am</span> <span class=\"o\">+</span> <span class=\"n\">offs_k</span><span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">*</span> <span class=\"n\">stride_ak</span><span class=\"p\">)</span>\n-    <span class=\"n\">b_ptrs</span> <span class=\"o\">=</span> <span class=\"n\">b_ptr</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">offs_k</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">stride_bk</span> <span class=\"o\">+</span> <span class=\"n\">offs_bn</span><span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">*</span> <span class=\"n\">stride_bn</span><span class=\"p\">)</span>\n-\n-    <span class=\"c1\"># -----------------------------------------------------------</span>\n-    <span class=\"c1\"># Iterate to compute a block of the C matrix</span>\n-    <span class=\"c1\"># We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block</span>\n-    <span class=\"c1\"># of fp32 values for higher accuracy.</span>\n-    <span class=\"c1\"># `accumulator` will be converted back to fp16 after the loop</span>\n-    <span class=\"n\">accumulator</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"k\">for</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">K</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_K</span><span class=\"p\">):</span>\n-        <span class=\"c1\"># Note that for simplicity, we don&#39;t apply a mask here.</span>\n-        <span class=\"c1\"># This means that if K is not a multiple of BLOCK_SIZE_K,</span>\n-        <span class=\"c1\"># this will access out-of-bounds memory and produce an</span>\n-        <span class=\"c1\"># error or (worse!) incorrect results.</span>\n-        <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">a_ptrs</span><span class=\"p\">)</span>\n-        <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">b_ptrs</span><span class=\"p\">)</span>\n-        <span class=\"c1\"># We accumulate along the K dimension</span>\n-        <span class=\"n\">accumulator</span> <span class=\"o\">+=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n-        <span class=\"c1\"># Advance the ptrs to the next K block</span>\n-        <span class=\"n\">a_ptrs</span> <span class=\"o\">+=</span> <span class=\"n\">BLOCK_SIZE_K</span> <span class=\"o\">*</span> <span class=\"n\">stride_ak</span>\n-        <span class=\"n\">b_ptrs</span> <span class=\"o\">+=</span> <span class=\"n\">BLOCK_SIZE_K</span> <span class=\"o\">*</span> <span class=\"n\">stride_bk</span>\n-    <span class=\"c1\"># you can fuse arbitrary activation functions here</span>\n-    <span class=\"c1\"># while the accumulator is still in FP32!</span>\n-    <span class=\"k\">if</span> <span class=\"n\">ACTIVATION</span><span class=\"p\">:</span>\n-        <span class=\"n\">accumulator</span> <span class=\"o\">=</span> <span class=\"n\">ACTIVATION</span><span class=\"p\">(</span><span class=\"n\">accumulator</span><span class=\"p\">)</span>\n-    <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">accumulator</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">)</span>\n-\n-    <span class=\"c1\"># -----------------------------------------------------------</span>\n-    <span class=\"c1\"># Write back the block of the output matrix C</span>\n-    <span class=\"n\">offs_cm</span> <span class=\"o\">=</span> <span class=\"n\">pid_m</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE_M</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">)</span>\n-    <span class=\"n\">offs_cn</span> <span class=\"o\">=</span> <span class=\"n\">pid_n</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE_N</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)</span>\n-    <span class=\"n\">c_ptrs</span> <span class=\"o\">=</span> <span class=\"n\">c_ptr</span> <span class=\"o\">+</span> <span class=\"n\">stride_cm</span> <span class=\"o\">*</span> <span class=\"n\">offs_cm</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">stride_cn</span> <span class=\"o\">*</span> <span class=\"n\">offs_cn</span><span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n-    <span class=\"n\">c_mask</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">offs_cm</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"n\">M</span><span class=\"p\">)</span> <span class=\"o\">&amp;</span> <span class=\"p\">(</span><span class=\"n\">offs_cn</span><span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span><span class=\"p\">)</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">c_ptrs</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">c_mask</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"c1\"># we can fuse `leaky_relu` by providing it as an `ACTIVATION` meta-parameter in `_matmul`</span>\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">leaky_relu</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n-    <span class=\"k\">return</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mf\">0.01</span> <span class=\"o\">*</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p>We can now create a convenience wrapper function that only takes two input tensors\n-and (1) checks any shape constraint; (2) allocates the output; (3) launches the above kernel</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">matmul</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n-    <span class=\"c1\"># checks constraints</span>\n-    <span class=\"k\">assert</span> <span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"n\">b</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"s2\">&quot;incompatible dimensions&quot;</span>\n-    <span class=\"k\">assert</span> <span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">is_contiguous</span><span class=\"p\">(),</span> <span class=\"s2\">&quot;matrix A must be contiguous&quot;</span>\n-    <span class=\"k\">assert</span> <span class=\"n\">b</span><span class=\"o\">.</span><span class=\"n\">is_contiguous</span><span class=\"p\">(),</span> <span class=\"s2\">&quot;matrix B must be contiguous&quot;</span>\n-    <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">K</span> <span class=\"o\">=</span> <span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n-    <span class=\"n\">K</span><span class=\"p\">,</span> <span class=\"n\">N</span> <span class=\"o\">=</span> <span class=\"n\">b</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n-    <span class=\"k\">assert</span> <span class=\"p\">(</span>\n-        <span class=\"n\">K</span> <span class=\"o\">%</span> <span class=\"mi\">32</span> <span class=\"o\">==</span> <span class=\"mi\">0</span>\n-    <span class=\"p\">),</span> <span class=\"s2\">&quot;We don&#39;t check memory-out-of-bounds with K so K must be divisible by BLOCK_SIZE_K&quot;</span>\n-    <span class=\"c1\"># allocates output</span>\n-    <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">),</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># 1D launch kernel where each block gets its own program.</span>\n-    <span class=\"n\">grid</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">META</span><span class=\"p\">:</span> <span class=\"p\">(</span>\n-        <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">META</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE_M&#39;</span><span class=\"p\">])</span> <span class=\"o\">*</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">META</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">]),</span>\n-    <span class=\"p\">)</span>\n-    <span class=\"n\">matmul_kernel</span><span class=\"p\">[</span><span class=\"n\">grid</span><span class=\"p\">](</span>\n-        <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"p\">,</span>\n-        <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">K</span><span class=\"p\">,</span>\n-        <span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">),</span>\n-        <span class=\"n\">b</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">b</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">),</span>\n-        <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">),</span>\n-        <span class=\"n\">ACTIVATION</span><span class=\"o\">=</span><span class=\"n\">activation</span><span class=\"p\">,</span>\n-    <span class=\"p\">)</span>\n-    <span class=\"k\">return</span> <span class=\"n\">c</span>\n-</pre></div>\n-</div>\n-</div>\n-<div class=\"section\" id=\"unit-test\">\n-<h2>Unit Test<a class=\"headerlink\" href=\"#unit-test\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>We can test our custom matrix multiplication operation against a native torch implementation (i.e., cuBLAS)</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">manual_seed</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-<span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">((</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">),</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">)</span>\n-<span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">((</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">),</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">)</span>\n-<span class=\"n\">triton_output</span> <span class=\"o\">=</span> <span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n-<span class=\"n\">torch_output</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n-<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;triton_output=</span><span class=\"si\">{</span><span class=\"n\">triton_output</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n-<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;torch_output=</span><span class=\"si\">{</span><span class=\"n\">torch_output</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n-<span class=\"k\">if</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">allclose</span><span class=\"p\">(</span><span class=\"n\">triton_output</span><span class=\"p\">,</span> <span class=\"n\">torch_output</span><span class=\"p\">):</span>\n-    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;\u2705 Triton and Torch match&quot;</span><span class=\"p\">)</span>\n-<span class=\"k\">else</span><span class=\"p\">:</span>\n-    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;\u274c Triton and Torch differ&quot;</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>triton_output=tensor([[  1.1045, -36.9688,  31.4688,  ..., -11.3984,  24.4531, -32.3438],\n-        [  6.3555, -19.6094,  34.0938,  ...,  -5.8945,   5.2891,   6.8867],\n-        [-32.0625,   5.9492,  15.3984,  ..., -21.3906, -23.9844, -10.1328],\n-        ...,\n-        [ -5.7031,   7.4492,   8.2656,  ..., -10.6953, -40.0000,  17.7500],\n-        [ 25.5000,  24.3281,  -8.4688,  ..., -18.9375,  32.5312, -29.9219],\n-        [ -5.3477,   4.9844,  11.8906,  ...,   5.5898,   6.4023, -17.3125]],\n-       device=&#39;cuda:0&#39;, dtype=torch.float16)\n-torch_output=tensor([[  1.1045, -36.9688,  31.4688,  ..., -11.3906,  24.4531, -32.3438],\n-        [  6.3516, -19.6094,  34.0938,  ...,  -5.8906,   5.2812,   6.8828],\n-        [-32.0625,   5.9531,  15.3984,  ..., -21.4062, -23.9844, -10.1328],\n-        ...,\n-        [ -5.7070,   7.4492,   8.2656,  ..., -10.6953, -40.0000,  17.7500],\n-        [ 25.5000,  24.3438,  -8.4609,  ..., -18.9375,  32.5312, -29.9219],\n-        [ -5.3477,   4.9805,  11.8828,  ...,   5.5859,   6.4023, -17.3125]],\n-       device=&#39;cuda:0&#39;, dtype=torch.float16)\n-\u2705 Triton and Torch match\n-</pre></div>\n-</div>\n-</div>\n-<div class=\"section\" id=\"benchmark\">\n-<h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<div class=\"section\" id=\"square-matrix-performance\">\n-<h3>Square Matrix Performance<a class=\"headerlink\" href=\"#square-matrix-performance\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>We can now compare the performance of our kernel against that of cuBLAS. Here we focus on square matrices, but feel free to arrange this script as you wish to benchmark any other matrix shape.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">perf_report</span><span class=\"p\">(</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">Benchmark</span><span class=\"p\">(</span>\n-        <span class=\"n\">x_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;M&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;N&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;K&#39;</span><span class=\"p\">],</span>  <span class=\"c1\"># argument names to use as an x-axis for the plot</span>\n-        <span class=\"n\">x_vals</span><span class=\"o\">=</span><span class=\"p\">[</span>\n-            <span class=\"mi\">128</span> <span class=\"o\">*</span> <span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">33</span><span class=\"p\">)</span>\n-        <span class=\"p\">],</span>  <span class=\"c1\"># different possible values for `x_name`</span>\n-        <span class=\"n\">line_arg</span><span class=\"o\">=</span><span class=\"s1\">&#39;provider&#39;</span><span class=\"p\">,</span>  <span class=\"c1\"># argument name whose value corresponds to a different line in the plot</span>\n-        <span class=\"c1\"># possible values for `line_arg``</span>\n-        <span class=\"n\">line_vals</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;cublas&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;cublas + relu&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;triton + relu&#39;</span><span class=\"p\">],</span>\n-        <span class=\"c1\"># label name for the lines</span>\n-        <span class=\"n\">line_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">&quot;cuBLAS&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;cuBLAS (+ torch.nn.LeakyReLU)&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;Triton&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;Triton (+ LeakyReLU)&quot;</span><span class=\"p\">],</span>\n-        <span class=\"c1\"># line styles</span>\n-        <span class=\"n\">styles</span><span class=\"o\">=</span><span class=\"p\">[(</span><span class=\"s1\">&#39;green&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;green&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;--&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;blue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;blue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;--&#39;</span><span class=\"p\">)],</span>\n-        <span class=\"n\">ylabel</span><span class=\"o\">=</span><span class=\"s2\">&quot;TFLOPS&quot;</span><span class=\"p\">,</span>  <span class=\"c1\"># label name for the y-axis</span>\n-        <span class=\"n\">plot_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;matmul-performance&quot;</span><span class=\"p\">,</span>  <span class=\"c1\"># name for the plot. Used also as a file name for saving the plot.</span>\n-        <span class=\"n\">args</span><span class=\"o\">=</span><span class=\"p\">{},</span>\n-    <span class=\"p\">)</span>\n-<span class=\"p\">)</span>\n-<span class=\"k\">def</span> <span class=\"nf\">benchmark</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">K</span><span class=\"p\">,</span> <span class=\"n\">provider</span><span class=\"p\">):</span>\n-    <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">((</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">K</span><span class=\"p\">),</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">)</span>\n-    <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">((</span><span class=\"n\">K</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">),</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">)</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;cublas&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">))</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">))</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;cublas + relu&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">torch_relu</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span>\n-            <span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">torch_relu</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">))</span>\n-        <span class=\"p\">)</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;triton + relu&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span>\n-            <span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">leaky_relu</span><span class=\"p\">)</span>\n-        <span class=\"p\">)</span>\n-    <span class=\"n\">perf</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">ms</span><span class=\"p\">:</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">M</span> <span class=\"o\">*</span> <span class=\"n\">N</span> <span class=\"o\">*</span> <span class=\"n\">K</span> <span class=\"o\">*</span> <span class=\"mf\">1e-12</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">ms</span> <span class=\"o\">*</span> <span class=\"mf\">1e-3</span><span class=\"p\">)</span>\n-    <span class=\"k\">return</span> <span class=\"n\">perf</span><span class=\"p\">(</span><span class=\"n\">ms</span><span class=\"p\">),</span> <span class=\"n\">perf</span><span class=\"p\">(</span><span class=\"n\">max_ms</span><span class=\"p\">),</span> <span class=\"n\">perf</span><span class=\"p\">(</span><span class=\"n\">min_ms</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"n\">benchmark</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">show_plots</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">print_data</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<img alt=\"03 matrix multiplication\" class=\"sphx-glr-single-img\" src=\"../../_images/sphx_glr_03-matrix-multiplication_001.png\" />\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>matmul-performance:\n-         M     cuBLAS  ...     Triton  Triton (+ LeakyReLU)\n-0    256.0   2.978909  ...   3.276800              2.978909\n-1    384.0   7.372800  ...   7.899428              8.507077\n-2    512.0  14.563555  ...  16.384000             16.384000\n-3    640.0  22.260869  ...  24.380953             24.380953\n-4    768.0  32.768000  ...  35.389441             34.028308\n-5    896.0  37.971025  ...  40.140799             39.025776\n-6   1024.0  49.932191  ...  53.773130             52.428801\n-7   1152.0  45.242181  ...  48.161033             47.396572\n-8   1280.0  51.200001  ...  57.690139             57.690139\n-9   1408.0  64.138541  ...  68.147202             67.305878\n-10  1536.0  79.526831  ...  79.526831             79.526831\n-11  1664.0  62.929456  ...  63.372618             62.929456\n-12  1792.0  72.512412  ...  63.142831             62.790080\n-13  1920.0  69.120002  ...  71.257735             70.892307\n-14  2048.0  73.262953  ...  78.033565             77.672296\n-15  2176.0  83.155572  ...  87.115360             86.739860\n-16  2304.0  68.251065  ...  77.810656             77.810656\n-17  2432.0  71.305746  ...  75.522751             75.320281\n-18  2560.0  77.833728  ...  82.539044             82.125311\n-19  2688.0  83.737433  ...  91.185232             90.748936\n-20  2816.0  84.523664  ...  81.445766             84.523664\n-21  2944.0  81.298583  ...  83.899046             84.040530\n-22  3072.0  82.540970  ...  90.164177             89.735509\n-23  3200.0  84.656085  ...  96.385543             96.240602\n-24  3328.0  83.226931  ...  85.602017             84.249616\n-25  3456.0  81.849303  ...  85.133652             84.864807\n-26  3584.0  87.466332  ...  99.684470             99.354022\n-27  3712.0  81.548851  ...  84.159518             87.706180\n-28  3840.0  84.874902  ...  86.535214             91.398346\n-29  3968.0  88.040360  ...  92.442373             86.480463\n-30  4096.0  93.760204  ...  91.992956             90.871857\n-\n-[31 rows x 5 columns]\n-</pre></div>\n-</div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 6 minutes  30.096 seconds)</p>\n-<div class=\"sphx-glr-footer class sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-03-matrix-multiplication-py\">\n-<div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/d5fee5b55a64e47f1b5724ec39adf171/03-matrix-multiplication.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">03-matrix-multiplication.py</span></code></a></p>\n-</div>\n-<div class=\"sphx-glr-download sphx-glr-download-jupyter docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/b51b68bc1c6b1a5e509f67800b6235af/03-matrix-multiplication.ipynb\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Jupyter</span> <span class=\"pre\">notebook:</span> <span class=\"pre\">03-matrix-multiplication.ipynb</span></code></a></p>\n-</div>\n-</div>\n-<p class=\"sphx-glr-signature\"><a class=\"reference external\" href=\"https://sphinx-gallery.github.io\">Gallery generated by Sphinx-Gallery</a></p>\n-</div>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"04-low-memory-dropout.html\" class=\"btn btn-neutral float-right\" title=\"Low-Memory Dropout\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"02-fused-softmax.html\" class=\"btn btn-neutral float-left\" title=\"Fused Softmax\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"03-matrix-multiplication.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/tutorials/04-low-memory-dropout.html", "status": "removed", "additions": 0, "deletions": 453, "changes": 453, "file_content_changes": "@@ -1,453 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Low-Memory Dropout &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"Layer Normalization\" href=\"05-layer-norm.html\" />\n-    <link rel=\"prev\" title=\"Matrix Multiplication\" href=\"03-matrix-multiplication.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../installation.html\">Installation</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"index.html\">Tutorials</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"01-vector-add.html\">Vector Addition</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"02-fused-softmax.html\">Fused Softmax</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"03-matrix-multiplication.html\">Matrix Multiplication</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">Low-Memory Dropout</a><ul>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#baseline\">Baseline</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#seeded-dropout\">Seeded dropout</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#exercises\">Exercises</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#references\">References</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"05-layer-norm.html\">Layer Normalization</a></li>\n-</ul>\n-</li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"index.html\">Tutorials</a> &raquo;</li>\n-        \n-      <li>Low-Memory Dropout</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/getting-started/tutorials/04-low-memory-dropout.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"sphx-glr-download-link-note admonition note\">\n-<p class=\"admonition-title\">Note</p>\n-<p>Click <a class=\"reference internal\" href=\"#sphx-glr-download-getting-started-tutorials-04-low-memory-dropout-py\"><span class=\"std std-ref\">here</span></a>\n-to download the full example code</p>\n-</div>\n-<div class=\"sphx-glr-example-title section\" id=\"low-memory-dropout\">\n-<span id=\"sphx-glr-getting-started-tutorials-04-low-memory-dropout-py\"></span><h1>Low-Memory Dropout<a class=\"headerlink\" href=\"#low-memory-dropout\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p>In this tutorial, you will write a memory-efficient implementation of dropout whose state\n-will be composed of a single int32 seed. This differs from more traditional implementations of dropout,\n-whose state is generally composed of a bit mask tensor of the same shape as the input. You will learn about:</p>\n-<ul class=\"simple\">\n-<li><p>The limitations of naive implementations of Dropout with PyTorch</p></li>\n-<li><p>Parallel pseudo-random number generation in Triton</p></li>\n-</ul>\n-<div class=\"section\" id=\"baseline\">\n-<h2>Baseline<a class=\"headerlink\" href=\"#baseline\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>The <em>dropout</em> operator was first introduced in <a class=\"reference internal\" href=\"#srivastava2014\" id=\"id1\"><span>[SRIVASTAVA2014]</span></a> as a way to improve the performance\n-of deep neural networks in low-data regime (i.e. regularization).</p>\n-<p>It takes a vector as input and produces a vector of the same shape as output. Each scalar in the\n-output has a probability <span class=\"math notranslate nohighlight\">\\(p\\)</span> of being changed to zero and otherwise it is copied from the input.\n-This forces the network to perform well even when only <span class=\"math notranslate nohighlight\">\\(1 - p\\)</span> scalars from the input are available.</p>\n-<p>At evaluation time we want to use the full power of the network so we set <span class=\"math notranslate nohighlight\">\\(p=0\\)</span>. Naively this would\n-increase the norm of the output (which can be a bad thing, e.g. it can lead to artificial decrease\n-in the output softmax temperature). To prevent this we multiply the output by <span class=\"math notranslate nohighlight\">\\(\\frac{1}{1 - p}\\)</span>, which\n-keeps the norm consistent regardless of the dropout probability.</p>\n-<p>Let\u2019s first take a look at the baseline implementation.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">tabulate</span>\n-<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n-\n-<span class=\"kn\">import</span> <span class=\"nn\">triton</span>\n-<span class=\"kn\">import</span> <span class=\"nn\">triton.language</span> <span class=\"k\">as</span> <span class=\"nn\">tl</span>\n-\n-\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">_dropout</span><span class=\"p\">(</span>\n-        <span class=\"n\">x_ptr</span><span class=\"p\">,</span>  <span class=\"c1\"># pointer to the input</span>\n-        <span class=\"n\">x_keep_ptr</span><span class=\"p\">,</span>  <span class=\"c1\"># pointer to a mask of 0s and 1s</span>\n-        <span class=\"n\">output_ptr</span><span class=\"p\">,</span>  <span class=\"c1\"># pointer to the output</span>\n-        <span class=\"n\">n_elements</span><span class=\"p\">,</span>  <span class=\"c1\"># number of elements in the `x` tensor</span>\n-        <span class=\"n\">p</span><span class=\"p\">,</span>  <span class=\"c1\"># probability that an element of `x` is changed to zero</span>\n-        <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span>\n-<span class=\"p\">):</span>\n-    <span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">block_start</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE</span>\n-    <span class=\"n\">offsets</span> <span class=\"o\">=</span> <span class=\"n\">block_start</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">)</span>\n-    <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">offsets</span> <span class=\"o\">&lt;</span> <span class=\"n\">n_elements</span>\n-    <span class=\"c1\"># Load data</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">x_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"n\">x_keep</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">x_keep_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># The line below is the crucial part, described in the paragraph above!</span>\n-    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">x_keep</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"o\">-</span> <span class=\"n\">p</span><span class=\"p\">),</span> <span class=\"mf\">0.0</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># Write-back output</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">output_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"k\">def</span> <span class=\"nf\">dropout</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">x_keep</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">):</span>\n-    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty_like</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-    <span class=\"k\">assert</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">is_contiguous</span><span class=\"p\">()</span>\n-    <span class=\"n\">n_elements</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span>\n-    <span class=\"n\">grid</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">meta</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">n_elements</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">]),)</span>\n-    <span class=\"n\">_dropout</span><span class=\"p\">[</span><span class=\"n\">grid</span><span class=\"p\">](</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">x_keep</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">n_elements</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">)</span>\n-    <span class=\"k\">return</span> <span class=\"n\">output</span>\n-\n-\n-<span class=\"c1\"># Input tensor</span>\n-<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,))</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n-<span class=\"c1\"># Dropout mask</span>\n-<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span>\n-<span class=\"n\">x_keep</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,))</span> <span class=\"o\">&gt;</span> <span class=\"n\">p</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">int32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n-<span class=\"c1\">#</span>\n-<span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">dropout</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">x_keep</span><span class=\"o\">=</span><span class=\"n\">x_keep</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>\n-<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tabulate</span><span class=\"o\">.</span><span class=\"n\">tabulate</span><span class=\"p\">([</span>\n-    <span class=\"p\">[</span><span class=\"s2\">&quot;input&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span>\n-    <span class=\"p\">[</span><span class=\"s2\">&quot;keep mask&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">x_keep</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span>\n-    <span class=\"p\">[</span><span class=\"s2\">&quot;output&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">output</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n-<span class=\"p\">]))</span>\n-</pre></div>\n-</div>\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>---------  -------  ---------  --------  --------  --------  --------  --------  --------  ---------  ---------\n-input      1.541    -0.293429  -2.17879  0.568431  -1.08452  -1.3986   0.403347  0.838026  -0.719258  -0.403344\n-keep mask  1         1          0        1          0         1        1         0          0          0\n-output     3.08199  -0.586858   0        1.13686    0        -2.79719  0.806694  0          0          0\n----------  -------  ---------  --------  --------  --------  --------  --------  --------  ---------  ---------\n-</pre></div>\n-</div>\n-</div>\n-<div class=\"section\" id=\"seeded-dropout\">\n-<h2>Seeded dropout<a class=\"headerlink\" href=\"#seeded-dropout\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Above implementation of dropout works fine, but it can be a bit awkward to deal with. Firstly\n-we need to store the dropout mask for backpropagation. Secondly, dropout state management can get\n-very tricky when using recompute/checkpointing (e.g. see all the notes about <cite>preserve_rng_state</cite> in\n-<a class=\"reference external\" href=\"https://pytorch.org/docs/1.9.0/checkpoint.html\">https://pytorch.org/docs/1.9.0/checkpoint.html</a>). In this tutorial we\u2019ll describe an alternative implementation\n-that (1) has a smaller memory footprint; (2) requires less data movement; and (3) simplifies the management\n-of persisting randomness across multiple invocations of the kernel.</p>\n-<p>Pseudorandom number generation in Triton is simple! In this tutorial we will use the\n-<code class=\"code docutils literal notranslate\"><span class=\"pre\">triton.language.rand</span></code> function which generates a block of uniformly distributed <code class=\"code docutils literal notranslate\"><span class=\"pre\">float32</span></code>\n-values in [0, 1), given a seed and a block of <code class=\"code docutils literal notranslate\"><span class=\"pre\">int32</span></code> offsets. But if you need it, Triton also provides\n-other <a class=\"reference internal\" href=\"../../python-api/triton.language.html#random-number-generation\"><span class=\"std std-ref\">random number generation strategies</span></a>.</p>\n-<div class=\"admonition note\">\n-<p class=\"admonition-title\">Note</p>\n-<p>Triton\u2019s implementation of PRNG is based on the Philox algorithm (described on <a class=\"reference internal\" href=\"#salmon2011\" id=\"id2\"><span>[SALMON2011]</span></a>).</p>\n-</div>\n-<p>Let\u2019s put it all together.</p>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">_seeded_dropout</span><span class=\"p\">(</span>\n-        <span class=\"n\">x_ptr</span><span class=\"p\">,</span>\n-        <span class=\"n\">output_ptr</span><span class=\"p\">,</span>\n-        <span class=\"n\">n_elements</span><span class=\"p\">,</span>\n-        <span class=\"n\">p</span><span class=\"p\">,</span>\n-        <span class=\"n\">seed</span><span class=\"p\">,</span>\n-        <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span>\n-<span class=\"p\">):</span>\n-    <span class=\"c1\"># compute memory offsets of elements handled by this instance</span>\n-    <span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">block_start</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE</span>\n-    <span class=\"n\">offsets</span> <span class=\"o\">=</span> <span class=\"n\">block_start</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># load data from x</span>\n-    <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">offsets</span> <span class=\"o\">&lt;</span> <span class=\"n\">n_elements</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">x_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># randomly prune it</span>\n-    <span class=\"n\">random</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"p\">,</span> <span class=\"n\">offsets</span><span class=\"p\">)</span>\n-    <span class=\"n\">x_keep</span> <span class=\"o\">=</span> <span class=\"n\">random</span> <span class=\"o\">&gt;</span> <span class=\"n\">p</span>\n-    <span class=\"c1\"># write-back</span>\n-    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">x_keep</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"o\">-</span> <span class=\"n\">p</span><span class=\"p\">),</span> <span class=\"mf\">0.0</span><span class=\"p\">)</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">output_ptr</span> <span class=\"o\">+</span> <span class=\"n\">offsets</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"k\">def</span> <span class=\"nf\">seeded_dropout</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">seed</span><span class=\"p\">):</span>\n-    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty_like</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-    <span class=\"k\">assert</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">is_contiguous</span><span class=\"p\">()</span>\n-    <span class=\"n\">n_elements</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span>\n-    <span class=\"n\">grid</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">meta</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">n_elements</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">]),)</span>\n-    <span class=\"n\">_seeded_dropout</span><span class=\"p\">[</span><span class=\"n\">grid</span><span class=\"p\">](</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">n_elements</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">seed</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">)</span>\n-    <span class=\"k\">return</span> <span class=\"n\">output</span>\n-\n-\n-<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,))</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n-<span class=\"c1\"># Compare this to the baseline - dropout mask is never instantiated!</span>\n-<span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">seeded_dropout</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">123</span><span class=\"p\">)</span>\n-<span class=\"n\">output2</span> <span class=\"o\">=</span> <span class=\"n\">seeded_dropout</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">123</span><span class=\"p\">)</span>\n-<span class=\"n\">output3</span> <span class=\"o\">=</span> <span class=\"n\">seeded_dropout</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">)</span>\n-\n-<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tabulate</span><span class=\"o\">.</span><span class=\"n\">tabulate</span><span class=\"p\">([</span>\n-    <span class=\"p\">[</span><span class=\"s2\">&quot;input&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span>\n-    <span class=\"p\">[</span><span class=\"s2\">&quot;output (seed = 123)&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">output</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span>\n-    <span class=\"p\">[</span><span class=\"s2\">&quot;output (seed = 123)&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">output2</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span>\n-    <span class=\"p\">[</span><span class=\"s2\">&quot;output (seed = 512)&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">output3</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">()</span>\n-<span class=\"p\">]))</span>\n-</pre></div>\n-</div>\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>-------------------  ---------  --------  --------  -------  --------  --------  ---------  ---------  ---------  ---------\n-input                -0.952835  0.371721  0.408716  1.42142  0.149397  -0.67086  -0.214186  -0.431969  -0.707878  -0.106434\n-output (seed = 123)   0         0.743443  0         0        0         -1.34172   0          0         -1.41576   -0.212868\n-output (seed = 123)   0         0.743443  0         0        0         -1.34172   0          0         -1.41576   -0.212868\n-output (seed = 512)   0         0         0.817432  2.84284  0         -1.34172  -0.428372   0          0          0\n--------------------  ---------  --------  --------  -------  --------  --------  ---------  ---------  ---------  ---------\n-</pre></div>\n-</div>\n-<p>Et Voil\u00e0! We have a triton kernel that applies the same dropout mask provided the seed is the same!\n-If you\u2019d like explore further applications of pseudorandomness in GPU programming, we encourage you\n-to explore the <cite>triton/language/random</cite> folder!</p>\n-</div>\n-<div class=\"section\" id=\"exercises\">\n-<h2>Exercises<a class=\"headerlink\" href=\"#exercises\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<ol class=\"arabic simple\">\n-<li><p>Extend the kernel to operate over a matrix and use a vector of seeds - one per row.</p></li>\n-<li><p>Add support for striding.</p></li>\n-<li><p>(challenge) Implement a kernel for sparse Johnson-Lindenstrauss transform which generates the projection matrix one the fly each time using a seed.</p></li>\n-</ol>\n-</div>\n-<div class=\"section\" id=\"references\">\n-<h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<dl class=\"citation\">\n-<dt class=\"label\" id=\"salmon2011\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id2\">SALMON2011</a></span></dt>\n-<dd><p>John K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw, \u201cParallel Random Numbers: As Easy as 1, 2, 3\u201d, 2011</p>\n-</dd>\n-<dt class=\"label\" id=\"srivastava2014\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id1\">SRIVASTAVA2014</a></span></dt>\n-<dd><p>Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov, \u201cDropout: A Simple Way to Prevent Neural Networks from Overfitting\u201d, JMLR 2014</p>\n-</dd>\n-</dl>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  0.324 seconds)</p>\n-<div class=\"sphx-glr-footer class sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-04-low-memory-dropout-py\">\n-<div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/c9aed78977a4c05741d675a38dde3d7d/04-low-memory-dropout.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">04-low-memory-dropout.py</span></code></a></p>\n-</div>\n-<div class=\"sphx-glr-download sphx-glr-download-jupyter docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/bc847dec325798bdc436c4ef5ac8b78a/04-low-memory-dropout.ipynb\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Jupyter</span> <span class=\"pre\">notebook:</span> <span class=\"pre\">04-low-memory-dropout.ipynb</span></code></a></p>\n-</div>\n-</div>\n-<p class=\"sphx-glr-signature\"><a class=\"reference external\" href=\"https://sphinx-gallery.github.io\">Gallery generated by Sphinx-Gallery</a></p>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"05-layer-norm.html\" class=\"btn btn-neutral float-right\" title=\"Layer Normalization\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"03-matrix-multiplication.html\" class=\"btn btn-neutral float-left\" title=\"Matrix Multiplication\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"04-low-memory-dropout.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/tutorials/05-layer-norm.html", "status": "removed", "additions": 0, "deletions": 567, "changes": 567, "file_content_changes": "@@ -1,567 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Layer Normalization &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton\" href=\"../../python-api/triton.html\" />\n-    <link rel=\"prev\" title=\"Low-Memory Dropout\" href=\"04-low-memory-dropout.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../installation.html\">Installation</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"index.html\">Tutorials</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"01-vector-add.html\">Vector Addition</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"02-fused-softmax.html\">Fused Softmax</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"03-matrix-multiplication.html\">Matrix Multiplication</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"04-low-memory-dropout.html\">Low-Memory Dropout</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">Layer Normalization</a></li>\n-</ul>\n-</li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"index.html\">Tutorials</a> &raquo;</li>\n-        \n-      <li>Layer Normalization</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/getting-started/tutorials/05-layer-norm.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"sphx-glr-download-link-note admonition note\">\n-<p class=\"admonition-title\">Note</p>\n-<p>Click <a class=\"reference internal\" href=\"#sphx-glr-download-getting-started-tutorials-05-layer-norm-py\"><span class=\"std std-ref\">here</span></a>\n-to download the full example code</p>\n-</div>\n-<div class=\"sphx-glr-example-title section\" id=\"layer-normalization\">\n-<span id=\"sphx-glr-getting-started-tutorials-05-layer-norm-py\"></span><h1>Layer Normalization<a class=\"headerlink\" href=\"#layer-normalization\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<img alt=\"05 layer norm\" class=\"sphx-glr-single-img\" src=\"../../_images/sphx_glr_05-layer-norm_001.png\" />\n-<p class=\"sphx-glr-script-out\">Out:</p>\n-<div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>layer-norm-backward:\n-          N      Triton       Torch        Apex\n-0    1024.0  361.411758   97.912354  303.407414\n-1    1536.0  409.599994  134.540150  341.333333\n-2    2048.0  491.520012  161.154101  323.368435\n-3    2560.0  461.954908  181.238943  326.808501\n-4    3072.0  515.580429  192.501302  320.556515\n-5    3584.0  554.941930  208.271186  311.652167\n-6    4096.0  561.737163  220.907859  294.323343\n-7    4608.0  502.690905  232.825259  291.799469\n-8    5120.0  525.128191  242.366855  289.129408\n-9    5632.0  540.671974  243.107920  288.820505\n-10   6144.0  546.133354  248.661056  286.322318\n-11   6656.0  527.207907  256.000009  285.257135\n-12   7168.0  503.017523  260.063480  285.293536\n-13   7680.0  483.779539  262.938666  275.928134\n-14   8192.0  463.698115  266.767970  284.526763\n-15   8704.0  413.655443  267.472468  284.987724\n-16   9216.0  427.822068  271.724806  288.375482\n-17   9728.0  436.396262  280.615388  289.667485\n-18  10240.0  446.025405  286.433562  290.153487\n-19  10752.0  428.651173  246.935876  290.267711\n-20  11264.0  426.397479  245.536784  286.980888\n-21  11776.0  420.571432  249.667843  288.981596\n-22  12288.0  416.542386  254.673582  294.617366\n-23  12800.0  410.695192  253.884294  288.180121\n-24  13312.0  409.075539  252.959629  290.443638\n-25  13824.0  404.604870  257.390218  292.056329\n-26  14336.0  394.116833  254.862216  286.959121\n-27  14848.0  385.662341  257.852379  289.952797\n-28  15360.0  380.433442  257.970599  286.433562\n-29  15872.0  370.192407  261.626369  290.562936\n-</pre></div>\n-</div>\n-<div class=\"line-block\">\n-<div class=\"line\"><br /></div>\n-</div>\n-<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n-\n-<span class=\"kn\">import</span> <span class=\"nn\">triton</span>\n-<span class=\"kn\">import</span> <span class=\"nn\">triton.language</span> <span class=\"k\">as</span> <span class=\"nn\">tl</span>\n-\n-<span class=\"k\">try</span><span class=\"p\">:</span>\n-    <span class=\"c1\"># This is https://github.com/NVIDIA/apex, NOT the apex on PyPi, so it</span>\n-    <span class=\"c1\"># should not be added to extras_require in setup.py.</span>\n-    <span class=\"kn\">import</span> <span class=\"nn\">apex</span>\n-    <span class=\"n\">HAS_APEX</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n-<span class=\"k\">except</span> <span class=\"ne\">ModuleNotFoundError</span><span class=\"p\">:</span>\n-    <span class=\"n\">HAS_APEX</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n-\n-\n-<span class=\"c1\"># Forward Pass</span>\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">_layer_norm_fwd_fused</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">W</span><span class=\"p\">,</span> <span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">V</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">,</span>\n-                          <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">):</span>\n-    <span class=\"c1\"># position of elements processed by this program</span>\n-    <span class=\"n\">row</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">cols</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">)</span>\n-    <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">cols</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span>\n-    <span class=\"c1\"># offset data pointers to start at the row of interest</span>\n-    <span class=\"n\">X</span> <span class=\"o\">+=</span> <span class=\"n\">row</span> <span class=\"o\">*</span> <span class=\"n\">stride</span>\n-    <span class=\"n\">Y</span> <span class=\"o\">+=</span> <span class=\"n\">row</span> <span class=\"o\">*</span> <span class=\"n\">stride</span>\n-    <span class=\"c1\"># load data and cast to float32</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">X</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">other</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># compute mean</span>\n-    <span class=\"n\">mean</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">N</span>\n-    <span class=\"c1\"># compute std</span>\n-    <span class=\"n\">xmean</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"o\">-</span> <span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">)</span>\n-    <span class=\"n\">var</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">xmean</span> <span class=\"o\">*</span> <span class=\"n\">xmean</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">N</span>\n-    <span class=\"n\">rstd</span> <span class=\"o\">=</span> <span class=\"mi\">1</span> <span class=\"o\">/</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sqrt</span><span class=\"p\">(</span><span class=\"n\">var</span> <span class=\"o\">+</span> <span class=\"n\">eps</span><span class=\"p\">)</span>\n-    <span class=\"n\">xhat</span> <span class=\"o\">=</span> <span class=\"n\">xmean</span> <span class=\"o\">*</span> <span class=\"n\">rstd</span>\n-    <span class=\"c1\"># write-back mean/rstd</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">M</span> <span class=\"o\">+</span> <span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">mean</span><span class=\"p\">)</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">V</span> <span class=\"o\">+</span> <span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">rstd</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># multiply by weight and add bias</span>\n-    <span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">W</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">B</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">xhat</span> <span class=\"o\">*</span> <span class=\"n\">w</span> <span class=\"o\">+</span> <span class=\"n\">b</span>\n-    <span class=\"c1\"># write-back</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">Y</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"c1\"># Backward pass (DX + partial DW + partial DB)</span>\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">_layer_norm_bwd_dx_fused</span><span class=\"p\">(</span><span class=\"n\">DX</span><span class=\"p\">,</span> <span class=\"n\">DY</span><span class=\"p\">,</span> <span class=\"n\">DW</span><span class=\"p\">,</span> <span class=\"n\">DB</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">W</span><span class=\"p\">,</span> <span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">V</span><span class=\"p\">,</span> <span class=\"n\">Lock</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">,</span>\n-                             <span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">):</span>\n-    <span class=\"c1\"># position of elements processed by this program</span>\n-    <span class=\"n\">row</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">cols</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)</span>\n-    <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">cols</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span>\n-    <span class=\"c1\"># offset data pointers to start at the row of interest</span>\n-    <span class=\"n\">X</span> <span class=\"o\">+=</span> <span class=\"n\">row</span> <span class=\"o\">*</span> <span class=\"n\">stride</span>\n-    <span class=\"n\">DY</span> <span class=\"o\">+=</span> <span class=\"n\">row</span> <span class=\"o\">*</span> <span class=\"n\">stride</span>\n-    <span class=\"n\">DX</span> <span class=\"o\">+=</span> <span class=\"n\">row</span> <span class=\"o\">*</span> <span class=\"n\">stride</span>\n-    <span class=\"c1\"># offset locks and weight/bias gradient pointer</span>\n-    <span class=\"c1\"># each kernel instance accumulates partial sums for</span>\n-    <span class=\"c1\"># DW and DB into one of GROUP_SIZE_M independent buffers</span>\n-    <span class=\"c1\"># these buffers stay in the L2, which allow this kernel</span>\n-    <span class=\"c1\"># to be fast</span>\n-    <span class=\"n\">lock_id</span> <span class=\"o\">=</span> <span class=\"n\">row</span> <span class=\"o\">%</span> <span class=\"n\">GROUP_SIZE_M</span>\n-    <span class=\"n\">Lock</span> <span class=\"o\">+=</span> <span class=\"n\">lock_id</span>\n-    <span class=\"n\">Count</span> <span class=\"o\">=</span> <span class=\"n\">Lock</span> <span class=\"o\">+</span> <span class=\"n\">GROUP_SIZE_M</span>\n-    <span class=\"n\">DW</span> <span class=\"o\">=</span> <span class=\"n\">DW</span> <span class=\"o\">+</span> <span class=\"n\">lock_id</span> <span class=\"o\">*</span> <span class=\"n\">N</span> <span class=\"o\">+</span> <span class=\"n\">cols</span>\n-    <span class=\"n\">DB</span> <span class=\"o\">=</span> <span class=\"n\">DB</span> <span class=\"o\">+</span> <span class=\"n\">lock_id</span> <span class=\"o\">*</span> <span class=\"n\">N</span> <span class=\"o\">+</span> <span class=\"n\">cols</span>\n-    <span class=\"c1\"># load data to SRAM</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">X</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">other</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"n\">dy</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">DY</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">other</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">W</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"n\">mean</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">M</span> <span class=\"o\">+</span> <span class=\"n\">row</span><span class=\"p\">)</span>\n-    <span class=\"n\">rstd</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">V</span> <span class=\"o\">+</span> <span class=\"n\">row</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># compute dx</span>\n-    <span class=\"n\">xhat</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">-</span> <span class=\"n\">mean</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">rstd</span>\n-    <span class=\"n\">wdy</span> <span class=\"o\">=</span> <span class=\"n\">w</span> <span class=\"o\">*</span> <span class=\"n\">dy</span>\n-    <span class=\"n\">xhat</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">xhat</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">)</span>\n-    <span class=\"n\">wdy</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">wdy</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">)</span>\n-    <span class=\"n\">mean1</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">xhat</span> <span class=\"o\">*</span> <span class=\"n\">wdy</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">N</span>\n-    <span class=\"n\">mean2</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">wdy</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">N</span>\n-    <span class=\"n\">dx</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">wdy</span> <span class=\"o\">-</span> <span class=\"p\">(</span><span class=\"n\">xhat</span> <span class=\"o\">*</span> <span class=\"n\">mean1</span> <span class=\"o\">+</span> <span class=\"n\">mean2</span><span class=\"p\">))</span> <span class=\"o\">*</span> <span class=\"n\">rstd</span>\n-    <span class=\"c1\"># write-back dx</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">DX</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">dx</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># accumulate partial sums for dw/db</span>\n-    <span class=\"n\">partial_dw</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">dy</span> <span class=\"o\">*</span> <span class=\"n\">xhat</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">)</span>\n-    <span class=\"n\">partial_db</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">dy</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">)</span>\n-    <span class=\"k\">while</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">atomic_cas</span><span class=\"p\">(</span><span class=\"n\">Lock</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">:</span>\n-        <span class=\"k\">pass</span>\n-    <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">Count</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># first store doesn&#39;t accumulate</span>\n-    <span class=\"k\">if</span> <span class=\"n\">count</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n-        <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">atomic_xchg</span><span class=\"p\">(</span><span class=\"n\">Count</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n-    <span class=\"k\">else</span><span class=\"p\">:</span>\n-        <span class=\"n\">partial_dw</span> <span class=\"o\">+=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">DW</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-        <span class=\"n\">partial_db</span> <span class=\"o\">+=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">DB</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">DW</span><span class=\"p\">,</span> <span class=\"n\">partial_dw</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">DB</span><span class=\"p\">,</span> <span class=\"n\">partial_db</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># release lock</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">atomic_xchg</span><span class=\"p\">(</span><span class=\"n\">Lock</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n-\n-<span class=\"c1\"># Backward pass (total DW + total DB)</span>\n-\n-\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">_layer_norm_bwd_dwdb</span><span class=\"p\">(</span><span class=\"n\">DW</span><span class=\"p\">,</span> <span class=\"n\">DB</span><span class=\"p\">,</span> <span class=\"n\">FINAL_DW</span><span class=\"p\">,</span> <span class=\"n\">FINAL_DB</span><span class=\"p\">,</span> <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span>\n-                         <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">:</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">constexpr</span><span class=\"p\">):</span>\n-    <span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">program_id</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">cols</span> <span class=\"o\">=</span> <span class=\"n\">pid</span> <span class=\"o\">*</span> <span class=\"n\">BLOCK_SIZE_N</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">)</span>\n-    <span class=\"n\">dw</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_N</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n-    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">):</span>\n-        <span class=\"n\">rows</span> <span class=\"o\">=</span> <span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">BLOCK_SIZE_M</span><span class=\"p\">)</span>\n-        <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">rows</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"n\">M</span><span class=\"p\">)</span> <span class=\"o\">&amp;</span> <span class=\"p\">(</span><span class=\"n\">cols</span><span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span><span class=\"p\">)</span>\n-        <span class=\"n\">offs</span> <span class=\"o\">=</span> <span class=\"n\">rows</span><span class=\"p\">[:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">N</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">[</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n-        <span class=\"n\">dw</span> <span class=\"o\">+=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">DW</span> <span class=\"o\">+</span> <span class=\"n\">offs</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">other</span><span class=\"o\">=</span><span class=\"mf\">0.</span><span class=\"p\">)</span>\n-        <span class=\"n\">db</span> <span class=\"o\">+=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">DB</span> <span class=\"o\">+</span> <span class=\"n\">offs</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">other</span><span class=\"o\">=</span><span class=\"mf\">0.</span><span class=\"p\">)</span>\n-    <span class=\"n\">sum_dw</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">dw</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">sum_db</span> <span class=\"o\">=</span> <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">FINAL_DW</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">sum_dw</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">cols</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span><span class=\"p\">)</span>\n-    <span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">FINAL_DB</span> <span class=\"o\">+</span> <span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">sum_db</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"o\">=</span><span class=\"n\">cols</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"k\">class</span> <span class=\"nc\">LayerNorm</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">autograd</span><span class=\"o\">.</span><span class=\"n\">Function</span><span class=\"p\">):</span>\n-\n-    <span class=\"nd\">@staticmethod</span>\n-    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">normalized_shape</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">):</span>\n-        <span class=\"c1\"># allocate output</span>\n-        <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty_like</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-        <span class=\"c1\"># reshape input data into 2D tensor</span>\n-        <span class=\"n\">x_arg</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n-        <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span> <span class=\"o\">=</span> <span class=\"n\">x_arg</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n-        <span class=\"n\">mean</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-        <span class=\"n\">rstd</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-        <span class=\"c1\"># Less than 64KB per feature: enqueue fused kernel</span>\n-        <span class=\"n\">MAX_FUSED_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">65536</span> <span class=\"o\">//</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">element_size</span><span class=\"p\">()</span>\n-        <span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">=</span> <span class=\"nb\">min</span><span class=\"p\">(</span><span class=\"n\">MAX_FUSED_SIZE</span><span class=\"p\">,</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">next_power_of_2</span><span class=\"p\">(</span><span class=\"n\">N</span><span class=\"p\">))</span>\n-        <span class=\"k\">if</span> <span class=\"n\">N</span> <span class=\"o\">&gt;</span> <span class=\"n\">BLOCK_SIZE</span><span class=\"p\">:</span>\n-            <span class=\"k\">raise</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">(</span><span class=\"s2\">&quot;This layer norm doesn&#39;t support feature dim &gt;= 64KB.&quot;</span><span class=\"p\">)</span>\n-        <span class=\"c1\"># heuristics for number of warps</span>\n-        <span class=\"n\">num_warps</span> <span class=\"o\">=</span> <span class=\"nb\">min</span><span class=\"p\">(</span><span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">//</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"mi\">8</span><span class=\"p\">)</span>\n-        <span class=\"c1\"># enqueue kernel</span>\n-        <span class=\"n\">_layer_norm_fwd_fused</span><span class=\"p\">[(</span><span class=\"n\">M</span><span class=\"p\">,)](</span><span class=\"n\">x_arg</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">,</span> <span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"n\">rstd</span><span class=\"p\">,</span>\n-                                    <span class=\"n\">x_arg</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">,</span>\n-                                    <span class=\"n\">BLOCK_SIZE</span><span class=\"o\">=</span><span class=\"n\">BLOCK_SIZE</span><span class=\"p\">,</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"n\">num_warps</span><span class=\"p\">)</span>\n-        <span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">save_for_backward</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">,</span> <span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"n\">rstd</span><span class=\"p\">)</span>\n-        <span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">=</span> <span class=\"n\">BLOCK_SIZE</span>\n-        <span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">num_warps</span> <span class=\"o\">=</span> <span class=\"n\">num_warps</span>\n-        <span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">eps</span> <span class=\"o\">=</span> <span class=\"n\">eps</span>\n-        <span class=\"k\">return</span> <span class=\"n\">y</span>\n-\n-    <span class=\"nd\">@staticmethod</span>\n-    <span class=\"k\">def</span> <span class=\"nf\">backward</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"n\">dy</span><span class=\"p\">):</span>\n-        <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"o\">=</span> <span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">saved_tensors</span>\n-        <span class=\"c1\"># heuristics for amount of parallel reduction stream for DG/DB</span>\n-        <span class=\"n\">N</span> <span class=\"o\">=</span> <span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n-        <span class=\"n\">GROUP_SIZE_M</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n-        <span class=\"k\">if</span> <span class=\"n\">N</span> <span class=\"o\">&lt;=</span> <span class=\"mi\">8192</span><span class=\"p\">:</span> <span class=\"n\">GROUP_SIZE_M</span> <span class=\"o\">=</span> <span class=\"mi\">96</span>\n-        <span class=\"k\">if</span> <span class=\"n\">N</span> <span class=\"o\">&lt;=</span> <span class=\"mi\">4096</span><span class=\"p\">:</span> <span class=\"n\">GROUP_SIZE_M</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>\n-        <span class=\"k\">if</span> <span class=\"n\">N</span> <span class=\"o\">&lt;=</span> <span class=\"mi\">1024</span><span class=\"p\">:</span> <span class=\"n\">GROUP_SIZE_M</span> <span class=\"o\">=</span> <span class=\"mi\">256</span>\n-        <span class=\"c1\"># allocate output</span>\n-        <span class=\"n\">locks</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">int32</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-        <span class=\"n\">_dw</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n-        <span class=\"n\">_db</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n-        <span class=\"n\">dw</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n-        <span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span>\n-        <span class=\"n\">dx</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">empty_like</span><span class=\"p\">(</span><span class=\"n\">dy</span><span class=\"p\">)</span>\n-        <span class=\"c1\"># enqueue kernel using forward pass heuristics</span>\n-        <span class=\"c1\"># also compute partial sums for DW and DB</span>\n-        <span class=\"n\">x_arg</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n-        <span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span> <span class=\"o\">=</span> <span class=\"n\">x_arg</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n-        <span class=\"n\">_layer_norm_bwd_dx_fused</span><span class=\"p\">[(</span><span class=\"n\">M</span><span class=\"p\">,)](</span><span class=\"n\">dx</span><span class=\"p\">,</span> <span class=\"n\">dy</span><span class=\"p\">,</span> <span class=\"n\">_dw</span><span class=\"p\">,</span> <span class=\"n\">_db</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">locks</span><span class=\"p\">,</span>\n-                                       <span class=\"n\">x_arg</span><span class=\"o\">.</span><span class=\"n\">stride</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">eps</span><span class=\"p\">,</span>\n-                                       <span class=\"n\">BLOCK_SIZE_N</span><span class=\"o\">=</span><span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">BLOCK_SIZE</span><span class=\"p\">,</span>\n-                                       <span class=\"n\">GROUP_SIZE_M</span><span class=\"o\">=</span><span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">,</span>\n-                                       <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"n\">ctx</span><span class=\"o\">.</span><span class=\"n\">num_warps</span><span class=\"p\">)</span>\n-        <span class=\"n\">grid</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">meta</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">cdiv</span><span class=\"p\">(</span><span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE_N&#39;</span><span class=\"p\">])]</span>\n-        <span class=\"c1\"># accumulate partial sums in separate kernel</span>\n-        <span class=\"n\">_layer_norm_bwd_dwdb</span><span class=\"p\">[</span><span class=\"n\">grid</span><span class=\"p\">](</span><span class=\"n\">_dw</span><span class=\"p\">,</span> <span class=\"n\">_db</span><span class=\"p\">,</span> <span class=\"n\">dw</span><span class=\"p\">,</span> <span class=\"n\">db</span><span class=\"p\">,</span> <span class=\"n\">GROUP_SIZE_M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span>\n-                                   <span class=\"n\">BLOCK_SIZE_M</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span>\n-                                   <span class=\"n\">BLOCK_SIZE_N</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">)</span>\n-        <span class=\"k\">return</span> <span class=\"n\">dx</span><span class=\"p\">,</span> <span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">dw</span><span class=\"p\">,</span> <span class=\"n\">db</span><span class=\"p\">,</span> <span class=\"kc\">None</span>\n-\n-\n-<span class=\"n\">layer_norm</span> <span class=\"o\">=</span> <span class=\"n\">LayerNorm</span><span class=\"o\">.</span><span class=\"n\">apply</span>\n-\n-\n-<span class=\"k\">def</span> <span class=\"nf\">test_layer_norm</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"o\">=</span><span class=\"mf\">1e-5</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">):</span>\n-    <span class=\"c1\"># create data</span>\n-    <span class=\"n\">x_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">)</span>\n-    <span class=\"n\">w_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">x_shape</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">)</span>\n-    <span class=\"n\">weight</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">requires_grad</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"n\">bias</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">requires_grad</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mf\">2.3</span> <span class=\"o\">+</span> <span class=\"mf\">0.5</span> <span class=\"o\">*</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">x_shape</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-    <span class=\"n\">dy</span> <span class=\"o\">=</span> <span class=\"mf\">.1</span> <span class=\"o\">*</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn_like</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-    <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">requires_grad_</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># forward pass</span>\n-    <span class=\"n\">y_tri</span> <span class=\"o\">=</span> <span class=\"n\">layer_norm</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">)</span>\n-    <span class=\"n\">y_ref</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">functional</span><span class=\"o\">.</span><span class=\"n\">layer_norm</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">dtype</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># backward pass (triton)</span>\n-    <span class=\"n\">y_tri</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">(</span><span class=\"n\">dy</span><span class=\"p\">,</span> <span class=\"n\">retain_graph</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"n\">dx_tri</span><span class=\"p\">,</span> <span class=\"n\">dw_tri</span><span class=\"p\">,</span> <span class=\"n\">db_tri</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">grad</span><span class=\"o\">.</span><span class=\"n\">clone</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">]]</span>\n-    <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">grad</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"o\">.</span><span class=\"n\">grad</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">.</span><span class=\"n\">grad</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"kc\">None</span>\n-    <span class=\"c1\"># backward pass (torch)</span>\n-    <span class=\"n\">y_ref</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">(</span><span class=\"n\">dy</span><span class=\"p\">,</span> <span class=\"n\">retain_graph</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"n\">dx_ref</span><span class=\"p\">,</span> <span class=\"n\">dw_ref</span><span class=\"p\">,</span> <span class=\"n\">db_ref</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">grad</span><span class=\"o\">.</span><span class=\"n\">clone</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">]]</span>\n-    <span class=\"c1\"># compare</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">assert_almost_equal</span><span class=\"p\">(</span><span class=\"n\">y_tri</span><span class=\"p\">,</span> <span class=\"n\">y_ref</span><span class=\"p\">)</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">assert_almost_equal</span><span class=\"p\">(</span><span class=\"n\">dx_tri</span><span class=\"p\">,</span> <span class=\"n\">dx_ref</span><span class=\"p\">)</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">assert_almost_equal</span><span class=\"p\">(</span><span class=\"n\">db_tri</span><span class=\"p\">,</span> <span class=\"n\">db_ref</span><span class=\"p\">,</span> <span class=\"n\">decimal</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">assert_almost_equal</span><span class=\"p\">(</span><span class=\"n\">dw_tri</span><span class=\"p\">,</span> <span class=\"n\">dw_ref</span><span class=\"p\">,</span> <span class=\"n\">decimal</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">perf_report</span><span class=\"p\">(</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">Benchmark</span><span class=\"p\">(</span>\n-        <span class=\"n\">x_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;N&#39;</span><span class=\"p\">],</span>\n-        <span class=\"n\">x_vals</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">512</span> <span class=\"o\">*</span> <span class=\"n\">i</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">)],</span>\n-        <span class=\"n\">line_arg</span><span class=\"o\">=</span><span class=\"s1\">&#39;provider&#39;</span><span class=\"p\">,</span>\n-        <span class=\"n\">line_vals</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;torch&#39;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">([</span><span class=\"s1\">&#39;apex&#39;</span><span class=\"p\">]</span> <span class=\"k\">if</span> <span class=\"n\">HAS_APEX</span> <span class=\"k\">else</span> <span class=\"p\">[]),</span>\n-        <span class=\"n\">line_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;Triton&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Torch&#39;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">([</span><span class=\"s1\">&#39;Apex&#39;</span><span class=\"p\">]</span> <span class=\"k\">if</span> <span class=\"n\">HAS_APEX</span> <span class=\"k\">else</span> <span class=\"p\">[]),</span>\n-        <span class=\"n\">styles</span><span class=\"o\">=</span><span class=\"p\">[(</span><span class=\"s1\">&#39;blue&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;green&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;orange&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;-&#39;</span><span class=\"p\">)],</span>\n-        <span class=\"n\">ylabel</span><span class=\"o\">=</span><span class=\"s1\">&#39;GB/s&#39;</span><span class=\"p\">,</span>\n-        <span class=\"n\">plot_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;layer-norm-backward&#39;</span><span class=\"p\">,</span>\n-        <span class=\"n\">args</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;M&#39;</span><span class=\"p\">:</span> <span class=\"mi\">4096</span><span class=\"p\">,</span> <span class=\"s1\">&#39;dtype&#39;</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float16</span><span class=\"p\">,</span> <span class=\"s1\">&#39;mode&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;backward&#39;</span><span class=\"p\">}</span>\n-    <span class=\"p\">)</span>\n-<span class=\"p\">)</span>\n-<span class=\"k\">def</span> <span class=\"nf\">bench_layer_norm</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">provider</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">&#39;backward&#39;</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"o\">=</span><span class=\"mf\">1e-5</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">):</span>\n-    <span class=\"c1\"># create data</span>\n-    <span class=\"n\">x_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"p\">)</span>\n-    <span class=\"n\">w_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">x_shape</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">)</span>\n-    <span class=\"n\">weight</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">requires_grad</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"n\">bias</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">,</span> <span class=\"n\">requires_grad</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mf\">2.3</span> <span class=\"o\">+</span> <span class=\"mf\">0.5</span> <span class=\"o\">*</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">x_shape</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span><span class=\"p\">)</span>\n-    <span class=\"n\">dy</span> <span class=\"o\">=</span> <span class=\"mf\">.1</span> <span class=\"o\">*</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn_like</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-    <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">requires_grad_</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># utility functions</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">y_fwd</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">layer_norm</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">)</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;torch&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">y_fwd</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">functional</span><span class=\"o\">.</span><span class=\"n\">layer_norm</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w_shape</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">,</span> <span class=\"n\">eps</span><span class=\"p\">)</span>\n-    <span class=\"k\">if</span> <span class=\"n\">provider</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;apex&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">apex_layer_norm</span> <span class=\"o\">=</span> <span class=\"n\">apex</span><span class=\"o\">.</span><span class=\"n\">normalization</span><span class=\"o\">.</span><span class=\"n\">FusedLayerNorm</span><span class=\"p\">(</span><span class=\"n\">w_shape</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">)</span>\n-        <span class=\"n\">y_fwd</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">apex_layer_norm</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># forward pass</span>\n-    <span class=\"k\">if</span> <span class=\"n\">mode</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;forward&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">gbps</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">ms</span><span class=\"p\">:</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span> <span class=\"o\">*</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">element_size</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"n\">ms</span> <span class=\"o\">*</span> <span class=\"mf\">1e-6</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"n\">y_fwd</span><span class=\"p\">,</span> <span class=\"n\">rep</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n-    <span class=\"c1\"># backward pass</span>\n-    <span class=\"k\">if</span> <span class=\"n\">mode</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;backward&#39;</span><span class=\"p\">:</span>\n-        <span class=\"n\">gbps</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">ms</span><span class=\"p\">:</span> <span class=\"mi\">3</span> <span class=\"o\">*</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span> <span class=\"o\">*</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">element_size</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"n\">ms</span> <span class=\"o\">*</span> <span class=\"mf\">1e-6</span>\n-        <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">y_fwd</span><span class=\"p\">()</span>\n-        <span class=\"n\">ms</span><span class=\"p\">,</span> <span class=\"n\">min_ms</span><span class=\"p\">,</span> <span class=\"n\">max_ms</span> <span class=\"o\">=</span> <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">testing</span><span class=\"o\">.</span><span class=\"n\">do_bench</span><span class=\"p\">(</span><span class=\"k\">lambda</span><span class=\"p\">:</span> <span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">(</span><span class=\"n\">dy</span><span class=\"p\">,</span> <span class=\"n\">retain_graph</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n-                                                     <span class=\"n\">grad_to_none</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">],</span> <span class=\"n\">rep</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n-    <span class=\"k\">return</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">ms</span><span class=\"p\">),</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">max_ms</span><span class=\"p\">),</span> <span class=\"n\">gbps</span><span class=\"p\">(</span><span class=\"n\">min_ms</span><span class=\"p\">)</span>\n-\n-\n-<span class=\"n\">bench_layer_norm</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">save_path</span><span class=\"o\">=</span><span class=\"s1\">&#39;.&#39;</span><span class=\"p\">,</span> <span class=\"n\">print_data</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n-</pre></div>\n-</div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 2 minutes  14.541 seconds)</p>\n-<div class=\"sphx-glr-footer class sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-05-layer-norm-py\">\n-<div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/935c0dd0fbeb4b2e69588471cbb2d4b2/05-layer-norm.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">05-layer-norm.py</span></code></a></p>\n-</div>\n-<div class=\"sphx-glr-download sphx-glr-download-jupyter docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/ae7fff29e1b574187bc930ed94bcc353/05-layer-norm.ipynb\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Jupyter</span> <span class=\"pre\">notebook:</span> <span class=\"pre\">05-layer-norm.ipynb</span></code></a></p>\n-</div>\n-</div>\n-<p class=\"sphx-glr-signature\"><a class=\"reference external\" href=\"https://sphinx-gallery.github.io\">Gallery generated by Sphinx-Gallery</a></p>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"../../python-api/triton.html\" class=\"btn btn-neutral float-right\" title=\"triton\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"04-low-memory-dropout.html\" class=\"btn btn-neutral float-left\" title=\"Low-Memory Dropout\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"05-layer-norm.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/tutorials/index.html", "status": "removed", "additions": 0, "deletions": 298, "changes": 298, "file_content_changes": "@@ -1,298 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Tutorials &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"Vector Addition\" href=\"01-vector-add.html\" />\n-    <link rel=\"prev\" title=\"Installation\" href=\"../installation.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../installation.html\">Installation</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"current reference internal\" href=\"#\">Tutorials</a><ul>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"01-vector-add.html\">Vector Addition</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"02-fused-softmax.html\">Fused Softmax</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"03-matrix-multiplication.html\">Matrix Multiplication</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"04-low-memory-dropout.html\">Low-Memory Dropout</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"05-layer-norm.html\">Layer Normalization</a></li>\n-</ul>\n-</li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-      <li>Tutorials</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/getting-started/tutorials/index.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"tutorials\">\n-<span id=\"sphx-glr-getting-started-tutorials\"></span><h1>Tutorials<a class=\"headerlink\" href=\"#tutorials\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p>Below is a gallery of tutorials for writing various basic operations with Triton. It is recommended that you read through the tutorials in order, starting with the simplest one.</p>\n-<p>To install the dependencies for the tutorials:</p>\n-<div class=\"highlight-bash notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nb\">cd</span> triton\n-pip install -e <span class=\"s1\">&#39;./python[tutorials]&#39;</span>\n-</pre></div>\n-</div>\n-<div class=\"sphx-glr-thumbcontainer\" tooltip=\"- The basic programming model of Triton - The triton.jit decorator, which is used to define Tri...\"><div class=\"figure align-default\" id=\"id1\">\n-<img alt=\"Vector Addition\" src=\"../../_images/sphx_glr_01-vector-add_thumb.png\" />\n-<p class=\"caption\"><span class=\"caption-text\"><a class=\"reference internal\" href=\"01-vector-add.html#sphx-glr-getting-started-tutorials-01-vector-add-py\"><span class=\"std std-ref\">Vector Addition</span></a></span><a class=\"headerlink\" href=\"#id1\" title=\"Permalink to this image\">\u00b6</a></p>\n-</div>\n-</div><div class=\"toctree-wrapper compound\">\n-</div>\n-<div class=\"sphx-glr-thumbcontainer\" tooltip=\"- The benefits of kernel fusion for bandwidth-bound operations. - Reduction operators in Triton...\"><div class=\"figure align-default\" id=\"id2\">\n-<img alt=\"Fused Softmax\" src=\"../../_images/sphx_glr_02-fused-softmax_thumb.png\" />\n-<p class=\"caption\"><span class=\"caption-text\"><a class=\"reference internal\" href=\"02-fused-softmax.html#sphx-glr-getting-started-tutorials-02-fused-softmax-py\"><span class=\"std std-ref\">Fused Softmax</span></a></span><a class=\"headerlink\" href=\"#id2\" title=\"Permalink to this image\">\u00b6</a></p>\n-</div>\n-</div><div class=\"toctree-wrapper compound\">\n-</div>\n-<div class=\"sphx-glr-thumbcontainer\" tooltip=\"- Block-level matrix multiplications - Multi-dimensional pointer arithmetic - Program re-orderi...\"><div class=\"figure align-default\" id=\"id3\">\n-<img alt=\"Matrix Multiplication\" src=\"../../_images/sphx_glr_03-matrix-multiplication_thumb.png\" />\n-<p class=\"caption\"><span class=\"caption-text\"><a class=\"reference internal\" href=\"03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py\"><span class=\"std std-ref\">Matrix Multiplication</span></a></span><a class=\"headerlink\" href=\"#id3\" title=\"Permalink to this image\">\u00b6</a></p>\n-</div>\n-</div><div class=\"toctree-wrapper compound\">\n-</div>\n-<div class=\"sphx-glr-thumbcontainer\" tooltip=\"In this tutorial, you will write a memory-efficient implementation of dropout whose state will ...\"><div class=\"figure align-default\" id=\"id4\">\n-<img alt=\"Low-Memory Dropout\" src=\"../../_images/sphx_glr_04-low-memory-dropout_thumb.png\" />\n-<p class=\"caption\"><span class=\"caption-text\"><a class=\"reference internal\" href=\"04-low-memory-dropout.html#sphx-glr-getting-started-tutorials-04-low-memory-dropout-py\"><span class=\"std std-ref\">Low-Memory Dropout</span></a></span><a class=\"headerlink\" href=\"#id4\" title=\"Permalink to this image\">\u00b6</a></p>\n-</div>\n-</div><div class=\"toctree-wrapper compound\">\n-</div>\n-<div class=\"sphx-glr-thumbcontainer\" tooltip=\"Layer Normalization\"><div class=\"figure align-default\" id=\"id5\">\n-<img alt=\"Layer Normalization\" src=\"../../_images/sphx_glr_05-layer-norm_thumb.png\" />\n-<p class=\"caption\"><span class=\"caption-text\"><a class=\"reference internal\" href=\"05-layer-norm.html#sphx-glr-getting-started-tutorials-05-layer-norm-py\"><span class=\"std std-ref\">Layer Normalization</span></a></span><a class=\"headerlink\" href=\"#id5\" title=\"Permalink to this image\">\u00b6</a></p>\n-</div>\n-</div><div class=\"toctree-wrapper compound\">\n-</div>\n-<div class=\"sphx-glr-clear\"></div><div class=\"sphx-glr-footer class sphx-glr-footer-gallery docutils container\">\n-<div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/763344228ae6bc253ed1a6cf586aa30d/tutorials_python.zip\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">all</span> <span class=\"pre\">examples</span> <span class=\"pre\">in</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">tutorials_python.zip</span></code></a></p>\n-</div>\n-<div class=\"sphx-glr-download sphx-glr-download-jupyter docutils container\">\n-<p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/662999063954282841dc90b8945f85ce/tutorials_jupyter.zip\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">all</span> <span class=\"pre\">examples</span> <span class=\"pre\">in</span> <span class=\"pre\">Jupyter</span> <span class=\"pre\">notebooks:</span> <span class=\"pre\">tutorials_jupyter.zip</span></code></a></p>\n-</div>\n-</div>\n-<p class=\"sphx-glr-signature\"><a class=\"reference external\" href=\"https://sphinx-gallery.github.io\">Gallery generated by Sphinx-Gallery</a></p>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"01-vector-add.html\" class=\"btn btn-neutral float-right\" title=\"Vector Addition\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"../installation.html\" class=\"btn btn-neutral float-left\" title=\"Installation\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"index.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/getting-started/tutorials/sg_execution_times.html", "status": "removed", "additions": 0, "deletions": 270, "changes": 270, "file_content_changes": "@@ -1,270 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Computation times &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-      <li>Computation times</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/getting-started/tutorials/sg_execution_times.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"computation-times\">\n-<span id=\"sphx-glr-getting-started-tutorials-sg-execution-times\"></span><h1>Computation times<a class=\"headerlink\" href=\"#computation-times\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p><strong>13:45.813</strong> total execution time for <strong>getting-started_tutorials</strong> files:</p>\n-<table class=\"docutils align-default\">\n-<colgroup>\n-<col style=\"width: 85%\" />\n-<col style=\"width: 9%\" />\n-<col style=\"width: 6%\" />\n-</colgroup>\n-<tbody>\n-<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py\"><span class=\"std std-ref\">Matrix Multiplication</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">03-matrix-multiplication.py</span></code>)</p></td>\n-<td><p>06:30.096</p></td>\n-<td><p>0.0 MB</p></td>\n-</tr>\n-<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"02-fused-softmax.html#sphx-glr-getting-started-tutorials-02-fused-softmax-py\"><span class=\"std std-ref\">Fused Softmax</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">02-fused-softmax.py</span></code>)</p></td>\n-<td><p>03:22.664</p></td>\n-<td><p>0.0 MB</p></td>\n-</tr>\n-<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"05-layer-norm.html#sphx-glr-getting-started-tutorials-05-layer-norm-py\"><span class=\"std std-ref\">Layer Normalization</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">05-layer-norm.py</span></code>)</p></td>\n-<td><p>02:14.541</p></td>\n-<td><p>0.0 MB</p></td>\n-</tr>\n-<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"01-vector-add.html#sphx-glr-getting-started-tutorials-01-vector-add-py\"><span class=\"std std-ref\">Vector Addition</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">01-vector-add.py</span></code>)</p></td>\n-<td><p>01:38.189</p></td>\n-<td><p>0.0 MB</p></td>\n-</tr>\n-<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"04-low-memory-dropout.html#sphx-glr-getting-started-tutorials-04-low-memory-dropout-py\"><span class=\"std std-ref\">Low-Memory Dropout</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">04-low-memory-dropout.py</span></code>)</p></td>\n-<td><p>00:00.324</p></td>\n-<td><p>0.0 MB</p></td>\n-</tr>\n-</tbody>\n-</table>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"sg_execution_times.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/index.html", "status": "removed", "additions": 0, "deletions": 274, "changes": 274, "file_content_changes": "@@ -1,274 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Welcome to Triton\u2019s documentation! &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"./\" src=\"_static/documentation_options.js\"></script>\n-        <script data-url_root=\"./\" id=\"documentation_options\" src=\"_static/documentation_options.js\"></script>\n-        <script src=\"_static/jquery.js\"></script>\n-        <script src=\"_static/underscore.js\"></script>\n-        <script src=\"_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"search.html\" />\n-    <link rel=\"next\" title=\"Installation\" href=\"getting-started/installation.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"#\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"#\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"#\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-      <li>Welcome to Triton\u2019s documentation!</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"_sources/index.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"welcome-to-triton-s-documentation\">\n-<h1>Welcome to Triton\u2019s documentation!<a class=\"headerlink\" href=\"#welcome-to-triton-s-documentation\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p>Triton is a language and compiler for parallel programming. It aims to provide a Python-based programming environment for productively writing custom DNN compute kernels capable of running at maximal throughput on modern GPU hardware.</p>\n-<div class=\"section\" id=\"getting-started\">\n-<h2>Getting Started<a class=\"headerlink\" href=\"#getting-started\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<ul class=\"simple\">\n-<li><p>Follow the <a class=\"reference internal\" href=\"getting-started/installation.html\"><span class=\"doc\">installation instructions</span></a> for your platform of choice.</p></li>\n-<li><p>Take a look at the <a class=\"reference internal\" href=\"getting-started/tutorials/index.html\"><span class=\"doc\">tutorials</span></a> to learn how to write your first Triton program.</p></li>\n-</ul>\n-<div class=\"toctree-wrapper compound\">\n-</div>\n-</div>\n-<div class=\"section\" id=\"python-api\">\n-<h2>Python API<a class=\"headerlink\" href=\"#python-api\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<ul class=\"simple\">\n-<li><p><a class=\"reference internal\" href=\"python-api/triton.html\"><span class=\"doc\">triton</span></a></p></li>\n-<li><p><a class=\"reference internal\" href=\"python-api/triton.language.html\"><span class=\"doc\">triton.language</span></a></p></li>\n-<li><p><a class=\"reference internal\" href=\"python-api/triton.testing.html\"><span class=\"doc\">triton.testing</span></a></p></li>\n-</ul>\n-<div class=\"toctree-wrapper compound\">\n-</div>\n-</div>\n-<div class=\"section\" id=\"going-further\">\n-<h2>Going Further<a class=\"headerlink\" href=\"#going-further\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Check out the following documents to learn more about Triton and how it compares against other DSLs for DNNs:</p>\n-<ul class=\"simple\">\n-<li><p>Chapter 1: <a class=\"reference internal\" href=\"programming-guide/chapter-1/introduction.html\"><span class=\"doc\">Introduction</span></a></p></li>\n-<li><p>Chapter 2: <a class=\"reference internal\" href=\"programming-guide/chapter-2/related-work.html\"><span class=\"doc\">Related Work</span></a></p></li>\n-</ul>\n-<div class=\"toctree-wrapper compound\">\n-</div>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"getting-started/installation.html\" class=\"btn btn-neutral float-right\" title=\"Installation\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"index.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/objects.inv", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/programming-guide/chapter-1/introduction.html", "status": "removed", "additions": 0, "deletions": 360, "changes": 360, "file_content_changes": "@@ -1,360 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Introduction &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"Related Work\" href=\"../chapter-2/related-work.html\" />\n-    <link rel=\"prev\" title=\"triton.testing.perf_report\" href=\"../../python-api/generated/triton.testing.perf_report.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1 current\"><a class=\"current reference internal\" href=\"#\">Introduction</a><ul>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#motivations\">Motivations</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#challenges\">Challenges</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#references\">References</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-      <li>Introduction</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/programming-guide/chapter-1/introduction.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"introduction\">\n-<h1>Introduction<a class=\"headerlink\" href=\"#introduction\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<div class=\"section\" id=\"motivations\">\n-<h2>Motivations<a class=\"headerlink\" href=\"#motivations\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Over the past decade, Deep Neural Networks (DNNs) have emerged as an important class of Machine Learning (ML) models, capable of  achieving state-of-the-art performance across many domains ranging from natural language processing <a class=\"reference internal\" href=\"#sutskever2014\" id=\"id1\"><span>[SUTSKEVER2014]</span></a> to computer vision <a class=\"reference internal\" href=\"#redmon2016\" id=\"id2\"><span>[REDMON2016]</span></a> to computational neuroscience <a class=\"reference internal\" href=\"#lee2017\" id=\"id3\"><span>[LEE2017]</span></a>. The strength of these models lies in their hierarchical structure, composed of a sequence of parametric (e.g., convolutional) and non-parametric (e.g., rectified linearity) <em>layers</em>. This pattern, though notoriously computationally expensive, also generates a large amount of highly parallelizable work particularly well suited for multi- and many- core processors.</p>\n-<p>As a consequence, Graphics Processing Units (GPUs) have become a cheap and accessible resource for exploring and/or deploying novel research ideas in the field. This trend has been accelerated by the release of several frameworks for General-Purpose GPU (GPGPU) computing, such as CUDA and OpenCL, which have made the development of high-performance programs easier. Yet, GPUs remain incredibly challenging to optimize for locality and parallelism, especially for computations that cannot be efficiently implemented using a combination of pre-existing optimized primitives. To make matters worse, GPU architectures are also rapidly evolving and specializing, as evidenced by the addition of tensor cores to NVIDIA (and more recently AMD) micro-architectures.</p>\n-<p>This tension between the computational opportunities offered by DNNs and the practical difficulty of GPU programming has created substantial academic and industrial interest for Domain-Specific Languages (DSLs) and compilers. Regrettably, these systems \u2013 whether they be based on  polyhedral machinery (<em>e.g.</em>, Tiramisu <a class=\"reference internal\" href=\"../chapter-2/related-work.html#baghdadi2021\" id=\"id4\"><span>[BAGHDADI2021]</span></a>, Tensor Comprehensions <a class=\"reference internal\" href=\"../chapter-2/related-work.html#vasilache2018\" id=\"id5\"><span>[VASILACHE2018]</span></a>) or scheduling languages (<em>e.g.</em>, Halide <a class=\"reference internal\" href=\"#jrk2013\" id=\"id6\"><span>[JRK2013]</span></a>, TVM <a class=\"reference internal\" href=\"#chen2018\" id=\"id7\"><span>[CHEN2018]</span></a>) \u2013 remain less flexible and (for the same algorithm) markedly slower than the best handwritten compute kernels available in libraries like <a class=\"reference external\" href=\"https://docs.nvidia.com/cuda/cublas/index.html\">cuBLAS</a>, <a class=\"reference external\" href=\"https://docs.nvidia.com/deeplearning/cudnn/api/index.html\">cuDNN</a> or <a class=\"reference external\" href=\"https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html\">TensorRT</a>.</p>\n-<p>The main premise of this project is the following: programming paradigms based on blocked algorithms <a class=\"reference internal\" href=\"#lam1991\" id=\"id8\"><span>[LAM1991]</span></a> can facilitate the construction of high-performance compute kernels for neural networks.  We specifically revisit traditional \u201cSingle Program, Multiple Data\u201d (SPMD <a class=\"reference internal\" href=\"#auguin1983\" id=\"id9\"><span>[AUGUIN1983]</span></a>) execution models for GPUs, and propose a variant in which programs \u2013 rather than threads \u2013 are blocked. For example, in the case of matrix multiplication, CUDA and Triton differ as follows:</p>\n-<table class=\"colwidths-given docutils align-default\">\n-<colgroup>\n-<col style=\"width: 50%\" />\n-<col style=\"width: 50%\" />\n-</colgroup>\n-<thead>\n-<tr class=\"row-odd\"><th class=\"head\"><p>CUDA Programming Model</p>\n-<p>(Scalar Program, Blocked Threads)</p>\n-</th>\n-<th class=\"head\"><p>Triton Programming Model</p>\n-<p>(Blocked Program, Scalar Threads)</p>\n-</th>\n-</tr>\n-</thead>\n-<tbody>\n-<tr class=\"row-even\"><td><div class=\"highlight-C notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"cp\">#pragma parallel</span>\n-<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"n\">M</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n-<span class=\"cp\">#pragma parallel</span>\n-<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">++</span><span class=\"p\">){</span>\n-  <span class=\"kt\">float</span> <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n-  <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">k</span> <span class=\"o\">&lt;</span> <span class=\"n\">K</span><span class=\"p\">;</span><span class=\"n\">k</span> <span class=\"o\">++</span><span class=\"p\">)</span>\n-    <span class=\"n\">acc</span> <span class=\"o\">+=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">]</span><span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">];</span>\n-\n-  <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc</span><span class=\"p\">;</span>\n-<span class=\"p\">}</span>\n-</pre></div>\n-</div>\n-</td>\n-<td><div class=\"highlight-C notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"cp\">#pragma parallel</span>\n-<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span> <span class=\"o\">&lt;</span> <span class=\"n\">M</span><span class=\"p\">;</span> <span class=\"n\">m</span> <span class=\"o\">+=</span> <span class=\"n\">MB</span><span class=\"p\">)</span>\n-<span class=\"cp\">#pragma parallel</span>\n-<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">n</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span><span class=\"p\">;</span> <span class=\"n\">n</span> <span class=\"o\">+=</span> <span class=\"n\">NB</span><span class=\"p\">){</span>\n-  <span class=\"kt\">float</span> <span class=\"n\">acc</span><span class=\"p\">[</span><span class=\"n\">MB</span><span class=\"p\">,</span> <span class=\"n\">NB</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n-  <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">k</span> <span class=\"o\">&lt;</span> <span class=\"n\">K</span><span class=\"p\">;</span> <span class=\"n\">k</span> <span class=\"o\">+=</span> <span class=\"n\">KB</span><span class=\"p\">)</span>\n-    <span class=\"n\">acc</span> <span class=\"o\">+=</span>  <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"nl\">m</span><span class=\"p\">:</span><span class=\"n\">m</span><span class=\"o\">+</span><span class=\"n\">MB</span><span class=\"p\">,</span> <span class=\"nl\">k</span><span class=\"p\">:</span><span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">KB</span><span class=\"p\">]</span>\n-          <span class=\"err\">@</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"nl\">k</span><span class=\"p\">:</span><span class=\"n\">k</span><span class=\"o\">+</span><span class=\"n\">KB</span><span class=\"p\">,</span> <span class=\"nl\">n</span><span class=\"p\">:</span><span class=\"n\">n</span><span class=\"o\">+</span><span class=\"n\">NB</span><span class=\"p\">];</span>\n-  <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"nl\">m</span><span class=\"p\">:</span><span class=\"n\">m</span><span class=\"o\">+</span><span class=\"n\">MB</span><span class=\"p\">,</span> <span class=\"nl\">n</span><span class=\"p\">:</span><span class=\"n\">n</span><span class=\"o\">+</span><span class=\"n\">NB</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc</span><span class=\"p\">;</span>\n-<span class=\"p\">}</span>\n-</pre></div>\n-</div>\n-</td>\n-</tr>\n-<tr class=\"row-odd\"><td><p><img alt=\"pic1\" src=\"../../_images/cuda-parallel-matmul.png\" /></p></td>\n-<td><p><img alt=\"pic2\" src=\"../../_images/triton-parallel-matmul.png\" /></p></td>\n-</tr>\n-</tbody>\n-</table>\n-<p>A key benefit of this approach is that it leads to block-structured iteration spaces that offer programmers more flexibility than existing DSLs when implementing sparse operations, all while allowing compilers to aggressively optimize programs for data locality and parallelism.</p>\n-</div>\n-<div class=\"section\" id=\"challenges\">\n-<h2>Challenges<a class=\"headerlink\" href=\"#challenges\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>The main challenge posed by our proposed paradigm is that of work scheduling, i.e., how the work done by each program instance should be partitioned for efficient execution on modern GPUs. To address this issue, the Triton compiler makes heavy use of <em>block-level data-flow analysis</em>, a technique for scheduling iteration blocks statically based on the control- and data-flow structure of the target program. The resulting system actually works surprisingly well: our compiler manages to apply a broad range of interesting optimization automatically (e.g., automatic coalescing, thread swizzling, pre-fetching, automatic vectorization, tensor core-aware instruction selection, shared memory allocation/synchronization, asynchronous copy scheduling). Of course doing all this is not trivial; one of the purposes of this guide is to give you a sense of how it works.</p>\n-</div>\n-<div class=\"section\" id=\"references\">\n-<h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<dl class=\"citation\">\n-<dt class=\"label\" id=\"sutskever2014\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id1\">SUTSKEVER2014</a></span></dt>\n-<dd><ol class=\"upperroman simple\">\n-<li><p>Sutskever et al., \u201cSequence to Sequence Learning with Neural Networks\u201d, NIPS 2014</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"redmon2016\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id2\">REDMON2016</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"10\">\n-<li><p>Redmon et al., \u201cYou Only Look Once: Unified, Real-Time Object Detection\u201d, CVPR 2016</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"lee2017\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id3\">LEE2017</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"11\">\n-<li><p>Lee et al., \u201cSuperhuman Accuracy on the SNEMI3D Connectomics Challenge\u201d, ArXiV 2017</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"baghdadi2021\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id4\">BAGHDADI2021</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"18\">\n-<li><p>Baghdadi et al., \u201cTiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code\u201d, CGO 2021</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"vasilache2018\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id5\">VASILACHE2018</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"14\">\n-<li><p>Vasilache et al., \u201cTensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions\u201d, ArXiV 2018</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"jrk2013\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id6\">JRK2013</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"10\">\n-<li><p>Ragan-Kelley et al., \u201cHalide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines\u201d, PLDI 2013</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"chen2018\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id7\">CHEN2018</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"20\">\n-<li><p>Chen et al., \u201cTVM: An Automated End-to-End Optimizing Compiler for Deep Learning\u201d, OSDI 2018</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"lam1991\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id8\">LAM1991</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"13\">\n-<li><p>Lam et al., \u201cThe Cache Performance and Optimizations of Blocked Algorithms\u201d, ASPLOS 1991</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"auguin1983\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id9\">AUGUIN1983</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"13\">\n-<li><p>Auguin et al., \u201cOpsila: an advanced SIMD for numerical analysis and signal processing\u201d, EUROMICRO 1983</p></li>\n-</ol>\n-</dd>\n-</dl>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"../chapter-2/related-work.html\" class=\"btn btn-neutral float-right\" title=\"Related Work\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"../../python-api/generated/triton.testing.perf_report.html\" class=\"btn btn-neutral float-left\" title=\"triton.testing.perf_report\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/programming-guide/chapter-1/introduction.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"introduction.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/programming-guide/chapter-2/related-work.html", "status": "removed", "additions": 0, "deletions": 486, "changes": 486, "file_content_changes": "@@ -1,486 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>Related Work &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"prev\" title=\"Introduction\" href=\"../chapter-1/introduction.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.html\">triton</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../python-api/triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"current reference internal\" href=\"#\">Related Work</a><ul>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#polyhedral-compilation\">Polyhedral Compilation</a><ul>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#program-representation\">Program Representation</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#advantages\">Advantages</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#limitations\">Limitations</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#scheduling-languages\">Scheduling Languages</a><ul>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#id16\">Advantages</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"#id17\">Limitations</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"#references\">References</a></li>\n-</ul>\n-</li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-      <li>Related Work</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/programming-guide/chapter-2/related-work.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"related-work\">\n-<h1>Related Work<a class=\"headerlink\" href=\"#related-work\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<p>At first sight, Triton may seem like just yet another DSL for DNNs. The purpose of this section is to contextualize Triton and highlight its differences with the two leading approaches in this domain: polyhedral compilation and scheduling languages.</p>\n-<div class=\"section\" id=\"polyhedral-compilation\">\n-<h2>Polyhedral Compilation<a class=\"headerlink\" href=\"#polyhedral-compilation\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Traditional compilers typically rely on intermediate representations, such as LLVM-IR <a class=\"reference internal\" href=\"#lattner2004\" id=\"id1\"><span>[LATTNER2004]</span></a>, that encode control flow information using (un)conditional branches. This relatively low-level format makes it difficult to statically analyze the runtime behavior (e.g., cache misses) of input programs, and to  automatically optimize loops accordingly through the use of tiling <a class=\"reference internal\" href=\"#wolfe1989\" id=\"id2\"><span>[WOLFE1989]</span></a>, fusion <a class=\"reference internal\" href=\"#darte1999\" id=\"id3\"><span>[DARTE1999]</span></a> and interchange <a class=\"reference internal\" href=\"#allen1984\" id=\"id4\"><span>[ALLEN1984]</span></a>. To solve this issue, polyhedral compilers <a class=\"reference internal\" href=\"#ancourt1991\" id=\"id5\"><span>[ANCOURT1991]</span></a> rely on program representations that have statically predictable control flow, thereby enabling aggressive compile-time program transformations for data locality and parallelism. Though this strategy has been adopted by many languages and compilers for DNNs such as Tiramisu <a class=\"reference internal\" href=\"#baghdadi2021\" id=\"id6\"><span>[BAGHDADI2021]</span></a>, Tensor Comprehensions <a class=\"reference internal\" href=\"#vasilache2018\" id=\"id7\"><span>[VASILACHE2018]</span></a>, Diesel <a class=\"reference internal\" href=\"#elango2018\" id=\"id8\"><span>[ELANGO2018]</span></a> and the Affine dialect in MLIR <a class=\"reference internal\" href=\"#lattner2019\" id=\"id9\"><span>[LATTNER2019]</span></a>, it also comes with a number of limitations that will be described later in this section.</p>\n-<div class=\"section\" id=\"program-representation\">\n-<h3>Program Representation<a class=\"headerlink\" href=\"#program-representation\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>Polyhedral compilation is a vast area of research. In this section we only outline the most basic aspects of this topic, but readers interested in the solid mathematical foundations underneath may refer to the ample litterature on linear and integer programming.</p>\n-<table class=\"colwidths-given docutils align-default\">\n-<colgroup>\n-<col style=\"width: 50%\" />\n-<col style=\"width: 50%\" />\n-</colgroup>\n-<tbody>\n-<tr class=\"row-odd\"><td><div class=\"highlight-C notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">3</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n-<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span> <span class=\"o\">=</span> <span class=\"n\">i</span><span class=\"p\">;</span> <span class=\"n\">j</span> <span class=\"o\">&lt;</span> <span class=\"mi\">5</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n-  <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n-</pre></div>\n-</div>\n-</td>\n-<td><p><a class=\"reference internal\" href=\"../../_images/polyhedral-iteration.png\"><img alt=\"pic1\" src=\"../../_images/polyhedral-iteration.png\" style=\"width: 300px;\" /></a></p></td>\n-</tr>\n-</tbody>\n-</table>\n-<p>Polyhedral compilers focus on a class of programs commonly known as <strong>Static Control Parts</strong> (SCoP), <em>i.e.</em>, maximal sets of consecutive statements in which conditionals and loop bounds are affine functions of surrounding loop indices and global invariant parameters. As shown above, programs in this format always lead to iteration domains that are bounded by affine inequalities, i.e., polyhedral. These polyhedra can also be defined algebraically; for the above example:</p>\n-<div class=\"math notranslate nohighlight\">\n-\\[\\begin{split}\\mathcal{P} = \\{ i, j \\in \\mathbb{Z}^2\n-~|~\n-\\begin{pmatrix}\n-1 &amp; 0 \\\\\n--1 &amp; 0 \\\\\n--1 &amp; 1 \\\\\n-0 &amp; -1 \\\\\n-\\end{pmatrix}\n-\\begin{pmatrix}\n-i \\\\\n-j\n-\\end{pmatrix}\n-+\n-\\begin{pmatrix}\n-0 \\\\\n-2 \\\\\n-0 \\\\\n-4\n-\\end{pmatrix}\n-\\geq\n-0\n-\\}\\end{split}\\]</div>\n-<p>Each point <span class=\"math notranslate nohighlight\">\\((i, j)\\)</span> in <span class=\"math notranslate nohighlight\">\\(\\mathcal{P}\\)</span> represents a <em>polyhedral statement</em>, that is a program statement which (1) does not induce control-flow side effects (e.g., <code class=\"code docutils literal notranslate\"><span class=\"pre\">for</span></code>, <code class=\"code docutils literal notranslate\"><span class=\"pre\">if</span></code>, <code class=\"code docutils literal notranslate\"><span class=\"pre\">break</span></code>) and (2) contains only affine functions of loop indices and global parameters in array accesses. To facilitate alias analysis, array accesses are also mathematically abstracted, using so-called <em>access function</em>. In other words, <code class=\"code docutils literal notranslate\"><span class=\"pre\">A[i][j]</span></code> is simply <code class=\"code docutils literal notranslate\"><span class=\"pre\">A[f(i,j)]</span></code> where the access function <span class=\"math notranslate nohighlight\">\\(f\\)</span> is defined by:</p>\n-<div class=\"math notranslate nohighlight\">\n-\\[\\begin{split}f(i, j) = \\begin{pmatrix}\n-1 &amp; 0\\\\\n-0 &amp; 1\\\\\n-\\end{pmatrix}\n-\\begin{pmatrix}\n-i\\\\\n-j\n-\\end{pmatrix}\n-=\n-(i, j)\\end{split}\\]</div>\n-<p>Note that the iteration domains of an SCoP does not specify the order in which its statements shall execute. In fact, this iteration domain may be traversed in many different possible legal orders, i.e. <em>schedules</em>. Formally, a schedule is defined as a p-dimensional affine transformation <span class=\"math notranslate nohighlight\">\\(\\Theta\\)</span> of loop indices <span class=\"math notranslate nohighlight\">\\(\\mathbf{x}\\)</span> and global invariant parameters <span class=\"math notranslate nohighlight\">\\(\\mathbf{g}\\)</span>:</p>\n-<div class=\"math notranslate nohighlight\">\n-\\[\\begin{split}\\Theta_S(\\mathbf{x}) = T_S \\begin{pmatrix}\n-\\vec{x}\\\\\n-\\vec{g}\\\\\n-1\n-\\end{pmatrix}\n-\\qquad\n-T_S \\in \\mathbb{Z} ^{p \\times (\\text{dim}(\\mathbf{x}) + \\text{dim}(\\mathbf{g}) + 1)}\\end{split}\\]</div>\n-<p>Where <span class=\"math notranslate nohighlight\">\\(\\Theta_S(\\mathbf{x})\\)</span> is a p-dimensional vector representing the slowest to fastest growing indices (from left to right) when traversing the loop nest surrounding <span class=\"math notranslate nohighlight\">\\(S\\)</span>. For the code shown above, the original schedule defined by the loop nest in C can be retrieved by using:</p>\n-<div class=\"math notranslate nohighlight\">\n-\\[\\begin{split}\\Theta_S(\\mathbf{x}) = \\begin{pmatrix}\n-1 &amp; 0 \\\\\n-0 &amp; 1 \\\\\n-\\end{pmatrix}\n-\\begin{pmatrix}\n-i &amp; j\n-\\end{pmatrix}^T\n-=\n-\\begin{pmatrix}\n-i &amp; j\n-\\end{pmatrix}^T\\end{split}\\]</div>\n-<p>where <span class=\"math notranslate nohighlight\">\\(i\\)</span> and <span class=\"math notranslate nohighlight\">\\(j\\)</span> are respectively the slowest and fastest growing loop indices in the nest. If <span class=\"math notranslate nohighlight\">\\(T_S\\)</span> is a vector (resp. tensor), then <span class=\"math notranslate nohighlight\">\\(\\Theta_S\\)</span> is a said to be one-dimensional (resp. multi-dimensional).</p>\n-</div>\n-<div class=\"section\" id=\"advantages\">\n-<h3>Advantages<a class=\"headerlink\" href=\"#advantages\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>Programs amenable to polyhedral compilation can be aggressively transformed and optimized. Most of these transformations actually boil down to the production of  schedules and iteration domains that enable loop transformations promoting parallelism and spatial/temporal data locality (e.g., fusion, interchange, tiling, parallelization).</p>\n-<p>Polyhedral compilers can also automatically go through complex verification processes to ensure that the semantics of their input program is preserved throughout this optimization phase. Note that polyhedral optimizers are not incompatible with more standard optimization techniques. In fact, it is not uncommon for these systems to be implemented as a set of LLVM passes that can be run ahead of more traditional compilation techniques <a class=\"reference internal\" href=\"#grosser2012\" id=\"id10\"><span>[GROSSER2012]</span></a>.</p>\n-<p>All in all, polyhedral machinery is extremely powerful, when applicable. It has been shown to support most common loop transformations, and has indeed achieved performance comparable to state-of-the-art GPU libraries for dense matrix multiplication <a class=\"reference internal\" href=\"#elango2018\" id=\"id11\"><span>[ELANGO2018]</span></a>. Additionally, it is also fully automatic and doesn\u2019t require any hint from programmers apart from source-code in a C-like format.</p>\n-</div>\n-<div class=\"section\" id=\"limitations\">\n-<h3>Limitations<a class=\"headerlink\" href=\"#limitations\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>Unfortunately, polyhedral compilers suffer from two major limitations that have prevented its adoption as a universal method for code generation in neural networks.</p>\n-<p>First, the set of possible program transformations <span class=\"math notranslate nohighlight\">\\(\\Omega = \\{ \\Theta_S ~|~ S \\in \\text{program} \\}\\)</span> is large, and grows with the number of statements in the program as well as with the size of their iteration domain. Verifying the legality of each transformation can also require the resolution of complex integer linear programs, making polyhedral compilation very computationally expensive. To make matters worse, hardware properties (e.g., cache size, number of SMs) and contextual characteristics (e.g., input tensor shapes) also have to be taken into account by this framework, leading to expensive auto-tuning procedures <a class=\"reference internal\" href=\"#sato2019\" id=\"id12\"><span>[SATO2019]</span></a>.</p>\n-<p>Second, the polyhedral framework is not very generally applicable; SCoPs are relatively common <a class=\"reference internal\" href=\"#girbal2006\" id=\"id13\"><span>[GIRBAL2006]</span></a> but require loop bounds and array subscripts to be affine functions of loop indices, which typically only occurs in regular, dense computations. For this reason, this framework still has to be successfully applied to sparse \u2013 or even structured-sparse \u2013 neural networks, whose importance has been rapidly rising over the past few years.</p>\n-<p>On the other hand, blocked program representations advocated by this dissertation are less restricted in scope and can achieve close to peak performance using standard dataflow analysis.</p>\n-</div>\n-</div>\n-<div class=\"section\" id=\"scheduling-languages\">\n-<h2>Scheduling Languages<a class=\"headerlink\" href=\"#scheduling-languages\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<p>Separation of concerns <a class=\"reference internal\" href=\"#dijkstra82\" id=\"id14\"><span>[DIJKSTRA82]</span></a> is a well-known design principle in computer science: programs should be decomposed into modular layers of abstraction that separate the semantics of their algorithms from the details of their implementation. Systems like Halide and TVM push this philosophy one step further, and enforce this separation at the grammatical level through the use of a  <strong>scheduling language</strong>. The benefits of this methodology are particularly visible in the case of matrix multiplication, where, as one can see below, the definition of the algorithm (Line 1-7) is completely disjoint from its implementation (Line 8-16), meaning that both can be maintained, optimized and distributed independently.</p>\n-<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"linenos\"> 1</span><span class=\"o\">//</span> <span class=\"n\">algorithm</span>\n-<span class=\"linenos\"> 2</span><span class=\"n\">Var</span> <span class=\"n\">x</span><span class=\"p\">(</span><span class=\"s2\">&quot;x&quot;</span><span class=\"p\">),</span> <span class=\"n\">y</span><span class=\"p\">(</span><span class=\"s2\">&quot;y&quot;</span><span class=\"p\">);</span>\n-<span class=\"linenos\"> 3</span><span class=\"n\">Func</span> <span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"s2\">&quot;matmul&quot;</span><span class=\"p\">);</span>\n-<span class=\"linenos\"> 4</span><span class=\"n\">RDom</span> <span class=\"n\">k</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">matrix_size</span><span class=\"p\">);</span>\n-<span class=\"linenos\"> 5</span><span class=\"n\">RVar</span> <span class=\"n\">ki</span><span class=\"p\">;</span>\n-<span class=\"linenos\"> 6</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span><span class=\"n\">f</span><span class=\"p\">;</span>\n-<span class=\"linenos\"> 7</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">+=</span> <span class=\"n\">A</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">);</span>\n-<span class=\"linenos\"> 8</span><span class=\"o\">//</span> <span class=\"n\">schedule</span>\n-<span class=\"linenos\"> 9</span><span class=\"n\">Var</span> <span class=\"n\">xi</span><span class=\"p\">(</span><span class=\"s2\">&quot;xi&quot;</span><span class=\"p\">),</span> <span class=\"n\">xo</span><span class=\"p\">(</span><span class=\"s2\">&quot;xo&quot;</span><span class=\"p\">),</span> <span class=\"n\">yo</span><span class=\"p\">(</span><span class=\"s2\">&quot;yo&quot;</span><span class=\"p\">),</span> <span class=\"n\">yi</span><span class=\"p\">(</span><span class=\"s2\">&quot;yo&quot;</span><span class=\"p\">),</span> <span class=\"n\">yii</span><span class=\"p\">(</span><span class=\"s2\">&quot;yii&quot;</span><span class=\"p\">),</span> <span class=\"n\">xii</span><span class=\"p\">(</span><span class=\"s2\">&quot;xii&quot;</span><span class=\"p\">);</span>\n-<span class=\"linenos\">10</span><span class=\"n\">matmul</span><span class=\"o\">.</span><span class=\"n\">vectorize</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">);</span>\n-<span class=\"linenos\">11</span><span class=\"n\">matmul</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n-<span class=\"linenos\">12</span>    <span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">xi</span><span class=\"p\">,</span> <span class=\"n\">block_size</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"n\">xi</span><span class=\"p\">,</span> <span class=\"n\">xi</span><span class=\"p\">,</span> <span class=\"n\">xii</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">)</span>\n-<span class=\"linenos\">13</span>    <span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">yi</span><span class=\"p\">,</span> <span class=\"n\">block_size</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"n\">yi</span><span class=\"p\">,</span> <span class=\"n\">yi</span><span class=\"p\">,</span> <span class=\"n\">yii</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">)</span>\n-<span class=\"linenos\">14</span>    <span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">ki</span><span class=\"p\">,</span> <span class=\"n\">block_size</span><span class=\"p\">)</span>\n-<span class=\"linenos\">15</span>    <span class=\"o\">.</span><span class=\"n\">reorder</span><span class=\"p\">(</span><span class=\"n\">xii</span><span class=\"p\">,</span> <span class=\"n\">yii</span><span class=\"p\">,</span> <span class=\"n\">xi</span><span class=\"p\">,</span> <span class=\"n\">ki</span><span class=\"p\">,</span> <span class=\"n\">yi</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n-<span class=\"linenos\">16</span>    <span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">vectorize</span><span class=\"p\">(</span><span class=\"n\">xii</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"n\">xi</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"n\">yii</span><span class=\"p\">);</span>\n-</pre></div>\n-</div>\n-<p>The resulting code may however not be completely portable, as schedules can sometimes rely on execution models (e.g., SPMD) or hardware intrinsics (e.g., matrix-multiply-accumulate) that are not widely available. This issue can be mitigated by auto-scheduling mechanisms <a class=\"reference internal\" href=\"#mullapudi2016\" id=\"id15\"><span>[MULLAPUDI2016]</span></a>.</p>\n-<div class=\"section\" id=\"id16\">\n-<h3>Advantages<a class=\"headerlink\" href=\"#id16\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>The main advantage of this approach is that it allows programmers to write an algorithm <em>only once</em>, and focus on performance optimization separately. It makes it possible to manually specify optimizations that a polyhedral compiler wouldn\u2019t be able to figure out automatically using static data-flow analysis.</p>\n-<p>Scheduling languages are, without a doubt, one of the most popular approaches for neural network code generation. The most popular system for this purpose is probably TVM, which provides good performance across a wide range of platforms as well as built-in automatic scheduling mechanisms.</p>\n-</div>\n-<div class=\"section\" id=\"id17\">\n-<h3>Limitations<a class=\"headerlink\" href=\"#id17\" title=\"Permalink to this headline\">\u00b6</a></h3>\n-<p>This ease-of-development comes at a cost. First of all, existing systems that follow this paradigm tend to be noticeably slower than Triton on modern hardware when applicable (e.g., V100/A100 tensor cores w/ equal tile sizes). I do believe that this is not a fundamental issue of scheduling languages \u2013 in the sense that it could probably be solved with more efforts \u2013 but it could mean that these systems are harder to engineer. More importantly, existing scheduling languages generate loops whose bounds and increments cannot depend on surrounding loop indice without at least imposing severe constraints on possible schedules \u2013 if not breaking the system entirely. This is problematic for sparse computations, whose iteration spaces may be irregular.</p>\n-<table class=\"colwidths-given docutils align-default\">\n-<colgroup>\n-<col style=\"width: 50%\" />\n-<col style=\"width: 50%\" />\n-</colgroup>\n-<tbody>\n-<tr class=\"row-odd\"><td><div class=\"highlight-C notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n-<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span> <span class=\"o\">&lt;</span> <span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n-  <span class=\"kt\">float</span> <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n-  <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">k</span> <span class=\"o\">&lt;</span> <span class=\"n\">K</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span> <span class=\"n\">k</span><span class=\"o\">++</span><span class=\"p\">)</span>\n-    <span class=\"n\">acc</span> <span class=\"o\">+=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"n\">col</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">k</span><span class=\"p\">]]</span><span class=\"o\">*</span><span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">k</span><span class=\"p\">][</span><span class=\"n\">j</span><span class=\"p\">]</span>\n-  <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc</span><span class=\"p\">;</span>\n-</pre></div>\n-</div>\n-</td>\n-<td><p><a class=\"reference internal\" href=\"../../_images/halide-iteration.png\"><img alt=\"pic2\" src=\"../../_images/halide-iteration.png\" style=\"width: 300px;\" /></a></p></td>\n-</tr>\n-</tbody>\n-</table>\n-<p>On the other hand, the block-based program representation that we advocate for through this work allows for block-structured iteration spaces and allows programmers to manually handle load-balancing as they wish.</p>\n-</div>\n-</div>\n-<div class=\"section\" id=\"references\">\n-<h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this headline\">\u00b6</a></h2>\n-<dl class=\"citation\">\n-<dt class=\"label\" id=\"lattner2004\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id1\">LATTNER2004</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"3\">\n-<li><p>Lattner et al., \u201cLLVM: a compilation framework for lifelong program analysis transformation\u201d, CGO 2004</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"wolfe1989\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id2\">WOLFE1989</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"13\">\n-<li><p>Wolfe, \u201cMore Iteration Space Tiling\u201d, SC 1989</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"darte1999\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id3\">DARTE1999</a></span></dt>\n-<dd><ol class=\"upperalpha simple\">\n-<li><p>Darte, \u201cOn the Complexity of Loop Fusion\u201d, PACT 1999</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"allen1984\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id4\">ALLEN1984</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"10\">\n-<li><p>Allen et al., \u201cAutomatic Loop Interchange\u201d, SIGPLAN Notices 1984</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"ancourt1991\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id5\">ANCOURT1991</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"3\">\n-<li><p>Ancourt et al., \u201cScanning Polyhedra with DO Loops\u201d, PPoPP 1991</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"baghdadi2021\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id6\">BAGHDADI2021</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"18\">\n-<li><p>Baghdadi et al., \u201cTiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code\u201d, CGO 2021</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"vasilache2018\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id7\">VASILACHE2018</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"14\">\n-<li><p>Vasilache et al., \u201cTensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions\u201d, ArXiV 2018</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"elango2018\"><span class=\"brackets\">ELANGO2018</span><span class=\"fn-backref\">(<a href=\"#id8\">1</a>,<a href=\"#id11\">2</a>)</span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"22\">\n-<li><p>Elango et al. \u201cDiesel: DSL for Linear Algebra and Neural Net Computations on GPUs\u201d, MAPL 2018</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"lattner2019\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id9\">LATTNER2019</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"3\">\n-<li><p>Lattner et al., \u201cMLIR Primer: A Compiler Infrastructure for the End of Moore\u2019s Law\u201d, Arxiv 2019</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"grosser2012\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id10\">GROSSER2012</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"20\">\n-<li><p>Grosser et al., \u201cPolly - Performing Polyhedral Optimizations on a Low-Level Intermediate Representation\u201d, Parallel Processing Letters 2012</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"sato2019\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id12\">SATO2019</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"25\">\n-<li><p>Sato et al., \u201cAn Autotuning Framework for Scalable Execution of Tiled Code via Iterative Polyhedral Compilation\u201d, TACO 2019</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"girbal2006\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id13\">GIRBAL2006</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"19\">\n-<li><p>Girbal et al., \u201cSemi-Automatic Composition of Loop Transformations for Deep Parallelism and Memory Hierarchies\u201d, International Journal of Parallel Programming 2006</p></li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"dijkstra82\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id14\">DIJKSTRA82</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"5\">\n-<li><ol class=\"upperalpha simple\" start=\"23\">\n-<li><p>Dijkstra et al., \u201cOn the role of scientific thought\u201d, Selected writings on computing: a personal perspective 1982</p></li>\n-</ol>\n-</li>\n-</ol>\n-</dd>\n-<dt class=\"label\" id=\"mullapudi2016\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id15\">MULLAPUDI2016</a></span></dt>\n-<dd><ol class=\"upperalpha simple\" start=\"18\">\n-<li><p>Mullapudi et al., \u201cAutomatically scheduling halide image processing pipelines\u201d, TOG 2016</p></li>\n-</ol>\n-</dd>\n-</dl>\n-</div>\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"../chapter-1/introduction.html\" class=\"btn btn-neutral float-left\" title=\"Introduction\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/programming-guide/chapter-2/related-work.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"related-work.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.Config.html", "status": "removed", "additions": 0, "deletions": 291, "changes": 291, "file_content_changes": "@@ -1,291 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.Config &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language\" href=\"../triton.language.html\" />\n-    <link rel=\"prev\" title=\"triton.heuristics\" href=\"triton.heuristics.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.html\">triton</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.jit.html\">triton.jit</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.autotune.html\">triton.autotune</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.heuristics.html\">triton.heuristics</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">triton.Config</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.html\">triton</a> &raquo;</li>\n-        \n-      <li>triton.Config</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.Config.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-config\">\n-<h1>triton.Config<a class=\"headerlink\" href=\"#triton-config\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py class\">\n-<dt class=\"sig sig-object py\" id=\"triton.Config\">\n-<em class=\"property\"><span class=\"pre\">class</span> </em><span class=\"sig-prename descclassname\"><span class=\"pre\">triton.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Config</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">self</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kwargs</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_warps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">4</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_stages</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pre_hook</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.Config\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>An object that represents a possible kernel configuration for the auto-tuner to try.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Variables</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>meta</strong> \u2013 a dictionary of meta-parameters to pass to the kernel as keyword arguments.</p></li>\n-<li><p><strong>num_warps</strong> \u2013 the number of warps to use for the kernel when compiled for GPUs. For example, if\n-<cite>num_warps=8</cite>, then each kernel instance will be automatically parallelized to\n-cooperatively execute using <cite>8 * 32 = 256</cite> threads.</p></li>\n-<li><p><strong>num_stages</strong> \u2013 the number of stages that the compiler should use when software-pipelining loops.\n-Mostly useful for matrix multiplication workloads on SM80+ GPUs.</p></li>\n-<li><p><strong>pre_hook</strong> \u2013 a function that will be called before the kernel is called. Parameters of this\n-function are args.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-<dl class=\"py method\">\n-<dt class=\"sig sig-object py\" id=\"triton.Config.__init__\">\n-<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">self</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kwargs</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_warps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">4</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_stages</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pre_hook</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.Config.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd></dd></dl>\n-\n-<p class=\"rubric\">Methods</p>\n-<table class=\"longtable docutils align-default\">\n-<colgroup>\n-<col style=\"width: 10%\" />\n-<col style=\"width: 90%\" />\n-</colgroup>\n-<tbody>\n-<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#triton.Config.__init__\" title=\"triton.Config.__init__\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">__init__</span></code></a>(self,\u00a0kwargs[,\u00a0num_warps,\u00a0\u2026])</p></td>\n-<td><p></p></td>\n-</tr>\n-</tbody>\n-</table>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"../triton.language.html\" class=\"btn btn-neutral float-right\" title=\"triton.language\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.heuristics.html\" class=\"btn btn-neutral float-left\" title=\"triton.heuristics\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.Config.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.autotune.html", "status": "removed", "additions": 0, "deletions": 291, "changes": 291, "file_content_changes": "@@ -1,291 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.autotune &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.heuristics\" href=\"triton.heuristics.html\" />\n-    <link rel=\"prev\" title=\"triton.jit\" href=\"triton.jit.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.html\">triton</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.jit.html\">triton.jit</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">triton.autotune</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.heuristics.html\">triton.heuristics</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.Config.html\">triton.Config</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.html\">triton</a> &raquo;</li>\n-        \n-      <li>triton.autotune</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.autotune.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-autotune\">\n-<h1>triton.autotune<a class=\"headerlink\" href=\"#triton-autotune\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.autotune\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.</span></span><span class=\"sig-name descname\"><span class=\"pre\">autotune</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">configs</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">key</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">prune_configs_by</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">reset_to_zero</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.autotune\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Decorator for auto-tuning a <code class=\"code docutils literal notranslate\"><span class=\"pre\">triton.jit</span></code>\u2019d function.</p>\n-<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">autotune</span><span class=\"p\">(</span><span class=\"n\">configs</span><span class=\"o\">=</span><span class=\"p\">[</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">(</span><span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">},</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">),</span>\n-    <span class=\"n\">triton</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">(</span><span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">:</span> <span class=\"mi\">1024</span><span class=\"p\">},</span> <span class=\"n\">num_warps</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">),</span>\n-  <span class=\"p\">],</span>\n-  <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;x_size&#39;</span><span class=\"p\">]</span> <span class=\"c1\"># the two above configs will be evaluated anytime</span>\n-                 <span class=\"c1\"># the value of x_size changes</span>\n-<span class=\"p\">)</span>\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">kernel</span><span class=\"p\">(</span><span class=\"n\">x_ptr</span><span class=\"p\">,</span> <span class=\"n\">x_size</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">META</span><span class=\"p\">):</span>\n-    <span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">=</span> <span class=\"n\">META</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">]</span>\n-</pre></div>\n-</div>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Note</dt>\n-<dd class=\"field-odd\"><p>When all the configurations are evaluated, the kernel will run multiple time.\n-This means that whatever value the kernel updates will be updated multiple times.\n-To avoid this undesired behavior, you can use the <cite>reset_to_zero</cite> argument, which\n-reset the value of the provided tensor to <cite>zero</cite> before running any configuration.</p>\n-</dd>\n-<dt class=\"field-even\">Parameters</dt>\n-<dd class=\"field-even\"><ul class=\"simple\">\n-<li><p><strong>configs</strong> (<em>list</em><em>[</em><a class=\"reference internal\" href=\"triton.Config.html#triton.Config\" title=\"triton.Config\"><em>triton.Config</em></a><em>]</em>) \u2013 a list of <code class=\"code docutils literal notranslate\"><span class=\"pre\">triton.Config</span></code> objects</p></li>\n-<li><p><strong>key</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) \u2013 a list of argument names whose change in value will trigger the evaluation of all provided configs.</p></li>\n-<li><p><strong>prune_configs_by</strong> \u2013 a dict of functions that are used to prune configs, fields:\n-\u2018perf_model\u2019: performance model used to predicate running time with different configs, returns running time\n-\u2018top_k\u2019: number of configs to bench\n-\u2018early_config_prune\u2019(optional): a function used to do early prune (eg, num_stages). It take configs:List[Config] as its input, and returns pruned configs.</p></li>\n-<li><p><strong>reset_to_zero</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) \u2013 a list of argument names whose value will be reset to zero before evaluating any configs.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.heuristics.html\" class=\"btn btn-neutral float-right\" title=\"triton.heuristics\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.jit.html\" class=\"btn btn-neutral float-left\" title=\"triton.jit\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.autotune.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.heuristics.html", "status": "removed", "additions": 0, "deletions": 272, "changes": 272, "file_content_changes": "@@ -1,272 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.heuristics &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.Config\" href=\"triton.Config.html\" />\n-    <link rel=\"prev\" title=\"triton.autotune\" href=\"triton.autotune.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.html\">triton</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.jit.html\">triton.jit</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.autotune.html\">triton.autotune</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">triton.heuristics</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.Config.html\">triton.Config</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.html\">triton</a> &raquo;</li>\n-        \n-      <li>triton.heuristics</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.heuristics.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-heuristics\">\n-<h1>triton.heuristics<a class=\"headerlink\" href=\"#triton-heuristics\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.heuristics\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.</span></span><span class=\"sig-name descname\"><span class=\"pre\">heuristics</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">values</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.heuristics\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Decorator for specifying how the values of certain meta-parameters may be computed.\n-This is useful for cases where auto-tuning is prohibitevely expensive, or just not applicable.</p>\n-<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">heuristics</span><span class=\"p\">(</span><span class=\"n\">values</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">:</span> <span class=\"k\">lambda</span> <span class=\"n\">args</span><span class=\"p\">:</span> <span class=\"mi\">2</span> <span class=\"o\">**</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">math</span><span class=\"o\">.</span><span class=\"n\">ceil</span><span class=\"p\">(</span><span class=\"n\">math</span><span class=\"o\">.</span><span class=\"n\">log2</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])))})</span>\n-<span class=\"nd\">@triton</span><span class=\"o\">.</span><span class=\"n\">jit</span>\n-<span class=\"k\">def</span> <span class=\"nf\">kernel</span><span class=\"p\">(</span><span class=\"n\">x_ptr</span><span class=\"p\">,</span> <span class=\"n\">x_size</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">META</span><span class=\"p\">):</span>\n-    <span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">=</span> <span class=\"n\">META</span><span class=\"p\">[</span><span class=\"s1\">&#39;BLOCK_SIZE&#39;</span><span class=\"p\">]</span> <span class=\"c1\"># smallest power-of-two &gt;= x_size</span>\n-</pre></div>\n-</div>\n-<dl class=\"simple\">\n-<dt>.param values: a dictionary of meta-parameter names and functions that compute the value of the meta-parameter.</dt><dd><p>each such function takes a list of positional arguments as input.</p>\n-</dd>\n-</dl>\n-<p>.type values: dict[str, Callable[[list[Any]], Any]]</p>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.Config.html\" class=\"btn btn-neutral float-right\" title=\"triton.Config\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.autotune.html\" class=\"btn btn-neutral float-left\" title=\"triton.autotune\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.heuristics.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.jit.html", "status": "removed", "additions": 0, "deletions": 277, "changes": 277, "file_content_changes": "@@ -1,277 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.jit &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.autotune\" href=\"triton.autotune.html\" />\n-    <link rel=\"prev\" title=\"triton\" href=\"../triton.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.html\">triton</a><ul class=\"current\">\n-<li class=\"toctree-l2 current\"><a class=\"current reference internal\" href=\"#\">triton.jit</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.autotune.html\">triton.autotune</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.heuristics.html\">triton.heuristics</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"triton.Config.html\">triton.Config</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.html\">triton</a> &raquo;</li>\n-        \n-      <li>triton.jit</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.jit.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-jit\">\n-<h1>triton.jit<a class=\"headerlink\" href=\"#triton-jit\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.jit\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.</span></span><span class=\"sig-name descname\"><span class=\"pre\">jit</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.jit\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Decorator for JIT-compiling a function using the Triton compiler.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Note</dt>\n-<dd class=\"field-odd\"><p>When a jit\u2019d function is called, <code class=\"code docutils literal notranslate\"><span class=\"pre\">torch.tensor</span></code> arguments are implicitly converted to pointers using the <code class=\"code docutils literal notranslate\"><span class=\"pre\">.data_ptr()</span></code> method.</p>\n-</dd>\n-<dt class=\"field-even\">Note</dt>\n-<dd class=\"field-even\"><p>This function will be compiled and run on the GPU. It will only have access to:</p>\n-<ul class=\"simple\">\n-<li><p>python primitives,</p></li>\n-<li><p>objects within the triton.language package,</p></li>\n-<li><p>arguments to this function,</p></li>\n-<li><p>other jit\u2019d functions</p></li>\n-</ul>\n-</dd>\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><p><strong>fn</strong> (<em>Callable</em>) \u2013 the function to be jit-compiled</p>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.autotune.html\" class=\"btn btn-neutral float-right\" title=\"triton.autotune\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"../triton.html\" class=\"btn btn-neutral float-left\" title=\"triton\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.jit.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.arange.html", "status": "removed", "additions": 0, "deletions": 280, "changes": 280, "file_content_changes": "@@ -1,280 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.arange &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.zeros\" href=\"triton.language.zeros.html\" />\n-    <link rel=\"prev\" title=\"triton.language.num_programs\" href=\"triton.language.num_programs.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.arange</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.zeros.html\">triton.language.zeros</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.arange</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.arange.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-arange\">\n-<h1>triton.language.arange<a class=\"headerlink\" href=\"#triton-language-arange\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.arange\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">arange</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">start</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">end</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.arange\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Returns contiguous values within the open interval [<code class=\"code docutils literal notranslate\"><span class=\"pre\">start</span></code>, <code class=\"code docutils literal notranslate\"><span class=\"pre\">end</span></code>).</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>start</strong> (<em>int</em>) \u2013 Start of the interval. Must be a power of two.</p></li>\n-<li><p><strong>stop</strong> (<em>int</em>) \u2013 End of the interval. Must be a power of two &gt;= start.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.zeros.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.zeros\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.num_programs.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.num_programs\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.arange.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.atomic_add.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "@@ -1,284 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.atomic_add &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.atomic_max\" href=\"triton.language.atomic_max.html\" />\n-    <link rel=\"prev\" title=\"triton.language.sum\" href=\"triton.language.sum.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_cas.html\">triton.language.atomic_cas</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.atomic_add</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_max.html\">triton.language.atomic_max</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_min.html\">triton.language.atomic_min</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.atomic_add</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.atomic_add.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-atomic-add\">\n-<h1>triton.language.atomic_add<a class=\"headerlink\" href=\"#triton-language-atomic-add\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.atomic_add\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">atomic_add</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pointer</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">val</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.atomic_add\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Performs an atomic add at the memory location specified by <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code>.</p>\n-<p>Return the data stored at <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code> before the atomic operation.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>pointer</strong> (<em>Block of dtype=triton.PointerDType</em>) \u2013 The memory locations to compare-and-swap.</p></li>\n-<li><p><strong>cmp</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values expected to be found in the atomic object</p></li>\n-<li><p><strong>val</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values to copy in case the expected value matches the contained value.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.atomic_max.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.atomic_max\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.sum.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.sum\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.atomic_add.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.atomic_cas.html", "status": "removed", "additions": 0, "deletions": 290, "changes": 290, "file_content_changes": "@@ -1,290 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.atomic_cas &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.atomic_xchg\" href=\"triton.language.atomic_xchg.html\" />\n-    <link rel=\"prev\" title=\"triton.language.store\" href=\"triton.language.store.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.load.html\">triton.language.load</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.store.html\">triton.language.store</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.atomic_cas</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_xchg.html\">triton.language.atomic_xchg</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.atomic_cas</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_add.html\">triton.language.atomic_add</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_max.html\">triton.language.atomic_max</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_min.html\">triton.language.atomic_min</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.atomic_cas</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.atomic_cas.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-atomic-cas\">\n-<h1>triton.language.atomic_cas<a class=\"headerlink\" href=\"#triton-language-atomic-cas\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.atomic_cas\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">atomic_cas</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pointer</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">cmp</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">val</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.atomic_cas\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Performs an atomic compare-and-swap at the memory location specified by <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code>.</p>\n-<p>Return the data stored at <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code> before the atomic operation.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>pointer</strong> (<em>Block of dtype=triton.PointerDType</em>) \u2013 The memory locations to compare-and-swap.</p></li>\n-<li><p><strong>cmp</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values expected to be found in the atomic object</p></li>\n-<li><p><strong>val</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values to copy in case the expected value matches the contained value.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.atomic_xchg.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.atomic_xchg\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.store.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.store\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.atomic_cas.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.atomic_max.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "@@ -1,284 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.atomic_max &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.atomic_min\" href=\"triton.language.atomic_min.html\" />\n-    <link rel=\"prev\" title=\"triton.language.atomic_add\" href=\"triton.language.atomic_add.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_cas.html\">triton.language.atomic_cas</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_add.html\">triton.language.atomic_add</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.atomic_max</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_min.html\">triton.language.atomic_min</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.atomic_max</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.atomic_max.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-atomic-max\">\n-<h1>triton.language.atomic_max<a class=\"headerlink\" href=\"#triton-language-atomic-max\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.atomic_max\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">atomic_max</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pointer</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">val</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.atomic_max\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Performs an atomic max at the memory location specified by <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code>.</p>\n-<p>Return the data stored at <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code> before the atomic operation.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>pointer</strong> (<em>Block of dtype=triton.PointerDType</em>) \u2013 The memory locations to compare-and-swap.</p></li>\n-<li><p><strong>cmp</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values expected to be found in the atomic object</p></li>\n-<li><p><strong>val</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values to copy in case the expected value matches the contained value.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.atomic_min.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.atomic_min\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.atomic_add.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.atomic_add\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.atomic_max.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.atomic_min.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "@@ -1,284 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.atomic_min &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.minimum\" href=\"triton.language.minimum.html\" />\n-    <link rel=\"prev\" title=\"triton.language.atomic_max\" href=\"triton.language.atomic_max.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_cas.html\">triton.language.atomic_cas</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_add.html\">triton.language.atomic_add</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_max.html\">triton.language.atomic_max</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.atomic_min</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.atomic_min</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.atomic_min.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-atomic-min\">\n-<h1>triton.language.atomic_min<a class=\"headerlink\" href=\"#triton-language-atomic-min\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.atomic_min\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">atomic_min</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pointer</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">val</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.atomic_min\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Performs an atomic min at the memory location specified by <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code>.</p>\n-<p>Return the data stored at <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code> before the atomic operation.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>pointer</strong> (<em>Block of dtype=triton.PointerDType</em>) \u2013 The memory locations to compare-and-swap.</p></li>\n-<li><p><strong>cmp</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values expected to be found in the atomic object</p></li>\n-<li><p><strong>val</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values to copy in case the expected value matches the contained value.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.minimum.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.minimum\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.atomic_max.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.atomic_max\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.atomic_min.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.atomic_xchg.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "@@ -1,284 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.atomic_xchg &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.where\" href=\"triton.language.where.html\" />\n-    <link rel=\"prev\" title=\"triton.language.atomic_cas\" href=\"triton.language.atomic_cas.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.load.html\">triton.language.load</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.store.html\">triton.language.store</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_cas.html\">triton.language.atomic_cas</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.atomic_xchg</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.atomic_xchg</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.atomic_xchg.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-atomic-xchg\">\n-<h1>triton.language.atomic_xchg<a class=\"headerlink\" href=\"#triton-language-atomic-xchg\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.atomic_xchg\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">atomic_xchg</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pointer</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">val</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.atomic_xchg\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Performs an atomic exchange at the memory location specified by <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code>.</p>\n-<p>Return the data stored at <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code> before the atomic operation.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>pointer</strong> (<em>Block of dtype=triton.PointerDType</em>) \u2013 The memory locations to compare-and-swap.</p></li>\n-<li><p><strong>cmp</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values expected to be found in the atomic object</p></li>\n-<li><p><strong>val</strong> (<em>Block of dtype=`pointer.dtype.element_ty`</em>) \u2013 The values to copy in case the expected value matches the contained value.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.where.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.where\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.atomic_cas.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.atomic_cas\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.atomic_xchg.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.broadcast_to.html", "status": "removed", "additions": 0, "deletions": 281, "changes": 281, "file_content_changes": "@@ -1,281 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.broadcast_to &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.reshape\" href=\"triton.language.reshape.html\" />\n-    <link rel=\"prev\" title=\"triton.language.zeros\" href=\"triton.language.zeros.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.broadcast_to</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.reshape.html\">triton.language.reshape</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.ravel.html\">triton.language.ravel</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.broadcast_to</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.broadcast_to.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-broadcast-to\">\n-<h1>triton.language.broadcast_to<a class=\"headerlink\" href=\"#triton-language-broadcast-to\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.broadcast_to\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">broadcast_to</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">shape</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.broadcast_to\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Tries to broadcast the given tensor to a new <code class=\"code docutils literal notranslate\"><span class=\"pre\">shape</span></code>.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>input</strong> (<em>Block</em>) \u2013 The input tensor.</p></li>\n-<li><p><strong>shape</strong> (<em>Tuple</em><em>[</em><em>int</em><em>]</em>) \u2013 The desired shape.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.reshape.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.reshape\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.zeros.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.zeros\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.broadcast_to.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.cos.html", "status": "removed", "additions": 0, "deletions": 282, "changes": 282, "file_content_changes": "@@ -1,282 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.cos &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.sin\" href=\"triton.language.sin.html\" />\n-    <link rel=\"prev\" title=\"triton.language.log\" href=\"triton.language.log.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.exp.html\">triton.language.exp</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.log.html\">triton.language.log</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.cos</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sin.html\">triton.language.sin</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sqrt.html\">triton.language.sqrt</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sigmoid.html\">triton.language.sigmoid</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.softmax.html\">triton.language.softmax</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.cos</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.cos.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-cos\">\n-<h1>triton.language.cos<a class=\"headerlink\" href=\"#triton-language-cos\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.cos\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">cos</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.cos\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Computes the element-wise cosine of <code class=\"code docutils literal notranslate\"><span class=\"pre\">x</span></code></p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><p><strong>x</strong> (<em>Block</em>) \u2013 the input values</p>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.sin.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.sin\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.log.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.log\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.cos.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.dot.html", "status": "removed", "additions": 0, "deletions": 280, "changes": 280, "file_content_changes": "@@ -1,280 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.dot &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.load\" href=\"triton.language.load.html\" />\n-    <link rel=\"prev\" title=\"triton.language.ravel\" href=\"triton.language.ravel.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.dot</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.dot</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.dot.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-dot\">\n-<h1>triton.language.dot<a class=\"headerlink\" href=\"#triton-language-dot\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.dot\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">dot</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">other</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">allow_tf32</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.dot\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Returns the matrix product of two blocks.</p>\n-<p>The two blocks must be two dimensionals and have compatible inner dimensions.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>input</strong> (2D tensor of scalar-type in {<code class=\"code docutils literal notranslate\"><span class=\"pre\">float16</span></code>, <code class=\"code docutils literal notranslate\"><span class=\"pre\">bfloat16</span></code>, <code class=\"code docutils literal notranslate\"><span class=\"pre\">float32</span></code>}) \u2013 The first tensor to be multiplied.</p></li>\n-<li><p><strong>other</strong> (2D tensor of scalar-type in {<code class=\"code docutils literal notranslate\"><span class=\"pre\">float16</span></code>, <code class=\"code docutils literal notranslate\"><span class=\"pre\">bfloat16</span></code>, <code class=\"code docutils literal notranslate\"><span class=\"pre\">float32</span></code>}) \u2013 The second tensor to be multiplied.</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.load.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.load\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.ravel.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.ravel\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.dot.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.exp.html", "status": "removed", "additions": 0, "deletions": 282, "changes": 282, "file_content_changes": "@@ -1,282 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.exp &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.log\" href=\"triton.language.log.html\" />\n-    <link rel=\"prev\" title=\"triton.language.where\" href=\"triton.language.where.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.exp</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.log.html\">triton.language.log</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.cos.html\">triton.language.cos</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sin.html\">triton.language.sin</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sqrt.html\">triton.language.sqrt</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sigmoid.html\">triton.language.sigmoid</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.softmax.html\">triton.language.softmax</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.exp</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.exp.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-exp\">\n-<h1>triton.language.exp<a class=\"headerlink\" href=\"#triton-language-exp\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.exp\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">exp</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.exp\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Computes the element-wise exponential of <code class=\"code docutils literal notranslate\"><span class=\"pre\">x</span></code></p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><p><strong>x</strong> (<em>Block</em>) \u2013 the input values</p>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.log.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.log\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.where.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.where\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.exp.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.load.html", "status": "removed", "additions": 0, "deletions": 287, "changes": 287, "file_content_changes": "@@ -1,287 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.load &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.store\" href=\"triton.language.store.html\" />\n-    <link rel=\"prev\" title=\"triton.language.dot\" href=\"triton.language.dot.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.load</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.store.html\">triton.language.store</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_cas.html\">triton.language.atomic_cas</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.atomic_xchg.html\">triton.language.atomic_xchg</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.load</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.load.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-load\">\n-<h1>triton.language.load<a class=\"headerlink\" href=\"#triton-language-load\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.load\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">load</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">pointer</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">other</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">cache_modifier</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">''</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">eviction_policy</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">''</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">volatile</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.load\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Return a tensor of data whose values are, elementwise, loaded from memory at location defined by <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer</span></code>.</p>\n-<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">mask</span></code> and <code class=\"code docutils literal notranslate\"><span class=\"pre\">other</span></code> are implicitly broadcast to <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer.shape</span></code>.</p>\n-<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">other</span></code> is implicitly typecast to <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer.dtype.element_ty</span></code>.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>pointer</strong> (<em>Block of dtype=triton.PointerDType</em>) \u2013 Pointers to the data to be loaded.</p></li>\n-<li><p><strong>mask</strong> (<em>Block of triton.int1</em><em>, </em><em>optional</em>) \u2013 if mask[idx] is false, do not load the data at address <code class=\"code docutils literal notranslate\"><span class=\"pre\">pointer[idx]</span></code>.</p></li>\n-<li><p><strong>other</strong> (<em>Block</em><em>, </em><em>optional</em>) \u2013 if mask[idx] is false, return other[idx]</p></li>\n-<li><p><strong>cache_modifier</strong> \u2013 changes cache option in nvidia ptx</p></li>\n-</ul>\n-</dd>\n-</dl>\n-<p>\u2018type cache_modifier: str, optional</p>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.store.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.store\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.dot.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.dot\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.load.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.log.html", "status": "removed", "additions": 0, "deletions": 282, "changes": 282, "file_content_changes": "@@ -1,282 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.log &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.cos\" href=\"triton.language.cos.html\" />\n-    <link rel=\"prev\" title=\"triton.language.exp\" href=\"triton.language.exp.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.exp.html\">triton.language.exp</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.log</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.cos.html\">triton.language.cos</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sin.html\">triton.language.sin</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sqrt.html\">triton.language.sqrt</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sigmoid.html\">triton.language.sigmoid</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.softmax.html\">triton.language.softmax</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.log</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.log.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-log\">\n-<h1>triton.language.log<a class=\"headerlink\" href=\"#triton-language-log\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.log\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">log</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.log\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Computes the element-wise natural logarithm of <code class=\"code docutils literal notranslate\"><span class=\"pre\">x</span></code></p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><p><strong>x</strong> (<em>Block</em>) \u2013 the input values</p>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.cos.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.cos\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.exp.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.exp\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.log.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.max.html", "status": "removed", "additions": 0, "deletions": 281, "changes": 281, "file_content_changes": "@@ -1,281 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.max &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.min\" href=\"triton.language.min.html\" />\n-    <link rel=\"prev\" title=\"triton.language.softmax\" href=\"triton.language.softmax.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a><ul class=\"current\">\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.max</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.min.html\">triton.language.min</a></li>\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.sum.html\">triton.language.sum</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.max</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.max.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-max\">\n-<h1>triton.language.max<a class=\"headerlink\" href=\"#triton-language-max\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.max\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">max</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">axis</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.max\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Returns the maximum of all elements in the <code class=\"code docutils literal notranslate\"><span class=\"pre\">input</span></code> tensor along the provided <code class=\"code docutils literal notranslate\"><span class=\"pre\">axis</span></code></p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>input</strong> \u2013 the input values</p></li>\n-<li><p><strong>axis</strong> \u2013 the dimension along which the reduction should be done</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.min.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.min\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.softmax.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.softmax\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.max.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.maximum.html", "status": "removed", "additions": 0, "deletions": 280, "changes": 280, "file_content_changes": "@@ -1,280 +0,0 @@\n-\n-\n-<!DOCTYPE html>\n-<html class=\"writer-html5\" lang=\"en\" >\n-<head>\n-  <meta charset=\"utf-8\" />\n-  \n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n-  \n-  <title>triton.language.maximum &mdash; Triton  documentation</title>\n-  \n-\n-  \n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/pygments.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/theme.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-binder.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-dataframe.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/gallery-rendered-html.css\" type=\"text/css\" />\n-  <link rel=\"stylesheet\" href=\"../../_static/css/custom.css\" type=\"text/css\" />\n-\n-  \n-  \n-\n-  \n-  \n-\n-  \n-\n-  \n-  <!--[if lt IE 9]>\n-    <script src=\"../../_static/js/html5shiv.min.js\"></script>\n-  <![endif]-->\n-  \n-    \n-      <script type=\"text/javascript\" id=\"documentation_options\" data-url_root=\"../../\" src=\"../../_static/documentation_options.js\"></script>\n-        <script data-url_root=\"../../\" id=\"documentation_options\" src=\"../../_static/documentation_options.js\"></script>\n-        <script src=\"../../_static/jquery.js\"></script>\n-        <script src=\"../../_static/underscore.js\"></script>\n-        <script src=\"../../_static/doctools.js\"></script>\n-    \n-    <script type=\"text/javascript\" src=\"../../_static/js/theme.js\"></script>\n-\n-    \n-    <link rel=\"index\" title=\"Index\" href=\"../../genindex.html\" />\n-    <link rel=\"search\" title=\"Search\" href=\"../../search.html\" />\n-    <link rel=\"next\" title=\"triton.language.randint4x\" href=\"triton.language.randint4x.html\" />\n-    <link rel=\"prev\" title=\"triton.language.minimum\" href=\"triton.language.minimum.html\" /> \n-</head>\n-\n-<body class=\"wy-body-for-nav\">\n-\n-   \n-  <div class=\"wy-grid-for-nav\">\n-    \n-    <nav data-toggle=\"wy-nav-shift\" class=\"wy-nav-side\">\n-      <div class=\"wy-side-scroll\">\n-        <div class=\"wy-side-nav-search\" >\n-          \n-\n-          \n-            <a href=\"../../index.html\" class=\"icon icon-home\"> Triton\n-          \n-\n-          \n-          </a>\n-\n-          \n-            \n-            \n-          \n-\n-          \n-<div role=\"search\">\n-  <form id=\"rtd-search-form\" class=\"wy-form\" action=\"../../search.html\" method=\"get\">\n-    <input type=\"text\" name=\"q\" placeholder=\"Search docs\" />\n-    <input type=\"hidden\" name=\"check_keywords\" value=\"yes\" />\n-    <input type=\"hidden\" name=\"area\" value=\"default\" />\n-  </form>\n-</div>\n-\n-          \n-        </div>\n-\n-        \n-        <div class=\"wy-menu wy-menu-vertical\" data-spy=\"affix\" role=\"navigation\" aria-label=\"main navigation\">\n-          \n-            \n-            \n-              \n-            \n-            \n-              <p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/installation.html\">Installation</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../getting-started/tutorials/index.html\">Tutorials</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Python API</span></p>\n-<ul class=\"current\">\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.html\">triton</a></li>\n-<li class=\"toctree-l1 current\"><a class=\"reference internal\" href=\"../triton.language.html\">triton.language</a><ul class=\"current\">\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#programming-model\">Programming Model</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#creation-ops\">Creation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#shape-manipulation-ops\">Shape Manipulation Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#linear-algebra-ops\">Linear Algebra Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#memory-ops\">Memory Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#indexing-ops\">Indexing Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#math-ops\">Math Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#reduction-ops\">Reduction Ops</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#atomic-ops\">Atomic Ops</a></li>\n-<li class=\"toctree-l2 current\"><a class=\"reference internal\" href=\"../triton.language.html#comparison-ops\">Comparison ops</a><ul class=\"current\">\n-<li class=\"toctree-l3\"><a class=\"reference internal\" href=\"triton.language.minimum.html\">triton.language.minimum</a></li>\n-<li class=\"toctree-l3 current\"><a class=\"current reference internal\" href=\"#\">triton.language.maximum</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#random-number-generation\">Random Number Generation</a></li>\n-<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"../triton.language.html#compiler-hint-ops\">Compiler Hint Ops</a></li>\n-</ul>\n-</li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../triton.testing.html\">triton.testing</a></li>\n-</ul>\n-<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Programming Guide</span></p>\n-<ul>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-1/introduction.html\">Introduction</a></li>\n-<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"../../programming-guide/chapter-2/related-work.html\">Related Work</a></li>\n-</ul>\n-\n-            \n-          \n-        </div>\n-        \n-      </div>\n-    </nav>\n-\n-    <section data-toggle=\"wy-nav-shift\" class=\"wy-nav-content-wrap\">\n-\n-      \n-      <nav class=\"wy-nav-top\" aria-label=\"top navigation\">\n-        \n-          <i data-toggle=\"wy-nav-top\" class=\"fa fa-bars\"></i>\n-          <a href=\"../../index.html\">Triton</a>\n-        \n-      </nav>\n-\n-\n-      <div class=\"wy-nav-content\">\n-        \n-        <div class=\"rst-content\">\n-        \n-          \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-<div role=\"navigation\" aria-label=\"breadcrumbs navigation\">\n-\n-  <ul class=\"wy-breadcrumbs\">\n-    \n-      <li><a href=\"../../index.html\" class=\"icon icon-home\"></a> &raquo;</li>\n-        \n-          <li><a href=\"../triton.language.html\">triton.language</a> &raquo;</li>\n-        \n-      <li>triton.language.maximum</li>\n-    \n-    \n-      <li class=\"wy-breadcrumbs-aside\">\n-        \n-          \n-            <a href=\"../../_sources/python-api/generated/triton.language.maximum.rst.txt\" rel=\"nofollow\"> View page source</a>\n-          \n-        \n-      </li>\n-    \n-  </ul>\n-\n-  \n-  <hr/>\n-</div>\n-          <div role=\"main\" class=\"document\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\">\n-           <div itemprop=\"articleBody\">\n-            \n-  <div class=\"section\" id=\"triton-language-maximum\">\n-<h1>triton.language.maximum<a class=\"headerlink\" href=\"#triton-language-maximum\" title=\"Permalink to this headline\">\u00b6</a></h1>\n-<dl class=\"py function\">\n-<dt class=\"sig sig-object py\" id=\"triton.language.maximum\">\n-<span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">maximum</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.maximum\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Computes the element-wise maximum of <code class=\"code docutils literal notranslate\"><span class=\"pre\">x</span></code> and <code class=\"code docutils literal notranslate\"><span class=\"pre\">y</span></code>.</p>\n-<dl class=\"field-list simple\">\n-<dt class=\"field-odd\">Parameters</dt>\n-<dd class=\"field-odd\"><ul class=\"simple\">\n-<li><p><strong>input</strong> (<em>Block</em>) \u2013 the first input tensor</p></li>\n-<li><p><strong>other</strong> (<em>Block</em>) \u2013 the second input tensor</p></li>\n-</ul>\n-</dd>\n-</dl>\n-</dd></dl>\n-\n-</div>\n-\n-\n-           </div>\n-           \n-          </div>\n-          <footer>\n-    <div class=\"rst-footer-buttons\" role=\"navigation\" aria-label=\"footer navigation\">\n-        <a href=\"triton.language.randint4x.html\" class=\"btn btn-neutral float-right\" title=\"triton.language.randint4x\" accesskey=\"n\" rel=\"next\">Next <span class=\"fa fa-arrow-circle-right\" aria-hidden=\"true\"></span></a>\n-        <a href=\"triton.language.minimum.html\" class=\"btn btn-neutral float-left\" title=\"triton.language.minimum\" accesskey=\"p\" rel=\"prev\"><span class=\"fa fa-arrow-circle-left\" aria-hidden=\"true\"></span> Previous</a>\n-    </div>\n-\n-  <hr/>\n-\n-  <div role=\"contentinfo\">\n-    <p>\n-        &#169; Copyright 2020, Philippe Tillet.\n-\n-    </p>\n-  </div>\n-    \n-    \n-    \n-    Built with <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> using a\n-    \n-    <a href=\"https://github.com/readthedocs/sphinx_rtd_theme\">theme</a>\n-    \n-    provided by <a href=\"https://readthedocs.org\">Read the Docs</a>. \n-\n-</footer>\n-        </div>\n-      </div>\n-\n-    </section>\n-\n-  </div>\n-  \n-<div class=\"rst-versions\" data-toggle=\"rst-versions\" role=\"note\" aria-label=\"versions\">\n-    <span class=\"rst-current-version\" data-toggle=\"rst-current-version\">\n-        <span class=\"fa fa-book\"> Other Versions</span>\n-        v: master\n-        <span class=\"fa fa-caret-down\"></span>\n-    </span>\n-    <div class=\"rst-other-versions\">\n-        <dl>\n-            <dt>Tags</dt>\n-            <dd><a href=\"../../../v1.1.2/index.html\">v1.1.2</a></dd>\n-        </dl>\n-        <dl>\n-            <dt>Branches</dt>\n-            <dd><a href=\"triton.language.maximum.html\">master</a></dd>\n-        </dl>\n-    </div>\n-</div>\n-\n-  <script type=\"text/javascript\">\n-      jQuery(function () {\n-          SphinxRtdTheme.Navigation.enable(true);\n-      });\n-  </script>\n-\n-  \n-  \n-    \n-   \n-\n-</body>\n-</html>\n\\ No newline at end of file"}, {"filename": "master/python-api/generated/triton.language.min.html", "status": "removed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.minimum.html", "status": "removed", "additions": 0, "deletions": 280, "changes": 280, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.multiple_of.html", "status": "removed", "additions": 0, "deletions": 271, "changes": 271, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.num_programs.html", "status": "removed", "additions": 0, "deletions": 277, "changes": 277, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.program_id.html", "status": "removed", "additions": 0, "deletions": 277, "changes": 277, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.rand.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.randint.html", "status": "removed", "additions": 0, "deletions": 285, "changes": 285, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.randint4x.html", "status": "removed", "additions": 0, "deletions": 285, "changes": 285, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.randn.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.ravel.html", "status": "removed", "additions": 0, "deletions": 278, "changes": 278, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.reshape.html", "status": "removed", "additions": 0, "deletions": 281, "changes": 281, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.sigmoid.html", "status": "removed", "additions": 0, "deletions": 282, "changes": 282, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.sin.html", "status": "removed", "additions": 0, "deletions": 282, "changes": 282, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.softmax.html", "status": "removed", "additions": 0, "deletions": 282, "changes": 282, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.sqrt.html", "status": "removed", "additions": 0, "deletions": 282, "changes": 282, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.store.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.sum.html", "status": "removed", "additions": 0, "deletions": 281, "changes": 281, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.where.html", "status": "removed", "additions": 0, "deletions": 284, "changes": 284, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.language.zeros.html", "status": "removed", "additions": 0, "deletions": 280, "changes": 280, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.testing.Benchmark.html", "status": "removed", "additions": 0, "deletions": 294, "changes": 294, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.testing.do_bench.html", "status": "removed", "additions": 0, "deletions": 271, "changes": 271, "file_content_changes": "N/A"}, {"filename": "master/python-api/generated/triton.testing.perf_report.html", "status": "removed", "additions": 0, "deletions": 264, "changes": 264, "file_content_changes": "N/A"}, {"filename": "master/python-api/triton.html", "status": "removed", "additions": 0, "deletions": 272, "changes": 272, "file_content_changes": "N/A"}, {"filename": "master/python-api/triton.language.html", "status": "removed", "additions": 0, "deletions": 553, "changes": 553, "file_content_changes": "N/A"}, {"filename": "master/python-api/triton.testing.html", "status": "removed", "additions": 0, "deletions": 268, "changes": 268, "file_content_changes": "N/A"}, {"filename": "master/search.html", "status": "removed", "additions": 0, "deletions": 254, "changes": 254, "file_content_changes": "N/A"}, {"filename": "master/searchindex.js", "status": "removed", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.buildinfo", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/environment.pickle", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/installation.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/tutorials/01-vector-add.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/tutorials/02-fused-softmax.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/tutorials/03-matrix-multiplication.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/tutorials/04-low-memory-dropout.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/tutorials/05-layer-norm.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/tutorials/index.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/getting-started/tutorials/sg_execution_times.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/index.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/programming-guide/chapter-1/introduction.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/programming-guide/chapter-2/related-work.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.Config.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.autotune.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.heuristics.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.jit.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.arange.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.atomic_add.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.atomic_cas.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.atomic_max.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.atomic_min.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.atomic_xchg.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.broadcast_to.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.cos.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "v1.1.2/.doctrees/python-api/generated/triton.language.dot.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}]