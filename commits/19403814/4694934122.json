[{"filename": "main/.buildinfo", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,4 +1,4 @@\n # Sphinx build info version 1\n # This file hashes the configuration used when building these files. When it is not found, a full rebuild will be done.\n-config: b07568a9faad04df86d02144741a0e8e\n+config: 2f3fc59ccdc3ec0b99873223c23d6538\n tags: 645f666f9bcd5a90fca523b33c5a78b7"}, {"filename": "main/.doctrees/environment.pickle", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/installation.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/01-vector-add.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/02-fused-softmax.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/03-matrix-multiplication.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/04-low-memory-dropout.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/05-layer-norm.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/06-fused-attention.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/07-math-functions.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/index.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/sg_execution_times.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/index.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/programming-guide/chapter-1/introduction.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/programming-guide/chapter-2/related-work.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.Config.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.autotune.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.heuristics.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.jit.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.abs.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.arange.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_add.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_cas.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_max.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_min.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_xchg.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.broadcast_to.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.cos.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.dot.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.exp.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.load.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.log.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.max.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.maximum.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.min.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.minimum.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.multiple_of.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.num_programs.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.program_id.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.rand.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.randint.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.randint4x.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.randn.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.ravel.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.reshape.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sigmoid.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sin.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.softmax.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sqrt.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.store.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sum.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.where.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.zeros.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.testing.Benchmark.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.testing.do_bench.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.testing.perf_report.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/triton.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/triton.language.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/triton.testing.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_downloads/662999063954282841dc90b8945f85ce/tutorials_jupyter.zip", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_downloads/763344228ae6bc253ed1a6cf586aa30d/tutorials_python.zip", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_01-vector-add_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_01-vector-add_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_02-fused-softmax_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_02-fused-softmax_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_03-matrix-multiplication_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_03-matrix-multiplication_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_05-layer-norm_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_05-layer-norm_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_06-fused-attention_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_06-fused-attention_002.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_06-fused-attention_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_sources/getting-started/tutorials/01-vector-add.rst.txt", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -243,7 +243,7 @@ We can now run the decorated function above. Pass `print_data=True` to see the p\n     7      524288.0   614.400016   614.400016\n     8     1048576.0   819.200021   819.200021\n     9     2097152.0  1023.999964  1023.999964\n-    10    4194304.0  1228.800031  1228.800031\n+    10    4194304.0  1260.307736  1228.800031\n     11    8388608.0  1424.695621  1424.695621\n     12   16777216.0  1560.380965  1560.380965\n     13   33554432.0  1624.859540  1624.859540\n@@ -256,7 +256,7 @@ We can now run the decorated function above. Pass `print_data=True` to see the p\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  25.429 seconds)\n+   **Total running time of the script:** ( 0 minutes  24.188 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_01-vector-add.py:"}, {"filename": "main/_sources/getting-started/tutorials/02-fused-softmax.rst.txt", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "file_content_changes": "@@ -308,14 +308,14 @@ We will then compare its performance against (1) :code:`torch.softmax` and (2) t\n     0     256.0   682.666643      682.666643   264.258068\n     1     384.0   877.714274      819.200021   332.108094\n     2     512.0   910.222190      910.222190   372.363633\n-    3     640.0   975.238103      930.909084   401.568635\n+    3     640.0   975.238103      975.238103   401.568635\n     4     768.0  1068.521715     1023.999964   431.157886\n     ..      ...          ...             ...          ...\n-    93  12160.0  1594.754129     1069.010969   591.367777\n-    94  12288.0  1598.438956     1018.694301   591.302256\n-    95  12416.0  1582.916395     1029.305700   587.739623\n-    96  12544.0  1580.346374     1013.656595   589.439056\n-    97  12672.0  1584.000004     1008.716405   590.253282\n+    93  12160.0  1594.754129     1069.010969   590.918747\n+    94  12288.0  1598.438956     1016.061996   590.414408\n+    95  12416.0  1576.634933     1031.979242   587.739623\n+    96  12544.0  1580.346374     1013.656595   590.305885\n+    97  12672.0  1584.000004     1006.213368   589.395349\n \n     [98 rows x 4 columns]\n \n@@ -332,7 +332,7 @@ In the above plot, we can see that:\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 1 minutes  18.602 seconds)\n+   **Total running time of the script:** ( 1 minutes  18.799 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_02-fused-softmax.py:"}, {"filename": "main/_sources/getting-started/tutorials/03-matrix-multiplication.rst.txt", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "file_content_changes": "@@ -448,45 +448,45 @@ We can now compare the performance of our kernel against that of cuBLAS. Here we\n \n     matmul-performance:\n              M      cuBLAS      Triton\n-    0    256.0    4.096000    4.096000\n-    1    384.0   11.059200   12.288000\n+    0    256.0    4.681143    4.096000\n+    1    384.0   12.288000   12.288000\n     2    512.0   26.214401   23.831273\n     3    640.0   42.666665   39.384616\n     4    768.0   63.195428   58.982401\n     5    896.0   78.051553   82.642822\n-    6   1024.0  104.857603   99.864382\n+    6   1024.0  110.376426  104.857603\n     7   1152.0  135.726544  129.825388\n     8   1280.0  163.840004  163.840004\n-    9   1408.0  155.765024  132.970149\n-    10  1536.0  176.947204  157.286398\n-    11  1664.0  179.978245  179.978245\n+    9   1408.0  151.438217  132.970149\n+    10  1536.0  181.484314  157.286398\n+    11  1664.0  183.651271  179.978245\n     12  1792.0  172.914215  208.137481\n     13  1920.0  200.347822  168.585369\n     14  2048.0  197.379013  190.650180\n-    15  2176.0  189.845737  209.621326\n+    15  2176.0  188.071477  209.621326\n     16  2304.0  225.357284  227.503545\n     17  2432.0  202.118452  200.674737\n-    18  2560.0  222.911566  217.006622\n+    18  2560.0  219.919464  217.006622\n     19  2688.0  196.544332  197.567993\n-    20  2816.0  208.680416  210.696652\n-    21  2944.0  221.493479  224.486628\n-    22  3072.0  207.410628  208.173173\n-    23  3200.0  214.046818  219.178074\n-    24  3328.0  205.103410  208.670419\n+    20  2816.0  209.683695  210.696652\n+    21  2944.0  210.278616  225.502413\n+    22  3072.0  205.156169  207.410628\n+    23  3200.0  210.526325  216.949149\n+    24  3328.0  203.941342  206.278780\n     25  3456.0  215.565692  216.724640\n-    26  3584.0  215.624440  211.068989\n-    27  3712.0  207.686788  217.404445\n-    28  3840.0  208.271176  206.328356\n-    29  3968.0  207.877238  216.738793\n-    30  4096.0  221.847481  214.748370\n+    26  3584.0  215.108588  206.702053\n+    27  3712.0  209.428397  217.168134\n+    28  3840.0  205.944129  208.664143\n+    29  3968.0  209.663117  218.680889\n+    30  4096.0  218.240199  214.405318\n \n \n \n \n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 1 minutes  37.087 seconds)\n+   **Total running time of the script:** ( 1 minutes  36.046 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_03-matrix-multiplication.py:"}, {"filename": "main/_sources/getting-started/tutorials/04-low-memory-dropout.rst.txt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -240,7 +240,7 @@ References\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  1.060 seconds)\n+   **Total running time of the script:** ( 0 minutes  1.048 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_04-low-memory-dropout.py:"}, {"filename": "main/_sources/getting-started/tutorials/05-layer-norm.rst.txt", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "file_content_changes": "@@ -440,36 +440,36 @@ Specifically, one can set :code:`'mode': 'backward'` to benchmark the backward p\n     [16384] 0\n     layer-norm-backward:\n               N      Triton       Torch\n-    0    1024.0  236.307695  356.173905\n-    1    1536.0  361.411771  400.695643\n-    2    2048.0  455.111110  438.857137\n-    3    2560.0  534.260858  469.007657\n-    4    3072.0  619.563043  501.551024\n-    5    3584.0  688.127967  443.381459\n-    6    4096.0  744.727267  436.906674\n-    7    4608.0  704.407633  437.122520\n-    8    5120.0  763.229797  443.610086\n+    0    1024.0  240.941181  361.411758\n+    1    1536.0  347.773587  405.098894\n+    2    2048.0  450.935778  438.857137\n+    3    2560.0  538.947358  472.615383\n+    4    3072.0  624.813540  501.551024\n+    5    3584.0  688.127967  445.678757\n+    6    4096.0  750.412251  436.906674\n+    7    4608.0  708.923101  438.857146\n+    8    5120.0  763.229797  445.217381\n     9    5632.0  809.389194  459.755106\n-    10   6144.0  842.605744  465.160886\n+    10   6144.0  847.448272  465.160886\n     11   6656.0  882.563556  472.615367\n-    12   7168.0  917.503992  452.715775\n+    12   7168.0  919.957230  452.715775\n     13   7680.0  950.103127  443.076928\n-    14   8192.0  983.040025  464.794337\n-    15   8704.0  663.161879  459.112087\n+    14   8192.0  983.040025  465.895721\n+    15   8704.0  663.161879  458.105254\n     16   9216.0  686.906817  466.632911\n-    17   9728.0  711.804890  472.615406\n-    18  10240.0  731.428577  468.114302\n-    19  10752.0  761.203560  467.478250\n-    20  11264.0  781.317950  470.149555\n+    17   9728.0  713.981680  471.184672\n+    18  10240.0  731.428577  467.224344\n+    19  10752.0  761.203560  466.632895\n+    20  11264.0  781.317950  469.333317\n     21  11776.0  802.909085  471.826361\n-    22  12288.0  828.404485  471.105436\n-    23  12800.0  832.520355  471.889394\n-    24  13312.0  847.448300  477.560558\n-    25  13824.0  848.531950  478.753261\n-    26  14336.0  851.643583  477.203871\n-    27  14848.0  852.516725  477.683661\n-    28  15360.0  865.352086  476.279061\n-    29  15872.0  867.717548  479.758191\n+    22  12288.0  826.084006  471.105436\n+    23  12800.0  825.806430  471.889394\n+    24  13312.0  842.976243  477.560558\n+    25  13824.0  846.367375  478.408086\n+    26  14336.0  851.643583  476.542919\n+    27  14848.0  852.516725  477.044187\n+    28  15360.0  861.308412  476.279061\n+    29  15872.0  867.717548  478.552759\n \n \n \n@@ -484,7 +484,7 @@ References\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  39.183 seconds)\n+   **Total running time of the script:** ( 0 minutes  39.016 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_05-layer-norm.py:"}, {"filename": "main/_sources/getting-started/tutorials/06-fused-attention.rst.txt", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "file_content_changes": "@@ -54,17 +54,17 @@ This is a Triton implementation of the Flash Attention algorithm\n     [128, 128] 1\n     fused-attention-batch4-head48-d64-fwd:\n         N_CTX     Triton\n-    0  1024.0   0.323929\n-    1  2048.0   1.086871\n-    2  4096.0   3.919503\n-    3  8192.0  14.976001\n+    0  1024.0   0.323668\n+    1  2048.0   1.094414\n+    2  4096.0   3.942359\n+    3  8192.0  15.056554\n     [128, 64] 1\n     fused-attention-batch4-head48-d64-bwd:\n         N_CTX     Triton\n-    0  1024.0   1.184640\n-    1  2048.0   3.757174\n-    2  4096.0  13.251730\n-    3  8192.0  49.541634\n+    0  1024.0   1.185261\n+    1  2048.0   3.758828\n+    2  4096.0  13.213110\n+    3  8192.0  49.180672\n \n \n \n@@ -433,7 +433,7 @@ This is a Triton implementation of the Flash Attention algorithm\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  5.605 seconds)\n+   **Total running time of the script:** ( 0 minutes  5.598 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_06-fused-attention.py:"}, {"filename": "main/_sources/getting-started/tutorials/07-math-functions.rst.txt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -147,7 +147,7 @@ We can also customize the libdevice library path by passing the path to the `lib\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  0.390 seconds)\n+   **Total running time of the script:** ( 0 minutes  0.380 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_07-math-functions.py:"}, {"filename": "main/_sources/getting-started/tutorials/sg_execution_times.rst.txt", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "file_content_changes": "@@ -6,20 +6,20 @@\n \n Computation times\n =================\n-**04:07.355** total execution time for **getting-started_tutorials** files:\n+**04:05.074** total execution time for **getting-started_tutorials** files:\n \n +---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_03-matrix-multiplication.py` (``03-matrix-multiplication.py``) | 01:37.087 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_03-matrix-multiplication.py` (``03-matrix-multiplication.py``) | 01:36.046 | 0.0 MB |\n +---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_02-fused-softmax.py` (``02-fused-softmax.py``)                 | 01:18.602 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_02-fused-softmax.py` (``02-fused-softmax.py``)                 | 01:18.799 | 0.0 MB |\n +---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_05-layer-norm.py` (``05-layer-norm.py``)                       | 00:39.183 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_05-layer-norm.py` (``05-layer-norm.py``)                       | 00:39.016 | 0.0 MB |\n +---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_01-vector-add.py` (``01-vector-add.py``)                       | 00:25.429 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_01-vector-add.py` (``01-vector-add.py``)                       | 00:24.188 | 0.0 MB |\n +---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_06-fused-attention.py` (``06-fused-attention.py``)             | 00:05.605 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_06-fused-attention.py` (``06-fused-attention.py``)             | 00:05.598 | 0.0 MB |\n +---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_04-low-memory-dropout.py` (``04-low-memory-dropout.py``)       | 00:01.060 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_04-low-memory-dropout.py` (``04-low-memory-dropout.py``)       | 00:01.048 | 0.0 MB |\n +---------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_07-math-functions.py` (``07-math-functions.py``)               | 00:00.390 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_07-math-functions.py` (``07-math-functions.py``)               | 00:00.380 | 0.0 MB |\n +---------------------------------------------------------------------------------------------------------+-----------+--------+"}, {"filename": "main/getting-started/tutorials/01-vector-add.html", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -242,15 +242,15 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n 7      524288.0   614.400016   614.400016\n 8     1048576.0   819.200021   819.200021\n 9     2097152.0  1023.999964  1023.999964\n-10    4194304.0  1228.800031  1228.800031\n+10    4194304.0  1260.307736  1228.800031\n 11    8388608.0  1424.695621  1424.695621\n 12   16777216.0  1560.380965  1560.380965\n 13   33554432.0  1624.859540  1624.859540\n 14   67108864.0  1669.706983  1662.646960\n 15  134217728.0  1684.008546  1678.616907\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  25.429 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  24.188 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-01-vector-add-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/62d97d49a32414049819dd8bb8378080/01-vector-add.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">01-vector-add.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/02-fused-softmax.html", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "file_content_changes": "@@ -300,14 +300,14 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n 0     256.0   682.666643      682.666643   264.258068\n 1     384.0   877.714274      819.200021   332.108094\n 2     512.0   910.222190      910.222190   372.363633\n-3     640.0   975.238103      930.909084   401.568635\n+3     640.0   975.238103      975.238103   401.568635\n 4     768.0  1068.521715     1023.999964   431.157886\n ..      ...          ...             ...          ...\n-93  12160.0  1594.754129     1069.010969   591.367777\n-94  12288.0  1598.438956     1018.694301   591.302256\n-95  12416.0  1582.916395     1029.305700   587.739623\n-96  12544.0  1580.346374     1013.656595   589.439056\n-97  12672.0  1584.000004     1008.716405   590.253282\n+93  12160.0  1594.754129     1069.010969   590.918747\n+94  12288.0  1598.438956     1016.061996   590.414408\n+95  12416.0  1576.634933     1031.979242   587.739623\n+96  12544.0  1580.346374     1013.656595   590.305885\n+97  12672.0  1584.000004     1006.213368   589.395349\n \n [98 rows x 4 columns]\n </pre></div>\n@@ -320,7 +320,7 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n </ul>\n </dd>\n </dl>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 1 minutes  18.602 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 1 minutes  18.799 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-02-fused-softmax-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/d91442ac2982c4e0cc3ab0f43534afbc/02-fused-softmax.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">02-fused-softmax.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/03-matrix-multiplication.html", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "file_content_changes": "@@ -463,40 +463,40 @@ <h3>Square Matrix Performance<a class=\"headerlink\" href=\"#square-matrix-performa\n </div>\n <img src=\"../../_images/sphx_glr_03-matrix-multiplication_001.png\" srcset=\"../../_images/sphx_glr_03-matrix-multiplication_001.png\" alt=\"03 matrix multiplication\" class = \"sphx-glr-single-img\"/><div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>matmul-performance:\n          M      cuBLAS      Triton\n-0    256.0    4.096000    4.096000\n-1    384.0   11.059200   12.288000\n+0    256.0    4.681143    4.096000\n+1    384.0   12.288000   12.288000\n 2    512.0   26.214401   23.831273\n 3    640.0   42.666665   39.384616\n 4    768.0   63.195428   58.982401\n 5    896.0   78.051553   82.642822\n-6   1024.0  104.857603   99.864382\n+6   1024.0  110.376426  104.857603\n 7   1152.0  135.726544  129.825388\n 8   1280.0  163.840004  163.840004\n-9   1408.0  155.765024  132.970149\n-10  1536.0  176.947204  157.286398\n-11  1664.0  179.978245  179.978245\n+9   1408.0  151.438217  132.970149\n+10  1536.0  181.484314  157.286398\n+11  1664.0  183.651271  179.978245\n 12  1792.0  172.914215  208.137481\n 13  1920.0  200.347822  168.585369\n 14  2048.0  197.379013  190.650180\n-15  2176.0  189.845737  209.621326\n+15  2176.0  188.071477  209.621326\n 16  2304.0  225.357284  227.503545\n 17  2432.0  202.118452  200.674737\n-18  2560.0  222.911566  217.006622\n+18  2560.0  219.919464  217.006622\n 19  2688.0  196.544332  197.567993\n-20  2816.0  208.680416  210.696652\n-21  2944.0  221.493479  224.486628\n-22  3072.0  207.410628  208.173173\n-23  3200.0  214.046818  219.178074\n-24  3328.0  205.103410  208.670419\n+20  2816.0  209.683695  210.696652\n+21  2944.0  210.278616  225.502413\n+22  3072.0  205.156169  207.410628\n+23  3200.0  210.526325  216.949149\n+24  3328.0  203.941342  206.278780\n 25  3456.0  215.565692  216.724640\n-26  3584.0  215.624440  211.068989\n-27  3712.0  207.686788  217.404445\n-28  3840.0  208.271176  206.328356\n-29  3968.0  207.877238  216.738793\n-30  4096.0  221.847481  214.748370\n+26  3584.0  215.108588  206.702053\n+27  3712.0  209.428397  217.168134\n+28  3840.0  205.944129  208.664143\n+29  3968.0  209.663117  218.680889\n+30  4096.0  218.240199  214.405318\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 1 minutes  37.087 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 1 minutes  36.046 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-03-matrix-multiplication-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/d5fee5b55a64e47f1b5724ec39adf171/03-matrix-multiplication.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">03-matrix-multiplication.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/04-low-memory-dropout.html", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -284,7 +284,7 @@ <h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this\n <p>Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov, \u201cDropout: A Simple Way to Prevent Neural Networks from Overfitting\u201d, JMLR 2014</p>\n </div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  1.060 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  1.048 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-04-low-memory-dropout-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/c9aed78977a4c05741d675a38dde3d7d/04-low-memory-dropout.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">04-low-memory-dropout.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/05-layer-norm.html", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "file_content_changes": "@@ -468,36 +468,36 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n [16384] 0\n layer-norm-backward:\n           N      Triton       Torch\n-0    1024.0  236.307695  356.173905\n-1    1536.0  361.411771  400.695643\n-2    2048.0  455.111110  438.857137\n-3    2560.0  534.260858  469.007657\n-4    3072.0  619.563043  501.551024\n-5    3584.0  688.127967  443.381459\n-6    4096.0  744.727267  436.906674\n-7    4608.0  704.407633  437.122520\n-8    5120.0  763.229797  443.610086\n+0    1024.0  240.941181  361.411758\n+1    1536.0  347.773587  405.098894\n+2    2048.0  450.935778  438.857137\n+3    2560.0  538.947358  472.615383\n+4    3072.0  624.813540  501.551024\n+5    3584.0  688.127967  445.678757\n+6    4096.0  750.412251  436.906674\n+7    4608.0  708.923101  438.857146\n+8    5120.0  763.229797  445.217381\n 9    5632.0  809.389194  459.755106\n-10   6144.0  842.605744  465.160886\n+10   6144.0  847.448272  465.160886\n 11   6656.0  882.563556  472.615367\n-12   7168.0  917.503992  452.715775\n+12   7168.0  919.957230  452.715775\n 13   7680.0  950.103127  443.076928\n-14   8192.0  983.040025  464.794337\n-15   8704.0  663.161879  459.112087\n+14   8192.0  983.040025  465.895721\n+15   8704.0  663.161879  458.105254\n 16   9216.0  686.906817  466.632911\n-17   9728.0  711.804890  472.615406\n-18  10240.0  731.428577  468.114302\n-19  10752.0  761.203560  467.478250\n-20  11264.0  781.317950  470.149555\n+17   9728.0  713.981680  471.184672\n+18  10240.0  731.428577  467.224344\n+19  10752.0  761.203560  466.632895\n+20  11264.0  781.317950  469.333317\n 21  11776.0  802.909085  471.826361\n-22  12288.0  828.404485  471.105436\n-23  12800.0  832.520355  471.889394\n-24  13312.0  847.448300  477.560558\n-25  13824.0  848.531950  478.753261\n-26  14336.0  851.643583  477.203871\n-27  14848.0  852.516725  477.683661\n-28  15360.0  865.352086  476.279061\n-29  15872.0  867.717548  479.758191\n+22  12288.0  826.084006  471.105436\n+23  12800.0  825.806430  471.889394\n+24  13312.0  842.976243  477.560558\n+25  13824.0  846.367375  478.408086\n+26  14336.0  851.643583  476.542919\n+27  14848.0  852.516725  477.044187\n+28  15360.0  861.308412  476.279061\n+29  15872.0  867.717548  478.552759\n </pre></div>\n </div>\n </section>\n@@ -509,7 +509,7 @@ <h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this\n <p>Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton, \u201cLayer Normalization\u201d, Arxiv 2016</p>\n </div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  39.183 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  39.016 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-05-layer-norm-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/935c0dd0fbeb4b2e69588471cbb2d4b2/05-layer-norm.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">05-layer-norm.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/06-fused-attention.html", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "file_content_changes": "@@ -113,17 +113,17 @@\n [128, 128] 1\n fused-attention-batch4-head48-d64-fwd:\n     N_CTX     Triton\n-0  1024.0   0.323929\n-1  2048.0   1.086871\n-2  4096.0   3.919503\n-3  8192.0  14.976001\n+0  1024.0   0.323668\n+1  2048.0   1.094414\n+2  4096.0   3.942359\n+3  8192.0  15.056554\n [128, 64] 1\n fused-attention-batch4-head48-d64-bwd:\n     N_CTX     Triton\n-0  1024.0   1.184640\n-1  2048.0   3.757174\n-2  4096.0  13.251730\n-3  8192.0  49.541634\n+0  1024.0   1.185261\n+1  2048.0   3.758828\n+2  4096.0  13.213110\n+3  8192.0  49.180672\n </pre></div>\n </div>\n <div class=\"line-block\">\n@@ -484,7 +484,7 @@\n <span class=\"n\">bench_flash_attention</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">save_path</span><span class=\"o\">=</span><span class=\"s1\">&#39;.&#39;</span><span class=\"p\">,</span> <span class=\"n\">print_data</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  5.605 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  5.598 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-06-fused-attention-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/54a35f6ec55f9746935b9566fb6bb1df/06-fused-attention.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">06-fused-attention.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/07-math-functions.html", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -185,7 +185,7 @@ <h2>Customize the libdevice library path<a class=\"headerlink\" href=\"#customize-t\n The maximum difference between torch and triton is 2.384185791015625e-07\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  0.390 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  0.380 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-07-math-functions-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/77571465f7f4bd281d3a847dc2633146/07-math-functions.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">07-math-functions.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/sg_execution_times.html", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "file_content_changes": "@@ -86,35 +86,35 @@\n              \n   <section id=\"computation-times\">\n <span id=\"sphx-glr-getting-started-tutorials-sg-execution-times\"></span><h1>Computation times<a class=\"headerlink\" href=\"#computation-times\" title=\"Permalink to this heading\">\u00b6</a></h1>\n-<p><strong>04:07.355</strong> total execution time for <strong>getting-started_tutorials</strong> files:</p>\n+<p><strong>04:05.074</strong> total execution time for <strong>getting-started_tutorials</strong> files:</p>\n <table class=\"docutils align-default\">\n <tbody>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py\"><span class=\"std std-ref\">Matrix Multiplication</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">03-matrix-multiplication.py</span></code>)</p></td>\n-<td><p>01:37.087</p></td>\n+<td><p>01:36.046</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"02-fused-softmax.html#sphx-glr-getting-started-tutorials-02-fused-softmax-py\"><span class=\"std std-ref\">Fused Softmax</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">02-fused-softmax.py</span></code>)</p></td>\n-<td><p>01:18.602</p></td>\n+<td><p>01:18.799</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"05-layer-norm.html#sphx-glr-getting-started-tutorials-05-layer-norm-py\"><span class=\"std std-ref\">Layer Normalization</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">05-layer-norm.py</span></code>)</p></td>\n-<td><p>00:39.183</p></td>\n+<td><p>00:39.016</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"01-vector-add.html#sphx-glr-getting-started-tutorials-01-vector-add-py\"><span class=\"std std-ref\">Vector Addition</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">01-vector-add.py</span></code>)</p></td>\n-<td><p>00:25.429</p></td>\n+<td><p>00:24.188</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"06-fused-attention.html#sphx-glr-getting-started-tutorials-06-fused-attention-py\"><span class=\"std std-ref\">Fused Attention</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">06-fused-attention.py</span></code>)</p></td>\n-<td><p>00:05.605</p></td>\n+<td><p>00:05.598</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"04-low-memory-dropout.html#sphx-glr-getting-started-tutorials-04-low-memory-dropout-py\"><span class=\"std std-ref\">Low-Memory Dropout</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">04-low-memory-dropout.py</span></code>)</p></td>\n-<td><p>00:01.060</p></td>\n+<td><p>00:01.048</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"07-math-functions.html#sphx-glr-getting-started-tutorials-07-math-functions-py\"><span class=\"std std-ref\">Libdevice (tl.math) function</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">07-math-functions.py</span></code>)</p></td>\n-<td><p>00:00.390</p></td>\n+<td><p>00:00.380</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n </tbody>"}, {"filename": "main/searchindex.js", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "N/A"}]