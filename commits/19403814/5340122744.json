[{"filename": "main/.buildinfo", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,4 +1,4 @@\n # Sphinx build info version 1\n # This file hashes the configuration used when building these files. When it is not found, a full rebuild will be done.\n-config: e882567c2ec7ebb53abb2bfcda802023\n+config: 1d6cdda7bec803425c96a06f91a385a9\n tags: 645f666f9bcd5a90fca523b33c5a78b7"}, {"filename": "main/.doctrees/environment.pickle", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/installation.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/01-vector-add.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/02-fused-softmax.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/03-matrix-multiplication.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/04-low-memory-dropout.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/05-layer-norm.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/06-fused-attention.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/07-math-functions.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/08-experimental-block-pointer.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/index.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/getting-started/tutorials/sg_execution_times.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/index.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/programming-guide/chapter-1/introduction.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/programming-guide/chapter-2/related-work.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.Config.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.autotune.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.heuristics.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.jit.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.abs.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.arange.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.argmax.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.argmin.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_add.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_cas.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_max.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_min.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.atomic_xchg.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.broadcast.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.broadcast_to.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.cat.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.cos.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.debug_barrier.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.device_assert.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.device_print.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.dot.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.exp.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.expand_dims.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.fdiv.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.full.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.load.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.log.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.max.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.max_contiguous.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.maximum.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.min.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.minimum.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.multiple_of.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.num_programs.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.program_id.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.rand.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.randint.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.randint4x.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.randn.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.ravel.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.reduce.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.reshape.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sigmoid.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sin.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.softmax.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sqrt.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.static_assert.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.static_print.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.static_range.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.store.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.sum.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.trans.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.umulhi.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.view.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.where.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.xor_sum.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.language.zeros.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.testing.Benchmark.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.testing.do_bench.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/generated/triton.testing.perf_report.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/triton.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/triton.language.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/.doctrees/python-api/triton.testing.doctree", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_downloads/662999063954282841dc90b8945f85ce/tutorials_jupyter.zip", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_downloads/763344228ae6bc253ed1a6cf586aa30d/tutorials_python.zip", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_01-vector-add_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_01-vector-add_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_02-fused-softmax_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_02-fused-softmax_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_03-matrix-multiplication_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_03-matrix-multiplication_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_05-layer-norm_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_05-layer-norm_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_06-fused-attention_001.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_06-fused-attention_002.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_images/sphx_glr_06-fused-attention_thumb.png", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "main/_sources/getting-started/tutorials/01-vector-add.rst.txt", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -236,8 +236,8 @@ We can now run the decorated function above. Pass `print_data=True` to see the p\n \n     vector-add-performance:\n                size       Triton        Torch\n-    0        4096.0     8.000000     9.600000\n-    1        8192.0    15.999999    15.999999\n+    0        4096.0     9.600000     9.600000\n+    1        8192.0    15.999999    19.200000\n     2       16384.0    31.999999    31.999999\n     3       32768.0    63.999998    63.999998\n     4       65536.0   127.999995   127.999995\n@@ -248,9 +248,9 @@ We can now run the decorated function above. Pass `print_data=True` to see the p\n     9     2097152.0  1023.999964  1023.999964\n     10    4194304.0  1228.800031  1228.800031\n     11    8388608.0  1424.695621  1424.695621\n-    12   16777216.0  1560.380965  1548.094408\n-    13   33554432.0  1624.859540  1624.859540\n-    14   67108864.0  1669.706983  1662.646960\n+    12   16777216.0  1560.380965  1560.380965\n+    13   33554432.0  1624.859540  1631.601649\n+    14   67108864.0  1669.706983  1666.169441\n     15  134217728.0  1684.008546  1678.616907\n \n \n@@ -259,7 +259,7 @@ We can now run the decorated function above. Pass `print_data=True` to see the p\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  5.755 seconds)\n+   **Total running time of the script:** ( 0 minutes  5.725 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_01-vector-add.py:"}, {"filename": "main/_sources/getting-started/tutorials/02-fused-softmax.rst.txt", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "file_content_changes": "@@ -286,17 +286,17 @@ We will then compare its performance against (1) :code:`torch.softmax` and (2) t\n \n     softmax-performance:\n               N       Triton  Torch (native)  Torch (jit)\n-    0     256.0   682.666643      682.666643   273.066674\n-    1     384.0   877.714274      877.714274   332.108094\n+    0     256.0   682.666643      744.727267   264.258068\n+    1     384.0   877.714274      819.200021   332.108094\n     2     512.0   910.222190      910.222190   372.363633\n-    3     640.0   975.238103      975.238103   401.568635\n+    3     640.0   975.238103      975.238103   409.600010\n     4     768.0  1068.521715     1023.999964   431.157886\n     ..      ...          ...             ...          ...\n-    93  12160.0  1588.244879     1066.082150   592.267887\n+    93  12160.0  1594.754129     1066.082150   592.267887\n     94  12288.0  1591.967682     1013.443336   592.192778\n-    95  12416.0  1576.634933     1026.645975   590.359582\n-    96  12544.0  1574.149071     1008.562805   591.610919\n-    97  12672.0  1577.836533     1006.213368   590.253282\n+    95  12416.0  1576.634933     1024.000037   590.359582\n+    96  12544.0  1574.149071     1011.103284   592.047213\n+    97  12672.0  1577.836533     1006.213368   591.113716\n \n     [98 rows x 4 columns]\n \n@@ -313,7 +313,7 @@ In the above plot, we can see that:\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  38.423 seconds)\n+   **Total running time of the script:** ( 0 minutes  37.979 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_02-fused-softmax.py:"}, {"filename": "main/_sources/getting-started/tutorials/03-matrix-multiplication.rst.txt", "status": "modified", "additions": 22, "deletions": 22, "changes": 44, "file_content_changes": "@@ -452,42 +452,42 @@ but feel free to arrange this script as you wish to benchmark any other matrix s\n     0    256.0    4.096000    4.096000\n     1    384.0   12.288000   12.288000\n     2    512.0   26.214401   23.831273\n-    3    640.0   42.666665   39.384616\n+    3    640.0   42.666665   42.666665\n     4    768.0   63.195428   58.982401\n     5    896.0   78.051553   82.642822\n-    6   1024.0  104.857603   99.864382\n+    6   1024.0  110.376426   99.864382\n     7   1152.0  135.726544  129.825388\n     8   1280.0  163.840004  163.840004\n     9   1408.0  155.765024  132.970149\n     10  1536.0  181.484314  157.286398\n-    11  1664.0  183.651271  179.978245\n-    12  1792.0  172.914215  208.137481\n-    13  1920.0  206.328356  168.585369\n-    14  2048.0  199.728763  190.650180\n+    11  1664.0  183.651271  183.651271\n+    12  1792.0  175.616000  208.137481\n+    13  1920.0  203.294114  168.585369\n+    14  2048.0  199.728763  192.841562\n     15  2176.0  193.496618  211.827867\n-    16  2304.0  227.503545  229.691080\n-    17  2432.0  202.118452  199.251522\n-    18  2560.0  222.911566  212.779229\n-    19  2688.0  196.544332  198.602388\n-    20  2816.0  211.719459  210.696652\n-    21  2944.0  222.482283  223.479969\n-    22  3072.0  210.494802  206.653671\n-    23  3200.0  216.949149  219.178074\n-    24  3328.0  208.067338  206.871539\n-    25  3456.0  216.143621  215.565692\n-    26  3584.0  218.772251  207.656790\n-    27  3712.0  210.310194  219.073119\n-    28  3840.0  208.271176  208.664143\n-    29  3968.0  210.386099  215.971570\n-    30  4096.0  222.214781  211.366499\n+    16  2304.0  231.921091  231.921091\n+    17  2432.0  208.107149  203.583068\n+    18  2560.0  224.438347  218.453323\n+    19  2688.0  195.531224  198.602388\n+    20  2816.0  209.683695  212.752230\n+    21  2944.0  223.479969  226.527416\n+    22  3072.0  209.715208  202.950194\n+    23  3200.0  219.931269  216.949149\n+    24  3328.0  207.467716  208.670419\n+    25  3456.0  216.143621  216.143621\n+    26  3584.0  219.305830  207.656790\n+    27  3712.0  210.310194  216.697064\n+    28  3840.0  211.053446  210.651436\n+    29  3968.0  211.479948  218.680889\n+    30  4096.0  221.116512  214.063362\n \n \n \n \n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  40.854 seconds)\n+   **Total running time of the script:** ( 0 minutes  40.772 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_03-matrix-multiplication.py:"}, {"filename": "main/_sources/getting-started/tutorials/04-low-memory-dropout.rst.txt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -242,7 +242,7 @@ References\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  0.639 seconds)\n+   **Total running time of the script:** ( 0 minutes  0.620 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_04-low-memory-dropout.py:"}, {"filename": "main/_sources/getting-started/tutorials/05-layer-norm.rst.txt", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "file_content_changes": "@@ -431,36 +431,36 @@ Specifically, one can set :code:`'mode': 'backward'` to benchmark the backward p\n \n     layer-norm-backward:\n               N       Triton       Torch\n-    0    1024.0   176.805760  372.363633\n-    1    1536.0   265.208640  438.857146\n-    2    2048.0   325.509933  496.484863\n-    3    2560.0   415.135117  529.655159\n-    4    3072.0   526.628557  538.160602\n-    5    3584.0   610.042567  470.032796\n-    6    4096.0   673.315042  474.898540\n+    0    1024.0   186.181817  372.363633\n+    1    1536.0   271.058819  438.857146\n+    2    2048.0   375.206126  496.484863\n+    3    2560.0   451.764698  534.260858\n+    4    3072.0   554.345889  542.117638\n+    5    3584.0   618.820161  470.032796\n+    6    4096.0   692.281669  474.898540\n     7    4608.0   718.129898  478.753251\n     8    5120.0   772.830175  483.779502\n-    9    5632.0   814.265070  487.971095\n+    9    5632.0   819.199976  487.971095\n     10   6144.0   867.388239  494.818794\n-    11   6656.0   907.636357  499.200013\n-    12   7168.0   945.230752  477.866659\n+    11   6656.0   907.636357  500.764869\n+    12   7168.0   940.065592  477.866659\n     13   7680.0   975.238103  479.999983\n     14   8192.0  1008.246151  487.861027\n-    15   8704.0   671.691295  486.937055\n-    16   9216.0   699.949388  489.345125\n-    17   9728.0   725.068307  494.644053\n-    18  10240.0   751.559663  495.483878\n-    19  10752.0   779.601236  486.883001\n-    20  11264.0   806.973159  488.853509\n-    21  11776.0   826.385931  492.376302\n-    22  12288.0   837.818175  497.322112\n-    23  12800.0   846.280994  499.512174\n-    24  13312.0   863.481094  499.200013\n-    25  13824.0   859.523317  498.911279\n-    26  14336.0   875.480928  491.520018\n-    27  14848.0   875.557709  494.933326\n-    28  15360.0   894.757295  500.529518\n-    29  15872.0   894.197155  502.543530\n+    15   8704.0   673.858058  488.074767\n+    16   9216.0   699.949388  491.520008\n+    17   9728.0   722.823562  495.694261\n+    18  10240.0   751.559663  496.484863\n+    19  10752.0   779.601236  487.803392\n+    20  11264.0   806.973159  489.739120\n+    21  11776.0   826.385931  493.235604\n+    22  12288.0   840.205140  499.005061\n+    23  12800.0   848.618804  499.512174\n+    24  13312.0   863.481094  500.764869\n+    25  13824.0   861.755862  500.416301\n+    26  14336.0   873.258878  492.928354\n+    27  14848.0   877.714272  496.311981\n+    28  15360.0   892.590796  502.234332\n+    29  15872.0   894.197155  503.207397\n \n \n \n@@ -475,7 +475,7 @@ References\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  29.357 seconds)\n+   **Total running time of the script:** ( 0 minutes  29.179 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_05-layer-norm.py:"}, {"filename": "main/_sources/getting-started/tutorials/06-fused-attention.rst.txt", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "file_content_changes": "@@ -52,16 +52,16 @@ This is a Triton implementation of the Flash Attention algorithm\n \n     fused-attention-batch4-head48-d64-fwd:\n         N_CTX     Triton\n-    0  1024.0   0.291746\n-    1  2048.0   1.001370\n-    2  4096.0   3.680926\n-    3  8192.0  14.026459\n+    0  1024.0   0.289582\n+    1  2048.0   1.000526\n+    2  4096.0   3.673443\n+    3  8192.0  14.027923\n     fused-attention-batch4-head48-d64-bwd:\n         N_CTX     Triton\n-    0  1024.0   1.207440\n-    1  2048.0   3.873628\n-    2  4096.0  13.652553\n-    3  8192.0  51.041279\n+    0  1024.0   1.200964\n+    1  2048.0   3.846676\n+    2  4096.0  13.620078\n+    3  8192.0  50.846722\n \n \n \n@@ -430,7 +430,7 @@ This is a Triton implementation of the Flash Attention algorithm\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  4.600 seconds)\n+   **Total running time of the script:** ( 0 minutes  4.587 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_06-fused-attention.py:"}, {"filename": "main/_sources/getting-started/tutorials/07-math-functions.rst.txt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -147,7 +147,7 @@ We can also customize the libdevice library path by passing the path to the `lib\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  0.222 seconds)\n+   **Total running time of the script:** ( 0 minutes  0.225 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_07-math-functions.py:"}, {"filename": "main/_sources/getting-started/tutorials/08-experimental-block-pointer.rst.txt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -298,7 +298,7 @@ Still we can test our matrix multiplication with block pointers against a native\n \n .. rst-class:: sphx-glr-timing\n \n-   **Total running time of the script:** ( 0 minutes  6.438 seconds)\n+   **Total running time of the script:** ( 0 minutes  6.391 seconds)\n \n \n .. _sphx_glr_download_getting-started_tutorials_08-experimental-block-pointer.py:"}, {"filename": "main/_sources/getting-started/tutorials/sg_execution_times.rst.txt", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "file_content_changes": "@@ -6,22 +6,22 @@\n \n Computation times\n =================\n-**02:06.289** total execution time for **getting-started_tutorials** files:\n+**02:05.480** total execution time for **getting-started_tutorials** files:\n \n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_03-matrix-multiplication.py` (``03-matrix-multiplication.py``)           | 00:40.854 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_03-matrix-multiplication.py` (``03-matrix-multiplication.py``)           | 00:40.772 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_02-fused-softmax.py` (``02-fused-softmax.py``)                           | 00:38.423 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_02-fused-softmax.py` (``02-fused-softmax.py``)                           | 00:37.979 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_05-layer-norm.py` (``05-layer-norm.py``)                                 | 00:29.357 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_05-layer-norm.py` (``05-layer-norm.py``)                                 | 00:29.179 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_08-experimental-block-pointer.py` (``08-experimental-block-pointer.py``) | 00:06.438 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_08-experimental-block-pointer.py` (``08-experimental-block-pointer.py``) | 00:06.391 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_01-vector-add.py` (``01-vector-add.py``)                                 | 00:05.755 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_01-vector-add.py` (``01-vector-add.py``)                                 | 00:05.725 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_06-fused-attention.py` (``06-fused-attention.py``)                       | 00:04.600 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_06-fused-attention.py` (``06-fused-attention.py``)                       | 00:04.587 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_04-low-memory-dropout.py` (``04-low-memory-dropout.py``)                 | 00:00.639 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_04-low-memory-dropout.py` (``04-low-memory-dropout.py``)                 | 00:00.620 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+\n-| :ref:`sphx_glr_getting-started_tutorials_07-math-functions.py` (``07-math-functions.py``)                         | 00:00.222 | 0.0 MB |\n+| :ref:`sphx_glr_getting-started_tutorials_07-math-functions.py` (``07-math-functions.py``)                         | 00:00.225 | 0.0 MB |\n +-------------------------------------------------------------------------------------------------------------------+-----------+--------+"}, {"filename": "main/getting-started/tutorials/01-vector-add.html", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -235,8 +235,8 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n </div>\n <img src=\"../../_images/sphx_glr_01-vector-add_001.png\" srcset=\"../../_images/sphx_glr_01-vector-add_001.png\" alt=\"01 vector add\" class = \"sphx-glr-single-img\"/><div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>vector-add-performance:\n            size       Triton        Torch\n-0        4096.0     8.000000     9.600000\n-1        8192.0    15.999999    15.999999\n+0        4096.0     9.600000     9.600000\n+1        8192.0    15.999999    19.200000\n 2       16384.0    31.999999    31.999999\n 3       32768.0    63.999998    63.999998\n 4       65536.0   127.999995   127.999995\n@@ -247,13 +247,13 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n 9     2097152.0  1023.999964  1023.999964\n 10    4194304.0  1228.800031  1228.800031\n 11    8388608.0  1424.695621  1424.695621\n-12   16777216.0  1560.380965  1548.094408\n-13   33554432.0  1624.859540  1624.859540\n-14   67108864.0  1669.706983  1662.646960\n+12   16777216.0  1560.380965  1560.380965\n+13   33554432.0  1624.859540  1631.601649\n+14   67108864.0  1669.706983  1666.169441\n 15  134217728.0  1684.008546  1678.616907\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  5.755 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  5.725 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-01-vector-add-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/62d97d49a32414049819dd8bb8378080/01-vector-add.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">01-vector-add.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/02-fused-softmax.html", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "file_content_changes": "@@ -282,17 +282,17 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n </div>\n <img src=\"../../_images/sphx_glr_02-fused-softmax_001.png\" srcset=\"../../_images/sphx_glr_02-fused-softmax_001.png\" alt=\"02 fused softmax\" class = \"sphx-glr-single-img\"/><div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>softmax-performance:\n           N       Triton  Torch (native)  Torch (jit)\n-0     256.0   682.666643      682.666643   273.066674\n-1     384.0   877.714274      877.714274   332.108094\n+0     256.0   682.666643      744.727267   264.258068\n+1     384.0   877.714274      819.200021   332.108094\n 2     512.0   910.222190      910.222190   372.363633\n-3     640.0   975.238103      975.238103   401.568635\n+3     640.0   975.238103      975.238103   409.600010\n 4     768.0  1068.521715     1023.999964   431.157886\n ..      ...          ...             ...          ...\n-93  12160.0  1588.244879     1066.082150   592.267887\n+93  12160.0  1594.754129     1066.082150   592.267887\n 94  12288.0  1591.967682     1013.443336   592.192778\n-95  12416.0  1576.634933     1026.645975   590.359582\n-96  12544.0  1574.149071     1008.562805   591.610919\n-97  12672.0  1577.836533     1006.213368   590.253282\n+95  12416.0  1576.634933     1024.000037   590.359582\n+96  12544.0  1574.149071     1011.103284   592.047213\n+97  12672.0  1577.836533     1006.213368   591.113716\n \n [98 rows x 4 columns]\n </pre></div>\n@@ -305,7 +305,7 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n </ul>\n </dd>\n </dl>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  38.423 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  37.979 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-02-fused-softmax-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/d91442ac2982c4e0cc3ab0f43534afbc/02-fused-softmax.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">02-fused-softmax.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/03-matrix-multiplication.html", "status": "modified", "additions": 22, "deletions": 22, "changes": 44, "file_content_changes": "@@ -466,37 +466,37 @@ <h3>Square Matrix Performance<a class=\"headerlink\" href=\"#square-matrix-performa\n 0    256.0    4.096000    4.096000\n 1    384.0   12.288000   12.288000\n 2    512.0   26.214401   23.831273\n-3    640.0   42.666665   39.384616\n+3    640.0   42.666665   42.666665\n 4    768.0   63.195428   58.982401\n 5    896.0   78.051553   82.642822\n-6   1024.0  104.857603   99.864382\n+6   1024.0  110.376426   99.864382\n 7   1152.0  135.726544  129.825388\n 8   1280.0  163.840004  163.840004\n 9   1408.0  155.765024  132.970149\n 10  1536.0  181.484314  157.286398\n-11  1664.0  183.651271  179.978245\n-12  1792.0  172.914215  208.137481\n-13  1920.0  206.328356  168.585369\n-14  2048.0  199.728763  190.650180\n+11  1664.0  183.651271  183.651271\n+12  1792.0  175.616000  208.137481\n+13  1920.0  203.294114  168.585369\n+14  2048.0  199.728763  192.841562\n 15  2176.0  193.496618  211.827867\n-16  2304.0  227.503545  229.691080\n-17  2432.0  202.118452  199.251522\n-18  2560.0  222.911566  212.779229\n-19  2688.0  196.544332  198.602388\n-20  2816.0  211.719459  210.696652\n-21  2944.0  222.482283  223.479969\n-22  3072.0  210.494802  206.653671\n-23  3200.0  216.949149  219.178074\n-24  3328.0  208.067338  206.871539\n-25  3456.0  216.143621  215.565692\n-26  3584.0  218.772251  207.656790\n-27  3712.0  210.310194  219.073119\n-28  3840.0  208.271176  208.664143\n-29  3968.0  210.386099  215.971570\n-30  4096.0  222.214781  211.366499\n+16  2304.0  231.921091  231.921091\n+17  2432.0  208.107149  203.583068\n+18  2560.0  224.438347  218.453323\n+19  2688.0  195.531224  198.602388\n+20  2816.0  209.683695  212.752230\n+21  2944.0  223.479969  226.527416\n+22  3072.0  209.715208  202.950194\n+23  3200.0  219.931269  216.949149\n+24  3328.0  207.467716  208.670419\n+25  3456.0  216.143621  216.143621\n+26  3584.0  219.305830  207.656790\n+27  3712.0  210.310194  216.697064\n+28  3840.0  211.053446  210.651436\n+29  3968.0  211.479948  218.680889\n+30  4096.0  221.116512  214.063362\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  40.854 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  40.772 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-03-matrix-multiplication-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/d5fee5b55a64e47f1b5724ec39adf171/03-matrix-multiplication.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">03-matrix-multiplication.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/04-low-memory-dropout.html", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -287,7 +287,7 @@ <h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this\n <p>Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov, \u201cDropout: A Simple Way to Prevent Neural Networks from Overfitting\u201d, JMLR 2014</p>\n </div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  0.639 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  0.620 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-04-low-memory-dropout-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/c9aed78977a4c05741d675a38dde3d7d/04-low-memory-dropout.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">04-low-memory-dropout.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/05-layer-norm.html", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "file_content_changes": "@@ -460,36 +460,36 @@ <h2>Benchmark<a class=\"headerlink\" href=\"#benchmark\" title=\"Permalink to this he\n </div>\n <img src=\"../../_images/sphx_glr_05-layer-norm_001.png\" srcset=\"../../_images/sphx_glr_05-layer-norm_001.png\" alt=\"05 layer norm\" class = \"sphx-glr-single-img\"/><div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>layer-norm-backward:\n           N       Triton       Torch\n-0    1024.0   176.805760  372.363633\n-1    1536.0   265.208640  438.857146\n-2    2048.0   325.509933  496.484863\n-3    2560.0   415.135117  529.655159\n-4    3072.0   526.628557  538.160602\n-5    3584.0   610.042567  470.032796\n-6    4096.0   673.315042  474.898540\n+0    1024.0   186.181817  372.363633\n+1    1536.0   271.058819  438.857146\n+2    2048.0   375.206126  496.484863\n+3    2560.0   451.764698  534.260858\n+4    3072.0   554.345889  542.117638\n+5    3584.0   618.820161  470.032796\n+6    4096.0   692.281669  474.898540\n 7    4608.0   718.129898  478.753251\n 8    5120.0   772.830175  483.779502\n-9    5632.0   814.265070  487.971095\n+9    5632.0   819.199976  487.971095\n 10   6144.0   867.388239  494.818794\n-11   6656.0   907.636357  499.200013\n-12   7168.0   945.230752  477.866659\n+11   6656.0   907.636357  500.764869\n+12   7168.0   940.065592  477.866659\n 13   7680.0   975.238103  479.999983\n 14   8192.0  1008.246151  487.861027\n-15   8704.0   671.691295  486.937055\n-16   9216.0   699.949388  489.345125\n-17   9728.0   725.068307  494.644053\n-18  10240.0   751.559663  495.483878\n-19  10752.0   779.601236  486.883001\n-20  11264.0   806.973159  488.853509\n-21  11776.0   826.385931  492.376302\n-22  12288.0   837.818175  497.322112\n-23  12800.0   846.280994  499.512174\n-24  13312.0   863.481094  499.200013\n-25  13824.0   859.523317  498.911279\n-26  14336.0   875.480928  491.520018\n-27  14848.0   875.557709  494.933326\n-28  15360.0   894.757295  500.529518\n-29  15872.0   894.197155  502.543530\n+15   8704.0   673.858058  488.074767\n+16   9216.0   699.949388  491.520008\n+17   9728.0   722.823562  495.694261\n+18  10240.0   751.559663  496.484863\n+19  10752.0   779.601236  487.803392\n+20  11264.0   806.973159  489.739120\n+21  11776.0   826.385931  493.235604\n+22  12288.0   840.205140  499.005061\n+23  12800.0   848.618804  499.512174\n+24  13312.0   863.481094  500.764869\n+25  13824.0   861.755862  500.416301\n+26  14336.0   873.258878  492.928354\n+27  14848.0   877.714272  496.311981\n+28  15360.0   892.590796  502.234332\n+29  15872.0   894.197155  503.207397\n </pre></div>\n </div>\n </section>\n@@ -501,7 +501,7 @@ <h2>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this\n <p>Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton, \u201cLayer Normalization\u201d, Arxiv 2016</p>\n </div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  29.357 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  29.179 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-05-layer-norm-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/935c0dd0fbeb4b2e69588471cbb2d4b2/05-layer-norm.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">05-layer-norm.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/06-fused-attention.html", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "file_content_changes": "@@ -112,16 +112,16 @@\n </ul>\n <div class=\"sphx-glr-script-out highlight-none notranslate\"><div class=\"highlight\"><pre><span></span>fused-attention-batch4-head48-d64-fwd:\n     N_CTX     Triton\n-0  1024.0   0.291746\n-1  2048.0   1.001370\n-2  4096.0   3.680926\n-3  8192.0  14.026459\n+0  1024.0   0.289582\n+1  2048.0   1.000526\n+2  4096.0   3.673443\n+3  8192.0  14.027923\n fused-attention-batch4-head48-d64-bwd:\n     N_CTX     Triton\n-0  1024.0   1.207440\n-1  2048.0   3.873628\n-2  4096.0  13.652553\n-3  8192.0  51.041279\n+0  1024.0   1.200964\n+1  2048.0   3.846676\n+2  4096.0  13.620078\n+3  8192.0  50.846722\n </pre></div>\n </div>\n <div class=\"line-block\">\n@@ -482,7 +482,7 @@\n <span class=\"n\">bench_flash_attention</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">save_path</span><span class=\"o\">=</span><span class=\"s1\">&#39;.&#39;</span><span class=\"p\">,</span> <span class=\"n\">print_data</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  4.600 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  4.587 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-06-fused-attention-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/54a35f6ec55f9746935b9566fb6bb1df/06-fused-attention.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">06-fused-attention.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/07-math-functions.html", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -186,7 +186,7 @@ <h2>Customize the libdevice library path<a class=\"headerlink\" href=\"#customize-t\n The maximum difference between torch and triton is 2.384185791015625e-07\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  0.222 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  0.225 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-07-math-functions-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/77571465f7f4bd281d3a847dc2633146/07-math-functions.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">07-math-functions.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/08-experimental-block-pointer.html", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -335,7 +335,7 @@ <h2>Unit Test<a class=\"headerlink\" href=\"#unit-test\" title=\"Permalink to this he\n \u2705 Triton and Torch match\n </pre></div>\n </div>\n-<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  6.438 seconds)</p>\n+<p class=\"sphx-glr-timing\"><strong>Total running time of the script:</strong> ( 0 minutes  6.391 seconds)</p>\n <div class=\"sphx-glr-footer sphx-glr-footer-example docutils container\" id=\"sphx-glr-download-getting-started-tutorials-08-experimental-block-pointer-py\">\n <div class=\"sphx-glr-download sphx-glr-download-python docutils container\">\n <p><a class=\"reference download internal\" download=\"\" href=\"../../_downloads/4d6052117d61c2ca779cd4b75567fee5/08-experimental-block-pointer.py\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Download</span> <span class=\"pre\">Python</span> <span class=\"pre\">source</span> <span class=\"pre\">code:</span> <span class=\"pre\">08-experimental-block-pointer.py</span></code></a></p>"}, {"filename": "main/getting-started/tutorials/sg_execution_times.html", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "file_content_changes": "@@ -86,39 +86,39 @@\n              \n   <section id=\"computation-times\">\n <span id=\"sphx-glr-getting-started-tutorials-sg-execution-times\"></span><h1>Computation times<a class=\"headerlink\" href=\"#computation-times\" title=\"Permalink to this heading\">\u00b6</a></h1>\n-<p><strong>02:06.289</strong> total execution time for <strong>getting-started_tutorials</strong> files:</p>\n+<p><strong>02:05.480</strong> total execution time for <strong>getting-started_tutorials</strong> files:</p>\n <table class=\"docutils align-default\">\n <tbody>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py\"><span class=\"std std-ref\">Matrix Multiplication</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">03-matrix-multiplication.py</span></code>)</p></td>\n-<td><p>00:40.854</p></td>\n+<td><p>00:40.772</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"02-fused-softmax.html#sphx-glr-getting-started-tutorials-02-fused-softmax-py\"><span class=\"std std-ref\">Fused Softmax</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">02-fused-softmax.py</span></code>)</p></td>\n-<td><p>00:38.423</p></td>\n+<td><p>00:37.979</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"05-layer-norm.html#sphx-glr-getting-started-tutorials-05-layer-norm-py\"><span class=\"std std-ref\">Layer Normalization</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">05-layer-norm.py</span></code>)</p></td>\n-<td><p>00:29.357</p></td>\n+<td><p>00:29.179</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"08-experimental-block-pointer.html#sphx-glr-getting-started-tutorials-08-experimental-block-pointer-py\"><span class=\"std std-ref\">Block Pointer (Experimental)</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">08-experimental-block-pointer.py</span></code>)</p></td>\n-<td><p>00:06.438</p></td>\n+<td><p>00:06.391</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"01-vector-add.html#sphx-glr-getting-started-tutorials-01-vector-add-py\"><span class=\"std std-ref\">Vector Addition</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">01-vector-add.py</span></code>)</p></td>\n-<td><p>00:05.755</p></td>\n+<td><p>00:05.725</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"06-fused-attention.html#sphx-glr-getting-started-tutorials-06-fused-attention-py\"><span class=\"std std-ref\">Fused Attention</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">06-fused-attention.py</span></code>)</p></td>\n-<td><p>00:04.600</p></td>\n+<td><p>00:04.587</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"04-low-memory-dropout.html#sphx-glr-getting-started-tutorials-04-low-memory-dropout-py\"><span class=\"std std-ref\">Low-Memory Dropout</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">04-low-memory-dropout.py</span></code>)</p></td>\n-<td><p>00:00.639</p></td>\n+<td><p>00:00.620</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n <tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"07-math-functions.html#sphx-glr-getting-started-tutorials-07-math-functions-py\"><span class=\"std std-ref\">Libdevice (tl.math) function</span></a> (<code class=\"docutils literal notranslate\"><span class=\"pre\">07-math-functions.py</span></code>)</p></td>\n-<td><p>00:00.222</p></td>\n+<td><p>00:00.225</p></td>\n <td><p>0.0 MB</p></td>\n </tr>\n </tbody>"}, {"filename": "main/python-api/generated/triton.language.device_assert.html", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "file_content_changes": "@@ -117,7 +117,15 @@ <h1>triton.language.device_assert<a class=\"headerlink\" href=\"#triton-language-de\n <dl class=\"py function\">\n <dt class=\"sig sig-object py\" id=\"triton.language.device_assert\">\n <span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">device_assert</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">cond</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">msg</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">''</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.device_assert\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Assert the condition at runtime from the device.</p>\n+<dd><p>Assert the condition at runtime from the device.  Requires that the environment variable <code class=\"code docutils literal notranslate\"><span class=\"pre\">TRITON_DEBUG</span></code>\n+is set to a value besides <code class=\"code docutils literal notranslate\"><span class=\"pre\">0</span></code> in order for this to have any effect.</p>\n+<p>Using the Python <code class=\"code docutils literal notranslate\"><span class=\"pre\">assert</span></code> statement is the same as calling this function, except that the second argument\n+must be provided and must be a string, e.g. <code class=\"code docutils literal notranslate\"><span class=\"pre\">assert</span> <span class=\"pre\">pid</span> <span class=\"pre\">==</span> <span class=\"pre\">0,</span> <span class=\"pre\">&quot;pid</span> <span class=\"pre\">!=</span> <span class=\"pre\">0&quot;</span></code>.  The environment variable must\n+be set for this <code class=\"code docutils literal notranslate\"><span class=\"pre\">assert</span></code> statement to have any effect.</p>\n+<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">device_assert</span><span class=\"p\">(</span><span class=\"n\">pid</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n+<span class=\"k\">assert</span> <span class=\"n\">pid</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s2\">&quot;pid != 0&quot;</span>\n+</pre></div>\n+</div>\n <dl class=\"field-list simple\">\n <dt class=\"field-odd\">Parameters<span class=\"colon\">:</span></dt>\n <dd class=\"field-odd\"><ul class=\"simple\">"}, {"filename": "main/python-api/generated/triton.language.device_print.html", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -117,7 +117,11 @@ <h1>triton.language.device_print<a class=\"headerlink\" href=\"#triton-language-dev\n <dl class=\"py function\">\n <dt class=\"sig sig-object py\" id=\"triton.language.device_print\">\n <span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">device_print</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">prefix</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.device_print\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Print the values at runtime from the device.</p>\n+<dd><p>Print the values at runtime from the device.  String formatting does not work, so you should\n+provide the values you want to print as arguments.</p>\n+<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">device_print</span><span class=\"p\">(</span><span class=\"s2\">&quot;pid&quot;</span><span class=\"p\">,</span> <span class=\"n\">pid</span><span class=\"p\">)</span>\n+</pre></div>\n+</div>\n <dl class=\"field-list simple\">\n <dt class=\"field-odd\">Parameters<span class=\"colon\">:</span></dt>\n <dd class=\"field-odd\"><ul class=\"simple\">"}, {"filename": "main/python-api/generated/triton.language.static_assert.html", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -117,7 +117,11 @@ <h1>triton.language.static_assert<a class=\"headerlink\" href=\"#triton-language-st\n <dl class=\"py function\">\n <dt class=\"sig sig-object py\" id=\"triton.language.static_assert\">\n <span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">static_assert</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">cond</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">msg</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">''</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.static_assert\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Assert the condition at compile time. The parameters are the same as the builtin <code class=\"code docutils literal notranslate\"><span class=\"pre\">assert</span></code>.</p>\n+<dd><p>Assert the condition at compile time.  Does not require that the <code class=\"code docutils literal notranslate\"><span class=\"pre\">TRITON_DEBUG</span></code> environment variable\n+is set.</p>\n+<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">static_assert</span><span class=\"p\">(</span><span class=\"n\">BLOCK_SIZE</span> <span class=\"o\">==</span> <span class=\"mi\">1024</span><span class=\"p\">)</span>\n+</pre></div>\n+</div>\n </dd></dl>\n \n </section>"}, {"filename": "main/python-api/generated/triton.language.static_print.html", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "file_content_changes": "@@ -117,7 +117,12 @@ <h1>triton.language.static_print<a class=\"headerlink\" href=\"#triton-language-sta\n <dl class=\"py function\">\n <dt class=\"sig sig-object py\" id=\"triton.language.static_print\">\n <span class=\"sig-prename descclassname\"><span class=\"pre\">triton.language.</span></span><span class=\"sig-name descname\"><span class=\"pre\">static_print</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">values</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sep</span></span><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"n\"><span class=\"pre\">str</span></span><span class=\"w\"> </span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"w\"> </span><span class=\"default_value\"><span class=\"pre\">'</span> <span class=\"pre\">'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">end</span></span><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"n\"><span class=\"pre\">str</span></span><span class=\"w\"> </span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"w\"> </span><span class=\"default_value\"><span class=\"pre\">'\\n'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">file</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">flush</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#triton.language.static_print\" title=\"Permalink to this definition\">\u00b6</a></dt>\n-<dd><p>Print the values at compile time. The parameters are the same as the builtin <code class=\"code docutils literal notranslate\"><span class=\"pre\">print</span></code>.</p>\n+<dd><p>Print the values at compile time. The parameters are the same as the Python builtin <code class=\"code docutils literal notranslate\"><span class=\"pre\">print</span></code>.</p>\n+<p>Calling the Python builtin <code class=\"code docutils literal notranslate\"><span class=\"pre\">print</span></code> inside your kernel is the same as calling this.</p>\n+<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">static_print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;</span><span class=\"si\">{</span><span class=\"n\">BLOCK_SIZE</span><span class=\"si\">=}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n+<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;</span><span class=\"si\">{</span><span class=\"n\">BLOCK_SIZE</span><span class=\"si\">=}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n+</pre></div>\n+</div>\n </dd></dl>\n \n </section>"}, {"filename": "main/searchindex.js", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "N/A"}]