[{"filename": "CMakeLists.txt", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -187,6 +187,7 @@ list(APPEND CMAKE_MODULE_PATH \"${LLVM_CMAKE_DIR}\")\n include(TableGen) # required by AddMLIR\n include(AddLLVM)\n include(AddMLIR)\n+include(HandleLLVMOptions)\n \n # Disable warnings that show up in external code (gtest;pybind11)\n set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Werror -Wno-covered-switch-default\")"}, {"filename": "include/triton/Analysis/AxisInfo.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -306,6 +306,7 @@ class ModuleAxisInfoAnalysis : public CallGraph<AxisInfoMapT> {\n       : CallGraph<AxisInfoMapT>(moduleOp) {\n     SmallVector<FunctionOpInterface> funcs;\n     for (auto root : getRoots()) {\n+      (void)root;\n       walk<WalkOrder::PreOrder, WalkOrder::PostOrder>(\n           // Pre-order edge walk callback\n           [](CallOpInterface callOp, FunctionOpInterface funcOp) {},"}, {"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -58,7 +58,7 @@ class ReduceOpHelper {\n   ArrayRef<int64_t> srcShape;\n   Attribute srcEncoding;\n   SmallVector<Type> srcElementTypes;\n-  int axis;\n+  unsigned axis;\n };\n \n bool maybeSharedAllocationOp(Operation *op);\n@@ -82,7 +82,7 @@ inline SmallVector<T_OUT> convertType(ArrayRef<T_IN> in) {\n }\n \n template <typename Int> Int product(llvm::ArrayRef<Int> arr) {\n-  return std::accumulate(arr.begin(), arr.end(), 1, std::multiplies{});\n+  return std::accumulate(arr.begin(), arr.end(), 1, std::multiplies<Int>{});\n }\n \n template <typename Int> Int ceil(Int m, Int n) { return (m + n - 1) / n; }"}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/GCNAsmFormat.h", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "file_content_changes": "@@ -15,9 +15,9 @@ class Location;\n namespace triton {\n using llvm::StringRef;\n \n-class GCNInstr;\n-class GCNInstrCommon;\n-class GCNInstrExecution;\n+struct GCNInstr;\n+struct GCNInstrCommon;\n+struct GCNInstrExecution;\n \n // GCNBuilder helps to manage a GCN asm program consists of one or multiple\n // instructions.\n@@ -94,7 +94,7 @@ struct GCNBuilder {\n     Operand() = default;\n     Operand(const Operation &) = delete;\n     Operand(Value value, StringRef constraint)\n-        : value(value), constraint(constraint) {}\n+        : constraint(constraint), value(value) {}\n \n     bool isList() const { return !value && constraint.empty(); }\n \n@@ -164,15 +164,15 @@ struct GCNBuilder {\n   Operand *newListOperand(unsigned count, mlir::Value val,\n                           const std::string &constraint) {\n     auto *list = newOperand();\n-    for (int i = 0; i < count; ++i) {\n+    for (unsigned i = 0; i < count; ++i) {\n       list->listAppend(newOperand(val, constraint));\n     }\n     return list;\n   }\n \n   Operand *newListOperand(unsigned count, const std::string &constraint) {\n     auto *list = newOperand();\n-    for (int i = 0; i < count; ++i) {\n+    for (unsigned i = 0; i < count; ++i) {\n       list->listAppend(newOperand(constraint));\n     }\n     return list;\n@@ -223,8 +223,8 @@ struct GCNBuilder {\n     return modArchive.back().get();\n   }\n \n-  friend class GCNInstr;\n-  friend class GCNInstrCommon;\n+  friend struct GCNInstr;\n+  friend struct GCNInstrCommon;\n \n protected:\n   llvm::SmallVector<std::unique_ptr<Operand>, 6> argArchive;\n@@ -264,7 +264,7 @@ struct GCNInstrCommon {\n   GCNBuilder *builder{};\n   llvm::SmallVector<std::string, 4> instrParts;\n \n-  friend class GCNInstrExecution;\n+  friend struct GCNInstrExecution;\n };\n \n template <class ConcreteT> struct GCNInstrBase : public GCNInstrCommon {\n@@ -320,8 +320,8 @@ struct GCNInstrExecution {\n   explicit GCNInstrExecution(GCNInstrCommon *instr,\n                              llvm::ArrayRef<Operand *> oprs,\n                              llvm::ArrayRef<Modifier *> modifiers)\n-      : instr(instr), argsInOrder(oprs.begin(), oprs.end()),\n-        mods(modifiers.begin(), modifiers.end()) {}\n+      : argsInOrder(oprs.begin(), oprs.end()),\n+        mods(modifiers.begin(), modifiers.end()), instr(instr) {}\n \n   std::string dump() const;\n "}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -410,9 +410,9 @@ For example, the matrix L corresponding to blockTileSize=[32,16] is:\n \n       do {\n         wpt_nm1 = wpt;\n-        if (wpt[0] * wpt[1] < numWarps)\n+        if (static_cast<int>(wpt[0] * wpt[1]) < numWarps)\n           wpt[0] = std::clamp<int>(wpt[0] * 2, 1, shapeC[0] / spw[0]);\n-        if (wpt[0] * wpt[1] < numWarps)\n+        if (static_cast<int>(wpt[0] * wpt[1]) < numWarps)\n           wpt[1] = std::clamp<int>(wpt[1] * 2, 1, shapeC[1] / spw[1]);\n       } while (wpt_nm1 != wpt);\n "}, {"filename": "lib/Analysis/Allocation.cpp", "status": "modified", "additions": 17, "deletions": 13, "changes": 30, "file_content_changes": "@@ -186,7 +186,7 @@ class AllocationAnalysis {\n       unsigned outVec = 0;\n       auto smemShape = getScratchConfigForCvtLayout(cvtLayout, inVec, outVec);\n       unsigned elems = std::accumulate(smemShape.begin(), smemShape.end(), 1,\n-                                       std::multiplies{});\n+                                       std::multiplies<unsigned>{});\n       auto bytes =\n           srcTy.getElementType().isa<triton::PointerType>()\n               ? elems * kPtrBitWidth / 8\n@@ -201,7 +201,7 @@ class AllocationAnalysis {\n       } else {\n         auto smemShape = getScratchConfigForAtomicRMW(atomicRMWOp);\n         unsigned elems = std::accumulate(smemShape.begin(), smemShape.end(), 1,\n-                                         std::multiplies{});\n+                                         std::multiplies<unsigned>{});\n         auto elemTy =\n             value.getType().cast<triton::PointerType>().getPointeeType();\n         auto bytes =\n@@ -214,7 +214,7 @@ class AllocationAnalysis {\n       auto value = op->getOperand(0);\n       auto smemShape = getScratchConfigForAtomicCAS(atomicCASOp);\n       unsigned elems = std::accumulate(smemShape.begin(), smemShape.end(), 1,\n-                                       std::multiplies{});\n+                                       std::multiplies<unsigned>{});\n       auto elemTy =\n           value.getType().cast<triton::PointerType>().getPointeeType();\n       auto bytes = elemTy.isa<triton::PointerType>()\n@@ -296,7 +296,7 @@ class AllocationAnalysis {\n           minId = std::min(minId, bufferRange[buffer].start());\n           maxId = std::max(maxId, bufferRange[buffer].end());\n         }\n-        bufferRange[buffer] = Interval(minId, maxId);\n+        bufferRange[buffer] = Interval<size_t>(minId, maxId);\n       }\n     }\n   }\n@@ -313,8 +313,9 @@ class AllocationAnalysis {\n         // range.\n         auto *op = opScratchIter.first;\n         auto *buffer = opScratchIter.second;\n-        bufferRange.insert({buffer, Interval(operationId.lookup(op),\n-                                             operationId.lookup(op) + 1)});\n+        bufferRange.insert(\n+            {buffer, Interval<size_t>(operationId.lookup(op),\n+                                      operationId.lookup(op) + 1)});\n       }\n     };\n     processScratchMemory(allocation->opScratch);\n@@ -358,7 +359,7 @@ class AllocationAnalysis {\n                         maxId = operationId[liveOp] + 1;\n                       }\n                     });\n-      return Interval(minId, maxId);\n+      return Interval<size_t>(minId, maxId);\n     };\n \n     resolveExplicitBufferLiveness(getValueLivenessRange);\n@@ -427,16 +428,19 @@ class AllocationAnalysis {\n         auto xRange = bufferRange.lookup(buffer);\n         bufferStart[buffer] = size;\n         tripleMap.insert(\n-            {size + xSize, Interval{std::max(range.start(), xRange.start()),\n-                                    std::min(range.end(), xRange.end())}});\n+            {size + xSize,\n+             Interval<size_t>{std::max(range.start(), xRange.start()),\n+                              std::min(range.end(), xRange.end())}});\n         // We could either insert (range.start, xRange.start) or (range.start,\n         // xRange.end), both are correct and determine the potential buffer\n         // offset, and the graph coloring algorithm will solve the interference,\n         // if any\n         if (range.start() < xRange.start())\n-          tripleMap.insert({size, Interval{range.start(), xRange.end()}});\n+          tripleMap.insert(\n+              {size, Interval<size_t>{range.start(), xRange.end()}});\n         if (xRange.end() < range.end())\n-          tripleMap.insert({size, Interval{xRange.start(), range.end()}});\n+          tripleMap.insert(\n+              {size, Interval<size_t>{xRange.start(), range.end()}});\n         xBuffers.erase(bufferIt);\n       }\n     }\n@@ -455,8 +459,8 @@ class AllocationAnalysis {\n         auto yStart = bufferStart.lookup(y);\n         auto xSize = x->size;\n         auto ySize = y->size;\n-        Interval xSizeRange = {xStart, xStart + xSize};\n-        Interval ySizeRange = {yStart, yStart + ySize};\n+        Interval<size_t> xSizeRange = {xStart, xStart + xSize};\n+        Interval<size_t> ySizeRange = {yStart, yStart + ySize};\n         auto xOpRange = bufferRange.lookup(x);\n         auto yOpRange = bufferRange.lookup(y);\n         if (xOpRange.intersects(yOpRange) &&"}, {"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 1, "deletions": 7, "changes": 8, "file_content_changes": "@@ -661,7 +661,7 @@ class SelectOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n         constantValue = lhsInfo.getConstantValue();\n       }\n     } else {\n-      for (auto d = 0; d < rank; ++d) {\n+      for (size_t d = 0; d < rank; ++d) {\n         constancy.push_back(\n             std::min(gcd(lhsInfo.getConstancy(d), condConstancy[d]),\n                      gcd(rhsInfo.getConstancy(d), condConstancy[d])));\n@@ -876,11 +876,6 @@ AxisInfoAnalysis::AxisInfoAnalysis(DataFlowSolver &solver)\n void AxisInfoAnalysis::visitOperation(\n     Operation *op, ArrayRef<const dataflow::Lattice<AxisInfo> *> operands,\n     ArrayRef<dataflow::Lattice<AxisInfo> *> results) {\n-  // TODO: For sure not the right way to do this\n-  // but why is scf.if not initialized otherwise?\n-  for (auto op : operands)\n-    if (op->getValue().getRank() == 0)\n-      setToEntryState((dataflow::Lattice<AxisInfo> *)op);\n   AxisInfo curr = visitors.apply(op, operands);\n   if (curr.getRank() == 0)\n     return setAllToEntryStates(results);\n@@ -912,7 +907,6 @@ unsigned ModuleAxisInfoAnalysis::getPtrContiguity(Value ptr) {\n   if (!tensorTy)\n     return 1;\n   auto layout = tensorTy.getEncoding();\n-  auto shape = tensorTy.getShape();\n \n   // Here order should be ordered by contiguous first, so the first element\n   // should have the largest contiguous."}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "file_content_changes": "@@ -285,7 +285,6 @@ struct ConvertLayoutOpConversion\n                               SmallVector<Value> &vals, Value smemBase,\n                               ArrayRef<int64_t> shape,\n                               bool isDestMma = false) const {\n-    unsigned accumNumCTAsEachRep = 1;\n     auto layout = type.getEncoding();\n     MmaEncodingAttr mma = layout.dyn_cast<MmaEncodingAttr>();\n     auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>();\n@@ -323,7 +322,7 @@ struct ConvertLayoutOpConversion\n       // when store to smem.\n       std::vector<std::pair<SmallVector<Value>, Value>> coord2val(\n           accumSizePerThread);\n-      for (unsigned elemId = 0; elemId < accumSizePerThread; ++elemId) {\n+      for (int elemId = 0; elemId < accumSizePerThread; ++elemId) {\n         // TODO[Superjomn]: Move the coordinate computation out of loop, it is\n         // duplicate in Volta.\n         SmallVector<Value> multiDimOffset =\n@@ -351,7 +350,7 @@ struct ConvertLayoutOpConversion\n \n     // Now the coord2valT has the transposed and contiguous elements(with\n     // vec=2), the original vals is not needed.\n-    for (unsigned elemId = 0; elemId < accumSizePerThread; elemId += vec) {\n+    for (int elemId = 0; elemId < accumSizePerThread; elemId += vec) {\n       auto coord = coord2valT[elemId].first;\n       Value offset = linearize(rewriter, loc, coord, paddedRepShape, outOrd);\n       auto elemPtrTy = ptr_ty(elemTy, 3);\n@@ -483,8 +482,6 @@ struct ConvertLayoutOpConversion\n     }\n \n     SmallVector<Type> types(outElems, llvmElemTy);\n-    auto *ctx = llvmElemTy.getContext();\n-    Type structTy = struct_ty(types);\n     Value result =\n         getTypeConverter()->packLLElements(loc, outVals, rewriter, dstTy);\n     rewriter.replaceOp(op, result);\n@@ -503,10 +500,11 @@ struct ConvertLayoutOpConversion\n     Value dst = op.getResult();\n     auto srcTy = src.getType().cast<RankedTensorType>();\n     auto srcShape = srcTy.getShape();\n-    auto dstTy = dst.getType().cast<RankedTensorType>();\n-    auto dstShape = dstTy.getShape();\n+    (void)srcShape;\n     assert(srcShape.size() == 2 &&\n            \"Unexpected rank of ConvertLayout(blocked->shared)\");\n+    auto dstTy = dst.getType().cast<RankedTensorType>();\n+    auto dstShape = dstTy.getShape();\n     auto srcLayout = srcTy.getEncoding();\n     auto dstSharedLayout = dstTy.getEncoding().cast<SharedEncodingAttr>();\n     auto inOrd = getOrder(srcLayout);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandFMA.cpp", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "file_content_changes": "@@ -19,7 +19,7 @@ getThreadIds(Value threadId, ArrayRef<unsigned int> shapePerCTA,\n              ConversionPatternRewriter &rewriter, Location loc) {\n   int dim = order.size();\n   SmallVector<Value> threadIds(dim);\n-  for (unsigned k = 0; k < dim - 1; k++) {\n+  for (int k = 0; k < dim - 1; k++) {\n     Value dimK = i32_val(shapePerCTA[order[k]] / sizePerThread[order[k]]);\n     Value rem = urem(threadId, dimK);\n     threadId = udiv(threadId, dimK);\n@@ -77,9 +77,9 @@ ValueTable getValueTableFromStruct(Value val, int K, int n0, int shapePerCTA,\n   ValueTable res;\n   auto elems = typeConverter->unpackLLElements(loc, val, rewriter, type);\n   int index = 0;\n-  for (unsigned k = 0; k < K; ++k) {\n-    for (unsigned m = 0; m < n0; m += shapePerCTA)\n-      for (unsigned mm = 0; mm < sizePerThread; ++mm) {\n+  for (int k = 0; k < K; ++k) {\n+    for (int m = 0; m < n0; m += shapePerCTA)\n+      for (int mm = 0; mm < sizePerThread; ++mm) {\n         res[{m + mm, k}] = elems[index++];\n       }\n   }\n@@ -137,9 +137,9 @@ Value loadAFMA(Value A, Value llA, BlockedEncodingAttr dLayout, Value thread,\n   int mShapePerCTA = getShapePerCTAForMN(dLayout, true /*isM*/);\n   int mSizePerThread = getSizePerThreadForMN(dLayout, true /*isM*/);\n \n-  for (unsigned k = 0; k < K; ++k)\n-    for (unsigned m = 0; m < M; m += mShapePerCTA)\n-      for (unsigned mm = 0; mm < mSizePerThread; ++mm) {\n+  for (int k = 0; k < K; ++k)\n+    for (int m = 0; m < M; m += mShapePerCTA)\n+      for (int mm = 0; mm < mSizePerThread; ++mm) {\n         Value offset =\n             add(mul(i32_val(m + mm), strideAM), mul(i32_val(k), strideAK));\n         Value pa = gep(ptrTy, aPtrs[0], offset);\n@@ -201,9 +201,9 @@ Value loadBFMA(Value B, Value llB, BlockedEncodingAttr dLayout, Value thread,\n   int nShapePerCTA = getShapePerCTAForMN(dLayout, false /*isM*/);\n   int nSizePerThread = getSizePerThreadForMN(dLayout, false /*isM*/);\n \n-  for (unsigned k = 0; k < K; ++k)\n-    for (unsigned n = 0; n < N; n += nShapePerCTA)\n-      for (unsigned nn = 0; nn < nSizePerThread; ++nn) {\n+  for (int k = 0; k < K; ++k)\n+    for (int n = 0; n < N; n += nShapePerCTA)\n+      for (int nn = 0; nn < nSizePerThread; ++nn) {\n         Value offset =\n             add(mul(i32_val(n + nn), strideBN), mul(i32_val(k), strideBK));\n         Value pb = gep(ptrTy, bPtrs[0], offset);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv1.cpp", "status": "modified", "additions": 4, "deletions": 13, "changes": 17, "file_content_changes": "@@ -26,15 +26,13 @@ computeOffsets(Value threadId, bool isARow, bool isBRow, ArrayRef<int> fpw,\n                ArrayRef<int> spw, ArrayRef<int> rep,\n                ConversionPatternRewriter &rewriter, Location loc,\n                Type resultTy) {\n-  auto *ctx = rewriter.getContext();\n   auto wpt = resultTy.cast<RankedTensorType>()\n                  .getEncoding()\n                  .cast<DotOperandEncodingAttr>()\n                  .getParent()\n                  .cast<MmaEncodingAttr>()\n                  .getWarpsPerCTA();\n \n-  Value _1 = i32_val(1);\n   Value _3 = i32_val(3);\n   Value _4 = i32_val(4);\n   Value _16 = i32_val(16);\n@@ -75,7 +73,6 @@ computeOffsets(Value threadId, bool isARow, bool isBRow, ArrayRef<int> fpw,\n   Value offsetBN = add(warpNOff, laneNOff);\n   Value offsetBK = and_(lane, _3);\n   // i indices\n-  Value offsetCM = add(and_(lane, _1), offsetAM);\n   if (isARow) {\n     offsetAM = add(offsetAM, urem(threadId, _4));\n     offsetAK = i32_val(0);\n@@ -100,7 +97,6 @@ static Value loadA(Value tensor, const SharedMemoryObject &smemObj,\n                  .cast<MmaEncodingAttr>()\n                  .getWarpsPerCTA();\n \n-  auto *ctx = rewriter.getContext();\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n   auto sharedLayout = tensorTy.getEncoding().cast<SharedEncodingAttr>();\n   auto shape = tensorTy.getShape();\n@@ -192,10 +188,8 @@ static Value loadA(Value tensor, const SharedMemoryObject &smemObj,\n     }\n   };\n \n-  bool isARow_ = resultEncoding.getMMAv1IsRow();\n-  bool isAVec4 = resultEncoding.getMMAv1IsVec4();\n   unsigned numM = resultEncoding.getMMAv1NumOuter(shape);\n-  for (unsigned k = 0; k < NK; k += 4)\n+  for (int k = 0; k < NK; k += 4)\n     for (unsigned m = 0; m < numM / 2; ++m)\n       if (!has.count({m, k}))\n         loadA(m, k);\n@@ -225,7 +219,6 @@ static Value loadB(Value tensor, const SharedMemoryObject &smemObj,\n   // smem\n   auto strides = smemObj.strides;\n \n-  auto *ctx = rewriter.getContext();\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n   auto sharedLayout = tensorTy.getEncoding().cast<SharedEncodingAttr>();\n \n@@ -316,10 +309,10 @@ static Value loadB(Value tensor, const SharedMemoryObject &smemObj,\n   };\n \n   bool isBRow_ = resultEncoding.getMMAv1IsRow();\n+  (void)isBRow_;\n   assert(isBRow == isBRow_ && \"B need smem isRow\");\n-  bool isBVec4 = resultEncoding.getMMAv1IsVec4();\n   unsigned numN = resultEncoding.getMMAv1NumOuter(shape);\n-  for (unsigned k = 0; k < NK; k += 4)\n+  for (int k = 0; k < NK; k += 4)\n     for (unsigned n = 0; n < numN / 2; ++n) {\n       if (!hbs.count({n, k}))\n         loadB(n, k);\n@@ -400,15 +393,13 @@ SmallVector<CoordTy> getMNCoords(Value thread,\n \n   // quad pair offset\n   Value offLaneM = add(offPairM, offQuadM);\n-  Value offLaneN = add(offPairN, offQuadN);\n   // a, b offset\n   Value offsetAM = add(offWarpM, offLaneM);\n-  Value offsetBN = add(offWarpN, offLaneN);\n   // m indices\n   Value offsetCM = add(and_(lane, _1), offsetAM);\n   SmallVector<Value> idxM;\n   for (unsigned m = 0; m < shape[0]; m += shapePerCTA[0])\n-    for (unsigned mm = 0; mm < rep[0]; ++mm)\n+    for (int mm = 0; mm < rep[0]; ++mm)\n       idxM.push_back(add(offsetCM, i32_val(m + mm * 2)));\n \n   // n indices"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -187,12 +187,10 @@ SmallVector<Value> MMA16816SmemLoader::computeLdsMatOffs(Value warpOff,\n   SmallVector<Value> offs(numPtrs);\n \n   int vecWidth = kWidth;\n-  int threadsPerQuad[2] = {8, 4};\n   int laneWidth = 4;\n   int laneHeight = 8;\n   int quadWidth = laneWidth * vecWidth;\n   int quadHeight = laneHeight;\n-  int numQuadI = 2;\n \n   // outer index base\n   Value iBase = udiv(lane, i32_val(laneWidth));"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/FMA.cpp", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "file_content_changes": "@@ -16,9 +16,9 @@ static ValueTableFMA getValueTableFromStructFMA(\n   ValueTableFMA res;\n   auto elems = typeConverter->unpackLLElements(loc, val, rewriter, type);\n   int index = 0;\n-  for (unsigned k = 0; k < K; ++k) {\n-    for (unsigned m = 0; m < n0; m += shapePerCTA)\n-      for (unsigned mm = 0; mm < sizePerThread; ++mm) {\n+  for (int k = 0; k < K; ++k) {\n+    for (int m = 0; m < n0; m += shapePerCTA)\n+      for (int mm = 0; mm < sizePerThread; ++mm) {\n         res[{m + mm, k}] = elems[index++];\n       }\n   }\n@@ -28,12 +28,10 @@ static ValueTableFMA getValueTableFromStructFMA(\n LogicalResult convertFMADot(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n                             TritonGPUToLLVMTypeConverter *typeConverter,\n                             ConversionPatternRewriter &rewriter) {\n-  auto *ctx = rewriter.getContext();\n   auto loc = op.getLoc();\n \n   auto A = op.getA();\n   auto B = op.getB();\n-  auto C = op.getC();\n   auto D = op.getResult();\n \n   auto aTensorTy = A.getType().cast<RankedTensorType>();\n@@ -78,11 +76,11 @@ LogicalResult convertFMADot(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n   SmallVector<Value> ret = cc;\n   bool isCRow = order[0] == 1;\n \n-  for (unsigned k = 0; k < K; k++) {\n-    for (unsigned m = 0; m < M; m += mShapePerCTA)\n-      for (unsigned n = 0; n < N; n += nShapePerCTA)\n-        for (unsigned mm = 0; mm < mSizePerThread; ++mm)\n-          for (unsigned nn = 0; nn < nSizePerThread; ++nn) {\n+  for (int k = 0; k < K; k++) {\n+    for (int m = 0; m < M; m += mShapePerCTA)\n+      for (int n = 0; n < N; n += nShapePerCTA)\n+        for (int mm = 0; mm < mSizePerThread; ++mm)\n+          for (int nn = 0; nn < nSizePerThread; ++nn) {\n             int mIdx = m / mShapePerCTA * mSizePerThread + mm;\n             int nIdx = n / nShapePerCTA * nSizePerThread + nn;\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/MMAv1.cpp", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "file_content_changes": "@@ -24,7 +24,7 @@ extractLoadedOperand(Value llStruct, int NK,\n   SmallVector<Value> elems = typeConverter->unpackLLElements(\n       llStruct.getLoc(), llStruct, rewriter, type);\n \n-  int offset = 0;\n+  size_t offset = 0;\n   for (int i = 0; offset < elems.size(); ++i) {\n     for (int k = 0; k < NK; k += 4) {\n       rcds[{i, k}] = std::make_pair(elems[offset], elems[offset + 1]);\n@@ -38,7 +38,6 @@ extractLoadedOperand(Value llStruct, int NK,\n LogicalResult convertMMA884(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n                             TritonGPUToLLVMTypeConverter *typeConverter,\n                             ConversionPatternRewriter &rewriter) {\n-  auto *ctx = op.getContext();\n   auto loc = op.getLoc();\n \n   Value A = op.getA();\n@@ -67,6 +66,10 @@ LogicalResult convertMMA884(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n   bool isBRow = BLayout.getMMAv1IsRow();\n   auto [isARow_, isBRow_, isAVec4_, isBVec4_, _] =\n       mmaLayout.decodeVoltaLayoutStates();\n+  (void)isARow_;\n+  (void)isBRow_;\n+  (void)isAVec4_;\n+  (void)isBVec4_;\n   assert(isARow == isARow_);\n   assert(isBRow == isBRow_);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/MMAv2.cpp", "status": "modified", "additions": 7, "deletions": 12, "changes": 19, "file_content_changes": "@@ -21,6 +21,7 @@ Value loadC(Value tensor, Value llTensor,\n   // Load a normal C tensor with mma layout, that should be a\n   // LLVM::struct with fcSize elements.\n   auto structTy = llTensor.getType().cast<LLVM::LLVMStructType>();\n+  (void)structTy;\n   assert(structTy.getBody().size() == fcSize &&\n          \"DotOp's $c operand should pass the same number of values as $d in \"\n          \"mma layout.\");\n@@ -34,7 +35,7 @@ Value loadC(Value tensor, Value llTensor,\n     auto cElemTy = tensorTy.getElementType();\n     int numCPackedElem = 4 / numMmaRets;\n     Type cPackTy = vec_ty(cElemTy, numCPackedElem);\n-    for (int i = 0; i < fcSize; i += numCPackedElem) {\n+    for (size_t i = 0; i < fcSize; i += numCPackedElem) {\n       Value pack = rewriter.create<LLVM::UndefOp>(loc, cPackTy);\n       for (int j = 0; j < numCPackedElem; ++j) {\n         pack = insert_element(\n@@ -172,7 +173,6 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n \n   SmallVector<int64_t> aShape(aTensorTy.getShape().begin(),\n                               aTensorTy.getShape().end());\n-  auto dShape = dTensorTy.getShape();\n   int bitwidth = aTensorTy.getElementType().getIntOrFloatBitWidth();\n   auto repA =\n       aTensorTy.getEncoding().cast<DotOperandEncodingAttr>().getMMAv2Rep(\n@@ -214,7 +214,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n     auto bArgs =\n         builder.newListOperand({{hb[{n, k}], \"r\"}, {hb[{n, k + 1}], \"r\"}});\n     auto cArgs = builder.newListOperand();\n-    for (int i = 0; i < numMmaRets; ++i) {\n+    for (unsigned i = 0; i < numMmaRets; ++i) {\n       cArgs->listAppend(builder.newOperand(\n           fc[(m * colsPerThread + 4 * n) / numCPackedElem + i],\n           std::to_string(i)));\n@@ -226,7 +226,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n         builder.launch(rewriter, loc, getMmaRetType(mmaType, op.getContext()));\n \n     Type elemTy = mmaOut.getType().cast<LLVM::LLVMStructType>().getBody()[0];\n-    for (int i = 0; i < numMmaRets; ++i) {\n+    for (unsigned i = 0; i < numMmaRets; ++i) {\n       fc[(m * colsPerThread + 4 * n) / numCPackedElem + i] =\n           extract_val(elemTy, mmaOut, i);\n     }\n@@ -243,7 +243,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   Type structTy = LLVM::LLVMStructType::getLiteral(\n       ctx, SmallVector<Type>(fc.size() * numCPackedElem, resElemTy));\n   SmallVector<Value> results(fc.size() * numCPackedElem);\n-  for (int i = 0; i < fc.size(); ++i) {\n+  for (size_t i = 0; i < fc.size(); ++i) {\n     for (int j = 0; j < numCPackedElem; ++j) {\n       results[i * numCPackedElem + j] =\n           numCPackedElem > 1\n@@ -262,20 +262,15 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n LogicalResult convertMMA16816(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n                               TritonGPUToLLVMTypeConverter *typeConverter,\n                               ConversionPatternRewriter &rewriter) {\n-  auto loc = op.getLoc();\n-  auto mmaLayout = op.getResult()\n-                       .getType()\n-                       .cast<RankedTensorType>()\n-                       .getEncoding()\n-                       .cast<MmaEncodingAttr>();\n-\n   Value A = op.getA();\n   Value B = op.getB();\n   Value C = op.getC();\n \n   auto ATensorTy = A.getType().cast<RankedTensorType>();\n   auto BTensorTy = B.getType().cast<RankedTensorType>();\n \n+  (void)ATensorTy;\n+  (void)BTensorTy;\n   assert(ATensorTy.getEncoding().isa<DotOperandEncodingAttr>() &&\n          BTensorTy.getEncoding().isa<DotOperandEncodingAttr>() &&\n          \"Both $a and %b should be DotOperand layout.\");"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "file_content_changes": "@@ -14,12 +14,12 @@ static SmallVector<Value> reorderValues(const SmallVector<Value> &values,\n       dyn_cast<triton::gpu::DotOperandEncodingAttr>(inTensorTy.getEncoding());\n   auto ouEncoding =\n       dyn_cast<triton::gpu::DotOperandEncodingAttr>(ouTensorTy.getEncoding());\n+  (void)ouEncoding;\n   assert(inEncoding == ouEncoding);\n   if (!inEncoding)\n     return values;\n   size_t inBitWidth = inTensorTy.getElementType().getIntOrFloatBitWidth();\n   size_t ouBitWidth = ouTensorTy.getElementType().getIntOrFloatBitWidth();\n-  auto ouEltTy = ouTensorTy.getElementType();\n   if (inBitWidth == ouBitWidth)\n     return values;\n   if (inBitWidth == 16 && ouBitWidth == 32) {\n@@ -98,7 +98,7 @@ inline SmallVector<Value> unpackI32(const SmallVector<Value> &inValues,\n     auto eltType = typeConverter->convertType(tensorTy.getElementType());\n     auto vecType = vec_ty(eltType, 32 / eltType.getIntOrFloatBitWidth());\n     auto vec = bitcast(v, vecType);\n-    for (int i = 0; i < 32 / eltType.getIntOrFloatBitWidth(); i++) {\n+    for (unsigned i = 0; i < 32 / eltType.getIntOrFloatBitWidth(); i++) {\n       outValues.push_back(extract_element(vec, i32_val(i)));\n     }\n   }\n@@ -119,7 +119,7 @@ inline SmallVector<Value> packI32(const SmallVector<Value> &inValues,\n   auto eltType = typeConverter->convertType(tensorTy.getElementType());\n   int vecWidth = 32 / eltType.getIntOrFloatBitWidth();\n   auto vecType = vec_ty(eltType, vecWidth);\n-  for (int i = 0; i < inValues.size(); i += vecWidth) {\n+  for (size_t i = 0; i < inValues.size(); i += vecWidth) {\n     Value vec = undef(vecType);\n     for (int j = 0; j < vecWidth; j++) {\n       vec = insert_element(vec, inValues[i + j], i32_val(j));\n@@ -625,7 +625,6 @@ struct FpToFpOpConversion\n     auto F16TyID = TypeID::get<mlir::Float16Type>();\n     auto BF16TyID = TypeID::get<mlir::BFloat16Type>();\n     auto F32TyID = TypeID::get<mlir::Float32Type>();\n-    auto F64TyID = TypeID::get<mlir::Float64Type>();\n     static DenseMap<std::pair<TypeID, TypeID>, ConvertorT> convertorMap = {\n         // F8 -> F16\n         {{F8E4M3TyID, F16TyID}, convertFp8E4M3x4ToFp16x4},\n@@ -727,9 +726,9 @@ class ElementwiseOpConversionBase\n     if (allOperands.size() == 0)\n       allOperands.push_back({});\n     for (const SmallVector<Value> &operands : allOperands) {\n+      auto thisPtr = static_cast<const ConcreteT *>(this);\n       Value curr =\n-          ((ConcreteT *)(this))\n-              ->createDestOp(op, adaptor, rewriter, elemTy, operands, loc);\n+          thisPtr->createDestOp(op, adaptor, rewriter, elemTy, operands, loc);\n       if (!bool(curr))\n         return failure();\n       resultVals.push_back(curr);\n@@ -1083,6 +1082,7 @@ struct ExtFOpConversion\n     auto inElemTy = getElementType(op.getIn());\n     if (inElemTy.isBF16()) {\n       auto outElemTy = getElementType(op.getOut());\n+      (void)outElemTy;\n       assert(outElemTy.isF32() && \"unsupported conversion\");\n       return FpToFpOpConversion::convertBf16ToFp32(loc, rewriter, operands[0]);\n     } else {\n@@ -1104,6 +1104,7 @@ struct TruncFOpConversion\n     auto outElemTy = getElementType(op.getOut());\n     if (outElemTy.isBF16()) {\n       auto inElemTy = getElementType(op.getIn());\n+      (void)inElemTy;\n       assert(inElemTy.isF32() && \"unsupported conversion\");\n       return FpToFpOpConversion::convertFp32ToBf16(loc, rewriter, operands[0]);\n     } else {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 14, "deletions": 28, "changes": 42, "file_content_changes": "@@ -124,6 +124,8 @@ struct LoadOpConversion\n       const size_t nWords = std::max<size_t>(1, totalWidth / width);\n       const size_t wordNElems = width / valueElemNBits;\n       const size_t movWidth = width < 16 ? 16 : width;\n+      (void)wordNElems;\n+      (void)numVecs;\n       assert(wordNElems * nWords * numVecs == numElems);\n \n       // TODO(Superjomn) Add cache policy fields to StoreOp.\n@@ -313,6 +315,7 @@ struct StoreOpConversion\n       const size_t width = std::min(totalWidth, maxWordWidth);\n       const size_t nWords = std::max<size_t>(1, totalWidth / width);\n       const size_t wordNElems = width / valueElemNBits;\n+      (void)numVecs;\n       assert(wordNElems * nWords * numVecs == elemsPerThread);\n \n       // TODO(Superjomn) Add cache policy fields to StoreOp.\n@@ -404,7 +407,6 @@ struct AtomicCASOpConversion\n     Type valueElemTy =\n         TensorTy ? getTypeConverter()->convertType(TensorTy.getElementType())\n                  : valueTy;\n-    auto valueElemNBits = valueElemTy.getIntOrFloatBitWidth();\n     Value mask = getMask(valueTy, rewriter, loc);\n     PTXBuilder ptxBuilderMemfence;\n     auto memfence = ptxBuilderMemfence.create<PTXInstr>(\"membar\")->o(\"gl\");\n@@ -492,21 +494,19 @@ struct AtomicRMWOpConversion\n     auto elemsPerThread = getTotalElemsPerThread(val.getType());\n     // vec = 1, numElements = 1 for scalar\n     auto vec = getVectorSize(ptr);\n-    int numElems = 1;\n     // tensor\n     if (tensorTy) {\n       auto valTy = val.getType().cast<RankedTensorType>();\n       vec = std::min<unsigned>(vec, valTy.getElementType().isF16() ? 2 : 1);\n-      // mask\n-      numElems = tensorTy.getNumElements();\n     }\n+    // mask\n     Value mask = getMask(valueTy, rewriter, loc);\n \n     auto vecTy = vec_ty(valueElemTy, vec);\n     SmallVector<Value> resultVals(elemsPerThread);\n     for (size_t i = 0; i < elemsPerThread; i += vec) {\n       Value rmwVal = undef(vecTy);\n-      for (int ii = 0; ii < vec; ++ii) {\n+      for (unsigned ii = 0; ii < vec; ++ii) {\n         Value iiVal = createIndexAttrConstant(\n             rewriter, loc, getTypeConverter()->getIndexType(), ii);\n         rmwVal = insert_element(vecTy, rmwVal, valElements[i + ii], iiVal);\n@@ -570,7 +570,7 @@ struct AtomicRMWOpConversion\n         atom(dstOpr, ptrOpr, valOpr).predicate(rmwMask);\n         auto retType = vec == 1 ? valueElemTy : vecTy;\n         auto ret = ptxBuilderAtomicRMW.launch(rewriter, loc, retType);\n-        for (int ii = 0; ii < vec; ++ii) {\n+        for (unsigned ii = 0; ii < vec; ++ii) {\n           resultVals[i + ii] =\n               vec == 1 ? ret : extract_element(valueElemTy, ret, i32_val(ii));\n         }\n@@ -623,17 +623,19 @@ struct InsertSliceOpConversion\n     Value res = op.getResult();\n     auto funcOp = op->getParentOfType<FunctionOpInterface>();\n     auto *funcAllocation = allocation->getFuncData(funcOp);\n+    (void)res;\n+    (void)funcAllocation;\n     assert(funcAllocation->getBufferId(res) == Allocation::InvalidBufferId &&\n            \"Only support in-place insert_slice for now\");\n \n     auto srcTy = src.getType().dyn_cast<RankedTensorType>();\n     auto srcLayout = srcTy.getEncoding().dyn_cast<BlockedEncodingAttr>();\n-    auto srcShape = srcTy.getShape();\n     assert(srcLayout && \"Unexpected srcLayout in InsertSliceOpConversion\");\n \n     auto dstTy = dst.getType().dyn_cast<RankedTensorType>();\n     auto dstLayout = dstTy.getEncoding().dyn_cast<SharedEncodingAttr>();\n     auto llDst = adaptor.getDest();\n+    (void)dstLayout;\n     assert(dstLayout && \"Unexpected dstLayout in InsertSliceOpConversion\");\n     assert(op.hasUnitStride() &&\n            \"Only unit stride supported by InsertSliceOpConversion\");\n@@ -644,7 +646,7 @@ struct InsertSliceOpConversion\n     SmallVector<Value, 4> offsets;\n     SmallVector<Value, 4> srcStrides;\n     auto mixedOffsets = op.getMixedOffsets();\n-    for (auto i = 0; i < mixedOffsets.size(); ++i) {\n+    for (size_t i = 0; i < mixedOffsets.size(); ++i) {\n       if (op.isDynamicOffset(i)) {\n         offsets.emplace_back(adaptor.getOffsets()[i]);\n       } else {\n@@ -702,6 +704,8 @@ struct InsertSliceAsyncOpConversion\n     Value other = op.getOther();\n     auto funcOp = op->getParentOfType<FunctionOpInterface>();\n     auto *funcAllocation = allocation->getFuncData(funcOp);\n+    (void)res;\n+    (void)funcAllocation;\n     assert(funcAllocation->getBufferId(res) == Allocation::InvalidBufferId &&\n            \"Only support in-place insert_slice_async for now\");\n \n@@ -711,6 +715,7 @@ struct InsertSliceAsyncOpConversion\n     auto srcBlockedLayout = srcTy.getEncoding().cast<BlockedEncodingAttr>();\n     auto resSharedLayout = resTy.getEncoding().cast<SharedEncodingAttr>();\n     auto srcShape = srcTy.getShape();\n+    (void)srcShape;\n     assert(srcShape.size() == 2 &&\n            \"insert_slice_async: Unexpected rank of %src\");\n \n@@ -731,19 +736,14 @@ struct InsertSliceAsyncOpConversion\n     auto axis = op->getAttrOfType<IntegerAttr>(\"axis\").getInt();\n     SmallVector<Value, 4> offsetVals;\n     SmallVector<Value, 4> srcStrides;\n-    for (auto i = 0; i < dstShape.size(); ++i) {\n+    for (long i = 0; i < static_cast<long>(dstShape.size()); ++i) {\n       if (i == axis) {\n         offsetVals.emplace_back(llIndex);\n       } else {\n         offsetVals.emplace_back(i32_val(0));\n         srcStrides.emplace_back(smemObj.strides[i]);\n       }\n     }\n-    // Compute the offset based on the original dimensions of the shared\n-    // memory object\n-    auto dstOffset = dot(rewriter, loc, offsetVals, smemObj.strides);\n-    auto dstPtrTy = ptr_ty(resElemTy, 3);\n-    Value dstPtrBase = gep(dstPtrTy, smemObj.base, dstOffset);\n \n     // %mask\n     SmallVector<Value> maskElems;\n@@ -772,25 +772,11 @@ struct InsertSliceAsyncOpConversion\n     unsigned outVec = resSharedLayout.getVec();\n     unsigned minVec = std::min(outVec, inVec);\n     unsigned numElems = getTotalElemsPerThread(srcTy);\n-    unsigned perPhase = resSharedLayout.getPerPhase();\n-    unsigned maxPhase = resSharedLayout.getMaxPhase();\n-    auto sizePerThread = srcBlockedLayout.getSizePerThread();\n     auto threadsPerCTA = getThreadsPerCTA(srcBlockedLayout);\n-    auto inOrder = srcBlockedLayout.getOrder();\n     DenseMap<unsigned, Value> sharedPtrs =\n         getSwizzledSharedPtrs(loc, inVec, srcTy, resSharedLayout, resElemTy,\n                               smemObj, rewriter, offsetVals, srcStrides);\n \n-    // If perPhase * maxPhase > threadsPerCTA, we will have elements\n-    // that share the same tile indices. The index calculation will\n-    // be cached.\n-    auto numSwizzleRows = std::max<unsigned>(\n-        (perPhase * maxPhase) / threadsPerCTA[inOrder[1]], 1);\n-    // A sharedLayout encoding has a \"vec\" parameter.\n-    // On the column dimension, if inVec > outVec, it means we have to divide\n-    // single vector read into multiple ones\n-    auto numVecCols = std::max<unsigned>(inVec / outVec, 1);\n-\n     auto srcIndices = emitIndices(loc, rewriter, srcBlockedLayout, srcTy);\n \n     for (unsigned elemIdx = 0; elemIdx < numElems; elemIdx += minVec) {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 1, "deletions": 8, "changes": 9, "file_content_changes": "@@ -89,6 +89,7 @@ struct ReduceOpConversion\n                           std::map<int, Value> &ints, unsigned axis) const {\n     if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n       auto dim = sliceLayout.getDim();\n+      (void)dim;\n       assert(dim != axis && \"Reduction axis cannot be sliced\");\n       auto parentLayout = sliceLayout.getParent();\n       getWriteIndexBasic(rewriter, loc, parentLayout, index, writeIdx, ints,\n@@ -144,17 +145,13 @@ struct ReduceOpConversion\n     // The order of the axes for the the threads within the warp\n     auto srcOrd = triton::gpu::getOrder(srcLayout);\n     auto sizePerThread = triton::gpu::getSizePerThread(srcLayout);\n-    auto srcShape = helper.getSrcShape();\n \n     SmallVector<Type> elemPtrTys(srcTys.size());\n     for (unsigned i = 0; i < op.getNumOperands(); ++i) {\n       auto ty = srcTys[i].getElementType();\n       auto llvmElemTy = getTypeConverter()->convertType(ty);\n       elemPtrTys[i] = LLVM::LLVMPointerType::get(llvmElemTy, 3);\n     }\n-    auto llvmIndexTy = getTypeConverter()->getIndexType();\n-    auto indexPtrTy = LLVM::LLVMPointerType::get(llvmIndexTy, 3);\n-\n     auto smemShape = helper.getScratchConfigBasic();\n     unsigned elems = product<unsigned>(smemShape);\n \n@@ -293,7 +290,6 @@ struct ReduceOpConversion\n       }\n     }\n \n-    auto parentBlock = op.getOperation()->getBlock();\n     rewriter.replaceOp(op, results);\n     return success();\n   }\n@@ -312,16 +308,13 @@ struct ReduceOpConversion\n       assert(false && \"Unexpected srcLayout in ReduceOpConversion\");\n     }\n     auto srcOrd = triton::gpu::getOrder(srcLayout);\n-    auto srcShape = helper.getSrcShape();\n \n     SmallVector<Type> elemPtrTys(srcTys.size());\n     for (unsigned i = 0; i < op.getNumOperands(); ++i) {\n       auto ty = srcTys[i].getElementType();\n       auto llvmElemTy = getTypeConverter()->convertType(ty);\n       elemPtrTys[i] = LLVM::LLVMPointerType::get(llvmElemTy, 3);\n     }\n-    auto llvmIndexTy = getTypeConverter()->getIndexType();\n-    auto indexPtrTy = LLVM::LLVMPointerType::get(llvmIndexTy, 3);\n \n     auto smemShapes = helper.getScratchConfigsFast();\n     unsigned elems = product<unsigned>(smemShapes[0]);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 6, "deletions": 13, "changes": 19, "file_content_changes": "@@ -59,9 +59,8 @@ struct BroadcastOpConversion\n     auto srcLayout = srcTy.getEncoding();\n     auto resultLayout = resultTy.getEncoding();\n     auto srcShape = srcTy.getShape();\n-    auto resultShape = resultTy.getShape();\n     unsigned rank = srcTy.getRank();\n-\n+    (void)rank;\n     assert(rank == resultTy.getRank());\n     auto order = triton::gpu::getOrder(srcLayout);\n     auto srcOffsets = emitOffsetForLayout(srcLayout, srcTy);\n@@ -193,8 +192,6 @@ struct PrintOpConversion\n     Type int8Ptr = ptr_ty(i8_ty);\n \n     auto *ctx = rewriter.getContext();\n-    auto moduleOp =\n-        rewriter.getBlock()->getParent()->getParentOfType<ModuleOp>();\n     auto funcOp = getVprintfDeclaration(rewriter);\n     auto loc = UnknownLoc::get(ctx);\n \n@@ -247,7 +244,6 @@ struct AssertOpConversion\n   matchAndRewrite(triton::AssertOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     auto loc = op.getLoc();\n-    auto ctx = rewriter.getContext();\n     auto elems = getTypeConverter()->unpackLLElements(\n         loc, adaptor.getCondition(), rewriter, op.getCondition().getType());\n     auto elemTy = elems[0].getType();\n@@ -275,7 +271,6 @@ struct AssertOpConversion\n                        StringRef file, StringRef func, int line,\n                        ConversionPatternRewriter &rewriter) {\n     ConversionPatternRewriter::InsertionGuard guard(rewriter);\n-    auto ctx = rewriter.getContext();\n     auto loc = op->getLoc();\n \n     // #block1\n@@ -289,8 +284,6 @@ struct AssertOpConversion\n     rewriter.setInsertionPointToStart(ifBlock);\n \n     auto funcOp = getAssertfailDeclaration(rewriter);\n-    auto moduleOp =\n-        rewriter.getBlock()->getParent()->getParentOfType<ModuleOp>();\n     Value messageString =\n         LLVM::addStringToModule(loc, rewriter, \"assertMessage_\", message);\n     Value fileString =\n@@ -302,7 +295,7 @@ struct AssertOpConversion\n \n     SmallVector<Value> operands = {messageString, fileString, lineNumber,\n                                    funcString, charSize};\n-    auto ret = call(funcOp, operands);\n+    call(funcOp, operands);\n \n     // Split a block after the call.\n     Block *thenBlock = rewriter.splitBlock(ifBlock, op->getIterator());\n@@ -352,7 +345,6 @@ struct MakeRangeOpConversion\n                   ConversionPatternRewriter &rewriter) const override {\n     Location loc = op->getLoc();\n     auto rankedTy = op.getResult().getType().cast<RankedTensorType>();\n-    auto shape = rankedTy.getShape();\n     auto layout = rankedTy.getEncoding();\n \n     auto elemTy = rankedTy.getElementType();\n@@ -503,6 +495,7 @@ struct ExtractSliceOpConversion\n     Location loc = op->getLoc();\n     auto srcTy = op.getSource().getType().dyn_cast<RankedTensorType>();\n     auto srcLayout = srcTy.getEncoding().dyn_cast<SharedEncodingAttr>();\n+    (void)srcLayout;\n     assert(srcLayout && \"Unexpected resultLayout in ExtractSliceOpConversion\");\n     assert(op.hasUnitStride() &&\n            \"Only unit stride supported by ExtractSliceOpConversion\");\n@@ -514,7 +507,7 @@ struct ExtractSliceOpConversion\n     SmallVector<Value, 4> opOffsetVals;\n     SmallVector<Value, 4> offsetVals;\n     auto mixedOffsets = op.getMixedOffsets();\n-    for (auto i = 0; i < mixedOffsets.size(); ++i) {\n+    for (size_t i = 0; i < mixedOffsets.size(); ++i) {\n       if (op.isDynamicOffset(i))\n         opOffsetVals.emplace_back(adaptor.getOffsets()[i]);\n       else\n@@ -527,7 +520,7 @@ struct ExtractSliceOpConversion\n     // newShape = rank_reduce(shape)\n     // Triton only supports static tensor sizes\n     SmallVector<Value, 4> strideVals;\n-    for (auto i = 0; i < op.static_sizes().size(); ++i) {\n+    for (size_t i = 0; i < op.static_sizes().size(); ++i) {\n       if (op.getStaticSize(i) == 1) {\n         offsetVals.erase(offsetVals.begin() + i);\n       } else {\n@@ -599,7 +592,7 @@ void vprintf_array(Value thread, ArrayRef<Value> arr, std::string info,\n                    std::string elem_repr, ConversionPatternRewriter &builder) {\n   std::string fmt = info + \" t-%d \";\n   std::vector<Value> new_arr({thread});\n-  for (int i = 0; i < arr.size(); ++i) {\n+  for (size_t i = 0; i < arr.size(); ++i) {\n     fmt += elem_repr + ((i == arr.size() - 1) ? \"\" : \", \");\n     new_arr.push_back(arr[i]);\n   }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 5, "deletions": 22, "changes": 27, "file_content_changes": "@@ -158,7 +158,6 @@ struct CacheKeyDenseMapInfo {\n         tombstone);\n   }\n   static unsigned getHashValue(IndexCacheKeyT key) {\n-    auto shape = key.second.getShape();\n     return llvm::hash_combine(mlir::hash_value(key.first),\n                               mlir::hash_value(key.second));\n   }\n@@ -218,7 +217,6 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n   }\n \n   Value getThreadId(ConversionPatternRewriter &rewriter, Location loc) const {\n-    auto llvmIndexTy = this->getTypeConverter()->getIndexType();\n     auto tid = rewriter.create<::mlir::gpu::ThreadIdOp>(\n         loc, rewriter.getIndexType(), ::mlir::gpu::Dimension::x);\n     return rewriter.create<arith::TruncIOp>(loc, i32_ty, tid);\n@@ -286,7 +284,6 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     Value dstPtrBase = gep(dstPtrTy, smemObj.base, dstOffset);\n \n     auto srcEncoding = srcTy.getEncoding();\n-    auto srcShape = srcTy.getShape();\n     unsigned numElems = triton::gpu::getTotalElemsPerThread(srcTy);\n     // swizzling params as described in TritonGPUAttrDefs.td\n     unsigned outVec = resSharedLayout.getVec();\n@@ -367,6 +364,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n                                 ConversionPatternRewriter &rewriter) const {\n     auto srcTy = src.getType().cast<RankedTensorType>();\n     auto srcShape = srcTy.getShape();\n+    (void)srcShape;\n     assert(srcShape.size() == 2 &&\n            \"Unexpected rank of storeDistributedToShared\");\n     auto dstTy = dst.getType().cast<RankedTensorType>();\n@@ -386,16 +384,11 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n             : 1;\n     unsigned outVec = dstSharedLayout.getVec();\n     unsigned minVec = std::min(outVec, inVec);\n-    unsigned perPhase = dstSharedLayout.getPerPhase();\n-    unsigned maxPhase = dstSharedLayout.getMaxPhase();\n     unsigned numElems = triton::gpu::getTotalElemsPerThread(srcTy);\n     assert(numElems == srcIndices.size());\n     auto inVals =\n         getTypeConverter()->unpackLLElements(loc, llSrc, rewriter, srcTy);\n     auto wordTy = vec_ty(elemTy, minVec);\n-    auto elemPtrTy = ptr_ty(elemTy);\n-    Value outVecVal = i32_val(outVec);\n-    Value minVecVal = i32_val(minVec);\n     Value word;\n \n     SmallVector<Value> srcStrides = {dstStrides[0], dstStrides[1]};\n@@ -761,12 +754,8 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n   emitBaseIndexForMmaLayoutV1(Location loc, ConversionPatternRewriter &rewriter,\n                               const MmaEncodingAttr &mmaLayout,\n                               RankedTensorType type) const {\n-    auto shape = type.getShape();\n-\n     auto wpt = mmaLayout.getWarpsPerCTA();\n     static constexpr std::array<int, 3> fpw{{2, 2, 1}};\n-    auto [isARow, isBRow, isAVec4, isBVec4, _] =\n-        mmaLayout.decodeVoltaLayoutStates();\n \n     Value thread = getThreadId(rewriter, loc);\n     auto *ctx = thread.getContext();\n@@ -818,10 +807,8 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     offQuadN = mul(offQuadN, i32_val(rep[1] / 2));\n     // quad pair offset\n     Value offLaneM = add(offPairM, offQuadM);\n-    Value offLaneN = add(offPairN, offQuadN);\n-    // a, b offset\n+    // a offset\n     Value offsetAM = add(offWarpM, offLaneM);\n-    Value offsetBN = add(offWarpN, offLaneN);\n     // m indices\n     Value offsetCM = add(and_(lane, _1), offsetAM);\n     // n indices\n@@ -834,9 +821,6 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n                            RankedTensorType type) const {\n     auto shape = type.getShape();\n \n-    auto [isARow, isBRow, isAVec4, isBVec4, _] =\n-        mmaLayout.decodeVoltaLayoutStates();\n-\n     // TODO: seems like the apttern below to get `rep`/`spw` appears quite often\n     // A info\n     auto aEncoding =\n@@ -857,7 +841,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n \n     SmallVector<unsigned> idxM;\n     for (unsigned m = 0; m < shape[0]; m += shapePerCTA[0])\n-      for (unsigned mm = 0; mm < rep[0]; ++mm)\n+      for (int mm = 0; mm < rep[0]; ++mm)\n         idxM.push_back(m + mm * 2);\n \n     SmallVector<unsigned> idxN;\n@@ -1008,9 +992,8 @@ class ConvertTritonGPUOpToLLVMPattern\n \n protected:\n   TritonGPUToLLVMTypeConverter *getTypeConverter() const {\n-    LLVMTypeConverter *ret =\n-        ((ConvertTritonGPUOpToLLVMPatternBase *)this)->getTypeConverter();\n-    return (TritonGPUToLLVMTypeConverter *)ret;\n+    return static_cast<const ConvertTritonGPUOpToLLVMPatternBase *>(this)\n+        ->getTypeConverter();\n   }\n };\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "file_content_changes": "@@ -103,8 +103,8 @@ struct ReturnOpConversion : public ConvertOpToLLVMPattern<triton::ReturnOp> {\n struct FuncOpConversion : public FuncOpConversionBase {\n   FuncOpConversion(LLVMTypeConverter &converter, int numWarps,\n                    ModuleAllocation &allocation, PatternBenefit benefit)\n-      : FuncOpConversionBase(converter, benefit), allocation(allocation),\n-        numWarps(numWarps) {}\n+      : FuncOpConversionBase(converter, benefit), numWarps(numWarps),\n+        allocation(allocation) {}\n \n   triton::FuncOp amendFuncOp(triton::FuncOp funcOp,\n                              ConversionPatternRewriter &rewriter) const {\n@@ -185,7 +185,7 @@ struct CallOpConversion : public ConvertOpToLLVMPattern<triton::CallOp> {\n   CallOpConversion(LLVMTypeConverter &converter, int numWarps,\n                    ModuleAllocation &allocation, PatternBenefit benefit)\n       : ConvertOpToLLVMPattern<triton::CallOp>(converter, benefit),\n-        allocation(allocation), numWarps(numWarps) {}\n+        numWarps(numWarps), allocation(allocation) {}\n \n   LogicalResult\n   matchAndRewrite(triton::CallOp callOp,\n@@ -250,6 +250,7 @@ struct CallOpConversion : public ConvertOpToLLVMPattern<triton::CallOp> {\n   SmallVector<Value>\n   getCallOpResults(triton::CallOp callOp, LLVM::CallOp newCallOp,\n                    ConversionPatternRewriter &rewriter) const {\n+    (void)numWarps;\n     auto numResults = callOp.getNumResults();\n     SmallVector<Value> results;\n     if (numResults < 2) {\n@@ -556,7 +557,7 @@ class ConvertTritonGPUToLLVM\n       auto sizes = SmallVector<OpFoldResult>(dstTy.getRank(), intAttr(1));\n       auto strides = SmallVector<OpFoldResult>(dstTy.getRank(), intAttr(1));\n       offsets[axis] = insertSliceAsyncOp.getIndex();\n-      for (size_t i = 0; i < dstTy.getRank(); i++) {\n+      for (int64_t i = 0; i < dstTy.getRank(); i++) {\n         if (i != axis)\n           sizes[i] = intAttr(dstTy.getShape()[i]);\n       }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -106,6 +106,7 @@ Type TritonGPUToLLVMTypeConverter::getElementTypeForStruct(\n     return elemTy;\n   if (mmaParent.isAmpere()) {\n     int bitwidth = elemTy.getIntOrFloatBitWidth();\n+    (void)bitwidth;\n     assert(bitwidth <= 32);\n     return IntegerType::get(ctx, 32);\n   } else {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/Utility.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -241,7 +241,7 @@ struct SharedMemoryObject {\n   }\n \n   Value getCSwizzleOffset(int order) const {\n-    assert(order >= 0 && order < strides.size());\n+    assert(order >= 0 && order < static_cast<int>(strides.size()));\n     return offsets[order];\n   }\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/ViewOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -29,8 +29,9 @@ struct SplatOpConversion\n     return typeConverter->packLLElements(loc, elems, rewriter, resType);\n   }\n \n-  LogicalResult matchAndRewrite(triton::SplatOp op, OpAdaptor adaptor,\n-                                ConversionPatternRewriter &rewriter) const {\n+  LogicalResult\n+  matchAndRewrite(triton::SplatOp op, OpAdaptor adaptor,\n+                  ConversionPatternRewriter &rewriter) const override {\n     auto loc = op->getLoc();\n     auto src = adaptor.getSrc();\n     auto llStruct = convertSplatLikeOp(src.getType(), op.getType(), src,"}, {"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "file_content_changes": "@@ -554,7 +554,6 @@ class TritonCallOpPattern : public OpConversionPattern<triton::CallOp> {\n   LogicalResult\n   matchAndRewrite(triton::CallOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    auto converter = getTypeConverter();\n     auto newOp = rewriter.replaceOpWithNewOp<triton::CallOp>(\n         op, op.getCallee(), op.getResultTypes(), adaptor.getOperands());\n     addNamedAttrs(newOp, adaptor.getAttributes());\n@@ -569,9 +568,7 @@ class TritonReturnOpPattern : public OpConversionPattern<ReturnOp> {\n   LogicalResult\n   matchAndRewrite(ReturnOp op, ReturnOp::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    auto converter = getTypeConverter();\n-    auto newOp =\n-        rewriter.replaceOpWithNewOp<ReturnOp>(op, adaptor.getOperands());\n+    rewriter.replaceOpWithNewOp<ReturnOp>(op, adaptor.getOperands());\n     return success();\n   }\n };"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -480,7 +480,6 @@ mlir::LogicalResult mlir::triton::ReduceOp::verifyRegions() {\n                                << \" arguments, but given block with \"\n                                << block.getNumArguments() << \" arguments\";\n   }\n-  unsigned i = 0;\n   const auto &blockArgTypes = block.getArgumentTypes();\n   for (unsigned i = 0; i < numArgs; ++i) {\n     const auto &blockArgTy = blockArgTypes[i];"}, {"filename": "lib/Dialect/Triton/Transforms/RewriteTensorPointer.cpp", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "file_content_changes": "@@ -27,8 +27,6 @@ struct RewritedInfo {\n public:\n   RewritedInfo() = default;\n \n-  RewritedInfo(const RewritedInfo &other) = default;\n-\n   RewritedInfo(Value base, const SmallVector<Value> &shape,\n                const SmallVector<Value> &strides,\n                const SmallVector<Value> &offsets,\n@@ -74,7 +72,7 @@ struct RewritedInfo {\n     // Expand dimensions\n     Value expandedResult =\n         builder.create<arith::AddIOp>(loc, splatOffset, i64Range);\n-    for (int j = 0; j < tensorShape.size(); ++j) {\n+    for (size_t j = 0; j < tensorShape.size(); ++j) {\n       if (j == i)\n         continue;\n       expandedResult =\n@@ -208,7 +206,7 @@ class RewriteTensorPointerPass\n                       const SmallVector<Value> &newValues) {\n     assert(index < oldOperands.size());\n     SmallVector<Value> newOperands;\n-    for (int i = 0; i < index; ++i)\n+    for (unsigned i = 0; i < index; ++i)\n       newOperands.push_back(oldOperands[i]);\n     for (auto value : newValues)\n       newOperands.push_back(value);\n@@ -251,7 +249,7 @@ class RewriteTensorPointerPass\n     // Calculate new offsets\n     assert(info.length() == op.getOffsets().size());\n     SmallVector<Value> newOffsets;\n-    for (int i = 0; i < info.length(); ++i) {\n+    for (unsigned int i = 0; i < info.length(); ++i) {\n       Value i64Offset = builder.create<arith::ExtSIOp>(\n           op.getLoc(), builder.getI64Type(), op.getOffsets()[i]);\n       Value newOffset = builder.create<arith::AddIOp>("}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 7, "deletions": 12, "changes": 19, "file_content_changes": "@@ -240,7 +240,7 @@ SmallVector<unsigned> getUniqueContigPerThread(Type type) {\n   SmallVector<unsigned> ret(rank);\n   auto contigPerThread = getContigPerThread(tensorType.getEncoding());\n   assert(contigPerThread.size() == rank && \"Unexpected contigPerThread size\");\n-  for (int d = 0; d < rank; ++d) {\n+  for (unsigned d = 0; d < rank; ++d) {\n     ret[d] = std::min<unsigned>(shape[d], contigPerThread[d]);\n   }\n   return ret;\n@@ -543,9 +543,10 @@ SmallVector<int64_t>\n DotOperandEncodingAttr::getMMAv2Rep(ArrayRef<int64_t> shape,\n                                     int bitwidth) const {\n   auto mmaParent = getParent().cast<MmaEncodingAttr>();\n+  (void)mmaParent;\n+  assert(mmaParent.isAmpere());\n   SmallVector<int> shapePerWarp = {16, 8, 4 * 64 / bitwidth};\n   auto warpsPerCTA = getParent().cast<MmaEncodingAttr>().getWarpsPerCTA();\n-  assert(mmaParent.isAmpere());\n   if (getOpIdx() == 0)\n     return {std::max<int64_t>(1, shape[0] / (shapePerWarp[0] * warpsPerCTA[0])),\n             std::max<int64_t>(1, shape[1] / shapePerWarp[2])};\n@@ -567,8 +568,6 @@ DotOperandEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n                                                         Type eltTy) const {\n   if (auto mmaParent = getParent().dyn_cast<MmaEncodingAttr>()) {\n-    int warpsPerCTAM = mmaParent.getWarpsPerCTA()[0];\n-    int warpsPerCTAN = mmaParent.getWarpsPerCTA()[1];\n     // A100\n     if (mmaParent.isAmpere()) {\n       auto rep = getMMAv2Rep(shape, eltTy.getIntOrFloatBitWidth());\n@@ -584,7 +583,6 @@ unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n       if (getOpIdx() == 0) {\n         int packSizeM = (isRow || isVec4) ? 1 : 2;\n         int repM = 2 * packSizeM;\n-        int spwM = 2 * 4 * repM;\n         int numM = getMMAv1NumOuter(shape);\n         int NK = shape[1];\n         int vec = 2 * repM;\n@@ -600,24 +598,22 @@ unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n               visited.insert({m + 1, k});\n           }\n         };\n-        for (unsigned k = 0; k < NK; k += 4)\n-          for (unsigned m = 0; m < numM / 2; ++m)\n+        for (int k = 0; k < NK; k += 4)\n+          for (int m = 0; m < numM / 2; ++m)\n             if (!visited.count({m, k}))\n               ld(m, k);\n         return visited.size() * 2;\n       }\n       if (getOpIdx() == 1) {\n         int packSizeN = (isRow && !isVec4) ? 2 : 1;\n         int repN = 2 * packSizeN;\n-        int spwN = 2 * 4 * repN;\n         int numN = getMMAv1NumOuter(shape);\n         int vec = 2 * repN;\n \n         int NK = shape[0];\n         // Here we mimic the logic in loadA, the result cannot be calculated\n         // directly.\n         llvm::DenseSet<std::pair<int, int>> visited;\n-        int elemsPerLd = vec > 4 ? 4 : 2;\n         auto ld = [&](int n, int k) {\n           visited.insert({n, k});\n           if (vec > 4) {\n@@ -628,8 +624,8 @@ unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n           }\n         };\n \n-        for (unsigned k = 0; k < NK; k += 4)\n-          for (unsigned n = 0; n < numN / 2; ++n) {\n+        for (int k = 0; k < NK; k += 4)\n+          for (int n = 0; n < numN / 2; ++n) {\n             if (!visited.count({n, k}))\n               ld(n, k);\n           }\n@@ -1251,7 +1247,6 @@ void ExtractSliceOp::build(OpBuilder &b, OperationState &result,\n   dispatchIndexOpFoldResults(offsets, dynamicOffsets, staticOffsets);\n   dispatchIndexOpFoldResults(sizes, dynamicSizes, staticSizes);\n   dispatchIndexOpFoldResults(strides, dynamicStrides, staticStrides);\n-  auto sourceRankedTensorType = source.getType().cast<RankedTensorType>();\n   build(b, result, resultType, source, dynamicOffsets, dynamicSizes,\n         dynamicStrides, b.getDenseI64ArrayAttr(staticOffsets),\n         b.getDenseI64ArrayAttr(staticSizes),"}, {"filename": "lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp", "status": "modified", "additions": 1, "deletions": 25, "changes": 26, "file_content_changes": "@@ -30,17 +30,6 @@ int computeCapabilityToMMAVersion(int computeCapability) {\n   }\n }\n \n-SmallVector<int64_t, 2> mmaVersionToShapePerWarp(int version) {\n-  if (version == 1)\n-    return {16, 16};\n-  else if (version == 2)\n-    return {16, 8};\n-  else {\n-    assert(false && \"version not supported\");\n-    return {0, 0};\n-  }\n-}\n-\n SmallVector<unsigned, 2> warpsPerTileV2(triton::DotOp dotOp,\n                                         const ArrayRef<int64_t> shape,\n                                         int numWarps) {\n@@ -53,14 +42,12 @@ SmallVector<unsigned, 2> warpsPerTileV2(triton::DotOp dotOp,\n \n   SmallVector<unsigned, 2> ret = {1, 1};\n   SmallVector<int64_t, 2> shapePerWarp = {16, 8};\n-  bool changed = false;\n   // TODO (@daadaada): double-check.\n   // original logic in\n   // https://github.com/openai/triton/blob/master/lib/codegen/analysis/layout.cc#L252\n   // seems buggy for shape = [32, 16] ?\n   do {\n-    changed = false;\n-    if (ret[0] * ret[1] >= numWarps)\n+    if (static_cast<int>(ret[0] * ret[1]) >= numWarps)\n       break;\n     if (shape[0] / shapePerWarp[0] / ret[0] >=\n         shape[1] / (shapePerWarp[1] * 2) / ret[1]) {\n@@ -159,17 +146,6 @@ class BlockedToMMA : public mlir::RewritePattern {\n     auto oldAcc = dotOp.getOperand(2);\n     auto newAcc = rewriter.create<triton::gpu::ConvertLayoutOp>(\n         oldAcc.getLoc(), newRetType, oldAcc);\n-    auto oldAOrder = oldAType.getEncoding()\n-                         .cast<triton::gpu::DotOperandEncodingAttr>()\n-                         .getParent()\n-                         .cast<triton::gpu::BlockedEncodingAttr>()\n-                         .getOrder();\n-    auto oldBOrder = oldBType.getEncoding()\n-                         .cast<triton::gpu::DotOperandEncodingAttr>()\n-                         .getParent()\n-                         .cast<triton::gpu::BlockedEncodingAttr>()\n-                         .getOrder();\n-\n     auto newAEncoding = triton::gpu::DotOperandEncodingAttr::get(\n         oldAType.getContext(), 0, newRetType.getEncoding(),\n         oldAType.getElementType());"}, {"filename": "lib/Dialect/TritonGPU/Transforms/OptimizeDotOperands.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -159,7 +159,8 @@ class TritonGPUOptimizeDotOperandsPass\n \n     mlir::PassManager pm(m.getContext());\n     pm.addPass(mlir::createCanonicalizerPass());\n-    auto ret = pm.run(m);\n+    if (pm.run(m).failed())\n+      signalPassFailure();\n \n     mlir::RewritePatternSet patterns(context);\n     patterns.add<ConvertTransConvert>(context);"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -572,7 +572,7 @@ scf::ForOp LoopPipeliner::createNewForOp() {\n     // is modified\n     auto it = std::find(loads.begin(), loads.end(), op.getOperand(0));\n     if (it == loads.end()) {\n-      Operation *newOp = cloneWithInferType(builder, &op, mapping);\n+      cloneWithInferType(builder, &op, mapping);\n       continue;\n     }\n "}, {"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -88,7 +88,7 @@ void Prefetcher::cloneElementwiseOps(Value &ret, const SmallVector<Value> &vals,\n                                      OpBuilder &builder) {\n   IRMapping mapping;\n   mapping.map(vals[0], ret);\n-  for (int i = 1; i < vals.size(); i++) {\n+  for (size_t i = 1; i < vals.size(); i++) {\n     Value v = vals[i];\n     Value curr = builder.clone(*v.getDefiningOp(), mapping)->getResult(0);\n     auto retType = RankedTensorType::get(\n@@ -205,6 +205,7 @@ LogicalResult Prefetcher::initialize() {\n     auto bEnc = bType.getEncoding().cast<triton::gpu::DotOperandEncodingAttr>();\n     int aKWidth = aEnc.getMMAv2kWidth();\n     int bKWidth = bEnc.getMMAv2kWidth();\n+    (void)bKWidth;\n     assert(aKWidth == bKWidth);\n \n     auto kSize = aType.getShape()[1];"}, {"filename": "lib/Dialect/TritonGPU/Transforms/RemoveLayoutConversions.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -208,7 +208,7 @@ void pushConversionForward(triton::gpu::ConvertLayoutOp cvt,\n   }\n   rewriter.setInsertionPoint(op);\n   if (op->getNumResults() == 0) {\n-    Operation *newOp = rewriter.clone(*op, mapping);\n+    rewriter.clone(*op, mapping);\n     rewriter.eraseOp(op);\n     return;\n   }\n@@ -251,7 +251,7 @@ class MoveConvertOutOfIf : public mlir::RewritePattern {\n     }\n \n     IRMapping mapping;\n-    for (size_t i = 0; i < numOps; i++) {\n+    for (int i = 0; i < numOps; i++) {\n       auto thenCvt = dyn_cast_or_null<triton::gpu::ConvertLayoutOp>(\n           thenYield.getOperand(i).getDefiningOp());\n       if (hasElse) {\n@@ -312,7 +312,7 @@ class MoveConvertOutOfIf : public mlir::RewritePattern {\n \n     rewriter.setInsertionPointAfter(newIfOp);\n     SmallVector<Value> newRetValues = newIfOp.getResults();\n-    for (size_t i = 0; i < numOps; i++) {\n+    for (int i = 0; i < numOps; i++) {\n       if (newIfOp.getResult(i).getType() != ifOp.getResult(i).getType()) {\n         newRetValues[i] = rewriter.create<triton::gpu::ConvertLayoutOp>(\n             newIfOp.getLoc(), ifOp.getResult(i).getType(),"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Utility.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -100,7 +100,6 @@ bool expensiveLoadOrStore(Operation *op, Attribute &targetEncoding) {\n       op->getParentOfType<ModuleOp>()->getAttrOfType<IntegerAttr>(\n           \"triton_gpu.num-warps\");\n   if (numWarps) {\n-    int sizePerThread = triton::gpu::getTotalElemsPerThread(ptrType);\n     if (ptrType.getNumElements() < numWarps.getInt() * 32)\n       return false;\n   }"}]