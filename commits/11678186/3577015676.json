[{"filename": "python/triton/ops/blocksparse/softmax.py", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -18,8 +18,8 @@ def num_warps(n):\n \n @triton.jit\n def _blocksparse_softmax_fwd(\n-    Out, A, LUT, R, stride_xz,\n-    extent, stride_zr, stride_hr,  # relative attention\n+    Out, A, stride_xz, LUT,\n+    R, extent, stride_zr, stride_hr,  # relative attention\n     scale, is_causal,\n     ROW_SIZE: tl.constexpr,\n     BLOCK_SIZE: tl.constexpr,\n@@ -164,8 +164,8 @@ def forward(\n         # enqueue kernel\n         out = torch.empty_like(a)\n         _blocksparse_softmax_fwd[grid](\n-            out, a, lut, rel_logits, a.stride(0),\n-            rel_shape[-1], rel_strides[0], rel_strides[1],  # relative attn\n+            out, a, a.stride(0), lut,\n+            rel_logits, rel_shape[-1], rel_strides[0], rel_strides[1],  # relative attn\n             scale,\n             is_causal,\n             BLOCK_SIZE=block,"}]