[{"filename": "lib/Conversion/NVGPUToLLVM/NVGPUToLLVMPass.cpp", "status": "modified", "additions": 128, "deletions": 99, "changes": 227, "file_content_changes": "@@ -21,24 +21,29 @@ using ::mlir::LLVM::getSRegValue;\n \n namespace {\n \n+using Constraint = std::variant<int, std::string>;\n+using OperandsAndConstraints = std::vector<std::pair<mlir::Value, Constraint>>;\n template <typename SourceOp, typename ConcreteT>\n class NVGPUOpPatternBase : public mlir::RewritePattern {\n public:\n   explicit NVGPUOpPatternBase(mlir::MLIRContext *context)\n       : mlir::RewritePattern(SourceOp::getOperationName(), 1, context) {}\n \n-  mlir::Value convertToType(mlir::Value val, std::string constraint,\n+  mlir::Value convertToType(mlir::Value val, Constraint constraint,\n                             Location &loc,\n                             mlir::PatternRewriter &rewriter) const {\n     if (val.getType().isa<PointerType>()) {\n-      if (constraint == \"ptr\") {\n-        return val;\n-      } else if (constraint == \"r\") {\n-        return ptrtoint(i32_ty, val);\n-      } else if (constraint == \"l\") {\n-        return ptrtoint(i64_ty, val);\n-      } else {\n-        assert(false && \"Unsupported type conversion\");\n+      if (std::holds_alternative<std::string>(constraint)) {\n+        auto constraintStr = std::get<std::string>(constraint);\n+        if (constraintStr == \"ptr\") {\n+          return val;\n+        } else if (constraintStr == \"r\") {\n+          return ptrtoint(i32_ty, val);\n+        } else if (constraintStr == \"l\") {\n+          return ptrtoint(i64_ty, val);\n+        } else {\n+          assert(false && \"Unsupported type conversion\");\n+        }\n       }\n     }\n     return val;\n@@ -54,16 +59,47 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n     return ptxOutputs;\n   }\n \n-  SmallVector<PTXBuilder::Operand *> getPtxOperands(\n-      std::vector<std::pair<mlir::Value, std::string>> &operandsAndConstraints,\n-      PTXBuilder &ptxBuilder, Location &loc,\n-      mlir::PatternRewriter &rewriter) const {\n-    SmallVector<PTXBuilder::Operand *> ptxOperands;\n+  OperandsAndConstraints\n+  unpackOperands(OperandsAndConstraints &operandsAndConstraints,\n+                 PTXBuilder &ptxBuilder, Location &loc,\n+                 mlir::PatternRewriter &rewriter) const {\n+    OperandsAndConstraints unpackedOperands;\n     for (auto &[operand, constraint] : operandsAndConstraints) {\n+      auto llvmStruct = llvm::dyn_cast<LLVM::LLVMStructType>(operand.getType());\n+      if (llvmStruct) {\n+        for (unsigned i = 0; i < llvmStruct.getBody().size(); i++) {\n+          if (std::holds_alternative<int>(constraint)) {\n+            auto constraintInt = std::get<int>(constraint);\n+            unpackedOperands.push_back(\n+                {extract_val(llvmStruct.getBody()[i], operand, i),\n+                 constraintInt + i});\n+          }\n+        }\n+      } else {\n+        unpackedOperands.push_back({operand, constraint});\n+      }\n+    }\n+    return unpackedOperands;\n+  }\n+\n+  SmallVector<PTXBuilder::Operand *>\n+  getPtxOperands(OperandsAndConstraints &operandsAndConstraints,\n+                 PTXBuilder &ptxBuilder, Location &loc,\n+                 mlir::PatternRewriter &rewriter) const {\n+    SmallVector<PTXBuilder::Operand *> ptxOperands;\n+    auto unpackedOperandsAndConstraints =\n+        unpackOperands(operandsAndConstraints, ptxBuilder, loc, rewriter);\n+    for (auto &[operand, constraint] : unpackedOperandsAndConstraints) {\n       auto convertedOperand = convertToType(operand, constraint, loc, rewriter);\n-      auto *ptxOperand =\n-          ptxBuilder.newAddrOperand(convertedOperand, constraint);\n-      ptxOperands.push_back(ptxOperand);\n+      if (std::holds_alternative<int>(constraint)) {\n+        auto *ptxOperand = ptxBuilder.newOperand(\n+            convertedOperand, std::to_string(std::get<int>(constraint)));\n+        ptxOperands.push_back(ptxOperand);\n+      } else {\n+        auto *ptxOperand = ptxBuilder.newOperand(\n+            convertedOperand, std::get<std::string>(constraint));\n+        ptxOperands.push_back(ptxOperand);\n+      }\n     }\n     return ptxOperands;\n   }\n@@ -72,8 +108,7 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n     return {};\n   }\n \n-  virtual std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndConstraints(SourceOp op) const {\n+  virtual OperandsAndConstraints getOperandsAndConstraints(SourceOp op) const {\n     return {};\n   }\n \n@@ -315,9 +350,9 @@ class StoreMatrixOpPattern\n   using Base = NVGPUOpPatternBase<ttn::StoreMatrixOp, StoreMatrixOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::StoreMatrixOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     auto addr = op.getAddr();\n     auto datas = op.getDatas();\n     operandsAndTypes.push_back({addr, \"r\"});\n@@ -354,9 +389,9 @@ class MBarrierInitOpPattern\n   using Base = NVGPUOpPatternBase<ttn::MBarrierInitOp, MBarrierInitOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::MBarrierInitOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     Value mbarrier = op.getMbarrier();\n     Value pred = op.getPred();\n     operandsAndTypes.push_back({mbarrier, \"r\"});\n@@ -380,9 +415,9 @@ class MBarrierArriveOpPattern\n       NVGPUOpPatternBase<ttn::MBarrierArriveOp, MBarrierArriveOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::MBarrierArriveOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     Value mbarrier = op.getMbarrier();\n     Value pred = op.getPred();\n     Value ctaId = op.getCtaId();\n@@ -447,9 +482,9 @@ class MBarrierWaitOpPattern\n   using Base = NVGPUOpPatternBase<ttn::MBarrierWaitOp, MBarrierWaitOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::MBarrierWaitOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     Value mbarrier = op.getMbarrier();\n     Value phase = op.getPhase();\n     operandsAndTypes.push_back({mbarrier, \"r\"});\n@@ -477,9 +512,9 @@ class TMALoadTiledOpPattern\n   using Base = NVGPUOpPatternBase<ttn::TMALoadTiledOp, TMALoadTiledOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::TMALoadTiledOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     auto dst = op.getDst();\n     auto mbarrier = op.getMbarrier();\n     auto tmaDesc = op.getTmaDesc();\n@@ -543,9 +578,9 @@ class TMAStoreTiledOpPattern\n   using Base = NVGPUOpPatternBase<ttn::TMAStoreTiledOp, TMAStoreTiledOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::TMAStoreTiledOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     auto src = op.getSrc();\n     auto tmaDesc = op.getTmaDesc();\n     auto pred = op.getPred();\n@@ -594,9 +629,9 @@ class NamedBarrierArriveOpPattern\n                                   NamedBarrierArriveOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::NamedBarrierArriveOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     auto bar = op.getBar();\n     auto numThreads = op.getNumThreads();\n     operandsAndTypes.push_back({bar, \"r\"});\n@@ -617,9 +652,9 @@ class NamedBarrierWaitOpPattern\n       NVGPUOpPatternBase<ttn::NamedBarrierWaitOp, NamedBarrierWaitOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n+  OperandsAndConstraints\n   getOperandsAndConstraints(ttn::NamedBarrierWaitOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+    OperandsAndConstraints operandsAndTypes;\n     auto bar = op.getBar();\n     auto numThreads = op.getNumThreads();\n     operandsAndTypes.push_back({bar, \"r\"});\n@@ -638,9 +673,8 @@ class StoreDSmemOpPattern\n   using Base = NVGPUOpPatternBase<ttn::StoreDSmemOp, StoreDSmemOpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndConstraints(ttn::StoreDSmemOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+  OperandsAndConstraints getOperandsAndConstraints(ttn::StoreDSmemOp op) const {\n+    OperandsAndConstraints operandsAndTypes;\n     auto addr = op.getAddr();\n     auto ctaId = op.getCtaId();\n     auto values = op.getValues();\n@@ -708,9 +742,8 @@ class Sts64OpPattern : public NVGPUOpPatternBase<ttn::Sts64Op, Sts64OpPattern> {\n   using Base = NVGPUOpPatternBase<ttn::Sts64Op, Sts64OpPattern>;\n   using Base::Base;\n \n-  std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndConstraints(ttn::Sts64Op op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+  OperandsAndConstraints getOperandsAndConstraints(ttn::Sts64Op op) const {\n+    OperandsAndConstraints operandsAndTypes;\n     auto offset = op.getOffset();\n     auto d0 = op.getD0();\n     auto d1 = op.getD1();\n@@ -737,9 +770,8 @@ class LoadDSmemOpPattern\n     auto vec = op.getVec();\n     return std::vector<std::string>(vec, c);\n   }\n-  std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndConstraints(ttn::LoadDSmemOp op) const {\n-    std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n+  OperandsAndConstraints getOperandsAndConstraints(ttn::LoadDSmemOp op) const {\n+    OperandsAndConstraints operandsAndTypes;\n     auto addr = op.getAddr();\n     auto ctaId = op.getCtaId();\n \n@@ -777,31 +809,60 @@ class LoadDSmemOpPattern\n   }\n };\n \n-class WGMMAOpPattern : public mlir::RewritePattern {\n+class WGMMAOpPattern : public NVGPUOpPatternBase<ttn::WGMMAOp, WGMMAOpPattern> {\n public:\n-  WGMMAOpPattern(mlir::MLIRContext *context)\n-      : mlir::RewritePattern(ttn::WGMMAOp::getOperationName(), 1, context) {}\n+  using Base = NVGPUOpPatternBase<ttn::WGMMAOp, WGMMAOpPattern>;\n+  using Base::Base;\n \n-  mlir::LogicalResult\n-  matchAndRewrite(mlir::Operation *op,\n-                  mlir::PatternRewriter &rewriter) const override {\n+  std::vector<std::string> getOutputConstraints(ttn::WGMMAOp op) const {\n+    // TODO (zahi): Return type must always be a struct for wgmma, currently\n+    // we rely on the size of output constraints vector to determine whether\n+    // the output is a struct or not. We should find a way to pass this info\n+    auto opC = op.getOpC();\n+    auto typeC = opC.getType();\n+\n+    auto structTypeC = typeC.dyn_cast<LLVM::LLVMStructType>();\n+    uint32_t numCRegs = structTypeC.getBody().size();\n+    std::string c = structTypeC.getBody().front().isF32() ? \"=f\" : \"=r\";\n+    return std::vector<std::string>(numCRegs, c);\n+  }\n+\n+  OperandsAndConstraints getOperandsAndConstraints(ttn::WGMMAOp op) const {\n+    OperandsAndConstraints operandsAndConstraints;\n+    auto opA = op.getOpA();\n+    auto opB = op.getOpB();\n+    auto opC = op.getOpC();\n+    auto typeA = opA.getType();\n+\n+    auto structTypeA = typeA.dyn_cast<LLVM::LLVMStructType>();\n+\n+    // TODO (zahi): is this the best way to tie inputs/outputs ?\n+    operandsAndConstraints.push_back({opC, 0});\n+\n+    if (structTypeA) {\n+      operandsAndConstraints.push_back({opA, \"f\"});\n+    } else {\n+      operandsAndConstraints.push_back({opA, \"l\"});\n+    }\n+\n+    // Operand B (must be `desc`)\n+    operandsAndConstraints.push_back({opB, \"l\"});\n+    return operandsAndConstraints;\n+  }\n+\n+  std::string getPtxAsm(ttn::WGMMAOp op) const {\n     using namespace ttn;\n-    auto ctx = rewriter.getContext();\n-    auto wgmmaOp = llvm::dyn_cast<ttn::WGMMAOp>(op);\n-    if (!wgmmaOp)\n-      return mlir::failure();\n-    auto loc = op->getLoc();\n-    auto opA = wgmmaOp.getOpA();\n-    auto opB = wgmmaOp.getOpB();\n-    auto opC = wgmmaOp.getOpC();\n-    auto m = wgmmaOp.getM();\n-    auto n = wgmmaOp.getN();\n-    auto k = wgmmaOp.getK();\n-    auto eltTypeC = wgmmaOp.getEltTypeC();\n-    auto eltTypeA = wgmmaOp.getEltTypeA();\n-    auto eltTypeB = wgmmaOp.getEltTypeB();\n-    auto layoutA = wgmmaOp.getLayoutA();\n-    auto layoutB = wgmmaOp.getLayoutB();\n+    auto opA = op.getOpA();\n+    auto opB = op.getOpB();\n+    auto opC = op.getOpC();\n+    auto m = op.getM();\n+    auto n = op.getN();\n+    auto k = op.getK();\n+    auto eltTypeC = op.getEltTypeC();\n+    auto eltTypeA = op.getEltTypeA();\n+    auto eltTypeB = op.getEltTypeB();\n+    auto layoutA = op.getLayoutA();\n+    auto layoutB = op.getLayoutB();\n \n     // Register checks\n     auto typeA = opA.getType();\n@@ -850,8 +911,6 @@ class WGMMAOpPattern : public mlir::RewritePattern {\n                    (m == 64 && 8 <= n && n <= 224 && k == 32);\n     }\n     assert(supported && \"WGMMA type or shape is not supported\");\n-    PTXBuilder ptxBuilder;\n-    SmallVector<PTXBuilder::Operand *> oprs;\n \n     // Operands\n     uint32_t asmOpIdx = 0;\n@@ -863,24 +922,9 @@ class WGMMAOpPattern : public mlir::RewritePattern {\n     args += \"{\";\n     for (uint32_t i = 0; i < numCRegs; ++i) {\n       args += \"$\" + std::to_string(asmOpIdx++) + (i == numCRegs - 1 ? \"\" : \",\");\n-      // LLVM does not support `+` semantic, we must repeat the arguments for\n-      // both input and outputs\n-      PTXBuilder::Operand *opr;\n-      if (structTypeC.getBody().front().isF32())\n-        opr = ptxBuilder.newOperand(\"=f\");\n-      else\n-        opr = ptxBuilder.newOperand(\"=r\");\n-      oprs.push_back(opr);\n     }\n     args += \"}, \";\n \n-    for (uint32_t i = asmOpIdx - numCRegs; i < asmOpIdx; ++i) {\n-      auto *opr = ptxBuilder.newOperand(\n-          extract_val(structTypeC.getBody()[i], opC, i), std::to_string(i));\n-      oprs.push_back(opr);\n-    }\n-\n-    // Note that LLVM will not skip the indexed repeating placeholders\n     asmOpIdx += numCRegs;\n     // Operand A\n     if (structTypeA) {\n@@ -890,21 +934,14 @@ class WGMMAOpPattern : public mlir::RewritePattern {\n       for (uint32_t i = 0; i < numARegs; ++i) {\n         args +=\n             \"$\" + std::to_string(asmOpIdx++) + (i == numARegs - 1 ? \"\" : \",\");\n-        auto *opr = ptxBuilder.newOperand(\n-            extract_val(structTypeA.getBody()[i], opA, i), \"f\");\n-        oprs.push_back(opr);\n       }\n       args += \"}, \";\n     } else {\n       args += \"$\" + std::to_string(asmOpIdx++) + \", \";\n-      auto *opr = ptxBuilder.newOperand(opA, \"l\");\n-      oprs.push_back(opr);\n     }\n \n     // Operand B (must be `desc`)\n     args += \"$\" + std::to_string(asmOpIdx++) + \", \";\n-    auto *opr = ptxBuilder.newOperand(opB, \"l\");\n-    oprs.push_back(opr);\n \n     // `scale-d` is 1 by default\n     args += \"1\";\n@@ -924,15 +961,7 @@ class WGMMAOpPattern : public mlir::RewritePattern {\n                   std::to_string(k) + \".\" + stringifyEnum(eltTypeC).str() +\n                   \".\" + stringifyEnum(eltTypeA).str() + \".\" +\n                   stringifyEnum(eltTypeB).str() + \" \" + args + \";\";\n-\n-    auto &ptxInstr = *ptxBuilder.create<PTXInstr>(ptxAsm);\n-    ptxInstr(oprs,\n-             /*onlyAttachMLIRArgs=*/true);\n-\n-    auto res =\n-        ptxBuilder.launch(rewriter, loc, structTypeC, /*hasSideEffect*/ true);\n-    rewriter.replaceOp(op, {res});\n-    return mlir::success();\n+    return ptxAsm;\n   }\n };\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/PTXAsmFormat.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -51,7 +51,7 @@ PTXBuilder::Operand *PTXBuilder::newOperand(StringRef constraint, bool init) {\n }\n \n PTXBuilder::Operand *PTXBuilder::newOperand(unsigned operandIndex) {\n-  assert(operandIndex < oprCounter && \"operand index out of range\");\n+  // assert(operandIndex < oprCounter && \"operand index out of range\");\n   auto *opr = newOperand();\n   opr->idx = oprCounter++;\n   opr->constraint = std::to_string(operandIndex);"}]