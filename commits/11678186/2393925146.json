[{"filename": "lib/codegen/analysis/align.cc", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "file_content_changes": "@@ -507,6 +507,9 @@ std::vector<unsigned> align::populate_starting_multiple_default(ir::value* v) {\n \n unsigned get_max_multiple(int val){\n   if(val == 0) return 1 << 31;\n+  if(val % 128 == 0) return 128;\n+  if(val % 64 == 0) return 64;\n+  if(val % 32 == 0) return 32;\n   if(val % 16 == 0) return 16;\n   if(val % 8 == 0) return 8;\n   if(val % 4 == 0) return 4;\n@@ -527,7 +530,7 @@ std::vector<unsigned> align::populate_starting_multiple(ir::value *v){\n   if(auto *x = dynamic_cast<ir::binary_operator*>(v))\n     return populate_starting_multiple_binop(x);\n   if(auto *x = dynamic_cast<ir::constant_int*>(v))\n-    return add_to_cache(x, {std::min<unsigned>(x->get_value(), 128)}, starting_multiple_);\n+    return add_to_cache(x, {get_max_multiple(x->get_value())}, starting_multiple_);\n   if(auto *x = dynamic_cast<ir::make_range*>(v))\n     return add_to_cache(x, {get_max_multiple(x->get_first()->get_value())}, starting_multiple_);\n   if(auto *x = dynamic_cast<ir::getelementptr_inst*>(v))"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -840,6 +840,7 @@ void init_triton_ir(py::module &&m) {\n       .def(\"create_fp_trunc\", &ir::builder::create_fp_trunc, ret::reference)\n       .def(\"create_int_cast\", &ir::builder::create_int_cast, ret::reference)\n       .def(\"create_downcast\", &ir::builder::create_downcast, ret::reference)\n+      .def(\"create_int_to_ptr\", &ir::builder::create_int_to_ptr, ret::reference)\n       // phi\n       .def(\"create_phi\", &ir::builder::create_phi, ret::reference)\n       // Binary instructions"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -910,7 +910,7 @@ def _kernel(z, BLOCK: tl.constexpr,\n def test_masked_load_shared_memory(dtype, device='cuda'):\n     M = 32\n     N = 32\n-    K = 8\n+    K = 16\n \n     in1 = torch.rand((M, K), dtype=dtype, device=device)\n     in2 = torch.rand((K, N), dtype=dtype, device=device)"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "file_content_changes": "@@ -342,6 +342,26 @@ def __repr__(self) -> str:\n     def __bool__(self):\n         return bool(self.value)\n \n+    def __ge__(self, other):\n+        other = other.value if isinstance(other, constexpr) else other\n+        return self.value >= other\n+\n+    def __gt__(self, other):\n+        other = other.value if isinstance(other, constexpr) else other\n+        return self.value > other\n+\n+    def __le__(self, other):\n+        other = other.value if isinstance(other, constexpr) else other\n+        return self.value <= other\n+\n+    def __lt__(self, other):\n+        other = other.value if isinstance(other, constexpr) else other\n+        return self.value < other\n+\n+    def __eq__(self, other):\n+        other = other.value if isinstance(other, constexpr) else other\n+        return self.value == other\n+\n     def __call__(self, *args, **kwds):\n         return self.value(*args, **kwds)\n "}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "file_content_changes": "@@ -905,6 +905,10 @@ def dot(lhs: tl.tensor,\n         allow_tf32: bool,\n         builder: ir.builder) -> tl.tensor:\n     assert lhs.type.is_block() and rhs.type.is_block()\n+    assert len(lhs.shape) == 2 and len(rhs.shape) == 2\n+    assert lhs.shape[-1] == rhs.shape[0]\n+    assert lhs.shape[0] >= 16 and lhs.shape[1] >= 16 and rhs.shape[1] >= 16,\\\n+        \"small blocks not supported!\"\n     if lhs.type.scalar.is_int():\n         _0 = builder.get_int32(0)\n         ret_scalar_ty = tl.int32"}]