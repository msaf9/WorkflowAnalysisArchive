[{"filename": "lib/Analysis/Membar.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -138,8 +138,8 @@ void MembarAnalysis::update(Operation *op, BlockInfo *blockInfo,\n       barSync(*builder, op, barId, 128);\n     } else {\n       builder->create<gpu::BarrierOp>(op->getLoc());\n-      blockInfo->sync();\n     }\n+    blockInfo->sync();\n     return;\n   }\n \n@@ -203,8 +203,8 @@ void MembarAnalysis::update(Operation *op, BlockInfo *blockInfo,\n       barSync(*builder, op, barId, 128);\n     } else {\n       builder->create<gpu::BarrierOp>(op->getLoc());\n-      blockInfo->sync();\n     }\n+    blockInfo->sync();\n   }\n   // Update the region info, even if barrier is inserted, we have to maintain\n   // the current op's read/write buffers."}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 19, "deletions": 1, "changes": 20, "file_content_changes": "@@ -49,6 +49,13 @@ namespace ttng = mlir::triton::nvidia_gpu;\n \n namespace {\n \n+// pass named attrs (e.g., ws related attributes)\n+static void addNamedAttrs(Operation *op, ArrayRef<mlir::NamedAttribute> attrs) {\n+  for (const NamedAttribute attr : attrs)\n+    if (!op->hasAttr(attr.getName()))\n+      op->setAttr(attr.getName(), attr.getValue());\n+}\n+\n class TritonLLVMFunctionConversionTarget : public ConversionTarget {\n public:\n   explicit TritonLLVMFunctionConversionTarget(MLIRContext &ctx, bool isROCM)\n@@ -617,10 +624,13 @@ class ConvertTritonGPUToLLVM\n       auto newCvtType = RankedTensorType::get(shape, F16Ty, cvtEncoding);\n       auto newArg = builder.create<mlir::triton::FpToFpOp>(\n           cvtOp.getLoc(), newArgType, cvtOp.getOperand());\n+      addNamedAttrs(newArg, cvtOp->getAttrs());\n       auto newCvt = builder.create<mlir::triton::gpu::ConvertLayoutOp>(\n           cvtOp.getLoc(), newCvtType, newArg);\n+      addNamedAttrs(newCvt, cvtOp->getAttrs());\n       auto newRet = builder.create<mlir::triton::FpToFpOp>(\n           cvtOp.getLoc(), cvtOp.getType(), newCvt.getResult());\n+      addNamedAttrs(newRet, cvtOp->getAttrs());\n       cvtOp.replaceAllUsesWith(newRet.getResult());\n       cvtOp.erase();\n     });\n@@ -646,8 +656,10 @@ class ConvertTritonGPUToLLVM\n                 getOrder(srcMma), numWarps, threadsPerWarp, numCTAs));\n         auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), tmpType, cvtOp.getOperand());\n+        addNamedAttrs(tmp, cvtOp->getAttrs());\n         auto newConvert = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), dstType, tmp);\n+        addNamedAttrs(newConvert, cvtOp->getAttrs());\n         cvtOp.replaceAllUsesWith(newConvert.getResult());\n         cvtOp.erase();\n       }\n@@ -674,8 +686,10 @@ class ConvertTritonGPUToLLVM\n                 srcType.getElementType()));\n         auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), tmpType, cvtOp.getOperand());\n+        addNamedAttrs(tmp, cvtOp->getAttrs());\n         auto newConvert = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), dstType, tmp);\n+        addNamedAttrs(newConvert, cvtOp->getAttrs());\n         cvtOp.replaceAllUsesWith(newConvert.getResult());\n         cvtOp.erase();\n       }\n@@ -750,6 +764,7 @@ class ConvertTritonGPUToLLVM\n           /*boundaryCheck=*/nullptr, /*padding=*/nullptr,\n           insertSliceAsyncOp.getCache(), insertSliceAsyncOp.getEvict(),\n           insertSliceAsyncOp.getIsVolatile());\n+      addNamedAttrs(loadOp, insertSliceAsyncOp->getAttrs());\n \n       // insert_slice\n       auto axis = insertSliceAsyncOp.getAxis();\n@@ -765,6 +780,7 @@ class ConvertTritonGPUToLLVM\n       auto insertSliceOp = builder.create<tensor::InsertSliceOp>(\n           insertSliceAsyncOp.getLoc(), loadOp, insertSliceAsyncOp.getDst(),\n           offsets, sizes, strides);\n+      addNamedAttrs(insertSliceOp, insertSliceAsyncOp->getAttrs());\n \n       // Replace\n       insertSliceAsyncOp.replaceAllUsesWith(insertSliceOp.getResult());\n@@ -784,7 +800,9 @@ class ConvertTritonGPUToLLVM\n       } else if (decomposed) {\n         // Wait for all previous async ops\n         OpBuilder builder(asyncWaitOp);\n-        builder.create<triton::gpu::AsyncWaitOp>(asyncWaitOp.getLoc(), 0);\n+        auto newWaitOp =\n+            builder.create<triton::gpu::AsyncWaitOp>(asyncWaitOp.getLoc(), 0);\n+        addNamedAttrs(newWaitOp, asyncWaitOp->getAttrs());\n         asyncWaitOp.erase();\n       }\n     });"}, {"filename": "python/test/unit/hopper/test_persistent_warp_specialized_gemm.py", "status": "modified", "additions": 10, "deletions": 8, "changes": 18, "file_content_changes": "@@ -855,19 +855,11 @@ def full_static_persistent_matmul_kernel(\n @pytest.mark.skipif(torch.cuda.get_device_capability()\n                     [0] < 9, reason=\"Requires compute capability >= 9\")\n def test_full_static_persistent_matmul_kernel(BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, TRANS_A, TRANS_B, epilogue, out_dtype, USE_TMA_STORE, NUM_STAGES, ENABLE_WS):\n-    pytest.skip(\"known failure, will fix it later!!!\")\n     if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, epilogue, out_dtype, USE_TMA_STORE, NUM_STAGES, ENABLE_WS])) in [\n         '128-128-128-4-1-256-256-192-none-float32-True-3-True',\n     ]:\n         pytest.skip('out of resource: shared memory, Required: 263168')\n \n-    if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, USE_TMA_STORE, ENABLE_WS])) in ([\n-        '64-16-16-4-1-512-256-256-True-True',\n-    ] + [\n-        f'128-128-64-4-1-{m}-{n}-{k}-True-True' for m in range(512, 4096, 360) for n in range(512, 4096, 360) for k in [512, 1024]\n-    ]):\n-        pytest.skip('known kernel hang problem when tma store is enabled')\n-\n     if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, TRANS_A, TRANS_B])) in [\n         '16-32-64-4-4-512-256-64-True-False',\n         '16-32-64-4-4-512-256-64-True-True',\n@@ -876,6 +868,16 @@ def test_full_static_persistent_matmul_kernel(BLOCK_M, BLOCK_N, BLOCK_K, NUM_WAR\n     ]:\n         pytest.skip('shapePerCTA[1] < 16 not supported')\n \n+    # with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n+    if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, TRANS_B])) in [\n+        '16-32-64-4-1-256-256-256-False',\n+        '16-32-64-4-2-256-256-256-False',\n+        '16-32-64-4-2-256-256-256-True',\n+        '16-32-64-8-2-256-256-256-False',\n+        '16-32-64-8-2-256-256-256-True',\n+    ]:\n+        pytest.skip('Known legacy issue, ldmatrix can only support x4')\n+\n     if epilogue == 'chain-dot':\n         pytest.skip('known failure: Assertion !region.empty() && unexpected empty region.')\n "}]