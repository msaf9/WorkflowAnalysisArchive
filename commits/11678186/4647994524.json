[{"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 32, "deletions": 21, "changes": 53, "file_content_changes": "@@ -46,22 +46,39 @@ AxisInfo AxisInfo::getPessimisticValueState(Value value) {\n   auto rank = 1;\n   if (TensorType ty = value.getType().dyn_cast<TensorType>())\n     rank = ty.getRank();\n-  auto contiHint = 1;\n-  auto divHint = 1;\n-  auto constHint = 1;\n+\n+  DimVectorT knownContiguity(rank, 1);\n+  DimVectorT knownDivisibility(rank, 1);\n+  DimVectorT knownConstancy(rank, 1);\n+\n   BlockArgument blockArg = value.dyn_cast<BlockArgument>();\n+\n+  auto parseFuncAttrs = [&]<class T>(T funcOp) {\n+    // liast of attributes that we care about\n+    SmallVector<std::pair<DimVectorT *, std::string>> retVecs;\n+    retVecs.push_back({&knownContiguity, \"tt.contiguity\"});\n+    retVecs.push_back({&knownDivisibility, \"tt.divisibility\"});\n+    retVecs.push_back({&knownConstancy, \"tt.constancy\"});\n+    // initialize attributes one by one\n+    for (auto [vec, attrName] : retVecs) {\n+      Attribute attr = funcOp.getArgAttr(blockArg.getArgNumber(), attrName);\n+      if (auto int_attr = attr.dyn_cast_or_null<IntegerAttr>())\n+        *vec = DimVectorT(rank, int_attr.getValue().getZExtValue());\n+      if (auto dense_attr = attr.dyn_cast_or_null<DenseElementsAttr>()) {\n+        auto vals = dense_attr.getValues<int>();\n+        *vec = DimVectorT(vals.begin(), vals.end());\n+      }\n+    }\n+  };\n+\n   if (blockArg && blockArg.getOwner()->isEntryBlock()) {\n     Operation *op = blockArg.getOwner()->getParentOp();\n-    if (func::FuncOp fun = dyn_cast<func::FuncOp>(op)) {\n-      Attribute attr =\n-          fun.getArgAttr(blockArg.getArgNumber(), \"tt.divisibility\");\n-      if (attr)\n-        divHint = attr.cast<IntegerAttr>().getValue().getZExtValue();\n-    } else if (auto fun = dyn_cast<LLVM::LLVMFuncOp>(op)) {\n-      Attribute attr =\n-          fun.getArgAttr(blockArg.getArgNumber(), \"tt.divisibility\");\n-      if (attr)\n-        divHint = attr.cast<IntegerAttr>().getValue().getZExtValue();\n+    if (auto fun = dyn_cast<func::FuncOp>(op)) {\n+      parseFuncAttrs(fun);\n+    }\n+    // llvm codegen check alignment to generate vector load/store\n+    if (auto fun = dyn_cast<LLVM::LLVMFuncOp>(op)) {\n+      parseFuncAttrs(fun);\n     } else {\n       // Derive the divisibility of the induction variable only when\n       // the step and the lower bound are both constants\n@@ -79,16 +96,13 @@ AxisInfo AxisInfo::getPessimisticValueState(Value value) {\n                   step.getValue().cast<IntegerAttr>().getValue().getZExtValue();\n               auto k = gcd(lowerBoundVal, stepVal);\n               if (k != 0)\n-                divHint = k;\n+                knownDivisibility = DimVectorT(rank, k);\n             }\n           }\n         }\n       }\n     }\n   } else if (Operation *op = value.getDefiningOp()) {\n-    DimVectorT knownContiguity(rank, 1);\n-    DimVectorT knownDivisibility(rank, 1);\n-    DimVectorT knownConstancy(rank, 1);\n     if (Attribute attr = op->getAttr(\"tt.divisibility\")) {\n       auto vals = attr.cast<DenseElementsAttr>().getValues<int>();\n       knownDivisibility = DimVectorT(vals.begin(), vals.end());\n@@ -101,12 +115,9 @@ AxisInfo AxisInfo::getPessimisticValueState(Value value) {\n       auto vals = attr.cast<DenseElementsAttr>().getValues<int>();\n       knownConstancy = DimVectorT(vals.begin(), vals.end());\n     }\n-    return AxisInfo(knownContiguity, knownDivisibility, knownConstancy);\n   }\n \n-  return AxisInfo(/*knownContiguity=*/DimVectorT(rank, contiHint),\n-                  /*knownDivisibility=*/DimVectorT(rank, divHint),\n-                  /*knownConstancy=*/DimVectorT(rank, constHint));\n+  return AxisInfo(knownContiguity, knownDivisibility, knownConstancy);\n }\n \n // The gcd of both arguments for each dimension"}, {"filename": "test/TritonGPU/loop-pipeline.mlir", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -257,9 +257,9 @@ func.func @lut_bmm(%77: i64 {tt.divisibility=16: i32},\n     %85 = tt.splat %84 : (i64) -> tensor<16x16xi64, #BL>\n     %86 = tt.addptr %60, %85 : tensor<16x16x!tt.ptr<f16>, #BL>, tensor<16x16xi64, #BL>\n     %87 = tt.load %86 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #BL>\n-    %88 = triton_gpu.convert_layout %82 : (tensor<16x16xf16, #AL>) -> tensor<16x16xf16, #A>>\n-    %89 = triton_gpu.convert_layout %87 : (tensor<16x16xf16, #BL>) -> tensor<16x16xf16, #B>>\n-    %90 = tt.dot %88, %89, %arg19 {allowTF32 = true} : tensor<16x16xf16, #A>> * tensor<16x16xf16, #B>> -> tensor<16x16xf32, #C>\n+    %88 = triton_gpu.convert_layout %82 : (tensor<16x16xf16, #AL>) -> tensor<16x16xf16, #A>\n+    %89 = triton_gpu.convert_layout %87 : (tensor<16x16xf16, #BL>) -> tensor<16x16xf16, #B>\n+    %90 = tt.dot %88, %89, %arg19 {allowTF32 = true} : tensor<16x16xf16, #A> * tensor<16x16xf16, #B> -> tensor<16x16xf32, #C>\n     %91 = tt.addptr %arg20, %78 : tensor<16x16x!tt.ptr<f16>, #AL>, tensor<16x16xi32, #AL>\n     %92 = tt.addptr %arg21, %c1_i32 : !tt.ptr<i64>, i32\n     scf.yield %90, %91, %92 : tensor<16x16xf32, #C>, tensor<16x16x!tt.ptr<f16>, #AL>, !tt.ptr<i64>"}]