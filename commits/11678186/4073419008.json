[{"filename": "CMakeLists.txt", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -1,4 +1,7 @@\n cmake_minimum_required(VERSION 3.6)\n+\n+cmake_policy(SET CMP0116 OLD)\n+\n include(ExternalProject)\n \n set(CMAKE_CXX_STANDARD 17)\n@@ -155,7 +158,6 @@ if(TRITON_BUILD_PYTHON_MODULE)\n     endif()\n endif()\n \n-\n # # Triton\n # file(GLOB_RECURSE LIBTRITON_SRC lib/*.cc)\n # if (WIN32 AND TRITON_BUILD_PYTHON_MODULE)\n@@ -212,7 +214,7 @@ if(TRITON_BUILD_PYTHON_MODULE)\n     # optimizations\n     MLIRPass\n     MLIRTransforms\n-    MLIRLLVMIR\n+    MLIRLLVMDialect\n     MLIRSupport\n     MLIRTargetLLVMIRExport\n     MLIRExecutionEngine"}, {"filename": "bin/CMakeLists.txt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -48,7 +48,7 @@ llvm_update_compile_flags(triton-translate)\n          # MLIR core\n          MLIROptLib\n          MLIRIR\n-         MLIRLLVMIR\n+         MLIRLLVMDialect\n          MLIRPass\n          MLIRSupport\n          MLIRTransforms"}, {"filename": "bin/FileCheck/FileCheck.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -19,6 +19,7 @@\n #include \"llvm/Support/CommandLine.h\"\n #include \"llvm/Support/InitLLVM.h\"\n #include \"llvm/Support/Process.h\"\n+#include \"llvm/Support/SourceMgr.h\"\n #include \"llvm/Support/WithColor.h\"\n #include \"llvm/Support/raw_ostream.h\"\n #include <cmath>\n@@ -360,6 +361,8 @@ static std::string GetCheckTypeAbbreviation(Check::FileCheckType Ty) {\n     return \"bad-not\";\n   case Check::CheckBadCount:\n     return \"bad-count\";\n+  case Check::CheckMisspelled:\n+    return \"misspelled\";\n   case Check::CheckNone:\n     llvm_unreachable(\"invalid FileCheckType\");\n   }"}, {"filename": "bin/triton-opt.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -8,7 +8,7 @@\n \n #include \"mlir/IR/Dialect.h\"\n #include \"mlir/InitAllPasses.h\"\n-#include \"mlir/Support/MlirOptMain.h\"\n+#include \"mlir/Tools/mlir-opt/MlirOptMain.h\"\n \n namespace mlir {\n namespace test {\n@@ -33,8 +33,8 @@ int main(int argc, char **argv) {\n   // TODO: register Triton & TritonGPU passes\n   mlir::DialectRegistry registry;\n   registry.insert<mlir::triton::TritonDialect,\n-                  mlir::triton::gpu::TritonGPUDialect, mlir::math::MathDialect,\n-                  mlir::arith::ArithmeticDialect, mlir::StandardOpsDialect,\n+                  mlir::triton::gpu::TritonGPUDialect, mlir::func::FuncDialect,\n+                  mlir::math::MathDialect, mlir::arith::ArithmeticDialect,\n                   mlir::scf::SCFDialect, mlir::gpu::GPUDialect>();\n \n   return mlir::asMainReturnCode(mlir::MlirOptMain("}, {"filename": "bin/triton-translate.cpp", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "file_content_changes": "@@ -3,7 +3,7 @@\n #include \"mlir/IR/AsmState.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/Dialect.h\"\n-#include \"mlir/Parser.h\"\n+#include \"mlir/Parser/Parser.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Pass/PassManager.h\"\n #include \"mlir/Support/FileUtilities.h\"\n@@ -38,7 +38,7 @@ OwningOpRef<ModuleOp> loadMLIRModule(llvm::StringRef inputFilename,\n   mlir::DialectRegistry registry;\n   registry.insert<TritonDialect, triton::gpu::TritonGPUDialect,\n                   mlir::math::MathDialect, arith::ArithmeticDialect,\n-                  StandardOpsDialect, scf::SCFDialect>();\n+                  scf::SCFDialect>();\n \n   context.appendDialectRegistry(registry);\n \n@@ -50,7 +50,8 @@ OwningOpRef<ModuleOp> loadMLIRModule(llvm::StringRef inputFilename,\n     context.loadAllAvailableDialects();\n     context.allowUnregisteredDialects();\n \n-    OwningOpRef<ModuleOp> module(parseSourceFile(sourceMgr, &context));\n+    OwningOpRef<ModuleOp> module =\n+        parseSourceFile<ModuleOp>(sourceMgr, &context);\n     if (!module) {\n       llvm::errs() << \"Parse MLIR file failed.\";\n       return nullptr;"}, {"filename": "include/triton/Analysis/Alias.h", "status": "modified", "additions": 15, "deletions": 6, "changes": 21, "file_content_changes": "@@ -2,7 +2,7 @@\n #define TRITON_ANALYSIS_ALIAS_H\n \n #include \"mlir/Analysis/AliasAnalysis.h\"\n-#include \"mlir/Analysis/DataFlowAnalysis.h\"\n+#include \"mlir/Analysis/DataFlow/SparseAnalysis.h\"\n #include \"llvm/ADT/DenseSet.h\"\n \n namespace mlir {\n@@ -21,14 +21,18 @@ class AliasInfo {\n   }\n \n   /// The pessimistic value state of a value without alias\n-  static AliasInfo getPessimisticValueState(MLIRContext *context) {\n+  static AliasInfo getPessimisticValueState(MLIRContext *context = nullptr) {\n     return AliasInfo();\n   }\n   static AliasInfo getPessimisticValueState(Value value) { return AliasInfo(); }\n \n   /// The union of both arguments\n   static AliasInfo join(const AliasInfo &lhs, const AliasInfo &rhs);\n \n+  void print(raw_ostream &os) const {\n+    llvm::interleaveComma(allocs, os, [&](Value alloc) { alloc.print(os); });\n+  }\n+\n private:\n   /// The set of allocated values that are aliased by this lattice.\n   /// For now, we only consider aliased value produced by the following\n@@ -58,9 +62,13 @@ class AliasInfo {\n //===----------------------------------------------------------------------===//\n // Shared Memory Alias Analysis\n //===----------------------------------------------------------------------===//\n-class SharedMemoryAliasAnalysis : public ForwardDataFlowAnalysis<AliasInfo> {\n+class SharedMemoryAliasAnalysis\n+    : public dataflow::SparseDataFlowAnalysis<dataflow::Lattice<AliasInfo>> {\n public:\n-  using ForwardDataFlowAnalysis<AliasInfo>::ForwardDataFlowAnalysis;\n+  using dataflow::SparseDataFlowAnalysis<\n+      dataflow::Lattice<AliasInfo>>::SparseDataFlowAnalysis;\n+  using dataflow::SparseDataFlowAnalysis<\n+      dataflow::Lattice<AliasInfo>>::getLatticeElement;\n \n   /// XXX(Keren): Compatible interface with MLIR AliasAnalysis for future use.\n   /// Given two values, returns their aliasing behavior.\n@@ -70,9 +78,10 @@ class SharedMemoryAliasAnalysis : public ForwardDataFlowAnalysis<AliasInfo> {\n   ModRefResult getModRef(Operation *op, Value location);\n \n   /// Computes if the alloc set of the results are changed.\n-  ChangeResult\n+  void\n   visitOperation(Operation *op,\n-                 ArrayRef<LatticeElement<AliasInfo> *> operands) override;\n+                 ArrayRef<const dataflow::Lattice<AliasInfo> *> operands,\n+                 ArrayRef<dataflow::Lattice<AliasInfo> *> results) override;\n };\n \n } // namespace mlir"}, {"filename": "include/triton/Analysis/Allocation.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -188,6 +188,8 @@ class Allocation {\n   friend class triton::AllocationAnalysis;\n };\n \n+template <typename T> Interval(T, T) -> Interval<T>;\n+\n } // namespace mlir\n \n #endif // TRITON_ANALYSIS_ALLOCATION_H"}, {"filename": "include/triton/Analysis/AxisInfo.h", "status": "modified", "additions": 40, "deletions": 16, "changes": 56, "file_content_changes": "@@ -1,9 +1,10 @@\n #ifndef TRITON_ANALYSIS_AXISINFO_H\n #define TRITON_ANALYSIS_AXISINFO_H\n \n-#include \"mlir/Analysis/DataFlowAnalysis.h\"\n+#include \"mlir/Analysis/DataFlow/SparseAnalysis.h\"\n #include \"llvm/Support/raw_ostream.h\"\n \n+#include \"mlir/Support/LLVM.h\"\n #include \"triton/Analysis/Utility.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n@@ -62,14 +63,30 @@ class AxisInfo {\n   }\n \n   /// The pessimistic value state of the contiguity is unknown.\n-  static AxisInfo getPessimisticValueState(MLIRContext *context) {\n+  static AxisInfo getPessimisticValueState(MLIRContext *context = nullptr) {\n     return AxisInfo();\n   }\n   static AxisInfo getPessimisticValueState(Value value);\n \n   /// The gcd of both arguments for each dimension\n   static AxisInfo join(const AxisInfo &lhs, const AxisInfo &rhs);\n \n+  void print(raw_ostream &os) const {\n+    auto print = [&](StringRef name, DimVectorT vec) {\n+      os << name << \" = [\";\n+      llvm::interleaveComma(vec, os);\n+      os << \"]\";\n+    };\n+    print(\"contiguity\", contiguity);\n+    print(\", divisibility\", divisibility);\n+    print(\", constancy\", constancy);\n+    os << \", constant_value = \";\n+    if (constantValue)\n+      os << *constantValue;\n+    else\n+      os << \"<none>\";\n+  }\n+\n private:\n   /// The _contiguity_ information maps the `d`-th\n   /// dimension to the length of the shortest\n@@ -147,7 +164,8 @@ class AxisInfoVisitor {\n   }\n \n   virtual AxisInfo\n-  getAxisInfo(Operation *op, ArrayRef<LatticeElement<AxisInfo> *> operands) = 0;\n+  getAxisInfo(Operation *op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) = 0;\n \n   virtual bool match(Operation *op) = 0;\n };\n@@ -157,15 +175,16 @@ template <typename OpTy> class AxisInfoVisitorImpl : public AxisInfoVisitor {\n public:\n   using AxisInfoVisitor::AxisInfoVisitor;\n \n-  AxisInfo getAxisInfo(Operation *op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) final {\n+  AxisInfo\n+  getAxisInfo(Operation *op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) final {\n     return getAxisInfo(cast<OpTy>(op), operands);\n   }\n \n   bool match(Operation *op) final { return isa<OpTy>(op); }\n \n-  virtual AxisInfo getAxisInfo(OpTy op,\n-                               ArrayRef<LatticeElement<AxisInfo> *> operands) {\n+  virtual AxisInfo\n+  getAxisInfo(OpTy op, ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) {\n     llvm_unreachable(\"Unimplemented getAxisInfo\");\n   }\n };\n@@ -176,8 +195,9 @@ class BinaryOpVisitorImpl : public AxisInfoVisitorImpl<OpTy> {\n public:\n   using AxisInfoVisitorImpl<OpTy>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(OpTy op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(OpTy op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     auto lhsInfo = operands[0]->getValue();\n     auto rhsInfo = operands[1]->getValue();\n     auto rank = lhsInfo.getRank();\n@@ -230,7 +250,8 @@ class AxisInfoVisitorList {\n     (visitors.emplace_back(std::make_unique<Ts>()), ...);\n   }\n \n-  AxisInfo apply(Operation *op, ArrayRef<LatticeElement<AxisInfo> *> operands) {\n+  AxisInfo apply(Operation *op,\n+                 ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) {\n     for (auto &visitor : visitors)\n       if (visitor->match(op))\n         return visitor->getAxisInfo(op, operands);\n@@ -241,16 +262,19 @@ class AxisInfoVisitorList {\n   std::vector<std::unique_ptr<AxisInfoVisitor>> visitors;\n };\n \n-class AxisInfoAnalysis : public ForwardDataFlowAnalysis<AxisInfo> {\n+class AxisInfoAnalysis\n+    : public dataflow::SparseDataFlowAnalysis<dataflow::Lattice<AxisInfo>> {\n private:\n   AxisInfoVisitorList visitors;\n \n public:\n-  AxisInfoAnalysis(MLIRContext *context);\n+  AxisInfoAnalysis(DataFlowSolver &solver);\n+  using dataflow::SparseDataFlowAnalysis<\n+      dataflow::Lattice<AxisInfo>>::getLatticeElement;\n \n-  ChangeResult\n-  visitOperation(Operation *op,\n-                 ArrayRef<LatticeElement<AxisInfo> *> operands) override;\n+  void visitOperation(Operation *op,\n+                      ArrayRef<const dataflow::Lattice<AxisInfo> *> operands,\n+                      ArrayRef<dataflow::Lattice<AxisInfo> *> results) override;\n \n   unsigned getPtrContiguity(Value ptr);\n \n@@ -261,4 +285,4 @@ class AxisInfoAnalysis : public ForwardDataFlowAnalysis<AxisInfo> {\n \n } // namespace mlir\n \n-#endif\n\\ No newline at end of file\n+#endif"}, {"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -1,6 +1,7 @@\n #ifndef TRITON_ANALYSIS_UTILITY_H\n #define TRITON_ANALYSIS_UTILITY_H\n \n+#include \"mlir/Analysis/DataFlowFramework.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n #include <algorithm>\n #include <numeric>\n@@ -11,7 +12,7 @@ namespace mlir {\n class ReduceOpHelper {\n public:\n   explicit ReduceOpHelper(triton::ReduceOp op) : op(op) {\n-    srcTy = op.operand().getType().cast<RankedTensorType>();\n+    srcTy = op.getOperand().getType().cast<RankedTensorType>();\n   }\n \n   ArrayRef<int64_t> getSrcShape() { return srcTy.getShape(); }\n@@ -97,6 +98,9 @@ bool isMmaToDotShortcut(triton::gpu::MmaEncodingAttr &mmaLayout,\n SetVector<Operation *>\n multiRootTopologicalSort(const SetVector<Operation *> &toSort);\n \n+// Create a basic DataFlowSolver with constant and dead code analysis included.\n+std::unique_ptr<DataFlowSolver> createDataFlowSolver();\n+\n } // namespace mlir\n \n #endif // TRITON_ANALYSIS_UTILITY_H"}, {"filename": "include/triton/Conversion/Passes.td", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "file_content_changes": "@@ -12,7 +12,6 @@ def ConvertTritonToTritonGPU: Pass<\"convert-triton-to-tritongpu\", \"mlir::ModuleO\n \n     let dependentDialects = [\"mlir::arith::ArithmeticDialect\",\n                              \"mlir::math::MathDialect\",\n-                             \"mlir::StandardOpsDialect\",\n                              // TODO: Does this pass depend on SCF?\n                              \"mlir::scf::SCFDialect\",\n                              \"mlir::triton::TritonDialect\",\n@@ -41,8 +40,7 @@ def ConvertTritonGPUToLLVM : Pass<\"convert-triton-gpu-to-llvm\", \"mlir::ModuleOp\"\n                              \"mlir::tensor::TensorDialect\",\n                              \"mlir::triton::TritonDialect\",\n                              \"mlir::triton::gpu::TritonGPUDialect\",\n-                             \"mlir::NVVM::NVVMDialect\",\n-                             \"mlir::StandardOpsDialect\"];\n+                             \"mlir::NVVM::NVVMDialect\"];\n \n     let options = [\n         Option<\"computeCapability\", \"compute-capability\","}, {"filename": "include/triton/Dialect/Triton/IR/Dialect.h", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "file_content_changes": "@@ -1,14 +1,15 @@\n #ifndef TRITON_DIALECT_TRITON_IR_DIALECT_H_\n #define TRITON_DIALECT_TRITON_IR_DIALECT_H_\n \n+#include \"mlir/Dialect/Arithmetic/IR/Arithmetic.h\"\n+#include \"mlir/Dialect/ControlFlow/IR/ControlFlow.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/Math/IR/Math.h\"\n-#include \"mlir/Dialect/SCF/SCF.h\"\n-#include \"mlir/Dialect/StandardOps/IR/Ops.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/Dialect.h\"\n #include \"mlir/Interfaces/ControlFlowInterfaces.h\"\n-\n #include \"triton/Dialect/Triton/IR/Dialect.h.inc\"\n #include \"triton/Dialect/Triton/IR/OpsEnums.h.inc\"\n #include \"triton/Dialect/Triton/IR/Traits.h\""}, {"filename": "include/triton/Dialect/Triton/IR/TritonDialect.td", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "file_content_changes": "@@ -25,19 +25,17 @@ def Triton_Dialect : Dialect {\n   let dependentDialects = [\n     \"arith::ArithmeticDialect\",\n     \"math::MathDialect\",\n-    \"StandardOpsDialect\",\n     \"scf::SCFDialect\",\n-\n-    // Since LLVM 15\n-    // \"cf::ControlFlowDialect\",\n-    // \"func::FuncDialect\"\n+    \"cf::ControlFlowDialect\",\n+    \"func::FuncDialect\"\n   ];\n \n   let extraClassDeclaration = [{\n     void registerTypes();\n   }];\n \n   let hasConstantMaterializer = 1;\n+  let useDefaultTypePrinterParser = 1;\n }\n \n include \"triton/Dialect/Triton/IR/TritonTypes.td\""}, {"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 2, "deletions": 10, "changes": 12, "file_content_changes": "@@ -141,11 +141,7 @@ def TT_LoadOp : TT_Op<\"load\",\n                        \"triton::EvictionPolicy\":$evict, \"bool\":$isVolatile)>,\n     ];\n \n-    // let assemblyFormat = \"operands attr-dict `:` type($result)\";\n-    let parser = [{ return mlir::triton::parseLoadOp(parser, result); }];\n-\n-    let printer = [{ return mlir::triton::printLoadOp(p, *this); }];\n-\n+    let hasCustomAssemblyFormat = 1;\n     let hasCanonicalizer = 1;\n }\n \n@@ -167,11 +163,7 @@ def TT_StoreOp : TT_Op<\"store\",\n         OpBuilder<(ins \"Value\":$ptr, \"Value\":$value)>,\n     ];\n \n-    // let assemblyFormat = \"operands attr-dict `:` type($value)\";\n-    let parser = [{ return mlir::triton::parseStoreOp(parser, result); }];\n-\n-    let printer = [{ return mlir::triton::printStoreOp(p, *this); }];\n-\n+    let hasCustomAssemblyFormat = 1;\n     let hasCanonicalizer = 1;\n }\n "}, {"filename": "include/triton/Dialect/Triton/IR/TritonTypes.td", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -1,6 +1,7 @@\n #ifndef TRITON_TYPES\n #define TRITON_TYPES\n \n+include \"mlir/IR/AttrTypeBase.td\"\n include \"triton/Dialect/Triton/IR/TritonDialect.td\"\n \n //\n@@ -58,6 +59,7 @@ def TT_Ptr : TritonTypeDef<\"Pointer\", \"ptr\"> {\n         }]>\n     ];\n \n+    let hasCustomAssemblyFormat = 1;\n     let skipDefaultBuilders = 1;\n }\n def TT_PtrTensor : TensorOf<[TT_Ptr]>;"}, {"filename": "include/triton/Dialect/Triton/Transforms/Passes.td", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "file_content_changes": "@@ -16,8 +16,7 @@ def TritonCombineOps : Pass</*cli-arg*/\"triton-combine\", /*Op*/\"mlir::ModuleOp\">\n \n   let constructor = \"mlir::triton::createCombineOpsPass()\";\n \n-  let dependentDialects = [\"mlir::arith::ArithmeticDialect\",\n-                           /*SelectOp*/\"mlir::StandardOpsDialect\"];\n+  let dependentDialects = [\"mlir::arith::ArithmeticDialect\"];\n }\n \n #endif"}, {"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "file_content_changes": "@@ -1,19 +1,17 @@\n #ifndef TRITON_DIALECT_TRITONGPU_IR_DIALECT_H_\n #define TRITON_DIALECT_TRITONGPU_IR_DIALECT_H_\n \n-#include \"mlir/Dialect/GPU/GPUDialect.h\"\n+#include \"mlir/Dialect/GPU/IR/GPUDialect.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/Dialect.h\"\n \n // TritonGPU depends on Triton\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n-\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h.inc\"\n #include \"triton/Dialect/TritonGPU/IR/Traits.h\"\n \n #define GET_ATTRDEF_CLASSES\n-#include \"triton/Dialect/Triton/IR/AttrInterfaces.h.inc\"\n #include \"triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.h.inc\"\n \n #define GET_OP_CLASSES"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "file_content_changes": "@@ -1,6 +1,7 @@\n #ifndef TRITONGPU_ATTRDEFS\n #define TRITONGPU_ATTRDEFS\n \n+include \"mlir/IR/AttrTypeBase.td\"\n include \"triton/Dialect/TritonGPU/IR/TritonGPUDialect.td\"\n include \"triton/Dialect/Triton/IR/TritonInterfaces.td\"\n \n@@ -136,6 +137,7 @@ A_{3, 2}  A_{3, 3}  A_{3, 0}  A_{3, 1} ...   [phase 1] /\n   ];\n \n   let extraClassDeclaration = extraBaseClassDeclaration;\n+  let hasCustomAssemblyFormat = 1;\n }\n \n //===----------------------------------------------------------------------===//\n@@ -273,6 +275,7 @@ for\n     // ArrayRefParameter<\"unsigned\">:$sizePerCTA\n   );\n \n+  let hasCustomAssemblyFormat = 1;\n }\n \n //===----------------------------------------------------------------------===//\n@@ -422,6 +425,7 @@ For example, the matrix L corresponding to blockTileSize=[32,16] is:\n     static constexpr int numBitsToHoldMmaV1ID{5};\n   }];\n \n+  let hasCustomAssemblyFormat = 1;\n }\n \n def SliceEncodingAttr : DistributedEncoding<\"SliceEncoding\"> {\n@@ -456,6 +460,8 @@ def SliceEncodingAttr : DistributedEncoding<\"SliceEncoding\"> {\n     template<class T>\n     SmallVector<T> paddedShape(ArrayRef<T> shape) const;\n   }];\n+\n+  let hasCustomAssemblyFormat = 1;\n }\n \n def DotOperandEncodingAttr : DistributedEncoding<\"DotOperandEncoding\"> {\n@@ -492,6 +498,7 @@ section 9.7.13.4.1 for more details.\n \n   ];\n \n+  let hasCustomAssemblyFormat = 1;\n   let extraClassDeclaration = extraBaseClassDeclaration;\n }\n "}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUDialect.td", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -30,7 +30,7 @@ def TritonGPU_Dialect : Dialect {\n     }\n   }];\n   \n-\n+  let useDefaultAttributePrinterParser = 1;\n }\n \n #endif"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUOps.td", "status": "modified", "additions": 5, "deletions": 8, "changes": 13, "file_content_changes": "@@ -59,7 +59,7 @@ def TTG_AsyncCommitGroupOp : TTG_Op<\"async_commit_group\"> {\n // This is needed because these ops don't\n // handle encodings\n // e.g., https://github.com/llvm/llvm-project/blob/main/mlir/include/mlir/Dialect/Arith/IR/ArithOps.td#L111\n-def TTG_CmpIOp : TTG_Op<\"cmpi\", [NoSideEffect, Elementwise, \n+def TTG_CmpIOp : TTG_Op<\"cmpi\", [NoSideEffect, Elementwise,\n                                  SameOperandsAndResultShape, \n                                  SameOperandsAndResultEncoding]> {\n   let summary = \"integer comparison operation\";\n@@ -73,7 +73,7 @@ def TTG_CmpIOp : TTG_Op<\"cmpi\", [NoSideEffect, Elementwise,\n   let results = (outs TT_BoolLike:$result);\n }\n \n-def TTG_CmpFOp : TTG_Op<\"cmpf\", [NoSideEffect, Elementwise, \n+def TTG_CmpFOp : TTG_Op<\"cmpf\", [NoSideEffect, Elementwise,\n                                  SameOperandsAndResultShape, \n                                  SameOperandsAndResultEncoding]> {\n   let summary = \"floating-point comparison operation\";\n@@ -88,8 +88,8 @@ def TTG_CmpFOp : TTG_Op<\"cmpf\", [NoSideEffect, Elementwise,\n }\n \n // TODO: migrate to arith::SelectOp on LLVM16\n-def TTG_SelectOp : TTG_Op<\"select\", [NoSideEffect, Elementwise, \n-                                     SameOperandsAndResultShape, \n+def TTG_SelectOp : TTG_Op<\"select\", [NoSideEffect, Elementwise,\n+                                     SameOperandsAndResultShape,\n                                      SameOperandsAndResultEncoding]> {\n   let summary = \"select operation\";\n \n@@ -188,10 +188,7 @@ def TTG_InsertSliceAsyncOp : TTG_Op<\"insert_slice_async\",\n     }\n   }];\n \n-  // The custom parser could be replaced with oilist in LLVM-16\n-  let parser = [{ return parseInsertSliceAsyncOp(parser, result); }];\n-\n-  let printer = [{ return printInsertSliceAsyncOp(p, *this); }];\n+  let hasCustomAssemblyFormat = 1;\n }\n \n def TTG_AllocTensorOp : TTG_Op<\"alloc_tensor\", [MemoryEffects<[MemAlloc]>,  // Allocate shared memory"}, {"filename": "lib/Analysis/Alias.cpp", "status": "modified", "additions": 6, "deletions": 8, "changes": 14, "file_content_changes": "@@ -18,8 +18,9 @@ AliasInfo AliasInfo::join(const AliasInfo &lhs, const AliasInfo &rhs) {\n   return ret;\n }\n \n-ChangeResult SharedMemoryAliasAnalysis::visitOperation(\n-    Operation *op, ArrayRef<LatticeElement<AliasInfo> *> operands) {\n+void SharedMemoryAliasAnalysis::visitOperation(\n+    Operation *op, ArrayRef<const dataflow::Lattice<AliasInfo> *> operands,\n+    ArrayRef<dataflow::Lattice<AliasInfo> *> results) {\n   AliasInfo aliasInfo;\n   bool pessimistic = true;\n   if (maybeSharedAllocationOp(op)) {\n@@ -44,14 +45,11 @@ ChangeResult SharedMemoryAliasAnalysis::visitOperation(\n   }\n \n   if (pessimistic) {\n-    return markAllPessimisticFixpoint(op->getResults());\n+    return markAllPessimisticFixpoint(results);\n   }\n   // Join all lattice elements\n-  ChangeResult result = ChangeResult::NoChange;\n-  for (Value value : op->getResults()) {\n-    result |= getLatticeElement(value).join(aliasInfo);\n-  }\n-  return result;\n+  for (auto *result : results)\n+    propagateIfChanged(result, result->join(aliasInfo));\n }\n \n AliasResult SharedMemoryAliasAnalysis::alias(Value lhs, Value rhs) {"}, {"filename": "lib/Analysis/Allocation.cpp", "status": "modified", "additions": 16, "deletions": 14, "changes": 30, "file_content_changes": "@@ -1,4 +1,5 @@\n #include \"triton/Analysis/Allocation.h\"\n+#include \"mlir/Analysis/DataFlowFramework.h\"\n #include \"mlir/Analysis/Liveness.h\"\n #include \"mlir/Analysis/SliceAnalysis.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n@@ -33,10 +34,8 @@ constexpr int kPtrBitWidth = 64;\n \n static std::pair<SmallVector<unsigned>, SmallVector<unsigned>>\n getCvtOrder(const Attribute &srcLayout, const Attribute &dstLayout) {\n-  auto srcBlockedLayout = srcLayout.dyn_cast<BlockedEncodingAttr>();\n   auto srcMmaLayout = srcLayout.dyn_cast<MmaEncodingAttr>();\n   auto srcDotLayout = srcLayout.dyn_cast<DotOperandEncodingAttr>();\n-  auto dstBlockedLayout = dstLayout.dyn_cast<BlockedEncodingAttr>();\n   auto dstMmaLayout = dstLayout.dyn_cast<MmaEncodingAttr>();\n   auto dstDotLayout = dstLayout.dyn_cast<DotOperandEncodingAttr>();\n   assert(!(srcMmaLayout && dstMmaLayout) &&\n@@ -224,14 +223,12 @@ class AllocationAnalysis {\n   }\n \n   void getValueAlias(Value value, SharedMemoryAliasAnalysis &analysis) {\n-    LatticeElement<AliasInfo> *latticeElement =\n-        analysis.lookupLatticeElement(value);\n-    if (latticeElement) {\n-      auto &info = latticeElement->getValue();\n-      if (!info.getAllocs().empty()) {\n-        for (auto alloc : info.getAllocs()) {\n-          allocation->addAlias(value, alloc);\n-        }\n+    dataflow::Lattice<AliasInfo> *latticeElement =\n+        analysis.getLatticeElement(value);\n+    if (latticeElement && !latticeElement->isUninitialized()) {\n+      AliasInfo &info = latticeElement->getValue();\n+      for (auto alloc : info.getAllocs()) {\n+        allocation->addAlias(value, alloc);\n       }\n     }\n   }\n@@ -244,14 +241,19 @@ class AllocationAnalysis {\n       getScratchValueSize(op);\n     });\n     // Get the alias values\n-    SharedMemoryAliasAnalysis aliasAnalysis(operation->getContext());\n-    aliasAnalysis.run(operation);\n+    std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n+    SharedMemoryAliasAnalysis *aliasAnalysis =\n+        solver->load<SharedMemoryAliasAnalysis>();\n+    if (failed(solver->initializeAndRun(operation))) {\n+      // TODO: return error instead of bailing out..\n+      llvm_unreachable(\"failed to run SharedMemoryAliasAnalysis\");\n+    }\n     operation->walk<WalkOrder::PreOrder>([&](Operation *op) {\n       for (auto operand : op->getOperands()) {\n-        getValueAlias(operand, aliasAnalysis);\n+        getValueAlias(operand, *aliasAnalysis);\n       }\n       for (auto value : op->getResults()) {\n-        getValueAlias(value, aliasAnalysis);\n+        getValueAlias(value, *aliasAnalysis);\n       }\n     });\n   }"}, {"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 46, "deletions": 33, "changes": 79, "file_content_changes": "@@ -1,4 +1,4 @@\n-#include \"mlir/Analysis/DataFlowAnalysis.h\"\n+#include \"mlir/Analysis/DataFlowFramework.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"llvm/Support/raw_ostream.h\"\n \n@@ -52,7 +52,7 @@ AxisInfo AxisInfo::getPessimisticValueState(Value value) {\n   BlockArgument blockArg = value.dyn_cast<BlockArgument>();\n   if (blockArg && blockArg.getOwner()->isEntryBlock()) {\n     Operation *op = blockArg.getOwner()->getParentOp();\n-    if (FuncOp fun = dyn_cast<FuncOp>(op)) {\n+    if (func::FuncOp fun = dyn_cast<func::FuncOp>(op)) {\n       Attribute attr =\n           fun.getArgAttr(blockArg.getArgNumber(), \"tt.divisibility\");\n       if (attr)\n@@ -119,8 +119,9 @@ class CastOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n public:\n   using AxisInfoVisitorImpl<OpTy>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(OpTy op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(OpTy op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     return operands[0]->getValue();\n   }\n };\n@@ -130,8 +131,9 @@ class MakeRangeOpAxisInfoVisitor final\n public:\n   using AxisInfoVisitorImpl<triton::MakeRangeOp>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(triton::MakeRangeOp op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(triton::MakeRangeOp op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     auto start = op.start();\n     auto end = op.end();\n     return AxisInfo(/*contiguity=*/{end - start},\n@@ -145,8 +147,9 @@ class ConstantOpAxisInfoVisitor final\n public:\n   using AxisInfoVisitorImpl<arith::ConstantOp>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(arith::ConstantOp op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(arith::ConstantOp op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     auto intAttr = op.getValue().dyn_cast<IntegerAttr>();\n     auto boolAttr = op.getValue().dyn_cast<BoolAttr>();\n     if (intAttr || boolAttr) {\n@@ -396,8 +399,9 @@ class SplatOpAxisInfoVisitor final\n public:\n   using AxisInfoVisitorImpl<triton::SplatOp>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(triton::SplatOp op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(triton::SplatOp op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     Type _retTy = *op->result_type_begin();\n     TensorType retTy = _retTy.cast<TensorType>();\n     AxisInfo opInfo = operands[0]->getValue();\n@@ -419,8 +423,9 @@ class ExpandDimsOpAxisInfoVisitor final\n public:\n   using AxisInfoVisitorImpl<triton::ExpandDimsOp>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(triton::ExpandDimsOp op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(triton::ExpandDimsOp op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     AxisInfo opInfo = operands[0]->getValue();\n     AxisInfo::DimVectorT contiguity = opInfo.getContiguity();\n     AxisInfo::DimVectorT divisibility = opInfo.getDivisibility();\n@@ -438,8 +443,9 @@ class BroadcastOpAxisInfoVisitor final\n public:\n   using AxisInfoVisitorImpl<triton::BroadcastOp>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(triton::BroadcastOp op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(triton::BroadcastOp op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     Type _retTy = *op->result_type_begin();\n     Type _opTy = *op->operand_type_begin();\n     TensorType retTy = _retTy.cast<TensorType>();\n@@ -466,8 +472,9 @@ class CmpOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n public:\n   using AxisInfoVisitorImpl<OpTy>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(OpTy op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(OpTy op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     auto resTy = op.getResult().getType().template dyn_cast<RankedTensorType>();\n     if (!resTy)\n       return AxisInfo();\n@@ -576,8 +583,9 @@ class SelectOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n public:\n   using AxisInfoVisitorImpl<OpTy>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(OpTy op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(OpTy op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     auto resTy = op.getResult().getType().template dyn_cast<RankedTensorType>();\n     if (!resTy)\n       return AxisInfo();\n@@ -737,8 +745,9 @@ class MaxMinOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n public:\n   using AxisInfoVisitorImpl<OpTy>::AxisInfoVisitorImpl;\n \n-  AxisInfo getAxisInfo(OpTy op,\n-                       ArrayRef<LatticeElement<AxisInfo> *> operands) override {\n+  AxisInfo\n+  getAxisInfo(OpTy op,\n+              ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n     auto lhsInfo = operands[0]->getValue();\n     auto rhsInfo = operands[1]->getValue();\n     std::optional<int64_t> constantValue;\n@@ -766,8 +775,8 @@ class MaxMinOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n // AxisInfoAnalysis\n //===----------------------------------------------------------------------===//\n \n-AxisInfoAnalysis::AxisInfoAnalysis(MLIRContext *context)\n-    : ForwardDataFlowAnalysis<AxisInfo>(context) {\n+AxisInfoAnalysis::AxisInfoAnalysis(DataFlowSolver &solver)\n+    : dataflow::SparseDataFlowAnalysis<dataflow::Lattice<AxisInfo>>(solver) {\n   // UnrealizedConversionCast:\n   // This is needed by TritonGPUToLLVM, to get AxisInfo when the graph is\n   // in the process of a PartialConversion, where UnrealizedConversionCast\n@@ -799,7 +808,7 @@ AxisInfoAnalysis::AxisInfoAnalysis(MLIRContext *context)\n   visitors.append<LogicalOpAxisInfoVisitor<arith::AndIOp>,\n                   LogicalOpAxisInfoVisitor<arith::OrIOp>,\n                   LogicalOpAxisInfoVisitor<arith::XOrIOp>>();\n-  visitors.append<SelectOpAxisInfoVisitor<mlir::SelectOp>,\n+  visitors.append<SelectOpAxisInfoVisitor<mlir::arith::SelectOp>,\n                   SelectOpAxisInfoVisitor<triton::gpu::SelectOp>>();\n   visitors.append<ShLIOpAxisInfoVisitor, ShROpAxisInfoVisitor<arith::ShRUIOp>,\n                   ShROpAxisInfoVisitor<arith::ShRSIOp>>();\n@@ -809,19 +818,17 @@ AxisInfoAnalysis::AxisInfoAnalysis(MLIRContext *context)\n                   MaxMinOpAxisInfoVisitor<arith::MinUIOp>>();\n }\n \n-ChangeResult AxisInfoAnalysis::visitOperation(\n-    Operation *op, ArrayRef<LatticeElement<AxisInfo> *> operands) {\n+void AxisInfoAnalysis::visitOperation(\n+    Operation *op, ArrayRef<const dataflow::Lattice<AxisInfo> *> operands,\n+    ArrayRef<dataflow::Lattice<AxisInfo> *> results) {\n   AxisInfo curr = visitors.apply(op, operands);\n   if (curr.getRank() == 0) {\n-    return markAllPessimisticFixpoint(op->getResults());\n+    return markAllPessimisticFixpoint(results);\n   }\n \n   // join all lattice elements\n-  ChangeResult result = ChangeResult::NoChange;\n-  for (Value value : op->getResults()) {\n-    result |= getLatticeElement(value).join(curr);\n-  }\n-  return result;\n+  for (auto *result : results)\n+    propagateIfChanged(result, result->join(curr));\n }\n \n unsigned AxisInfoAnalysis::getPtrContiguity(Value ptr) {\n@@ -847,7 +854,10 @@ unsigned AxisInfoAnalysis::getPtrAlignment(Value ptr) {\n   auto tensorTy = ptr.getType().dyn_cast<RankedTensorType>();\n   if (!tensorTy)\n     return 1;\n-  auto axisInfo = lookupLatticeElement(ptr)->getValue();\n+  dataflow::Lattice<AxisInfo> *latticeElement = getLatticeElement(ptr);\n+  if (!latticeElement || latticeElement->isUninitialized())\n+    return 1;\n+  auto axisInfo = latticeElement->getValue();\n   auto layout = tensorTy.getEncoding();\n   auto order = triton::gpu::getOrder(layout);\n   auto maxMultiple = axisInfo.getDivisibility(order[0]);\n@@ -860,8 +870,11 @@ unsigned AxisInfoAnalysis::getMaskAlignment(Value mask) {\n   auto tensorTy = mask.getType().dyn_cast<RankedTensorType>();\n   if (!tensorTy)\n     return 1;\n+  dataflow::Lattice<AxisInfo> *latticeElement = getLatticeElement(mask);\n+  if (!latticeElement || latticeElement->isUninitialized())\n+    return 1;\n+  auto maskAxis = latticeElement->getValue();\n   auto maskOrder = triton::gpu::getOrder(tensorTy.getEncoding());\n-  auto maskAxis = lookupLatticeElement(mask)->getValue();\n   auto alignment = std::max<unsigned>(maskAxis.getConstancy(maskOrder[0]), 1);\n   return alignment;\n }"}, {"filename": "lib/Analysis/CMakeLists.txt", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -8,4 +8,7 @@ add_mlir_library(TritonAnalysis\n   DEPENDS\n   TritonTableGen\n   TritonGPUAttrDefsIncGen\n+\n+  LINK_LIBS PUBLIC\n+  MLIRAnalysis\n )"}, {"filename": "lib/Analysis/Membar.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -2,7 +2,7 @@\n #include \"triton/Analysis/Alias.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n \n-#include \"mlir/Dialect/GPU/GPUDialect.h\"\n+#include \"mlir/Dialect/GPU/IR/GPUDialect.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n \n namespace mlir {"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 54, "deletions": 0, "changes": 54, "file_content_changes": "@@ -1,5 +1,8 @@\n #include \"triton/Analysis/Utility.h\"\n+#include \"mlir/Analysis/DataFlow/ConstantPropagationAnalysis.h\"\n+#include \"mlir/Analysis/DataFlow/DeadCodeAnalysis.h\"\n #include \"mlir/IR/Dialect.h\"\n+#include \"mlir/IR/Matchers.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n #include <deque>\n@@ -300,4 +303,55 @@ multiRootTopologicalSort(const SetVector<Operation *> &toSort) {\n   return res;\n }\n \n+namespace {\n+// Copied from TestDeadCodeAnalysis.cpp, because some dead code analysis\n+// interacts with constant propagation, but SparseConstantPropagation\n+// doesn't seem to be sufficient.\n+struct ConstantAnalysis : public DataFlowAnalysis {\n+  using DataFlowAnalysis::DataFlowAnalysis;\n+\n+  LogicalResult initialize(Operation *top) override {\n+    WalkResult result = top->walk([&](Operation *op) {\n+      if (failed(visit(op)))\n+        return WalkResult::interrupt();\n+      return WalkResult::advance();\n+    });\n+    return success(!result.wasInterrupted());\n+  }\n+\n+  LogicalResult visit(ProgramPoint point) override {\n+    Operation *op = point.get<Operation *>();\n+    Attribute value;\n+    if (matchPattern(op, m_Constant(&value))) {\n+      auto *constant = getOrCreate<dataflow::Lattice<dataflow::ConstantValue>>(\n+          op->getResult(0));\n+      propagateIfChanged(constant, constant->join(dataflow::ConstantValue(\n+                                       value, op->getDialect())));\n+      return success();\n+    }\n+    setAllToUnknownConstants(op->getResults());\n+    for (Region &region : op->getRegions())\n+      setAllToUnknownConstants(region.getArguments());\n+    return success();\n+  }\n+\n+  /// Set all given values as not constants.\n+  void setAllToUnknownConstants(ValueRange values) {\n+    dataflow::ConstantValue unknownConstant(nullptr, nullptr);\n+    for (Value value : values) {\n+      auto *constant =\n+          getOrCreate<dataflow::Lattice<dataflow::ConstantValue>>(value);\n+      propagateIfChanged(constant, constant->join(unknownConstant));\n+    }\n+  }\n+};\n+} // namespace\n+\n+std::unique_ptr<DataFlowSolver> createDataFlowSolver() {\n+  auto solver = std::make_unique<DataFlowSolver>();\n+  solver->load<dataflow::DeadCodeAnalysis>();\n+  solver->load<ConstantAnalysis>();\n+  return solver;\n+}\n+\n } // namespace mlir"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "file_content_changes": "@@ -159,9 +159,6 @@ struct ConvertLayoutOpConversion\n                       Value smemBase) const {\n     auto accumNumCTAsEachRep = product<unsigned>(numCTAsEachRep);\n     auto layout = type.getEncoding();\n-    auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>();\n-    auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>();\n-    auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>();\n     auto rank = type.getRank();\n     auto sizePerThread = getSizePerThread(layout);\n     auto accumSizePerThread = product<unsigned>(sizePerThread);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpHelpers.h", "status": "modified", "additions": 4, "deletions": 9, "changes": 13, "file_content_changes": "@@ -7,10 +7,8 @@\n #include \"mlir/Conversion/LLVMCommon/LoweringOptions.h\"\n #include \"mlir/Conversion/LLVMCommon/Pattern.h\"\n #include \"mlir/Conversion/MathToLLVM/MathToLLVM.h\"\n-#include \"mlir/Conversion/SCFToStandard/SCFToStandard.h\"\n-#include \"mlir/Conversion/StandardToLLVM/ConvertStandardToLLVM.h\"\n #include \"mlir/Dialect/Arithmetic/IR/Arithmetic.h\"\n-#include \"mlir/Dialect/GPU/GPUDialect.h\"\n+#include \"mlir/Dialect/GPU/IR/GPUDialect.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/Matchers.h\"\n@@ -422,8 +420,6 @@ struct DotOpMmaV1ConversionHelper {\n   computeOffsets(Value threadId, bool isARow, bool isBRow, ArrayRef<int> fpw,\n                  ArrayRef<int> spw, ArrayRef<int> rep,\n                  ConversionPatternRewriter &rewriter, Location loc) const {\n-    auto *ctx = rewriter.getContext();\n-    Value _1 = i32_val(1);\n     Value _3 = i32_val(3);\n     Value _4 = i32_val(4);\n     Value _16 = i32_val(16);\n@@ -464,7 +460,6 @@ struct DotOpMmaV1ConversionHelper {\n     Value offsetBN = add(warpNOff, laneNOff);\n     Value offsetBK = and_(lane, _3);\n     // i indices\n-    Value offsetCM = add(and_(lane, _1), offsetAM);\n     if (isARow) {\n       offsetAM = add(offsetAM, urem(threadId, _4));\n       offsetAK = i32_val(0);\n@@ -1314,9 +1309,9 @@ struct MMA16816ConversionHelper {\n   MMA16816ConversionHelper(Type dotOperand, MmaEncodingAttr mmaLayout,\n                            Value thread, ConversionPatternRewriter &rewriter,\n                            TypeConverter *typeConverter, Location loc)\n-      : mmaLayout(mmaLayout), thread(thread), helper(mmaLayout),\n-        rewriter(rewriter), typeConverter(typeConverter), loc(loc),\n-        ctx(mmaLayout.getContext()), wpt(mmaLayout.getWarpsPerCTA()) {\n+      : mmaLayout(mmaLayout), wpt(mmaLayout.getWarpsPerCTA()), thread(thread),\n+        helper(mmaLayout), rewriter(rewriter), typeConverter(typeConverter),\n+        loc(loc), ctx(mmaLayout.getContext()) {\n     helper.deduceMmaType(dotOperand);\n \n     Value _32 = i32_val(32);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "file_content_changes": "@@ -115,8 +115,6 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n     auto DTensorTy = D.getType().cast<RankedTensorType>();\n     auto AShape = ATensorTy.getShape();\n     auto BShape = BTensorTy.getShape();\n-    auto DShape = DTensorTy.getShape();\n-    auto wpt = mmaLayout.getWarpsPerCTA();\n \n     bool isARow = ALayout.getIsMMAv1Row().cast<BoolAttr>().getValue();\n     bool isBRow = BLayout.getIsMMAv1Row().cast<BoolAttr>().getValue();\n@@ -221,7 +219,6 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n                               ConversionPatternRewriter &rewriter) const {\n     auto *ctx = rewriter.getContext();\n     auto loc = op.getLoc();\n-    auto threadId = getThreadId(rewriter, loc);\n \n     auto A = op.a();\n     auto B = op.b();\n@@ -230,12 +227,10 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n \n     auto aTensorTy = A.getType().cast<RankedTensorType>();\n     auto bTensorTy = B.getType().cast<RankedTensorType>();\n-    auto cTensorTy = C.getType().cast<RankedTensorType>();\n     auto dTensorTy = D.getType().cast<RankedTensorType>();\n \n     auto aShape = aTensorTy.getShape();\n     auto bShape = bTensorTy.getShape();\n-    auto cShape = cTensorTy.getShape();\n \n     BlockedEncodingAttr dLayout =\n         dTensorTy.getEncoding().cast<BlockedEncodingAttr>();"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -61,7 +61,6 @@ struct FpToFpOpConversion\n   convertFp16x4ToFp8x4(Location loc, ConversionPatternRewriter &rewriter,\n                        const Value &v0, const Value &v1, const Value &v2,\n                        const Value &v3) {\n-    auto ctx = rewriter.getContext();\n     auto fp16x2VecTy = vec_ty(f16_ty, 2);\n     Value fp16x2Vec0 = undef(fp16x2VecTy);\n     Value fp16x2Vec1 = undef(fp16x2VecTy);\n@@ -153,7 +152,6 @@ struct FpToFpOpConversion\n   convertBf16x4ToFp8x4(Location loc, ConversionPatternRewriter &rewriter,\n                        const Value &v0, const Value &v1, const Value &v2,\n                        const Value &v3) {\n-    auto ctx = rewriter.getContext();\n     auto bf16x2VecTy = vec_ty(i16_ty, 2);\n     Value bf16x2Vec0 = undef(bf16x2VecTy);\n     Value bf16x2Vec1 = undef(bf16x2VecTy);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -114,7 +114,8 @@ struct LoadOpConversion\n     DenseElementsAttr constAttr;\n     int64_t splatVal = 0;\n     if (other && valueElemTy.isa<IntegerType>() &&\n-        matchPattern(other, m_Constant(&constAttr)) && constAttr.isSplat()) {\n+        matchPattern(other, m_Constant(&constAttr)) && constAttr.isSplat() &&\n+        constAttr.getElementType().isa<IntegerType>()) {\n       otherIsSplatConstInt = true;\n       splatVal = constAttr.getSplatValue<APInt>().getSExtValue();\n     }\n@@ -338,7 +339,6 @@ struct StoreOpConversion\n             elem = rewriter.create<LLVM::SExtOp>(loc, type::i8Ty(ctx), elem);\n           elem = bitcast(elem, valueElemTy);\n \n-          Type u32Ty = typeConverter->convertType(type::u32Ty(ctx));\n           llWord = insert_element(wordTy, llWord, elem, i32_val(elemIdx));\n         }\n         llWord = bitcast(llWord, valArgTy);\n@@ -392,7 +392,6 @@ struct AtomicCASOpConversion\n                   ConversionPatternRewriter &rewriter) const override {\n     auto loc = op.getLoc();\n     MLIRContext *ctx = rewriter.getContext();\n-    Value ptr = op.ptr();\n \n     Value llPtr = adaptor.ptr();\n     Value llCmp = adaptor.cmp();"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -286,7 +286,6 @@ struct ReduceOpConversion\n     auto srcTy = op.operand().getType().cast<RankedTensorType>();\n     auto srcLayout = srcTy.getEncoding();\n     auto srcShape = srcTy.getShape();\n-    auto srcRank = srcTy.getRank();\n     auto order = getOrder(srcLayout);\n \n     auto threadsPerWarp = triton::gpu::getThreadsPerWarp(srcLayout);\n@@ -351,7 +350,6 @@ struct ReduceOpConversion\n \n     Value zero = i32_val(0);\n     Value laneZero = icmp_eq(laneIdAxis, zero);\n-    Value warpZero = icmp_eq(warpIdAxis, zero);\n \n     for (auto it : accs) {\n       const SmallVector<unsigned> &key = it.first;"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "file_content_changes": "@@ -11,11 +11,11 @@ using ::mlir::LLVM::getStructFromElements;\n using ::mlir::triton::gpu::getElemsPerThread;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n-struct ReturnOpConversion : public ConvertOpToLLVMPattern<::mlir::ReturnOp> {\n-  using ConvertOpToLLVMPattern<ReturnOp>::ConvertOpToLLVMPattern;\n+struct ReturnOpConversion : public ConvertOpToLLVMPattern<func::ReturnOp> {\n+  using ConvertOpToLLVMPattern<func::ReturnOp>::ConvertOpToLLVMPattern;\n \n   LogicalResult\n-  matchAndRewrite(ReturnOp op, OpAdaptor adaptor,\n+  matchAndRewrite(func::ReturnOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     unsigned numArguments = op.getNumOperands();\n \n@@ -505,7 +505,6 @@ struct ExtractSliceOpConversion\n \n     auto llvmElemTy = getTypeConverter()->convertType(srcTy.getElementType());\n     auto elemPtrTy = ptr_ty(llvmElemTy, 3);\n-    auto resTy = op.getType().dyn_cast<RankedTensorType>();\n     smemObj = SharedMemoryObject(gep(elemPtrTy, smemObj.base, offset),\n                                  strideVals, offsetVals);\n     auto retVal = getStructFromSharedMemoryObject(loc, smemObj, rewriter);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 15, "deletions": 14, "changes": 29, "file_content_changes": "@@ -4,12 +4,14 @@\n // TODO: refactor so that it doesn't fail if Allocation.h\n // is included after utility.h (due to conflict in `store` macro\n // and <atomic>\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"triton/Analysis/Allocation.h\"\n \n //\n-#include \"Utility.h\"\n #include \"mlir/IR/TypeUtilities.h\"\n #include \"triton/Analysis/AxisInfo.h\"\n+// Needs to be last because of load macro.\n+#include \"Utility.h\"\n \n using namespace mlir;\n using namespace mlir::triton;\n@@ -38,15 +40,15 @@ void vprintf_array(Value thread, ArrayRef<Value> arr, std::string info,\n // TODO(Superjomn): remove the code when MLIR v15.0 is included.\n // All the rights are reserved by the LLVM community.\n \n-struct FuncOpConversionBase : public ConvertOpToLLVMPattern<FuncOp> {\n+struct FuncOpConversionBase : public ConvertOpToLLVMPattern<func::FuncOp> {\n private:\n   /// Only retain those attributes that are not constructed by\n   /// `LLVMFuncOp::build`. If `filterArgAttrs` is set, also filter out argument\n   /// attributes.\n-  static void filterFuncAttributes(ArrayRef<NamedAttribute> attrs,\n-                                   bool filterArgAttrs,\n+  static void filterFuncAttributes(func::FuncOp op, bool filterArgAttrs,\n                                    SmallVectorImpl<NamedAttribute> &result) {\n-    for (const auto &attr : attrs) {\n+\n+    for (const auto &attr : op->getAttrs()) {\n       if (attr.getName() == SymbolTable::getSymbolAttrName() ||\n           attr.getName() == FunctionOpInterface::getTypeAttrName() ||\n           attr.getName() == \"std.varargs\" ||\n@@ -64,27 +66,27 @@ struct FuncOpConversionBase : public ConvertOpToLLVMPattern<FuncOp> {\n   }\n \n protected:\n-  using ConvertOpToLLVMPattern<FuncOp>::ConvertOpToLLVMPattern;\n+  using ConvertOpToLLVMPattern<func::FuncOp>::ConvertOpToLLVMPattern;\n \n   // Convert input FuncOp to LLVMFuncOp by using the LLVMTypeConverter provided\n   // to this legalization pattern.\n   LLVM::LLVMFuncOp\n-  convertFuncOpToLLVMFuncOp(FuncOp funcOp,\n+  convertFuncOpToLLVMFuncOp(func::FuncOp funcOp,\n                             ConversionPatternRewriter &rewriter) const {\n     // Convert the original function arguments. They are converted using the\n     // LLVMTypeConverter provided to this legalization pattern.\n     auto varargsAttr = funcOp->getAttrOfType<BoolAttr>(\"func.varargs\");\n     TypeConverter::SignatureConversion result(funcOp.getNumArguments());\n     auto llvmType = getTypeConverter()->convertFunctionSignature(\n-        funcOp.getType(), varargsAttr && varargsAttr.getValue(), result);\n+        funcOp.getFunctionType(), varargsAttr && varargsAttr.getValue(),\n+        result);\n     if (!llvmType)\n       return nullptr;\n \n     // Propagate argument/result attributes to all converted arguments/result\n     // obtained after converting a given original argument/result.\n     SmallVector<NamedAttribute, 4> attributes;\n-    filterFuncAttributes(funcOp->getAttrs(), /*filterArgAttrs=*/true,\n-                         attributes);\n+    filterFuncAttributes(funcOp, /*filterArgAttrs=*/true, attributes);\n     if (ArrayAttr resAttrDicts = funcOp.getAllResultAttrs()) {\n       assert(!resAttrDicts.empty() && \"expected array to be non-empty\");\n       auto newResAttrDicts =\n@@ -130,7 +132,7 @@ struct FuncOpConversionBase : public ConvertOpToLLVMPattern<FuncOp> {\n     }\n     auto newFuncOp = rewriter.create<LLVM::LLVMFuncOp>(\n         funcOp.getLoc(), funcOp.getName(), llvmType, linkage,\n-        /*dsoLocal*/ false, attributes);\n+        /*dsoLocal*/ false, LLVM::CConv::C, attributes);\n     rewriter.inlineRegionBefore(funcOp.getBody(), newFuncOp.getBody(),\n                                 newFuncOp.end());\n     if (failed(rewriter.convertRegionTypes(&newFuncOp.getBody(), *typeConverter,\n@@ -190,8 +192,8 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n                                                const Allocation *allocation,\n                                                Value smem,\n                                                IndexCacheInfo indexCacheInfo)\n-      : converter(&typeConverter), indexCacheInfo(indexCacheInfo),\n-        allocation(allocation), smem(smem) {}\n+      : converter(&typeConverter), allocation(allocation), smem(smem),\n+        indexCacheInfo(indexCacheInfo) {}\n \n   LLVMTypeConverter *getTypeConverter() const { return converter; }\n \n@@ -796,7 +798,6 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n                             ArrayRef<int64_t> shape) const {\n     auto parent = sliceLayout.getParent();\n     unsigned dim = sliceLayout.getDim();\n-    size_t rank = shape.size();\n     auto parentIndices =\n         emitIndices(loc, rewriter, parent, sliceLayout.paddedShape(shape));\n     unsigned numIndices = parentIndices.size();"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 29, "deletions": 23, "changes": 52, "file_content_changes": "@@ -1,10 +1,11 @@\n #include \"triton/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.h\"\n \n+#include \"mlir/Analysis/DataFlowFramework.h\"\n #include \"mlir/Conversion/ArithmeticToLLVM/ArithmeticToLLVM.h\"\n+#include \"mlir/Conversion/ControlFlowToLLVM//ControlFlowToLLVM.h\"\n #include \"mlir/Conversion/GPUToNVVM/GPUToNVVMPass.h\"\n #include \"mlir/Conversion/MathToLLVM/MathToLLVM.h\"\n-#include \"mlir/Conversion/SCFToStandard/SCFToStandard.h\"\n-#include \"mlir/Conversion/StandardToLLVM/ConvertStandardToLLVM.h\"\n+#include \"mlir/Conversion/SCFToControlFlow/SCFToControlFlow.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n #include \"mlir/Pass/Pass.h\"\n@@ -40,7 +41,6 @@ class TritonLLVMConversionTarget : public ConversionTarget {\n     addIllegalDialect<triton::TritonDialect>();\n     addIllegalDialect<triton::gpu::TritonGPUDialect>();\n     addIllegalDialect<mlir::gpu::GPUDialect>();\n-    addIllegalDialect<mlir::StandardOpsDialect>();\n     addLegalOp<mlir::UnrealizedConversionCastOp>();\n   }\n };\n@@ -51,7 +51,7 @@ class TritonLLVMFunctionConversionTarget : public ConversionTarget {\n       : ConversionTarget(ctx) {\n     addLegalDialect<LLVM::LLVMDialect>();\n     addLegalDialect<NVVM::NVVMDialect>();\n-    addIllegalOp<mlir::FuncOp>();\n+    addIllegalOp<mlir::func::FuncOp>();\n     addLegalOp<mlir::UnrealizedConversionCastOp>();\n   }\n };\n@@ -69,7 +69,7 @@ struct FuncOpConversion : public FuncOpConversionBase {\n       : FuncOpConversionBase(converter, benefit), numWarps(numWarps) {}\n \n   LogicalResult\n-  matchAndRewrite(FuncOp funcOp, OpAdaptor adaptor,\n+  matchAndRewrite(func::FuncOp funcOp, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     auto newFuncOp = convertFuncOpToLLVMFuncOp(funcOp, rewriter);\n     if (!newFuncOp)\n@@ -133,7 +133,8 @@ class ConvertTritonGPUToLLVM\n     decomposeBlockedToDotOperand(mod);\n \n     // Step 2\n-    decomposeInsertSliceAsyncOp(mod);\n+    if (failed(decomposeInsertSliceAsyncOp(mod)))\n+      return signalPassFailure();\n \n     // Step 3\n     Allocation allocation(mod);\n@@ -142,7 +143,7 @@ class ConvertTritonGPUToLLVM\n \n     // Step 4\n     RewritePatternSet scf_patterns(context);\n-    mlir::populateLoopToStdConversionPatterns(scf_patterns);\n+    mlir::populateSCFToControlFlowConversionPatterns(scf_patterns);\n     mlir::ConversionTarget scf_target(*context);\n     scf_target.addIllegalOp<scf::ForOp, scf::IfOp, scf::ParallelOp,\n                             scf::WhileOp, scf::ExecuteRegionOp>();\n@@ -159,8 +160,10 @@ class ConvertTritonGPUToLLVM\n       return signalPassFailure();\n \n     // Step 6 - get axis and shared memory info\n-    AxisInfoAnalysis axisInfoAnalysis(mod.getContext());\n-    axisInfoAnalysis.run(mod);\n+    std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n+    AxisInfoAnalysis *axisInfoAnalysis = solver->load<AxisInfoAnalysis>();\n+    if (failed(solver->initializeAndRun(mod)))\n+      return signalPassFailure();\n     initSharedMemory(allocation.getSharedMemorySize(), typeConverter);\n     mod->setAttr(\"triton_gpu.shared\",\n                  mlir::IntegerAttr::get(mlir::IntegerType::get(context, 32),\n@@ -178,38 +181,39 @@ class ConvertTritonGPUToLLVM\n \n     // Normal conversions\n     populateTritonGPUToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                    axisInfoAnalysis, &allocation, smem,\n+                                    *axisInfoAnalysis, &allocation, smem,\n                                     indexCacheInfo, /*benefit=*/10);\n     // ConvertLayoutOp\n     populateConvertLayoutOpToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                          axisInfoAnalysis, &allocation, smem,\n+                                          *axisInfoAnalysis, &allocation, smem,\n                                           indexCacheInfo, /*benefit=*/10);\n     // DotOp\n     populateDotOpToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                axisInfoAnalysis, &allocation, smem,\n+                                *axisInfoAnalysis, &allocation, smem,\n                                 /*benefit=*/10);\n     // ElementwiseOp\n     populateElementwiseOpToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                        axisInfoAnalysis, &allocation, smem,\n+                                        *axisInfoAnalysis, &allocation, smem,\n                                         /*benefit=*/10);\n     // LoadStoreOp\n     populateLoadStoreOpToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                      axisInfoAnalysis, &allocation, smem,\n+                                      *axisInfoAnalysis, &allocation, smem,\n                                       indexCacheInfo, /*benefit=*/10);\n     // ReduceOp\n     populateReduceOpToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                   axisInfoAnalysis, &allocation, smem,\n+                                   *axisInfoAnalysis, &allocation, smem,\n                                    indexCacheInfo, /*benefit=*/10);\n     // ViewOp\n     populateViewOpToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                 axisInfoAnalysis, &allocation, smem,\n+                                 *axisInfoAnalysis, &allocation, smem,\n                                  /*benefit=*/10);\n \n     // Add arith/math's patterns to help convert scalar expression to LLVM.\n     mlir::arith::populateArithmeticToLLVMConversionPatterns(typeConverter,\n                                                             patterns);\n     mlir::populateMathToLLVMConversionPatterns(typeConverter, patterns);\n-    mlir::populateStdToLLVMConversionPatterns(typeConverter, patterns);\n+    mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n+                                                          patterns);\n     mlir::populateGpuToNVVMConversionPatterns(typeConverter, patterns);\n \n     if (failed(applyPartialConversion(mod, target, std::move(patterns))))\n@@ -306,9 +310,11 @@ class ConvertTritonGPUToLLVM\n     });\n   }\n \n-  void decomposeInsertSliceAsyncOp(ModuleOp mod) const {\n-    AxisInfoAnalysis axisInfoAnalysis(mod.getContext());\n-    axisInfoAnalysis.run(mod);\n+  LogicalResult decomposeInsertSliceAsyncOp(ModuleOp mod) const {\n+    std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n+    AxisInfoAnalysis *axisInfoAnalysis = solver->load<AxisInfoAnalysis>();\n+    if (failed(solver->initializeAndRun(mod)))\n+      return failure();\n     // TODO(Keren): This is a hacky knob that may cause performance regression\n     // when decomposition has been performed. We should remove this knob once we\n     // have thorough analysis on async wait. Currently, we decompose\n@@ -342,7 +348,7 @@ class ConvertTritonGPUToLLVM\n       auto resSharedLayout =\n           dstTy.getEncoding().dyn_cast<triton::gpu::SharedEncodingAttr>();\n       auto resElemTy = dstTy.getElementType();\n-      unsigned inVec = axisInfoAnalysis.getPtrContiguity(src);\n+      unsigned inVec = axisInfoAnalysis->getPtrContiguity(src);\n       unsigned outVec = resSharedLayout.getVec();\n       unsigned minVec = std::min(outVec, inVec);\n       auto maxBitWidth =\n@@ -400,11 +406,11 @@ class ConvertTritonGPUToLLVM\n       } else if (decomposed) {\n         // Wait for all previous async ops\n         OpBuilder builder(asyncWaitOp);\n-        auto newAsyncWaitOp =\n-            builder.create<triton::gpu::AsyncWaitOp>(asyncWaitOp.getLoc(), 0);\n+        builder.create<triton::gpu::AsyncWaitOp>(asyncWaitOp.getLoc(), 0);\n         asyncWaitOp.erase();\n       }\n     });\n+    return success();\n   }\n };\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/Utility.h", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "file_content_changes": "@@ -220,10 +220,7 @@ struct SharedMemoryObject {\n                      ConversionPatternRewriter &rewriter)\n       : base(base) {\n     strides = getStridesFromShapeAndOrder(shape, order, loc, rewriter);\n-\n-    for (auto idx : order) {\n-      offsets.emplace_back(i32_val(0));\n-    }\n+    offsets.append(order.size(), i32_val(0));\n   }\n \n   SmallVector<Value> getElems() const {"}, {"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 36, "deletions": 33, "changes": 69, "file_content_changes": "@@ -1,10 +1,10 @@\n #include \"triton/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.h\"\n \n #include \"mlir/Dialect/Arithmetic/IR/Arithmetic.h\"\n-#include \"mlir/Dialect/GPU/GPUDialect.h\"\n+#include \"mlir/Dialect/ControlFlow/IR/ControlFlowOps.h\"\n+#include \"mlir/Dialect/GPU/IR/GPUDialect.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n-#include \"mlir/Dialect/StandardOps/IR/Ops.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Transforms/DialectConversion.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n@@ -59,10 +59,13 @@ class ArithConstantPattern : public OpConversionPattern<arith::ConstantOp> {\n     Type retType = getTypeConverter()->convertType(op.getType());\n     auto value = adaptor.getValue().dyn_cast<DenseElementsAttr>();\n     assert(value);\n-    rewriter.replaceOpWithNewOp<arith::ConstantOp>(\n-        op, retType,\n-        value.reshape(retType) // This is a hack. We just want to add encoding\n-    );\n+    if (value.getElementType().isInteger(1) && value.isSplat())\n+      // Workaround until https://reviews.llvm.org/D133743 is included.\n+      value = DenseElementsAttr::get(retType, value.getSplatValue<bool>());\n+    else\n+      // This is a hack. We just want to add encoding\n+      value = value.reshape(retType);\n+    rewriter.replaceOpWithNewOp<arith::ConstantOp>(op, retType, value);\n     return success();\n   }\n };\n@@ -127,12 +130,12 @@ void populateArithmeticPatternsAndLegality(\n }\n \n // this shouldn't exist if mlir's SelectOp checked encodings properly\n-class StdSelectPattern : public OpConversionPattern<SelectOp> {\n+class StdSelectPattern : public OpConversionPattern<arith::SelectOp> {\n public:\n-  using OpConversionPattern<SelectOp>::OpConversionPattern;\n+  using OpConversionPattern<arith::SelectOp>::OpConversionPattern;\n \n   LogicalResult\n-  matchAndRewrite(SelectOp op, typename SelectOp::Adaptor adaptor,\n+  matchAndRewrite(arith::SelectOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Type retType = this->getTypeConverter()->convertType(op.getType());\n     rewriter.replaceOpWithNewOp<triton::gpu::SelectOp>(\n@@ -148,8 +151,8 @@ void populateStdPatternsAndLegality(TritonGPUTypeConverter &typeConverter,\n   MLIRContext *context = patterns.getContext();\n   // Rewrite rule\n   patterns.add<StdSelectPattern>(typeConverter, context);\n-  target.addLegalOp<ReturnOp>(); // this is ok because all functions are inlined\n-                                 // by the frontend\n+  target.addLegalOp<func::ReturnOp>(); // this is ok because all functions are\n+                                       // inlined by the frontend\n }\n \n void populateMathPatternsAndLegality(TritonGPUTypeConverter &typeConverter,\n@@ -454,18 +457,19 @@ struct TritonPrintfPattern : public OpConversionPattern<triton::PrintfOp> {\n void populateTritonPatterns(TritonGPUTypeConverter &typeConverter,\n                             RewritePatternSet &patterns) {\n   MLIRContext *context = patterns.getContext();\n-  patterns.add< // TODO: view should have custom pattern that views the layout\n-      TritonGenericPattern<triton::ViewOp>,\n-      TritonGenericPattern<triton::BitcastOp>,\n-      TritonGenericPattern<triton::FpToFpOp>,\n-      TritonGenericPattern<triton::IntToPtrOp>,\n-      TritonGenericPattern<triton::PtrToIntOp>,\n-      TritonGenericPattern<triton::SplatOp>, TritonBroadcastPattern,\n-      TritonGenericPattern<triton::AddPtrOp>, TritonCatPattern,\n-      TritonReducePattern, TritonTransPattern, TritonExpandDimsPattern,\n-      TritonMakeRangePattern, TritonDotPattern, TritonLoadPattern,\n-      TritonStorePattern, TritonExtElemwisePattern, TritonPrintfPattern,\n-      TritonAtomicRMWPattern>(typeConverter, context);\n+  patterns\n+      .insert< // TODO: view should have custom pattern that views the layout\n+          TritonGenericPattern<triton::ViewOp>,\n+          TritonGenericPattern<triton::BitcastOp>,\n+          TritonGenericPattern<triton::FpToFpOp>,\n+          TritonGenericPattern<triton::IntToPtrOp>,\n+          TritonGenericPattern<triton::PtrToIntOp>,\n+          TritonGenericPattern<triton::SplatOp>, TritonBroadcastPattern,\n+          TritonGenericPattern<triton::AddPtrOp>, TritonCatPattern,\n+          TritonReducePattern, TritonTransPattern, TritonExpandDimsPattern,\n+          TritonMakeRangePattern, TritonDotPattern, TritonLoadPattern,\n+          TritonStorePattern, TritonExtElemwisePattern, TritonPrintfPattern,\n+          TritonAtomicRMWPattern>(typeConverter, context);\n }\n \n //\n@@ -622,29 +626,28 @@ void populateSCFPatterns(TritonGPUTypeConverter &typeConverter,\n \n // CF\n \n-class CFBranchPattern : public OpConversionPattern<BranchOp> {\n+class CFBranchPattern : public OpConversionPattern<cf::BranchOp> {\n public:\n-  using OpConversionPattern<BranchOp>::OpConversionPattern;\n+  using OpConversionPattern<cf::BranchOp>::OpConversionPattern;\n \n   LogicalResult\n-  matchAndRewrite(BranchOp op, BranchOp::Adaptor adaptor,\n+  matchAndRewrite(cf::BranchOp op, cf::BranchOp::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    auto converter = getTypeConverter();\n-    auto newOp = rewriter.replaceOpWithNewOp<BranchOp>(op, op.getSuccessor(),\n-                                                       adaptor.getOperands());\n+    auto newOp = rewriter.replaceOpWithNewOp<cf::BranchOp>(\n+        op, op.getSuccessor(), adaptor.getOperands());\n     return success();\n   }\n };\n \n-class CFCondBranchPattern : public OpConversionPattern<CondBranchOp> {\n+class CFCondBranchPattern : public OpConversionPattern<cf::CondBranchOp> {\n public:\n-  using OpConversionPattern<CondBranchOp>::OpConversionPattern;\n+  using OpConversionPattern<cf::CondBranchOp>::OpConversionPattern;\n \n   LogicalResult\n-  matchAndRewrite(CondBranchOp op, CondBranchOp::Adaptor adaptor,\n+  matchAndRewrite(cf::CondBranchOp op, cf::CondBranchOp::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     auto converter = getTypeConverter();\n-    auto newOp = rewriter.replaceOpWithNewOp<CondBranchOp>(\n+    auto newOp = rewriter.replaceOpWithNewOp<cf::CondBranchOp>(\n         op, adaptor.getCondition(), op.getTrueDest(),\n         adaptor.getTrueDestOperands(), op.getFalseDest(),\n         adaptor.getFalseDestOperands());"}, {"filename": "lib/Dialect/Triton/IR/CMakeLists.txt", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "file_content_changes": "@@ -10,11 +10,7 @@ add_mlir_dialect_library(TritonIR\n \n   LINK_LIBS PUBLIC\n   MLIRIR\n-  MLIRArithmetic\n-  MLIRSCF\n-\n-  # Since LLVM 15\n-  # MLIRFunc\n-  # else\n-  MLIRStandard\n+  MLIRArithmeticDialect\n+  MLIRSCFDialect\n+  MLIRFuncDialect\n )"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "file_content_changes": "@@ -1,10 +1,9 @@\n-#include \"triton/Dialect/Triton/IR/Dialect.h\"\n-#include \"triton/Dialect/Triton/IR/Types.h\"\n-\n #include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/OperationSupport.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"triton/Dialect/Triton/IR/Types.h\"\n \n namespace mlir {\n namespace triton {\n@@ -38,8 +37,8 @@ static Type getPointerTypeSameShape(Type type) {\n }\n \n // Parser & printer for assembly forms\n-ParseResult parseLoadOp(OpAsmParser &parser, OperationState &result) {\n-  SmallVector<OpAsmParser::OperandType, 4> allOperands;\n+ParseResult LoadOp::parse(OpAsmParser &parser, OperationState &result) {\n+  SmallVector<OpAsmParser::UnresolvedOperand, 4> allOperands;\n   Type resultTypes[1];\n   SMLoc allOperandLoc = parser.getCurrentLocation();\n   if (parser.parseOperandList(allOperands) ||\n@@ -73,18 +72,18 @@ ParseResult parseLoadOp(OpAsmParser &parser, OperationState &result) {\n   return success();\n }\n \n-void printLoadOp(OpAsmPrinter &printer, LoadOp loadOp) {\n+void LoadOp::print(OpAsmPrinter &printer) {\n   printer << \" \";\n-  printer << loadOp.getOperation()->getOperands();\n+  printer << getOperation()->getOperands();\n   // \"operand_segment_sizes\" can be deduced, so we don't print it.\n-  printer.printOptionalAttrDict(loadOp->getAttrs(),\n-                                {loadOp.operand_segment_sizesAttrName()});\n+  printer.printOptionalAttrDict(getOperation()->getAttrs(),\n+                                {operand_segment_sizesAttrName()});\n   printer << \" : \";\n-  printer.printStrippedAttrOrType(loadOp.result().getType());\n+  printer.printStrippedAttrOrType(getResult().getType());\n }\n \n-ParseResult parseStoreOp(OpAsmParser &parser, OperationState &result) {\n-  SmallVector<OpAsmParser::OperandType, 4> allOperands;\n+ParseResult StoreOp::parse(OpAsmParser &parser, OperationState &result) {\n+  SmallVector<OpAsmParser::UnresolvedOperand, 4> allOperands;\n   Type valueType;\n   SMLoc allOperandLoc = parser.getCurrentLocation();\n   if (parser.parseOperandList(allOperands) ||\n@@ -104,12 +103,12 @@ ParseResult parseStoreOp(OpAsmParser &parser, OperationState &result) {\n   return success();\n }\n \n-void printStoreOp(OpAsmPrinter &printer, StoreOp storeOp) {\n+void StoreOp::print(OpAsmPrinter &printer) {\n   printer << \" \";\n-  printer << storeOp.getOperation()->getOperands();\n-  printer.printOptionalAttrDict(storeOp->getAttrs(), /*elidedAttrs=*/{});\n+  printer << getOperation()->getOperands();\n+  printer.printOptionalAttrDict(getOperation()->getAttrs(), /*elidedAttrs=*/{});\n   printer << \" : \";\n-  printer.printStrippedAttrOrType(storeOp.value().getType());\n+  printer.printStrippedAttrOrType(value().getType());\n }\n \n } // namespace triton\n@@ -316,7 +315,8 @@ OpFoldResult SplatOp::fold(ArrayRef<Attribute> operands) {\n   if (!constOperand)\n     return {};\n   auto shapedType = getType().cast<ShapedType>();\n-  auto ret = SplatElementsAttr::get(shapedType, {constOperand.getValue()});\n+  auto ret = SplatElementsAttr::get(\n+      shapedType, ArrayRef<Attribute>(constOperand.getValue()));\n   return ret;\n }\n "}, {"filename": "lib/Dialect/Triton/Transforms/Combine.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -57,13 +57,13 @@ DenseElementsAttr getConstantValue(Builder &builder, Attribute value,\n class CombineSelectMaskedLoadPattern : public mlir::RewritePattern {\n public:\n   CombineSelectMaskedLoadPattern(mlir::MLIRContext *context)\n-      : mlir::RewritePattern(mlir::SelectOp::getOperationName(), 3, context,\n-                             {triton::LoadOp::getOperationName()}) {}\n+      : mlir::RewritePattern(mlir::arith::SelectOp::getOperationName(), 3,\n+                             context, {triton::LoadOp::getOperationName()}) {}\n \n   mlir::LogicalResult\n   matchAndRewrite(mlir::Operation *op,\n                   mlir::PatternRewriter &rewriter) const override {\n-    auto selectOp = llvm::dyn_cast<mlir::SelectOp>(op);\n+    auto selectOp = llvm::dyn_cast<mlir::arith::SelectOp>(op);\n     if (!selectOp)\n       return mlir::failure();\n "}, {"filename": "lib/Dialect/Triton/Transforms/Combine.td", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,9 +1,9 @@\n #ifndef TRITON_PATTERNS\n #define TRITON_PATTERNS\n \n-include \"mlir/Dialect/StandardOps/IR/Ops.td\"\n include \"mlir/Dialect/Arithmetic/IR/ArithmeticOps.td\"\n include \"triton/Dialect/Triton/IR/TritonOps.td\"\n+include \"mlir/IR/PatternBase.td\"\n \n \n // AddIOp(DotOp(a, b, c), d) and c==0 => DotOp(a, b, d)"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 12, "deletions": 15, "changes": 27, "file_content_changes": "@@ -1,14 +1,14 @@\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+\n #include <numeric>\n \n #include \"mlir/IR/DialectImplementation.h\"\n #include \"mlir/IR/OpImplementation.h\"\n #include \"triton/Analysis/Utility.h\"\n-#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Dialect.cpp.inc\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n #include \"llvm/ADT/TypeSwitch.h\"\n \n-#include \"triton/Dialect/TritonGPU/IR/Dialect.cpp.inc\"\n-\n using namespace mlir;\n using namespace mlir::triton::gpu;\n \n@@ -376,7 +376,6 @@ template SmallVector<int64_t>\n SliceEncodingAttr::paddedShape<int64_t>(ArrayRef<int64_t> shape) const;\n \n unsigned SliceEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape) const {\n-  size_t rank = shape.size();\n   auto parent = getParent();\n   return ::getElemsPerThread(parent, paddedShape(shape));\n }\n@@ -657,9 +656,9 @@ void DotOperandEncodingAttr::print(mlir::AsmPrinter &printer) const {\n // InsertSliceAsyncOp\n //===----------------------------------------------------------------------===//\n \n-ParseResult parseInsertSliceAsyncOp(OpAsmParser &parser,\n-                                    OperationState &result) {\n-  SmallVector<OpAsmParser::OperandType, 8> allOperands;\n+ParseResult InsertSliceAsyncOp::parse(OpAsmParser &parser,\n+                                      OperationState &result) {\n+  SmallVector<OpAsmParser::UnresolvedOperand, 8> allOperands;\n   Type srcType, dstType;\n   SMLoc allOperandLoc = parser.getCurrentLocation();\n   if (parser.parseOperandList(allOperands) ||\n@@ -698,18 +697,16 @@ ParseResult parseInsertSliceAsyncOp(OpAsmParser &parser,\n   return success();\n }\n \n-void printInsertSliceAsyncOp(OpAsmPrinter &printer,\n-                             InsertSliceAsyncOp insertSliceAsyncOp) {\n+void InsertSliceAsyncOp::print(OpAsmPrinter &printer) {\n   printer << \" \";\n-  printer << insertSliceAsyncOp.getOperation()->getOperands();\n+  printer << getOperation()->getOperands();\n   // \"operand_segment_sizes\" can be deduced, so we don't print it.\n-  printer.printOptionalAttrDict(\n-      insertSliceAsyncOp->getAttrs(),\n-      {insertSliceAsyncOp.operand_segment_sizesAttrName()});\n+  printer.printOptionalAttrDict(getOperation()->getAttrs(),\n+                                {operand_segment_sizesAttrName()});\n   printer << \" : \";\n-  printer.printStrippedAttrOrType(insertSliceAsyncOp.src().getType());\n+  printer.printStrippedAttrOrType(src().getType());\n   printer << \" -> \";\n-  printer.printStrippedAttrOrType(insertSliceAsyncOp.result().getType());\n+  printer.printStrippedAttrOrType(result().getType());\n }\n \n //===----------------------------------------------------------------------===//"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Coalesce.cpp", "status": "modified", "additions": 14, "deletions": 9, "changes": 23, "file_content_changes": "@@ -16,7 +16,11 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     auto origType = ptr.getType().cast<RankedTensorType>();\n     // Get the shape of the tensor.\n     size_t rank = origType.getRank();\n-    AxisInfo info = axisInfo.lookupLatticeElement(ptr)->getValue();\n+    dataflow::Lattice<AxisInfo> *latticeElement =\n+        axisInfo.getLatticeElement(ptr);\n+    AxisInfo info = latticeElement && !latticeElement->isUninitialized()\n+                        ? latticeElement->getValue()\n+                        : AxisInfo();\n     // Layout order in decreasing order of contiguity\n     SmallVector<unsigned, 4> order(rank);\n     std::iota(order.begin(), order.end(), 0);\n@@ -69,7 +73,6 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     auto mod = op->getParentOfType<ModuleOp>();\n     int numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n \n-    AxisInfo info = axisInfo.lookupLatticeElement(ptr)->getValue();\n     auto convertType = getTypeConverter(axisInfo, ptr, numWarps);\n     // convert operands\n     SmallVector<Value, 4> newArgs;\n@@ -105,8 +108,10 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n   void runOnOperation() override {\n     Operation *op = getOperation();\n     // Run axis info analysis\n-    AxisInfoAnalysis axisInfo(&getContext());\n-    axisInfo.run(op);\n+    std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n+    AxisInfoAnalysis *axisInfo = solver->load<AxisInfoAnalysis>();\n+    if (failed(solver->initializeAndRun(op)))\n+      return signalPassFailure();\n     OpBuilder builder(op);\n \n     // For each memory op that has a layout L1:\n@@ -120,16 +125,16 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n       OpBuilder::InsertionGuard g(builder);\n       builder.setInsertionPoint(curr);\n       if (auto load = dyn_cast<triton::LoadOp>(curr))\n-        coalesceOp<triton::LoadOp>(axisInfo, curr, load.ptr(), builder);\n+        coalesceOp<triton::LoadOp>(*axisInfo, curr, load.ptr(), builder);\n       if (auto op = dyn_cast<triton::AtomicRMWOp>(curr))\n-        coalesceOp<triton::AtomicRMWOp>(axisInfo, curr, op.ptr(), builder);\n+        coalesceOp<triton::AtomicRMWOp>(*axisInfo, curr, op.ptr(), builder);\n       if (auto op = dyn_cast<triton::AtomicCASOp>(curr))\n-        coalesceOp<triton::AtomicCASOp>(axisInfo, curr, op.ptr(), builder);\n+        coalesceOp<triton::AtomicCASOp>(*axisInfo, curr, op.ptr(), builder);\n       if (auto load = dyn_cast<triton::gpu::InsertSliceAsyncOp>(curr))\n-        coalesceOp<triton::gpu::InsertSliceAsyncOp>(axisInfo, curr, load.src(),\n+        coalesceOp<triton::gpu::InsertSliceAsyncOp>(*axisInfo, curr, load.src(),\n                                                     builder);\n       if (auto store = dyn_cast<triton::StoreOp>(curr))\n-        coalesceOp<triton::StoreOp>(axisInfo, curr, store.ptr(), builder);\n+        coalesceOp<triton::StoreOp>(*axisInfo, curr, store.ptr(), builder);\n     });\n   }\n };"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,6 +1,6 @@\n #include \"Utility.h\"\n #include \"mlir/Analysis/SliceAnalysis.h\"\n-#include \"mlir/Dialect/SCF/SCF.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n #include \"mlir/IR/BlockAndValueMapping.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/Matchers.h\""}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.td", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -3,5 +3,6 @@\n \n include \"triton/Dialect/TritonGPU/IR/TritonGPUOps.td\"\n include \"triton/Dialect/Triton/IR/TritonOps.td\"\n+include \"mlir/IR/PatternBase.td\"\n \n #endif"}, {"filename": "lib/Dialect/TritonGPU/Transforms/DecomposeConversions.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,5 +1,5 @@\n #include \"mlir/Analysis/SliceAnalysis.h\"\n-#include \"mlir/Dialect/SCF/SCF.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n #include \"mlir/IR/BlockAndValueMapping.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/Matchers.h\""}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "file_content_changes": "@@ -2,6 +2,7 @@\n #include \"mlir/IR/BlockAndValueMapping.h\"\n #include \"mlir/IR/TypeUtilities.h\"\n #include \"triton/Analysis/AxisInfo.h\"\n+#include \"triton/Analysis/Utility.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n \n@@ -160,15 +161,18 @@ ttg::AllocTensorOp LoopPipeliner::allocateEmptyBuffer(Operation *op,\n LogicalResult LoopPipeliner::initialize() {\n   Block *loop = forOp.getBody();\n \n-  AxisInfoAnalysis axisInfoAnalysis(forOp.getContext());\n-  axisInfoAnalysis.run(forOp->getParentOfType<ModuleOp>());\n+  std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n+  AxisInfoAnalysis *axisInfoAnalysis = solver->load<AxisInfoAnalysis>();\n+  if (failed(solver->initializeAndRun(forOp->getParentOfType<ModuleOp>()))) {\n+    return failure();\n+  }\n \n   // can we use forOp.walk(...) here?\n   SmallVector<triton::LoadOp, 2> allLoads;\n   for (Operation &op : *loop)\n     if (auto loadOp = dyn_cast<triton::LoadOp>(&op)) {\n       auto ptr = loadOp.ptr();\n-      unsigned vec = axisInfoAnalysis.getPtrContiguity(ptr);\n+      unsigned vec = axisInfoAnalysis->getPtrContiguity(ptr);\n       auto ty = getElementTypeOrSelf(ptr.getType())\n                     .cast<triton::PointerType>()\n                     .getPointeeType();"}, {"filename": "lib/Dialect/TritonGPU/Transforms/ReorderInstructions.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,5 +1,5 @@\n #include \"mlir/Analysis/SliceAnalysis.h\"\n-#include \"mlir/Dialect/SCF/SCF.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n #include \"mlir/IR/BlockAndValueMapping.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/Matchers.h\""}, {"filename": "lib/Dialect/TritonGPU/Transforms/TritonGPUConversion.cpp", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -82,12 +82,12 @@ TritonGPUConversionTarget::TritonGPUConversionTarget(\n                scf::ReduceReturnOp>();\n \n   addDynamicallyLegalDialect<arith::ArithmeticDialect, math::MathDialect,\n-                             triton::TritonDialect, StandardOpsDialect,\n-                             scf::SCFDialect>([&](Operation *op) {\n-    if (typeConverter.isLegal(op))\n-      return true;\n-    return false;\n-  });\n+                             triton::TritonDialect, scf::SCFDialect>(\n+      [&](Operation *op) {\n+        if (typeConverter.isLegal(op))\n+          return true;\n+        return false;\n+      });\n \n   // We have requirements for the data layouts\n   addDynamicallyLegalOp<triton::DotOp>([](triton::DotOp dotOp) -> bool {"}, {"filename": "lib/Dialect/TritonGPU/Transforms/UpdateMmaForVolta.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,5 +1,5 @@\n #include \"Utility.h\"\n-#include \"mlir/Dialect/SCF/SCF.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n #include \"mlir/IR/Matchers.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\""}, {"filename": "lib/Dialect/TritonGPU/Transforms/Utility.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,5 +1,5 @@\n #include \"Utility.h\"\n-#include \"mlir/Dialect/SCF/SCF.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n #include \"mlir/IR/BlockAndValueMapping.h\"\n #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n "}, {"filename": "lib/Target/LLVMIR/CMakeLists.txt", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "file_content_changes": "@@ -6,8 +6,7 @@ add_mlir_translation_library(TritonLLVMIR\n \n         LINK_LIBS PUBLIC\n         MLIRIR\n-        MLIRLLVMIR\n-        MLIRSCFToStandard\n+        MLIRLLVMDialect\n         MLIRSupport\n         MLIRTargetLLVMIRExport\n         )"}, {"filename": "lib/Target/PTX/PTXTranslation.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -1,11 +1,14 @@\n #include \"triton/Target/PTX/PTXTranslation.h\"\n #include \"triton/Target/LLVMIR/LLVMIRTranslation.h\"\n+#include <optional>\n \n #include \"llvm/IR/IRBuilder.h\"\n #include \"llvm/IR/LegacyPassManager.h\"\n #include \"llvm/IR/Module.h\"\n #include \"llvm/IR/Verifier.h\"\n #include \"llvm/MC/TargetRegistry.h\"\n+#include \"llvm/Pass.h\"\n+#include \"llvm/Support/CommandLine.h\"\n #include \"llvm/Support/TargetSelect.h\"\n #include \"llvm/Target/TargetMachine.h\"\n "}, {"filename": "python/setup.py", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "file_content_changes": "@@ -54,12 +54,8 @@ def get_llvm_package_info():\n     system = platform.system()\n     system_suffix = {\"Linux\": \"linux-gnu-ubuntu-18.04\", \"Darwin\": \"apple-darwin\"}[system]\n     use_assert_enabled_llvm = check_env_flag(\"TRITON_USE_ASSERT_ENABLED_LLVM\", \"False\")\n-    if use_assert_enabled_llvm:\n-        name = 'llvm+mlir-14.0.0-x86_64-{}-assert'.format(system_suffix)\n-        url = \"https://github.com/shintaro-iwasaki/llvm-releases/releases/download/llvm-14.0.0-329fda39c507/{}.tar.xz\".format(name)\n-    else:\n-        name = 'clang+llvm-14.0.0-x86_64-{}'.format(system_suffix)\n-        url = \"https://github.com/llvm/llvm-project/releases/download/llvmorg-14.0.0/{}.tar.xz\".format(name)\n+    name = 'llvm+mlir-15.0.7-x86_64-{}-{}'.format(system_suffix, \"assert\" if use_assert_enabled_llvm else \"release\")\n+    url = \"https://github.com/ptillet/triton-llvm-releases/releases/download/llvm-15.0.7-8dfdcc7b7bf6/{}.tar.xz\".format(name)\n     return Package(\"llvm\", name, url, \"lib\", \"LLVM_INCLUDE_DIRS\", \"LLVM_LIBRARY_DIR\", \"LLVM_SYSPATH\")\n \n "}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 44, "deletions": 39, "changes": 83, "file_content_changes": "@@ -8,9 +8,10 @@\n #include \"mlir/Pass/PassManager.h\"\n #include \"mlir/Transforms/Passes.h\"\n \n-#include \"mlir/Parser.h\"\n+#include \"mlir/Parser/Parser.h\"\n #include \"mlir/Support/FileUtilities.h\"\n \n+#include \"mlir/Dialect/ControlFlow/IR/ControlFlowOps.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"triton/Analysis/Allocation.h\"\n #include \"triton/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.h\"\n@@ -341,7 +342,7 @@ void init_triton_ir(py::module &&m) {\n              return str;\n            })\n       .def(\"push_back\",\n-           [](mlir::ModuleOp &self, mlir::FuncOp &funcOp) -> void {\n+           [](mlir::ModuleOp &self, mlir::func::FuncOp &funcOp) -> void {\n              self.push_back(funcOp);\n            })\n       .def(\"has_function\",\n@@ -351,16 +352,18 @@ void init_triton_ir(py::module &&m) {\n              return false;\n            })\n       .def(\"get_function\",\n-           [](mlir::ModuleOp &self, std::string &funcName) -> mlir::FuncOp {\n-             return self.lookupSymbol<mlir::FuncOp>(funcName);\n-           })\n-      .def(\"get_single_function\", [](mlir::ModuleOp &self) -> mlir::FuncOp {\n-        llvm::SmallVector<mlir::FuncOp> funcs;\n-        self.walk([&](mlir::FuncOp func) { funcs.push_back(func); });\n-        if (funcs.size() != 1)\n-          throw std::runtime_error(\"Expected a single function\");\n-        return funcs[0];\n-      });\n+           [](mlir::ModuleOp &self,\n+              std::string &funcName) -> mlir::func::FuncOp {\n+             return self.lookupSymbol<mlir::func::FuncOp>(funcName);\n+           })\n+      .def(\"get_single_function\",\n+           [](mlir::ModuleOp &self) -> mlir::func::FuncOp {\n+             llvm::SmallVector<mlir::func::FuncOp> funcs;\n+             self.walk([&](mlir::func::FuncOp func) { funcs.push_back(func); });\n+             if (funcs.size() != 1)\n+               throw std::runtime_error(\"Expected a single function\");\n+             return funcs[0];\n+           });\n \n   m.def(\"make_attr\",\n         [](const std::vector<int> &values, mlir::MLIRContext &context) {\n@@ -381,47 +384,48 @@ void init_triton_ir(py::module &&m) {\n         registry.insert<mlir::triton::TritonDialect,\n                         mlir::triton::gpu::TritonGPUDialect,\n                         mlir::math::MathDialect, mlir::arith::ArithmeticDialect,\n-                        mlir::StandardOpsDialect, mlir::scf::SCFDialect>();\n+                        mlir::func::FuncDialect, mlir::scf::SCFDialect>();\n         context.appendDialectRegistry(registry);\n         context.loadAllAvailableDialects();\n \n         // parse module\n-        mlir::OwningOpRef<mlir::ModuleOp> module(\n-            mlir::parseSourceFile(inputFilename, &context));\n+        mlir::OwningOpRef<mlir::ModuleOp> module =\n+            mlir::parseSourceFile<mlir::ModuleOp>(inputFilename, &context);\n+        if (!module)\n+          throw std::runtime_error(\"Parse MLIR file failed.\");\n         // locations are incompatible with ptx < 7.5 !\n         module->walk([](mlir::Operation *op) {\n           op->setLoc(mlir::UnknownLoc::get(op->getContext()));\n         });\n-        if (!module)\n-          throw std::runtime_error(\"Parse MLIR file failed.\");\n \n         return module->clone();\n       },\n       ret::take_ownership);\n \n-  py::class_<mlir::FuncOp, mlir::OpState>(m, \"function\")\n+  py::class_<mlir::func::FuncOp, mlir::OpState>(m, \"function\")\n       // .def_property_readonly(\"attrs\", &ir::function::attrs)\n       // .def(\"add_attr\", &ir::function::add_attr);\n       .def(\"args\",\n-           [](mlir::FuncOp &self, unsigned idx) -> mlir::BlockArgument {\n+           [](mlir::func::FuncOp &self, unsigned idx) -> mlir::BlockArgument {\n              return self.getArgument(idx);\n            })\n       .def(\n           \"add_entry_block\",\n-          [](mlir::FuncOp &self) -> mlir::Block * {\n+          [](mlir::func::FuncOp &self) -> mlir::Block * {\n             return self.addEntryBlock();\n           },\n           ret::reference)\n       .def(\n           \"set_arg_attr\",\n-          [](mlir::FuncOp &self, int arg_no, const std::string &name, int val) {\n+          [](mlir::func::FuncOp &self, int arg_no, const std::string &name,\n+             int val) {\n             // set arg attributes \"name\" to value \"val\"\n             auto attrTy = mlir::IntegerType::get(self.getContext(), 32);\n             self.setArgAttr(arg_no, name, mlir::IntegerAttr::get(attrTy, val));\n           },\n           ret::reference)\n-      .def_property_readonly(\"type\", &mlir::FuncOp::getType)\n-      .def(\"reset_type\", &mlir::FuncOp::setType);\n+      .def_property_readonly(\"type\", &mlir::func::FuncOp::getFunctionType)\n+      .def(\"reset_type\", &mlir::func::FuncOp::setType);\n \n   py::class_<mlir::OpBuilder::InsertPoint>(m, \"InsertPoint\");\n \n@@ -438,13 +442,13 @@ void init_triton_ir(py::module &&m) {\n       .def(\"ret\",\n            [](mlir::OpBuilder &self, std::vector<mlir::Value> &vals) -> void {\n              auto loc = self.getUnknownLoc();\n-             self.create<mlir::ReturnOp>(loc, vals);\n+             self.create<mlir::func::ReturnOp>(loc, vals);\n            })\n       .def(\"call\",\n-           [](mlir::OpBuilder &self, mlir::FuncOp &func,\n+           [](mlir::OpBuilder &self, mlir::func::FuncOp &func,\n               std::vector<mlir::Value> &args) -> mlir::OpState {\n              auto loc = self.getUnknownLoc();\n-             return self.create<mlir::CallOp>(loc, func, args);\n+             return self.create<mlir::func::CallOp>(loc, func, args);\n            })\n       // insertion block/point\n       .def(\"set_insertion_point_to_start\",\n@@ -611,15 +615,16 @@ void init_triton_ir(py::module &&m) {\n       .def(\"get_or_insert_function\",\n            [](mlir::OpBuilder &self, mlir::ModuleOp &module,\n               std::string &funcName, mlir::Type &funcType,\n-              std::string &visibility) -> mlir::FuncOp {\n+              std::string &visibility) -> mlir::func::FuncOp {\n              if (mlir::Operation *funcOperation = module.lookupSymbol(funcName))\n-               return llvm::dyn_cast<mlir::FuncOp>(funcOperation);\n+               return llvm::dyn_cast<mlir::func::FuncOp>(funcOperation);\n              auto loc = self.getUnknownLoc();\n              if (auto funcTy = funcType.dyn_cast<mlir::FunctionType>()) {\n                llvm::SmallVector<mlir::NamedAttribute> attrs = {\n                    mlir::NamedAttribute(self.getStringAttr(\"sym_visibility\"),\n                                         self.getStringAttr(visibility))};\n-               return self.create<mlir::FuncOp>(loc, funcName, funcTy, attrs);\n+               return self.create<mlir::func::FuncOp>(loc, funcName, funcTy,\n+                                                      attrs);\n              }\n              throw std::runtime_error(\"invalid function type\");\n            })\n@@ -651,15 +656,15 @@ void init_triton_ir(py::module &&m) {\n            [](mlir::OpBuilder &self, mlir::Value condition,\n               mlir::Block *trueDest, mlir::Block *falseDest) {\n              auto loc = self.getUnknownLoc();\n-             self.create<mlir::CondBranchOp>(loc, condition, trueDest,\n-                                             falseDest);\n+             self.create<mlir::cf::CondBranchOp>(loc, condition, trueDest,\n+                                                 falseDest);\n              return;\n            })\n       .def(\"create_branch\",\n            [](mlir::OpBuilder &self, mlir::Block *dest,\n               std::vector<mlir::Value> &args) {\n              auto loc = self.getUnknownLoc();\n-             self.create<mlir::BranchOp>(loc, dest, args);\n+             self.create<mlir::cf::BranchOp>(loc, dest, args);\n              return;\n            })\n       // Structured control flow\n@@ -785,14 +790,14 @@ void init_triton_ir(py::module &&m) {\n       .def(\"create_to_index\",\n            [](mlir::OpBuilder &self, mlir::Value &input) -> mlir::Value {\n              auto loc = self.getUnknownLoc();\n-             return self.create<mlir::arith::IndexCastOp>(loc, input,\n-                                                          self.getIndexType());\n+             return self.create<mlir::arith::IndexCastOp>(\n+                 loc, self.getIndexType(), input);\n            })\n       .def(\"create_index_to_si\",\n            [](mlir::OpBuilder &self, mlir::Value &input) -> mlir::Value {\n              auto loc = self.getUnknownLoc();\n-             return self.create<mlir::arith::IndexCastOp>(loc, input,\n-                                                          self.getI32Type());\n+             return self.create<mlir::arith::IndexCastOp>(\n+                 loc, self.getI32Type(), input);\n            })\n       .def(\"create_fmul\",\n            [](mlir::OpBuilder &self, mlir::Value &lhs,\n@@ -1305,8 +1310,8 @@ void init_triton_ir(py::module &&m) {\n            [](mlir::OpBuilder &self, mlir::Value &condition,\n               mlir::Value &trueValue, mlir::Value &falseValue) -> mlir::Value {\n              auto loc = self.getUnknownLoc();\n-             return self.create<mlir::SelectOp>(loc, condition, trueValue,\n-                                                falseValue);\n+             return self.create<mlir::arith::SelectOp>(loc, condition,\n+                                                       trueValue, falseValue);\n            })\n       .def(\"create_printf\",\n            [](mlir::OpBuilder &self, const std::string &prefix,\n@@ -1418,7 +1423,7 @@ void init_triton_ir(py::module &&m) {\n              self.addPass(mlir::triton::createConvertTritonGPUToLLVMPass());\n            })\n       .def(\"add_scf_to_cfg\", [](mlir::PassManager &self) {\n-        self.addPass(mlir::createLowerToCFGPass());\n+        self.addPass(mlir::createConvertSCFToCFPass());\n       });\n }\n "}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1926,7 +1926,7 @@ def test_convert2d(dtype, shape, src_layout, dst_layout, device='cuda'):\n #dst = {dst_layout}\n \"\"\" + \"\"\"\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  func public @kernel_0d1d(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}) {\n+  func.func public @kernel_0d1d(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}) {\n     %cst = arith.constant dense<128> : tensor<128x1xi32, #src>\n     %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #src}>>\n     %1 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #triton_gpu.slice<{dim = 0, parent = #src}>>"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1505,14 +1505,14 @@ def make_hash(fn, **kwargs):\n     return hashlib.md5((Path(fn).read_text() + triton.runtime.jit.version_key()).encode(\"utf-8\")).hexdigest()\n \n \n-# - ^\\s*func\\s+ : match the start of the string, any leading whitespace, the keyword func,\n+# - ^\\s*func\\.func\\s+ : match the start of the string, any leading whitespace, the keyword func,\n #    and any following whitespace\n # - (public\\s+)? : optionally match the keyword public and any following whitespace\n # - (@\\w+) : match an @ symbol followed by one or more word characters\n #   (letters, digits, or underscores), and capture it as group 1 (the function name)\n # - (\\((?:%\\w+: \\S+(?: \\{\\S+ = \\S+ : \\S+\\})?(?:, )?)*\\)) : match a pair of parentheses enclosing\n #   zero or more arguments separated by commas, and capture it as group 2 (the argument list)\n-mlir_prototype_pattern = r'^\\s*func\\s+(?:public\\s+)?(@\\w+)(\\((?:%\\w+: \\S+(?: \\{\\S+ = \\S+ : \\S+\\})?(?:, )?)*\\))\\s*\\{\\s*$'\n+mlir_prototype_pattern = r'^\\s*func\\.func\\s+(?:public\\s+)?(@\\w+)(\\((?:%\\w+: \\S+(?: \\{\\S+ = \\S+ : \\S+\\})?(?:, )?)*\\))\\s*\\{\\s*$'\n ptx_prototype_pattern = r\"\\.(?:visible|extern)\\s+\\.(?:entry|func)\\s+(\\w+)\\s*\\(([^)]*)\\)\"\n prototype_pattern = {\n     \"ttir\": mlir_prototype_pattern,"}, {"filename": "test/Analysis/test-alias.mlir", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "file_content_changes": "@@ -11,7 +11,7 @@\n \n // CHECK-LABEL: matmul_loop\n // There shouldn't be any aliasing with the dot op encoding.\n-func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n   %b_ptr_init = tt.broadcast %B : (!tt.ptr<f16>) -> tensor<32x128x!tt.ptr<f16>, #BL>\n   %a_mask = arith.constant dense<true> : tensor<128x32xi1, #AL>\n@@ -36,7 +36,7 @@ func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B\n }\n \n // CHECK-LABEL: alloc\n-func @alloc(%A : !tt.ptr<f16>) {\n+func.func @alloc(%A : !tt.ptr<f16>) {\n   // CHECK: %cst -> %cst\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %cst1 = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #AL>\n@@ -46,15 +46,15 @@ func @alloc(%A : !tt.ptr<f16>) {\n }\n \n // CHECK-LABEL: convert\n-func @convert(%A : !tt.ptr<f16>) {\n+func.func @convert(%A : !tt.ptr<f16>) {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n   // CHECK: %0 -> %0\n   %cst1 = triton_gpu.convert_layout %cst0 : (tensor<16x16xf16, #AL>) -> tensor<16x16xf16, #A_SHARED>\n   return\n }\n \n // CHECK-LABEL: trans\n-func @trans(%A : !tt.ptr<f16>) {\n+func.func @trans(%A : !tt.ptr<f16>) {\n   // CHECK: %cst -> %cst\n   %tensor = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n   // CHECK: %0 -> %cst\n@@ -63,7 +63,7 @@ func @trans(%A : !tt.ptr<f16>) {\n }\n \n // CHECK-LABEL: insert_slice_async\n-func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n+func.func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>\n   %mask = tt.splat %i1 : (i1) -> tensor<16x16xi1, #AL>\n   %other = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n@@ -76,7 +76,7 @@ func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n }\n \n // CHECK-LABEL: insert_slice\n-func @insert_slice(%A : !tt.ptr<f16>, %i1 : i1) {\n+func.func @insert_slice(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>\n   %mask = tt.splat %i1 : (i1) -> tensor<16x16xi1, #AL>\n   %other = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n@@ -90,7 +90,7 @@ func @insert_slice(%A : !tt.ptr<f16>, %i1 : i1) {\n }\n \n // CHECK-LABEL: extract_slice\n-func @extract_slice(%A : !tt.ptr<f16>) {\n+func.func @extract_slice(%A : !tt.ptr<f16>) {\n   // CHECK: %cst -> %cst\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<1x16x16xf16, #A_SHARED>\n   %index = arith.constant 0 : index\n@@ -100,7 +100,7 @@ func @extract_slice(%A : !tt.ptr<f16>) {\n }\n \n // CHECK-LABEL: if_cat\n-func @if_cat(%i1 : i1) {\n+func.func @if_cat(%i1 : i1) {\n   // CHECK: %cst -> %cst\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK: %cst_0 -> %cst_0\n@@ -119,7 +119,7 @@ func @if_cat(%i1 : i1) {\n }\n \n // CHECK-LABEL: if_alias\n-func @if_alias(%i1 : i1) {\n+func.func @if_alias(%i1 : i1) {\n   // CHECK: %cst -> %cst\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK-NEXT: %cst_0 -> %cst_0\n@@ -134,7 +134,7 @@ func @if_alias(%i1 : i1) {\n }\n \n // CHECK-LABEL: for\n-func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   // CHECK: %cst -> %cst\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: %cst_0 -> %cst_0\n@@ -154,7 +154,7 @@ func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.p\n }\n \n // CHECK-LABEL: for_if\n-func @for_if(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n+func.func @for_if(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n   // CHECK: %cst -> %cst\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: %cst_0 -> %cst_0\n@@ -180,7 +180,7 @@ func @for_if(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !t\n }\n \n // CHECK-LABEL: for_if_for\n-func @for_if_for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n+func.func @for_if_for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n   // CHECK: %cst -> %cst\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: %cst_0 -> %cst_0"}, {"filename": "test/Analysis/test-alignment.mlir", "status": "modified", "additions": 153, "deletions": 153, "changes": 306, "file_content_changes": "@@ -1,282 +1,282 @@\n-// RUN: triton-opt %s -test-print-alignment -split-input-file 2>&1 | FileCheck %s\n+// RUN: triton-opt %s -test-print-alignment -split-input-file -o %t 2>&1 | FileCheck %s\n \n // CHECK-LABEL: cast\n-func @cast() {\n-  // CHECK: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [1]\n+func.func @cast() {\n+  // CHECK: contiguity = [1], divisibility = [1], constancy = [1], constant_value = 1\n   %cst = arith.constant 1 : i32\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = 1\n   %0 = arith.extsi %cst : i32 to i64\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 1\n   %cst_tensor = arith.constant dense<1> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 1\n   %1 = tt.bitcast %cst_tensor : tensor<128xi32> -> tensor<128xi64>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: add\n-func @add() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @add() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 1\n   %1 = arith.constant dense<1> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [1], constancy = [1], constant_value = <none>\n   %2 = arith.addi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [127]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 127\n   %3 = arith.constant dense<127> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [128] ; ConstantValue: [128]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [128], constant_value = 128\n   %4 = arith.addi %1, %3 : tensor<128xi32>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: sub\n-func @sub() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @sub() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 1\n   %1 = arith.constant dense<1> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [1], constancy = [1], constant_value = <none>\n   %2 = arith.subi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [129]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 129\n   %3 = arith.constant dense<129> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [128] ; ConstantValue: [128]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [128], constant_value = 128\n   %4 = arith.subi %3, %1 : tensor<128xi32>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: mul\n-func @mul() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @mul() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 1\n   %1 = arith.constant dense<1> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %2 = arith.muli %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [128] ; ConstantValue: [128]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [128], constant_value = 128\n   %3 = arith.constant dense<128> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [128] ; ConstantValue: [128]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [128], constant_value = 128\n   %4 = arith.muli %3, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [2] ; Constancy: [128] ; ConstantValue: [2]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [2], constancy = [128], constant_value = 2\n   %5 = arith.constant dense<2> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [256] ; Constancy: [128] ; ConstantValue: [256]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [256], constancy = [128], constant_value = 256\n   %6 = arith.muli %4, %5 : tensor<128xi32>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: div\n-func @div() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @div() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 1\n   %1 = arith.constant dense<1> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %2 = arith.divsi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %3 = arith.divui %1, %0 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [64] ; Constancy: [128] ; ConstantValue: [64]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [64], constancy = [128], constant_value = 64\n   %4 = arith.constant dense<64> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [16777216] ; Constancy: [64] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [16777216], constancy = [64], constant_value = <none>\n   %5 = arith.divsi %0, %4 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [16777216] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [16777216], constancy = [1], constant_value = <none>\n   %6 = arith.divsi %4, %0 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [2] ; Constancy: [128] ; ConstantValue: [66]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [2], constancy = [128], constant_value = 66\n   %7 = arith.constant dense<66> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [536870912] ; Constancy: [2] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [536870912], constancy = [2], constant_value = <none>\n   %8 = arith.divui %0, %7 : tensor<128xi32>\n-  return \n+  return\n }\n \n // -----\n \n // CHECK-LABEL: rem\n-func @rem() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @rem() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 1\n   %1 = arith.constant dense<1> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4611686018427387904] ; Constancy: [128] ; ConstantValue: [0]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4611686018427387904], constancy = [128], constant_value = 0\n   %2 = arith.remsi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %3 = arith.remui %1, %0 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [64] ; Constancy: [128] ; ConstantValue: [64]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [64], constancy = [128], constant_value = 64\n   %4 = arith.constant dense<64> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [64] ; Divisibility: [64] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [64], divisibility = [64], constancy = [1], constant_value = <none>\n   %5 = arith.remsi %0, %4 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [64] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [64], constancy = [1], constant_value = <none>\n   %6 = arith.remsi %4, %0 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [2] ; Constancy: [128] ; ConstantValue: [66]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [2], constancy = [128], constant_value = 66\n   %7 = arith.constant dense<66> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [2] ; Divisibility: [2] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [2], divisibility = [2], constancy = [1], constant_value = <none>\n   %8 = arith.remui %0, %7 : tensor<128xi32>\n-  return \n+  return\n }\n \n // -----\n \n // CHECK-LABEL: broadcast\n-func @broadcast() {\n-  // CHECK: Contiguity: [1] ; Divisibility: [64] ; Constancy: [128] ; ConstantValue: [64]\n+func.func @broadcast() {\n+  // CHECK: contiguity = [1], divisibility = [64], constancy = [128], constant_value = 64\n   %0 = arith.constant dense<64> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [64, 1] ; Constancy: [128, 1] ; ConstantValue: [64]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [64, 1], constancy = [128, 1], constant_value = 64\n   %1 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<128xi32>) -> tensor<128x1xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [64, 1] ; Constancy: [128, 128] ; ConstantValue: [64]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [64, 1], constancy = [128, 128], constant_value = 64\n   %2 = tt.broadcast %1 : (tensor<128x1xi32>) -> tensor<128x128xi32>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: splat\n-func @splat(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n-  // CHECK: Contiguity: [1, 1] ; Divisibility: [16, 16] ; Constancy: [128, 128] ; ConstantValue: [None]\n+func.func @splat(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n+  // CHECK: contiguity = [1, 1], divisibility = [16, 16], constancy = [128, 128], constant_value = <none>\n   %0 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: cmp\n-func @cmp() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @cmp() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4611686018427387904] ; Constancy: [128] ; ConstantValue: [0]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4611686018427387904], constancy = [128], constant_value = 0\n   %1 = arith.constant dense<0> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = <none>\n   %2 = arith.cmpi eq, %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = <none>\n   %3 = arith.cmpi slt, %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %4 = arith.cmpi sle, %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = <none>\n   %5 = arith.cmpi sge, %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [8] ; Constancy: [128] ; ConstantValue: [8]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [8], constancy = [128], constant_value = 8\n   %6 = arith.constant dense<8> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [8] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [8], constant_value = <none>\n   %7 = arith.cmpi sgt, %0, %6 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [0]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = 0\n   %8 = arith.cmpi sgt, %1, %6 : tensor<128xi32>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: logic\n-func @logic() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @logic() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [64] ; Constancy: [128] ; ConstantValue: [64]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [64], constancy = [128], constant_value = 64\n   %1 = arith.constant dense<64> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [16777216] ; Constancy: [64] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [16777216], constancy = [64], constant_value = <none>\n   %2 = arith.divsi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [8] ; Constancy: [128] ; ConstantValue: [8]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [8], constancy = [128], constant_value = 8\n   %3 = arith.constant dense<8> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [134217728] ; Constancy: [8] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [134217728], constancy = [8], constant_value = <none>\n   %4 = arith.divsi %0, %3 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %5 = arith.andi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %6 = arith.ori %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %7 = arith.xori %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [8] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [8], constant_value = <none>\n   %8 = arith.andi %2, %4 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [8] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [8], constant_value = <none>\n   %9 = arith.ori %2, %4 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [8] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [8], constant_value = <none>\n   %10 = arith.xori %2, %4 : tensor<128xi32>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: select\n-func @select() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @select() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4611686018427387904] ; Constancy: [128] ; ConstantValue: [0]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4611686018427387904], constancy = [128], constant_value = 0\n   %1 = arith.constant dense<0> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = <none>\n   %2 = arith.cmpi eq, %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = <none>\n   %3 = arith.cmpi slt, %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4611686018427387904] ; Constancy: [1] ; ConstantValue: [0]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4611686018427387904], constancy = [1], constant_value = 0\n   %4 = arith.constant 0 : i1\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4611686018427387904] ; Constancy: [128] ; ConstantValue: [0]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4611686018427387904], constancy = [128], constant_value = 0\n   %7 = tt.splat %4 : (i1) -> tensor<128xi1>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4611686018427387904] ; Constancy: [128] ; ConstantValue: [0]\n-  %5 = select %4, %3, %7 : tensor<128xi1>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4611686018427387904], constancy = [128], constant_value = 0\n+  %5 = arith.select %4, %3, %7 : tensor<128xi1>\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [128], constant_value = <none>\n   %8 = \"triton_gpu.select\"(%7, %3, %2) : (tensor<128xi1>, tensor<128xi1>, tensor<128xi1>) -> tensor<128xi1>\n   return\n }\n \n // -----\n \n-func @shift() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @shift() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [8] ; Constancy: [128] ; ConstantValue: [8]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [8], constancy = [128], constant_value = 8\n   %1 = arith.constant dense<8> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4] ; Constancy: [128] ; ConstantValue: [4]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4], constancy = [128], constant_value = 4\n   %2 = arith.constant dense<4> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [274877906944] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [274877906944], constancy = [1], constant_value = <none>\n   %3 = arith.shli %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [67108864] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [67108864], constancy = [1], constant_value = <none>\n   %4 = arith.shrsi %0, %2 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [128] ; ConstantValue: [128]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [128], constant_value = 128\n   %5 = arith.shli %1, %2 : tensor<128xi32>\n   return\n }\n \n // -----\n \n-func @max_min() {\n-  // CHECK: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @max_min() {\n+  // CHECK: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [64] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [64], constancy = [1], constant_value = <none>\n   %1 = tt.make_range {end = 192 : i32, start = 64 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %2 = arith.maxsi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %3 = arith.minsi %0, %1 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [8] ; Constancy: [128] ; ConstantValue: [8]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [8], constancy = [128], constant_value = 8\n   %4 = arith.constant dense<8> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4] ; Constancy: [128] ; ConstantValue: [4]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4], constancy = [128], constant_value = 4\n   %5 = arith.constant dense<4> : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [8]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = 8\n   %6 = arith.maxsi %4, %5 : tensor<128xi32>\n   return\n }\n \n // -----\n \n // CHECK-LABEL: for\n-func @for() {\n-  // CHECK: Contiguity: [1, 1] ; Divisibility: [4611686018427387904, 4611686018427387904] ; Constancy: [128, 32] ; ConstantValue: [0]\n+func.func @for() {\n+  // CHECK: contiguity = [1, 1], divisibility = [4611686018427387904, 4611686018427387904], constancy = [128, 32], constant_value = 0\n   %a_init = arith.constant dense<0> : tensor<128x32xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [1, 1] ; Constancy: [128, 32] ; ConstantValue: [1]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [1, 1], constancy = [128, 32], constant_value = 1\n   %b_init = arith.constant dense<1> : tensor<128x32xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [4, 4] ; Constancy: [128, 32] ; ConstantValue: [4]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [4, 4], constancy = [128, 32], constant_value = 4\n   %c_init = arith.constant dense<4> : tensor<128x32xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [1] ; ConstantValue: [128]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [1], constant_value = 128\n   %ub = arith.constant 128 : index\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [4611686018427387904] ; Constancy: [1] ; ConstantValue: [0]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [4611686018427387904], constancy = [1], constant_value = 0\n   %lb = arith.constant 0 : index\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [16] ; Constancy: [1] ; ConstantValue: [16]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [16], constancy = [1], constant_value = 16\n   %step = arith.constant 16 : index\n   %a, %b, %c = scf.for %iv = %lb to %ub step %step iter_args(%a = %a_init, %b = %b_init, %c = %c_init) -> (tensor<128x32xi32>, tensor<128x32xi32>, tensor<128x32xi32>) {\n-    // CHECK-NEXT: Contiguity: [1] ; Divisibility: [16] ; Constancy: [1] ; ConstantValue: [None]\n+    // CHECK-NEXT: contiguity = [1], divisibility = [16], constancy = [1], constant_value = <none>\n     %t = arith.index_cast %iv : index to i32\n-    // CHECK: Contiguity: [1, 1] ; Divisibility: [1, 1] ; Constancy: [128, 32] ; ConstantValue: [None]\n-    // CHECK: Contiguity: [1, 1] ; Divisibility: [1, 1] ; Constancy: [128, 32] ; ConstantValue: [None]\n-    // CHECK: Contiguity: [1, 1] ; Divisibility: [4, 4] ; Constancy: [128, 32] ; ConstantValue: [4]\n+    // CHECK: contiguity = [1, 1], divisibility = [1, 1], constancy = [128, 32], constant_value = <none>\n+    // CHECK: contiguity = [1, 1], divisibility = [1, 1], constancy = [128, 32], constant_value = <none>\n+    // CHECK: contiguity = [1, 1], divisibility = [4, 4], constancy = [128, 32], constant_value = 4\n     scf.yield %b, %a, %c : tensor<128x32xi32>, tensor<128x32xi32>, tensor<128x32xi32>\n   }\n   return\n@@ -285,52 +285,52 @@ func @for() {\n // -----\n \n // CHECK-LABEL: permute_2d\n-func @permute_2d(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32 {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}) {\n-  // CHECK: Contiguity: [1, 1] ; Divisibility: [1, 1] ; Constancy: [128, 128] ; ConstantValue: [1]\n+func.func @permute_2d(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32 {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}) {\n+  // CHECK: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>\n   %cst = arith.constant dense<true> : tensor<128x128xi1>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [1, 1] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>\n   %cst_0 = arith.constant dense<0.000000e+00> : tensor<128x128xf32>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %1 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [128, 1] ; Divisibility: [1073741824, 1] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128, 1], divisibility = [1073741824, 1], constancy = [1, 1], constant_value = <none>\n   %2 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<128xi32>) -> tensor<128x1xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 16] ; Constancy: [128, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 16], constancy = [128, 1], constant_value = <none>\n   %3 = tt.splat %arg1 : (i32) -> tensor<128x1xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [17179869184, 16] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [17179869184, 16], constancy = [1, 1], constant_value = <none>\n   %4 = arith.muli %2, %3 : tensor<128x1xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 16] ; Constancy: [128, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 16], constancy = [128, 1], constant_value = <none>\n   %5 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<128x1x!tt.ptr<f32>>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 16] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 1], constant_value = <none>\n   %6 = tt.addptr %5, %4 : tensor<128x1x!tt.ptr<f32>>, tensor<128x1xi32>\n-  // CHECK-NEXT: Contiguity: [1, 128] ; Divisibility: [1, 1073741824] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 128], divisibility = [1, 1073741824], constancy = [1, 1], constant_value = <none>\n   %7 = tt.expand_dims %1 {axis = 0 : i32}: (tensor<128xi32>) -> tensor<1x128xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 16] ; Constancy: [1, 128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 128], constant_value = <none>\n   %8 = tt.broadcast %6 : (tensor<128x1x!tt.ptr<f32>>) -> tensor<128x128x!tt.ptr<f32>>\n-  // CHECK-NEXT: Contiguity: [1, 128] ; Divisibility: [1, 1073741824] ; Constancy: [128, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 128], divisibility = [1, 1073741824], constancy = [128, 1], constant_value = <none>\n   %9 = tt.broadcast %7 : (tensor<1x128xi32>) -> tensor<128x128xi32>\n-  // CHECK-NEXT: Contiguity: [1, 128] ; Divisibility: [1, 16] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 128], divisibility = [1, 16], constancy = [1, 1], constant_value = <none>\n   %10 = tt.addptr %8, %9 : tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>\n-  // CHECK-NEXT: Contiguity: [128, 1] ; Divisibility: [1073741824, 1] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128, 1], divisibility = [1073741824, 1], constancy = [1, 1], constant_value = <none>\n   %11 = tt.expand_dims %0 {axis = 1 : i32}: (tensor<128xi32>) -> tensor<128x1xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 16] ; Constancy: [128, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 16], constancy = [128, 1], constant_value = <none>\n   %12 = tt.splat %arg2 : (!tt.ptr<f32>) -> tensor<128x1x!tt.ptr<f32>>\n-  // CHECK-NEXT: Contiguity: [128, 1] ; Divisibility: [16, 1] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128, 1], divisibility = [16, 1], constancy = [1, 1], constant_value = <none>\n   %13 = tt.addptr %12, %11 : tensor<128x1x!tt.ptr<f32>>, tensor<128x1xi32>\n-  // CHECK-NEXT: Contiguity: [1, 128] ; Divisibility: [1, 1073741824] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 128], divisibility = [1, 1073741824], constancy = [1, 1], constant_value = <none>\n   %14 = tt.expand_dims %1 {axis = 0 : i32} : (tensor<128xi32>) -> tensor<1x128xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 16] ; Constancy: [1, 128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 16], constancy = [1, 128], constant_value = <none>\n   %15 = tt.splat %arg3 : (i32) -> tensor<1x128xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 17179869184] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 17179869184], constancy = [1, 1], constant_value = <none>\n   %16 = arith.muli %14, %15 : tensor<1x128xi32>\n-  // CHECK-NEXT: Contiguity: [128, 1] ; Divisibility: [16, 1] ; Constancy: [1, 128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128, 1], divisibility = [16, 1], constancy = [1, 128], constant_value = <none>\n   %17 = tt.broadcast %13 : (tensor<128x1x!tt.ptr<f32>>) -> tensor<128x128x!tt.ptr<f32>>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [16, 17179869184] ; Constancy: [128, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [16, 17179869184], constancy = [128, 1], constant_value = <none>\n   %18 = tt.broadcast %16 : (tensor<1x128xi32>) -> tensor<128x128xi32>\n-  // CHECK-NEXT: Contiguity: [128, 1] ; Divisibility: [16, 1] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128, 1], divisibility = [16, 1], constancy = [1, 1], constant_value = <none>\n   %19 = tt.addptr %17, %18 : tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>\n-  // CHECK-NEXT: Contiguity: [1, 1] ; Divisibility: [1, 1] ; Constancy: [1, 1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1, 1], divisibility = [1, 1], constancy = [1, 1], constant_value = <none>\n   %20 = tt.load %10, %cst, %cst_0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<128x128xf32>\n   tt.store %19, %20, %cst : tensor<128x128xf32>\n   return\n@@ -342,28 +342,28 @@ module {\n \n // This is a tiny test for verifying StoreOp-related alignment, It simply store a constant to a buffer.\n // CHECK-LABEL: store_constant_align\n-func @store_constant_align(%addr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n: i32 {tt.divisibility = 16 : i32}) {\n-  // CHECK: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+func.func @store_constant_align(%addr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n: i32 {tt.divisibility = 16 : i32}) {\n+  // CHECK: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %pid = tt.get_program_id {axis = 0 : i32} : i32\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [1] ; ConstantValue: [128]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [1], constant_value = 128\n   %c128_i32 = arith.constant 128 : i32\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [1], constant_value = <none>\n   %1 = arith.muli %pid, %c128_i32 : i32\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [1073741824] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [1073741824], constancy = [1], constant_value = <none>\n   %2 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n- // CHECK-NEXT: Contiguity: [1] ; Divisibility: [128] ; Constancy: [128] ; ConstantValue: [None]\n+ // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [128], constant_value = <none>\n   %3 = tt.splat %1 : (i32) -> tensor<128xi32>\n- // CHECK-NEXT: Contiguity: [128] ; Divisibility: [128] ; Constancy: [1] ; ConstantValue: [None]\n+ // CHECK-NEXT: contiguity = [128], divisibility = [128], constancy = [1], constant_value = <none>\n   %4 = arith.addi %3, %2 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [16] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [16], constancy = [128], constant_value = <none>\n   %5 = tt.splat %addr : (!tt.ptr<f32>) -> tensor<128x!tt.ptr<f32>>\n-  // CHECK-NEXT: Contiguity: [128] ; Divisibility: [16] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [128], divisibility = [16], constancy = [1], constant_value = <none>\n   %6 = tt.addptr %5, %4 : tensor<128x!tt.ptr<f32>>, tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [16] ; Constancy: [128] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [16], constancy = [128], constant_value = <none>\n   %9 = tt.splat %n : (i32) -> tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [16] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [16], constant_value = <none>\n   %mask = arith.cmpi slt, %4, %9 : tensor<128xi32>\n-  // CHECK-NEXT: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None]\n+  // CHECK-NEXT: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n   %cst = arith.constant dense<0.0> : tensor<128xf32>\n   tt.store %5, %cst, %mask : tensor<128xf32>\n   return\n@@ -376,7 +376,7 @@ func @store_constant_align(%addr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n:\n // This IR is dumped from vecadd test.\n // Note, the hint {tt.divisibility = 16 : i32} for %n_elements affects the alignment of mask.\n // CHECK-LABEL: vecadd_mask_align_16\n-func @vecadd_mask_align_16(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32 {tt.divisibility = 16 : i32}) {\n+func.func @vecadd_mask_align_16(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32 {tt.divisibility = 16 : i32}) {\n   %c64_i32 = arith.constant 64 : i32\n   %0 = tt.get_program_id {axis = 0 : i32} : i32\n   %1 = arith.muli %0, %c64_i32 : i32\n@@ -388,13 +388,13 @@ func @vecadd_mask_align_16(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %ar\n   %7 = tt.splat %arg1 : (!tt.ptr<f32>) -> tensor<64x!tt.ptr<f32>>\n   %8 = tt.addptr %7, %4 : tensor<64x!tt.ptr<f32>>, tensor<64xi32>\n   %9 = tt.splat %n_elements : (i32) -> tensor<64xi32>\n-  // CHECK: Contiguity: [1] ; Divisibility: [1] ; Constancy: [16] ; ConstantValue: [None] ( %{{.*}} = arith.cmpi slt, %{{.*}}, %{{.*}} : tensor<64xi32> )\n+  // CHECK: arith.cmpi slt, %{{.*}} => contiguity = [1], divisibility = [64], constancy = [16], constant_value = <none>\n   %mask = arith.cmpi slt, %4, %9 : tensor<64xi32>\n   %11 = tt.load %6, %mask {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<64xf32>\n   %12 = tt.load %8, %mask {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<64xf32>\n   %13 = arith.addf %11, %12 : tensor<64xf32>\n   %14 = tt.splat %arg2 : (!tt.ptr<f32>) -> tensor<64x!tt.ptr<f32>>\n-  // CHECK: Contiguity: [64] ; Divisibility: [16] ; Constancy: [1] ; ConstantValue: [None] ( %{{.*}} = tt.addptr %{{.*}}, %{{.*}} : tensor<64x!tt.ptr<f32>>, tensor<64xi32> )\n+  // CHECK: tt.addptr %{{.*}} => contiguity = [64], divisibility = [16], constancy = [1], constant_value = <none>\n   %15 = tt.addptr %14, %4 : tensor<64x!tt.ptr<f32>>, tensor<64xi32>\n   tt.store %15, %13, %mask : tensor<64xf32>\n   return\n@@ -405,7 +405,7 @@ func @vecadd_mask_align_16(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %ar\n // This IR is dumped from vecadd test.\n // Note, there is no divisibility hint for %n_elements, Triton should assume its divisibility to be 1 by default.\n // CHECK-LABEL: vecadd_mask_align_1\n-func @vecadd_mask_align_1(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32) {\n+func.func @vecadd_mask_align_1(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32) {\n   %c64_i32 = arith.constant 64 : i32\n   %0 = tt.get_program_id {axis = 0 : i32} : i32\n   %1 = arith.muli %0, %c64_i32 : i32\n@@ -417,7 +417,7 @@ func @vecadd_mask_align_1(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg\n   %7 = tt.splat %arg1 : (!tt.ptr<f32>) -> tensor<64x!tt.ptr<f32>>\n   %8 = tt.addptr %7, %4 : tensor<64x!tt.ptr<f32>>, tensor<64xi32>\n   %9 = tt.splat %n_elements : (i32) -> tensor<64xi32>\n-  // CHECK: Contiguity: [1] ; Divisibility: [1] ; Constancy: [1] ; ConstantValue: [None] ( %{{.*}} = arith.cmpi slt, %{{.*}}, %{{.*}} : tensor<64xi32> )\n+  // CHECK: arith.cmpi slt, %{{.*}} => contiguity = [1], divisibility = [64], constancy = [1], constant_value = <none>\n   %10 = arith.cmpi slt, %4, %9 : tensor<64xi32>\n   %11 = tt.load %6, %10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<64xf32>\n   %12 = tt.load %8, %10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<64xf32>"}, {"filename": "test/Analysis/test-allocation.mlir", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "file_content_changes": "@@ -13,7 +13,7 @@\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n // CHECK-LABEL: matmul_loop\n-func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n   %b_ptr_init = tt.broadcast %B : (!tt.ptr<f16>) -> tensor<32x128x!tt.ptr<f16>, #BL>\n \n@@ -46,7 +46,7 @@ func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B\n \n // Shared memory is available after a tensor's liveness range ends\n // CHECK-LABEL: reusable\n-func @reusable(%A : !tt.ptr<f16>) {\n+func.func @reusable(%A : !tt.ptr<f16>) {\n   %cst1 = arith.constant dense<true> : tensor<128x32xi1, #AL>\n   %cst2 = arith.constant dense<0.000000e+00> : tensor<128x32xf16, #AL>\n   %cst3 = arith.constant dense<true> : tensor<32x128xi1, #AL>\n@@ -78,7 +78,7 @@ func @reusable(%A : !tt.ptr<f16>) {\n // %cst1->%cst4\n // %cst3->%g->%h->%i\n // CHECK-LABEL: preallocate\n-func @preallocate(%A : !tt.ptr<f16>) {\n+func.func @preallocate(%A : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 512\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 1024, size = 512\n@@ -113,7 +113,7 @@ func @preallocate(%A : !tt.ptr<f16>) {\n \n // Unused tensors are immediately released\n // CHECK-LABEL: unused\n-func @unused(%A : !tt.ptr<f16>) {\n+func.func @unused(%A : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 1024\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<32x16xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 0, size = 512\n@@ -128,7 +128,7 @@ func @unused(%A : !tt.ptr<f16>) {\n \n // cst0 is alive through the entire function, it cannot be released before the end of the function\n // CHECK-LABEL: longlive\n-func @longlive(%A : !tt.ptr<f16>) {\n+func.func @longlive(%A : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 512\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 512, size = 512\n@@ -156,7 +156,7 @@ func @longlive(%A : !tt.ptr<f16>) {\n }\n \n // CHECK-LABEL: alloc\n-func @alloc(%A : !tt.ptr<f16>) {\n+func.func @alloc(%A : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 512\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %cst1 = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #AL>\n@@ -167,7 +167,7 @@ func @alloc(%A : !tt.ptr<f16>) {\n }\n \n // CHECK-LABEL: scratch\n-func @scratch() {\n+func.func @scratch() {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n   // CHECK: scratch offset = 0, size = 512\n   %b = tt.reduce %cst0 {redOp = 1 : i32, axis = 0 : i32} : tensor<16x16xf16, #AL> -> tensor<16xf16, #sliceAd0>\n@@ -176,15 +176,15 @@ func @scratch() {\n }\n \n // CHECK-LABEL: trans\n-func @trans(%A : !tt.ptr<f16>) {\n+func.func @trans(%A : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 1024\n   %tensor = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n   %b = tt.trans %tensor : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED_T>\n   return\n }\n \n // CHECK-LABEL: insert_slice_async\n-func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n+func.func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>\n   %mask = tt.splat %i1 : (i1) -> tensor<16x16xi1, #AL>\n   %other = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n@@ -197,7 +197,7 @@ func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n }\n \n // CHECK-LABEL: extract_slice\n-func @extract_slice(%A : !tt.ptr<f16>) {\n+func.func @extract_slice(%A : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 512\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<1x16x16xf16, #A_SHARED>\n   %index = arith.constant 0 : index\n@@ -209,7 +209,7 @@ func @extract_slice(%A : !tt.ptr<f16>) {\n // B0 -> (B1) -> B0\n // Memory used by B1 can be reused by B0.\n // CHECK-LABEL: if\n-func @if(%i1 : i1) {\n+func.func @if(%i1 : i1) {\n   // CHECK: offset = 0, size = 512\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 512, size = 512\n@@ -233,7 +233,7 @@ func @if(%i1 : i1) {\n // B0 -> (B1) -> (B2) -> B0\n // Memory used by B0 cannot be reused by B1 or B2.\n // CHECK-LABEL: if_else\n-func @if_else(%i1 : i1) {\n+func.func @if_else(%i1 : i1) {\n   // CHECK: offset = 0, size = 512\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 512, size = 512\n@@ -260,7 +260,7 @@ func @if_else(%i1 : i1) {\n // Block arguments and yields are memory aliases that do not trigger a new\n // allocation.\n // CHECK-LABEL: for\n-func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   // CHECK: offset = 0, size = 8192\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 8192, size = 8192\n@@ -275,7 +275,7 @@ func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.p\n }\n \n // CHECK-LABEL: for_if_slice\n-func @for_if_slice(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n+func.func @for_if_slice(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n   // CHECK: offset = 0, size = 8192\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 8192, size = 8192\n@@ -296,7 +296,7 @@ func @for_if_slice(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %\n \n // c0 cannot be released in the loop\n // CHECK-LABEL: for_use_ancestor\n-func @for_use_ancestor(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n+func.func @for_use_ancestor(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n   // CHECK: offset = 0, size = 8192\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 8192, size = 8192\n@@ -316,7 +316,7 @@ func @for_use_ancestor(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16\n // a_shared_init, b_shared_init, and c_shared_init's liveness ranges are span over the entire function before cst2.\n // So they cannot be reused by cst0 and cst1, but can be reused by cst2.\n // CHECK-LABEL: for_if_for\n-func @for_if_for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n+func.func @for_if_for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n   // CHECK: offset = 0, size = 8192\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: offset = 8192, size = 8192"}, {"filename": "test/Analysis/test-membar.mlir", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "file_content_changes": "@@ -14,7 +14,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n // CHECK-LABEL: matmul_loop\n // There shouldn't be any membar with the dot op encoding.\n-func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n   %b_ptr_init = tt.broadcast %B : (!tt.ptr<f16>) -> tensor<32x128x!tt.ptr<f16>, #BL>\n \n@@ -42,7 +42,7 @@ func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B\n }\n \n // CHECK-LABEL: raw_single_block\n-func @raw_single_block(%A : !tt.ptr<f16>) {\n+func.func @raw_single_block(%A : !tt.ptr<f16>) {\n   %cst1 = arith.constant dense<true> : tensor<128x32xi1, #AL>\n   %cst2 = arith.constant dense<0.000000e+00> : tensor<128x32xf16, #AL>\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n@@ -54,7 +54,7 @@ func @raw_single_block(%A : !tt.ptr<f16>) {\n }\n \n // CHECK-LABEL: war_single_block\n-func @war_single_block(%A : !tt.ptr<f16>) {\n+func.func @war_single_block(%A : !tt.ptr<f16>) {\n   %cst1 = arith.constant dense<true> : tensor<128x32xi1, #AL>\n   %cst2 = arith.constant dense<0.000000e+00> : tensor<128x32xf16, #AL>\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n@@ -70,7 +70,7 @@ func @war_single_block(%A : !tt.ptr<f16>) {\n }\n \n // CHECK-LABEL: scratch\n-func @scratch() {\n+func.func @scratch() {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK: Membar 1\n   %a = tt.cat %cst0, %cst0 {axis = 0} : (tensor<16x16xf16, #A_SHARED>, tensor<16x16xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n@@ -81,7 +81,7 @@ func @scratch() {\n }\n \n // CHECK-LABEL: async_wait\n-func @async_wait() {\n+func.func @async_wait() {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   // CHECK: Membar 1\n   %a = tt.cat %cst0, %cst0 {axis = 0} : (tensor<16x16xf16, #A_SHARED>, tensor<16x16xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n@@ -92,7 +92,7 @@ func @async_wait() {\n }\n \n // CHECK-LABEL: alloc\n-func @alloc() {\n+func.func @alloc() {\n   %cst0 = triton_gpu.alloc_tensor : tensor<16x16xf16, #A_SHARED>\n   %a = tt.cat %cst0, %cst0 {axis = 0} : (tensor<16x16xf16, #A_SHARED>, tensor<16x16xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n   // CHECK: Membar 2\n@@ -101,7 +101,7 @@ func @alloc() {\n }\n \n // CHECK-LABEL: extract_slice\n-func @extract_slice() {\n+func.func @extract_slice() {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<1x16x16xf16, #A_SHARED>\n   %index = arith.constant 0 : index\n   %cst1 = tensor.extract_slice %cst0[%index, 0, 0][1, 16, 16][1, 1, 1] : tensor<1x16x16xf16, #A_SHARED> to tensor<16x16xf16, #A_SHARED>\n@@ -113,14 +113,14 @@ func @extract_slice() {\n }\n \n // CHECK-LABEL: trans\n-func @trans() {\n+func.func @trans() {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n   %b = tt.trans %cst0 : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED_T>\n   return\n }\n \n // CHECK-LABEL: insert_slice_async\n-func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n+func.func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>\n   %mask = tt.splat %i1 : (i1) -> tensor<16x16xi1, #AL>\n   %other = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n@@ -135,7 +135,7 @@ func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n }\n \n // CHECK-LABEL: insert_slice\n-func @insert_slice(%A : !tt.ptr<f16>, %i1 : i1) {\n+func.func @insert_slice(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>\n   %mask = tt.splat %i1 : (i1) -> tensor<16x16xi1, #AL>\n   %other = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n@@ -153,7 +153,7 @@ func @insert_slice(%A : !tt.ptr<f16>, %i1 : i1) {\n \n // If branch inserted a barrier for %cst0 and %cst1, but else didn't, then the barrier should be inserted in the parent region\n // CHECK-LABEL: multi_blocks\n-func @multi_blocks(%i1 : i1) {\n+func.func @multi_blocks(%i1 : i1) {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %cst1 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   scf.if %i1 {\n@@ -174,7 +174,7 @@ func @multi_blocks(%i1 : i1) {\n \n // Both branches inserted a barrier for %cst0 and %cst1, then the barrier doesn't need to be inserted in the parent region\n // CHECK-LABEL: multi_blocks_join_barrier\n-func @multi_blocks_join_barrier(%i1 : i1) {\n+func.func @multi_blocks_join_barrier(%i1 : i1) {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %cst1 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   scf.if %i1 {\n@@ -192,7 +192,7 @@ func @multi_blocks_join_barrier(%i1 : i1) {\n \n // Read yielded tensor requires a barrier\n // CHECK-LABEL: multi_blocks_yield\n-func @multi_blocks_yield(%i1 : i1) {\n+func.func @multi_blocks_yield(%i1 : i1) {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %cst1 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %a = scf.if %i1 -> (tensor<32x16xf16, #A_SHARED>) {\n@@ -212,7 +212,7 @@ func @multi_blocks_yield(%i1 : i1) {\n \n // Conservatively add a barrier as if the branch (%i1) is never taken\n // CHECK-LABEL: multi_blocks_noelse\n-func @multi_blocks_noelse(%i1 : i1) {\n+func.func @multi_blocks_noelse(%i1 : i1) {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %cst1 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   scf.if %i1 {\n@@ -226,7 +226,7 @@ func @multi_blocks_noelse(%i1 : i1) {\n \n // Conservatively add a barrier as if the branch (%i2) is never taken\n // CHECK-LABEL: multi_blocks_nested_scf\n-func @multi_blocks_nested_scf(%i1 : i1, %i2 : i1) {\n+func.func @multi_blocks_nested_scf(%i1 : i1, %i2 : i1) {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   %cst1 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #A_SHARED>\n   scf.if %i1 {\n@@ -247,7 +247,7 @@ func @multi_blocks_nested_scf(%i1 : i1, %i2 : i1) {\n }\n \n // CHECK-LABEL: for\n-func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   %b_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   %c_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n@@ -262,7 +262,7 @@ func @for(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.p\n // Although a_shared and b_shared are synced before entering the loop,\n // they are reassociated with aliases (c_shared) and thus require a barrier.\n // CHECK-LABEL: for_alias\n-func @for_alias(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @for_alias(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   %b_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: Membar 2\n@@ -282,7 +282,7 @@ func @for_alias(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B :\n // Although cst2 is not an argument of scf.yield, its memory is reused by cst1.\n // So we need a barrier both before and after cst1\n // CHECK-LABEL: for_reuse\n-func @for_reuse(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @for_reuse(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   %b_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: Membar 2\n@@ -302,7 +302,7 @@ func @for_reuse(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B :\n \n \n // CHECK-LABEL: for_reuse_nested\n-func @for_reuse_nested(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @for_reuse_nested(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   %b_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n   // CHECK-NEXT: Membar 2"}, {"filename": "test/Conversion/triton_ops.mlir", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "file_content_changes": "@@ -1,6 +1,6 @@\n // RUN: triton-opt %s | FileCheck %s\n \n-func @cast_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_f32: f32, %scalar_i64: i64) {\n+func.func @cast_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_f32: f32, %scalar_i64: i64) {\n   // scalar -> scalar\n   // CHECK:  i64 -> !tt.ptr<f32>\n   %0 = tt.int_to_ptr %scalar_i64 : i64 -> !tt.ptr<f32>\n@@ -35,7 +35,7 @@ func @cast_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_f32: f32, %scalar_i64: i64) {\n   return\n }\n \n-func @addptr_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_i32: i32) {\n+func.func @addptr_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_i32: i32) {\n   // scalar -> scalar\n   // CHECK: !tt.ptr<f32>\n   %0 = tt.addptr %scalar_ptr, %scalar_i32 : !tt.ptr<f32>, i32\n@@ -54,7 +54,7 @@ func @addptr_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_i32: i32) {\n   return\n }\n \n-func @load_store_ops_scalar(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %mask : i1) {\n+func.func @load_store_ops_scalar(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %mask : i1) {\n   // Test if Load/Store ops can handle scalar values\n   %other = arith.constant 0.0e+0 : f32\n \n@@ -76,7 +76,7 @@ func @load_store_ops_scalar(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %ma\n   return\n }\n \n-func @reduce_ops_infer(%ptr: !tt.ptr<f32>, %v : tensor<1x2x4xf32>) {\n+func.func @reduce_ops_infer(%ptr: !tt.ptr<f32>, %v : tensor<1x2x4xf32>) {\n   // Test if reduce ops infer types correctly\n \n   // CHECK: %{{.*}} = tt.reduce %{{.*}} -> tensor<2x4xf32>\n@@ -101,7 +101,7 @@ func @reduce_ops_infer(%ptr: !tt.ptr<f32>, %v : tensor<1x2x4xf32>) {\n   return\n }\n \n-func @dot_ops_infer(%ptr: !tt.ptr<f32>, %v : f32) {\n+func.func @dot_ops_infer(%ptr: !tt.ptr<f32>, %v : f32) {\n   // Test if reduce ops infer types correctly\n   %v128x32 = tt.splat %v : (f32) -> tensor<128x32xf32>\n   %v32x128 = tt.splat %v : (f32) -> tensor<32x128xf32>"}, {"filename": "test/Conversion/triton_to_tritongpu.mlir", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -1,6 +1,6 @@\n // RUN: triton-opt %s -split-input-file -convert-triton-to-tritongpu=num-warps=2 | FileCheck %s\n \n-func @ops() {\n+func.func @ops() {\n   // CHECK: module attributes {\"triton_gpu.num-warps\" = 2 : i32} {{.*}}\n   %a = arith.constant dense<1.00e+00> : tensor<128x32xf16>\n   %b = arith.constant dense<2.00e+00> : tensor<32x128xf16>\n@@ -11,7 +11,7 @@ func @ops() {\n \n // -----\n \n-func @load_ops(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n+func.func @load_ops(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n   // Test if LoadOp is lowered properly (see #771)\n   %ptrs = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<128x!tt.ptr<f32>>\n   %mask = arith.constant dense<true> : tensor<128xi1>\n@@ -30,7 +30,7 @@ func @load_ops(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n \n // -----\n \n-func @reduce_ops(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n+func.func @reduce_ops(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n   // Test if the total number of threadsPerWarp is 32\n   // Test if the total number of warps is 2\n   // CHECK: #blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [4, 8], warpsPerCTA = [1, 2], order = [0, 1]}>"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 46, "deletions": 46, "changes": 92, "file_content_changes": "@@ -4,7 +4,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK: llvm.func @test_empty_kernel(%arg0: i32, %arg1: !llvm.ptr<f16, 1>)\n   // Here the 128 comes from the 4 in module attribute multiples 32\n   // CHECK:  attributes {nvvm.kernel = 1 : ui1, nvvm.maxntid = 128 : i32} {{.*}}\n-  func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n+  func.func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n     // CHECK:  llvm.return\n     return\n   }\n@@ -15,7 +15,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_load\n-  func @basic_load(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>, %cst_0 : tensor<256xf32, #blocked0>) {\n+  func.func @basic_load(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>, %cst_0 : tensor<256xf32, #blocked0>) {\n     // CHECK: llvm.inline_asm\n     // CHECK: llvm.inline_asm\n     %1 = tt.load %a_ptr_init, %cst, %cst_0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<256xf32, #blocked0>\n@@ -28,7 +28,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [2], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: vectorized_load\n-  func @vectorized_load(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>, %cst_0 : tensor<256xf32, #blocked0>) {\n+  func.func @vectorized_load(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>, %cst_0 : tensor<256xf32, #blocked0>) {\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: ld.global.b32\n     // CHECK: llvm.inline_asm\n@@ -43,7 +43,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [8], threadsPerWarp = [32], warpsPerCTA = [1], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: vectorized_load_f16\n-  func @vectorized_load_f16(%a_ptr_init: tensor<256x!tt.ptr<f16>, #blocked0>, %cst : tensor<256xi1, #blocked0>, %cst_0 : tensor<256xf16, #blocked0>) {\n+  func.func @vectorized_load_f16(%a_ptr_init: tensor<256x!tt.ptr<f16>, #blocked0>, %cst : tensor<256xi1, #blocked0>, %cst_0 : tensor<256xf16, #blocked0>) {\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: ld.global.b16\n     // CHECK: llvm.inline_asm\n@@ -59,7 +59,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [8], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: masked_load_const_other\n-  func @masked_load_const_other(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>) {\n+  func.func @masked_load_const_other(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>) {\n     %cst_0 = arith.constant dense<0.000000e+00> : tensor<256xf32, #blocked0>\n     %1 = tt.load %a_ptr_init, %cst, %cst_0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<256xf32, #blocked0>\n     return\n@@ -72,7 +72,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [8], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: masked_load_const_other_vec\n-  func @masked_load_const_other_vec(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>) {\n+  func.func @masked_load_const_other_vec(%a_ptr_init : tensor<256x!tt.ptr<f32>, #blocked0>, %cst : tensor<256xi1, #blocked0>) {\n     %cst_0 = arith.constant dense<0.000000e+00> : tensor<256xf32, #blocked0>\n     %1 = tt.load %a_ptr_init, %cst, %cst_0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<256xf32, #blocked0>\n     return\n@@ -84,7 +84,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [2], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n   // CHECK-LABEL: global_load_store_no_vec\n-  func @global_load_store_no_vec(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg3: i32) {\n+  func.func @global_load_store_no_vec(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg3: i32) {\n     %c256_i32 = arith.constant 256 : i32\n     %0 = tt.get_program_id {axis = 0 : i32} : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n@@ -128,7 +128,7 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [2], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n   // CHECK-LABEL: global_load_store_vec4\n-  func @global_load_store_vec4(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg3: i32) {\n+  func.func @global_load_store_vec4(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg3: i32) {\n     %c256_i32 = arith.constant 256 : i32\n     %0 = tt.get_program_id {axis = 0 : i32} : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n@@ -165,7 +165,7 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n #blocked = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [2], order = [0]}>\n // Note, the %n_elements doesn't have a \"tt.divisibility\" hint, so Triton assumes it's divisibility is 1, this should effect the mask's alignment and further restrict the load/store ops' vector width to be 1.\n module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n-  func @vecadd_masked_vec1(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32) {\n+  func.func @vecadd_masked_vec1(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32) {\n     %c64_i32 = arith.constant 64 : i32\n     %0 = tt.get_program_id {axis = 0 : i32} : i32\n     %1 = arith.muli %0, %c64_i32 : i32\n@@ -195,7 +195,7 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [8], threadsPerWarp = [32], warpsPerCTA = [1], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: global_load_store_vec8\n-    func @global_load_store_vec8(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg3: i32) {\n+    func.func @global_load_store_vec8(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg3: i32) {\n     %c256_i32 = arith.constant 256 : i32\n     %0 = tt.get_program_id {axis = 0 : i32} : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n@@ -238,7 +238,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_view_broadcast\n-  func @basic_view_broadcast(%arg : tensor<256xf32,#blocked0>) {\n+  func.func @basic_view_broadcast(%arg : tensor<256xf32,#blocked0>) {\n     // CHECK: llvm.mlir.undef\n     // CHECK: %[[T0:.*]] = llvm.extractvalue\n     // CHECK: %[[T1:.*]] = llvm.extractvalue\n@@ -262,7 +262,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [2], threadsPerWarp = [32], warpsPerCTA = [1], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_make_range\n-  func @basic_make_range() {\n+  func.func @basic_make_range() {\n     // CHECK: nvvm.read.ptx.sreg.tid.x\n     // CHECK: llvm.mlir.undef\n     // CHECK: llvm.insertvalue\n@@ -277,7 +277,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_addf\n-  func @basic_addf(%arg0 : tensor<256xf32,#blocked0>, %arg1 : tensor<256xf32,#blocked0>) {\n+  func.func @basic_addf(%arg0 : tensor<256xf32,#blocked0>, %arg1 : tensor<256xf32,#blocked0>) {\n     // CHECK: llvm.fadd\n     // CHECK: llvm.fadd\n     %1 = arith.addf %arg0, %arg1 : tensor<256xf32,#blocked0>\n@@ -290,7 +290,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_addi\n-  func @basic_addi(%arg0 : tensor<256xi32,#blocked0>, %arg1 : tensor<256xi32,#blocked0>) {\n+  func.func @basic_addi(%arg0 : tensor<256xi32,#blocked0>, %arg1 : tensor<256xi32,#blocked0>) {\n     // CHECK: llvm.add\n     // CHECK: llvm.add\n     %1 = arith.addi %arg0, %arg1 : tensor<256xi32,#blocked0>\n@@ -302,7 +302,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_program_id\n-  func @basic_program_id() {\n+  func.func @basic_program_id() {\n     // CHECK: nvvm.read.ptx.sreg.ctaid.x : i32\n     %0 = tt.get_program_id {axis = 0 : i32} : i32\n     return\n@@ -314,7 +314,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_addptr\n-  func @basic_addptr(%arg0 : tensor<256x!tt.ptr<f32>,#blocked0>, %arg1 : tensor<256xi32,#blocked0>) {\n+  func.func @basic_addptr(%arg0 : tensor<256x!tt.ptr<f32>,#blocked0>, %arg1 : tensor<256xi32,#blocked0>) {\n     // CHECK: llvm.getelementptr\n     // CHECK: llvm.getelementptr\n     %0 = tt.addptr %arg0, %arg1 : tensor<256x!tt.ptr<f32>, #blocked0>, tensor<256xi32, #blocked0>\n@@ -328,7 +328,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem\n   // CHECK-LABEL: basic_alloc_tensor\n-  func @basic_alloc_tensor() {\n+  func.func @basic_alloc_tensor() {\n     // CHECK: llvm.mlir.addressof @global_smem\n     // CHECK-NEXT: llvm.bitcast\n     // CHECK-NEXT: llvm.mlir.constant\n@@ -345,7 +345,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem\n   // CHECK-LABEL: basic_extract_slice\n-  func @basic_extract_slice() {\n+  func.func @basic_extract_slice() {\n     // CHECK: llvm.mlir.addressof @global_smem\n     // CHECK: llvm.extractvalue\n     // CHECK-NEXT: llvm.extractvalue\n@@ -378,7 +378,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_async_wait\n-  func @basic_async_wait() {\n+  func.func @basic_async_wait() {\n     // CHECK: cp.async.wait_group 0x4\n     triton_gpu.async_wait {num = 4: i32}\n     return\n@@ -397,7 +397,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #A = #triton_gpu.shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_fallback\n-  func @basic_insert_slice_async_fallback(%arg0: !tt.ptr<f16> {tt.divisibility = 1 : i32}) {\n+  func.func @basic_insert_slice_async_fallback(%arg0: !tt.ptr<f16> {tt.divisibility = 1 : i32}) {\n     %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #slice2d1>\n     %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<64xi32, #slice3d0>\n     %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #slice2d1>) -> tensor<16x1xi32, #block2>\n@@ -436,7 +436,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #A = #triton_gpu.shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v4\n-  func @basic_insert_slice_async_v4(%arg0: !tt.ptr<f32> {tt.divisibility = 8 : i32}) {\n+  func.func @basic_insert_slice_async_v4(%arg0: !tt.ptr<f32> {tt.divisibility = 8 : i32}) {\n     %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #slice2d1>\n     %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<64xi32, #slice3d0>\n     %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #slice2d1>) -> tensor<16x1xi32, #block2>\n@@ -478,7 +478,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #A = #triton_gpu.shared<{vec = 1, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v1\n-  func @basic_insert_slice_async_v1(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n+  func.func @basic_insert_slice_async_v1(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n     %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #slice2d1>\n     %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #slice3d0>\n     %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #slice2d1>) -> tensor<16x1xi32, #block2>\n@@ -523,7 +523,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #A = #triton_gpu.shared<{vec = 1, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v1_multictas\n-  func @basic_insert_slice_async_v1_multictas(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n+  func.func @basic_insert_slice_async_v1_multictas(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n     %off0_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #slice2d1>\n     %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #slice3d0>\n     %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<32xi32, #slice2d1>) -> tensor<32x1xi32, #block2>\n@@ -574,7 +574,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK: basic_splat\n-  func @basic_splat(%ptr: !tt.ptr<f32>) {\n+  func.func @basic_splat(%ptr: !tt.ptr<f32>) {\n     // CHECK: llvm.mlir.undef\n     // CHECK: llvm.insertvalue\n     // CHECK: llvm.insertvalue\n@@ -588,7 +588,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_store\n-  func @basic_store(%ptrs: tensor<256x!tt.ptr<f32>, #blocked0>, %vals: tensor<256xf32, #blocked0>, %mask: tensor<256xi1, #blocked0>) {\n+  func.func @basic_store(%ptrs: tensor<256x!tt.ptr<f32>, #blocked0>, %vals: tensor<256xf32, #blocked0>, %mask: tensor<256xi1, #blocked0>) {\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: st.global.b32 [ ${{.*}} + 0 ], { ${{.*}} };\n     // CHECK: llvm.inline_asm\n@@ -605,7 +605,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_blocked\n-  func @convert_layout_blocked_blocked(%arg0: tensor<16x16xf32, #blocked0>) {\n+  func.func @convert_layout_blocked_blocked(%arg0: tensor<16x16xf32, #blocked0>) {\n     // CHECK: llvm.mlir.addressof @global_smem\n     // CHECK: llvm.store\n     // CHECK-SAME: !llvm.ptr<vector<1xf32>, 3>\n@@ -652,7 +652,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_blocked_vec\n-  func @convert_layout_blocked_blocked_vec(%arg0: tensor<16x16xf32, #blocked0>) {\n+  func.func @convert_layout_blocked_blocked_vec(%arg0: tensor<16x16xf32, #blocked0>) {\n     // CHECK: llvm.mlir.addressof @global_smem\n     // CHECK: llvm.store\n     // CHECK-SAME: !llvm.ptr<vector<4xf32>, 3>\n@@ -675,7 +675,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_blocked_multi_rep\n-  func @convert_layout_blocked_blocked_multi_rep(%arg0: tensor<16x16xf32, #blocked0>) {\n+  func.func @convert_layout_blocked_blocked_multi_rep(%arg0: tensor<16x16xf32, #blocked0>) {\n     // CHECK: llvm.mlir.addressof @global_smem\n     // CHECK: llvm.store\n     // CHECK-SAME: !llvm.ptr<vector<4xf32>, 3>\n@@ -706,7 +706,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma0}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: convert_dot\n-  func @convert_dot(%A: tensor<16x16xf16, #blocked0>, %B: tensor<16x16xf16, #blocked0>) {\n+  func.func @convert_dot(%A: tensor<16x16xf16, #blocked0>, %B: tensor<16x16xf16, #blocked0>) {\n     %AA = triton_gpu.convert_layout %A : (tensor<16x16xf16, #blocked0>) -> tensor<16x16xf16, #shared0>\n     %BB = triton_gpu.convert_layout %B : (tensor<16x16xf16, #blocked0>) -> tensor<16x16xf16, #shared0>\n     // CHECK: llvm.inline_asm\n@@ -730,7 +730,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n // TODO: problems in MLIR's parser on slice layout\n // #blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [8, 4], warpsPerCTA = [1, 1], order = [1, 0]}>\n // module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n-//   func @make_range_sliced_layout() {\n+//   func.func @make_range_sliced_layout() {\n //     %0 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #triton_gpu.slice<{dim = 0, parent = #blocked0}>>\n //     return\n //   }\n@@ -743,7 +743,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_mmav2_block\n-  func @convert_layout_mmav2_blocked(%arg0: tensor<32x16xf32, #mma>) {\n+  func.func @convert_layout_mmav2_blocked(%arg0: tensor<32x16xf32, #mma>) {\n     // CHECK: llvm.store\n     // CHECK-SAME: !llvm.ptr<vector<2xf32>, 3>\n     // CHECK: llvm.store\n@@ -763,7 +763,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_mmav1_block\n-  func @convert_layout_mmav1_blocked(%arg0: tensor<32x64xf32, #mma>) {\n+  func.func @convert_layout_mmav1_blocked(%arg0: tensor<32x64xf32, #mma>) {\n     // CHECK: llvm.store\n     // CHECK-SAME: !llvm.ptr<vector<2xf32>, 3>\n     // CHECK: llvm.store\n@@ -786,7 +786,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_shared\n-  func @convert_layout_blocked_shared(%arg0: tensor<128x32xf32, #blocked0>) {\n+  func.func @convert_layout_blocked_shared(%arg0: tensor<128x32xf32, #blocked0>) {\n     // CHECK: llvm.store\n     // CHECK-SAME: !llvm.ptr<vector<8xf32>, 3>\n     // CHECK: llvm.store\n@@ -802,7 +802,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [1, 1], order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: convert_blocked1d_to_slice0\n-  func @convert_blocked1d_to_slice0(%src:tensor<32xi32, #blocked0>) {\n+  func.func @convert_blocked1d_to_slice0(%src:tensor<32xi32, #blocked0>) {\n     // CHECK-COUNT-4: llvm.load {{.*}} : !llvm.ptr<vector<1xi32>, 3>\n     %cvt = triton_gpu.convert_layout %src : (tensor<32xi32, #blocked0>) -> tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked1}>>\n     return\n@@ -815,7 +815,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [1, 1], order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: convert_blocked1d_to_slice1\n-  func @convert_blocked1d_to_slice1(%src:tensor<32xi32, #blocked0>) {\n+  func.func @convert_blocked1d_to_slice1(%src:tensor<32xi32, #blocked0>) {\n     // CHECK-COUNT-32: llvm.load {{.*}} : !llvm.ptr<vector<1xi32>, 3>\n     %cvt = triton_gpu.convert_layout %src : (tensor<32xi32, #blocked0>) -> tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>\n     return\n@@ -828,7 +828,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [1], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: convert_blocked_to_blocked_ptr\n-  func @convert_blocked_to_blocked_ptr(%src:tensor<32x!tt.ptr<f32>, #blocked0>) {\n+  func.func @convert_blocked_to_blocked_ptr(%src:tensor<32x!tt.ptr<f32>, #blocked0>) {\n     // CHECK: llvm.ptrtoint\n     // CHECK: llvm.store\n     // CHECK: nvvm.barrier0\n@@ -847,7 +847,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma}>\n #dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  func @matmul_kernel_dot_operand_layout(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n+  func.func @matmul_kernel_dot_operand_layout(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n   %a:tensor<128x32xf16, #shared>, %b:tensor<32x256xf16, #shared>) {\n     %cst = arith.constant dense<0.000000e+00> : tensor<128x256xf32, #mma>\n     // CHECK: ldmatrix.sync.aligned.m8n8.x4.shared.b16\n@@ -873,7 +873,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma, isMMAv1Row=true}>\n #dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma, isMMAv1Row=true}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  func @matmul884_kernel_dot_operand_layout(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n+  func.func @matmul884_kernel_dot_operand_layout(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n   %a:tensor<32x64xf16, #shared0>, %b:tensor<64x64xf16, #shared1>) {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32x64xf32, #mma>\n     // CHECK: ldmatrix.sync.aligned.m8n8.x4.shared.b16\n@@ -896,7 +896,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#blocked}>\n #dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#blocked}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  func @matmul_fmadot(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n+  func.func @matmul_fmadot(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n   %a:tensor<32x16xf32, #shared>, %b:tensor<16x32xf32, #shared>) {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked>\n     // CHECK: llvm.intr.fmuladd\n@@ -920,7 +920,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: matmul_tf32dot\n-  func @matmul_tf32dot(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n+  func.func @matmul_tf32dot(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n   %a:tensor<32x16xf32, #shared>, %b:tensor<16x32xf32, #shared>) {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma>\n     // CHECK: llvm.inline_asm\n@@ -955,7 +955,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: atomic_add_f32\n-  func @atomic_add_f32(%arg0 : tensor<256x!tt.ptr<f32>, #blocked0>, %arg1 : tensor<256xi1, #blocked0>, %arg2 : tensor<256xf32, #blocked0>) {\n+  func.func @atomic_add_f32(%arg0 : tensor<256x!tt.ptr<f32>, #blocked0>, %arg1 : tensor<256xi1, #blocked0>, %arg2 : tensor<256xf32, #blocked0>) {\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: atom.global.gpu.add.f32\n     %0 = \"tt.atomic_rmw\" (%arg0, %arg2, %arg1) {atomic_rmw_op = 5 : i32} : (tensor<256x!tt.ptr<f32>, #blocked0>, tensor<256xf32, #blocked0>, tensor<256xi1, #blocked0>) -> tensor<256xf32, #blocked0>\n@@ -967,7 +967,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n-func @test_get_program_id(%a: tensor<32x!tt.ptr<i32>, #blocked0>) {\n+func.func @test_get_program_id(%a: tensor<32x!tt.ptr<i32>, #blocked0>) {\n   %blockidx = tt.get_program_id {axis=0:i32} : i32\n   %blockidy = tt.get_program_id {axis=1:i32} : i32\n   %blockidz = tt.get_program_id {axis=2:i32} : i32\n@@ -987,7 +987,7 @@ func @test_get_program_id(%a: tensor<32x!tt.ptr<i32>, #blocked0>) {\n // -----\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  func @test_get_num_program(%a: tensor<32x!tt.ptr<i32>, #blocked0>) {\n+  func.func @test_get_num_program(%a: tensor<32x!tt.ptr<i32>, #blocked0>) {\n     // CHECK: nvvm.read.ptx.sreg.nctaid.x\n     // CHECK: nvvm.read.ptx.sreg.nctaid.y\n     // CHECK: nvvm.read.ptx.sreg.nctaid.z\n@@ -1007,7 +1007,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [2], threadsPerWarp = [32], warpsPerCTA = [1], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: test_index_cache\n-  func @test_index_cache() {\n+  func.func @test_index_cache() {\n     // CHECK: nvvm.read.ptx.sreg.tid.x\n     %0 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked0>\n     // CHECK-NOT: nvvm.read.ptx.sreg.tid.x\n@@ -1021,7 +1021,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #shared0 = #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: test_base_index_cache\n-  func @test_base_index_cache(%arg0: tensor<128x32xf32, #blocked0>) {\n+  func.func @test_base_index_cache(%arg0: tensor<128x32xf32, #blocked0>) {\n     // CHECK: nvvm.read.ptx.sreg.tid.x\n     %0 = triton_gpu.convert_layout %arg0 : (tensor<128x32xf32, #blocked0>) -> tensor<128x32xf32, #shared0>\n     // CHECK-NOT: nvvm.read.ptx.sreg.tid.x\n@@ -1035,7 +1035,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #shared0 = #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: test_index_cache_different_block\n-  func @test_index_cache_different_block(%arg0: tensor<128x32xf32, #blocked0>, %arg1: i1) {\n+  func.func @test_index_cache_different_block(%arg0: tensor<128x32xf32, #blocked0>, %arg1: i1) {\n     // CHECK: nvvm.read.ptx.sreg.tid.x\n     %0 = triton_gpu.convert_layout %arg0 : (tensor<128x32xf32, #blocked0>) -> tensor<128x32xf32, #shared0>\n     scf.if %arg1 {"}, {"filename": "test/Target/tritongpu_to_llvmir.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -4,11 +4,11 @@\n // CHECK-LABEL: ; ModuleID = 'LLVMDialectModule'\n // CHECK: define void @test_empty_kernel\n // CHECK: !nvvm.annotations\n-// CHECK: !{void (i32, half addrspace(1)*)* @test_empty_kernel, !\"maxntidx\", i32 128}\n+// CHECK: !{ptr @test_empty_kernel, !\"maxntidx\", i32 128}\n \n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n-func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n+func.func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n \n   return\n }"}, {"filename": "test/Target/tritongpu_to_ptx.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -6,7 +6,7 @@\n \n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n-func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n+func.func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n \n   return\n }"}, {"filename": "test/Triton/combine.mlir", "status": "modified", "additions": 18, "deletions": 18, "changes": 36, "file_content_changes": "@@ -2,10 +2,10 @@\n // RUN: triton-opt %s -split-input-file -canonicalize -triton-combine | FileCheck %s\n \n // CHECK-LABEL: @test_combine_dot_add_pattern\n-func @test_combine_dot_add_pattern() -> (tensor<128x128xf32>, tensor<128x128xf32>) {\n-    // CHECK: %[[d:.*]] = arith.constant dense<3.000000e+00> : tensor<128x128xf32>\n-    // CHECK: %[[b:.*]] = arith.constant dense<2.000000e+00> : tensor<128x128xf32>\n-    // CHECK: %[[a:.*]] = arith.constant dense<1.000000e+00> : tensor<128x128xf32>\n+func.func @test_combine_dot_add_pattern() -> (tensor<128x128xf32>, tensor<128x128xf32>) {\n+    // CHECK-DAG: %[[d:.*]] = arith.constant dense<3.000000e+00> : tensor<128x128xf32>\n+    // CHECK-DAG: %[[b:.*]] = arith.constant dense<2.000000e+00> : tensor<128x128xf32>\n+    // CHECK-DAG: %[[a:.*]] = arith.constant dense<1.000000e+00> : tensor<128x128xf32>\n     %a = arith.constant dense<1.0> : tensor<128x128xf32>\n     %b = arith.constant dense<2.0> : tensor<128x128xf32>\n     %zero = arith.constant dense<0.0> : tensor<128x128xf32>\n@@ -24,7 +24,7 @@ func @test_combine_dot_add_pattern() -> (tensor<128x128xf32>, tensor<128x128xf32\n \n \n // COM: CHECK-LABEL: @test_combine_addptr_pattern\n-func @test_combine_addptr_pattern(%base: !tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>> {\n+func.func @test_combine_addptr_pattern(%base: !tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>> {\n     %off0 = arith.constant 10 : i32\n     %off1 = arith.constant 15 : i32\n \n@@ -47,40 +47,40 @@ func @test_combine_addptr_pattern(%base: !tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n \n \n // CHECK-LABEL: @test_combine_select_masked_load_pattern\n-func @test_combine_select_masked_load_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %cond: i1) -> (tensor<8xf32>, tensor<8xf32>) {\n+func.func @test_combine_select_masked_load_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %cond: i1) -> (tensor<8xf32>, tensor<8xf32>) {\n     %mask = tt.broadcast %cond : (i1) -> tensor<8xi1>\n     %false_val = arith.constant dense<0.0> : tensor<8xf32>\n \n     // CHECK: %[[res1:.*]] = tt.load %{{.*}}, %{{.*}}, %{{.*}} {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n     %x = tt.load %ptr, %mask, %false_val {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n-    %0 = select %cond, %x, %false_val : tensor<8xf32>\n+    %0 = arith.select %cond, %x, %false_val : tensor<8xf32>\n \n     // CHECK: %[[res2:.*]] = tt.load %{{.*}}, %{{.*}}, %{{.*}} {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n     %y = tt.load %ptr, %mask, %false_val {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n-    %1 = select %cond, %y, %false_val : tensor<8xf32>\n+    %1 = arith.select %cond, %y, %false_val : tensor<8xf32>\n \n     // CHECK: return %[[res1]], %[[res2]] : tensor<8xf32>, tensor<8xf32>\n     return %0, %1 : tensor<8xf32>, tensor<8xf32>\n }\n \n // CHECK-LABEL: @test_combine_select_masked_load_fail_pattern\n-func @test_combine_select_masked_load_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %dummy_load: tensor<8xf32>, %dummy_broadcast: tensor<8xi1>, %cond: i1) -> (tensor<8xf32>, tensor<8xf32>) {\n+func.func @test_combine_select_masked_load_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %dummy_load: tensor<8xf32>, %dummy_broadcast: tensor<8xi1>, %cond: i1) -> (tensor<8xf32>, tensor<8xf32>) {\n     %false_val = arith.constant dense<0.0> : tensor<8xf32>\n \n     // Case 1: value at the \"load\" position is not an \"op\".  Select should not be canonicalized.\n-    // CHECK: %{{.*}} = select %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n-    %0 = select %cond, %dummy_load, %false_val : tensor<8xf32>\n+    // CHECK: %{{.*}} = arith.select %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n+    %0 = arith.select %cond, %dummy_load, %false_val : tensor<8xf32>\n \n     // Case 2: value at the \"broadcast\" position is not an \"op\".  Select should not be canonicalized.\n     %real_load = tt.load %ptr, %dummy_broadcast, %false_val {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n-    // CHECK: %{{.*}} = select %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n-    %1 = select %cond, %real_load, %false_val : tensor<8xf32>\n+    // CHECK: %{{.*}} = arith.select %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n+    %1 = arith.select %cond, %real_load, %false_val : tensor<8xf32>\n \n     return %0, %1 : tensor<8xf32>, tensor<8xf32>\n }\n \n // CHECK-LABEL: @test_combine_broadcast_constant_pattern\n-func @test_combine_broadcast_constant_pattern(%cst : f32) -> tensor<8x2xf32> {\n+func.func @test_combine_broadcast_constant_pattern(%cst : f32) -> tensor<8x2xf32> {\n     // CHECK: %[[cst:.*]] = arith.constant dense<1.000000e+00> : tensor<8x2xf32>\n     %const = arith.constant dense<1.0> : tensor<8xf32>\n     %bst_out = tt.broadcast %const : (tensor<8xf32>) -> tensor<8x2xf32>\n@@ -90,7 +90,7 @@ func @test_combine_broadcast_constant_pattern(%cst : f32) -> tensor<8x2xf32> {\n }\n \n // CHECK-LABEL: @test_canonicalize_masked_load_pattern\n-func @test_canonicalize_masked_load_pattern(%ptr: tensor<8x!tt.ptr<f32>>) -> (tensor<8xf32>, tensor<8xf32>, tensor<8xf32>) {\n+func.func @test_canonicalize_masked_load_pattern(%ptr: tensor<8x!tt.ptr<f32>>) -> (tensor<8xf32>, tensor<8xf32>, tensor<8xf32>) {\n     %true_mask = arith.constant dense<true> : tensor<8xi1>\n     %false_mask = arith.constant dense<false> : tensor<8xi1>\n     %other_val = arith.constant dense<0.0> : tensor<8xf32>\n@@ -111,7 +111,7 @@ func @test_canonicalize_masked_load_pattern(%ptr: tensor<8x!tt.ptr<f32>>) -> (te\n }\n \n // CHECK-LABEL: @test_canonicalize_masked_load_fail_pattern\n-func @test_canonicalize_masked_load_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %mask: tensor<8xi1>) -> (tensor<8xf32>, tensor<8xf32>) {\n+func.func @test_canonicalize_masked_load_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %mask: tensor<8xi1>) -> (tensor<8xf32>, tensor<8xf32>) {\n     %other_val = arith.constant dense<0.0> : tensor<8xf32>\n \n     // Case: value at the \"mask\" position is not an \"op\".  Load should not be canonicalized.\n@@ -124,7 +124,7 @@ func @test_canonicalize_masked_load_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %\n }\n \n // CHECK-LABEL: @test_canonicalize_masked_store_pattern\n-func @test_canonicalize_masked_store_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %val: tensor<8xf32>) {\n+func.func @test_canonicalize_masked_store_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %val: tensor<8xf32>) {\n     %true_mask = arith.constant dense<true> : tensor<8xi1>\n     %false_mask = arith.constant dense<false> : tensor<8xi1>\n \n@@ -138,7 +138,7 @@ func @test_canonicalize_masked_store_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %val:\n }\n \n // CHECK-LABEL: @test_canonicalize_masked_store_fail_pattern\n-func @test_canonicalize_masked_store_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %val: tensor<8xf32>, %mask: tensor<8xi1>) {\n+func.func @test_canonicalize_masked_store_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %val: tensor<8xf32>, %mask: tensor<8xi1>) {\n     // Case: value at the \"mask\" position is not an \"op\".  Store should not be canonicalized.\n     // CHECK: tt.store %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n     tt.store %ptr, %val, %mask : tensor<8xf32>"}, {"filename": "test/Triton/vecadd.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1,7 +1,7 @@\n // RUN: triton-opt %s -verify-diagnostics\n \n module {\n-  func @add_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32__(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) {\n+  func.func @add_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32__(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) {\n     %0 = tt.get_program_id {axis = 0 : i32} : i32\n     %c256_i32 = arith.constant 256 : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n@@ -43,7 +43,7 @@ module {\n   }\n }\n // module {\n-//   func @add_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32__(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) {\n+//   func.func @add_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32__(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) {\n //     %c64 = arith.constant 64 : index\n //     %c32 = arith.constant 32 : index\n //     %c0 = arith.constant 0 : index"}, {"filename": "test/TritonGPU/coalesce.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -19,7 +19,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n // CHECK: [[store_val:%.*]] = triton_gpu.convert_layout {{.*}} -> tensor<64x64xf32, [[col_layout]]>\n // CHECK: [[store_mask:%.*]] = triton_gpu.convert_layout {{.*}} -> tensor<64x64xi1, [[col_layout]]>\n // CHECK: tt.store [[store_ptr]], [[store_val]], [[store_mask]]\n-func @transpose(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32},\n+func.func @transpose(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32},\n                 %arg1: i32 {tt.divisibility = 16 : i32},\n                 %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32},\n                 %arg3: i32 {tt.divisibility = 16 : i32}) {"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 18, "deletions": 18, "changes": 36, "file_content_changes": "@@ -9,7 +9,7 @@\n // CHECK: [[col_layout:#.*]] = #triton_gpu.blocked<{sizePerThread = [4, 1], threadsPerWarp = [16, 2], warpsPerCTA = [4, 1], order = [0, 1]}>\n // CHECK: [[col_layout_novec:#.*]] = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>\n // CHECK-LABEL: cst\n-func @cst() -> tensor<1024xi32, #layout1> {\n+func.func @cst() -> tensor<1024xi32, #layout1> {\n   %cst = arith.constant dense<0> : tensor<1024xi32, #layout0>\n   %1 = triton_gpu.convert_layout %cst : (tensor<1024xi32, #layout0>) -> tensor<1024xi32, #layout1>\n   // CHECK-NOT: triton_gpu.convert_layout\n@@ -18,7 +18,7 @@ func @cst() -> tensor<1024xi32, #layout1> {\n }\n \n // CHECK-LABEL: range\n-func @range() -> tensor<1024xi32, #layout1> {\n+func.func @range() -> tensor<1024xi32, #layout1> {\n   %0 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32, #layout0>\n   %1 = triton_gpu.convert_layout %0 : (tensor<1024xi32, #layout0>) -> tensor<1024xi32, #layout1>\n   // CHECK-NOT: triton_gpu.convert_layout\n@@ -27,7 +27,7 @@ func @range() -> tensor<1024xi32, #layout1> {\n }\n \n // CHECK-LABEL: splat\n-func @splat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n+func.func @splat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n   %0 = tt.splat %arg0 : (i32) -> tensor<1024xi32, #layout0>\n   %1 = triton_gpu.convert_layout %0 : (tensor<1024xi32, #layout0>) -> tensor<1024xi32, #layout1>\n   // CHECK-NOT: triton_gpu.convert_layout\n@@ -36,7 +36,7 @@ func @splat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n }\n \n // CHECK-LABEL: remat\n-func @remat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n+func.func @remat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n   %0 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32, #layout0>\n   %1 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32, #layout0>\n   %2 = arith.muli %0, %1 : tensor<1024xi32, #layout0>\n@@ -56,7 +56,7 @@ func @remat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n }\n \n // CHECK-LABEL: remat_load_store\n-func @remat_load_store(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @remat_load_store(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #layout0>\n   %1 = tt.splat %arg : (!tt.ptr<i32>) -> tensor<64x!tt.ptr<i32>, #layout0>\n   %2 = tt.addptr %1, %0 : tensor<64x!tt.ptr<i32>, #layout0>, tensor<64xi32, #layout0>\n@@ -70,7 +70,7 @@ func @remat_load_store(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n \n // Don't rematerialize vectorized loads\n // CHECK-LABEL: remat_expensive\n-func @remat_expensive(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @remat_expensive(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #layout1>\n   %1 = tt.splat %arg : (!tt.ptr<i32>) -> tensor<64x!tt.ptr<i32>, #layout1>\n   %2 = tt.addptr %1, %0 : tensor<64x!tt.ptr<i32>, #layout1>, tensor<64xi32, #layout1>\n@@ -85,7 +85,7 @@ func @remat_expensive(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n \n // Don't rematerialize loads when original and target layouts are different\n // CHECK-LABEL: remat_multi_layout\n-func @remat_multi_layout(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @remat_multi_layout(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #layout0>\n   %1 = tt.splat %arg : (!tt.ptr<i32>) -> tensor<64x!tt.ptr<i32>, #layout0>\n   %2 = tt.addptr %1, %0 : tensor<64x!tt.ptr<i32>, #layout0>, tensor<64xi32, #layout0>\n@@ -100,7 +100,7 @@ func @remat_multi_layout(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n \n // Always rematerialize single value loads\n // CHECK-LABEL: remat_single_value\n-func @remat_single_value(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @remat_single_value(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %0 = tt.splat %arg : (!tt.ptr<i32>) -> tensor<1x!tt.ptr<i32>, #layout1>\n   %1 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<1xi32, #layout1>\n   // CHECK-NOT: triton_gpu.convert_layout\n@@ -111,7 +111,7 @@ func @remat_single_value(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n }\n \n // CHECK-LABEL: if\n-func @if(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @if(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   // CHECK-NOT: triton_gpu.convert_layout\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout1>\n   %0 = tt.get_program_id {axis = 0 : i32} : i32\n@@ -128,7 +128,7 @@ func @if(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n }\n \n // CHECK-LABEL: if_convert_else_not\n-func @if_convert_else_not(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @if_convert_else_not(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout0>\n   %0 = tt.get_program_id {axis = 0 : i32} : i32\n   %1 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout0>\n@@ -149,7 +149,7 @@ func @if_convert_else_not(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16\n }\n \n // CHECK-LABEL: if_not_else_convert\n-func @if_not_else_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @if_not_else_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout0>\n   %0 = tt.get_program_id {axis = 0 : i32} : i32\n   %1 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout0>\n@@ -170,7 +170,7 @@ func @if_not_else_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16\n }\n \n // CHECK-LABEL: if_else_both_convert\n-func @if_else_both_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n+func.func @if_else_both_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout0>\n   %0 = tt.get_program_id {axis = 0 : i32} : i32\n   %1 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout0>\n@@ -200,7 +200,7 @@ func @if_else_both_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16\n #blocked4 = #triton_gpu.blocked<{sizePerThread = [4, 1], threadsPerWarp = [16, 2], warpsPerCTA = [4, 1], order = [0, 1]}>\n \n // CHECK-LABEL: transpose\n-func @transpose(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32 {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}) {\n+func.func @transpose(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32 {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}) {\n   // CHECK-NOT: triton_gpu.convert_layout\n   // CHECK: [[loaded_val:%.*]] = tt.load {{.*}}, {{%cst.*}}, {{%cst.*}} {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<64x64xf32, [[row_layout]]>\n   // CHECK: [[cvt_val:%.*]] = triton_gpu.convert_layout [[loaded_val]] : (tensor<64x64xf32, [[row_layout]]>) -> tensor<64x64xf32, [[col_layout]]>\n@@ -241,7 +241,7 @@ func @transpose(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32 {tt\n }\n \n // CHECK-LABEL: loop\n-func @loop(%arg0: !tt.ptr<f32>, %arg1: i32, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32) {\n+func.func @loop(%arg0: !tt.ptr<f32>, %arg1: i32, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32) {\n     // CHECK-NOT: triton_gpu.convert_layout\n     // CHECK: [[loop_ret:%.*]]:2 = scf.for {{.*}} -> (tensor<64x64xf32, [[row_layout]]>, tensor<64x64x!tt.ptr<f32>, [[row_layout]]>)\n     // CHECK-NEXT: {{.*}} = tt.load {{.*}} : tensor<64x64xf32, [[row_layout]]>\n@@ -295,7 +295,7 @@ func @loop(%arg0: !tt.ptr<f32>, %arg1: i32, %arg2: !tt.ptr<f32>, %arg3: i32, %ar\n }\n \n // CHECK-LABEL: vecadd\n-func @vecadd(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32) {\n+func.func @vecadd(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32) {\n   // CHECK-NOT: triton_gpu.convert_layout\n   %c256_i32 = arith.constant 256 : i32\n   %0 = tt.get_program_id {axis = 0 : i32} : i32\n@@ -327,7 +327,7 @@ func @vecadd(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f3\n \n // Select has args with different element types\n // CHECK-LABEL: select\n-func @select(%arg0: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32}) {\n+func.func @select(%arg0: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32}) {\n   // CHECK-NOT: triton_gpu.convert_layout\n   %cst = arith.constant dense<30000> : tensor<1x1xi32, #blocked2>\n   %cst_0 = arith.constant dense<30000> : tensor<1x512xi32, #blocked2>\n@@ -378,7 +378,7 @@ func @select(%arg0: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f6\n \n // Make sure the following IR doesn't hang the compiler.\n // CHECK-LABEL: long_func\n-func public @long_func(%arg0: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg4: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg5: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg6: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg7: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg8: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg9: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg10: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg11: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg12: !tt.ptr<i32> {tt.divisibility = 16 : i32}, %arg13: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg14: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg15: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg16: i32 {tt.divisibility = 16 : i32}) {\n+func.func public @long_func(%arg0: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg4: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg5: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg6: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg7: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg8: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg9: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg10: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg11: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg12: !tt.ptr<i32> {tt.divisibility = 16 : i32}, %arg13: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg14: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg15: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg16: i32 {tt.divisibility = 16 : i32}) {\n   %cst = arith.constant dense<1.000000e+00> : tensor<1024xf32, #blocked0>\n   %cst_0 = arith.constant dense<5.000000e-04> : tensor<1024xf32, #blocked0>\n   %cst_1 = arith.constant dense<0.999499976> : tensor<1024xf32, #blocked0>\n@@ -775,7 +775,7 @@ func public @long_func(%arg0: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg1:\n // A mnist model from torch inductor.\n // Check if topological sort is working correct and there's no unnecessary convert\n // CHECK-LABEL: mnist\n-func public @mnist(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32}, %arg3: i32) {\n+func.func public @mnist(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32}, %arg3: i32) {\n   // CHECK-NOT: triton_gpu.convert_layout\n   %cst = arith.constant dense<10> : tensor<16x1xi32, #blocked2>\n   %cst_0 = arith.constant dense<10> : tensor<1x16xi32, #blocked3>"}, {"filename": "test/TritonGPU/loop-pipeline.mlir", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "file_content_changes": "@@ -10,7 +10,7 @@\n #A = #triton_gpu.dot_op<{opIdx = 0, parent = #C}>\n #B = #triton_gpu.dot_op<{opIdx = 1, parent = #C}>\n \n-// CHECK: func @matmul_loop\n+// CHECK: func.func @matmul_loop\n // CHECK-DAG: %[[CONSTANT_0:.*]] = arith.constant 0 : i32\n // CHECK-DAG: %[[CONSTANT_1:.*]] = arith.constant 1 : i32\n // CHECK-DAG: %[[CONSTANT_2:.*]] = arith.constant 2 : i32\n@@ -46,8 +46,8 @@\n // CHECK-DAG: %[[NEXT_PIPELINE_IDX:.*]] = arith.addi %[[PIPELINE_IDX]], %[[CONSTANT_1]]\n // CHECK-DAG: %[[NEXT_LOOP_IDX:.*]] = arith.addi %[[LOOP_IDX]], %[[CONSTANT_1]]\n // CHECK:   scf.yield {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_BUFFER]], %[[NEXT_B_BUFFER]], %[[NEXT_A]], %[[NEXT_B]], {{.*}}, {{.*}}, {{.*}}, %[[NEXT_PIPELINE_IDX]], %[[NEXT_LOOP_IDX]]\n-func @matmul_loop(%lb : index, %ub : index, %step : index, \n-                  %A : !tt.ptr<f16> {tt.divisibility = 16 : i32}, \n+func.func @matmul_loop(%lb : index, %ub : index, %step : index,\n+                  %A : !tt.ptr<f16> {tt.divisibility = 16 : i32},\n                   %B : !tt.ptr<f16> {tt.divisibility = 16 : i32}) {\n   // A ptrs\n   %a_ptr_splat = tt.splat %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n@@ -61,7 +61,7 @@ func @matmul_loop(%lb : index, %ub : index, %step : index,\n   %b_tmp1 = tt.expand_dims %b_tmp0 {axis = 0 : i32} : (tensor<128xi32, #BLs0>) -> tensor<1x128xi32, #BL>\n   %b_offs = tt.broadcast %b_tmp1 : (tensor<1x128xi32, #BL>) -> tensor<32x128xi32, #BL>\n   %b_ptr_init = tt.addptr %b_ptr_splat, %b_offs : tensor<32x128x!tt.ptr<f16>, #BL>, tensor<32x128xi32, #BL>\n-  \n+\n \n   %a_mask = arith.constant dense<true> : tensor<128x32xi1, #AL>\n   %a_other = arith.constant dense<0.00e+00> : tensor<128x32xf16, #AL>\n@@ -88,7 +88,7 @@ func @matmul_loop(%lb : index, %ub : index, %step : index,\n }\n \n \n-// CHECK: func @matmul_loop_nested\n+// CHECK: func.func @matmul_loop_nested\n // CHECK-DAG: %[[CONSTANT_0:.*]] = arith.constant 0 : i32\n // CHECK-DAG: %[[CONSTANT_1:.*]] = arith.constant 1 : i32\n // CHECK-DAG: %[[CONSTANT_2:.*]] = arith.constant 2 : i32\n@@ -118,8 +118,8 @@ func @matmul_loop(%lb : index, %ub : index, %step : index,\n // CHECK-DAG: %[[NEXT_PIPELINE_IDX:.*]] = arith.addi %[[PIPELINE_IDX]], %[[CONSTANT_1]]\n // CHECK-DAG: %[[NEXT_LOOP_IDX:.*]] = arith.addi %[[LOOP_IDX]], %[[CONSTANT_1]]\n // CHECK:     scf.yield {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_BUFFER]], %[[NEXT_B_BUFFER]], %[[NEXT_A]], %[[NEXT_B]], {{.*}}, {{.*}}, {{.*}}, %[[NEXT_PIPELINE_IDX]], %[[NEXT_LOOP_IDX]]\n-func @matmul_loop_nested(%lb : index, %ub : index, %step : index, \n-                         %A : !tt.ptr<f16> {tt.divisibility = 16 : i32}, \n+func.func @matmul_loop_nested(%lb : index, %ub : index, %step : index,\n+                         %A : !tt.ptr<f16> {tt.divisibility = 16 : i32},\n                          %B : !tt.ptr<f16> {tt.divisibility = 16 : i32}) {\n   scf.for %iv0 = %lb to %ub step %step {\n     // A ptrs\n@@ -134,7 +134,7 @@ func @matmul_loop_nested(%lb : index, %ub : index, %step : index,\n     %b_tmp1 = tt.expand_dims %b_tmp0 {axis = 0 : i32} : (tensor<128xi32, #BLs0>) -> tensor<1x128xi32, #BL>\n     %b_offs = tt.broadcast %b_tmp1 : (tensor<1x128xi32, #BL>) -> tensor<32x128xi32, #BL>\n     %b_ptr_init = tt.addptr %b_ptr_splat, %b_offs : tensor<32x128x!tt.ptr<f16>, #BL>, tensor<32x128xi32, #BL>\n-  \n+\n     %a_mask = arith.constant dense<true> : tensor<128x32xi1, #AL>\n     %a_other = arith.constant dense<0.00e+00> : tensor<128x32xf16, #AL>\n     %b_mask = arith.constant dense<true> : tensor<32x128xi1, #BL>\n@@ -161,7 +161,7 @@ func @matmul_loop_nested(%lb : index, %ub : index, %step : index,\n }\n \n \n-// CHECK: func @matmul_loop_single_pipeline\n+// CHECK: func.func @matmul_loop_single_pipeline\n // CHECK-DAG: %[[CONSTANT_0:.*]] = arith.constant 0 : i32\n // CHECK-DAG: %[[CONSTANT_1:.*]] = arith.constant 1 : i32\n // CHECK-DAG: %[[CONSTANT_2:.*]] = arith.constant 2 : i32\n@@ -183,8 +183,8 @@ func @matmul_loop_nested(%lb : index, %ub : index, %step : index,\n // CHECK-DAG: %[[NEXT_PIPELINE_IDX:.*]] = arith.addi %[[PIPELINE_IDX]], %[[CONSTANT_1]]\n // CHECK-DAG: %[[NEXT_LOOP_IDX:.*]] = arith.addi %[[LOOP_IDX]], %[[CONSTANT_1]]\n // CHECK:   scf.yield {{.*}}, {{.*}}, %[[NEXT_B_BUFFER]], %[[NEXT_B]], {{.*}}, {{.*}}, %[[NEXT_PIPELINE_IDX]], %[[NEXT_LOOP_IDX]]\n-func @matmul_loop_single_pipeline(%lb : index, %ub : index, %step : index, \n-                                  %A : !tt.ptr<f16> {tt.divisibility = 16 : i32}, \n+func.func @matmul_loop_single_pipeline(%lb : index, %ub : index, %step : index,\n+                                  %A : !tt.ptr<f16> {tt.divisibility = 16 : i32},\n                                   %B : !tt.ptr<f16> {tt.divisibility = 16 : i32}) {\n   // A ptrs\n   %a_ptr_splat = tt.splat %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>"}, {"filename": "test/TritonGPU/matmul.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -4,7 +4,7 @@\n // CHECK: offset = 49152, size = 49152\n // CHECK: size = 98304\n module {\n-func @matmul_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32_i32_i32_i32_i32_i32_i32__12c64_13c64_14c64_15c8(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32) {\n+func.func @matmul_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32_i32_i32_i32_i32_i32_i32__12c64_13c64_14c64_15c8(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32) {\n     %cst = arith.constant dense<true> : tensor<64x64xi1>\n     %c64 = arith.constant 64 : index\n     %c0 = arith.constant 0 : index\n@@ -22,7 +22,7 @@ func @matmul_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32_i32_i32_i32_i32_i32_i32__12c6\n     %7 = arith.muli %6, %c8_i32 : i32\n     %8 = arith.subi %2, %7 : i32\n     %9 = arith.cmpi slt, %8, %c8_i32 : i32\n-    %10 = select %9, %8, %c8_i32 : i32\n+    %10 = arith.select %9, %8, %c8_i32 : i32\n     %11 = arith.remsi %0, %10 : i32\n     %12 = arith.addi %7, %11 : i32\n     %13 = arith.remsi %0, %5 : i32"}, {"filename": "test/TritonGPU/prefetch.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -11,7 +11,7 @@\n #B_OP = #triton_gpu.dot_op<{opIdx = 1, parent = #C}>\n \n \n-// CHECK: func @matmul_loop\n+// CHECK: func.func @matmul_loop\n // CHECK-DAG: %[[A0_PREFETCH_SMEM:.*]] = tensor.extract_slice %[[A0:.*]][0, 0] [128, 16]\n // CHECK-DAG: %[[A0_PREFETCH:.*]] = triton_gpu.convert_layout %[[A0_PREFETCH_SMEM]]\n // CHECK-DAG: %[[B0_PREFETCH_SMEM:.*]] = tensor.extract_slice %[[B0:.*]][0, 0] [16, 128]\n@@ -28,7 +28,7 @@\n // CHECK-DAG:   %[[NEXT_B_PREFETCH_SMEM:.*]] = tensor.extract_slice {{.*}}[0, 0] [16, 128]\n // CHECK-DAG:   %[[NEXT_B_PREFETCH:.*]] = triton_gpu.convert_layout %[[NEXT_B_PREFETCH_SMEM]]\n // CHECK:     scf.yield {{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_PREFETCH]], %[[NEXT_B_PREFETCH]]\n-func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n+func.func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n   %b_ptr_init = tt.broadcast %B : (!tt.ptr<f16>) -> tensor<32x128x!tt.ptr<f16>, #BL>\n "}, {"filename": "test/TritonGPU/update-mma-for-volta.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -15,7 +15,7 @@\n // CHECK: [[new_mma:#mma.*]] = #triton_gpu.mma<{versionMajor = 1, versionMinor = 3, warpsPerCTA = [4, 2]}>\n module attributes {\"triton_gpu.num-warps\" = 16 : i32} {\n   // CHECK-LABEL: dot_mmav1\n-  func @dot_mmav1(%A: tensor<64x64xf16, #blocked0>, %B: tensor<64x64xf16, #blocked0>) -> tensor<64x64xf32, #blocked0> {\n+  func.func @dot_mmav1(%A: tensor<64x64xf16, #blocked0>, %B: tensor<64x64xf16, #blocked0>) -> tensor<64x64xf32, #blocked0> {\n     %C = arith.constant dense<0.000000e+00> : tensor<64x64xf32, #blocked0>\n     %AA = triton_gpu.convert_layout %A : (tensor<64x64xf16, #blocked0>) -> tensor<64x64xf16, #dot_operand_a>\n     %BB = triton_gpu.convert_layout %B : (tensor<64x64xf16, #blocked0>) -> tensor<64x64xf16, #dot_operand_b>\n@@ -50,7 +50,7 @@ module attributes {\"triton_gpu.num-warps\" = 16 : i32} {\n \n module attributes {\"triton_gpu.num-warps\" = 16 : i32} {\n   // CHECK-LABEL: dot_mmav1\n-  func @dot_mmav1(%A: tensor<64x64xf16, #blocked0>, %B: tensor<64x64xf16, #blocked0>) -> tensor<64x64xf32, #blocked0> {\n+  func.func @dot_mmav1(%A: tensor<64x64xf16, #blocked0>, %B: tensor<64x64xf16, #blocked0>) -> tensor<64x64xf32, #blocked0> {\n     %C = arith.constant dense<0.000000e+00> : tensor<64x64xf32, #blocked0>\n     %AA = triton_gpu.convert_layout %A : (tensor<64x64xf16, #blocked0>) -> tensor<64x64xf16, #dot_operand_a>\n     %BB = triton_gpu.convert_layout %B : (tensor<64x64xf16, #blocked0>) -> tensor<64x64xf16, #dot_operand_b>"}, {"filename": "test/lib/Analysis/TestAlias.cpp", "status": "modified", "additions": 15, "deletions": 14, "changes": 29, "file_content_changes": "@@ -9,10 +9,10 @@ using namespace mlir;\n namespace {\n \n struct TestAliasPass\n-    : public PassWrapper<TestAliasPass, OperationPass<FuncOp>> {\n+    : public PassWrapper<TestAliasPass, OperationPass<func::FuncOp>> {\n+\n+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestAliasPass);\n \n-  // LLVM15+\n-  // MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestAliasPass);\n   static void print(StringRef name, SmallVector<std::string, 4> &vals,\n                     raw_ostream &os) {\n     if (vals.empty())\n@@ -39,23 +39,24 @@ struct TestAliasPass\n     auto opName = SymbolTable::getSymbolName(operation).getValue().str();\n     os << opName << \"\\n\";\n \n-    SharedMemoryAliasAnalysis analysis(&getContext());\n-    analysis.run(operation);\n+    std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n+    SharedMemoryAliasAnalysis *analysis =\n+        solver->load<SharedMemoryAliasAnalysis>();\n+    if (failed(solver->initializeAndRun(operation)))\n+      return signalPassFailure();\n \n     AsmState state(operation->getParentOfType<ModuleOp>());\n     // Get operation ids of value's aliases\n     auto getAllocOpNames = [&](Value value) {\n-      LatticeElement<AliasInfo> *latticeElement =\n-          analysis.lookupLatticeElement(value);\n+      dataflow::Lattice<AliasInfo> *latticeElement =\n+          analysis->getLatticeElement(value);\n       SmallVector<std::string, 4> opNames;\n-      if (latticeElement) {\n+      if (latticeElement && !latticeElement->isUninitialized()) {\n         auto &info = latticeElement->getValue();\n-        if (!info.getAllocs().empty()) {\n-          for (auto &alias : info.getAllocs()) {\n-            auto opName =\n-                getValueOperandName(alias.getDefiningOp()->getResult(0), state);\n-            opNames.push_back(std::move(opName));\n-          }\n+        for (auto &alias : info.getAllocs()) {\n+          auto opName =\n+              getValueOperandName(alias.getDefiningOp()->getResult(0), state);\n+          opNames.push_back(std::move(opName));\n         }\n       }\n       // Ensure deterministic output"}, {"filename": "test/lib/Analysis/TestAllocation.cpp", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -6,10 +6,9 @@ using namespace mlir;\n namespace {\n \n struct TestAllocationPass\n-    : public PassWrapper<TestAllocationPass, OperationPass<FuncOp>> {\n+    : public PassWrapper<TestAllocationPass, OperationPass<func::FuncOp>> {\n \n-  // LLVM15+\n-  // MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestAllocationPass);\n+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestAllocationPass);\n \n   StringRef getArgument() const final { return \"test-print-allocation\"; }\n   StringRef getDescription() const final {"}, {"filename": "test/lib/Analysis/TestAxisInfo.cpp", "status": "modified", "additions": 10, "deletions": 39, "changes": 49, "file_content_changes": "@@ -1,25 +1,15 @@\n #include \"mlir/Pass/Pass.h\"\n #include \"triton/Analysis/AxisInfo.h\"\n+#include \"triton/Analysis/Utility.h\"\n \n using namespace mlir;\n \n namespace {\n \n struct TestAxisInfoPass\n-    : public PassWrapper<TestAxisInfoPass, OperationPass<FuncOp>> {\n+    : public PassWrapper<TestAxisInfoPass, OperationPass<func::FuncOp>> {\n \n-  // LLVM15+\n-  // MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestAlignmentPass);\n-\n-  void print(const std::string &name, raw_ostream &os, ArrayRef<int64_t> vals) {\n-    os << name << \": [\";\n-    for (size_t d = 0; d < vals.size(); d++) {\n-      if (d != 0)\n-        os << \", \";\n-      os << vals[d];\n-    }\n-    os << \"]\";\n-  }\n+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestAxisInfoPass);\n \n   StringRef getArgument() const final { return \"test-print-alignment\"; }\n   StringRef getDescription() const final {\n@@ -31,37 +21,18 @@ struct TestAxisInfoPass\n     auto &os = llvm::errs();\n     auto opName = SymbolTable::getSymbolName(operation).getValue().str();\n     os << opName << \"\\n\";\n-    AxisInfoAnalysis analysis(&getContext());\n-    analysis.run(operation);\n+\n+    std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n+    AxisInfoAnalysis *analysis = solver->load<AxisInfoAnalysis>();\n+    if (failed(solver->initializeAndRun(operation)))\n+      return signalPassFailure();\n     operation->walk([&](Operation *op) {\n       if (op->getNumResults() < 1)\n         return;\n       for (Value result : op->getResults()) {\n-        // std::ostringstream oss;\n-        // result.print(oss);\n-        // os << \" => \";\n-        LatticeElement<AxisInfo> *latticeElement =\n-            analysis.lookupLatticeElement(result);\n-        if (!latticeElement) {\n-          os << \"None\\n\";\n-          return;\n-        }\n-        AxisInfo &info = latticeElement->getValue();\n-        print(\"Contiguity\", os, info.getContiguity());\n-        os << \" ; \";\n-        print(\"Divisibility\", os, info.getDivisibility());\n-        os << \" ; \";\n-        print(\"Constancy\", os, info.getConstancy());\n-        os << \" ; \";\n-        auto constantValue = info.getConstantValue();\n-        os << \"ConstantValue: [\";\n-        if (constantValue.has_value())\n-          os << constantValue.value();\n-        else\n-          os << \"None\";\n-        os << \"] ( \";\n         result.print(os);\n-        os << \" ) \";\n+        os << \" => \";\n+        analysis->getLatticeElement(result)->getValue().print(os);\n         os << \"\\n\";\n       }\n     });"}, {"filename": "test/lib/Analysis/TestMembar.cpp", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "file_content_changes": "@@ -1,4 +1,4 @@\n-#include \"mlir/Dialect/GPU/GPUDialect.h\"\n+#include \"mlir/Dialect/GPU/IR/GPUDialect.h\"\n #include \"mlir/IR/Dialect.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"triton/Analysis/Allocation.h\"\n@@ -9,10 +9,9 @@ using namespace mlir;\n namespace {\n \n struct TestMembarPass\n-    : public PassWrapper<TestMembarPass, OperationPass<FuncOp>> {\n+    : public PassWrapper<TestMembarPass, OperationPass<func::FuncOp>> {\n \n-  // LLVM15+\n-  // MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestMembarPass);\n+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TestMembarPass);\n \n   StringRef getArgument() const final { return \"test-print-membar\"; }\n   StringRef getDescription() const final {"}]