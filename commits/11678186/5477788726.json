[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -244,6 +244,7 @@ jobs:\n             mv cache reference\n           else\n             echo \"No artifact found with the name: $ARTIFACT_NAME\"\n+            exit 1\n           fi\n       - name: Download current job artifacts\n         uses: actions/download-artifact@v2\n@@ -294,6 +295,7 @@ jobs:\n         if: ${{ env.COMPARISON_RESULT == 'false' }}\n         uses: actions/github-script@v5\n         with:\n+          github-token: ${{ secrets.CI_ACCESS_TOKEN }}\n           script: |\n             const run_id = ${{ env.RUN_ID }};\n             const issue_number = context.payload.pull_request.number;"}, {"filename": "docs/python-api/triton.language.rst", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "file_content_changes": "@@ -111,6 +111,16 @@ Reduction Ops\n     sum\n     xor_sum\n \n+Scan Ops\n+-------------\n+\n+.. autosummary::\n+    :toctree: generated\n+    :nosignatures:\n+\n+    associative_scan\n+    cumsum\n+    cumprod\n \n Atomic Ops\n ----------"}, {"filename": "include/triton/Dialect/TritonGPU/IR/Attributes.h", "status": "added", "additions": 7, "deletions": 0, "changes": 7, "file_content_changes": "@@ -0,0 +1,7 @@\n+#ifndef TRITON_DIALECT_TRITONGPU_IR_ATTRIBUTES_H_\n+#define TRITON_DIALECT_TRITONGPU_IR_ATTRIBUTES_H_\n+\n+#define GET_ATTRDEF_CLASSES\n+#include \"triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.h.inc\"\n+\n+#endif // TRITON_DIALECT_TRITONGPU_IR_ATTRIBUTES_H_"}, {"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "file_content_changes": "@@ -8,12 +8,10 @@\n \n // TritonGPU depends on Triton\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Attributes.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h.inc\"\n #include \"triton/Dialect/TritonGPU/IR/Traits.h\"\n \n-#define GET_ATTRDEF_CLASSES\n-#include \"triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.h.inc\"\n-\n #define GET_OP_CLASSES\n #include \"triton/Dialect/TritonGPU/IR/Ops.h.inc\"\n \n@@ -82,9 +80,10 @@ bool isaDistributedLayout(Attribute layout);\n \n bool isSharedEncoding(Value value);\n \n+bool isExpensiveCat(CatOp cat, Attribute &targetEncoding);\n+\n } // namespace gpu\n } // namespace triton\n-\n } // namespace mlir\n \n #endif // TRITON_DIALECT_TRITONGPU_IR_DIALECT_H_"}, {"filename": "include/triton/Dialect/TritonGPU/Transforms/Utility.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -18,8 +18,6 @@ LogicalResult invertEncoding(Attribute targetEncoding, Operation *op,\n \n bool isExpensiveLoadOrStore(Operation *op, Attribute &targetEncoding);\n \n-bool isExpensiveCat(triton::CatOp cat, Attribute &targetEncoding);\n-\n bool isExpensiveToRemat(Operation *op, Attribute &targetEncoding);\n \n // skipInit is True when we only consider the operands of the initOp but"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 21, "deletions": 1, "changes": 22, "file_content_changes": "@@ -10,11 +10,31 @@\n \n namespace mlir {\n \n+namespace {\n+\n+int getParentAxis(Attribute layout, int axis) {\n+  if (auto sliceEncoding = layout.dyn_cast<triton::gpu::SliceEncodingAttr>()) {\n+    axis = axis < sliceEncoding.getDim() ? axis : axis + 1;\n+    return getParentAxis(sliceEncoding.getParent(), axis);\n+  }\n+  return axis;\n+}\n+\n+SmallVector<unsigned> getParentOrder(Attribute layout) {\n+  if (auto sliceEncoding = layout.dyn_cast<triton::gpu::SliceEncodingAttr>()) {\n+    return getParentOrder(sliceEncoding.getParent());\n+  }\n+  return triton::gpu::getOrder(layout);\n+}\n+\n+} // namespace\n+\n bool ReduceOpHelper::isFastReduction() {\n   // Disable fast reduction only for debugging purpose\n   if (::triton::tools::getBoolEnv(\"DISABLE_FAST_REDUCTION\"))\n     return false;\n-  return axis == triton::gpu::getOrder(getSrcLayout())[0];\n+  return getParentAxis(getSrcLayout(), axis) ==\n+         getParentOrder(getSrcLayout())[0];\n }\n \n unsigned ReduceOpHelper::getInterWarpSize() {"}, {"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 18, "deletions": 4, "changes": 22, "file_content_changes": "@@ -154,10 +154,24 @@ class StdSelectPattern : public OpConversionPattern<arith::SelectOp> {\n   matchAndRewrite(arith::SelectOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Type retType = this->getTypeConverter()->convertType(op.getType());\n-    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::gpu::SelectOp>(\n-                      op, retType, adaptor.getCondition(),\n-                      adaptor.getTrueValue(), adaptor.getFalseValue()),\n-                  adaptor.getAttributes());\n+\n+    Value cond = adaptor.getCondition();\n+    if (llvm::isa<RankedTensorType>(retType) &&\n+        !llvm::isa<TensorType>(cond.getType())) {\n+      // triton_gpu.select doesn't support scalar condition values, so add a\n+      // splat\n+      auto retTypeTensor = llvm::cast<RankedTensorType>(retType);\n+      auto retShape = retTypeTensor.getShape();\n+      auto retEncoding = retTypeTensor.getEncoding();\n+      Type condTy =\n+          RankedTensorType::get(retShape, cond.getType(), retEncoding);\n+      cond = rewriter.create<triton::SplatOp>(op.getLoc(), condTy, cond);\n+    }\n+\n+    addNamedAttrs(\n+        rewriter.replaceOpWithNewOp<triton::gpu::SelectOp>(\n+            op, retType, cond, adaptor.getTrueValue(), adaptor.getFalseValue()),\n+        adaptor.getAttributes());\n     return success();\n   }\n };"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -6,7 +6,7 @@\n #include \"mlir/IR/OperationSupport.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/Triton/IR/Types.h\"\n-#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Attributes.h\"\n \n namespace mlir {\n namespace triton {"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 13, "deletions": 2, "changes": 15, "file_content_changes": "@@ -7,7 +7,6 @@\n #include \"triton/Analysis/Utility.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.cpp.inc\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n-#include \"triton/Dialect/TritonGPU/Transforms/Utility.h\"\n #include \"llvm/ADT/TypeSwitch.h\"\n \n using namespace mlir;\n@@ -368,9 +367,21 @@ bool isSharedEncoding(Value value) {\n   return false;\n }\n \n+bool isExpensiveCat(CatOp cat, Attribute &targetEncoding) {\n+  // If the new elements per thread is less than the old one, we will need to do\n+  // convert encoding that goes through shared memory anyway. So we consider it\n+  // as expensive.\n+  auto tensorTy = cat.getResult().getType().cast<RankedTensorType>();\n+  auto totalElemsPerThread = gpu::getTotalElemsPerThread(tensorTy);\n+  auto shape = tensorTy.getShape();\n+  auto elemTy = tensorTy.getElementType();\n+  auto newTotalElemsPerThread =\n+      gpu::getTotalElemsPerThread(targetEncoding, shape, elemTy);\n+  return newTotalElemsPerThread < totalElemsPerThread;\n+}\n+\n } // namespace gpu\n } // namespace triton\n-\n } // namespace mlir\n \n static LogicalResult parseIntAttrValue(AsmParser &parser, Attribute attr,"}, {"filename": "lib/Dialect/TritonGPU/Transforms/ReorderInstructions.cpp", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "file_content_changes": "@@ -80,30 +80,31 @@ class TritonGPUReorderInstructionsPass\n         return;\n       op->moveAfter(argOp);\n     });\n-    // Move `dot` operand so that conversions to opIdx=0 happens before\n-    // conversions to opIdx=1\n+    // Move `dot` operand so that conversions to opIdx=1 happens after\n+    // conversions to opIdx=0\n     m.walk([&](triton::gpu::ConvertLayoutOp op) {\n       auto dstType = op.getResult().getType().cast<RankedTensorType>();\n       auto dstEncoding =\n           dstType.getEncoding().dyn_cast<triton::gpu::DotOperandEncodingAttr>();\n       if (!dstEncoding)\n         return;\n       int opIdx = dstEncoding.getOpIdx();\n-      if (opIdx != 0)\n+      if (opIdx != 1)\n         return;\n       if (op->getUsers().empty())\n         return;\n       auto dotUser = dyn_cast<triton::DotOp>(*op->user_begin());\n       if (!dotUser)\n         return;\n-      auto BOp = dotUser.getOperand(1).getDefiningOp();\n-      if (!BOp)\n+      auto AOp =\n+          dotUser.getOperand(0).getDefiningOp<triton::gpu::ConvertLayoutOp>();\n+      if (!AOp)\n         return;\n-      // TODO: An alternative would be to move cvt of OpIdx=0 down instead of\n-      // movig cvt of OpIdx=1 up. This would allow re-ordering more cases.\n-      if (!dom.dominates(op.getOperand(), BOp))\n+      // Check that the conversion to OpIdx=1 happens before and can be moved\n+      // after the conversion to OpIdx=0.\n+      if (!dom.dominates(op.getOperation(), AOp.getOperation()))\n         return;\n-      op->moveBefore(BOp);\n+      op->moveAfter(AOp);\n     });\n     return;\n   }"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Utility.cpp", "status": "modified", "additions": 3, "deletions": 15, "changes": 18, "file_content_changes": "@@ -104,26 +104,13 @@ bool isExpensiveLoadOrStore(Operation *op, Attribute &targetEncoding) {\n   return true;\n }\n \n-bool isExpensiveCat(triton::CatOp cat, Attribute &targetEncoding) {\n-  // If the new elements per thread is less than the old one, we will need to do\n-  // convert encoding that goes through shared memory anyway. So we consider it\n-  // as expensive.\n-  auto tensorTy = cat.getResult().getType().cast<RankedTensorType>();\n-  auto totalElemsPerThread = triton::gpu::getTotalElemsPerThread(tensorTy);\n-  auto shape = tensorTy.getShape();\n-  auto elemTy = tensorTy.getElementType();\n-  auto newTotalElemsPerThread =\n-      triton::gpu::getTotalElemsPerThread(targetEncoding, shape, elemTy);\n-  return newTotalElemsPerThread < totalElemsPerThread;\n-}\n-\n bool isExpensiveToRemat(Operation *op, Attribute &targetEncoding) {\n   if (!op)\n     return true;\n   if (isa<triton::LoadOp, triton::StoreOp>(op))\n     return isExpensiveLoadOrStore(op, targetEncoding);\n   if (isa<triton::CatOp>(op))\n-    return isExpensiveCat(cast<triton::CatOp>(op), targetEncoding);\n+    return triton::gpu::isExpensiveCat(cast<triton::CatOp>(op), targetEncoding);\n   if (isa<tensor::ExtractSliceOp, triton::gpu::AllocTensorOp,\n           triton::gpu::InsertSliceAsyncOp, triton::AtomicRMWOp,\n           triton::AtomicCASOp, triton::DotOp>(op))\n@@ -136,7 +123,8 @@ bool isExpensiveToRemat(Operation *op, Attribute &targetEncoding) {\n \n bool canFoldConversion(Operation *op, Attribute &targetEncoding) {\n   if (isa<triton::CatOp>(op))\n-    return !isExpensiveCat(cast<triton::CatOp>(op), targetEncoding);\n+    return !triton::gpu::isExpensiveCat(cast<triton::CatOp>(op),\n+                                        targetEncoding);\n   return isa<triton::gpu::ConvertLayoutOp, arith::ConstantOp,\n              triton::MakeRangeOp, triton::SplatOp, triton::ViewOp>(op);\n }"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "file_content_changes": "@@ -1534,7 +1534,7 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n     for type in ['int32', 'float32']\n     for axis in [1, 0]\n     for shape in scan2d_shapes\n-    for op in ['cumsum']\n+    for op in ['cumsum', 'cumprod']\n ]\n \n \n@@ -1557,7 +1557,7 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n     x = numpy_random(shape, dtype_str=dtype_str, rs=rs)\n     z = np.empty_like(x)\n     x_tri = to_triton(x, device=device)\n-    numpy_op = {'cumsum': np.cumsum}[op]\n+    numpy_op = {'cumsum': np.cumsum, 'cumprod': np.cumprod}[op]\n     z_dtype_str = dtype_str\n     z_ref = numpy_op(x, axis=axis).astype(getattr(np, z_dtype_str))\n     # triton result\n@@ -1566,7 +1566,10 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n     z_tri = to_numpy(z_tri)\n     # compare\n     if dtype_str == 'float32':\n-        np.testing.assert_allclose(z_ref, z_tri, rtol=0.01)\n+        if op == 'cumprod':\n+            np.testing.assert_allclose(z_ref, z_tri, rtol=0.01, atol=1e-3)\n+        else:\n+            np.testing.assert_allclose(z_ref, z_tri, rtol=0.01)\n     else:\n         np.testing.assert_equal(z_ref, z_tri)\n "}, {"filename": "python/triton/interpreter/tl_lang.py", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -629,3 +629,9 @@ def cumsum(self, input, axis=None):\n         if axis is None:\n             return torch.cumsum(input)\n         return torch.cumsum(input, dim=axis)\n+\n+    @_tensor_operation\n+    def cumprod(self, input, axis=None):\n+        if axis is None:\n+            return torch.cumprod(input)\n+        return torch.cumprod(input, dim=axis)"}, {"filename": "python/triton/language/__init__.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -35,6 +35,7 @@\n     cat,\n     constexpr,\n     cos,\n+    cumprod,\n     cumsum,\n     debug_barrier,\n     device_assert,\n@@ -130,6 +131,7 @@\n     \"cdiv\",\n     \"constexpr\",\n     \"cos\",\n+    \"cumprod\",\n     \"cumsum\",\n     \"debug_barrier\",\n     \"device_assert\","}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "file_content_changes": "@@ -1562,6 +1562,20 @@ def cumsum(input, axis=0):\n     input = _promote_reduction_input(input)\n     return associative_scan(input, axis, _sum_combine)\n \n+# cumprod\n+\n+\n+@jit\n+def _prod_combine(a, b):\n+    return a * b\n+\n+\n+@jit\n+@_add_scan_docstr(\"cumprod\")\n+def cumprod(input, axis=0):\n+    # todo rename this to a generic function name\n+    input = _promote_reduction_input(input)\n+    return associative_scan(input, axis, _prod_combine)\n \n # -----------------------\n # Compiler Hint Ops"}, {"filename": "test/Conversion/triton_to_tritongpu.mlir", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "file_content_changes": "@@ -67,3 +67,24 @@ tt.func @reduce_ops(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n \n   tt.return\n }\n+\n+\n+// -----\n+\n+tt.func public @select_op(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i1) attributes {noinline = false} {\n+  // CHECK-LABEL: select_op\n+  %cst = arith.constant dense<0.000000e+00> : tensor<128xf32>\n+  %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32>\n+  %1 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<128x!tt.ptr<f32>>\n+  %2 = tt.addptr %1, %0 : tensor<128x!tt.ptr<f32>>, tensor<128xi32>\n+  %3 = tt.load %2 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<128xf32>\n+\n+  // CHECK: %[[splat:.*]] = tt.splat %arg2 : (i1) -> tensor<128xi1, #blocked>\n+  // CHECK-NEXT: %{{.*}} = \"triton_gpu.select\"(%[[splat]], %{{.*}}, %{{.*}}) : (tensor<128xi1, #blocked>, tensor<128xf32, #blocked>, tensor<128xf32, #blocked>) -> tensor<128xf32, #blocked>\n+  %4 = arith.select %arg2, %cst, %3 : tensor<128xf32>\n+\n+  %5 = tt.splat %arg1 : (!tt.ptr<f32>) -> tensor<128x!tt.ptr<f32>>\n+  %6 = tt.addptr %5, %0 : tensor<128x!tt.ptr<f32>>, tensor<128xi32>\n+  tt.store %6, %4 {cache = 1 : i32, evict = 1 : i32} : tensor<128xf32>\n+  tt.return\n+}"}, {"filename": "test/TritonGPU/reorder-instructions.mlir", "status": "modified", "additions": 29, "deletions": 12, "changes": 41, "file_content_changes": "@@ -9,24 +9,41 @@\n #mma = #triton_gpu.mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2]}>\n #shared = #triton_gpu.shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [0, 1]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32, \"triton_gpu.threads-per-warp\" = 32 : i32} {\n-  tt.func public @convert_cannot_hoist(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}) attributes {noinline = false} {\n+  tt.func public @convert_cannot_hoist(%arg0: tensor<32x32x!tt.ptr<f32>, #blocked>) attributes {noinline = false} {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma>\n     %cst_0 = arith.constant dense<1.230000e+02> : tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>>\n-    %0 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>\n-    %1 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>) -> tensor<32x1xi32, #blocked>\n-    %2 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>\n-    %3 = tt.expand_dims %2 {axis = 0 : i32} : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>) -> tensor<1x32xi32, #blocked>\n-    %4 = tt.broadcast %1 : (tensor<32x1xi32, #blocked>) -> tensor<32x32xi32, #blocked>\n-    %5 = tt.broadcast %3 : (tensor<1x32xi32, #blocked>) -> tensor<32x32xi32, #blocked>\n-    %6 = arith.addi %4, %5 : tensor<32x32xi32, #blocked>\n-    %7 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<32x32x!tt.ptr<f32>, #blocked>\n-    %8 = tt.addptr %7, %6 : tensor<32x32x!tt.ptr<f32>, #blocked>, tensor<32x32xi32, #blocked>\n-    %9 = tt.load %8 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<32x32xf32, #blocked>\n+    %9 = tt.load %arg0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<32x32xf32, #blocked>\n     %10 = triton_gpu.convert_layout %9 : (tensor<32x32xf32, #blocked>) -> tensor<32x32xf32, #shared>\n     %11 = triton_gpu.convert_layout %10 : (tensor<32x32xf32, #shared>) -> tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>>\n     %12 = tt.dot %11, %cst_0, %cst {allowTF32 = true} : tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma>\n     %13 = triton_gpu.convert_layout %12 : (tensor<32x32xf32, #mma>) -> tensor<32x32xf32, #blocked>\n-    tt.store %8, %13 {cache = 1 : i32, evict = 1 : i32} : tensor<32x32xf32, #blocked>\n+    tt.store %arg0, %13 {cache = 1 : i32, evict = 1 : i32} : tensor<32x32xf32, #blocked>\n+    tt.return\n+  }\n+}\n+\n+// -----\n+\n+// CHECK-LABEL: sink_convert_idx_1\n+//       CHECK: triton_gpu.convert_layout %{{.*}} : (tensor<32x32xf32, #shared>) -> tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>>\n+//       CHECK: triton_gpu.convert_layout %{{.*}} : (tensor<32x32xf32, #shared>) -> tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>>\n+//       CHECK: tt.dot\n+#blocked = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [1, 4], order = [0, 1]}>\n+#mma = #triton_gpu.mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2]}>\n+#shared = #triton_gpu.shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [0, 1]}>\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32, \"triton_gpu.threads-per-warp\" = 32 : i32} {\n+  tt.func public @sink_convert_idx_1(%arg0: tensor<32x32x!tt.ptr<f32>, #blocked>) attributes {noinline = false} {\n+    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma>\n+    %B = tt.load %arg0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<32x32xf32, #blocked>\n+    %BS = triton_gpu.convert_layout %B : (tensor<32x32xf32, #blocked>) -> tensor<32x32xf32, #shared>\n+    %BD = triton_gpu.convert_layout %BS : (tensor<32x32xf32, #shared>) -> tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>>\n+    %cst_0 = arith.constant dense<1.230000e+02> : tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>>\n+    %A = tt.load %arg0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<32x32xf32, #blocked>\n+    %AS = triton_gpu.convert_layout %A : (tensor<32x32xf32, #blocked>) -> tensor<32x32xf32, #shared>\n+    %AD = triton_gpu.convert_layout %AS : (tensor<32x32xf32, #shared>) -> tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>>\n+    %12 = tt.dot %AD, %BD, %cst {allowTF32 = true} : tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<32x32xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma>\n+    %13 = triton_gpu.convert_layout %12 : (tensor<32x32xf32, #mma>) -> tensor<32x32xf32, #blocked>\n+    tt.store %arg0, %13 {cache = 1 : i32, evict = 1 : i32} : tensor<32x32xf32, #blocked>\n     tt.return\n   }\n }"}]