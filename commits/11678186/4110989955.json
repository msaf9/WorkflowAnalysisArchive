[{"filename": "lib/Dialect/TritonGPU/Transforms/Coalesce.cpp", "status": "modified", "additions": 32, "deletions": 34, "changes": 66, "file_content_changes": "@@ -1,8 +1,8 @@\n+#include \"mlir/Analysis/SliceAnalysis.h\"\n #include \"triton/Analysis/AxisInfo.h\"\n #include \"triton/Analysis/Utility.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n-#include \"mlir/Analysis/SliceAnalysis.h\"\n #include <numeric>\n \n using namespace mlir;\n@@ -16,13 +16,11 @@ int argMax(ArrayRef<int64_t> arr) {\n   return std::distance(arr.begin(), it);\n }\n \n-template<class T>\n-SmallVector<unsigned, 4> argSort(const T& arr){\n+template <class T> SmallVector<unsigned, 4> argSort(const T &arr) {\n   SmallVector<unsigned, 4> ret(arr.size());\n   std::iota(ret.begin(), ret.end(), 0);\n-  std::sort(ret.begin(), ret.end(), [&](unsigned x, unsigned y) {\n-    return arr[x] > arr[y];\n-  });\n+  std::sort(ret.begin(), ret.end(),\n+            [&](unsigned x, unsigned y) { return arr[x] > arr[y]; });\n   return ret;\n }\n \n@@ -42,14 +40,14 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     // `ptr`\n     SetVector<Value> withSameOrder;\n     withSameOrder.insert(ptr);\n-    if(ptr.getDefiningOp())\n-      for(Operation *op: mlir::getSlice(ptr.getDefiningOp())){\n-        for(Value val: op->getResults()){\n-          if(val.getType() != origType) \n+    if (ptr.getDefiningOp())\n+      for (Operation *op : mlir::getSlice(ptr.getDefiningOp())) {\n+        for (Value val : op->getResults()) {\n+          if (val.getType() != origType)\n             continue;\n           auto valInfo = axisInfo.lookupLatticeElement(val);\n           auto currOrder = argSort(valInfo->getValue().getContiguity());\n-          if(order == currOrder)\n+          if (order == currOrder)\n             withSameOrder.insert(val);\n         }\n       }\n@@ -61,7 +59,7 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     unsigned elemNumBits = getPointeeBitWidth(origType);\n     unsigned elemNumBytes = std::max(elemNumBits / 8, 1u);\n     unsigned perThread = 1;\n-    for(Value val: withSameOrder){\n+    for (Value val : withSameOrder) {\n       AxisInfo info = axisInfo.lookupLatticeElement(val)->getValue();\n       unsigned maxMultipleBytes = info.getDivisibility(order[0]);\n       unsigned maxMultiple = std::max(maxMultipleBytes / elemNumBytes, 1u);\n@@ -90,7 +88,7 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n   }\n \n   template <class T>\n-  void coalesceOp(LayoutMap& layoutMap, Operation *op, Value ptr,\n+  void coalesceOp(LayoutMap &layoutMap, Operation *op, Value ptr,\n                   OpBuilder builder) {\n     RankedTensorType ty = ptr.getType().template dyn_cast<RankedTensorType>();\n     if (!ty)\n@@ -137,27 +135,27 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     // the pointers should have for best memory coalescing\n     LayoutMap layoutMap;\n     op->walk([&](Operation *curr) {\n-        Value ptr;\n-        if (auto op = dyn_cast<triton::LoadOp>(curr)) \n-          ptr = op.ptr();\n-        if (auto op = dyn_cast<triton::AtomicRMWOp>(curr)) \n-          ptr = op.ptr();\n-        if (auto op = dyn_cast<triton::AtomicCASOp>(curr)) \n-          ptr = op.ptr();\n-        if (auto op = dyn_cast<triton::gpu::InsertSliceAsyncOp>(curr)) \n-          ptr = op.src();\n-        if (auto op = dyn_cast<triton::StoreOp>(curr)) \n-          ptr = op.ptr();\n-        if(!ptr)\n-          return;\n-        RankedTensorType ty =  ptr.getType().template dyn_cast<RankedTensorType>();\n-        if(!ty || !ty.getElementType().isa<PointerType>())\n-          return;\n-        AxisInfo info = axisInfo.lookupLatticeElement(ptr)->getValue();\n-        auto mod = curr->getParentOfType<ModuleOp>();\n-        int numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n-        auto convertType = getTypeConverter(axisInfo, ptr, numWarps);\n-        layoutMap[ptr] = convertType;\n+      Value ptr;\n+      if (auto op = dyn_cast<triton::LoadOp>(curr))\n+        ptr = op.ptr();\n+      if (auto op = dyn_cast<triton::AtomicRMWOp>(curr))\n+        ptr = op.ptr();\n+      if (auto op = dyn_cast<triton::AtomicCASOp>(curr))\n+        ptr = op.ptr();\n+      if (auto op = dyn_cast<triton::gpu::InsertSliceAsyncOp>(curr))\n+        ptr = op.src();\n+      if (auto op = dyn_cast<triton::StoreOp>(curr))\n+        ptr = op.ptr();\n+      if (!ptr)\n+        return;\n+      RankedTensorType ty = ptr.getType().template dyn_cast<RankedTensorType>();\n+      if (!ty || !ty.getElementType().isa<PointerType>())\n+        return;\n+      AxisInfo info = axisInfo.lookupLatticeElement(ptr)->getValue();\n+      auto mod = curr->getParentOfType<ModuleOp>();\n+      int numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n+      auto convertType = getTypeConverter(axisInfo, ptr, numWarps);\n+      layoutMap[ptr] = convertType;\n     });\n \n     // For each memory op that has a layout L1:"}]