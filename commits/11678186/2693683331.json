[{"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,7 +1,7 @@\n \"\"\"\n Fused Attention\n ===============\n-This is a Triton implementation of the Flash Attention algorithm \n+This is a Triton implementation of the Flash Attention algorithm\n (see: Dao et al., https://arxiv.org/pdf/2205.14135v2.pdf; Rabe and Staats https://arxiv.org/pdf/2112.05682v2.pdf)\n \"\"\"\n "}]