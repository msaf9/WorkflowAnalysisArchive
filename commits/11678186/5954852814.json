[{"filename": "lib/Conversion/NVGPUToLLVM/NVGPUToLLVMPass.cpp", "status": "modified", "additions": 60, "deletions": 75, "changes": 135, "file_content_changes": "@@ -27,26 +27,15 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n   explicit NVGPUOpPatternBase(mlir::MLIRContext *context)\n       : mlir::RewritePattern(SourceOp::getOperationName(), 1, context) {}\n \n-  std::string getConstraint(std::string type) const {\n-    std::string constraint;\n-    static std::map<std::string, std::string> typeMap = {\n-        {\"i1\", \"b\"},  {\"i16\", \"h\"}, {\"i32\", \"r\"},\n-        {\"i64\", \"l\"}, {\"f32\", \"f\"}, {\"f64\", \"d\"}};\n-    if (typeMap.count(type) == 0) {\n-      llvm::errs() << \"Unsupported type \" << type << \"\\n\";\n-      llvm_unreachable(\"\");\n-    }\n-    return typeMap[type];\n-  }\n-\n-  mlir::Value convertToType(mlir::Value val, std::string type, Location &loc,\n+  mlir::Value convertToType(mlir::Value val, std::string constraint,\n+                            Location &loc,\n                             mlir::PatternRewriter &rewriter) const {\n     if (val.getType().isa<PointerType>()) {\n-      if (type == \"ptr\") {\n+      if (constraint == \"ptr\") {\n         return val;\n-      } else if (type == \"i32\") {\n+      } else if (constraint == \"r\") {\n         return ptrtoint(i32_ty, val);\n-      } else if (type == \"i64\") {\n+      } else if (constraint == \"l\") {\n         return ptrtoint(i64_ty, val);\n       } else {\n         assert(false && \"Unsupported type conversion\");\n@@ -66,15 +55,14 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n   }\n \n   SmallVector<PTXBuilder::Operand *> getPtxOperands(\n-      std::vector<std::pair<mlir::Value, std::string>> &operandsAndTypes,\n+      std::vector<std::pair<mlir::Value, std::string>> &operandsAndConstraints,\n       PTXBuilder &ptxBuilder, Location &loc,\n       mlir::PatternRewriter &rewriter) const {\n     SmallVector<PTXBuilder::Operand *> ptxOperands;\n-    for (auto &operandAndType : operandsAndTypes) {\n-      auto constraint = getConstraint(operandAndType.second);\n-      auto operand = convertToType(operandAndType.first, operandAndType.second,\n-                                   loc, rewriter);\n-      auto *ptxOperand = ptxBuilder.newAddrOperand(operand, constraint);\n+    for (auto &[operand, constraint] : operandsAndConstraints) {\n+      auto convertedOperand = convertToType(operand, constraint, loc, rewriter);\n+      auto *ptxOperand =\n+          ptxBuilder.newAddrOperand(convertedOperand, constraint);\n       ptxOperands.push_back(ptxOperand);\n     }\n     return ptxOperands;\n@@ -85,7 +73,7 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n   }\n \n   virtual std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(SourceOp op) const {\n+  getOperandsAndConstraints(SourceOp op) const {\n     return {};\n   }\n \n@@ -143,13 +131,13 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n     auto concrete = static_cast<const ConcreteT *>(this);\n     auto ptxAsm = concrete->getPtxAsm(sourceOp);\n     auto hasSideEffects = !isMemoryEffectFree(sourceOp);\n-    auto operandsAndTypes = concrete->getOperandsAndTypes(sourceOp);\n+    auto operandsAndConstraints = concrete->getOperandsAndConstraints(sourceOp);\n     auto outputConstraints = concrete->getOutputConstraints(sourceOp);\n \n     PTXBuilder ptxBuilder;\n     auto ptxOutputs = getPtxOutputs(outputConstraints, ptxBuilder);\n     auto ptxOperands =\n-        getPtxOperands(operandsAndTypes, ptxBuilder, loc, rewriter);\n+        getPtxOperands(operandsAndConstraints, ptxBuilder, loc, rewriter);\n     SmallVector<PTXBuilder::Operand *> outputsAndOperands = ptxOutputs;\n     outputsAndOperands.append(ptxOperands.begin(), ptxOperands.end());\n     auto &ptxInstr = *ptxBuilder.create<PTXInstr>(ptxAsm);\n@@ -323,13 +311,13 @@ class StoreMatrixOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::StoreMatrixOp op) const {\n+  getOperandsAndConstraints(ttn::StoreMatrixOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto addr = op.getAddr();\n     auto datas = op.getDatas();\n-    operandsAndTypes.push_back({addr, \"i32\"});\n+    operandsAndTypes.push_back({addr, \"r\"});\n     for (unsigned i = 0; i < datas.size(); i++) {\n-      operandsAndTypes.push_back({datas[i], \"i32\"});\n+      operandsAndTypes.push_back({datas[i], \"r\"});\n     }\n     return operandsAndTypes;\n   }\n@@ -362,12 +350,12 @@ class MBarrierInitOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::MBarrierInitOp op) const {\n+  getOperandsAndConstraints(ttn::MBarrierInitOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     Value mbarrier = op.getMbarrier();\n     Value pred = op.getPred();\n-    operandsAndTypes.push_back({mbarrier, \"i32\"});\n-    operandsAndTypes.push_back({pred, \"i1\"});\n+    operandsAndTypes.push_back({mbarrier, \"r\"});\n+    operandsAndTypes.push_back({pred, \"b\"});\n     return operandsAndTypes;\n   }\n \n@@ -388,7 +376,7 @@ class MBarrierArriveOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::MBarrierArriveOp op) const {\n+  getOperandsAndConstraints(ttn::MBarrierArriveOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     Value mbarrier = op.getMbarrier();\n     Value pred = op.getPred();\n@@ -399,13 +387,13 @@ class MBarrierArriveOpPattern\n     case ttn::MBarriveType::normal:\n     case ttn::MBarriveType::cp_async:\n     case ttn::MBarriveType::expect_tx:\n-      operandsAndTypes.push_back({mbarrier, \"i32\"});\n-      operandsAndTypes.push_back({pred, \"i1\"});\n+      operandsAndTypes.push_back({mbarrier, \"r\"});\n+      operandsAndTypes.push_back({pred, \"b\"});\n       break;\n     case ttn::MBarriveType::remote:\n-      operandsAndTypes.push_back({mbarrier, \"i32\"});\n-      operandsAndTypes.push_back({ctaId, \"i32\"});\n-      operandsAndTypes.push_back({pred, \"i1\"});\n+      operandsAndTypes.push_back({mbarrier, \"r\"});\n+      operandsAndTypes.push_back({ctaId, \"r\"});\n+      operandsAndTypes.push_back({pred, \"b\"});\n       break;\n     default:\n       llvm::errs() << \"Unsupported mbarrier arrive type \" << arriveType << \"\\n\";\n@@ -455,12 +443,12 @@ class MBarrierWaitOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::MBarrierWaitOp op) const {\n+  getOperandsAndConstraints(ttn::MBarrierWaitOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     Value mbarrier = op.getMbarrier();\n     Value phase = op.getPhase();\n-    operandsAndTypes.push_back({mbarrier, \"i32\"});\n-    operandsAndTypes.push_back({phase, \"i32\"});\n+    operandsAndTypes.push_back({mbarrier, \"r\"});\n+    operandsAndTypes.push_back({phase, \"r\"});\n     return operandsAndTypes;\n   }\n \n@@ -485,7 +473,7 @@ class TMALoadTiledOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::TMALoadTiledOp op) const {\n+  getOperandsAndConstraints(ttn::TMALoadTiledOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto dst = op.getDst();\n     auto mbarrier = op.getMbarrier();\n@@ -499,20 +487,17 @@ class TMALoadTiledOpPattern\n     assert(dimSize == 2 || (dimSize == 4 && mcastMask == nullptr) &&\n                                \"Does not support TMA configuration\");\n \n-    operandsAndTypes.push_back({dst, \"i32\"});\n-    operandsAndTypes.push_back({tmaDesc, \"i64\"});\n-    operandsAndTypes.push_back({coords[0], \"i32\"});\n-    operandsAndTypes.push_back({coords[1], \"i32\"});\n-    if (dimSize == 4) {\n-      operandsAndTypes.push_back({coords[2], \"i32\"});\n-      operandsAndTypes.push_back({coords[3], \"i32\"});\n+    operandsAndTypes.push_back({dst, \"r\"});\n+    operandsAndTypes.push_back({tmaDesc, \"l\"});\n+    for (unsigned i = 0; i < coords.size(); i++) {\n+      operandsAndTypes.push_back({coords[i], \"r\"});\n     }\n-    operandsAndTypes.push_back({mbarrier, \"i64\"});\n+    operandsAndTypes.push_back({mbarrier, \"l\"});\n     if (mcastMask) {\n-      operandsAndTypes.push_back({mcastMask, \"i16\"});\n+      operandsAndTypes.push_back({mcastMask, \"h\"});\n     }\n-    operandsAndTypes.push_back({l2Desc, \"i64\"});\n-    operandsAndTypes.push_back({pred, \"i1\"});\n+    operandsAndTypes.push_back({l2Desc, \"l\"});\n+    operandsAndTypes.push_back({pred, \"b\"});\n \n     return operandsAndTypes;\n   }\n@@ -554,7 +539,7 @@ class TMAStoreTiledOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::TMAStoreTiledOp op) const {\n+  getOperandsAndConstraints(ttn::TMAStoreTiledOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto src = op.getSrc();\n     auto tmaDesc = op.getTmaDesc();\n@@ -566,12 +551,12 @@ class TMAStoreTiledOpPattern\n       llvm::errs() << \"Unsupported dimSize \" << dimSize << \"\\n\";\n       llvm_unreachable(\"\");\n     }\n-    operandsAndTypes.push_back({tmaDesc, \"i64\"});\n-    operandsAndTypes.push_back({src, \"i32\"});\n+    operandsAndTypes.push_back({tmaDesc, \"l\"});\n+    operandsAndTypes.push_back({src, \"r\"});\n     for (unsigned i = 0; i < dimSize; i++) {\n-      operandsAndTypes.push_back({coords[i], \"i32\"});\n+      operandsAndTypes.push_back({coords[i], \"r\"});\n     }\n-    operandsAndTypes.push_back({pred, \"i1\"});\n+    operandsAndTypes.push_back({pred, \"b\"});\n \n     return operandsAndTypes;\n   }\n@@ -605,12 +590,12 @@ class NamedBarrierArriveOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::NamedBarrierArriveOp op) const {\n+  getOperandsAndConstraints(ttn::NamedBarrierArriveOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto bar = op.getBar();\n     auto numThreads = op.getNumThreads();\n-    operandsAndTypes.push_back({bar, \"i32\"});\n-    operandsAndTypes.push_back({numThreads, \"i32\"});\n+    operandsAndTypes.push_back({bar, \"r\"});\n+    operandsAndTypes.push_back({numThreads, \"r\"});\n     return operandsAndTypes;\n   }\n \n@@ -628,12 +613,12 @@ class NamedBarrierWaitOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::NamedBarrierWaitOp op) const {\n+  getOperandsAndConstraints(ttn::NamedBarrierWaitOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto bar = op.getBar();\n     auto numThreads = op.getNumThreads();\n-    operandsAndTypes.push_back({bar, \"i32\"});\n-    operandsAndTypes.push_back({numThreads, \"i32\"});\n+    operandsAndTypes.push_back({bar, \"r\"});\n+    operandsAndTypes.push_back({numThreads, \"r\"});\n     return operandsAndTypes;\n   }\n \n@@ -649,17 +634,17 @@ class StoreDSmemOpPattern\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::StoreDSmemOp op) const {\n+  getOperandsAndConstraints(ttn::StoreDSmemOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto addr = op.getAddr();\n     auto ctaId = op.getCtaId();\n     auto values = op.getValues();\n     auto pred = op.getPred();\n     auto bitwidth = op.getBitwidth();\n-    operandsAndTypes.push_back({addr, \"i32\"});\n-    operandsAndTypes.push_back({ctaId, \"i32\"});\n-    operandsAndTypes.push_back({pred, \"i1\"});\n-    std::string c = bitwidth == 16 ? \"i16\" : (bitwidth == 32 ? \"i32\" : \"i64\");\n+    operandsAndTypes.push_back({addr, \"r\"});\n+    operandsAndTypes.push_back({ctaId, \"r\"});\n+    operandsAndTypes.push_back({pred, \"b\"});\n+    std::string c = bitwidth == 16 ? \"h\" : (bitwidth == 32 ? \"r\" : \"l\");\n     for (unsigned i = 0; i < values.size(); i++) {\n       operandsAndTypes.push_back({values[i], c});\n     }\n@@ -719,14 +704,14 @@ class Sts64OpPattern : public NVGPUOpPatternBase<ttn::Sts64Op, Sts64OpPattern> {\n   using Base::Base;\n \n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::Sts64Op op) const {\n+  getOperandsAndConstraints(ttn::Sts64Op op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto offset = op.getOffset();\n     auto d0 = op.getD0();\n     auto d1 = op.getD1();\n-    operandsAndTypes.push_back({offset, \"i32\"});\n-    operandsAndTypes.push_back({d0, \"i32\"});\n-    operandsAndTypes.push_back({d1, \"i32\"});\n+    operandsAndTypes.push_back({offset, \"r\"});\n+    operandsAndTypes.push_back({d0, \"r\"});\n+    operandsAndTypes.push_back({d1, \"r\"});\n     return operandsAndTypes;\n   }\n \n@@ -748,13 +733,13 @@ class LoadDSmemOpPattern\n     return std::vector<std::string>(vec, c);\n   }\n   std::vector<std::pair<mlir::Value, std::string>>\n-  getOperandsAndTypes(ttn::LoadDSmemOp op) const {\n+  getOperandsAndConstraints(ttn::LoadDSmemOp op) const {\n     std::vector<std::pair<mlir::Value, std::string>> operandsAndTypes;\n     auto addr = op.getAddr();\n     auto ctaId = op.getCtaId();\n \n-    operandsAndTypes.push_back({addr, \"i32\"});\n-    operandsAndTypes.push_back({ctaId, \"i32\"});\n+    operandsAndTypes.push_back({addr, \"r\"});\n+    operandsAndTypes.push_back({ctaId, \"r\"});\n     return operandsAndTypes;\n   }\n "}]