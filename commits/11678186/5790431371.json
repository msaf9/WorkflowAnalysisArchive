[{"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 17, "deletions": 8, "changes": 25, "file_content_changes": "@@ -697,6 +697,15 @@ struct ConvertLayoutOpConversion\n     return success();\n   }\n \n+  // Pack two 16-bit values into a 32-bit register.\n+  static Value pack16bitsTo32(ConversionPatternRewriter &rewriter, Location loc,\n+                              Value hb, Value lb) {\n+    hb = zext(i32_ty, bitcast(hb, i16_ty));\n+    lb = zext(i32_ty, bitcast(lb, i16_ty));\n+    Value pack = or_(lb, shl(hb, i32_val(16)));\n+    return pack;\n+  }\n+\n   // blocked -> shared.\n   // Swizzling in shared memory to avoid bank conflict. Normally used for\n   // A/B operands of dots.\n@@ -768,14 +777,14 @@ struct ConvertLayoutOpConversion\n               numElemsPerSwizzlingRow, true);\n \n           Value addr = gep(elemPtrTy, smemBase, offset);\n-          Value data0 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 1], inVals[elemIdx + 0]);\n-          Value data1 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 3], inVals[elemIdx + 2]);\n-          Value data2 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 5], inVals[elemIdx + 4]);\n-          Value data3 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 7], inVals[elemIdx + 6]);\n+          Value data0 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 1],\n+                                       inVals[elemIdx + 0]);\n+          Value data1 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 3],\n+                                       inVals[elemIdx + 2]);\n+          Value data2 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 5],\n+                                       inVals[elemIdx + 4]);\n+          Value data3 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 7],\n+                                       inVals[elemIdx + 6]);\n \n           rewriter.create<triton::nvgpu::StoreMatrixOp>(\n               loc, bitcast(addr, ptrI8SharedTy),"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/WGMMA.cpp", "status": "modified", "additions": 59, "deletions": 19, "changes": 78, "file_content_changes": "@@ -216,6 +216,50 @@ DotOpMmaV3SmemLoader loadB(TritonGPUToLLVMTypeConverter *typeConverter,\n           loc};\n }\n \n+// Return a vector of Value of the accumulator start at startIndex and pack the\n+// values into 32bits in case the accumulator is fp16.\n+llvm::SmallVector<Value> loadC(ConversionPatternRewriter &rewriter,\n+                               Location loc, const SmallVector<Value> &elements,\n+                               int startIndex, int numElements) {\n+  if (!elements[0].getType().isF16()) {\n+    llvm::SmallVector<Value> mmaOut(numElements);\n+    for (int i = 0; i < numElements; ++i)\n+      mmaOut[i] = elements[startIndex + i];\n+    return mmaOut;\n+  }\n+  // For FP16 we need to pack accumulator into 32-bit integers.\n+  llvm::SmallVector<Value> mmaOut(numElements / 2);\n+  for (int i = 0; i < numElements / 2; ++i) {\n+    Value a0 = elements[startIndex + 2 * i];\n+    Value a1 = elements[startIndex + 2 * i + 1];\n+    Type cPackTy = vec_ty(rewriter.getF16Type(), 2);\n+    Value pack = rewriter.create<LLVM::UndefOp>(loc, cPackTy);\n+    pack = insert_element(cPackTy, pack, a0, i32_val(0));\n+    pack = insert_element(cPackTy, pack, a1, i32_val(1));\n+    pack = bitcast(pack, rewriter.getIntegerType(32));\n+    mmaOut[i] = pack;\n+  }\n+  return mmaOut;\n+}\n+\n+// If the accumulator is fp16 unpack it from 32-bit integers.\n+SmallVector<Value> unpackAccumulator(ConversionPatternRewriter &rewriter,\n+                                     Location loc,\n+                                     const SmallVector<Value> &packed,\n+                                     RankedTensorType tensorTy) {\n+  if (!tensorTy.getElementType().isF16())\n+    return packed;\n+  // For fp16 the accumualtor is pack into 32-bit integers so we need to unpack\n+  // it.\n+  SmallVector<Value> results;\n+  for (Value elem : packed) {\n+    elem = bitcast(elem, vec_ty(rewriter.getF16Type(), 2));\n+    results.push_back(extract_element(rewriter.getF16Type(), elem, i32_val(0)));\n+    results.push_back(extract_element(rewriter.getF16Type(), elem, i32_val(1)));\n+  }\n+  return results;\n+}\n+\n LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n                          ConversionPatternRewriter &rewriter, Location loc,\n                          Operation *op, Value a, Value b, Value c, Value d,\n@@ -236,11 +280,6 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   auto dShapePerCTA = getShapePerCTA(dTensorTy);\n   auto instrShape = mmaEncoding.getInstrShape();\n   auto accSize = 2 * (instrShape[1] / 4);\n-  Type resElemTy = dTensorTy.getElementType();\n-  llvm::SmallVector<Type> elemTypes(accSize, resElemTy);\n-  auto accTy =\n-      LLVM::LLVMStructType::getLiteral(rewriter.getContext(), elemTypes);\n-\n   int M = 4 * instrShape[0];\n   int N = instrShape[1];\n   int K = instrShape[2];\n@@ -258,9 +297,6 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   auto fc = typeConverter->unpackLLElements(loc, loadedC, rewriter, dTensorTy);\n \n   triton::nvgpu::WGMMAEltType eltTypeC = getMmaRetType(d);\n-  assert(eltTypeC != triton::nvgpu::WGMMAEltType::f16 &&\n-         \"TODO support f16 return type. This requires packing C into \"\n-         \"vector<2xf16> type.\");\n   triton::nvgpu::WGMMAEltType eltTypeA = getMmaOperandType(a, allowTF32);\n   triton::nvgpu::WGMMAEltType eltTypeB = eltTypeA;\n \n@@ -276,13 +312,16 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n     rewriter.create<triton::nvgpu::FenceAsyncSharedOp>(loc, 0);\n   rewriter.create<triton::nvgpu::WGMMAFenceOp>(loc);\n \n-  llvm::SmallVector<Value> mmaOut(accSize);\n+  SmallVector<Value> mmaResults;\n   for (int m = 0; m < numRepM; ++m) {\n     for (int n = 0; n < numRepN; ++n) {\n-      // reuse the same mmaOut\n-      for (int i = 0; i < accSize; ++i) {\n-        mmaOut[i] = fc[(m * numRepN + n) * accSize + i];\n-      }\n+      llvm::SmallVector<Value> mmaOut =\n+          loadC(rewriter, loc, fc, (m * numRepN + n) * accSize, accSize);\n+      llvm::SmallVector<Type> elemTypes;\n+      for (Value accEl : mmaOut)\n+        elemTypes.push_back(accEl.getType());\n+      auto accTy =\n+          LLVM::LLVMStructType::getLiteral(rewriter.getContext(), elemTypes);\n       Value d = typeConverter->packLLElements(loc, mmaOut, rewriter, accTy);\n       for (int k = 0; k < numRepK; ++k) {\n         auto a = aLoader.smemLoad(m, k);\n@@ -294,7 +333,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n       }\n       auto acc = typeConverter->unpackLLElements(loc, d, rewriter, accTy);\n       for (int i = 0; i < acc.size(); ++i) {\n-        fc[(m * numRepN + n) * accSize + i] = acc[i];\n+        mmaResults.push_back(acc[i]);\n       }\n     }\n   }\n@@ -303,13 +342,14 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   if (sync)\n     rewriter.create<triton::nvgpu::WGMMAWaitOp>(loc, 0);\n \n-  for (auto &elem : fc) {\n-    elem = bitcast(elem, resElemTy);\n-  }\n+  SmallVector<Value> results =\n+      unpackAccumulator(rewriter, loc, mmaResults, dTensorTy);\n+\n   // replace with new packed result\n   Type structTy = LLVM::LLVMStructType::getLiteral(\n-      mmaEncoding.getContext(), SmallVector<Type>(fc.size(), resElemTy));\n-  auto res = typeConverter->packLLElements(loc, fc, rewriter, structTy);\n+      mmaEncoding.getContext(),\n+      SmallVector<Type>(results.size(), dTensorTy.getElementType()));\n+  auto res = typeConverter->packLLElements(loc, results, rewriter, structTy);\n   rewriter.replaceOp(op, res);\n   return success();\n }"}, {"filename": "lib/Dialect/NVGPU/ToLLVMIR/NVGPUToLLVMIR.cpp", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -326,16 +326,15 @@ llvm::Value *createWGMMA(llvm::IRBuilderBase &builder, uint32_t m, uint32_t n,\n   uint32_t asmOpIdx = 0;\n \n   // Operand C\n-  uint32_t numCRegs = m * n / 128;\n-  assert(numCRegs == structTypeC->getStructNumElements());\n+  uint32_t numCRegs = structTypeC->getStructNumElements();\n   asmOs << \"{\";\n   for (uint32_t i = 0; i < numCRegs; ++i) {\n     argTypes.push_back(structTypeC->getElementType(i));\n     args.push_back(builder.CreateExtractValue(opC, {i}));\n     asmOs << \"$\" << asmOpIdx++ << (i == numCRegs - 1 ? \"\" : \",\");\n     // LLVM does not support `+` semantic, we must repeat the arguments for both\n     // input and outputs\n-    if (structTypeC->getElementType(0)->isFloatTy())\n+    if (structTypeC->getElementType(i)->isFloatTy())\n       conOs << \"=f,\";\n     else\n       conOs << \"=r,\";"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "file_content_changes": "@@ -2139,9 +2139,6 @@ def test_dot(M, N, K, num_warps, col_a, col_b, epilogue, allow_tf32, in_dtype, o\n         if out_dtype == 'float16':\n             # TODO: support out_dtype=float16 for tl.dot on V100\n             pytest.skip(\"Only test out_dtype=float16 on devices with sm >=80\")\n-    if capability[0] == 9 and out_dtype == 'float16':\n-        # TODO: support out_dtype=float16 for tl.dot on H100\n-        pytest.skip(\"Only test out_dtype=float16 on devices with sm<90\")\n \n     torch.backends.cuda.matmul.allow_tf32 = allow_tf32\n \n@@ -2297,7 +2294,7 @@ def kernel(X, stride_xm, stride_xk,\n     elif in_dtype == 'float16' and out_dtype == tl.float32:\n         assert re.search(r'[mma|wgmma.mma_async].sync.aligned.m\\d+n\\d+k16(?:.row.col)?.f32.f16.f16', ptx)\n     elif in_dtype == 'float16' and out_dtype == tl.float16:\n-        assert 'mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16' in ptx\n+        assert re.search(r'[mma|wgmma.mma_async].sync.aligned.m\\d+n\\d+k16(?:.row.col)?.f16.f16.f16', ptx)\n     elif in_dtype == 'int8':\n         assert 'wgmma.mma_async.sync.aligned' in ptx or\\\n             'mma.sync.aligned.m16n8k32.row.col.satfinite.s32.s8.s8.s32' in ptx"}]