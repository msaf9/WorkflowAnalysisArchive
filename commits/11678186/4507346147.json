[{"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "file_content_changes": "@@ -199,9 +199,12 @@ struct LoadOpConversion\n           v = bitcast(v, IntegerType::get(getContext(), width));\n \n           PTXInstr::Operand *opr{};\n-          if (otherIsSplatConstInt)\n+\n+          if (otherIsSplatConstInt) {\n+            for (size_t s = 0; s < 32; s += valueElemNbits)\n+              splatVal |= splatVal << valueElemNbits;\n             opr = ptxBuilder.newConstantOperand(splatVal);\n-          else\n+          } else\n             opr = ptxBuilder.newOperand(v, readConstraint);\n \n           mov(dstsOpr->listGet(ii), opr).predicateNot(pred, \"b\");"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "file_content_changes": "@@ -1511,6 +1511,7 @@ def _kernel(in_ptr, out_ptr, in_size: tl.constexpr, out_size: tl.constexpr):\n     kernel[(1,)](input, output, input_size, output_size)\n \n     reference_out = torch.cat((input, torch.ones((size_diff,), dtype=dtype, device=device)))\n+    # print((output - reference_out).nonzero())\n     torch.testing.assert_allclose(output, reference_out)\n \n # Testing masked loads with an intermate copy to shared memory run.\n@@ -1542,15 +1543,15 @@ def _kernel(in1_ptr, in2_ptr, output_ptr,\n         in2_offsets = K_offsets[:, None] * in2_stride + N_offsets[None, :]\n \n         # Load inputs.\n-        x = tl.load(in1_ptr + in_offsets, mask=in_offsets < in_numel)\n-        w = tl.load(in2_ptr + in2_offsets, mask=in2_offsets < in2_numel)\n+        x = tl.load(in1_ptr + in_offsets, mask=in_offsets < M*K)\n+        w = tl.load(in2_ptr + in2_offsets, mask=in2_offsets < K*N)\n \n         # Without a dot product the memory doesn't get promoted to shared.\n         o = tl.dot(x, w, out_dtype=tl.float32)\n \n         # Store output\n         output_offsets = M_offsets[:, None] * out_stride + N_offsets[None, :]\n-        tl.store(output_ptr + output_offsets, o, mask=output_offsets < in2_numel)\n+        tl.store(output_ptr + output_offsets, o, mask=output_offsets < M*N)\n \n     pgm = _kernel[(1,)](in1, in2, out,\n                         in1.stride()[0],"}]