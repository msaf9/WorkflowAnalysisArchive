[{"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 14, "deletions": 10, "changes": 24, "file_content_changes": "@@ -375,21 +375,23 @@ For example, the matrix L corresponding to blockTileSize=[32,16] is:\n     ArrayRefParameter<\"unsigned\">:$warpsPerCTA\n   );\n \n-let builders = [\n-     // specific for MMAV1(Volta)\n+  let builders = [\n+     // Specially for MMAV1(Volta)\n     AttrBuilder<(ins \"int\":$versionMajor,\n                      \"int\":$numWarps,\n                      \"int\":$id), [{\n       assert(versionMajor == 1 && \"Only MMAv1 has multiple versionMinor.\");\n       SmallVector<unsigned> wpt({static_cast<unsigned>(numWarps), 1});\n       int versionMinor = 0;\n-      versionMinor |= static_cast<bool>((1<<0) & id) * (1<<4);\n-      versionMinor |= static_cast<bool>((1<<1) & id) * (1<<5);\n-      versionMinor |= static_cast<bool>((1<<2) & id) * (1<<6);\n+\n+      assert(id < (1<<numBitsToHoldMmaV1ID()) && \"MMAv1 ID exceeds the maximum\");\n+      for (int i = 0; i < numBitsToHoldMmaV1ID(); ++i)\n+        versionMinor |= static_cast<bool>((1<<i) & id) * (1<<(4+i));\n+\n       return $_get(context, versionMajor, versionMinor, wpt);\n     }]>,\n \n-    // specific for MMAV1(Volta)\n+    // Specially for MMAV1(Volta)\n     AttrBuilder<(ins \"int\":$versionMajor,\n                      \"ArrayRef<unsigned>\":$warpsPerCTA,\n                      \"ArrayRef<int64_t>\":$shapeA,\n@@ -401,14 +403,14 @@ let builders = [\n       bool isAVec4 = !isARow && (shapeA[isARow] <= 16);\n       bool isBVec4 = isBRow && (shapeB[isBRow] <= 16);\n       // 4-bits to encode 4 booleans: [isARow, isBRow, isAVec4, isBVec4]\n-      // 3-bits to encode the MMA ID to make each unique\n       int versionMinor = (isARow * (1<<0)) |\\\n                          (isBRow * (1<<1)) |\\\n                          (isAVec4 * (1<<2)) |\\\n                          (isBVec4 * (1<<3));\n-      versionMinor |= static_cast<bool>((1<<0) & id) * (1<<4);\n-      versionMinor |= static_cast<bool>((1<<1) & id) * (1<<5);\n-      versionMinor |= static_cast<bool>((1<<2) & id) * (1<<6);\n+\n+      assert(id < (1<<numBitsToHoldMmaV1ID()) && \"MMAv1 ID exceeds the maximum\");\n+      for (int i = 0; i < numBitsToHoldMmaV1ID(); ++i)\n+        versionMinor |= static_cast<bool>((1<<i) & id) * (1<<(4+i));\n \n       return $_get(context, versionMajor, versionMinor, warpsPerCTA);\n     }]>\n@@ -419,6 +421,8 @@ let builders = [\n     bool isAmpere() const;\n     // Get [isARow, isBRow, isAVec4, isBVec4, id] from versionMinor\n     std::tuple<bool, bool, bool, bool, int> decodeVoltaLayoutStates() const;\n+    // Get number of bits in versionMinor to hold the ID of the MMA encoding instance.\n+    static int numBitsToHoldMmaV1ID();\n   }];\n \n }"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 9, "deletions": 3, "changes": 12, "file_content_changes": "@@ -601,13 +601,19 @@ MmaEncodingAttr::decodeVoltaLayoutStates() const {\n   bool isBRow = versionMinor & (1 << 1);\n   bool isAVec4 = versionMinor & (1 << 2);\n   bool isBVec4 = versionMinor & (1 << 3);\n-  int id = static_cast<bool>(versionMinor & (1 << (4 + 2)));\n-  id = (id << 1) + static_cast<bool>(versionMinor & (1 << (4 + 1)));\n-  id = (id << 1) + static_cast<bool>(versionMinor & (1 << (4 + 0)));\n+\n+  int id = 0;\n+  for (int i = numBitsToHoldMmaV1ID() - 1; i >= 0; --i)\n+    id = (id << 1) + static_cast<bool>(versionMinor & (1 << (4 + i)));\n \n   return std::make_tuple(isARow, isBRow, isAVec4, isBVec4, id);\n }\n \n+int MmaEncodingAttr::numBitsToHoldMmaV1ID() {\n+  return 5; // 5 bits to hold maxinum 32 MMA encoding instances in a single\n+            // kernel.\n+}\n+\n //===----------------------------------------------------------------------===//\n // DotOperand Encoding\n //===----------------------------------------------------------------------===//"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 0, "deletions": 29, "changes": 29, "file_content_changes": "@@ -183,32 +183,3 @@ func @vecadd(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f3\n   tt.store %21, %22 : tensor<256xf32, #layout1>\n   return\n }\n-\n-\n-// -----\n-\n-// check the UpdateMMAVersionMinorForVolta pattern\n-#blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [8, 4], warpsPerCTA = [1, 1], order = [1, 0]}>\n-#shared0 = #triton_gpu.shared<{vec = 1, perPhase=2, maxPhase=8 ,order = [1, 0]}>\n-#mma0 = #triton_gpu.mma<{versionMajor=1, versionMinor=0, warpsPerCTA=[1,1]}>\n-// Here, the isMMAv1Row of a and b's dot_operands mismatch #mma0's versionMinor,\n-// and the pattern should update the versionMinor.\n-#dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma0, isMMAv1Row=true}>\n-#dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma0, isMMAv1Row=false}>\n-// It creates a new MMA layout to fit with $a and $b's dot_operand\n-// CHECK: [[new_mma:#mma.*]] = #triton_gpu.mma<{versionMajor = 1, versionMinor = 11, warpsPerCTA = [1, 1]}>\n-module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n-  // CHECK-LABEL: dot_mmav1\n-  func @dot_mmav1(%A: tensor<16x16xf16, #blocked0>, %B: tensor<16x16xf16, #blocked0>) -> tensor<16x16xf32, #blocked0> {\n-    %C = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked0>\n-    %AA = triton_gpu.convert_layout %A : (tensor<16x16xf16, #blocked0>) -> tensor<16x16xf16, #dot_operand_a>\n-    %BB = triton_gpu.convert_layout %B : (tensor<16x16xf16, #blocked0>) -> tensor<16x16xf16, #dot_operand_b>\n-    %CC = triton_gpu.convert_layout %C : (tensor<16x16xf32, #blocked0>) -> tensor<16x16xf32, #mma0>\n-\n-    // CHECK: {{.*}} = tt.dot {{.*}}, {{.*}}, %cst {allowTF32 = true} : tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 0, parent = [[new_mma]], isMMAv1Row = true}>> * tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 1, parent = [[new_mma]], isMMAv1Row = true}>> -> tensor<16x16xf32, [[new_mma]]>\n-    %D = tt.dot %AA, %BB, %CC {allowTF32 = true} : tensor<16x16xf16, #dot_operand_a> * tensor<16x16xf16, #dot_operand_b> -> tensor<16x16xf32, #mma0>\n-    %res = triton_gpu.convert_layout %D : (tensor<16x16xf32, #mma0>) -> tensor<16x16xf32, #blocked0>\n-\n-    return %res : tensor<16x16xf32, #blocked0>\n-  }\n-}"}, {"filename": "unittest/Dialect/TritonGPU/CMakeLists.txt", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "file_content_changes": "@@ -1,6 +1,5 @@\n-\n add_triton_ut(\n \tNAME TestSwizzling\n \tSRCS SwizzleTest.cpp\n \tLIBS TritonGPUIR  ${dialect_libs} ${conversion_libs}\n-)\n\\ No newline at end of file\n+)"}]