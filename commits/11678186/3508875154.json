[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 4, "deletions": 16, "changes": 20, "file_content_changes": "@@ -464,21 +464,6 @@ struct SharedMemoryObject {\n     }\n   }\n \n-  // XXX(Keren): a special allocator for 3d tensors. It's a workaround for\n-  // now since we don't have a correct way to encoding 3d tensors in the\n-  // pipeline pass.\n-  // SharedMemoryObject(Value base, ArrayRef<int64_t> shape, Location loc,\n-  //                    ConversionPatternRewriter &rewriter)\n-  //     : base(base) {\n-  //   auto stride = 1;\n-  //   for (auto dim : llvm::reverse(shape)) {\n-  //     strides.emplace_back(i32_val(stride));\n-  //     offsets.emplace_back(i32_val(0));\n-  //     stride *= dim;\n-  //   }\n-  //   strides = llvm::to_vector<4>(llvm::reverse(strides));\n-  // }\n-\n   SmallVector<Value> getElems() const {\n     SmallVector<Value> elems;\n     elems.push_back(base);\n@@ -2253,11 +2238,14 @@ struct AllocTensorOpConversion\n     smemBase = bitcast(smemBase, elemPtrTy);\n     auto order = resultTy.getEncoding().cast<SharedEncodingAttr>().getOrder();\n     // workaround for 3D tensors\n-    // We need to modify the pipeline pass to give a proper shared encoding to 3D tensors\n+    // TODO: We need to modify the pipeline pass to give a proper shared encoding to 3D tensors\n     SmallVector<unsigned> newOrder;\n     if (resultTy.getShape().size() == 3) \n       newOrder = {1 + order[0], 1 + order[1], 0};\n+    else\n+      newOrder = SmallVector<unsigned>(order.begin(), order.end());\n \n+    \n     auto smemObj =\n         SharedMemoryObject(smemBase, resultTy.getShape(), newOrder, loc, rewriter);\n     auto retVal = getStructFromSharedMemoryObject(loc, smemObj, rewriter);"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -887,7 +887,7 @@ def ttir_to_ttgir(mod, num_warps, num_stages):\n     pm.add_tritongpu_pipeline_pass(num_stages)\n     # Prefetch must be done after pipeline pass because pipeline pass\n     # extracts slices from the original tensor.\n-    # pm.add_tritongpu_prefetch_pass()\n+    pm.add_tritongpu_prefetch_pass()\n     pm.add_canonicalizer_pass()\n     pm.add_cse_pass()\n     pm.add_triton_gpu_combine_pass()"}]