[{"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "file_content_changes": "@@ -64,12 +64,13 @@ def computation_type_impl(a_ty: tl.dtype, b_ty: tl.dtype, div_or_mod: bool) -> t\n             return tl.float32\n         else:\n             return tl.float16\n-    # 4) if one is bf16, the other is implicitly converted to bf16\n-    #    Supported PTX op: fma, neg, abs, min, max, tensor cores\n-    #    NOT supported: add, sub, mul, setp, tanh, ex2\n-    # TODO: bf16 + f16 -> f16 (?), pytorch: bf16 + f16 -> f32\n+    # 4) return bf16 only if both operands are of bf16\n     if a_ty.is_bf16() or b_ty.is_bf16():\n-        return tl.float32 if div_or_mod else tl.bfloat16\n+        if div_or_mod:\n+            return tl.float32\n+        if a_ty.is_bf16() and b_ty.is_bf16():\n+            return tl.bfloat16\n+        return tl.float32\n     if not a_ty.is_int() or not b_ty.is_int():\n         assert False\n     # 5 ) both operands are integer and undergo\n@@ -775,8 +776,9 @@ def atomic_cas(ptr: tl.tensor,\n                cmp: tl.tensor,\n                val: tl.tensor,\n                builder: ir.builder) -> tl.tensor:\n-    # TODO: type checking\n-    # supported bit width: 16, 32, 64\n+    element_ty = ptr.type.scalar.element_ty\n+    if element_ty.primitive_bitwidth not in [16, 32, 64]:\n+        raise ValueError(\"atomic_cas only supports elements with width {16, 32, 64}\")\n     return tl.tensor(builder.create_atomic_cas(ptr.handle, cmp.handle, val.handle), val.type)\n \n \n@@ -787,8 +789,7 @@ def atom_red_typechecking_impl(ptr: tl.tensor,\n                                builder: ir.builder) -> Tuple[tl.tensor, tl.tensor, tl.tensor]:\n     if not ptr.type.scalar.is_ptr():\n         raise ValueError(\"Pointer argument of store instruction is \" + ptr.type.__repr__())\n-    # supported type: f32, f64, i32, i64, u32, u64, (f16, atomic_add only)\n-    # not supported type: i1, i8, i16, bf16\n+\n     element_ty = ptr.type.scalar.element_ty\n     if element_ty is tl.float16 and op != 'add':\n         raise ValueError(\"atomic_\" + op + \" does not support fp16\")"}]