[{"filename": "python/setup.py", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -200,7 +200,8 @@ def build_extension(self, ext):\n             build_args += [\"--\", \"/m\"]\n         else:\n             cmake_args += [\"-DCMAKE_BUILD_TYPE=\" + cfg]\n-            build_args += ['-j' + str(2 * os.cpu_count())]\n+            max_jobs = os.getenv(\"MAX_JOBS\", str(2 * os.cpu_count()))\n+            build_args += ['-j' + max_jobs]\n \n         env = os.environ.copy()\n         subprocess.check_call([\"cmake\", self.base_dir] + cmake_args, cwd=self.build_temp, env=env)"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "file_content_changes": "@@ -1883,22 +1883,26 @@ def kernel(ptr, n_elements, num1, num2):\n # -------------\n \n \n-def test_if():\n+@pytest.mark.parametrize(\"if_type\", [\"if\", \"if_exp\"])\n+def test_if(if_type):\n \n     @triton.jit\n-    def kernel(Cond, XTrue, XFalse, Ret):\n+    def kernel(Cond, XTrue, XFalse, Ret, IfType: tl.constexpr):\n         pid = tl.program_id(0)\n         cond = tl.load(Cond)\n-        if pid % 2:\n-            tl.store(Ret, tl.load(XTrue))\n+        if IfType == \"if\":\n+            if pid % 2:\n+                tl.store(Ret, tl.load(XTrue))\n+            else:\n+                tl.store(Ret, tl.load(XFalse))\n         else:\n-            tl.store(Ret, tl.load(XFalse))\n+            tl.store(Ret, tl.load(XTrue)) if pid % 2 else tl.store(Ret, tl.load(XFalse))\n \n     cond = torch.ones(1, dtype=torch.int32, device='cuda')\n     x_true = torch.tensor([3.14], dtype=torch.float32, device='cuda')\n     x_false = torch.tensor([1.51], dtype=torch.float32, device='cuda')\n     ret = torch.empty(1, dtype=torch.float32, device='cuda')\n-    kernel[(1,)](cond, x_true, x_false, ret)\n+    kernel[(1,)](cond, x_true, x_false, ret, if_type)\n \n \n def test_num_warps_pow2():"}, {"filename": "python/test/unit/runtime/test_launch.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -13,7 +13,7 @@\n import triton\n import triton.language as tl\n \n-LATENCY_THRESHOLD_US = 43\n+LATENCY_THRESHOLD_US = 46\n \n \n def test_memory_leak() -> None:"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -548,7 +548,9 @@ def visit_If(self, node):\n \n     def visit_IfExp(self, node):\n         cond = self.visit(node.test)\n-        if cond.value:\n+        if _is_triton_tensor(cond):\n+            cond = cond.to(triton.language.int1, _builder=self.builder)\n+        if _unwrap_if_constexpr(cond):\n             return self.visit(node.body)\n         else:\n             return self.visit(node.orelse)"}, {"filename": "python/tutorials/05-layer-norm.py", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -311,10 +311,10 @@ def test_layer_norm(M, N, dtype, eps=1e-5, device='cuda'):\n     y_ref.backward(dy, retain_graph=True)\n     dx_ref, dw_ref, db_ref = [_.grad.clone() for _ in [x, weight, bias]]\n     # compare\n-    triton.testing.assert_almost_equal(y_tri, y_ref)\n-    triton.testing.assert_almost_equal(dx_tri, dx_ref)\n-    triton.testing.assert_almost_equal(db_tri, db_ref, decimal=1)\n-    triton.testing.assert_almost_equal(dw_tri, dw_ref, decimal=1)\n+    assert torch.allclose(y_tri, y_ref, atol=1e-2, rtol=0)\n+    assert torch.allclose(dx_tri, dx_ref, atol=1e-2, rtol=0)\n+    assert torch.allclose(db_tri, db_ref, atol=1e-2, rtol=0)\n+    assert torch.allclose(dw_tri, dw_ref, atol=1e-2, rtol=0)\n \n \n @triton.testing.perf_report("}, {"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -299,10 +299,10 @@ def test_op(Z, H, N_CTX, D_HEAD, dtype=torch.float16):\n     tri_dk, k.grad = k.grad.clone(), None\n     tri_dq, q.grad = q.grad.clone(), None\n     # compare\n-    triton.testing.assert_almost_equal(ref_out, tri_out)\n-    triton.testing.assert_almost_equal(ref_dv, tri_dv)\n-    triton.testing.assert_almost_equal(ref_dk, tri_dk)\n-    triton.testing.assert_almost_equal(ref_dq, tri_dq)\n+    assert torch.allclose(ref_out, tri_out, atol=1e-2, rtol=0)\n+    assert torch.allclose(ref_dv, tri_dv, atol=1e-2, rtol=0)\n+    assert torch.allclose(ref_dk, tri_dk, atol=1e-2, rtol=0)\n+    assert torch.allclose(ref_dq, tri_dq, atol=1e-2, rtol=0)\n \n \n try:"}]