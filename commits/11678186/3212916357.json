[{"filename": "python/tutorials/01-vector-add.py", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "file_content_changes": "@@ -3,9 +3,9 @@\n =================\n In this tutorial, you will write a simple vector addition using Triton and learn about:\n \n-- The basic programming model of Triton\n+- The basic programming model of Triton.\n - The `triton.jit` decorator, which is used to define Triton kernels.\n-- The best practices for validating and benchmarking your custom ops against native reference implementations\n+- The best practices for validating and benchmarking your custom ops against native reference implementations.\n \"\"\"\n \n # %%\n@@ -49,7 +49,7 @@ def add_kernel(\n \n # %%\n # Let's also declare a helper function to (1) allocate the `z` tensor\n-# and (2) enqueue the above kernel with appropriate grid/block sizes.\n+# and (2) enqueue the above kernel with appropriate grid/block sizes:\n \n \n def add(x: torch.Tensor, y: torch.Tensor):\n@@ -58,7 +58,7 @@ def add(x: torch.Tensor, y: torch.Tensor):\n     assert x.is_cuda and y.is_cuda and output.is_cuda\n     n_elements = output.numel()\n     # The SPMD launch grid denotes the number of kernel instances that run in parallel.\n-    # It is analogous to CUDA launch grids. It can be either Tuple[int], or Callable(metaparameters) -> Tuple[int]\n+    # It is analogous to CUDA launch grids. It can be either Tuple[int], or Callable(metaparameters) -> Tuple[int].\n     # In this case, we use a 1D grid where the size is the number of blocks:\n     grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n     # NOTE:\n@@ -94,7 +94,7 @@ def add(x: torch.Tensor, y: torch.Tensor):\n # Benchmark\n # -----------\n # We can now benchmark our custom op on vectors of increasing sizes to get a sense of how it does relative to PyTorch.\n-# To make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops\n+# To make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops.\n # for different problem sizes.\n \n \n@@ -103,13 +103,13 @@ def add(x: torch.Tensor, y: torch.Tensor):\n         x_names=['size'],  # Argument names to use as an x-axis for the plot.\n         x_vals=[\n             2 ** i for i in range(12, 28, 1)\n-        ],  # Different possible values for `x_name`\n+        ],  # Different possible values for `x_name`.\n         x_log=True,  # x axis is logarithmic.\n         line_arg='provider',  # Argument name whose value corresponds to a different line in the plot.\n         line_vals=['triton', 'torch'],  # Possible values for `line_arg`.\n         line_names=['Triton', 'Torch'],  # Label name for the lines.\n         styles=[('blue', '-'), ('green', '-')],  # Line styles.\n-        ylabel='GB/s',  # Label name for the y-axis\n+        ylabel='GB/s',  # Label name for the y-axis.\n         plot_name='vector-add-performance',  # Name for the plot. Used also as a file name for saving the plot.\n         args={},  # Values for function arguments not in `x_names` and `y_name`.\n     )\n@@ -127,5 +127,5 @@ def benchmark(size, provider):\n \n # %%\n # We can now run the decorated function above. Pass `print_data=True` to see the performance number, `show_plots=True` to plot them, and/or\n-# `save_path='/path/to/results/' to save them to disk along with raw CSV data\n+# `save_path='/path/to/results/' to save them to disk along with raw CSV data:\n benchmark.run(print_data=True, show_plots=True)"}]