[{"filename": "python/tests/test_math_ops.py", "status": "removed", "additions": 0, "deletions": 33, "changes": 33, "file_content_changes": "@@ -1,33 +0,0 @@\n-\n-import triton\n-import triton.language as tl\n-\n-\n-@triton.jit\n-def math_kernel(x1_ptr, x2_ptr, x3_ptr, x4_ptr, n, BLOCK_SIZE: tl.constexpr):\n-    offsets = tl.arange(0, BLOCK_SIZE)\n-    x1 = tl.load(x1_ptr + offsets, mask=offsets < n)\n-    x2 = tl.load(x2_ptr + offsets, mask=offsets < n)\n-    x3 = tl.load(x3_ptr + offsets, mask=offsets < n)\n-    x4 = tl.load(x4_ptr + offsets, mask=offsets < n)\n-\n-    y1 = tl.sin(x1)\n-    y2 = tl.libdevice.sin(x2)\n-    y3 = tl.libdevice.div_rn(x3, x3)\n-    y4 = tl.libdevice.fma_rd(x4, x4, x4)\n-\n-    tl.store(x1_ptr + offsets, y1, mask=offsets < n)\n-    tl.store(x2_ptr + offsets, y2, mask=offsets < n)\n-    tl.store(x3_ptr + offsets, y3, mask=offsets < n)\n-    tl.store(x4_ptr + offsets, y4, mask=offsets < n)\n-\n-\n-def test_empty_kernel_cubin_compile():\n-    kernel = triton.compiler._compile(math_kernel,\n-                                      \"*fp32,*fp32,*fp32,*fp32,i32\",\n-                                      device=0,\n-                                      constants={\"BLOCK_SIZE\": 256},\n-                                      output=\"ttgir\")  # \"cubin\"\n-    assert kernel\n-    # TODO: Check if the values are correct.\n-    # TODO: Cover all the math operators"}, {"filename": "python/tests/test_type.py", "status": "removed", "additions": 0, "deletions": 80, "changes": 80, "file_content_changes": "@@ -1,80 +0,0 @@\n-import triton\n-import triton.language as tl\n-\n-\n-# TODO: function with no arguments don't work\n-@triton.jit\n-def binop_type_check(X):\n-    # 0d-tensor is not allowed.\n-    # zero_0d = tl.zeros([], dtype=tl.float32)\n-    zero_1d = tl.zeros([2], dtype=tl.float32)\n-    zero_2d_21 = tl.zeros([2, 1], dtype=tl.float32)\n-    zero_2d_22 = tl.zeros([2, 2], dtype=tl.float32)\n-\n-    # scalar + scalar -> scalar\n-    a0 = 0.0 + 0.0\n-    # # scalar + 0D -> 0D\n-    # a1 = 0.0 + zero_0d\n-    # a2 = zero_0d + 0.0\n-    # scalar + 1D -> 1D\n-    a3 = 0.0 + zero_1d\n-    a4 = zero_1d + 0.0\n-    # scalar + 2D -> 2D\n-    a5 = 0.0 + zero_2d_22\n-    a6 = zero_2d_22 + 0.0\n-\n-    # # 0D + 0D -> 0D\n-    # b1 = zero_0d + zero_0d\n-    # # 0D + 1D -> 1D\n-    # b2 = zero_0d + zero_1d\n-    # b3 = zero_1d + zero_0d\n-    # # 0D + 2D -> 2D\n-    # b4 = zero_0d + zero_2d_22\n-    # b5 = zero_2d_22 + zero_0d\n-\n-    # 1D + 1D -> 1D\n-    c1 = zero_1d + zero_1d\n-    # 1D + 2D -> 2D\n-    c2 = zero_1d + zero_2d_21\n-    c3 = zero_1d + zero_2d_22\n-    c4 = zero_2d_21 + zero_1d\n-    c5 = zero_2d_22 + zero_1d\n-\n-    # 2D + 2D -> 2D\n-    d1 = zero_2d_21 + zero_2d_21\n-    d2 = zero_2d_22 + zero_2d_22\n-    d3 = zero_2d_21 + zero_2d_22\n-    d4 = zero_2d_22 + zero_2d_21\n-\n-    # return a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, c1, c2, c3, c4, c5, d1, d2, d3, d4\n-    return a0, a3, a4, a5, a6, c1, c2, c3, c4, c5, d1, d2, d3, d4\n-\n-\n-def test_binop_type_check():\n-    kernel = triton.compiler._compile(binop_type_check,\n-                                      signature=\"*fp32\",\n-                                      device=0,\n-                                      output=\"ttir\")\n-    assert (kernel)\n-    # TODO: Check types of the results\n-\n-\n-@triton.jit\n-def reduce_type_check(ptr):\n-    v_32 = tl.load(ptr + tl.arange(0, 32))\n-    v_scalar = tl.min(v_32, axis=0)\n-    tl.store(ptr, v_scalar)\n-    v_64x128 = tl.load(ptr + tl.arange(0, 64)[:, None] + tl.arange(0, 128)[None, :])\n-    v_64 = tl.max(v_64x128, axis=1)\n-    tl.store(ptr + tl.arange(0, 64), v_64)\n-    v_128 = tl.max(v_64x128, axis=0)\n-    tl.store(ptr + tl.arange(0, 128), v_128)\n-\n-\n-def test_reduce_type_check():\n-    kernel = triton.compiler._compile(reduce_type_check,\n-                                      signature=\"*fp32\",\n-                                      device=0,\n-                                      output=\"ttir\")\n-    assert (kernel)\n-    # TODO: Check types of the results"}]