[{"filename": "python/triton/debugger/memory_map.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -1,3 +1,5 @@\n+from __future__ import annotations\n+\n import dataclasses\n \n from triton.debugger import torch_wrapper"}, {"filename": "python/triton/debugger/tl_lang.py", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -1,3 +1,5 @@\n+from __future__ import annotations\n+\n import triton\n from .core import ExecutionContext\n from .memory_map import MemoryMap\n@@ -405,7 +407,9 @@ def zeros(self, shape, dtype):\n         return torch.zeros(size=shape, dtype=dtype, device=\"cuda\")\n \n     @_tensor_operation\n-    def dequantize(self, input, scale, shift, nbit, dst_ty=torch.float16):\n+    def dequantize(self, input, scale, shift, nbit, dst_ty=None):\n+        if dst_ty is None:\n+            dst_ty = torch.float16\n         raise NotImplementedError()\n \n     @_tensor_operation"}]