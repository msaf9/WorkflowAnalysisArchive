[{"filename": "python/tests/test_cast.py", "status": "removed", "additions": 0, "deletions": 57, "changes": 57, "file_content_changes": "@@ -1,57 +0,0 @@\n-import triton\n-import triton.language as tl\n-\n-\n-# TODO: function with no arguments don't work\n-@triton.jit\n-def cast_check(X):\n-    zero_0d = tl.zeros([], dtype=tl.float32)\n-    zero_1d = tl.zeros([2], dtype=tl.float32)\n-    zero_2d_21 = tl.zeros([2, 1], dtype=tl.float32)\n-    zero_2d_22 = tl.zeros([2, 2], dtype=tl.float32)\n-\n-    # scalar + scalar -> scalar\n-    a0 = 0.0 + 0.0\n-    # scalar + 0D -> 0D\n-    a1 = 0.0 + zero_0d\n-    a2 = zero_0d + 0.0\n-    # scalar + 1D -> 1D\n-    a3 = 0.0 + zero_1d\n-    a4 = zero_1d + 0.0\n-    # scalar + 2D -> 2D\n-    a5 = 0.0 + zero_2d_22\n-    a6 = zero_2d_22 + 0.0\n-\n-    # 0D + 0D -> 0D\n-    b1 = zero_0d + zero_0d\n-    # 0D + 1D -> 1D\n-    b2 = zero_0d + zero_1d\n-    b3 = zero_1d + zero_0d\n-    # 0D + 2D -> 2D\n-    b4 = zero_0d + zero_2d_22\n-    b5 = zero_2d_22 + zero_0d\n-\n-    # 1D + 1D -> 1D\n-    c1 = zero_1d + zero_1d\n-    # 1D + 2D -> 2D\n-    c2 = zero_1d + zero_2d_21\n-    c3 = zero_1d + zero_2d_22\n-    c4 = zero_2d_21 + zero_1d\n-    c5 = zero_2d_22 + zero_1d\n-\n-    # 2D + 2D -> 2D\n-    d1 = zero_2d_21 + zero_2d_21\n-    d2 = zero_2d_22 + zero_2d_22\n-    d3 = zero_2d_21 + zero_2d_22\n-    d4 = zero_2d_22 + zero_2d_21\n-\n-    return a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, c1, c2, c3, c4, c5, d1, d2, d3, d4\n-\n-\n-def test_cast_check():\n-    kernel = triton.compiler._compile(cast_check,\n-                                      signature=\"*fp32\",\n-                                      device=0,\n-                                      output=\"ttgir\")\n-    assert (kernel)\n-    # TODO: Check types of the results"}, {"filename": "python/tests/test_type.py", "status": "added", "additions": 80, "deletions": 0, "changes": 80, "file_content_changes": "@@ -0,0 +1,80 @@\n+import triton\n+import triton.language as tl\n+\n+\n+# TODO: function with no arguments don't work\n+@triton.jit\n+def binop_type_check(X):\n+    # 0d-tensor is not allowed.\n+    # zero_0d = tl.zeros([], dtype=tl.float32)\n+    zero_1d = tl.zeros([2], dtype=tl.float32)\n+    zero_2d_21 = tl.zeros([2, 1], dtype=tl.float32)\n+    zero_2d_22 = tl.zeros([2, 2], dtype=tl.float32)\n+\n+    # scalar + scalar -> scalar\n+    a0 = 0.0 + 0.0\n+    # # scalar + 0D -> 0D\n+    # a1 = 0.0 + zero_0d\n+    # a2 = zero_0d + 0.0\n+    # scalar + 1D -> 1D\n+    a3 = 0.0 + zero_1d\n+    a4 = zero_1d + 0.0\n+    # scalar + 2D -> 2D\n+    a5 = 0.0 + zero_2d_22\n+    a6 = zero_2d_22 + 0.0\n+\n+    # # 0D + 0D -> 0D\n+    # b1 = zero_0d + zero_0d\n+    # # 0D + 1D -> 1D\n+    # b2 = zero_0d + zero_1d\n+    # b3 = zero_1d + zero_0d\n+    # # 0D + 2D -> 2D\n+    # b4 = zero_0d + zero_2d_22\n+    # b5 = zero_2d_22 + zero_0d\n+\n+    # 1D + 1D -> 1D\n+    c1 = zero_1d + zero_1d\n+    # 1D + 2D -> 2D\n+    c2 = zero_1d + zero_2d_21\n+    c3 = zero_1d + zero_2d_22\n+    c4 = zero_2d_21 + zero_1d\n+    c5 = zero_2d_22 + zero_1d\n+\n+    # 2D + 2D -> 2D\n+    d1 = zero_2d_21 + zero_2d_21\n+    d2 = zero_2d_22 + zero_2d_22\n+    d3 = zero_2d_21 + zero_2d_22\n+    d4 = zero_2d_22 + zero_2d_21\n+\n+    # return a0, a1, a2, a3, a4, a5, a6, b1, b2, b3, b4, b5, c1, c2, c3, c4, c5, d1, d2, d3, d4\n+    return a0, a3, a4, a5, a6, c1, c2, c3, c4, c5, d1, d2, d3, d4\n+\n+\n+def test_binop_type_check():\n+    kernel = triton.compiler._compile(binop_type_check,\n+                                      signature=\"*fp32\",\n+                                      device=0,\n+                                      output=\"ttgir\")\n+    assert (kernel)\n+    # TODO: Check types of the results\n+\n+\n+@triton.jit\n+def reduce_type_check(ptr):\n+    v_32 = tl.load(ptr + tl.arange(0, 32))\n+    v_scalar = tl.min(v_32, axis=0)\n+    tl.store(ptr, v_scalar)\n+    v_64x128 = tl.load(ptr + tl.arange(0, 64)[:, None] + tl.arange(0, 128)[None, :])\n+    v_64 = tl.max(v_64x128, axis=1)\n+    tl.store(ptr + tl.arange(0, 64), v_64)\n+    v_128 = tl.max(v_64x128, axis=0)\n+    tl.store(ptr + tl.arange(0, 128), v_128)\n+\n+\n+def test_reduce_type_check():\n+    kernel = triton.compiler._compile(reduce_type_check,\n+                                      signature=\"*fp32\",\n+                                      device=0,\n+                                      output=\"ttgir\")\n+    assert (kernel)\n+    # TODO: Check types of the results"}, {"filename": "test/Conversion/triton_ops.mlir", "status": "modified", "additions": 56, "deletions": 1, "changes": 57, "file_content_changes": "@@ -55,7 +55,7 @@ func @addptr_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_i32: i32) {\n }\n \n func @load_store_ops_scalar(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %mask : i1) {\n-  // Test if Load/Store ops can handle scalar values (see #XXX)\n+  // Test if Load/Store ops can handle scalar values\n   %other = arith.constant 0.0e+0 : f32\n \n   // load scalar\n@@ -75,3 +75,58 @@ func @load_store_ops_scalar(%ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %ma\n   tt.store %ptr, %c, %mask : f32\n   return\n }\n+\n+func @reduce_ops_infer(%ptr: !tt.ptr<f32>, %v : tensor<1x2x4xf32>) {\n+  // Test if reduce ops infer types correctly\n+\n+  // CHECK: %{{.*}} = tt.reduce %{{.*}} -> tensor<2x4xf32>\n+  %a = tt.reduce %v {redOp = 1 : i32, axis = 0 : i32} : tensor<1x2x4xf32> -> tensor<2x4xf32>\n+  // CHECK: %{{.*}} = tt.reduce %{{.*}} -> tensor<1x4xf32>\n+  %b = tt.reduce %v {redOp = 1 : i32, axis = 1 : i32} : tensor<1x2x4xf32> -> tensor<1x4xf32>\n+  // CHECK: %{{.*}} = tt.reduce %{{.*}} -> tensor<1x2xf32>\n+  %c = tt.reduce %v {redOp = 1 : i32, axis = 2 : i32} : tensor<1x2x4xf32> -> tensor<1x2xf32>\n+  // CHECK: %{{.*}} = tt.reduce %{{.*}} -> tensor<1xf32>\n+  %e = tt.reduce %b {redOp = 1 : i32, axis = 1 : i32} : tensor<1x4xf32> -> tensor<1xf32>\n+  // CHECK: %{{.*}} = tt.reduce %{{.*}} -> tensor<4xf32>\n+  %f = tt.reduce %a {redOp = 1 : i32, axis = 0 : i32} : tensor<2x4xf32> -> tensor<4xf32>\n+  // CHECK: %{{.*}} = tt.reduce %{{.*}} -> f32\n+  %g = tt.reduce %f {redOp = 1 : i32, axis = 0 : i32} : tensor<4xf32> -> f32\n+\n+  // Avoid optimizations for c, e, and g\n+  %ptr1x2 = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<1x2x!tt.ptr<f32>>\n+  %ptr1 = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<1x!tt.ptr<f32>>\n+  tt.store %ptr1x2, %c : tensor<1x2xf32>\n+  tt.store %ptr1, %e : tensor<1xf32>\n+  tt.store %ptr, %g : f32\n+  return\n+}\n+\n+func @dot_ops_infer(%ptr: !tt.ptr<f32>, %v : f32) {\n+  // Test if reduce ops infer types correctly\n+  %v128x32 = tt.splat %v : (f32) -> tensor<128x32xf32>\n+  %v32x128 = tt.splat %v : (f32) -> tensor<32x128xf32>\n+  %v128x1 = tt.splat %v : (f32) -> tensor<128x1xf32>\n+  %v1x128 = tt.splat %v : (f32) -> tensor<1x128xf32>\n+\n+  %zero128x128 = arith.constant dense<0.00e+00> : tensor<128x128xf32>\n+  %zero32x32 = arith.constant dense<0.00e+00> : tensor<32x32xf32>\n+  %zero1x1 = arith.constant dense<0.00e+00> : tensor<1x1xf32>\n+\n+  // CHECK: %{{.*}} = tt.dot %{{.*}} -> tensor<128x128xf32>\n+  %r1 = tt.dot %v128x32, %v32x128, %zero128x128 {allowTF32 = true} : tensor<128x32xf32> * tensor<32x128xf32> -> tensor<128x128xf32>\n+  // CHECK: %{{.*}} = tt.dot %{{.*}} -> tensor<32x32xf32>\n+  %r2 = tt.dot %v32x128, %v128x32, %zero32x32 {allowTF32 = true} : tensor<32x128xf32> * tensor<128x32xf32> -> tensor<32x32xf32>\n+  // CHECK: %{{.*}} = tt.dot %{{.*}} -> tensor<128x128xf32>\n+  %r3 = tt.dot %v128x1, %v1x128, %zero128x128 {allowTF32 = true} : tensor<128x1xf32> * tensor<1x128xf32> -> tensor<128x128xf32>\n+  // CHECK: %{{.*}} = tt.dot %{{.*}} -> tensor<1x1xf32>\n+  %r4 = tt.dot %v1x128, %v128x1, %zero1x1 {allowTF32 = true} : tensor<1x128xf32> * tensor<128x1xf32> -> tensor<1x1xf32>\n+\n+  %ptr128x128 = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>\n+  %ptr32x32 = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<32x32x!tt.ptr<f32>>\n+  %ptr1x1 = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<1x1x!tt.ptr<f32>>\n+  tt.store %ptr128x128, %r1 : tensor<128x128xf32>\n+  tt.store %ptr32x32, %r2 : tensor<32x32xf32>\n+  tt.store %ptr128x128, %r3 : tensor<128x128xf32>\n+  tt.store %ptr1x1, %r4 : tensor<1x1xf32>\n+  return\n+}"}]