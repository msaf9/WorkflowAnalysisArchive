[{"filename": "python/test/regression/test_performance.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -96,7 +96,7 @@ def test_matmul(M, N, K, dtype_str):\n     ms = triton.testing.do_bench(fn, percentiles=None, warmup=100, rep=300)\n     cur_gpu_perf = 2. * M * N * K / ms * 1e-9\n     cur_gpu_util = cur_gpu_perf / max_gpu_perf\n-    assert triton.testing.allclose(cur_gpu_util, ref_gpu_util, tol=0.05)\n+    assert triton.testing.allclose(cur_gpu_util, ref_gpu_util, atol=0.01, rtol=0.05)\n \n \n #######################\n@@ -152,7 +152,7 @@ def test_elementwise(N):\n     ms = triton.testing.do_bench(fn, percentiles=None, warmup=100, rep=500)\n     cur_gpu_perf = 3. * N * z.element_size() / ms * 1e-6\n     cur_gpu_util = cur_gpu_perf / max_gpu_perf\n-    assert triton.testing.allclose(cur_gpu_util, ref_gpu_util, tol=0.05)\n+    assert triton.testing.allclose(cur_gpu_util, ref_gpu_util, atol=0.01, rtol=0.05)\n \n #######################\n # Flash-Attention\n@@ -200,4 +200,4 @@ def test_flash_attention(Z, H, N_CTX, D_HEAD, mode, dtype_str):\n     max_gpu_perf = get_max_tensorcore_tflops(dtype, clock_rate=cur_sm_clock * 1e3)\n     cur_gpu_util = cur_gpu_perf / max_gpu_perf\n     ref_gpu_util = flash_attention_data[DEVICE_NAME][(Z, H, N_CTX, D_HEAD, mode, dtype_str)]\n-    assert triton.testing.allclose(cur_gpu_util, ref_gpu_util, tol=0.05)\n+    assert triton.testing.allclose(cur_gpu_util, ref_gpu_util, atol=0.01, rtol=0.05)"}, {"filename": "python/triton/testing.py", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "file_content_changes": "@@ -93,7 +93,7 @@ def assert_almost_equal(x, y, decimal=2, err_msg=''):\n     npt.assert_array_almost_equal(x, y, err_msg=err_msg, decimal=decimal)\n \n \n-def allclose(x, y, tol=1e-2):\n+def allclose(x, y, atol=0, rtol=1e-2):\n     if not isinstance(x, torch.Tensor):\n         x = torch.tensor(x)\n     if not isinstance(y, torch.Tensor):\n@@ -105,12 +105,11 @@ def allclose(x, y, tol=1e-2):\n     if x.dtype == torch.bool:\n         return torch.sum(x ^ y) == 0\n     if x.dtype in [torch.int8, torch.int16, torch.int32, torch.int64]:\n-        tol = 0\n+        rtol = 0\n     diff = abs(x - y)\n     x_max = torch.max(x)\n     y_max = torch.max(y)\n-    err = torch.max(diff) / torch.max(x_max, y_max)\n-    return err <= tol\n+    return torch.max(diff) <= atol + rtol * torch.max(x_max, y_max)\n \n \n def nvsmi(attrs):"}]