[{"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 53, "deletions": 60, "changes": 113, "file_content_changes": "@@ -49,14 +49,14 @@ class Prefetcher {\n   /// dots to be prefetched\n   SetVector<Value> dots;\n   /// dot => dot operand\n-  DenseMap<Value, Value> dot2aArg;\n-  DenseMap<Value, Value> dot2aDef;\n-  DenseMap<Value, Value> dot2bArg;\n-  DenseMap<Value, Value> dot2bDef;\n+  DenseMap<Value, Value> dot2aLoopArg;\n+  DenseMap<Value, Value> dot2aHeaderDef;\n+  DenseMap<Value, Value> dot2bLoopArg;\n+  DenseMap<Value, Value> dot2bHeaderDef;\n   DenseMap<Value, Value> dot2aYield;\n   DenseMap<Value, Value> dot2bYield;\n   /// operand => defining\n-  DenseMap<Value, Value> operand2headDef;\n+  DenseMap<Value, Value> operand2headPrefetch;\n \n   LogicalResult isForOpOperand(Value v);\n \n@@ -120,6 +120,14 @@ LogicalResult Prefetcher::initialize() {\n   if (dotsInFor.empty())\n     return failure();\n \n+  // returns source of cvt\n+  auto getPrefetchSrc = [this](Value v) -> Value {\n+    // TODO: Check if the layout of src is SharedEncodingAttr\n+    if (auto cvt = v.getDefiningOp<triton::gpu::ConvertLayoutOp>())\n+      return cvt.src();\n+    return Value();\n+  };\n+\n   auto getIncomingOp = [this](Value v) -> Value {\n     if (auto arg = v.dyn_cast<BlockArgument>())\n       if (arg.getOwner()->getParentOp() == forOp.getOperation())\n@@ -133,19 +141,22 @@ LogicalResult Prefetcher::initialize() {\n     return yieldOp.getOperand(yieldIdx);\n   };\n \n-  // Only prefetch loop arg\n   for (triton::DotOp dot : dotsInFor) {\n-    if (Value op = getIncomingOp(dot.a())) {\n-      dot2aDef[dot] = op;\n-      dot2aArg[dot] = dot.a();\n-      dot2aYield[dot] = getYieldOp(dot.a());\n-      dots.insert(dot);\n-    }\n-    if (Value op = getIncomingOp(dot.b())) {\n-      dot2bDef[dot] = op;\n-      dot2bArg[dot] = dot.b();\n-      dot2bYield[dot] = getYieldOp(dot.b());\n-      dots.insert(dot);\n+    Value aSmem = getPrefetchSrc(dot.a());\n+    Value bSmem = getPrefetchSrc(dot.b());\n+    if (aSmem && bSmem) {\n+      Value aHeaderDef = getIncomingOp(aSmem);\n+      Value bHeaderDef = getIncomingOp(bSmem);\n+      // Only prefetch loop arg\n+      if (aHeaderDef && bHeaderDef) {\n+        dots.insert(dot);\n+        dot2aHeaderDef[dot] = aHeaderDef;\n+        dot2bHeaderDef[dot] = bHeaderDef;\n+        dot2aLoopArg[dot] = aSmem;\n+        dot2bLoopArg[dot] = bSmem;\n+        dot2aYield[dot] = getYieldOp(aSmem);\n+        dot2bYield[dot] = getYieldOp(bSmem);\n+      }\n     }\n   }\n \n@@ -160,16 +171,12 @@ void Prefetcher::emitPrologue() {\n                            .cast<RankedTensorType>()\n                            .getEncoding()\n                            .cast<triton::gpu::MmaEncodingAttr>();\n-    if (Value aDef = dot2aDef.lookup(dot)) {\n-      Value newA =\n-          generatePrefetch(aDef, 0, /*isPrefetch*/ true, mmaEncoding, builder);\n-      operand2headDef[dot.getDefiningOp<triton::DotOp>().a()] = newA;\n-    }\n-    if (Value bDef = dot2bDef.lookup(dot)) {\n-      Value newB =\n-          generatePrefetch(bDef, 1, /*isPrefetch*/ true, mmaEncoding, builder);\n-      operand2headDef[dot.getDefiningOp<triton::DotOp>().b()] = newB;\n-    }\n+    Value aPrefetched =\n+      generatePrefetch(dot2aHeaderDef[dot], 0, true, mmaEncoding, builder);\n+    operand2headPrefetch[dot.getDefiningOp<triton::DotOp>().a()] = aPrefetched;\n+    Value bPrefetched =\n+      generatePrefetch(dot2bHeaderDef[dot], 1, true, mmaEncoding, builder);\n+    operand2headPrefetch[dot.getDefiningOp<triton::DotOp>().b()] = bPrefetched;\n   }\n }\n \n@@ -180,10 +187,8 @@ scf::ForOp Prefetcher::createNewForOp() {\n   for (auto v : forOp.getIterOperands())\n     loopArgs.push_back(v);\n   for (Value dot : dots) {\n-    if (Value a = dot2aArg.lookup(dot))\n-      loopArgs.push_back(operand2headDef[a]);\n-    if (Value b = dot2bArg.lookup(dot))\n-      loopArgs.push_back(operand2headDef[b]);\n+    loopArgs.push_back(operand2headPrefetch[dot.getDefiningOp<triton::DotOp>().a()]);\n+    loopArgs.push_back(operand2headPrefetch[dot.getDefiningOp<triton::DotOp>().b()]);\n   }\n \n   auto newForOp = builder.create<scf::ForOp>(\n@@ -197,35 +202,31 @@ scf::ForOp Prefetcher::createNewForOp() {\n \n   for (Operation &op : forOp.getBody()->without_terminator()) {\n     Operation *newOp = nullptr;\n-    if (auto dot = dyn_cast<triton::DotOp>(&op)) {\n+    auto dot = dyn_cast<triton::DotOp>(&op);\n+    if (dots.contains(dot)) {\n       auto mmaEncoding = dot.getType()\n                              .cast<RankedTensorType>()\n                              .getEncoding()\n                              .cast<triton::gpu::MmaEncodingAttr>();\n       // prefetched dot\n       Operation *firstDot = builder.clone(*dot, mapping);\n-      if (Value a = operand2headDef.lookup(dot.a()))\n+      if (Value a = operand2headPrefetch.lookup(dot.a()))\n         firstDot->setOperand(\n             0, newForOp.getRegionIterArgForOpOperand(*a.use_begin()));\n-      if (Value b = operand2headDef.lookup(dot.b()))\n+      if (Value b = operand2headPrefetch.lookup(dot.b()))\n         firstDot->setOperand(\n             1, newForOp.getRegionIterArgForOpOperand(*b.use_begin()));\n \n-      // remaining part (Note it's possible that dot.a() is not in mapping)\n-      Value aRem = mapping.lookupOrNull(dot.a());\n-      Value bRem = mapping.lookupOrNull(dot.b());\n-      if (Value a = dot2aArg.lookup(dot))\n-        aRem =\n-            generatePrefetch(mapping.lookup(a), 0, false, mmaEncoding, builder);\n-      if (Value b = dot2bArg.lookup(dot))\n-        bRem =\n-            generatePrefetch(mapping.lookup(b), 1, false, mmaEncoding, builder);\n+      // remaining part\n+      Value aRem =\n+          generatePrefetch(\n+            mapping.lookup(dot2aLoopArg[dot]), 0, false, mmaEncoding, builder);\n+      Value bRem =\n+          generatePrefetch(\n+            mapping.lookup(dot2bLoopArg[dot]), 1, false, mmaEncoding, builder);\n       newOp = builder.clone(*dot, mapping);\n-      // Use sliced a & b\n-      if (aRem && aRem != mapping.lookup(dot.a()))\n-        newOp->setOperand(0, aRem);\n-      if (bRem && bRem != mapping.lookup(dot.b()))\n-        newOp->setOperand(1, bRem);\n+      newOp->setOperand(0, aRem);\n+      newOp->setOperand(1, bRem);\n       newOp->setOperand(2, firstDot->getResult(0));\n     } else {\n       newOp = builder.clone(op, mapping);\n@@ -244,12 +245,10 @@ scf::ForOp Prefetcher::createNewForOp() {\n                            .cast<RankedTensorType>()\n                            .getEncoding()\n                            .cast<triton::gpu::MmaEncodingAttr>();\n-    if (Value a = dot2aYield.lookup(dot))\n-      yieldValues.push_back(\n-          generatePrefetch(mapping.lookup(a), 0, true, mmaEncoding, builder));\n-    if (Value b = dot2bYield.lookup(dot))\n-      yieldValues.push_back(\n-          generatePrefetch(mapping.lookup(b), 1, true, mmaEncoding, builder));\n+    yieldValues.push_back(\n+      generatePrefetch(mapping.lookup(dot2aYield[dot]), 0, true, mmaEncoding, builder));\n+    yieldValues.push_back(\n+      generatePrefetch(mapping.lookup(dot2bYield[dot]), 1, true, mmaEncoding, builder));\n   }\n   // Update ops of yield\n   builder.create<scf::YieldOp>(yieldOp.getLoc(), yieldValues);\n@@ -272,12 +271,6 @@ struct PrefetchPass : public TritonGPUPrefetchBase<PrefetchPass> {\n         forOp->getResult(i).replaceAllUsesWith(newForOp->getResult(i));\n       forOp->erase();\n     });\n-\n-    // // TODO: Can we use canonicalizer?\n-    // // a & b in `dot a, b, c` should be of DotOperand layout\n-    // getOperand->walk([&](triton::DotOp dotOp) {\n-    //   //\n-    // });\n   }\n };\n "}, {"filename": "test/TritonGPU/prefetch.mlir", "status": "modified", "additions": 18, "deletions": 13, "changes": 31, "file_content_changes": "@@ -7,24 +7,27 @@\n #A = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n #B = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n #C = #triton_gpu.mma<{version = 2, warpsPerCTA = [4, 1]}>\n+#A_OP = #triton_gpu.dot_op<{opIdx = 0, parent = #C}>\n+#B_OP = #triton_gpu.dot_op<{opIdx = 1, parent = #C}>\n+\n \n // CHECK: func @matmul_loop\n // CHECK-DAG: %[[A0_PREFETCH_SMEM:.*]] = tensor.extract_slice %[[A0:.*]][0, 0] [128, 16]\n // CHECK-DAG: %[[A0_PREFETCH:.*]] = triton_gpu.convert_layout %[[A0_PREFETCH_SMEM]]\n // CHECK-DAG: %[[B0_PREFETCH_SMEM:.*]] = tensor.extract_slice %[[B0:.*]][0, 0] [16, 128]\n // CHECK-DAG: %[[B0_PREFETCH:.*]] = triton_gpu.convert_layout %[[B0_PREFETCH_SMEM]]\n-// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, %[[a0_prefetch:.*]] = %[[A0_PREFETCH]], %[[b0_prefetch:.*]] = %[[B0_PREFETCH]]\n-// CHECK:   %[[D_FIRST:.*]] = tt.dot %[[a0_prefetch]], %[[b0_prefetch:.*]], {{.*}}\n-// CHECK-DAG: %[[A_REM_SMEM:.*]] = tensor.extract_slice %[[arg_a0]][0, 16] [128, 16]\n-// CHECK-DAG: %[[A_REM:.*]] = triton_gpu.convert_layout %[[A_REM_SMEM]]\n-// CHECK-DAG: %[[B_REM_SMEM:.*]] = tensor.extract_slice %[[arg_b0]][16, 0] [16, 128]\n-// CHECK-DAG: %[[B_REM:.*]] = triton_gpu.convert_layout %[[B_REM_SMEM]]\n-// CHECK:   tt.dot %[[A_REM]], %[[B_REM]], %[[D_FIRST:.*]]\n-// CHECK-DAG: %[[NEXT_A_PREFETCH_SMEM:.*]] = tensor.extract_slice {{.*}}[0, 0] [128, 16]\n-// CHECK-DAG: %[[NEXT_A_PREFETCH:.*]] = triton_gpu.convert_layout %[[NEXT_A_PREFETCH_SMEM]]\n-// CHECK-DAG: %[[NEXT_B_PREFETCH_SMEM:.*]] = tensor.extract_slice {{.*}}[0, 0] [16, 128]\n-// CHECK-DAG: %[[NEXT_B_PREFETCH:.*]] = triton_gpu.convert_layout %[[NEXT_B_PREFETCH_SMEM]]\n-// CHECK:   scf.yield {{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_PREFETCH]], %[[NEXT_B_PREFETCH]]\n+// CHECK:     scf.for {{.*}} iter_args({{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, %[[a0_prefetch:.*]] = %[[A0_PREFETCH]], %[[b0_prefetch:.*]] = %[[B0_PREFETCH]]\n+// CHECK:       %[[D_FIRST:.*]] = tt.dot %[[a0_prefetch]], %[[b0_prefetch:.*]], {{.*}}\n+// CHECK-DAG:   %[[A_REM_SMEM:.*]] = tensor.extract_slice %[[arg_a0]][0, 16] [128, 16]\n+// CHECK-DAG:   %[[A_REM:.*]] = triton_gpu.convert_layout %[[A_REM_SMEM]]\n+// CHECK-DAG:   %[[B_REM_SMEM:.*]] = tensor.extract_slice %[[arg_b0]][16, 0] [16, 128]\n+// CHECK-DAG:   %[[B_REM:.*]] = triton_gpu.convert_layout %[[B_REM_SMEM]]\n+// CHECK:       tt.dot %[[A_REM]], %[[B_REM]], %[[D_FIRST:.*]]\n+// CHECK-DAG:   %[[NEXT_A_PREFETCH_SMEM:.*]] = tensor.extract_slice {{.*}}[0, 0] [128, 16]\n+// CHECK-DAG:   %[[NEXT_A_PREFETCH:.*]] = triton_gpu.convert_layout %[[NEXT_A_PREFETCH_SMEM]]\n+// CHECK-DAG:   %[[NEXT_B_PREFETCH_SMEM:.*]] = tensor.extract_slice {{.*}}[0, 0] [16, 128]\n+// CHECK-DAG:   %[[NEXT_B_PREFETCH:.*]] = triton_gpu.convert_layout %[[NEXT_B_PREFETCH_SMEM]]\n+// CHECK:     scf.yield {{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_PREFETCH]], %[[NEXT_B_PREFETCH]]\n func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n   %b_ptr_init = tt.broadcast %B : (!tt.ptr<f16>) -> tensor<32x128x!tt.ptr<f16>, #BL>\n@@ -44,7 +47,9 @@ func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B\n   %b_init = triton_gpu.convert_layout %b_ : (tensor<32x128xf16, #BL>) -> tensor<32x128xf16, #B>\n \n   scf.for %iv = %lb to %ub step %step iter_args(%a_ptr = %a_ptr_init, %b_ptr = %b_ptr_init, %a = %a_init, %b = %b_init, %prev_c = %c_init) -> (tensor<128x32x!tt.ptr<f16>, #AL>, tensor<32x128x!tt.ptr<f16>, #BL>, tensor<128x32xf16, #A>, tensor<32x128xf16, #B>, tensor<128x128xf32, #C>) {\n-    %c = tt.dot %a, %b, %prev_c {allowTF32 = true} : tensor<128x32xf16, #A> * tensor<32x128xf16, #B> -> tensor<128x128xf32, #C>\n+    %a_op = triton_gpu.convert_layout %a : (tensor<128x32xf16, #A>) -> tensor<128x32xf16, #A_OP>\n+    %b_op = triton_gpu.convert_layout %b : (tensor<32x128xf16, #B>) -> tensor<32x128xf16, #B_OP>\n+    %c = tt.dot %a_op, %b_op, %prev_c {allowTF32 = true} : tensor<128x32xf16, #A_OP> * tensor<32x128xf16, #B_OP> -> tensor<128x128xf32, #C>\n \n     %next_a_ptr = tt.addptr %a_ptr, %a_off : tensor<128x32x!tt.ptr<f16>, #AL>\n     %next_b_ptr = tt.addptr %b_ptr, %b_off : tensor<32x128x!tt.ptr<f16>, #BL>"}]