[{"filename": "python/tests/libdevice_testutil.py", "status": "added", "additions": 18, "deletions": 0, "changes": 18, "file_content_changes": "@@ -0,0 +1,18 @@\n+import os\n+from typing import Optional\n+\n+_SYSTEM_LIBDEVICE_SEARCH_PATHS = [\n+    '/usr/lib/cuda/nvvm/libdevice/libdevice.10.bc',\n+    '/usr/local/cuda/nvvm/libdevice/libdevice.10.bc',\n+]\n+\n+SYSTEM_LIBDEVICE_PATH: Optional[str] = None\n+for _p in _SYSTEM_LIBDEVICE_SEARCH_PATHS:\n+    if os.path.exists(_p):\n+        SYSTEM_LIBDEVICE_PATH = _p\n+\n+def system_libdevice_path() -> str:\n+    assert SYSTEM_LIBDEVICE_PATH is not None, \\\n+        \"Could not find libdevice.10.bc path\"\n+    return SYSTEM_LIBDEVICE_PATH\n+"}, {"filename": "python/tests/test_core.py", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -12,6 +12,7 @@\n import triton._C.libtriton.triton as _triton\n import triton.language as tl\n from triton.runtime.jit import JITFunction, TensorWrapper, reinterpret\n+from tests.libdevice_testutil import system_libdevice_path\n \n int_dtypes = ['int8', 'int16', 'int32', 'int64']\n uint_dtypes = ['uint8', 'uint16', 'uint32', 'uint64']\n@@ -1552,7 +1553,7 @@ def _kernel(dst):\n \n @pytest.mark.parametrize(\"dtype_str, expr, lib_path\",\n                          [('int32', 'libdevice.ffs', ''),\n-                          ('float32', 'libdevice.pow', '/usr/local/cuda/nvvm/libdevice/libdevice.10.bc'),\n+                          ('float32', 'libdevice.pow', system_libdevice_path()),\n                           ('float64', 'libdevice.norm4d', '')])\n def test_libdevice_tensor(dtype_str, expr, lib_path):\n "}, {"filename": "python/tests/test_elementwise.py", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "file_content_changes": "@@ -5,6 +5,7 @@\n import pytest\n import torch\n from torch.testing import assert_close\n+from tests.libdevice_testutil import system_libdevice_path\n \n import triton\n import triton.language as tl\n@@ -32,8 +33,6 @@\n     \"where\": \"where\",\n }\n \n-libdevice = '/usr/local/cuda/nvvm/libdevice/libdevice.10.bc'\n-\n \n def get_tensor(shape, data_type, b_positive=False):\n     x = None\n@@ -90,7 +89,11 @@ def kernel(X, Y, BLOCK: tl.constexpr):\n     x = get_tensor(shape, input0_type, expr == 'log' or expr == 'sqrt')\n     # triton result\n     y = torch.zeros(shape, dtype=torch_type[output_type], device=\"cuda\")\n-    kernel[(1,)](x, y, BLOCK=shape[0], extern_libs={\"libdevice\": libdevice})\n+    kernel[(1,)](\n+        x, y,\n+        BLOCK=shape[0],\n+        extern_libs={\"libdevice\": sytem_libdevice_path()},\n+    )\n     # reference result\n     y_ref = getattr(torch, torch_ops[expr])(x)\n     # compare"}, {"filename": "python/tests/test_ext_elemwise.py", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -5,6 +5,7 @@\n \n import triton\n import triton.language as tl\n+from tests.libdevice_testutil import system_libdevice_path\n \n \n @pytest.mark.parametrize('num_warps, block_size, iter_size', [\n@@ -125,7 +126,7 @@ def kernel(x_ptr,\n \n \n @pytest.mark.parametrize(\"dtype_str, expr, lib_path\",\n-                         [('int32', 'libdevice.ffs', '/usr/local/cuda/nvvm/libdevice/libdevice.10.bc'),\n+                         [('int32', 'libdevice.ffs', system_libdevice_path()),\n                           ('int32', 'libdevice.ffs', '')])\n def test_libdevice(dtype_str, expr, lib_path):\n     src = f\"\"\""}]