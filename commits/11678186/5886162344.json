[{"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -143,11 +143,11 @@ compared to 1*64 when the hasLeadingOffset is false.\n \n         // ---- begin Ampere ----\n         if (mmaEnc.isAmpere()) {\n-          int perPhase = 128 / (shapePerCTA[order[0]] * 4 / dotOpEnc.getMMAv2kWidth());\n+          int perPhase = 128 / (shapePerCTA[order[0]] * 4 / dotOpEnc.getKWidth());\n           perPhase = std::max<int>(perPhase, 1);\n-          std::vector<size_t> matShape = {8, 8, 4 * dotOpEnc.getMMAv2kWidth()};\n+          std::vector<size_t> matShape = {8, 8, 4 * dotOpEnc.getKWidth()};\n           // for now, disable swizzle when using transposed int8 tensor cores\n-          if ((32 / typeWidthInBit != dotOpEnc.getMMAv2kWidth()) && order[0] == inner)\n+          if ((32 / typeWidthInBit != dotOpEnc.getKWidth()) && order[0] == inner)\n             return get(context, 1, 1, 1, order, CTALayout);\n \n           // --- handle A operand ---\n@@ -655,7 +655,7 @@ section 9.7.13.4.1 for more details.\n     ins\n     \"unsigned\":$opIdx,\n     \"Attribute\":$parent,\n-    \"unsigned\":$MMAv2kWidth\n+    \"unsigned\":$kWidth\n   );\n \n   let builders = ["}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -582,7 +582,7 @@ Value loadArg(ConversionPatternRewriter &rewriter, Location loc, Value tensor,\n   int matShapeM = 8, matShapeN = 8, matShapeK = 2 * 64 / bitwidth;\n \n   auto numRep = encoding.getMMAv2Rep(shapePerCTA, bitwidth);\n-  int kWidth = encoding.getMMAv2kWidth();\n+  int kWidth = encoding.getKWidth();\n \n   auto warpsPerCTA = mmaLayout.getWarpsPerCTA();\n   auto order = triton::gpu::getOrder(mmaLayout);"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1258,7 +1258,7 @@ void DotOperandEncodingAttr::print(mlir::AsmPrinter &printer) const {\n   printer << \"<{\"\n           << \"opIdx = \" << getOpIdx() << \", parent = \" << getParent();\n   if (mmaParent && mmaParent.isAmpere())\n-    printer << \", kWidth = \" << getMMAv2kWidth();\n+    printer << \", kWidth = \" << getKWidth();\n   printer << \"}>\";\n }\n \n@@ -1496,7 +1496,7 @@ struct TritonGPUInferLayoutInterface\n     // Verify that the encodings are valid.\n     if (!aEncoding || !bEncoding)\n       return op->emitError(\"mismatching encoding between A and B operands\");\n-    if (aEncoding.getMMAv2kWidth() != bEncoding.getMMAv2kWidth())\n+    if (aEncoding.getKWidth() != bEncoding.getKWidth())\n       return op->emitError(\"mismatching kWidth between A and B operands\");\n     return success();\n   }"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -203,8 +203,8 @@ LogicalResult Prefetcher::initialize() {\n     auto bType = dot.getB().getType().cast<RankedTensorType>();\n     auto aEnc = aType.getEncoding().cast<triton::gpu::DotOperandEncodingAttr>();\n     auto bEnc = bType.getEncoding().cast<triton::gpu::DotOperandEncodingAttr>();\n-    int aKWidth = aEnc.getMMAv2kWidth();\n-    int bKWidth = bEnc.getMMAv2kWidth();\n+    int aKWidth = aEnc.getKWidth();\n+    int bKWidth = bEnc.getKWidth();\n     assert(aKWidth == bKWidth);\n \n     auto kSize = aType.getShape()[1];"}]