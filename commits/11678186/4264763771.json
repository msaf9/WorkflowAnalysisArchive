[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 11, "deletions": 5, "changes": 16, "file_content_changes": "@@ -1528,7 +1528,7 @@ def kernel(VALUE, X):\n # test constexpr\n # ----------------\n \n-@pytest.mark.parametrize(\"op\", ['+', '-', '*', '/', '%', '<', '>'])\n+@pytest.mark.parametrize(\"op\", ['+', '-', '*', '/', '%', '<', '>', '<<', '>>', '&', '^', '|'])\n @pytest.mark.parametrize(\"is_lhs_constexpr\", [False, True])\n @pytest.mark.parametrize(\"is_rhs_constexpr\", [True, False])\n def test_bin_op_constexpr(op, is_lhs_constexpr, is_rhs_constexpr):\n@@ -1540,11 +1540,17 @@ def kernel(Z, X, Y):\n         z = GENERATE_TEST_HERE\n         tl.store(Z, z)\n \n-    x_str = \"3.14\" if is_lhs_constexpr else \"x\"\n-    y_str = \"4.13\" if is_rhs_constexpr else \"y\"\n+    if op in ['<<', '>>', '&', '^', '|']:  # int op\n+        x_str = \"3\" if is_lhs_constexpr else \"x\"\n+        y_str = \"4\" if is_rhs_constexpr else \"y\"\n+        x = numpy_random((1,), dtype_str=\"int32\")\n+        y = numpy_random((1,), dtype_str=\"int32\")\n+    else:\n+        x_str = \"3.14\" if is_lhs_constexpr else \"x\"\n+        y_str = \"4.13\" if is_rhs_constexpr else \"y\"\n+        x = numpy_random((1,), dtype_str=\"float32\")\n+        y = numpy_random((1,), dtype_str=\"float32\")\n     kernel = patch_kernel(kernel, {'GENERATE_TEST_HERE': f\"{x_str} {op} {y_str}\"})\n-    x = numpy_random((1,), dtype_str=\"float32\")\n-    y = numpy_random((1,), dtype_str=\"float32\")\n     z = np.array(eval(f\"{x_str} {op} {y_str}\"))\n     x_tri = to_triton(x)\n     y_tri = to_triton(y)"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 32, "deletions": 0, "changes": 32, "file_content_changes": "@@ -419,6 +419,9 @@ def logical_and(self, other):\n     def __or__(self, other):\n         return constexpr(self.value | other.value)\n \n+    def __xor__(self, other):\n+        return constexpr(self.value ^ other.value)\n+\n     def logical_or(self, other):\n         return constexpr(self.value or other.value)\n \n@@ -535,21 +538,42 @@ def __and__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.and_(self, other, _builder)\n \n+    @builtin\n+    def __rand__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.and_(other, self, _builder)\n+\n     @builtin\n     def __or__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.or_(self, other, _builder)\n \n+    @builtin\n+    def __ror__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.or_(other, self, _builder)\n+\n+\n     @builtin\n     def __xor__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.xor_(self, other, _builder)\n \n+    @builtin\n+    def __rxor__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.xor_(other, self, _builder)\n+\n     @builtin\n     def __lshift__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.shl(self, other, _builder)\n \n+    @builtin\n+    def __rlshift__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.shl(other, self, _builder)\n+\n     @builtin\n     def __rshift__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n@@ -558,6 +582,14 @@ def __rshift__(self, other, _builder=None):\n         else:\n             return semantic.lshr(self, other, _builder)\n \n+    @builtin\n+    def __rrshift__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        if self.dtype.is_int_signed():\n+            return semantic.ashr(other, self, _builder)\n+        else:\n+            return semantic.lshr(other, self, _builder)\n+\n     # comparison operators\n \n     # >"}]