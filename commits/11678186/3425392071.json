[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 18, "deletions": 12, "changes": 30, "file_content_changes": "@@ -87,7 +87,6 @@ static Value createLLVMIntegerConstant(OpBuilder &builder, Location loc,\n void llPrintf(StringRef msg, ValueRange args,\n               ConversionPatternRewriter &rewriter);\n \n-// Shortcuts for some commonly used LLVM ops to keep code simple and intuitive//\n // Shortcuts for some commonly used LLVM ops to keep code simple and intuitive\n #define zext(...) rewriter.create<LLVM::ZExtOp>(loc, __VA_ARGS__)\n #define udiv(...) rewriter.create<LLVM::UDivOp>(loc, __VA_ARGS__)\n@@ -2964,15 +2963,19 @@ class MMA16816SmemLoader {\n       Type elemTy = type::f32Ty(ctx);\n       Type elemPtrTy = ptr_ty(elemTy);\n       if (kOrder == 1) {\n-        elems[0] = load(gep(elemTy, ptr, sOffsetElemVal));\n-        elems[1] = load(gep(elemTy, ptr2, sOffsetElemVal));\n-        elems[2] = load(gep(elemTy, ptr, sOffsetArrElemVal));\n-        elems[3] = load(gep(elemTy, ptr2, sOffsetArrElemVal));\n+        elems[0] = load(gep(elemPtrTy, ptr, i32_val(sOffsetElem)));\n+        elems[1] = load(gep(elemPtrTy, ptr2, i32_val(sOffsetElem)));\n+        elems[2] =\n+            load(gep(elemPtrTy, ptr, i32_val(sOffsetElem + sOffsetArrElem)));\n+        elems[3] =\n+            load(gep(elemPtrTy, ptr2, i32_val(sOffsetElem + sOffsetArrElem)));\n       } else {\n-        elems[0] = load(gep(elemTy, ptr, sOffsetElemVal));\n-        elems[2] = load(gep(elemTy, ptr2, sOffsetElemVal));\n-        elems[1] = load(gep(elemTy, ptr, sOffsetArrElemVal));\n-        elems[3] = load(gep(elemTy, ptr2, sOffsetArrElemVal));\n+        elems[0] = load(gep(elemPtrTy, ptr, i32_val(sOffsetElem)));\n+        elems[2] = load(gep(elemPtrTy, ptr2, i32_val(sOffsetElem)));\n+        elems[1] =\n+            load(gep(elemPtrTy, ptr, i32_val(sOffsetElem + sOffsetArrElem)));\n+        elems[3] =\n+            load(gep(elemPtrTy, ptr2, i32_val(sOffsetElem + sOffsetArrElem)));\n       }\n       return {elems[0], elems[1], elems[2], elems[3]};\n \n@@ -3164,6 +3167,9 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n     auto mmaLayout = dTensorTy.getEncoding().cast<MmaEncodingAttr>();\n     auto aElemTy = aTensorTy.getElementType();\n     auto bElemTy = bTensorTy.getElementType();\n+\n+    assert((mmaLayout.getVersion() == 1 || mmaLayout.getVersion() == 2) &&\n+           \"Unexpected MMA layout version found\");\n     // Refer to mma section for the data type supported by Volta and Hopper\n     // Tensor Core in\n     // https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-fragment-mma-884-f16\n@@ -3694,6 +3700,7 @@ struct MMA16816ConversionHelper {\n     std::function<void(int, int)> loadFn;\n     auto [matShapeM, matShapeN, matShapeK] = getMmaMatShape(aTensorTy);\n     auto [mmaInstrM, mmaInstrN, mmaInstrK] = getMmaInstrShape(aTensorTy);\n+\n     int numRepM = getNumRepM(aTensorTy, shape[0]);\n     int numRepK = getNumRepK(aTensorTy, shape[1]);\n \n@@ -3809,6 +3816,7 @@ struct MMA16816ConversionHelper {\n                                              std::to_string(i)));\n         // reuse the output registers\n       }\n+\n       mma(retArgs, aArgs, bArgs, cArgs);\n       Value mmaOut = builder.launch(rewriter, loc, helper.getMmaRetType());\n \n@@ -3829,7 +3837,6 @@ struct MMA16816ConversionHelper {\n \n     Type resElemTy = dTensorTy.getElementType();\n \n-    // bitcast to fp32 in bulk\n     for (auto &elem : fc) {\n       elem = bitcast(elem, resElemTy);\n     }\n@@ -3872,9 +3879,7 @@ struct MMA16816ConversionHelper {\n           tensorTy.getShape() /*tileShape*/, instrShape, matShape, perPhase,\n           maxPhase, elemBytes, rewriter, typeConverter, loc);\n       SmallVector<Value> offs = loader.computeOffsets(warpId, lane);\n-\n       const int numPtrs = loader.getNumPtr();\n-\n       SmallVector<Value> ptrs(numPtrs);\n \n       Type smemPtrTy = helper.getShemPtrTy();\n@@ -3886,6 +3891,7 @@ struct MMA16816ConversionHelper {\n       auto [ha0, ha1, ha2, ha3] = loader.loadX4(\n           (kOrder == 1) ? a : b /*mat0*/, (kOrder == 1) ? b : a /*mat1*/, offs,\n           ptrs, helper.getMatType(), helper.getShemPtrTy());\n+\n       if (!needTrans) {\n         ld2(vals, a, b, ha0);\n         ld2(vals, a + 1, b, ha1);"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -123,6 +123,7 @@ SmallVector<unsigned> getShapePerCTA(const Attribute &layout) {\n     if (mmaLayout.getVersion() == 1)\n       return {16 * mmaLayout.getWarpsPerCTA()[0],\n               16 * mmaLayout.getWarpsPerCTA()[1]};\n+    assert(0 && \"Unexpected MMA layout version found\");\n   } else {\n     assert(0 && \"Unimplemented usage of getShapePerCTA\");\n   }"}, {"filename": "python/tests/test_gemm.py", "status": "modified", "additions": 27, "deletions": 2, "changes": 29, "file_content_changes": "@@ -55,6 +55,33 @@ def test_gemm_no_scf(SIZE_M, SIZE_N, SIZE_K, NUM_WARPS):\n     assert_close(c, golden, rtol=1e-3, atol=1e-3, check_dtype=False)\n \n \n+@pytest.mark.parametrize('SIZE_M,SIZE_N,SIZE_K,NUM_WARPS', [\n+    [64, 128, 128, 1],\n+    [128, 128, 128, 4],\n+    [16, 8, 32, 1],\n+    [32, 16, 64, 2],\n+    [32, 16, 64, 4],\n+])\n+def test_gemm_no_scf_int8(SIZE_M, SIZE_N, SIZE_K, NUM_WARPS):\n+    a = torch.randint(-5, 5, (SIZE_M, SIZE_K), device='cuda', dtype=torch.int8)\n+    b = torch.randint(-5, 5, (SIZE_K, SIZE_N), device='cuda', dtype=torch.int8)\n+    c = torch.empty((SIZE_M, SIZE_N), device=a.device, dtype=torch.int32)\n+\n+    grid = lambda META: (1, )\n+    matmul_no_scf_kernel[grid](a_ptr=a, b_ptr=b, c_ptr=c,\n+                               stride_am=a.stride(0), stride_ak=a.stride(1),\n+                               stride_bk=b.stride(0), stride_bn=b.stride(1),\n+                               stride_cm=c.stride(0), stride_cn=c.stride(1),\n+                               M=SIZE_M, N=SIZE_N, K=SIZE_K,\n+                               num_warps=NUM_WARPS)\n+\n+    aa = a.cpu()\n+    bb = b.cpu()\n+    golden = torch.matmul(aa.float(), bb.float()).int()\n+    torch.set_printoptions(profile=\"full\")\n+    torch.testing.assert_close(c.cpu(), golden, check_dtype=False)\n+\n+\n @triton.jit\n def matmul_kernel(\n     a_ptr, b_ptr, c_ptr,\n@@ -80,8 +107,6 @@ def matmul_kernel(\n     c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n     tl.store(c_ptrs, accumulator)\n \n-# TODO: DotConversion in TritonGPUToLLVM cannot support non-splat C for the moment\n-\n \n def get_variant_golden(a, b):\n     SIZE_M = a.shape[0]"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -347,7 +347,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_extract_slice\n   func @basic_extract_slice() {\n     // CHECK: llvm.mlir.addressof @global_smem\n-    // CHECK: llvm.extractvalue \n+    // CHECK: llvm.extractvalue\n     // CHECK-NEXT: llvm.extractvalue\n     // CHECK-NEXT: llvm.extractvalue\n     // CHECK-NEXT: llvm.extractvalue"}]