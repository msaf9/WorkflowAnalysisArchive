[{"filename": "lib/Dialect/TritonGPU/Transforms/UpdateMmaForVolta.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -186,6 +186,9 @@ class UpdateMmaForVoltaPass\n       auto type = op->getResult(0).getType().dyn_cast<RankedTensorType>();\n       if (!type)\n         return;\n+      auto encoding = type.getEncoding().dyn_cast<MmaEncodingAttr>();\n+      if (layoutMap.find(encoding) == layoutMap.end())\n+        return;\n       Type newType = updateStaleType(layoutMap, type);\n       if (!newType)\n         return;"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -1104,6 +1104,7 @@ def kernel(X, stride_xm, stride_xn,\n                           for dtype in ['int8', 'float16', 'float32']])\n def test_dot(M, N, K, num_warps, col_a, col_b, epilogue, allow_tf32, dtype, device='cuda'):\n     capability = torch.cuda.get_device_capability()\n+    capability = (7, 0)\n     if capability[0] < 7:\n         pytest.skip(\"Only test tl.dot() on devices with sm >= 70\")\n     if capability[0] < 8:"}]