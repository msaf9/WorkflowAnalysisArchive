[{"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "file_content_changes": "@@ -444,6 +444,11 @@ void pushConversionForward(triton::gpu::ConvertLayoutOp cvt,\n     }\n   }\n   rewriter.setInsertionPoint(op);\n+  if(op->getNumResults() == 0){\n+    Operation* newOp = rewriter.clone(*op, mapping);\n+    rewriter.eraseOp(op);\n+    return;\n+  }\n   auto *newOp = cloneWithInferType(rewriter, op, mapping);\n   auto newType = newOp->getResult(0).getType().cast<RankedTensorType>();\n   auto newCvtType = RankedTensorType::get(\n@@ -590,12 +595,13 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n     llvm::MapVector<Value, Attribute> toConvert;\n     for (Operation *op : cvtSlices) {\n       // don't rematerialize anything expensive\n-      if (expensiveToRemat(op, srcEncoding)) {\n+      if (expensiveToRemat(op, dstEncoding)) {\n         return failure();\n       }\n       // don't rematerialize non-element-wise\n       if (!op->hasTrait<mlir::OpTrait::SameOperandsAndResultEncoding>() &&\n-          !op->hasTrait<mlir::OpTrait::Elementwise>()) {\n+          !op->hasTrait<mlir::OpTrait::Elementwise>() &&\n+          !isa<triton::StoreOp>(op)) {\n         return failure();\n       }\n       // don't rematerialize if it adds an extra conversion that can't"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -2,7 +2,7 @@\n \n #layout0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n #layout1 = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n-#layout2 = #triton_gpu.mma<{version = 2, warpsPerCTA = [4, 1]}>\n+#layout2 = #triton_gpu.mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [4, 1]}>\n \n // CHECK: [[target_layout:#.*]] = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n // CHECK: [[row_layout:#.*]] = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [1, 4], order = [1, 0]}>"}]