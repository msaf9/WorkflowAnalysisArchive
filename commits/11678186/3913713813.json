[{"filename": "include/triton/Dialect/TritonGPU/Transforms/Passes.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -13,8 +13,6 @@ std::unique_ptr<Pass> createTritonGPUCanonicalizeLoopsPass();\n \n std::unique_ptr<Pass> createTritonGPUCoalescePass();\n \n-std::unique_ptr<Pass> createTritonGPUOptimizeLoadConvertPass();\n-\n std::unique_ptr<Pass> createTritonGPUReorderInstructionsPass();\n \n std::unique_ptr<Pass> createTritonGPUDecomposeConversionsPass();"}, {"filename": "include/triton/Dialect/TritonGPU/Transforms/Passes.td", "status": "modified", "additions": 0, "deletions": 13, "changes": 13, "file_content_changes": "@@ -71,19 +71,6 @@ def TritonGPUCombineOps : Pass<\"tritongpu-combine\", \"mlir::ModuleOp\"> {\n   ];\n }\n \n-def TritonGPUOptimizeLoadConvert: Pass<\"tritongpu-optimize-load-convert\", \"mlir::ModuleOp\"> {\n-  let summary = \"Optimize load + convert into insert_slice_async + wait + extract_slice + convert\";\n-\n-  let description = \"Transform load + convert into insert_slice_async + wait + extract_slice + convert.\"\n-                    \"This decreases registers pressure on architecture with direct pathways between DRAM \"\n-                    \"and shared memory\";\n-\n-  let constructor = \"mlir::createTritonGPUOptimizeLoadConvertPass()\";\n-\n-  let dependentDialects = [\"mlir::triton::gpu::TritonGPUDialect\",\n-                           \"mlir::triton::TritonDialect\"];\n-}\n-\n def TritonGPUReorderInstructions: Pass<\"tritongpu-reorder-instructions\", \"mlir::ModuleOp\"> {\n   let summary = \"Reorder instructions\";\n "}, {"filename": "lib/Dialect/TritonGPU/Transforms/CMakeLists.txt", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -8,7 +8,6 @@ add_mlir_dialect_library(TritonGPUTransforms\n   Combine.cpp\n   Pipeline.cpp\n   Prefetch.cpp\n-  OptimizeLoadConvert.cpp\n   ReorderInstructions.cpp\n   DecomposeConversions.cpp\n   TritonGPUConversion.cpp"}, {"filename": "lib/Dialect/TritonGPU/Transforms/OptimizeLoadConvert.cpp", "status": "removed", "additions": 0, "deletions": 104, "changes": 104, "file_content_changes": "@@ -1,104 +0,0 @@\n-#include \"mlir/Analysis/SliceAnalysis.h\"\n-#include \"mlir/Dialect/SCF/SCF.h\"\n-#include \"mlir/IR/BlockAndValueMapping.h\"\n-#include \"mlir/IR/BuiltinAttributes.h\"\n-#include \"mlir/IR/Matchers.h\"\n-#include \"mlir/IR/PatternMatch.h\"\n-#include \"mlir/IR/Verifier.h\"\n-#include \"mlir/Interfaces/InferTypeOpInterface.h\"\n-#include \"mlir/Pass/Pass.h\"\n-#include \"mlir/Pass/PassManager.h\"\n-#include \"mlir/Support/LogicalResult.h\"\n-#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n-#include \"mlir/Transforms/Passes.h\"\n-#include \"mlir/Transforms/RegionUtils.h\"\n-#include \"triton/Analysis/Utility.h\"\n-#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n-#include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n-#include \"triton/Dialect/TritonGPU/Transforms/TritonGPUConversion.h\"\n-#define GEN_PASS_CLASSES\n-#include \"triton/Dialect/TritonGPU/Transforms/Passes.h.inc\"\n-\n-using namespace mlir;\n-\n-\n-class LoadConvertToInsertSlice : public mlir::RewritePattern{\n-\n-public:\n-  explicit LoadConvertToInsertSlice(mlir::MLIRContext *context)\n-      : mlir::RewritePattern(triton::gpu::ConvertLayoutOp::getOperationName(), 2, context) {}\n-\n-  mlir::LogicalResult\n-  matchAndRewrite(mlir::Operation *op,\n-                  mlir::PatternRewriter &rewriter) const override {\n-      auto cvt = cast<triton::gpu::ConvertLayoutOp>(op);\n-      auto origRetType = cvt.getResult().getType().cast<RankedTensorType>();\n-      auto shape = origRetType.getShape();\n-      auto eltType = origRetType.getElementType();\n-      auto dotOpEncoding = origRetType.getEncoding().dyn_cast<triton::gpu::DotOperandEncodingAttr>();\n-      if(!dotOpEncoding){\n-        return failure();\n-      }\n-      auto cvtArg = cvt.getOperand().getDefiningOp();\n-      if(!cvtArg)\n-        return failure();\n-      auto loadOp = dyn_cast<triton::LoadOp>(*cvtArg);\n-      if(!loadOp){\n-        return failure();\n-      }\n-      auto blockedEncoding = loadOp.getType().cast<RankedTensorType>().getEncoding().dyn_cast<triton::gpu::BlockedEncodingAttr>();\n-      if(!blockedEncoding)\n-        return failure();\n-      auto sharedEncoding = triton::gpu::SharedEncodingAttr::get(getContext(), dotOpEncoding, shape, \n-                                                                 blockedEncoding.getOrder(), eltType);\n-      auto srcTy = RankedTensorType::get({1, shape[0], shape[1]}, \n-                                          eltType, \n-                                          sharedEncoding); \n-      auto loadTensor = rewriter.create<triton::gpu::AllocTensorOp>(op->getLoc(), srcTy);\n-      \n-      auto newOp = rewriter.create<triton::gpu::InsertSliceAsyncOp>(\n-              op->getLoc(), loadTensor.getType(),\n-              loadOp.ptr(),\n-              loadTensor, rewriter.create<arith::ConstantIntOp>(op->getLoc(), 0, 32), \n-              loadOp.mask(),\n-              loadOp.other(), loadOp.cache(),\n-              loadOp.evict(), loadOp.isVolatile(), /*axis*/ 0);\n-      \n-      rewriter.create<triton::gpu::AsyncWaitOp>(op->getLoc(), 0);\n-      auto tmpType = RankedTensorType::get({shape[0], shape[1]}, eltType, sharedEncoding);\n-      auto _0 = rewriter.getI64IntegerAttr(0);\n-      auto _1 = rewriter.getI64IntegerAttr(1);\n-      auto tmp = rewriter.create<tensor::ExtractSliceOp>(op->getLoc(), tmpType, newOp,\n-        SmallVector<OpFoldResult>{_0, _0, _0},\n-        SmallVector<OpFoldResult>{_1,\n-                                  rewriter.getI64IntegerAttr(shape[0]),\n-                                  rewriter.getI64IntegerAttr(shape[1])},\n-        SmallVector<OpFoldResult>{_1, _1, _1});\n-      rewriter.replaceOpWithNewOp<triton::gpu::ConvertLayoutOp>(op, origRetType, tmp);\n-      return success();\n-\n-  }\n-    \n-};\n-\n-class TritonGPUOptimizeLoadConvertPass\n-    : public TritonGPUOptimizeLoadConvertBase<TritonGPUOptimizeLoadConvertPass> {\n-public:\n-  TritonGPUOptimizeLoadConvertPass() = default;\n-\n-  void runOnOperation() override {\n-    MLIRContext *context = &getContext();\n-    ModuleOp m = getOperation();\n-\n-    mlir::RewritePatternSet patterns(context);\n-    patterns.add<LoadConvertToInsertSlice>(context);\n-    if (applyPatternsAndFoldGreedily(m, std::move(patterns)).failed()) {\n-      signalPassFailure();\n-    }\n-  }\n-};\n-\n-std::unique_ptr<Pass>\n-mlir::createTritonGPUOptimizeLoadConvertPass() {\n-  return std::make_unique<TritonGPUOptimizeLoadConvertPass>();\n-}"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "file_content_changes": "@@ -1347,10 +1347,6 @@ void init_triton_ir(py::module &&m) {\n              self.addPass(\n                  mlir::createTritonGPUCombineOpsPass(computeCapability));\n            })\n-      .def(\"add_tritongpu_optimize_load_convert_pass\",\n-           [](mlir::PassManager &self) {\n-             self.addPass(mlir::createTritonGPUOptimizeLoadConvertPass());\n-           })\n       .def(\"add_tritongpu_reorder_instructions_pass\",\n            [](mlir::PassManager &self) {\n              self.addPass(mlir::createTritonGPUReorderInstructionsPass());"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -901,7 +901,6 @@ def ttir_to_ttgir(mod, num_warps, num_stages, compute_capability):\n     pm.add_licm_pass()\n     pm.add_tritongpu_combine_pass(compute_capability)\n     pm.add_cse_pass()\n-    # pm.add_tritongpu_optimize_load_convert_pass()\n     pm.add_tritongpu_decompose_conversions_pass()\n     pm.add_cse_pass()\n     pm.add_symbol_dce_pass()"}]