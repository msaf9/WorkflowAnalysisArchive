[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 38, "deletions": 0, "changes": 38, "file_content_changes": "@@ -1543,7 +1543,45 @@ def test_store_op(M, src_layout, device='cuda'):\n \n     pgm = store_kernel[(1, 1, 1)](x_tri, y_tri)\n     y_ref = x\n+    np.testing.assert_allclose(y_ref, y_tri.cpu().numpy(), rtol=0.01, atol=1e-3)\n+\n \n+@pytest.mark.parametrize(\"src_layout\", layouts)\n+@pytest.mark.parametrize(\"dst_layout\", layouts)\n+@pytest.mark.parametrize(\"src_dim\", [0, 1])\n+@pytest.mark.parametrize(\"dst_dim\", [0, 1])\n+def test_convert_layout(src_layout, dst_layout, src_dim, dst_dim, device='cuda'):\n+    ir = f\"\"\"\n+    #dst = {dst_layout}\n+    #src = {src_layout}\n+    module attributes {{\"triton_gpu.num-warps\" = 4 : i32}} {{\n+        tt.func public @kernel(%arg0: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}, %arg1: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}) {{\n+            %0 = tt.splat %arg0 : (!tt.ptr<i32>) -> tensor<128x!tt.ptr<i32>, #triton_gpu.slice<{{dim = {src_dim}, parent = #src}}>>\n+            %1 = tt.make_range {{end = 128 : i32, start = 0 : i32}} : tensor<128xi32, #triton_gpu.slice<{{dim = {src_dim}, parent = #src}}>>\n+            %2 = tt.addptr %0, %1 : tensor<128x!tt.ptr<i32>, #triton_gpu.slice<{{dim = {src_dim}, parent = #src}}>>, tensor<128xi32, #triton_gpu.slice<{{dim = {src_dim}, parent = #src}}>>\n+            %3 = tt.load %2 {{cache = 1 : i32, evict = 1 : i32, isVolatile = false}} : tensor<128xi32, #triton_gpu.slice<{{dim = {src_dim}, parent = #src}}>>\n+            %4 = tt.splat %arg1 : (!tt.ptr<i32>) -> tensor<128x!tt.ptr<i32>, #triton_gpu.slice<{{dim = {dst_dim}, parent = #dst}}>>\n+            %5 = tt.make_range {{end = 128 : i32, start = 0 : i32}} : tensor<128xi32, #triton_gpu.slice<{{dim = {dst_dim}, parent = #dst}}>>\n+            %6 = tt.addptr %4, %5 : tensor<128x!tt.ptr<i32>, #triton_gpu.slice<{{dim = {dst_dim}, parent = #dst}}>>, tensor<128xi32, #triton_gpu.slice<{{dim = {dst_dim}, parent = #dst}}>>\n+            %7 = triton_gpu.convert_layout %3 : (tensor<128xi32, #triton_gpu.slice<{{dim = {src_dim}, parent = #src}}>>) -> tensor<128xi32, #triton_gpu.slice<{{dim = {dst_dim}, parent = #dst}}>>\n+            tt.store %6, %7 : tensor<128xi32, #triton_gpu.slice<{{dim = {dst_dim}, parent = #dst}}>>\n+            tt.return\n+        }}\n+    }}\n+    \"\"\"\n+    import tempfile\n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.ttgir') as f:\n+        f.write(ir)\n+        f.flush()\n+        kernel = triton.compile(f.name)\n+\n+    rs = RandomState(17)\n+    x = rs.randint(0, 4, (128, )).astype('int32')\n+    y = np.zeros((128, ), dtype='int32')\n+    x_tri = torch.tensor(x, device=device)\n+    y_tri = torch.tensor(y, device=device)\n+    pgm = kernel[(1, 1, 1)](x_tri, y_tri)\n+    y_ref = x\n     np.testing.assert_allclose(y_ref, y_tri.cpu().numpy(), rtol=0.01, atol=1e-3)\n \n "}]