[{"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 31, "deletions": 4, "changes": 35, "file_content_changes": "@@ -113,6 +113,16 @@ compared to 1*64 when the hasLeadingOffset is false.\n                      \"ArrayRef<unsigned>\":$order,\n                      \"CTALayoutAttr\":$CTALayout,\n                      \"unsigned\":$typeWidthInBit), [{\n+        bool needTrans = false; // default value\n+        return get(context, dotOpEnc, shape, order, CTALayout, typeWidthInBit, needTrans);\n+    }]>,\n+\n+    AttrBuilder<(ins \"DotOperandEncodingAttr\":$dotOpEnc,\n+                     \"ArrayRef<int64_t>\":$shape,\n+                     \"ArrayRef<unsigned>\":$order,\n+                     \"CTALayoutAttr\":$CTALayout,\n+                     \"unsigned\":$typeWidthInBit,\n+                     \"bool\":$needTrans), [{\n         auto mmaEnc = dotOpEnc.getParent().dyn_cast<MmaEncodingAttr>();\n \n         if(!mmaEnc)\n@@ -152,16 +162,23 @@ compared to 1*64 when the hasLeadingOffset is false.\n \n           // --- handle A operand ---\n           if (opIdx == 0) { // compute swizzling for A operand\n-              int vec = (order[0] == 1) ? matShape[2] : matShape[0]; // k : m\n-              int mmaStride = (order[0] == 1) ? matShape[0] : matShape[2];\n+              int m = (needTrans) ? matShape[2] : matShape[0];\n+              int k = (needTrans) ? matShape[0] : matShape[2];\n+              int vec = (order[0] == 1) ? k : m;\n+              int mmaStride = (order[0] == 1) ? m : k;\n               int maxPhase = mmaStride / perPhase;\n               return get(context, vec, perPhase, maxPhase, order, CTALayout);\n           }\n \n           // --- handle B operand ---\n           if (opIdx == 1) {\n-              int vec = (order[0] == 1) ? matShape[1] : matShape[2]; // n : k\n-              int mmaStride = (order[0] == 1) ? matShape[2] : matShape[1];\n+              // we compute vec and maxPhase m, n and k size of the mma\n+              // instruction. when matmul operands is transposed, we should\n+              // consider that to get m, n and k.\n+              int n = needTrans ? matShape[2] : matShape[1];\n+              int k = needTrans ? matShape[1] : matShape[2];\n+              int vec = (order[0] == 1) ? n : k;\n+              int mmaStride = (order[0] == 1) ? k : n;\n               int maxPhase = mmaStride / perPhase;\n               return get(context, vec, perPhase, maxPhase, order, CTALayout);\n           }\n@@ -189,6 +206,16 @@ compared to 1*64 when the hasLeadingOffset is false.\n       return get(context, dotOpEnc, shape, order, CTALayout, bitwidth);\n     }]>,\n \n+    AttrBuilder<(ins \"DotOperandEncodingAttr\":$dotOpEnc,\n+                     \"ArrayRef<int64_t>\":$shape,\n+                     \"ArrayRef<unsigned>\":$order,\n+                     \"CTALayoutAttr\":$CTALayout,\n+                     \"Type\":$eltTy,\n+                     \"bool\":$needTrans), [{\n+      unsigned bitwidth = eltTy.getIntOrFloatBitWidth();\n+      return get(context, dotOpEnc, shape, order, CTALayout, bitwidth, needTrans);\n+    }]>,\n+\n     AttrBuilder<(ins \"ArrayRef<int64_t>\":$shape,\n                      \"ArrayRef<unsigned>\":$order,\n                      \"CTALayoutAttr\":$CTALayout,"}, {"filename": "lib/Dialect/TritonGPU/Transforms/OptimizeDotOperands.cpp", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "file_content_changes": "@@ -60,9 +60,14 @@ class ConvertTransConvert : public mlir::RewritePattern {\n     // used here. For tests where numCTAs = 1, this is not a problem since all\n     // CTALayouts are the same.\n     auto newXOrder = triton::gpu::getOrder(argEncoding);\n+    // set needTrans to true here. newXEncoding is computed based on argEncoding\n+    // which is before the transpose. without needTrans we will compute vec and\n+    // maxPhase based on incorrect m, n and k size of mma. the type inference of\n+    // TransOp simply swap the order but doesn't fix the vec and maxPhase for\n+    // the YType, hence it would causing incorrect swizzling code.\n     auto newXEncoding = triton::gpu::SharedEncodingAttr::get(\n         getContext(), ZEncoding, XType.getShape(), newXOrder,\n-        XEncoding.getCTALayout(), XType.getElementType());\n+        XEncoding.getCTALayout(), XType.getElementType(), true);\n     auto newXType = RankedTensorType::get(XType.getShape(),\n                                           XType.getElementType(), newXEncoding);\n     if (XEncoding == newXEncoding)"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -652,10 +652,12 @@ void LoopPipeliner::createBufferTypes() {\n                             .getEncoding()\n                             .dyn_cast<ttg::DotOperandEncodingAttr>()) {\n       // MMAv1 and MMAv2\n+      bool needTrans = dyn_cast_or_null<tt::TransOp>(\n+          cvt.getDefiningOp()->getOperand(0).getDefiningOp());\n       unsigned bitWidth = ty.getElementType().getIntOrFloatBitWidth();\n       sharedEnc = ttg::SharedEncodingAttr::get(\n           ty.getContext(), dotOpEnc, ty.getShape(),\n-          ttg::getOrder(ty.getEncoding()), CTALayout, bitWidth);\n+          ttg::getOrder(ty.getEncoding()), CTALayout, bitWidth, needTrans);\n     } else {\n       // MMAv3\n       sharedEnc = ttg::SharedEncodingAttr::get(ty.getContext(), ty.getShape(),"}]