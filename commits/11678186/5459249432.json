[{"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 12, "deletions": 11, "changes": 23, "file_content_changes": "@@ -89,13 +89,14 @@ struct ReduceOpConversion\n   void getWriteIndexBasic(ConversionPatternRewriter &rewriter, Location loc,\n                           Attribute layout, SmallVector<Value> &index,\n                           SmallVector<Value> &writeIdx,\n-                          std::map<int, Value> &ints, unsigned axis) const {\n+                          std::map<int, Value> &ints, unsigned originalAxis,\n+                          unsigned axis) const {\n     if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n-      auto dim = sliceLayout.getDim();\n-      assert(dim != axis && \"Reduction axis cannot be sliced\");\n+      // Recover the axis in the parent tensor\n+      axis = axis < sliceLayout.getDim() ? axis : axis + 1;\n       auto parentLayout = sliceLayout.getParent();\n       getWriteIndexBasic(rewriter, loc, parentLayout, index, writeIdx, ints,\n-                         axis);\n+                         originalAxis, axis);\n       return;\n     }\n \n@@ -110,21 +111,21 @@ struct ReduceOpConversion\n       // we would have a single accumulation every `axisSizePerThread`\n       // contiguous values in the original tensor, so we would need\n       // to map every `axisSizePerThread` to 1 value in smem as:\n-      // writeIdx[axis] = index[axis] / axisSizePerThread\n-      writeIdx[axis] = udiv(index[axis], axisSizePerThread);\n+      // writeIdx[originalAxis] = index[originalAxis] / axisSizePerThread\n+      writeIdx[originalAxis] = udiv(index[originalAxis], axisSizePerThread);\n     } else if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n       if (!mmaLayout.isAmpere()) {\n         llvm::report_fatal_error(\"Unsupported layout\");\n       }\n-      if (axis == 0) {\n+      if (originalAxis == 0) {\n         // Because warpTileSize = [16, 8] and threadsPerWarp = [8, 4], each 8\n         // rows in smem would correspond to a warp. The mapping\n         // is: (warp_index) x 8 + (row index within warp)\n-        writeIdx[axis] =\n-            add(mul(udiv(index[axis], _16), _8), urem(index[axis], _8));\n+        writeIdx[originalAxis] = add(mul(udiv(index[originalAxis], _16), _8),\n+                                     urem(index[originalAxis], _8));\n       } else {\n         // Same as BlockedEncodingAttr case\n-        writeIdx[axis] = udiv(index[axis], axisSizePerThread);\n+        writeIdx[originalAxis] = udiv(index[originalAxis], axisSizePerThread);\n       }\n     } else {\n       llvm::report_fatal_error(\"Unsupported layout\");\n@@ -214,7 +215,7 @@ struct ReduceOpConversion\n       // get the writeIdx at which to write in smem\n       SmallVector<Value> writeIdx;\n       getWriteIndexBasic(rewriter, loc, srcLayout, indices[key], writeIdx, ints,\n-                         axis);\n+                         axis, axis);\n \n       // calculate the offset in smem for that writeIdx\n       Value writeOffset = linearize(rewriter, loc, writeIdx, smemShape, srcOrd);"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "file_content_changes": "@@ -1830,7 +1830,8 @@ def _welford_combine(mean_1, m2_1, weight_1, mean_2, m2_2, weight_2):\n @pytest.mark.parametrize(\"M, N\", [[128, 128], [256, 128], [256, 256], [128, 256]])\n @pytest.mark.parametrize(\"src_layout\", layouts)\n @pytest.mark.parametrize(\"op\", [\"sum\", \"max\"])\n-def test_chain_reduce(M, N, src_layout, op, device):\n+@pytest.mark.parametrize(\"first_axis\", [0, 1])\n+def test_chain_reduce(M, N, src_layout, op, device, first_axis):\n     op_str = \"\"\n     if op == \"sum\":\n         op_str = f\"\"\"\n@@ -1860,11 +1861,11 @@ def test_chain_reduce(M, N, src_layout, op, device):\n         %11 = \"tt.reduce\"(%10) ({{\n         ^bb0(%arg2: i32, %arg3: i32):\n         {op_str}\n-        }}) {{axis = 1 : i32}} : (tensor<{M}x{N}xi32, #src>) -> tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n+        }}) {{axis = {first_axis} : i32}} : (tensor<{M}x{N}xi32, #src>) -> tensor<{M if first_axis == 1 else N}xi32, #triton_gpu.slice<{{dim = {first_axis}, parent = #src}}>>\n         %12 = \"tt.reduce\"(%11) ({{\n         ^bb0(%arg2: i32, %arg3: i32):\n         {op_str}\n-        }}) {{axis = 0 : i32}} : (tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>) -> i32\n+        }}) {{axis = 0 : i32}} : (tensor<{M if first_axis == 1 else N}xi32, #triton_gpu.slice<{{dim = {first_axis}, parent = #src}}>>) -> i32\n         tt.store %arg1, %12 {{cache = 1 : i32, evict = 1 : i32}} : i32\n         tt.return\n     }}"}]