[{"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -96,8 +96,8 @@ def TT_FpToFpOp : TT_Op<\"fp_to_fp\", [SameOperandsAndResultShape,\n \n def TT_AddPtrOp : TT_Op<\"addptr\",\n                      [NoSideEffect,\n-                     SameOperandsAndResultShape,\n-                     SameOperandsAndResultEncoding,\n+                      SameOperandsAndResultShape,\n+                      SameOperandsAndResultEncoding,\n                       TypesMatchWith<\"result type matches ptr type\",\n                                      \"result\", \"ptr\", \"$_self\">]> {\n     let arguments = (ins TT_PtrLike:$ptr, TT_IntLike:$offset);"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUOps.td", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "file_content_changes": "@@ -16,7 +16,9 @@ class TTG_Op<string mnemonic, list<Trait> traits = []> :\n     Op<TritonGPU_Dialect, mnemonic, traits>;\n \n def TTG_ConvertLayoutOp : TTG_Op<\"convert_layout\",\n-                                 [SameOperandsAndResultShape, NoSideEffect]> {\n+                                 [SameOperandsAndResultShape,\n+                                  SameOperandsAndResultElementType,\n+                                  NoSideEffect]> {\n   let summary = \"convert layout\";\n \n   let arguments = (ins TT_Tensor:$src);\n@@ -87,8 +89,8 @@ def TTG_CmpFOp : TTG_Op<\"cmpf\", [NoSideEffect, Elementwise,\n \n // TODO: migrate to arith::SelectOp on LLVM16\n def TTG_SelectOp : TTG_Op<\"select\", [NoSideEffect, Elementwise, \n-                                 SameOperandsAndResultShape, \n-                                 SameOperandsAndResultEncoding]> {\n+                                     SameOperandsAndResultShape, \n+                                     SameOperandsAndResultEncoding]> {\n   let summary = \"select operation\";\n \n   let description = [{}];"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 9, "deletions": 10, "changes": 19, "file_content_changes": "@@ -498,8 +498,6 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n       // don't rematerialize non-element-wise\n       if (!op->hasTrait<mlir::OpTrait::Elementwise>())\n         return failure();\n-      Attribute dstEncoding =\n-          cvt.getOperand().getType().cast<RankedTensorType>().getEncoding();\n       // don't rematerialize if it adds an extra conversion that can't\n       // be removed\n       for (Value arg : op->getOperands()) {\n@@ -509,7 +507,7 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n         llvm::MapVector<Value, Attribute> toConvert;\n         if (argOp && (argOp != cvt) && cvtSlices.count(argOp) == 0 &&\n             failed(simulateBackwardRematerialization(argOp, processed, layout,\n-                                                     toConvert, dstEncoding))) {\n+                                                     toConvert, srcEncoding))) {\n           return failure();\n         }\n       }\n@@ -521,8 +519,11 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n       if (arg.getDefiningOp() == cvt)\n         mapping.map(arg, cvt.getOperand());\n       else {\n-        auto cvtI = rewriter.create<triton::gpu::ConvertLayoutOp>(\n-            arg.getLoc(), cvt.getOperand().getType(), arg);\n+        auto oldType = arg.getType().cast<RankedTensorType>();\n+        auto newType = RankedTensorType::get(\n+            oldType.getShape(), oldType.getElementType(), srcEncoding);\n+        auto cvtI = rewriter.create<triton::gpu::ConvertLayoutOp>(arg.getLoc(),\n+                                                                  newType, arg);\n         if (Operation *argOp = arg.getDefiningOp())\n           cvtI->moveAfter(argOp);\n         mapping.map(arg, cvtI);\n@@ -531,14 +532,12 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n     rewriter.setInsertionPoint(op);\n     Operation *newOp = rewriter.clone(*op, mapping);\n     auto oldType = op->getResult(0).getType().cast<RankedTensorType>();\n-    auto newType = RankedTensorType::get(\n-        oldType.getShape(), oldType.getElementType(),\n-        cvt.getOperand().getType().cast<RankedTensorType>().getEncoding());\n+    auto newType = RankedTensorType::get(oldType.getShape(),\n+                                         oldType.getElementType(), srcEncoding);\n \n     newOp->getResult(0).setType(newType);\n     auto newCvtType = RankedTensorType::get(\n-        oldType.getShape(), oldType.getElementType(),\n-        cvt.getResult().getType().cast<RankedTensorType>().getEncoding());\n+        oldType.getShape(), oldType.getElementType(), dstEncoding);\n     auto newCvt = rewriter.create<triton::gpu::ConvertLayoutOp>(\n         newOp->getLoc(), newCvtType, newOp->getResult(0));\n     rewriter.replaceOp(op, newCvt->getResults());"}]