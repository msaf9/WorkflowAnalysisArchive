[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "file_content_changes": "@@ -85,10 +85,8 @@ jobs:\n           cd python/test/regression\n           sudo nvidia-smi -i 0 -pm 1\n           sudo nvidia-smi -i 0 --lock-gpu-clocks=1350,1350\n-          sudo nvidia-smi -i 0 --lock-memory-clocks=1215,1215\n           pytest -vs .\n           sudo nvidia-smi -i 0 -rgc\n-          sudo nvidia-smi -i 0 -rmc\n \n       # - name: Run lit tests\n       #   run: |"}, {"filename": "python/test/regression/test_performance.py", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "file_content_changes": "@@ -50,7 +50,7 @@ def nvsmi(attrs):\n         (4096, 64, 4096): {'float16': 0.264},\n         (8192, 64, 8192): {'float16': 0.452},\n     },\n-    # NOTE: \n+    # NOTE:\n     # A100 in the CI server is slow-ish for some reason.\n     # On some other servers, we are getting about 90% peak for 8kx8x8k float16\n     'a100': {\n@@ -146,9 +146,7 @@ def test_elementwise(N):\n     torch.manual_seed(0)\n     ref_gpu_util = elementwise_data[DEVICE_NAME][N]\n     cur_mem_clock = nvsmi(['clocks.current.memory'])[0]\n-    ref_mem_clock = mem_clocks[DEVICE_NAME]\n     max_gpu_perf = get_dram_gbps()\n-    assert abs(cur_mem_clock - ref_mem_clock) < 15, f'GPU memory must run at {ref_mem_clock} MHz'\n     z = torch.empty((N, ), dtype=torch.float16, device='cuda')\n     x = torch.randn_like(z)\n     y = torch.randn_like(z)"}]