[{"filename": "docs/python-api/triton.language.rst", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "file_content_changes": "@@ -111,6 +111,16 @@ Reduction Ops\n     sum\n     xor_sum\n \n+Scan Ops\n+-------------\n+\n+.. autosummary::\n+    :toctree: generated\n+    :nosignatures:\n+\n+    associative_scan\n+    cumsum\n+    cumprod\n \n Atomic Ops\n ----------"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "file_content_changes": "@@ -1534,7 +1534,7 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n     for type in ['int32', 'float32']\n     for axis in [1, 0]\n     for shape in scan2d_shapes\n-    for op in ['cumsum']\n+    for op in ['cumsum', 'cumprod']\n ]\n \n \n@@ -1557,7 +1557,7 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n     x = numpy_random(shape, dtype_str=dtype_str, rs=rs)\n     z = np.empty_like(x)\n     x_tri = to_triton(x, device=device)\n-    numpy_op = {'cumsum': np.cumsum}[op]\n+    numpy_op = {'cumsum': np.cumsum, 'cumprod': np.cumprod}[op]\n     z_dtype_str = dtype_str\n     z_ref = numpy_op(x, axis=axis).astype(getattr(np, z_dtype_str))\n     # triton result\n@@ -1566,7 +1566,10 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n     z_tri = to_numpy(z_tri)\n     # compare\n     if dtype_str == 'float32':\n-        np.testing.assert_allclose(z_ref, z_tri, rtol=0.01)\n+        if op == 'cumprod':\n+            np.testing.assert_allclose(z_ref, z_tri, rtol=0.01, atol=1e-3)\n+        else:\n+            np.testing.assert_allclose(z_ref, z_tri, rtol=0.01)\n     else:\n         np.testing.assert_equal(z_ref, z_tri)\n "}, {"filename": "python/triton/interpreter/tl_lang.py", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -629,3 +629,9 @@ def cumsum(self, input, axis=None):\n         if axis is None:\n             return torch.cumsum(input)\n         return torch.cumsum(input, dim=axis)\n+\n+    @_tensor_operation\n+    def cumprod(self, input, axis=None):\n+        if axis is None:\n+            return torch.cumprod(input)\n+        return torch.cumprod(input, dim=axis)"}, {"filename": "python/triton/language/__init__.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -35,6 +35,7 @@\n     cat,\n     constexpr,\n     cos,\n+    cumprod,\n     cumsum,\n     debug_barrier,\n     device_assert,\n@@ -130,6 +131,7 @@\n     \"cdiv\",\n     \"constexpr\",\n     \"cos\",\n+    \"cumprod\",\n     \"cumsum\",\n     \"debug_barrier\",\n     \"device_assert\","}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "file_content_changes": "@@ -1562,6 +1562,20 @@ def cumsum(input, axis=0):\n     input = _promote_reduction_input(input)\n     return associative_scan(input, axis, _sum_combine)\n \n+# cumprod\n+\n+\n+@jit\n+def _prod_combine(a, b):\n+    return a * b\n+\n+\n+@jit\n+@_add_scan_docstr(\"cumprod\")\n+def cumprod(input, axis=0):\n+    # todo rename this to a generic function name\n+    input = _promote_reduction_input(input)\n+    return associative_scan(input, axis, _prod_combine)\n \n # -----------------------\n # Compiler Hint Ops"}]