[{"filename": "lib/Analysis/Allocation.cpp", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "file_content_changes": "@@ -162,21 +162,22 @@ class AllocationAnalysis {\n     }\n   }\n \n+  template <BufferT::BufferKind T>\n   void maybeAddScratchBuffer(Operation *op, unsigned bytes) {\n     if (bytes > 0)\n-      allocation->addBuffer<BufferT::BufferKind::Scratch>(op, bytes);\n+      allocation->addBuffer<T>(op, bytes);\n   }\n \n   /// Initializes temporary shared memory for a given operation.\n   void getScratchValueSize(Operation *op) {\n     if (auto reduceOp = dyn_cast<triton::ReduceOp>(op)) {\n       ReduceOpHelper helper(reduceOp);\n       unsigned bytes = helper.getScratchSizeInBytes();\n-      maybeAddScratchBuffer(op, bytes);\n+      maybeAddScratchBuffer<BufferT::BufferKind::Scratch>(op, bytes);\n     } else if (auto scanOp = dyn_cast<triton::ScanOp>(op)) {\n       ScanLoweringHelper helper(scanOp);\n       unsigned bytes = helper.getScratchSizeInBytes();\n-      maybeAddScratchBuffer(op, bytes);\n+      maybeAddScratchBuffer<BufferT::BufferKind::Scratch>(op, bytes);\n     } else if (auto cvtLayout = dyn_cast<triton::gpu::ConvertLayoutOp>(op)) {\n       auto srcTy = cvtLayout.getSrc().getType().cast<RankedTensorType>();\n       auto dstTy = cvtLayout.getResult().getType().cast<RankedTensorType>();\n@@ -200,7 +201,7 @@ class AllocationAnalysis {\n           srcTy.getElementType().isa<triton::PointerType>()\n               ? elems * kPtrBitWidth / 8\n               : elems * std::max<int>(8, srcTy.getElementTypeBitWidth()) / 8;\n-      maybeAddScratchBuffer(op, bytes);\n+      maybeAddScratchBuffer<BufferT::BufferKind::Scratch>(op, bytes);\n     } else if (auto atomicRMWOp = dyn_cast<triton::AtomicRMWOp>(op)) {\n       auto value = op->getOperand(0);\n       // only scalar requires scratch memory\n@@ -217,7 +218,7 @@ class AllocationAnalysis {\n             elemTy.isa<triton::PointerType>()\n                 ? elems * kPtrBitWidth / 8\n                 : elems * std::max<int>(8, elemTy.getIntOrFloatBitWidth()) / 8;\n-        maybeAddScratchBuffer(op, bytes);\n+        maybeAddScratchBuffer<BufferT::BufferKind::Scratch>(op, bytes);\n       }\n     } else if (auto atomicCASOp = dyn_cast<triton::AtomicCASOp>(op)) {\n       auto value = op->getOperand(0);\n@@ -229,13 +230,13 @@ class AllocationAnalysis {\n       auto bytes = elemTy.isa<triton::PointerType>()\n                        ? elems * kPtrBitWidth / 8\n                        : elems * elemTy.getIntOrFloatBitWidth() / 8;\n-      maybeAddScratchBuffer(op, bytes);\n+      maybeAddScratchBuffer<BufferT::BufferKind::Scratch>(op, bytes);\n     } else if (auto callOp = dyn_cast<CallOpInterface>(op)) {\n       auto callable = callOp.resolveCallable();\n       auto funcOp = dyn_cast<FunctionOpInterface>(callable);\n       auto *funcAlloc = &(*funcAllocMap)[funcOp];\n       auto bytes = funcAlloc->getSharedMemorySize();\n-      maybeAddScratchBuffer(op, bytes);\n+      maybeAddScratchBuffer<BufferT::BufferKind::Virtual>(op, bytes);\n     }\n   }\n "}]