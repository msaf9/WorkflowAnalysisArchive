[{"filename": "python/test/unit/runtime/test_cache.py", "status": "modified", "additions": 16, "deletions": 13, "changes": 29, "file_content_changes": "@@ -201,28 +201,31 @@ def kernel_add_device(a, b, o, N: tl.constexpr):\n instance_descriptor = namedtuple(\"instance_descriptor\", [\"divisible_by_16\", \"equal_to_1\"])\n \n \n-def test_compile_in_subproc() -> None:\n+def compile_fn(config, cc):\n     @triton.jit\n     def kernel_sub(a, b, o, N: tl.constexpr):\n         idx = tl.arange(0, N)\n-        tl.store(o + idx,\n-                 tl.load(a + idx) - tl.load(b + idx) * 777)\n+        tl.store(o + idx, tl.load(a + idx) - tl.load(b + idx) * 777)\n+    triton.compile(\n+        fn=kernel_sub,\n+        signature={0: \"*fp32\", 1: \"*fp32\", 2: \"*fp32\"},\n+        device=0,\n+        constants={3: 32},\n+        configs=[config],\n+        warm_cache_only=True,\n+        cc=cc,\n+    )\n \n+\n+def test_compile_in_subproc() -> None:\n     major, minor = torch.cuda.get_device_capability(0)\n     cc = major * 10 + minor\n     config = instance_descriptor(tuple(range(4)), ())\n \n+    multiprocessing.set_start_method('spawn')\n     proc = multiprocessing.Process(\n-        target=triton.compile,\n-        kwargs=dict(\n-            fn=kernel_sub,\n-            signature={0: \"*fp32\", 1: \"*fp32\", 2: \"*fp32\"},\n-            device=0,\n-            constants={3: 32},\n-            configs=[config],\n-            warm_cache_only=True,\n-            cc=cc,\n-        ))\n+        target=compile_fn,\n+        args=(config, cc))\n     proc.start()\n     proc.join()\n     assert proc.exitcode == 0"}]