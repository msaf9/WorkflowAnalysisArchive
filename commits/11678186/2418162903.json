[{"filename": "lib/codegen/selection/generator.cc", "status": "modified", "additions": 18, "deletions": 7, "changes": 25, "file_content_changes": "@@ -2350,10 +2350,15 @@ void generator::visit_reducend_inst_fast(ir::reduce_inst* x, std::function<Value\n   std::vector<unsigned> shapes = layout->get_shape();\n \n   Type* sca_ty = cvt(arg->get_type()->get_scalar_ty());\n+  size_t n_bits = sca_ty->getPrimitiveSizeInBits();\n+\n+  std::string n_bits_str = std::to_string(n_bits);\n+  std::string cst = (n_bits == 64) ? \"l\" : \"r\";\n+\n   FunctionType *st_shared_ty = FunctionType::get(void_ty, {i1_ty, ptr_ty(sca_ty, 3), sca_ty}, false);\n-  InlineAsm *st_shared = InlineAsm::get(st_shared_ty, \"@$0 st.shared.b32 [$1], $2;\", \"b,r,r\", true);\n+  InlineAsm *st_shared = InlineAsm::get(st_shared_ty, \"@$0 st.shared.b\" + n_bits_str + \" [$1], $2;\", \"b,\" + cst + \",\" + cst, true);\n   FunctionType *ld_shared_ty = FunctionType::get(sca_ty, {i1_ty, ptr_ty(sca_ty, 3)}, false);\n-  InlineAsm *ld_shared = InlineAsm::get(ld_shared_ty, \"@$1 ld.shared.b32 $0, [$2];\", \"=r,b,r\", true);\n+  InlineAsm *ld_shared = InlineAsm::get(ld_shared_ty, \"@$1 ld.shared.b\" + n_bits_str + \" $0, [$2];\", \"=\" + cst + \",b,\" + cst, true);\n \n \n   Value* thread = tgt_->get_local_id(mod_, *builder_, 0);\n@@ -2410,15 +2415,17 @@ void generator::visit_reducend_inst_fast(ir::reduce_inst* x, std::function<Value\n     for(int k = shuffle_width/2 ; k > 0; k >>= 1)\n       acc = do_acc(acc, shfl_sync(acc, k));\n     // store partial result to shared memory\n-    Value* x_idx = idxs_[x][i][0];\n+    auto x_idxs = idxs_[x][i];\n+    Value* x_idx = x_idxs.empty() ? builder_->getInt32(0) : x_idxs[0];\n     Value* st_off = add(mul(x_idx, i32(warps_per_inner)), warp_j);\n     call(st_shared, {icmp_eq(lane_j, i32(0)), gep(base, st_off), acc});\n   }\n   add_barrier();\n   // at this point, partial accumulator synchronized in shared memory\n   // Just need to reduce `warp_per_inner` numbers in shared memory\n   for(size_t i = 0; i < n_elts/col_per_thread; i++){\n-    Value* x_idx = idxs_[x][i][0];\n+    auto x_idxs = idxs_[x][i];\n+    Value* x_idx = x_idxs.empty() ? builder_->getInt32(0) : x_idxs[0];\n     Value* ld_off = add(mul(x_idx, i32(warps_per_inner)), urem(lane_j, i32(warps_per_inner)));\n     Value* acc = call(ld_shared, {builder_->getInt1(true), gep(base, ld_off)});\n     for(int k = warps_per_inner/2; k > 0; k >>= 1)\n@@ -2525,11 +2532,15 @@ void generator::visit_reduce_inst(ir::reduce_inst* x) {\n     default: throw std::runtime_error(\"unreachable\");\n   }\n   ir::value *arg = x->get_operand(0);\n+  int cc = tgt_->as_nvidia()->sm();\n   analysis::scanline_layout* scanline = layouts_->get(x->get_operand(0))->to_scanline();\n-  // if(scanline && scanline->get_order()[0] == x->get_axis())\n+  analysis::mma_layout* mma = layouts_->get(x->get_operand(0))->to_mma();\n+  bool is_coalesced_scanline = scanline && (scanline->get_order()[0] == x->get_axis());\n+  bool is_a100_mma = mma && (cc >= 80) && (x->get_axis() == 1);\n+  if(is_coalesced_scanline || is_a100_mma)\n     visit_reducend_inst_fast(x, do_acc, neutral);\n-  // else\n-  //   visit_reducend_inst(x, do_acc, neutral);\n+  else\n+    visit_reducend_inst(x, do_acc, neutral);\n }\n \n /**"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -666,6 +666,7 @@ def kernel(X, Z, BLOCK: tl.constexpr):\n \n     rs = RandomState(17)\n     x = numpy_random((shape,), dtype_str=dtype_str, rs=rs)\n+    x[:] = 1\n     # numpy result\n     z_ref = np.sum(x).astype(getattr(np, dtype_str))\n     # triton result"}]