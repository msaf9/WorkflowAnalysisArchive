[{"filename": "include/triton/Conversion/TritonGPUToLLVM/PTXAsmFormat.h", "status": "modified", "additions": 5, "deletions": 10, "changes": 15, "file_content_changes": "@@ -211,16 +211,11 @@ struct PTXInstrCommon {\n \n   using Operand = PTXBuilder::Operand;\n \n-  // clang-format off\n-  PTXInstrExecution& operator()() { return call({}); }\n-  PTXInstrExecution& operator()(Operand* a) { return call({a}); }\n-  PTXInstrExecution& operator()(Operand* a, Operand* b) { return call({a, b}); }\n-  PTXInstrExecution& operator()(Operand* a, Operand* b, Operand* c) { return call({a, b, c}); }\n-  PTXInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d) { return call({a, b, c, d}); }\n-  PTXInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d, Operand * e) { return call({a, b, c, d, e}); }\n-  PTXInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d, Operand * e, Operand* f) { return call({a, b, c, d, e, f}); }\n-  PTXInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d, Operand * e, Operand* f, Operand* g) { return call({a, b, c, d, e, f, g}); }\n-  // clang-format on\n+  template <typename... Args,\n+            typename = typename std::enable_if<sizeof...(Args) <= 7>::type>\n+  PTXInstrExecution &operator()(Args &&...args) {\n+    return call({std::forward<Args>(args)...});\n+  }\n \n   // Set operands of this instruction.\n   PTXInstrExecution &operator()(llvm::ArrayRef<Operand *> oprs,"}, {"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -108,6 +108,8 @@ def TT_AddPtrOp : TT_Op<\"addptr\",\n     let results = (outs TT_PtrLike:$result);\n \n     let assemblyFormat = \"$ptr `,` $offset attr-dict `:` type($result) `,` type($offset)\";\n+\n+    let hasCanonicalizeMethod = 1;\n }\n \n def TT_AdvanceOp : TT_Op<\"advance\","}, {"filename": "include/triton/Dialect/Triton/IR/TritonTypes.td", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -69,6 +69,12 @@ def TT_PtrType : TritonTypeDef<\"Pointer\", \"ptr\"> {\n     let hasCustomAssemblyFormat = 1;\n \n     let skipDefaultBuilders = 1;\n+\n+    let extraClassDeclaration = [{\n+        constexpr static size_t getBitWidth() {\n+            return 64 * 8;\n+        }\n+    }];\n }\n \n // Scalar Pointer Type: `ptr<>`"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 44, "deletions": 0, "changes": 44, "file_content_changes": "@@ -145,6 +145,47 @@ void StoreOp::print(OpAsmPrinter &printer) {\n namespace mlir {\n namespace triton {\n \n+//-- AddPtrOp --\n+// addptr(addptr(%ptr, %idx0), %idx1) => addptr(%ptr, AddI(%idx0, %idx1))\n+LogicalResult AddPtrOp::canonicalize(AddPtrOp op, PatternRewriter &rewriter) {\n+  auto addPtrOp = op.getPtr().getDefiningOp<AddPtrOp>();\n+  if (!addPtrOp) {\n+    return failure();\n+  }\n+\n+  if (!addPtrOp.getOffset().getType().isa<ShapedType>()) {\n+    return failure();\n+  }\n+\n+  size_t targetPtrBitWidth = PointerType::getBitWidth();\n+  auto createExplicitConvert = [&](Value integerOperand) -> Value {\n+    auto integerShapeType = integerOperand.getType().cast<ShapedType>();\n+    auto resultType =\n+        RankedTensorType::get(integerShapeType.getShape(),\n+                              rewriter.getIntegerType(targetPtrBitWidth / 8));\n+    if (integerShapeType.getElementType().getIntOrFloatBitWidth() <\n+        targetPtrBitWidth) {\n+      return rewriter.create<arith::ExtUIOp>(op.getLoc(), resultType,\n+                                             integerOperand);\n+    } else if (integerShapeType.getElementType().getIntOrFloatBitWidth() >\n+               targetPtrBitWidth) {\n+      return rewriter.create<arith::TruncIOp>(op.getLoc(), resultType,\n+                                              integerOperand);\n+    }\n+    return integerOperand;\n+  };\n+\n+  auto lhsIntegerValue = createExplicitConvert(addPtrOp.getOffset());\n+  auto rhsIntegerValue = createExplicitConvert(op.getOffset());\n+\n+  auto sumIntegerValue = rewriter.create<arith::AddIOp>(\n+      op.getLoc(), lhsIntegerValue, rhsIntegerValue);\n+  rewriter.updateRootInPlace(op, [=]() mutable {\n+    op.getOperation()->setOperands({addPtrOp.getPtr(), sumIntegerValue});\n+  });\n+  return success();\n+}\n+\n //-- LoadOp --\n static Type getLoadOpResultType(::mlir::OpBuilder &builder, Type ptrType) {\n   auto ptrTensorType = ptrType.dyn_cast<RankedTensorType>();\n@@ -668,6 +709,9 @@ OpFoldResult BroadcastOp::fold(FoldAdaptor adaptor) {\n   if (!value)\n     return {};\n \n+  if (getOperand().getType().isIntOrIndexOrFloat())\n+    return SplatElementsAttr::get(getType().cast<ShapedType>(), value);\n+\n   if (auto denseElemsAttr = value.dyn_cast<SplatElementsAttr>()) {\n     auto shapedType = getType().cast<ShapedType>();\n     return denseElemsAttr.resizeSplat(shapedType);"}, {"filename": "test/Triton/combine.mlir", "status": "modified", "additions": 48, "deletions": 4, "changes": 52, "file_content_changes": "@@ -23,28 +23,72 @@ tt.func @test_combine_dot_add_pattern() -> (tensor<128x128xf32>, tensor<128x128x\n }\n \n \n-// COM: CHECK-LABEL: @test_combine_addptr_pattern\n+// CHECK-LABEL: @test_combine_addptr_pattern\n tt.func @test_combine_addptr_pattern(%base: !tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>> {\n     %off0 = arith.constant 10 : i32\n     %off1 = arith.constant 15 : i32\n \n     // 10 + 15 = 25\n-    // COM: CHECK-NEXT: %[[cst:.*]] = arith.constant dense<25> : tensor<8xi32>\n+    // CHECK-NEXT: %[[cst:.*]] = arith.constant dense<25> : tensor<8xi64>\n \n     %base_ = tt.broadcast %base : (!tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n \n-    // COM: CHECK-NEXT: %[[tmp0:.*]] = tt.broadcast %{{.*}} : (!tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n+    // CHECK-NEXT: %[[tmp0:.*]] = tt.broadcast %{{.*}} : (!tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n \n     %idx0 = tt.broadcast %off0 : (i32) -> tensor<8xi32>\n     %idx1 = tt.broadcast %off1 : (i32) -> tensor<8xi32>\n \n-    // COM: CHECK-NEXT: %1 = tt.addptr %[[tmp0]], %[[cst]] : tensor<8x!tt.ptr<f32>>, tensor<8xi32>\n+    // CHECK-NEXT: %1 = tt.addptr %[[tmp0]], %[[cst]] : tensor<8x!tt.ptr<f32>>, tensor<8xi64>\n     %ptr0 = tt.addptr %base_, %idx0 : tensor<8x!tt.ptr<f32>>, tensor<8xi32>\n     %ptr1 = tt.addptr %ptr0, %idx1 : tensor<8x!tt.ptr<f32>>, tensor<8xi32>\n \n     tt.return %ptr1 : tensor<8x!tt.ptr<f32>>\n }\n \n+// CHECK-LABEL: @test_combine_addptr_extinteger_pattern\n+tt.func @test_combine_addptr_extinteger_pattern(%base: !tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>> {\n+    %off0 = arith.constant 10 : i64\n+    %off1 = arith.constant 15 : i32\n+\n+    // 10 + 15 = 25\n+    // CHECK-NEXT: %[[cst:.*]] = arith.constant dense<25> : tensor<8xi64>\n+\n+    %base_ = tt.broadcast %base : (!tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n+\n+    // CHECK-NEXT: %[[tmp0:.*]] = tt.broadcast %{{.*}} : (!tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n+\n+    %idx0 = tt.broadcast %off0 : (i64) -> tensor<8xi64>\n+    %idx1 = tt.broadcast %off1 : (i32) -> tensor<8xi32>\n+\n+    // CHECK-NEXT: %1 = tt.addptr %[[tmp0]], %[[cst]] : tensor<8x!tt.ptr<f32>>, tensor<8xi64>\n+    %ptr0 = tt.addptr %base_, %idx0 : tensor<8x!tt.ptr<f32>>, tensor<8xi64>\n+    %ptr1 = tt.addptr %ptr0, %idx1 : tensor<8x!tt.ptr<f32>>, tensor<8xi32>\n+\n+    tt.return %ptr1 : tensor<8x!tt.ptr<f32>>\n+}\n+\n+// CHECK-LABEL: @test_combine_addptr_extinteger_boundary_pattern\n+tt.func @test_combine_addptr_extinteger_boundary_pattern(%base: !tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>> {\n+    %off0 = arith.constant 1 : i64\n+    %off1 = arith.constant 65535 : i16\n+\n+    // 1 + 65535 = 65536\n+    // CHECK-NEXT: %[[cst:.*]] = arith.constant dense<65536> : tensor<8xi64>\n+\n+    %base_ = tt.broadcast %base : (!tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n+\n+    // CHECK-NEXT: %[[tmp0:.*]] = tt.broadcast %{{.*}} : (!tt.ptr<f32>) -> tensor<8x!tt.ptr<f32>>\n+\n+    %idx0 = tt.broadcast %off0 : (i64) -> tensor<8xi64>\n+    %idx1 = tt.broadcast %off1 : (i16) -> tensor<8xi16>\n+\n+    // CHECK-NEXT: %1 = tt.addptr %[[tmp0]], %[[cst]] : tensor<8x!tt.ptr<f32>>, tensor<8xi64>\n+    %ptr0 = tt.addptr %base_, %idx0 : tensor<8x!tt.ptr<f32>>, tensor<8xi64>\n+    %ptr1 = tt.addptr %ptr0, %idx1 : tensor<8x!tt.ptr<f32>>, tensor<8xi16>\n+\n+    tt.return %ptr1 : tensor<8x!tt.ptr<f32>>\n+}\n+\n \n // CHECK-LABEL: @test_combine_select_masked_load_pattern\n tt.func @test_combine_select_masked_load_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %cond: i1) -> (tensor<8xf32>, tensor<8xf32>) {"}]