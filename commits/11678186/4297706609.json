[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 16, "changes": 19, "file_content_changes": "@@ -451,22 +451,9 @@ struct ExtractSliceOpConversion\n     SmallVector<Value, 4> offsetVals;\n     auto mixedOffsets = op.getMixedOffsets();\n     for (auto i = 0; i < mixedOffsets.size(); ++i) {\n-      if (op.isDynamicOffset(i)) {\n-        // A little hacky here, but couldn't find any other way:\n-        // Before we codegen TritonGPUToLLVM, we are using int64 indices\n-        // But for TritonGPU codegen we want int32 indices. Which means\n-        // %tmp = builtin.unrealized_conversion_cast %622 : i64 to index\n-        // %offset = builtin.unrealized_conversion_cast %623 : index to i32\n-        auto off = adaptor.getOffsets()[i];\n-        // off = rewriter\n-        //           .create<UnrealizedConversionCastOp>(loc, TypeRange{i64_ty},\n-        //                                               ValueRange{off})\n-        //           .getResult(0);\n-        // off = rewriter.create<arith::TruncIOp>(loc, i32_ty, off);\n-        llvm::outs() << off << \"\\n\";\n-\n-        opOffsetVals.emplace_back(off);\n-      } else\n+      if (op.isDynamicOffset(i))\n+        opOffsetVals.emplace_back(adaptor.getOffsets()[i]);\n+      else\n         opOffsetVals.emplace_back(i32_val(op.getStaticOffset(i)));\n       offsetVals.emplace_back(add(smemObj.offsets[i], opOffsetVals[i]));\n     }"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 22, "deletions": 18, "changes": 40, "file_content_changes": "@@ -1246,16 +1246,13 @@ def format_of(ty):\n   PyObject *launch_enter_hook = NULL;\n   PyObject *launch_exit_hook = NULL;\n   PyObject *compiled_kernel = NULL;\n-  PyObject *hook_ret = NULL;\n   {' '.join([f\"{_extracted_type(ty)} _arg{i}; \" for i, ty in signature.items()])}\n   if(!PyArg_ParseTuple(args, \\\"{format}\\\", &gridX, &gridY, &gridZ, &num_warps, &shared_memory, &_stream, &_function, &launch_enter_hook, &launch_exit_hook, &compiled_kernel, {', '.join(f\"&_arg{i}\" for i, ty in signature.items())})) {{\n     return NULL;\n   }}\n \n   if (launch_enter_hook != Py_None) {{\n-    PyObject *new_args = PyTuple_Pack(1, compiled_kernel);\n-    hook_ret = PyObject_CallObject(launch_enter_hook, new_args);\n-    Py_DECREF(new_args);\n+    PyObject_CallObject(launch_enter_hook, args);\n   }}\n \n \n@@ -1264,19 +1261,9 @@ def format_of(ty):\n   _launch(gridX, gridY, gridZ, num_warps, shared_memory, (CUstream)_stream, (CUfunction)_function, {', '.join(f\"ptr_info{i}.dev_ptr\" if ty[0]==\"*\" else f\"_arg{i}\"for i, ty in signature.items())});\n \n   if (launch_exit_hook != Py_None) {{\n-    PyObject *new_args = NULL;\n-    if (hook_ret) {{\n-        new_args = PyTuple_Pack(2, compiled_kernel, hook_ret);\n-    }} else {{\n-        new_args = PyTuple_Pack(1, compiled_kernel);\n-    }}\n-    hook_ret = PyObject_CallObject(launch_exit_hook, new_args);\n-    Py_DECREF(new_args);\n+    PyObject_CallObject(launch_exit_hook, args);\n   }}\n \n-  if (hook_ret) {{\n-      Py_DECREF(hook_ret);\n-  }}\n   if(PyErr_Occurred()) {{\n     return NULL;\n   }}\n@@ -1543,7 +1530,22 @@ def make_hash(fn, **kwargs):\n }\n \n \n+def _get_jsonable_constants(constants):\n+    def _is_jsonable(x):\n+        try:\n+            json.dumps(x)\n+            return True\n+        except (TypeError, OverflowError):\n+            return False\n+    serialized_constants = {}\n+    for constant in constants:\n+        if _is_jsonable(constants[constant]):\n+            serialized_constants[constant] = constants[constant]\n+    return serialized_constants\n+\n # def compile(fn, signature: str, device: int = -1, constants=dict(), num_warps: int = 4, num_stages: int = 3, extern_libs=None, configs=None):\n+\n+\n def compile(fn, **kwargs):\n     capability = kwargs.get(\"cc\", None)\n     if capability is None:\n@@ -1616,7 +1618,7 @@ def compile(fn, **kwargs):\n         with open(fn_cache_manager._make_path(f\"{name}.json\")) as f:\n             metadata = json.load(f)\n     else:\n-        metadata = {\"num_warps\": num_warps, \"num_stages\": num_stages, \"ctime\": dict()}\n+        metadata = {\"num_warps\": num_warps, \"num_stages\": num_stages, \"constants\": _get_jsonable_constants(constants), \"ctime\": dict()}\n         if ext == \"ptx\":\n             assert \"shared\" in kwargs, \"ptx compilation must provide shared memory size\"\n             metadata[\"shared\"] = kwargs[\"shared\"]\n@@ -1647,7 +1649,7 @@ def compile(fn, **kwargs):\n     # write-back metadata\n     fn_cache_manager.put(json.dumps(metadata), f\"{name}.json\", binary=False)\n     # return handle to compiled kernel\n-    return CompiledKernel(so_path, metadata, asm)\n+    return CompiledKernel(fn, so_path, metadata, asm)\n \n \n class CompiledKernel:\n@@ -1656,17 +1658,19 @@ class CompiledKernel:\n     launch_enter_hook = None\n     launch_exit_hook = None\n \n-    def __init__(self, so_path, metadata, asm):\n+    def __init__(self, fn, so_path, metadata, asm):\n         # initialize launcher\n         import importlib.util\n         spec = importlib.util.spec_from_file_location(\"__triton_launcher\", so_path)\n         mod = importlib.util.module_from_spec(spec)\n+        self.fn = fn\n         spec.loader.exec_module(mod)\n         self.c_wrapper = getattr(mod, \"launch\")\n         # initialize metadata\n         self.shared = metadata[\"shared\"]\n         self.num_warps = metadata[\"num_warps\"]\n         self.num_stages = metadata[\"num_stages\"]\n+        self.constants = metadata[\"constants\"]\n         # initialize asm dict\n         self.asm = asm\n         # binaries are lazily initialized"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 31, "deletions": 0, "changes": 31, "file_content_changes": "@@ -419,6 +419,9 @@ def logical_and(self, other):\n     def __or__(self, other):\n         return constexpr(self.value | other.value)\n \n+    def __xor__(self, other):\n+        return constexpr(self.value ^ other.value)\n+\n     def logical_or(self, other):\n         return constexpr(self.value or other.value)\n \n@@ -535,21 +538,41 @@ def __and__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.and_(self, other, _builder)\n \n+    @builtin\n+    def __rand__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.and_(other, self, _builder)\n+\n     @builtin\n     def __or__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.or_(self, other, _builder)\n \n+    @builtin\n+    def __ror__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.or_(other, self, _builder)\n+\n     @builtin\n     def __xor__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.xor_(self, other, _builder)\n \n+    @builtin\n+    def __rxor__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.xor_(other, self, _builder)\n+\n     @builtin\n     def __lshift__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n         return semantic.shl(self, other, _builder)\n \n+    @builtin\n+    def __rlshift__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        return semantic.shl(other, self, _builder)\n+\n     @builtin\n     def __rshift__(self, other, _builder=None):\n         other = _to_tensor(other, _builder)\n@@ -558,6 +581,14 @@ def __rshift__(self, other, _builder=None):\n         else:\n             return semantic.lshr(self, other, _builder)\n \n+    @builtin\n+    def __rrshift__(self, other, _builder=None):\n+        other = _to_tensor(other, _builder)\n+        if self.dtype.is_int_signed():\n+            return semantic.ashr(other, self, _builder)\n+        else:\n+            return semantic.lshr(other, self, _builder)\n+\n     # comparison operators\n \n     # >"}]