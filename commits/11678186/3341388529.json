[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 6, "deletions": 13, "changes": 19, "file_content_changes": "@@ -624,13 +624,6 @@ class ConvertTritonGPUOpToLLVMPattern\n   Value smem;\n };\n \n-Value convertSplatLikeOpWithMmaLayout(const MmaEncodingAttr &layout,\n-                                      Type resType, Type elemType,\n-                                      Value constVal,\n-                                      TypeConverter *typeConverter,\n-                                      ConversionPatternRewriter &rewriter,\n-                                      Location loc);\n-\n Value convertSplatLikeOpWithMmaLayout(const MmaEncodingAttr &layout,\n                                       Type resType, Type elemType,\n                                       Value constVal,\n@@ -654,8 +647,8 @@ Value convertSplatLikeOp(Type elemType, Type resType, Value constVal,\n     auto srcType = typeConverter->convertType(elemType);\n     auto llSrc = bitcast(srcType, constVal);\n     size_t elemsPerThread = getElemsPerThread(layout, tensorTy.getShape());\n-    llvm::SmallVector<Value, 4> elems(elemsPerThread, llSrc);\n-    llvm::SmallVector<Type, 4> elemTypes(elems.size(), srcType);\n+    llvm::SmallVector<Value> elems(elemsPerThread, llSrc);\n+    llvm::SmallVector<Type> elemTypes(elems.size(), srcType);\n     auto structTy =\n         LLVM::LLVMStructType::getLiteral(rewriter.getContext(), elemTypes);\n \n@@ -3492,7 +3485,7 @@ struct InsertSliceAsyncOpConversion\n \n     auto srcTy = src.getType().cast<RankedTensorType>();\n     auto resTy = dst.getType().cast<RankedTensorType>();\n-    auto resElemTy = resTy.getElementType();\n+    auto resElemTy = getTypeConverter()->convertType(resTy.getElementType());\n     auto srcBlockedLayout = srcTy.getEncoding().cast<BlockedEncodingAttr>();\n     auto resSharedLayout = resTy.getEncoding().cast<SharedEncodingAttr>();\n     auto srcShape = srcTy.getShape();\n@@ -3628,16 +3621,16 @@ struct InsertSliceAsyncOpConversion\n       CacheModifier srcCacheModifier =\n           byteWidth == 16 ? CacheModifier::CG : CacheModifier::CA;\n       assert(byteWidth == 16 || byteWidth == 8 || byteWidth == 4);\n+      auto resByteWidth = resElemTy.getIntOrFloatBitWidth() / 8;\n \n       auto tileOffset = tileOffsetMap[{tileVecIdxRow, tileVecIdxCol}];\n       for (unsigned wordIdx = 0; wordIdx < numWords; ++wordIdx) {\n         PTXBuilder ptxBuilder;\n         auto wordElemIdx = wordIdx * numWordElems;\n         auto &copyAsyncOp =\n             *ptxBuilder.create<PTXCpAsyncLoadInstr>(srcCacheModifier);\n-        auto tileOffsetWord =\n-            gep(dstPtrTy, tileOffset, i32_val(wordElemIdx + baseOffset));\n-        auto *dstOperand = ptxBuilder.newAddrOperand(tileOffsetWord, \"r\");\n+        auto *dstOperand = ptxBuilder.newAddrOperand(\n+            tileOffset, \"r\", (wordElemIdx + baseOffset) * resByteWidth);\n         auto *srcOperand =\n             ptxBuilder.newAddrOperand(srcElems[elemIdx + wordElemIdx], \"l\");\n         auto *copySize = ptxBuilder.newConstantOperand(byteWidth);"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -113,6 +113,9 @@ class SimplifyConversion : public mlir::RewritePattern {\n     auto insert_slice = dyn_cast<triton::gpu::InsertSliceAsyncOp>(arg);\n     if (insert_slice) {\n       auto newType = op->getResult(0).getType();\n+      // Ensure that the new insert_slice op is placed in the same place as the\n+      // old insert_slice op. Otherwise, the new insert_slice op may be placed\n+      // after the async_wait op, which is not allowed.\n       OpBuilder::InsertionGuard guard(rewriter);\n       rewriter.setInsertionPoint(insert_slice);\n       auto new_arg = rewriter.create<triton::gpu::ConvertLayoutOp>(\n@@ -128,6 +131,9 @@ class SimplifyConversion : public mlir::RewritePattern {\n     auto extract_slice = dyn_cast<triton::gpu::ExtractSliceOp>(arg);\n     if (extract_slice) {\n       auto origType = extract_slice.src().getType().cast<RankedTensorType>();\n+      // Ensure that the new extract_slice op is placed in the same place as the\n+      // old extract_slice op. Otherwise, the new extract_slice op may be placed\n+      // after the async_wait op, which is not allowed.\n       OpBuilder::InsertionGuard guard(rewriter);\n       rewriter.setInsertionPoint(extract_slice);\n       auto newType = RankedTensorType::get("}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "file_content_changes": "@@ -365,19 +365,20 @@ void LoopPipeliner::emitPrologue() {\n         loadStageBuffer[loadOp][numStages - 1], loopIterIdx, /*axis*/ 0);\n     loadsExtract[loadOp] = extractSlice;\n   }\n-  // bump up loopIterIdx, this is used for the *next* iteration\n+  // bump up loopIterIdx, this is used for getting the correct slice for the\n+  // *next* iteration\n   loopIterIdx = builder.create<arith::AddIOp>(\n       loopIterIdx.getLoc(), loopIterIdx,\n       builder.create<arith::ConstantIntOp>(loopIterIdx.getLoc(), 1, 32));\n }\n \n void LoopPipeliner::emitEpilogue() {\n-  // If there's any dangling async copies, we need to wait for them.\n+  // If there's any outstanding async copies, we need to wait for them.\n   OpBuilder builder(forOp);\n   OpBuilder::InsertionGuard g(builder);\n   builder.setInsertionPointAfter(forOp);\n-  Operation *asyncWait = builder.create<triton::gpu::AsyncWaitOp>(\n-      forOp.getLoc(), 0);\n+  Operation *asyncWait =\n+      builder.create<triton::gpu::AsyncWaitOp>(forOp.getLoc(), 0);\n }\n \n scf::ForOp LoopPipeliner::createNewForOp() {"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -998,7 +998,6 @@ def _compile(fn, signature: str, device: int = -1, constants=dict(), specializat\n     ptx = make_ptx(llvm_ir, compute_capability, ptx_version)\n     shem_size = _triton.get_shared_memory_size(module)\n     kernel_name = ptx_get_kernel_name(ptx)\n-\n     if output == \"ptx\":\n         return ptx, shem_size, kernel_name\n "}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "file_content_changes": "@@ -326,7 +326,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n #shared0 = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  // CHECK: llvm.mlir.global internal @global_smem\n+  // CHECK: llvm.mlir.global external @global_smem\n   // CHECK-LABEL: basic_alloc_tensor\n   func @basic_alloc_tensor() {\n     // CHECK: llvm.mlir.addressof @global_smem\n@@ -343,7 +343,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n #shared0 = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  // CHECK: llvm.mlir.global internal @global_smem\n+  // CHECK: llvm.mlir.global external @global_smem\n   // CHECK-LABEL: basic_extract_slice\n   func @basic_extract_slice() {\n     // CHECK: %[[BASE0:.*]] = llvm.mlir.addressof @global_smem\n@@ -382,10 +382,10 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #slice2d1 = #triton_gpu.slice<{dim = 1, parent=#block2}>\n #slice3d0 = #triton_gpu.slice<{dim = 0, parent=#block3}>\n #AL = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n-#A = #triton_gpu.shared<{vec = 4, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n+#A = #triton_gpu.shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v4\n-  func @basic_insert_slice_async_v4(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n+  func @basic_insert_slice_async_v4(%arg0: !tt.ptr<f32> {tt.divisibility = 8 : i32}) {\n     %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #slice2d1>\n     %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<64xi32, #slice3d0>\n     %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #slice2d1>) -> tensor<16x1xi32, #block2>\n@@ -406,7 +406,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n     // CHECK: llvm.inline_asm has_side_effects asm_dialect = att\n     // CHECK-SAME: cp.async.cg.shared.global [ ${{.*}} + 0 ], [ ${{.*}} + 0 ], 0x10, 0x10\n     // CHECK: llvm.inline_asm has_side_effects asm_dialect = att\n-    // CHECK-SAME: cp.async.cg.shared.global [ ${{.*}} + 8 ], [ ${{.*}} + 0 ], 0x10, 0x10\n+    // CHECK-SAME: cp.async.cg.shared.global [ ${{.*}} + 16 ], [ ${{.*}} + 0 ], 0x10, 0x10\n     // CHECK: llvm.inline_asm has_side_effects asm_dialect = att\n     // CHECK-SAME: cp.async.commit_group\n     %a = triton_gpu.insert_slice_async %a_ptr, %tensor, %index {axis = 0 : i32, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x64x!tt.ptr<f32>, #AL> -> tensor<2x16x64xf32, #A>\n@@ -497,13 +497,13 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 0 ], [ ${{.*}} + 0 ], 0x4, 0x4\n     // CHECK: llvm.inline_asm\n-    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 512 ], [ ${{.*}} + 0 ], 0x4, 0x4\n+    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 2048 ], [ ${{.*}} + 0 ], 0x4, 0x4\n     // CHECK: llvm.inline_asm\n-    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 512 ], [ ${{.*}} + 0 ], 0x4, 0x4\n+    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 2048 ], [ ${{.*}} + 0 ], 0x4, 0x4\n     // CHECK: llvm.inline_asm\n-    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 512 ], [ ${{.*}} + 0 ], 0x4, 0x4\n+    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 2048 ], [ ${{.*}} + 0 ], 0x4, 0x4\n     // CHECK: llvm.inline_asm\n-    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 512 ], [ ${{.*}} + 0 ], 0x4, 0x4\n+    // CHECK-SAME: cp.async.ca.shared.global [ ${{.*}} + 2048 ], [ ${{.*}} + 0 ], 0x4, 0x4\n     // CHECK: llvm.inline_asm\n     // CHECK-SAME: cp.async.commit_group\n     %a = triton_gpu.insert_slice_async %a_ptr, %tensor, %index {axis = 0 : i32, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<32x32x!tt.ptr<f32>, #AL> -> tensor<2x32x32xf32, #A>\n@@ -545,7 +545,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [8, 4], warpsPerCTA = [1, 1], order = [1, 0]}>\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [4, 1], threadsPerWarp = [4, 8], warpsPerCTA = [1, 1], order = [0, 1]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n-  // CHECK: llvm.mlir.global internal @global_smem() {addr_space = 3 : i32} : !llvm.array<1088 x i8>\n+  // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_blocked\n   func @convert_layout_blocked_blocked(%arg0: tensor<16x16xf32, #blocked0>) {\n     // CHECK: llvm.mlir.addressof @global_smem\n@@ -593,7 +593,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [8, 4], warpsPerCTA = [1, 1], order = [1, 0]}>\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [16, 2], warpsPerCTA = [1, 1], order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n-  // CHECK: llvm.mlir.global internal @global_smem() {addr_space = 3 : i32} : !llvm.array<1280 x i8>\n+  // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_blocked_vec\n   func @convert_layout_blocked_blocked_vec(%arg0: tensor<16x16xf32, #blocked0>) {\n     // CHECK: llvm.mlir.addressof @global_smem\n@@ -617,7 +617,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [8, 4], warpsPerCTA = [1, 1], order = [1, 0]}>\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [1, 1], order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n-  // CHECK: llvm.mlir.global internal @global_smem() {addr_space = 3 : i32} : !llvm.array<640 x i8>\n+  // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_blocked_multi_rep\n   func @convert_layout_blocked_blocked_multi_rep(%arg0: tensor<16x16xf32, #blocked0>) {\n     // CHECK: llvm.mlir.addressof @global_smem\n@@ -682,7 +682,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [32, 1], warpsPerCTA = [1, 4], order = [1, 0]}>\n #mma = #triton_gpu.mma<{version = 2, warpsPerCTA = [2, 2]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n-  // CHECK: llvm.mlir.global internal @global_smem() {addr_space = 3 : i32} : !llvm.array<2560 x i8>\n+  // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_mma_block\n   func @convert_layout_mma_blocked(%arg0: tensor<32x16xf32, #mma>) {\n     // CHECK: nvvm.barrier0\n@@ -703,7 +703,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [8, 1], order = [1, 0]}>\n #shared0 = #triton_gpu.shared<{vec = 8, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n-  // CHECK: llvm.mlir.global internal @global_smem() {addr_space = 3 : i32} : !llvm.array<16384 x i8>\n+  // CHECK: llvm.mlir.global external @global_smem() {addr_space = 3 : i32} : !llvm.array<0 x i8>\n   // CHECK-LABEL: convert_layout_blocked_shared\n   func @convert_layout_blocked_shared(%arg0: tensor<128x32xf32, #blocked0>) {\n     // CHECK: llvm.store"}, {"filename": "test/TritonGPU/loop-pipeline.mlir", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -22,7 +22,7 @@\n // CHECK:   triton_gpu.async_wait {num = 2 : i32}\n // CHECK: %[[A0:.*]] = triton_gpu.extract_slice %[[A1BUFFER]], %[[CONSTANT_0]]\n // CHECK: %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]], %[[CONSTANT_0]]\n-// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_0]]\n+// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_1]]\n // CHECK:   tt.dot %[[arg_a0]], %[[arg_b0]], {{.*}}\n // CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n // CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n@@ -78,7 +78,7 @@ func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B\n // CHECK:   triton_gpu.async_wait {num = 2 : i32}\n // CHECK:   %[[A0:.*]] = triton_gpu.extract_slice %[[A1BUFFER]], %[[CONSTANT_0]]\n // CHECK:   %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]], %[[CONSTANT_0]]\n-// CHECK:   scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_0]]\n+// CHECK:   scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_1]]\n // CHECK:     tt.dot %[[arg_a0]], %[[arg_b0]], {{.*}}\n // CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n // CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n@@ -131,7 +131,7 @@ func @matmul_loop_nested(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f\n // CHECK: %[[B1BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_1]]\n // CHECK: triton_gpu.async_wait {num = 1 : i32}\n // CHECK: %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]], %[[CONSTANT_0]]\n-// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_0]]\n+// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_1]]\n // CHECK:   tt.dot {{.*}}, %[[arg_b0]], {{.*}}\n // CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n // CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]"}]