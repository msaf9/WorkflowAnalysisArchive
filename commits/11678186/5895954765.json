[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 26, "deletions": 5, "changes": 31, "file_content_changes": "@@ -52,6 +52,7 @@ jobs:\n           echo \"BACKEND=CUDA\" >> \"${GITHUB_ENV}\"\n           echo \"ENABLE_TMA=0\" >> \"${GITHUB_ENV}\"\n           echo \"ENABLE_MMA_V3=0\" >> \"${GITHUB_ENV}\"\n+          echo \"TRITON_DISABLE_LINE_INFO=1\" >> \"${GITHUB_ENV}\"\n \n       - name: Clear cache\n         run: |\n@@ -91,23 +92,43 @@ jobs:\n         if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '1' && env.ENABLE_MMA_V3 == '1'}}\n         run: |\n           cd python/test/unit\n-          python3 -m pytest -n 8 --ignore=runtime\n+          python3 -m pytest -n 8 --ignore=runtime --ignore=operators --ignore=language/test_line_info.py\n           # run runtime tests serially to avoid race condition with cache handling.\n           python3 -m pytest runtime/\n+          # run test_line_info.py separately with TRITON_DISABLE_LINE_INFO=0\n+          TRITON_DISABLE_LINE_INFO=0 python3 -m pytest language/test_line_info.py\n \n       - name: Run python tests on CUDA with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n         if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '0' && env.ENABLE_MMA_V3 == '0'}}\n         run: |\n           cd python/test/unit\n-          python3 -m pytest -n 8 --ignore=runtime\n+          python3 -m pytest -n 8 --ignore=runtime --ignore=hopper --ignore=operators --ignore=language/test_line_info.py\n           # run runtime tests serially to avoid race condition with cache handling.\n           python3 -m pytest runtime/\n+          # run test_line_info.py separately with TRITON_DISABLE_LINE_INFO=0\n+          TRITON_DISABLE_LINE_INFO=0 python3 -m pytest language/test_line_info.py\n+\n+      - name: Clear cache\n+        run: |\n+          rm -rf ~/.triton\n+\n+      - name: Run partial tests on CUDA with ENABLE_TMA=1 and ENABLE_MMA_V3=1\n+        if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '1' && env.ENABLE_MMA_V3 == '1'}}\n+        run: |\n+          cd python/test/unit\n+          python3 -m pytest -n 8 operators\n+\n+      - name: Run partial tests on CUDA with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n+        if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '0' && env.ENABLE_MMA_V3 == '0'}}\n+        run: |\n+          cd python/test/unit\n+          python3 -m pytest -n 8 operators\n \n       - name: Create artifacts archive\n         if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n         run: |\n           cd ~/.triton\n-          tar -czvf artifacts.tar.gz cache\n+          tar -czf artifacts.tar.gz cache\n \n       - name: Upload artifacts archive\n         if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n@@ -135,6 +156,7 @@ jobs:\n \n   Integration-Tests-Third-Party:\n     needs: Runner-Preparation\n+    if: false\n \n     runs-on: ${{ matrix.runner }}\n \n@@ -315,7 +337,7 @@ jobs:\n       - name: Compare artifacts\n         run: |\n           set +e\n-          python3 python/test/tools/compare_files.py --path1 reference --path2 current --kernels python/test/kernel_comparison/kernels.yml\n+          python3 python/test/tools/compare_files.py --path1 reference --path2 current\n           exit_code=$?\n           set -e\n           echo $exit_code\n@@ -329,7 +351,6 @@ jobs:\n             echo \"Error while comparing artifacts\"\n             echo \"COMPARISON_RESULT=error\" >> $GITHUB_ENV\n           fi\n-          echo \"COMPARISON_RESULT=env.COMPARISON_RESULT\"\n       - name: Check exit code and handle failure\n         if: ${{ env.COMPARISON_RESULT == 'error' }}\n         run: |"}, {"filename": "docs/meetups/08-22-2023.md", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "file_content_changes": "@@ -5,5 +5,8 @@\n \n ##### Items:\n 1. H100 updates\n-2. Linalg updates\n-3. Open discussion\n+2. Triton release plan update\n+3. Linalg updates\n+4. Intel GPU Backend status update.\n+2. Intel working on the CPU backend for Triton.\n+4. Open discussion"}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/Passes.td", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -27,7 +27,7 @@ def ConvertTritonGPUToLLVM : Pass<\"convert-triton-gpu-to-llvm\", \"mlir::ModuleOp\"\n         Option<\"computeCapability\", \"compute-capability\",\n                \"int32_t\", /*default*/\"80\",\n                \"device compute capability\">,\n-        Option<\"TmaMetadata\", \"tma-metadata\",\n+        Option<\"tmaMetadata\", \"tma-metadata\",\n                \"mlir::triton::gpu::TMAMetadataTy*\", /*default*/\"nullptr\",\n                \"tma metadata to the runtime\">,\n         Option<\"isROCM\", \"is-rocm\","}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.h", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "file_content_changes": "@@ -14,10 +14,12 @@ template <typename T> class OperationPass;\n \n namespace triton {\n \n-std::unique_ptr<OperationPass<ModuleOp>> createConvertTritonGPUToLLVMPass(\n-    int computeCapability = 80,\n-    mlir::triton::gpu::TMAMetadataTy *tmaMetadata = nullptr,\n-    bool isROCM = false);\n+#define GEN_PASS_DECL\n+#include \"triton/Conversion/TritonGPUToLLVM/Passes.h.inc\"\n+\n+std::unique_ptr<OperationPass<ModuleOp>> createConvertTritonGPUToLLVMPass();\n+std::unique_ptr<OperationPass<ModuleOp>>\n+createConvertTritonGPUToLLVMPass(const ConvertTritonGPUToLLVMOptions &options);\n \n } // namespace triton\n "}, {"filename": "include/triton/Dialect/Triton/IR/TritonTypes.td", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -14,7 +14,7 @@ class TritonTypeDef<string name, string _mnemonic>\n }\n \n // Floating-point Type\n-def TT_Float : AnyTypeOf<[F8E4M3FNUZ, F8E4M3B11FNUZ, F8E5M2, F16, BF16, F32, F64], \"floating-point\">;\n+def TT_Float : AnyTypeOf<[F8E4M3FNUZ, F8E4M3FN, F8E4M3B11FNUZ, F8E5M2, F16, BF16, F32, F64], \"floating-point\">;\n def TT_FloatTensor : TensorOf<[TT_Float]>;\n def TT_FloatLike : AnyTypeOf<[TT_Float, TT_FloatTensor]>;\n "}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -143,11 +143,11 @@ compared to 1*64 when the hasLeadingOffset is false.\n \n         // ---- begin Ampere ----\n         if (mmaEnc.isAmpere()) {\n-          int perPhase = 128 / (shapePerCTA[order[0]] * 4 / dotOpEnc.getMMAv2kWidth());\n+          int perPhase = 128 / (shapePerCTA[order[0]] * 4 / dotOpEnc.getKWidth());\n           perPhase = std::max<int>(perPhase, 1);\n-          std::vector<size_t> matShape = {8, 8, 4 * dotOpEnc.getMMAv2kWidth()};\n+          std::vector<size_t> matShape = {8, 8, 4 * dotOpEnc.getKWidth()};\n           // for now, disable swizzle when using transposed int8 tensor cores\n-          if ((32 / typeWidthInBit != dotOpEnc.getMMAv2kWidth()) && order[0] == inner)\n+          if ((32 / typeWidthInBit != dotOpEnc.getKWidth()) && order[0] == inner)\n             return get(context, 1, 1, 1, order, CTALayout);\n \n           // --- handle A operand ---\n@@ -655,7 +655,7 @@ section 9.7.13.4.1 for more details.\n     ins\n     \"unsigned\":$opIdx,\n     \"Attribute\":$parent,\n-    \"unsigned\":$MMAv2kWidth\n+    \"unsigned\":$kWidth\n   );\n \n   let builders = ["}, {"filename": "include/triton/Tools/Sys/GetEnv.hpp", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -24,7 +24,9 @@\n \n #include <algorithm>\n #include <cstdlib>\n+#include <set>\n #include <string>\n+\n namespace triton {\n \n const std::set<std::string> ENV_VARS = {"}, {"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "file_content_changes": "@@ -667,14 +667,10 @@ class SelectOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n   AxisInfo\n   getAxisInfo(OpTy op,\n               ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n-    auto resTy = op.getResult().getType().template dyn_cast<RankedTensorType>();\n-    if (!resTy)\n-      return AxisInfo();\n-    auto shape = resTy.getShape();\n-    auto rank = shape.size();\n     auto condConstancy = operands[0]->getValue().getConstancy();\n     auto lhsInfo = operands[1]->getValue();\n     auto rhsInfo = operands[2]->getValue();\n+    auto rank = lhsInfo.getRank();\n \n     AxisInfo::DimVectorT contiguity, divisibility, constancy;\n     std::optional<int64_t> constantValue;"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -576,7 +576,8 @@ struct ConvertLayoutOpConversion\n     unsigned inVec = 0;\n     unsigned outVec = 0;\n     auto paddedRepShape = getScratchConfigForCvtLayout(op, inVec, outVec);\n-    if (getElementTypeOrSelf(op.getType()).isa<mlir::Float8E4M3B11FNUZType>()) {\n+    if (getElementTypeOrSelf(op.getType())\n+            .isa<mlir::Float8E4M3B11FNUZType, mlir::Float8E4M3FNType>()) {\n       assert(inVec % 4 == 0 && \"conversion not supported for FP8E4M3B15\");\n       assert(outVec % 4 == 0 && \"conversion not supported for FP8E4M3B15\");\n     }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 38, "deletions": 26, "changes": 64, "file_content_changes": "@@ -19,7 +19,7 @@ using ::mlir::triton::gpu::SharedEncodingAttr;\n // Data loader for mma.16816 instruction.\n class MMA16816SmemLoader {\n public:\n-  MMA16816SmemLoader(int warpsPerTile, ArrayRef<uint32_t> order,\n+  MMA16816SmemLoader(int nPerWarp, int warpsPerTile, ArrayRef<uint32_t> order,\n                      ArrayRef<uint32_t> warpsPerCTA, uint32_t kOrder,\n                      int kWidth, ArrayRef<Value> smemStrides,\n                      ArrayRef<int64_t> tileShape, ArrayRef<int> instrShape,\n@@ -93,6 +93,8 @@ class MMA16816SmemLoader {\n   int inWarpMatOffset;\n   // Offset in number of matrices to increment on non-k dim across warps\n   int warpMatOffset;\n+\n+  int nPerWarp;\n };\n \n SmallVector<Value>\n@@ -131,10 +133,18 @@ MMA16816SmemLoader::computeLdmatrixMatOffs(Value warpId, Value lane,\n   // address (s0,s1) annotates.\n \n   Value matOff[2];\n-  matOff[kOrder ^ 1] = add(\n-      mul(warpId, i32_val(warpMatOffset)), // warp offset (kOrder=1)\n-      mul(nkMatArr,\n-          i32_val(inWarpMatOffset))); // matrix offset inside a warp (kOrder=1)\n+  // When B's shape(k, n) is (16, 8) and ldmatrix.x4 is used, the shared memory\n+  // access will be out of bound. In the future we should change this case to\n+  // ldmatrix.x2\n+  if (kOrder == 0 && nPerWarp == 8) {\n+    matOff[kOrder ^ 1] = mul(warpId, i32_val(warpMatOffset));\n+  } else {\n+    matOff[kOrder ^ 1] = add(\n+        mul(warpId, i32_val(warpMatOffset)), // warp offset (kOrder=1)\n+        mul(nkMatArr,\n+            i32_val(\n+                inWarpMatOffset))); // matrix offset inside a warp (kOrder=1)\n+  }\n   matOff[kOrder] = kMatArr;\n \n   // Physical offset (before swizzling)\n@@ -390,13 +400,13 @@ MMA16816SmemLoader::loadX4(int mat0, int mat1, ArrayRef<Value> ptrs, Type matTy,\n }\n \n MMA16816SmemLoader::MMA16816SmemLoader(\n-    int warpsPerTile, ArrayRef<uint32_t> order, ArrayRef<uint32_t> warpsPerCTA,\n-    uint32_t kOrder, int kWidth, ArrayRef<Value> smemStrides,\n-    ArrayRef<int64_t> tileShape, ArrayRef<int> instrShape,\n-    ArrayRef<int> matShape, int perPhase, int maxPhase, int elemBytes,\n-    ConversionPatternRewriter &rewriter,\n+    int nPerWarp, int warpsPerTile, ArrayRef<uint32_t> order,\n+    ArrayRef<uint32_t> warpsPerCTA, uint32_t kOrder, int kWidth,\n+    ArrayRef<Value> smemStrides, ArrayRef<int64_t> tileShape,\n+    ArrayRef<int> instrShape, ArrayRef<int> matShape, int perPhase,\n+    int maxPhase, int elemBytes, ConversionPatternRewriter &rewriter,\n     TritonGPUToLLVMTypeConverter *typeConverter, const Location &loc)\n-    : order(order.begin(), order.end()),\n+    : nPerWarp(nPerWarp), order(order.begin(), order.end()),\n       warpsPerCTA(warpsPerCTA.begin(), warpsPerCTA.end()), kOrder(kOrder),\n       kWidth(kWidth), tileShape(tileShape.begin(), tileShape.end()),\n       instrShape(instrShape.begin(), instrShape.end()),\n@@ -490,6 +500,7 @@ std::function<void(int, int)> getLoadMatrixFn(\n     bool isA, TritonGPUToLLVMTypeConverter *typeConverter,\n     ConversionPatternRewriter &rewriter, Location loc) {\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n+  auto shapePerCTA = getShapePerCTA(tensorTy);\n   Type eltTy = tensorTy.getElementType();\n   // We assumes that the input operand of Dot should be from shared layout.\n   // TODO(Superjomn) Consider other layouts if needed later.\n@@ -503,21 +514,24 @@ std::function<void(int, int)> getLoadMatrixFn(\n   if (tensor.getType()\n           .cast<RankedTensorType>()\n           .getElementType()\n-          .isa<mlir::Float8E4M3B11FNUZType>()) {\n+          .isa<mlir::Float8E4M3B11FNUZType, mlir::Float8E4M3FNType>()) {\n     bool noTrans = (isA ^ (order[0] == 0));\n     assert(noTrans && \"float8e4b15 must have row-col layout\");\n   }\n \n   if (kWidth != (4 / elemBytes))\n     assert(vecPhase == 1 || vecPhase == 4 * kWidth);\n \n+  int nPerWarp =\n+      std::max<int>(shapePerCTA[1] / mmaLayout.getWarpsPerCTA()[1], 8);\n+\n   // (a, b) is the coordinate.\n   auto load = [=, &rewriter, &vals](int a, int b) {\n-    MMA16816SmemLoader loader(\n-        warpsPerTile, sharedLayout.getOrder(), mmaLayout.getWarpsPerCTA(),\n-        kOrder, kWidth, smemObj.strides, tensorTy.getShape() /*tileShape*/,\n-        instrShape, matShape, perPhase, maxPhase, elemBytes, rewriter,\n-        typeConverter, loc);\n+    MMA16816SmemLoader loader(nPerWarp, warpsPerTile, sharedLayout.getOrder(),\n+                              mmaLayout.getWarpsPerCTA(), kOrder, kWidth,\n+                              smemObj.strides, shapePerCTA /*tileShape*/,\n+                              instrShape, matShape, perPhase, maxPhase,\n+                              elemBytes, rewriter, typeConverter, loc);\n     // Offset of a slice within the original tensor in shared memory\n     Value cSwizzleOffset = smemObj.getCSwizzleOffset(order[0]);\n     SmallVector<Value> offs =\n@@ -559,18 +573,16 @@ Value loadArg(ConversionPatternRewriter &rewriter, Location loc, Value tensor,\n               TritonGPUToLLVMTypeConverter *typeConverter, Value thread,\n               bool isA) {\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n+  auto shapePerCTA = getShapePerCTA(tensorTy);\n   int bitwidth = tensorTy.getElementTypeBitWidth();\n   auto mmaLayout = encoding.getParent().cast<MmaEncodingAttr>();\n \n-  SmallVector<int64_t> shape(tensorTy.getShape().begin(),\n-                             tensorTy.getShape().end());\n-\n   ValueTable vals;\n   int mmaInstrM = 16, mmaInstrN = 8, mmaInstrK = 4 * 64 / bitwidth;\n   int matShapeM = 8, matShapeN = 8, matShapeK = 2 * 64 / bitwidth;\n \n-  auto numRep = encoding.getMMAv2Rep(tensorTy.getShape(), bitwidth);\n-  int kWidth = encoding.getMMAv2kWidth();\n+  auto numRep = encoding.getMMAv2Rep(shapePerCTA, bitwidth);\n+  int kWidth = encoding.getKWidth();\n \n   auto warpsPerCTA = mmaLayout.getWarpsPerCTA();\n   auto order = triton::gpu::getOrder(mmaLayout);\n@@ -579,14 +591,14 @@ Value loadArg(ConversionPatternRewriter &rewriter, Location loc, Value tensor,\n \n   SmallVector<Value> multiDimWarpId =\n       delinearize(rewriter, loc, warp, warpsPerCTA, order);\n-  Value warpM = urem(multiDimWarpId[0], i32_val(shape[0] / 16));\n-  Value warpN = urem(multiDimWarpId[1], i32_val(shape[1] / 8));\n+  Value warpM = urem(multiDimWarpId[0], i32_val(shapePerCTA[0] / 16));\n+  Value warpN = urem(multiDimWarpId[1], i32_val(shapePerCTA[1] / 8));\n \n   int warpsPerTile;\n   if (isA)\n-    warpsPerTile = std::min<int>(warpsPerCTA[0], shape[0] / 16);\n+    warpsPerTile = std::min<int>(warpsPerCTA[0], shapePerCTA[0] / 16);\n   else\n-    warpsPerTile = std::min<int>(warpsPerCTA[1], shape[1] / 16);\n+    warpsPerTile = std::min<int>(warpsPerCTA[1], shapePerCTA[1] / 16);\n \n   std::function<void(int, int)> loadFn;\n   if (isA)"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 53, "deletions": 64, "changes": 117, "file_content_changes": "@@ -10,13 +10,11 @@ using ::mlir::triton::gpu::getTotalElemsPerThread;\n const std::string Fp16_to_Fp8E5M2 =\n     \"{                            \\n\"\n     \".reg .b32 a<2>;              \\n\"\n-    \"and.b32 a0, $1, 0x7fff7fff;  \\n\"           // a0 &= 0x7fff7fff\n-    \"and.b32 a1, $2, 0x7fff7fff;  \\n\"           // (strip sign)\n-    \"add.u32 a0, a0, 0x00800080;  \\n\"           // a0 += 0x00800080\n-    \"add.u32 a1, a1, 0x00800080;  \\n\"           // (round to nearest)\n-    \"lop3.b32 a0, $1, 0x80008000, a0, 0xea; \\n\" // a0 = a0|(0x80008000&in0)\n-    \"lop3.b32 a1, $2, 0x80008000, a1, 0xea; \\n\" // (restore sign)\n-    \"prmt.b32 $0, a0, a1, 0x7531; \\n\\t\"         // output = a1a0\n+    \"and.b32 a0, $1, 0xfffefffe;  \\n\"   // a0 &= 0xfffefffe\n+    \"and.b32 a1, $2, 0xfffefffe;  \\n\"   // (strip lowest bit)\n+    \"add.u32 a0, a0, 0x00800080;  \\n\"   // a0 += 0x00800080\n+    \"add.u32 a1, a1, 0x00800080;  \\n\"   // (round to nearest)\n+    \"prmt.b32 $0, a0, a1, 0x7531; \\n\\t\" // output = a1a0\n     \"}\";\n \n const std::string Fp8E5M2_to_Fp16 = \"{                           \\n\"\n@@ -93,32 +91,27 @@ const std::string Bf16_to_Fp8E5M2 =\n const std::string Fp8E4M3B15_to_Fp16 =\n     \"{                                      \\n\"\n     \".reg .b32 a<2>, b<2>;                  \\n\"\n-    \"prmt.b32 a0, 0, $2, 0x5040;            \\n\"\n-    \"prmt.b32 a1, 0, $2, 0x7060;            \\n\"\n-    \"lop3.b32 b0, a0, 0x7fff7fff, 0, 0xc0;  \\n\"\n-    \"lop3.b32 b1, a1, 0x7fff7fff, 0, 0xc0;  \\n\"\n+    \"prmt.b32 a0, 0, $2, 0x5746;            \\n\"\n+    \"and.b32 b0, a0, 0x7f007f00;            \\n\"\n+    \"and.b32 b1, a0, 0x00ff00ff;            \\n\"\n+    \"and.b32 a1, a0, 0x00800080;            \\n\"\n     \"shr.b32  b0, b0, 1;                    \\n\"\n-    \"shr.b32  b1, b1, 1;                    \\n\"\n+    \"add.u32 b1, b1, a1;                    \\n\"\n     \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\"\n-    \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\"\n+    \"shl.b32 $1, b1, 7;                     \\n\"\n     \"}                                      \\n\";\n \n const std::string Fp16_to_Fp8E4M3B15 =\n     \"{                                      \\n\"\n     \".reg .b32 a<2>, b<2>;                  \\n\"\n-    \".reg .b32 min_val, max_val;            \\n\"\n-    \"mov.b32 min_val, 0xBF80BF80;           \\n\"\n+    \".reg .b32 max_val;                     \\n\"\n     \"mov.b32 max_val, 0x3F803F80;           \\n\"\n-    \"max.f16x2 $1, $1, min_val;             \\n\"\n-    \"min.f16x2 $1, $1, max_val;             \\n\"\n-    \"max.f16x2 $2, $2, min_val;             \\n\"\n-    \"min.f16x2 $2, $2, max_val;             \\n\"\n-    \"shl.b32 a0, $1, 1;                     \\n\"\n-    \"shl.b32 a1, $2, 1;                     \\n\"\n-    \"lop3.b32 a0, a0, 0x7fff7fff, 0, 0xc0;  \\n\"\n-    \"lop3.b32 a1, a1, 0x7fff7fff, 0, 0xc0;  \\n\"\n-    \"add.u32 a0, a0, 0x00800080;            \\n\"\n-    \"add.u32 a1, a1, 0x00800080;            \\n\"\n+    \"and.b32 a0, $1, 0x7fff7fff;            \\n\"\n+    \"and.b32 a1, $2, 0x7fff7fff;            \\n\"\n+    \"min.f16x2 a0, a0, max_val;             \\n\"\n+    \"min.f16x2 a1, a1, max_val;             \\n\"\n+    \"mad.lo.u32 a0, a0, 2, 0x00800080;      \\n\"\n+    \"mad.lo.u32 a1, a1, 2, 0x00800080;      \\n\"\n     \"lop3.b32 b0, $1, 0x80008000, a0, 0xea; \\n\"\n     \"lop3.b32 b1, $2, 0x80008000, a1, 0xea; \\n\"\n     \"prmt.b32 $0, b0, b1, 0x7531;           \\n\"\n@@ -137,12 +130,11 @@ const std::string Fp16_to_Fp8E4M3B15 =\n const std::string Fp8E4M3B15x4_to_Fp16 =\n     \"{                                      \\n\"\n     \".reg .b32 a<2>;                        \\n\"\n-    \"shl.b32 a0, $2, 1;                     \\n\"\n+    \"add.u32 a0, $2, $2;                    \\n\"\n     \"shl.b32 a1, $2, 7;                     \\n\"\n     \"and.b32  $0, a0, 0x80008000;           \\n\"\n     \"lop3.b32 $0, $0, a1, 0x3f803f80, 0xf8; \\n\"\n-    \"and.b32  $1, $2, 0x80008000;           \\n\"\n-    \"lop3.b32 $1, $1, $2, 0x3f803f80, 0xf8; \\n\"\n+    \"and.b32  $1, $2, 0xbf80bf80;           \\n\"\n     \"}\";\n \n // Fp16 -> Fp8E4M3B15 (packed)\n@@ -159,8 +151,7 @@ const std::string Fp16_to_Fp8E4M3B15x4 =\n     \"shr.b32  a1, $1, 7;                     \\n\"\n     \"and.b32  $0,     a0, 0x40004000;        \\n\"\n     \"lop3.b32 $0, $0, a1, 0x007f007f, 0xf8;  \\n\"\n-    \"lop3.b32 $0, $0, $2, 0x80008000, 0xf8;  \\n\"\n-    \"lop3.b32 $0, $0, $2, 0x3f803f80, 0xf8;  \\n\"\n+    \"lop3.b32 $0, $0, $2, 0xbf80bf80, 0xf8;  \\n\"\n     \"}\";\n \n /* ----- FP8E4M3 ------ */\n@@ -172,53 +163,44 @@ const std::string Fp16_to_Fp8E4M3B15x4 =\n const std::string Fp8E4M3_to_Fp16 =\n     \"{                                      \\n\"\n     \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n-    \"prmt.b32 a0, 0, $2, 0x5040;            \\n\" // a0 = 0xf300f400\n-    \"prmt.b32 a1, 0, $2, 0x7060;            \\n\" // a1 = 0xf100f200\n-    \"lop3.b32 b0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // b0 = a0 & 0x7fff7fff\n-    \"lop3.b32 b1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n-    \"shr.b32  b0, b0, 1;                    \\n\" // b0 >>= 1\n-    \"shr.b32  b1, b1, 1;                    \\n\" // shift into fp16 position\n-    \"add.u32  b0, b0, 0x20002000;           \\n\" // b0.exp += 2**4-2**3\n-                                                // exponent compensate = 8\n-    \"add.u32  b1, b1, 0x20002000;           \\n\" // b1 += 8<<10 | 8<<10<<16\n-    \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n-    \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n+    \"prmt.b32 a0, 0, $2, 0x0504;            \\n\" // a0 = 0x00f300f4\n+    \"prmt.b32 a1, 0, $2, 0x0706;            \\n\" // a1 = 0x00f100f2\n+    \"and.b32  b0, a0, 0x00800080;           \\n\" // b0 = a0 & 0x00800080\n+    \"and.b32  b1, a1, 0x00800080;           \\n\" // (extract sign)\n+    \"add.u32  b0, b0, a0;                   \\n\" // b0 = b0 + a0\n+    \"add.u32  b1, b1, a1;                   \\n\" // (move sign to the left)\n+    \"mad.lo.u32 $0, b0, 128, 0x20002000;    \\n\" // out0 = (b0 << 7) + 0x20002000\n+    \"mad.lo.u32 $1, b1, 128, 0x20002000;    \\n\" // (shift into position and bias\n+                                                // exponent)\n     \"}\";\n \n // Fp16 -> Fp8E4M3 (packed)\n const std::string Fp16_to_Fp8E4M3 =\n     \"{                                      \\n\"\n     \".reg .b32 a<2>, b<2>;                  \\n\" // see Fp8E4M3x4ToFp16x4\n-    \"sub.u32 a0, $1, 0x20002000;            \\n\" // a0 = input0 - 0x20002000\n-                                                // (compensate offset)\n-    \"sub.u32 a1, $2, 0x20002000;            \\n\" // a1 = input1 - 0x20002000\n-                                                // (8 << 10 | 8 << 10 << 16)\n-    \"shl.b32 a0, a0, 1;                     \\n\" // a0 <<= 1\n-    \"shl.b32 a1, a1, 1;                     \\n\" // shift into fp8e4 position\n-    \"lop3.b32 a0, a0, 0x7fff7fff, 0, 0xc0;  \\n\" // a0 &= 0x7fff7fff\n-    \"lop3.b32 a1, a1, 0x7fff7fff, 0, 0xc0;  \\n\" // (strip sign)\n-    \"add.u32 a0, a0, 0x00800080;            \\n\" // a0 += 0x00800080\n-    \"add.u32 a1, a1, 0x00800080;            \\n\" // (round to nearest)\n-    \"lop3.b32 b0, $1, 0x80008000, a0, 0xea; \\n\" // b0 = a0|(0x80008000&in0)\n-    \"lop3.b32 b1, $2, 0x80008000, a1, 0xea; \\n\" // (restore sign)\n+    \"and.b32 a0, $1, 0x7fff7fff;            \\n\" // a0 = input0 & 0x7fff7fff\n+    \"and.b32 a1, $2, 0x7fff7fff;            \\n\" // (strip sign)\n+    \"mad.lo.u32 a0, a0, 2, 0x40804080;      \\n\" // shift exponent (<< 1),\n+    \"mad.lo.u32 a1, a1, 2, 0x40804080;      \\n\" // correct bias (0x40004000),\n+                                                // and round to nearest\n+    \"lop3.b32 b0, $1, 0x80008000, a0, 0xe2; \\n\" // b0 = 0x80008000 ? in0 : a0\n+    \"lop3.b32 b1, $2, 0x80008000, a1, 0xe2; \\n\" // (restore sign)\n     \"prmt.b32 $0, b0, b1, 0x7531;           \\n\" // output = b1b0\n     \"}\";\n \n // WARN: subnormal (0bs0000xxx) are not handled\n const std::string Fp8E4M3_to_Bf16 =\n     \"{                                      \\n\"\n     \".reg .b32 a<2>, b<2>;                  \\n\" // if input = 0xf1f2f3f4\n-    \"prmt.b32 a0, 0, $2, 0x5040;            \\n\" // a0 = 0xf300f400\n-    \"prmt.b32 a1, 0, $2, 0x7060;            \\n\" // a1 = 0xf100f200\n-    \"and.b32 b0, a0, 0x7fff7fff;            \\n\" // b0 = a0 & 0x7fff7fff\n-    \"and.b32 b1, a1, 0x7fff7fff;            \\n\" // (strip sign)\n-    \"shr.b32 b0, b0, 4;                     \\n\" // b0 >>= 4\n-    \"shr.b32 b1, b1, 4;                     \\n\" // shift into fp16 position\n-    \"add.u32 b0, b0, 0x3c003c00;            \\n\" // b0.exp += 2**7-2**3\n-                                                // exponent compensate = 120\n-    \"add.u32 b1, b1, 0x3c003c00;            \\n\" // b1 += 120<<7 | 120<<7<<16\n-    \"lop3.b32 $0, b0, 0x80008000, a0, 0xf8; \\n\" // out0 = b0|(0x80008000&a0)\n-    \"lop3.b32 $1, b1, 0x80008000, a1, 0xf8; \\n\" // (restore sign)\n+    \"prmt.b32 a0, 0, $2, 0x0504;            \\n\" // a0 = 0x00f300f4\n+    \"prmt.b32 a1, 0, $2, 0x0706;            \\n\" // a1 = 0x00f100f2\n+    \"and.b32  b0, a0, 0x00800080;           \\n\" // b0 = a0 & 0x00800080\n+    \"and.b32  b1, a1, 0x00800080;           \\n\" // (extract sign)\n+    \"mad.lo.u32 b0, b0, 15, a0;             \\n\" // b0 = b0 * 15 + a0\n+    \"mad.lo.u32 b1, b1, 15, a1;             \\n\" // (move sign to the left)\n+    \"mad.lo.u32 $0, b0, 16, 0x3c003c00;     \\n\" // out0 = (b0 << 4) + 0x3c003c00\n+    \"mad.lo.u32 $1, b1, 16, 0x3c003c00;     \\n\" // (shift into position and bias\n+                                                // exponent)\n     \"}\";\n \n const std::string Bf16_to_Fp8E4M3 =\n@@ -627,17 +609,20 @@ struct FpToFpOpConversion\n     auto F8E4M3B15TyID = TypeID::get<mlir::Float8E4M3B11FNUZType>();\n     auto F8E4M3TyID = TypeID::get<mlir::Float8E4M3FNUZType>();\n     auto F8E5M2TyID = TypeID::get<mlir::Float8E5M2Type>();\n+    auto F8E4M3FNTyID = TypeID::get<mlir::Float8E4M3FNType>();\n     auto F16TyID = TypeID::get<mlir::Float16Type>();\n     auto BF16TyID = TypeID::get<mlir::BFloat16Type>();\n     auto F32TyID = TypeID::get<mlir::Float32Type>();\n     auto F64TyID = TypeID::get<mlir::Float64Type>();\n     static DenseMap<std::pair<TypeID, TypeID>, std::string> srcMap = {\n         // F8 -> F16\n         {{F8E4M3B15TyID, F16TyID}, Fp8E4M3B15_to_Fp16},\n+        {{F8E4M3FNTyID, F16TyID}, Fp8E4M3B15x4_to_Fp16},\n         {{F8E4M3TyID, F16TyID}, Fp8E4M3_to_Fp16},\n         {{F8E5M2TyID, F16TyID}, Fp8E5M2_to_Fp16},\n         // F16 -> F8\n         {{F16TyID, F8E4M3B15TyID}, Fp16_to_Fp8E4M3B15},\n+        {{F16TyID, F8E4M3FNTyID}, Fp16_to_Fp8E4M3B15x4},\n         {{F16TyID, F8E4M3TyID}, Fp16_to_Fp8E4M3},\n         {{F16TyID, F8E5M2TyID}, Fp16_to_Fp8E5M2},\n         // F8 -> BF16\n@@ -1181,7 +1166,11 @@ void populateElementwiseOpToLLVMPatterns(\n   POPULATE_BINARY_OP(arith::ShRSIOp, LLVM::AShrOp)  // >>\n   POPULATE_BINARY_OP(arith::ShRUIOp, LLVM::LShrOp)  // >>\n   POPULATE_BINARY_OP(arith::MinFOp, LLVM::MinNumOp) // fmin\n+  POPULATE_BINARY_OP(arith::MaxFOp, LLVM::MaxNumOp) // fmax\n   POPULATE_BINARY_OP(arith::MinSIOp, LLVM::SMinOp)  // smin\n+  POPULATE_BINARY_OP(arith::MaxSIOp, LLVM::SMaxOp)  // smax\n+  POPULATE_BINARY_OP(arith::MinUIOp, LLVM::UMinOp)  // umin\n+  POPULATE_BINARY_OP(arith::MaxUIOp, LLVM::UMaxOp)  // umax\n #undef POPULATE_BINARY_OP\n \n #define POPULATE_UNARY_OP(SRC_OP, DST_OP)                                      \\"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 8, "deletions": 11, "changes": 19, "file_content_changes": "@@ -321,17 +321,14 @@ struct ReduceOpConversion\n       return NVVM::ReduxKind::OR;\n     if (isa<arith::XOrIOp>(reduceOp))\n       return NVVM::ReduxKind::XOR;\n-    if (auto externalCall =\n-            dyn_cast<triton::PureExternElementwiseOp>(reduceOp)) {\n-      if (externalCall.getSymbol() == \"__nv_min\")\n-        return NVVM::ReduxKind::MIN;\n-      if (externalCall.getSymbol() == \"__nv_umin\")\n-        return NVVM::ReduxKind::UMIN;\n-      if (externalCall.getSymbol() == \"__nv_max\")\n-        return NVVM::ReduxKind::MAX;\n-      if (externalCall.getSymbol() == \"__nv_umax\")\n-        return NVVM::ReduxKind::UMAX;\n-    }\n+    if (isa<arith::MinSIOp>(reduceOp))\n+      return NVVM::ReduxKind::MIN;\n+    if (isa<arith::MinUIOp>(reduceOp))\n+      return NVVM::ReduxKind::UMIN;\n+    if (isa<arith::MaxSIOp>(reduceOp))\n+      return NVVM::ReduxKind::MAX;\n+    if (isa<arith::MaxUIOp>(reduceOp))\n+      return NVVM::ReduxKind::UMAX;\n     return std::nullopt;\n   }\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "file_content_changes": "@@ -569,6 +569,28 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n         mask = and_(mask, icmp_slt(mul(threadDim, i32_val(sizePerThread[dim])),\n                                    i32_val(shape[dim])));\n       }\n+      // Do not write duplicated data when multicast is enabled\n+      if (triton::gpu::getNumCTAs(layout) > 1) {\n+        auto _0 = i32_val(0);\n+        auto CTAsPerCGA = triton::gpu::getCTAsPerCGA(layout);\n+        auto CTASplitNum = triton::gpu::getCTASplitNum(layout);\n+        auto CTAOrder = triton::gpu::getCTAOrder(layout);\n+\n+        auto clusterCTAId = getClusterCTAId(rewriter, loc);\n+        auto multiDimClusterCTAId =\n+            delinearize(rewriter, loc, clusterCTAId, CTAsPerCGA, CTAOrder);\n+\n+        for (unsigned dim = 0; dim < rank; ++dim) {\n+          // Skip when multicast is not enabled in this dimension\n+          if (CTAsPerCGA[dim] == CTASplitNum[dim])\n+            continue;\n+          // This wrapping rule must be consistent with emitCTAOffsetForLayout\n+          unsigned splitNum = std::min<unsigned>(shape[dim], CTASplitNum[dim]);\n+          multiDimClusterCTAId[dim] =\n+              urem(multiDimClusterCTAId[dim], i32_val(splitNum));\n+          mask = and_(mask, icmp_eq(multiDimClusterCTAId[dim], _0));\n+        }\n+      }\n     } else {\n       // If the tensor is not ranked, then it is a scalar and only thread 0 can\n       // write"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 18, "deletions": 22, "changes": 40, "file_content_changes": "@@ -40,13 +40,17 @@\n \n #include \"mlir/Dialect/ControlFlow/IR/ControlFlowOps.h\"\n \n+namespace mlir {\n+namespace triton {\n+#define GEN_PASS_DEF_CONVERTTRITONGPUTOLLVM\n+#include \"triton/Conversion/TritonGPUToLLVM/Passes.h.inc\"\n+} // namespace triton\n+} // namespace mlir\n+\n using namespace mlir;\n using namespace mlir::triton;\n namespace ttng = mlir::triton::nvidia_gpu;\n \n-#define GEN_PASS_CLASSES\n-#include \"triton/Conversion/TritonGPUToLLVM/Passes.h.inc\"\n-\n namespace {\n \n // pass ws related named attrs.\n@@ -372,15 +376,10 @@ class TritonLLVMConversionTarget : public ConversionTarget {\n   }\n };\n \n-class ConvertTritonGPUToLLVM\n-    : public ConvertTritonGPUToLLVMBase<ConvertTritonGPUToLLVM> {\n-\n-public:\n-  explicit ConvertTritonGPUToLLVM(int computeCapability,\n-                                  mlir::triton::gpu::TMAMetadataTy *tmaMetadata,\n-                                  bool isROCM)\n-      : computeCapability(computeCapability), tmaMetadata(tmaMetadata),\n-        isROCM(isROCM) {}\n+struct ConvertTritonGPUToLLVM\n+    : public triton::impl::ConvertTritonGPUToLLVMBase<ConvertTritonGPUToLLVM> {\n+  using ConvertTritonGPUToLLVMBase<\n+      ConvertTritonGPUToLLVM>::ConvertTritonGPUToLLVMBase;\n \n   void runOnOperation() override {\n     MLIRContext *context = &getContext();\n@@ -569,10 +568,6 @@ class ConvertTritonGPUToLLVM\n            CacheKeyDenseMapInfo>\n       indexCache;\n \n-  int computeCapability{};\n-  bool isROCM{};\n-  mlir::triton::gpu::TMAMetadataTy *tmaMetadata;\n-\n   void initSharedMemory(ModuleAllocation &allocation,\n                         TritonGPUToLLVMTypeConverter &typeConverter) {\n     ModuleOp mod = getOperation();\n@@ -610,7 +605,8 @@ class ConvertTritonGPUToLLVM\n   void decomposeFp8e4b15Convert(ModuleOp mod) const {\n     mod.walk([&](triton::gpu::ConvertLayoutOp cvtOp) -> void {\n       OpBuilder builder(cvtOp);\n-      if (!getElementTypeOrSelf(cvtOp).isa<mlir::Float8E4M3B11FNUZType>())\n+      if (!getElementTypeOrSelf(cvtOp)\n+               .isa<mlir::Float8E4M3B11FNUZType, mlir::Float8E4M3FNType>())\n         return;\n       auto shape = cvtOp.getType().cast<RankedTensorType>().getShape();\n       auto argEncoding =\n@@ -861,12 +857,12 @@ class ConvertTritonGPUToLLVM\n namespace mlir {\n namespace triton {\n \n+std::unique_ptr<OperationPass<ModuleOp>> createConvertTritonGPUToLLVMPass() {\n+  return std::make_unique<ConvertTritonGPUToLLVM>();\n+}\n std::unique_ptr<OperationPass<ModuleOp>>\n-createConvertTritonGPUToLLVMPass(int computeCapability,\n-                                 mlir::triton::gpu::TMAMetadataTy *tmaMetadata,\n-                                 bool isROCM) {\n-  return std::make_unique<::ConvertTritonGPUToLLVM>(computeCapability,\n-                                                    tmaMetadata, isROCM);\n+createConvertTritonGPUToLLVMPass(const ConvertTritonGPUToLLVMOptions &options) {\n+  return std::make_unique<ConvertTritonGPUToLLVM>(options);\n }\n \n } // namespace triton"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -27,6 +27,9 @@ TritonGPUToLLVMTypeConverter::TritonGPUToLLVMTypeConverter(\n   addConversion([&](mlir::Float8E4M3B11FNUZType type) -> std::optional<Type> {\n     return IntegerType::get(type.getContext(), 8);\n   });\n+  addConversion([&](mlir::Float8E4M3FNType type) -> std::optional<Type> {\n+    return IntegerType::get(type.getContext(), 8);\n+  });\n   addConversion([&](mlir::Float8E4M3FNUZType type) -> std::optional<Type> {\n     return IntegerType::get(type.getContext(), 8);\n   });"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 11, "deletions": 8, "changes": 19, "file_content_changes": "@@ -849,11 +849,13 @@ DotOperandEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape,\n \n unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n                                                         Type eltTy) const {\n+  auto shapePerCTA = getShapePerCTA(*this, shape);\n   if (auto mmaParent = getParent().dyn_cast<MmaEncodingAttr>()) {\n     int warpsPerCTAM = mmaParent.getWarpsPerCTA()[0];\n     int warpsPerCTAN = mmaParent.getWarpsPerCTA()[1];\n+    // A100\n     if (mmaParent.isAmpere()) {\n-      auto rep = getMMAv2Rep(shape, eltTy.getIntOrFloatBitWidth());\n+      auto rep = getMMAv2Rep(shapePerCTA, eltTy.getIntOrFloatBitWidth());\n       if (getOpIdx() == 0)\n         return 4 * rep[0] * rep[1];\n       if (getOpIdx() == 1)\n@@ -925,8 +927,8 @@ unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n     auto order = blockedLayout.getOrder();\n     auto sizePerThread = getSizePerThread(blockedLayout);\n \n-    int K = getOpIdx() == 0 ? shape[1] : shape[0];\n-    int otherDim = getOpIdx() == 1 ? shape[1] : shape[0];\n+    int K = getOpIdx() == 0 ? shapePerCTA[1] : shapePerCTA[0];\n+    int otherDim = getOpIdx() == 1 ? shapePerCTA[1] : shapePerCTA[0];\n \n     bool isM = getOpIdx() == 0;\n \n@@ -1256,7 +1258,7 @@ void DotOperandEncodingAttr::print(mlir::AsmPrinter &printer) const {\n   printer << \"<{\"\n           << \"opIdx = \" << getOpIdx() << \", parent = \" << getParent();\n   if (mmaParent && mmaParent.isAmpere())\n-    printer << \", kWidth = \" << getMMAv2kWidth();\n+    printer << \", kWidth = \" << getKWidth();\n   printer << \"}>\";\n }\n \n@@ -1460,9 +1462,10 @@ struct TritonGPUInferLayoutInterface\n     return success();\n   }\n \n-  LogicalResult inferDotOpEncoding(Attribute operandEncoding, unsigned opIdx,\n-                                   Attribute retEncoding,\n-                                   Optional<Location> location) const override {\n+  LogicalResult\n+  inferDotOpEncoding(Attribute operandEncoding, unsigned opIdx,\n+                     Attribute retEncoding,\n+                     std::optional<Location> location) const override {\n     auto mmaRetEncoding = retEncoding.dyn_cast<MmaEncodingAttr>();\n     if (mmaRetEncoding && mmaRetEncoding.isHopper()) {\n       // TODO: support gmma when A/B does not reside in shared memory\n@@ -1493,7 +1496,7 @@ struct TritonGPUInferLayoutInterface\n     // Verify that the encodings are valid.\n     if (!aEncoding || !bEncoding)\n       return op->emitError(\"mismatching encoding between A and B operands\");\n-    if (aEncoding.getMMAv2kWidth() != bEncoding.getMMAv2kWidth())\n+    if (aEncoding.getKWidth() != bEncoding.getKWidth())\n       return op->emitError(\"mismatching kWidth between A and B operands\");\n     return success();\n   }"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -203,8 +203,8 @@ LogicalResult Prefetcher::initialize() {\n     auto bType = dot.getB().getType().cast<RankedTensorType>();\n     auto aEnc = aType.getEncoding().cast<triton::gpu::DotOperandEncodingAttr>();\n     auto bEnc = bType.getEncoding().cast<triton::gpu::DotOperandEncodingAttr>();\n-    int aKWidth = aEnc.getMMAv2kWidth();\n-    int bKWidth = bEnc.getMMAv2kWidth();\n+    int aKWidth = aEnc.getKWidth();\n+    int bKWidth = bEnc.getKWidth();\n     assert(aKWidth == bKWidth);\n \n     auto kSize = aType.getShape()[1];"}, {"filename": "lib/Dialect/TritonNvidiaGPU/Transforms/PlanCTA.cpp", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "file_content_changes": "@@ -325,8 +325,18 @@ bool CTAPlanner::processReduce(triton::FuncOp &funcOp) {\n       }\n     }\n \n+    llvm::SmallVector<unsigned> CTASplitNum = CTAsPerCGA;\n+\n+    // If numCTAs > 1 and the only dimension is the reduced dimension, after the\n+    // above two for-loops, CTAsPerCGA = [0] and remainingCTAs = numCTAs. We set\n+    // CTAsPerCGA[0] = numCTAs and keep CTASplitNum[0] = 1 to ensure that no\n+    // cross-CTA reduction is required, although this will introduce duplicated\n+    // calculation\n+    if (remainingCTAs > 0)\n+      CTAsPerCGA[order[rank - 1]] *= remainingCTAs;\n+\n     auto CTALayout =\n-        ttg::CTALayoutAttr::get(context, CTAsPerCGA, CTAsPerCGA, CTAOrder);\n+        ttg::CTALayoutAttr::get(context, CTAsPerCGA, CTASplitNum, CTAOrder);\n     if (!tiled)\n       setTiling(CTALayout.getCTAsPerCGA());\n     auto newSrcLayout = replaceCTALayout(srcLayout, srcShape, CTALayout);"}, {"filename": "lib/Dialect/TritonNvidiaGPU/Transforms/WSMaterialization.cpp", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -30,6 +30,8 @@\n #include \"triton/Dialect/TritonNvidiaGPU/IR/Dialect.h\"\n #include \"triton/Dialect/TritonNvidiaGPU/Transforms/Utility.h\"\n \n+#include <set>\n+\n using namespace mlir;\n namespace ttg = triton::gpu;\n namespace ttng = triton::nvidia_gpu;"}, {"filename": "lib/Target/LLVMIR/LLVMIRTranslation.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -351,7 +351,7 @@ translateTritonGPUToLLVMIR(llvm::LLVMContext *llvmContext,\n   pm.addPass(mlir::createConvertSCFToCFPass());\n   pm.addPass(mlir::createConvertIndexToLLVMPass());\n   pm.addPass(\n-      createConvertTritonGPUToLLVMPass(computeCapability, &tmaInfos, isROCM));\n+      createConvertTritonGPUToLLVMPass({computeCapability, &tmaInfos, isROCM}));\n   pm.addPass(createConvertNVGPUToLLVMPass());\n   pm.addPass(mlir::createArithToLLVMConversionPass());\n   pm.addPass(mlir::createCanonicalizerPass());"}, {"filename": "python/setup.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -335,6 +335,7 @@ def build_extension(self, ext):\n             \"matplotlib\",\n             \"pandas\",\n             \"tabulate\",\n+            \"torch\",\n         ],\n     },\n )"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 36, "deletions": 0, "changes": 36, "file_content_changes": "@@ -765,6 +765,12 @@ void init_triton_ir(py::module &&m) {\n              // have a float-like type compatible with float only native ops\n              return self.getBuilder().getType<mlir::Float8E4M3B11FNUZType>();\n            })\n+      .def(\"get_fp8e4b15x4_ty\",\n+           [](TritonOpBuilder &self) -> mlir::Type {\n+             // TODO: upstream FP8E4B15 into MLIR, or find a way to externally\n+             // have a float-like type compatible with float only native ops\n+             return self.getBuilder().getType<mlir::Float8E4M3FNType>();\n+           })\n       .def(\"get_fp8e5_ty\",\n            [](TritonOpBuilder &self) -> mlir::Type {\n              return self.getBuilder().getType<mlir::Float8E5M2Type>();\n@@ -1066,6 +1072,36 @@ void init_triton_ir(py::module &&m) {\n               mlir::Value &rhs) -> mlir::Value {\n              return mlir::Value(self.create<mlir::arith::ShRSIOp>(lhs, rhs));\n            })\n+      .def(\"create_minsi\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MinSIOp>(lhs, rhs));\n+           })\n+      .def(\"create_minui\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MinUIOp>(lhs, rhs));\n+           })\n+      .def(\"create_minf\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MinFOp>(lhs, rhs));\n+           })\n+      .def(\"create_maxsi\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MaxSIOp>(lhs, rhs));\n+           })\n+      .def(\"create_maxui\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MaxUIOp>(lhs, rhs));\n+           })\n+      .def(\"create_maxf\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MaxFOp>(lhs, rhs));\n+           })\n       // AddPtr (similar to GEP)\n       .def(\"create_addptr\",\n            [](TritonOpBuilder &self, mlir::Value &ptr,"}, {"filename": "python/test/kernel_comparison/kernels.yml", "status": "modified", "additions": 14, "deletions": 12, "changes": 26, "file_content_changes": "@@ -1,31 +1,33 @@\n name_and_extension:\n-  - name: _kernel_0d1d2d34567c89c1011c\n+  - name: _kernel_0d1d2d3de4de5de6c7de8de9c10de11c\n     extension: ptx\n-  - name: _kernel_0d1d2d3d4d5d6d7c8d9c10d11c\n+  - name: _kernel_0d1d2d3de4de5de6de7c8de9c10de11c\n     extension: ptx\n-  - name: _kernel_0d1d2d3d4d5d6d7c8c9d10d11c\n+  - name: _kernel_0d1d2d345de6c789c1011c\n     extension: ptx\n   - name: _kernel_0d1d2d3456c789c1011c\n     extension: ptx\n-  - name: _kernel_0d1d2d345d6d7c8c9d1011c\n+  - name: _kernel_0d1d2d3de4de5de6c7de8c9de10de11c\n     extension: ptx\n   - name: _kernel_0d1d2d34567c8c91011c\n     extension: ptx\n   - name: _kernel_0d1d2d3456c78c91011c\n     extension: ptx\n-  - name: _kernel_0d1d2d345d6c78c9d1011c\n+  - name: _kernel_0d1d2d3de4de5de6de7c8c9de10de11c\n+    extension: ptx\n+  - name: _kernel_0d1d2d34567c89c1011c\n     extension: ptx\n-  - name: _kernel_0d1d2d345d6c789c1011c\n+  - name: _kernel_0d1d2d345de6de7c89c1011c\n     extension: ptx\n-  - name: _kernel_0d1d2d3d4d5d6c7d8d9c10d11c\n+  - name: _kernel_0d1d2d345de6de7c8c9de1011c\n     extension: ptx\n-  - name: _kernel_0d1d2d3d4d5d6c7d8c9d10d11c\n+  - name: kernel_0d1d2de\n     extension: ptx\n-  - name: _kernel_0d1d2d345d6d7c89c1011c\n+  - name: _kernel_0d1d2d345de6c78c9de1011c\n     extension: ptx\n-  - name: _bwd_kernel_0d1d2d34d5d6d7d8d9d10d11d12d13d14d15d16c17d18d19d20c21d22d23d24c2526d27d\n+  - name: _bwd_kernel_0d1d2d34d5d6d7d8d9d10d11de12de13de14de15c16de17de18de19c20de21de22de23c2425de26de\n     extension: ptx\n-  - name: _fwd_kernel_0d1d2d34d5d6d7d8d9d10c11d12d13d14c15d16d17d18c19d20d21d22c2324d25d\n+  - name: _fwd_kernel_0d1d2d34d5d6de7de8de9c10de11de12de13c14de15de16de17c18de19de20de21c2223de24de\n     extension: ptx\n-  - name: _bwd_preprocess_0d1d2d3d4d\n+  - name: _bwd_preprocess_0d1d2d\n     extension: ptx"}, {"filename": "python/test/tools/compare_files.py", "status": "modified", "additions": 11, "deletions": 24, "changes": 35, "file_content_changes": "@@ -9,9 +9,8 @@\n \n \n class ComparisonResult:\n-    def __init__(self, name: str, extension: str, numComparisons: int, diffs: List[str] = None, errors: List[str] = None):\n+    def __init__(self, name: str, numComparisons: int, diffs: List[str] = None, errors: List[str] = None):\n         self.name = name\n-        self.extension = extension\n         self.numComparisons = numComparisons\n         self.diffs = [] if diffs is None else diffs\n         self.errors = [] if errors is None else errors\n@@ -20,7 +19,7 @@ def isSuccess(self) -> bool:\n         return len(self.diffs) == 0 and len(self.errors) == 0\n \n     def __str__(self) -> str:\n-        return f\"name={self.name}, extension={self.extension}, numComparisons={self.numComparisons}, success={self.isSuccess()}\"\n+        return f\"name={self.name}, numComparisons={self.numComparisons}, success={self.isSuccess()}\"\n \n \n def listFilesWithExtension(path: str, extension: str) -> List[str]:\n@@ -143,9 +142,9 @@ def doFilesMatch(path1: str, path2: str) -> bool:\n     return True\n \n \n-def compareMatchingFiles(name: str, extension: str, nameToHashes1: Dict[str, List[str]], nameToHashes2: Dict[str, List[str]], args) -> ComparisonResult:\n+def compareMatchingFiles(name: str, nameToHashes1: Dict[str, List[str]], nameToHashes2: Dict[str, List[str]], args) -> ComparisonResult:\n     \"\"\"\n-        Compare files with the given name/extension in all hashes in both paths\n+        Compare files with the given name in all hashes in both paths\n         Return the first mismatching files as a tuple (file1, file2), otherwise, return an empty tuple\n     \"\"\"\n     hashes1 = nameToHashes1.get(name, [])\n@@ -164,14 +163,14 @@ def compareMatchingFiles(name: str, extension: str, nameToHashes1: Dict[str, Lis\n             if not doFilesMatch(path1, path2):\n                 continue\n             numComparisons += 1\n-            extFile1 = listFilesWithExtension(path1, extension)[0]\n-            extFile2 = listFilesWithExtension(path2, extension)[0]\n+            extFile1 = listFilesWithExtension(path1, \"ptx\")[0]\n+            extFile2 = listFilesWithExtension(path2, \"ptx\")[0]\n             diff = diffFiles(extFile1, extFile2)\n             if len(diff) > 0:\n                 diffs.append(diffFiles(extFile2, extFile1))\n     if numComparisons == 0:\n         errors.append(f\"Did not find any matching files for {name}\")\n-    return ComparisonResult(name=name, extension=extension, numComparisons=numComparisons, diffs=diffs, errors=errors)\n+    return ComparisonResult(name=name, numComparisons=numComparisons, diffs=diffs, errors=errors)\n \n \n def dumpResults(results: List[ComparisonResult], fileName: str):\n@@ -203,20 +202,15 @@ def main(args) -> bool:\n     nameToHashes1 = getNameToHashesDict(args.path1)\n     nameToHashes2 = getNameToHashesDict(args.path2)\n \n-    yamlFilePath = args.kernels\n-    if not os.path.exists(yamlFilePath):\n-        print(f\"Path {yamlFilePath} does not exist!\")\n-        sys.exit(2)\n-    nameAndExtension = loadYamlFile(yamlFilePath)[\"name_and_extension\"]\n+    # Get all kernels that need to be checked\n+    kernelNames = set(nameToHashes1.keys()).union(set(nameToHashes2.keys()))\n \n     results = []\n     # iterate over the kernels that need to be checked\n-    for d in nameAndExtension:\n-        name = d[\"name\"]  # kernel name\n-        extension = d[\"extension\"]  # extension of the file to be compared (e.g. ptx)\n+    for name in kernelNames:\n         # Compare all hashes on path 1 with all hashes on path 2\n         # result is either the mismatching (file1, file2) with \"extension\" or empty tuple if no mismatch\n-        result = compareMatchingFiles(name, extension, nameToHashes1, nameToHashes2, args)\n+        result = compareMatchingFiles(name, nameToHashes1, nameToHashes2, args)\n         print(result)\n         # Otherwise, add it to the mismatches\n         results.append(result)\n@@ -250,12 +244,5 @@ def main(args) -> bool:\n         required=True,\n         help=(\"Path to second cache directory\"),\n     )\n-    parser.add_argument(\n-        \"--kernels\",\n-        type=str,\n-        default=None,\n-        required=True,\n-        help=(\"Path to kernels yaml file\"),\n-    )\n     args = parser.parse_args()\n     main(args)"}, {"filename": "python/test/unit/hopper/test_persistent_warp_specialized_gemm.py", "status": "modified", "additions": 13, "deletions": 28, "changes": 41, "file_content_changes": "@@ -302,20 +302,7 @@ def test_non_persistent_warp_specialized_gemm(M, N, K, BLOCK_M, BLOCK_N, BLOCK_K\n     th_c = torch.matmul(a, b)\n     torch.testing.assert_allclose(th_c, c, atol=1e-2, rtol=0)\n \n-    # # #############################################Performance Evaluation#############################################\n-    # fn = lambda: call_vintage()\n-    # ms = triton.testing.do_bench(fn, warmup=25, rep=100)\n-    # cur_gpu_perf = round(2. * M * N * K / ms * 1e-9, 2)\n-    # print(' '.join(['Performance of', str(M), str(N), str(K), ':', str(ms), 'ms, ', str(cur_gpu_perf), 'TFLOPS']))\n-\n-\n-@triton.autotune(\n-    configs=[\n-        triton.Config({}, num_stages=3, num_warps=4, enable_warp_specialization=True),\n-        # triton.Config({}, num_stages=3, num_warps=4, enable_warp_specialization=False),\n-    ],\n-    key=['M', 'N', 'K'],\n-)\n+\n @triton.jit\n def static_persistent_warp_specialized_matmul_kernel(\n     a_ptr, b_ptr, c_ptr,\n@@ -355,13 +342,6 @@ def static_persistent_warp_specialized_matmul_kernel(\n         tl.store(c_ptrs, accumulator)\n \n \n-@triton.autotune(\n-    configs=[\n-        triton.Config({}, num_stages=3, num_warps=4, enable_warp_specialization=True),\n-        # triton.Config({}, num_stages=3, num_warps=4, enable_warp_specialization=False),\n-    ],\n-    key=['M', 'N', 'K'],\n-)\n @triton.jit\n def static_persistent_tma_warp_specialized_matmul_kernel(\n     a_ptr, b_ptr, c_ptr,\n@@ -429,6 +409,12 @@ def static_persistent_tma_warp_specialized_matmul_kernel(\n                              [4096, 4096, 256, 256, 128, 64, 1, False, True],\n                              [4096, 4096, 256, 128, 256, 16, 1, False, True],\n                              [4096, 4096, 256, 128, 256, 64, 1, False, True],\n+                             # numCTAs > 1\n+                             [2048, 2048, 64, 128, 128, 64, 2, False, True],\n+                             [2048, 2048, 128, 256, 128, 64, 4, False, True],\n+                             [4096, 4096, 128, 256, 128, 64, 4, False, True],\n+                             [4096, 4096, 256, 128, 256, 64, 4, False, True],\n+                             [4096, 4096, 256, 256, 256, 64, 4, False, True],\n                          ]\n                              for use_tma in [False, True]\n                          ])\n@@ -455,23 +441,22 @@ def test_user_defined_persistent_warp_specialized_gemm(M, N, K, BLOCK_M, BLOCK_N\n             a.stride(0), a.stride(1),\n             b.stride(0), b.stride(1),\n             c.stride(0), c.stride(1),\n-            BLOCK_M, BLOCK_N, BLOCK_K, num_SMs)\n+            BLOCK_M, BLOCK_N, BLOCK_K, num_SMs,\n+            num_warps=4, num_ctas=NUM_CTAS,\n+            enable_warp_specialization=True)\n     else:\n         static_persistent_warp_specialized_matmul_kernel[grid](\n             a, b, c,\n             M, N, K,\n             a.stride(0), a.stride(1),\n             b.stride(0), b.stride(1),\n             c.stride(0), c.stride(1),\n-            BLOCK_M, BLOCK_N, BLOCK_K, num_SMs)\n+            BLOCK_M, BLOCK_N, BLOCK_K, num_SMs,\n+            num_warps=4, num_ctas=NUM_CTAS,\n+            enable_warp_specialization=True)\n \n     th_c = torch.matmul(a, b)\n     torch.testing.assert_allclose(th_c, c, atol=1e-2, rtol=0)\n-    # #############################################Performance Evaluation#############################################\n-    # fn = lambda: call_stylish()\n-    # ms = triton.testing.do_bench(fn, warmup=25, rep=100)\n-    # cur_gpu_perf = round(2. * M * N * K / ms * 1e-9, 2)\n-    # print(' '.join(['Performance of', str(M), str(N), str(K), ':', str(ms), 'ms, ', str(cur_gpu_perf), 'TFLOPS']))\n \n \n @triton.jit"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 49, "deletions": 30, "changes": 79, "file_content_changes": "@@ -352,6 +352,29 @@ def test_bin_op(dtype_x, dtype_y, op, num_ctas, device):\n             num_ctas=num_ctas)\n \n \n+@pytest.mark.parametrize(\"dtype, order\", [(dtype, order) for dtype in dtypes_with_bfloat16 for order in [0, 1]])\n+def test_addptr(dtype, order, device):\n+    check_type_supported(dtype, device)\n+\n+    @triton.jit\n+    def kernel(x, y, ORDER: tl.constexpr, SIZE: tl.constexpr):\n+        offs = tl.arange(0, SIZE)\n+        if ORDER == 0:\n+            tl.store(y + offs, tl.load(x + offs))\n+        else:\n+            tl.store(offs + y, tl.load(offs + x))\n+\n+    SIZE = 1024\n+    rs = RandomState(17)\n+    x = numpy_random(SIZE, dtype_str=dtype, rs=rs)\n+    y = numpy_random(SIZE, dtype_str=dtype, rs=rs)\n+    x_tri = to_triton(x, dst_type=dtype, device=device)\n+    y_tri = to_triton(y, dst_type=dtype, device=device)\n+    y = x\n+    kernel[1,](x_tri, y_tri, order, SIZE)\n+    np.testing.assert_allclose(y, to_numpy(y_tri))\n+\n+\n @pytest.mark.parametrize(\"dtype_x, dtype_y\",\n                          [(dtype_x, dtype_y) for dtype_x in int_dtypes for dtype_y in int_dtypes] +\n                          [(dtype_x, dtype_y) for dtype_x in uint_dtypes for dtype_y in uint_dtypes]\n@@ -1384,43 +1407,39 @@ def test_convert_float16_to_float32(in_dtype, device):\n \n \n def serialize_fp8(np_data, in_dtype):\n-    return np_data\n-# def serialize_fp8(np_data, in_dtype):\n-#     if in_dtype == tl.float8e4b15:\n-#         # triton's f8e4b15 format is optimized for software emulation\n-#         # as a result, each pack of 4xfp8 values:\n-#         # s0b0s1b1s2b2s3b3 (for s, b sign and bits respectively)\n-#         # is actually internally stored as\n-#         # s0s2b0b2s1s3b1b3\n-#         # we apply the conversion here\n-#         f8x4 = np_data.view(np.uint32)\n-#         s = [(f8x4 & (0x80000000 >> i)) << i for i in range(0, 32, 8)]\n-#         b = [(f8x4 & (0x7f000000 >> i)) << i for i in range(0, 32, 8)]\n-#         signs = (s[0] >> 0) | (s[1] >> 16) | (s[2] >> 1) | (s[3] >> 17)\n-#         bits = (b[0] >> 1) | (b[1] >> 17) | (b[2] >> 8) | (b[3] >> 24)\n-#         # tensor of triton fp8 data\n-#         return (signs | bits).view(np.int8)\n-#     else:\n-#         return np_data\n+    if in_dtype == tl.float8e4b15x4:\n+        # triton's f8e4b15 format is optimized for software emulation\n+        # as a result, each pack of 4xfp8 values:\n+        # s0b0s1b1s2b2s3b3 (for s, b sign and bits respectively)\n+        # is actually internally stored as\n+        # s0s2b0b2s1s3b1b3\n+        # we apply the conversion here\n+        f8x4 = np_data.view(np.uint32)\n+        s = [(f8x4 & (0x80000000 >> i)) << i for i in range(0, 32, 8)]\n+        b = [(f8x4 & (0x7f000000 >> i)) << i for i in range(0, 32, 8)]\n+        signs = (s[0] >> 0) | (s[1] >> 16) | (s[2] >> 1) | (s[3] >> 17)\n+        bits = (b[0] >> 1) | (b[1] >> 17) | (b[2] >> 8) | (b[3] >> 24)\n+        # tensor of triton fp8 data\n+        return (signs | bits).view(np.int8)\n+    else:\n+        return np_data\n \n # inverse of `serialize_fp8`\n \n \n def deserialize_fp8(np_data, in_dtype):\n-    return np_data\n-# def deserialize_fp8(np_data, in_dtype):\n-#     if in_dtype == tl.float8e4b15:\n-#         f8x4 = np_data.view(np.uint32)\n-#         s = [(f8x4 & (0x80000000 >> i)) << i for i in [0, 16, 1, 17]]\n-#         b = [(f8x4 & (0x7f000000 >> i)) << i for i in [1, 17, 8, 24]]\n-#         signs = (s[0] >> 0) | (s[1] >> 8) | (s[2] >> 16) | (s[3] >> 24)\n-#         bits = (b[0] >> 0) | (b[1] >> 8) | (b[2] >> 16) | (b[3] >> 24)\n-#         return (signs | bits).view(np.int8)\n-#     else:\n-#         return np_data\n+    if in_dtype == tl.float8e4b15x4:\n+        f8x4 = np_data.view(np.uint32)\n+        s = [(f8x4 & (0x80000000 >> i)) << i for i in [0, 16, 1, 17]]\n+        b = [(f8x4 & (0x7f000000 >> i)) << i for i in [1, 17, 8, 24]]\n+        signs = (s[0] >> 0) | (s[1] >> 8) | (s[2] >> 16) | (s[3] >> 24)\n+        bits = (b[0] >> 0) | (b[1] >> 8) | (b[2] >> 16) | (b[3] >> 24)\n+        return (signs | bits).view(np.int8)\n+    else:\n+        return np_data\n \n \n-@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4b15, tl.float8e4, tl.float8e5])\n+@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4b15, tl.float8e4b15x4, tl.float8e4, tl.float8e5])\n @pytest.mark.parametrize(\"out_dtype\", [torch.float16, torch.float32])\n def test_fp8_fpN_roundtrip(in_dtype, out_dtype, device):\n     \"\"\""}, {"filename": "python/test/unit/operators/test_matmul.py", "status": "modified", "additions": 26, "deletions": 28, "changes": 54, "file_content_changes": "@@ -58,14 +58,10 @@ def kernel(Y, X, N, BLOCK_SIZE: tl.constexpr):\n                 (128, 256, 16, 1, 8, 2, None, None, None, AT, BT, DTYPE, DTYPE),\n                 (256, 128, 16, 1, 8, 2, None, None, None, AT, BT, DTYPE, DTYPE),\n                 (256, 128, 32, 1, 8, 2, None, None, None, AT, BT, DTYPE, DTYPE),\n-                # split-k\n-                (64, 64, 16, 2, 4, 2, None, None, None, AT, BT, DTYPE, DTYPE),\n-                (64, 64, 16, 4, 4, 2, None, None, None, AT, BT, DTYPE, DTYPE),\n-                (64, 64, 16, 8, 4, 2, None, None, None, AT, BT, DTYPE, DTYPE),\n                 # variable input\n                 (128, 128, 32, 1, 4, 2, 256, 384, 160, AT, BT, DTYPE, DTYPE),\n-                (128, 128, 32, 1, 4, 2, 107, 233, 256, AT, BT, DTYPE, DTYPE),\n-                (128, 128, 32, 1, 4, 2, 107, 233, 311, AT, BT, DTYPE, DTYPE),\n+                (128, 128, 32, 1, 4, 2, 107, 233, 128, AT, BT, DTYPE, DTYPE),\n+                (128, 128, 32, 1, 4, 2, 107, 233, 83, AT, BT, DTYPE, DTYPE),\n                 (128, 256, 64, 1, 8, 3, 256, 512, 160, AT, BT, DTYPE, DTYPE),\n             ] for DTYPE in [\"float16\", \"bfloat16\", \"float32\"] for AT in [False, True] for BT in [False, True]\n         ],\n@@ -77,9 +73,6 @@ def kernel(Y, X, N, BLOCK_SIZE: tl.constexpr):\n                 (128, 64, 16, 1, 4, STAGES, 256, 128, 80, AT, BT, DTYPE, DTYPE),\n                 (256, 128, 32, 1, 8, STAGES, 512, 256, 160, AT, BT, DTYPE, DTYPE),\n                 (128, 128, 32, 1, 4, STAGES, 256, 256, 160, AT, BT, DTYPE, DTYPE),\n-                # split-k\n-                (64, 64, 16, 8, 4, STAGES, 128, 128, 768, AT, BT, DTYPE, DTYPE),\n-                (64, 64, 16, 8, 4, STAGES, 128, 128, 32, AT, BT, DTYPE, DTYPE),\n             ] for DTYPE in [\"float16\", \"bfloat16\", \"float32\"] for AT in [False, True] for BT in [False, True] for STAGES in [4]\n         ],\n         # mixed-precision\n@@ -88,7 +81,6 @@ def kernel(Y, X, N, BLOCK_SIZE: tl.constexpr):\n                 (32, 32, 32, 1, 1, 2, None, None, None, AT, BT, ADTYPE, BDTYPE),\n                 (128, 256, 32, 1, 8, 2, None, None, None, AT, BT, ADTYPE, BDTYPE),\n                 (32, 64, 32, 1, 1, 2, 64, 128, 32, AT, BT, ADTYPE, BDTYPE),\n-                (128, 128, 32, 8, 4, 2, 256, 256, 128, AT, BT, ADTYPE, BDTYPE),\n             ] for ADTYPE, BDTYPE in [(\"float8e4\", \"float8e5\"),\n                                      (\"float8e4\", \"float16\"),\n                                      (\"float16\", \"float8e5\"),\n@@ -131,35 +123,44 @@ def test_op(BLOCK_M, BLOCK_N, BLOCK_K, SPLIT_K, NWARP, NSTAGE, M, N, K, AT, BT,\n     M = BLOCK_M if M is None else M\n     N = BLOCK_N if N is None else N\n     K = BLOCK_K * SPLIT_K if K is None else K\n-    a_fp8 = \"float8\" in ADTYPE\n-    b_fp8 = \"float8\" in BDTYPE\n \n     def maybe_upcast(x, dtype, is_float8):\n         if is_float8:\n             return f8_to_f16(x, dtype)\n         return x\n \n-    def init_input(n, m, t, dtype, is_float8):\n-        if t:\n-            return init_input(m, n, False, dtype, is_float8).t()\n-        if is_float8:\n-            return torch.randint(20, 50, (n, m), device=\"cuda\", dtype=torch.int8)\n+    def init_input(m, n, dtype):\n+        if 'float8' in dtype:\n+            ewidth = {'float8e4b15': 4, 'float8e4': 4, 'float8e5': 5}[dtype]\n+            sign = torch.randint(2, size=(m, n), device=\"cuda\", dtype=torch.int8) * 128\n+            val = torch.randint(2**3 - 1, size=(m, n), device=\"cuda\", dtype=torch.int8) << 7 - ewidth\n+            return sign | val\n         if dtype == \"int8\":\n-            return torch.randint(-128, 127, (n, m), device=\"cuda\", dtype=torch.int8)\n+            return torch.randint(-128, 127, (m, n), device=\"cuda\", dtype=torch.int8)\n         dtype = {\"float16\": torch.float16, \"bfloat16\": torch.bfloat16, \"float32\": torch.float32}[dtype]\n-        return .1 * torch.randn((n, m), device=\"cuda\", dtype=dtype)\n+        exponents = torch.randint(-10, 0, size=(m, n))\n+        ret = (2. ** exponents).to(dtype).to(\"cuda\")\n+        return ret\n \n     # allocate/transpose inputs\n-    a = init_input(M, K, AT, ADTYPE, a_fp8)\n-    b = init_input(K, N, BT, BDTYPE, b_fp8)\n+    a = init_input(M, K, ADTYPE)\n+    b = init_input(K, N, BDTYPE)\n+    a = a if not AT else a.T.contiguous().T\n+    b = b if not BT else b.T.contiguous().T\n     # run test\n-    th_a = maybe_upcast(a, ADTYPE, a_fp8).to(torch.float32)\n+    a_fp8 = \"float8\" in ADTYPE\n+    b_fp8 = \"float8\" in BDTYPE\n+    th_a = maybe_upcast(a, ADTYPE, a_fp8)\n     if AT and a_fp8:\n         th_a = th_a.view(th_a.shape[::-1]).T\n-    th_b = maybe_upcast(b, BDTYPE, b_fp8).to(torch.float32)\n+    th_b = maybe_upcast(b, BDTYPE, b_fp8)\n     if BT and b_fp8:\n         th_b = th_b.view(th_b.shape[::-1]).T\n-    th_c = torch.matmul(th_a, th_b)\n+    if th_a.is_floating_point():\n+        ab_dtype = th_a.dtype if th_a.element_size() > th_b.element_size() else th_b.dtype\n+    else:\n+        ab_dtype = torch.float32\n+    th_c = torch.matmul(th_a.to(ab_dtype), th_b.to(ab_dtype))\n     if ADTYPE == \"int8\" or BDTYPE == \"int8\":\n         th_c = th_c.to(torch.int8)\n     try:\n@@ -168,9 +169,6 @@ def init_input(n, m, t, dtype, is_float8):\n         if b_fp8:\n             b = triton.reinterpret(b, getattr(tl, BDTYPE))\n         tt_c = triton.ops.matmul(a, b)\n-        atol, rtol = 1e-2, 0\n-        if ADTYPE == torch.bfloat16 or BDTYPE == torch.bfloat16:\n-            atol, rtol = 3.5e-2, 0\n-        torch.testing.assert_allclose(th_c, tt_c, atol=atol, rtol=rtol)\n+        torch.testing.assert_allclose(th_c, tt_c, atol=0, rtol=0)\n     except triton.OutOfResources as e:\n         pytest.skip(str(e))"}, {"filename": "python/triton/compiler/code_generator.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -1065,6 +1065,7 @@ def str_to_ty(name):\n         \"fp8e4\": language.float8e4,\n         \"fp8e5\": language.float8e5,\n         \"fp8e4b15\": language.float8e4b15,\n+        \"fp8e4b15x4\": language.float8e4b15x4,\n         \"fp16\": language.float16,\n         \"bf16\": language.bfloat16,\n         \"fp32\": language.float32,"}, {"filename": "python/triton/compiler/compiler.py", "status": "modified", "additions": 15, "deletions": 16, "changes": 31, "file_content_changes": "@@ -11,10 +11,9 @@\n from pathlib import Path\n from typing import Any, Tuple\n \n-import triton\n-import triton._C.libtriton.triton as _triton\n-from .._C.libtriton.triton import (add_external_libs, compile_ptx_to_cubin,\n-                                   get_num_warps, get_shared_memory_size, ir,\n+from .._C.libtriton.triton import (ClusterInfo, TMAInfos, add_external_libs,\n+                                   compile_ptx_to_cubin, get_env_vars, get_num_warps,\n+                                   get_shared_memory_size, ir,\n                                    translate_llvmir_to_hsaco, translate_llvmir_to_ptx,\n                                    translate_triton_gpu_to_llvmir)\n from ..common.backend import get_backend, path_to_ptxas\n@@ -101,8 +100,8 @@ def optimize_ttgir(mod, num_stages, num_warps, num_ctas, arch,\n     if arch // 10 >= 9 and enable_warp_specialization and num_warps == 4:\n         pm.add_tritongpu_ws_feasibility_checking_pass(arch)\n         pm.run(mod)\n-        ws_enabled = _triton.ir.is_ws_supported(mod)\n-        pm = _triton.ir.pass_manager(mod.context)\n+        ws_enabled = ir.is_ws_supported(mod)\n+        pm = ir.pass_manager(mod.context)\n         pm.enable_debug()\n     if ws_enabled:\n         pm.add_tritongpu_wsdecomposing_pass(arch)\n@@ -426,12 +425,12 @@ def compile(fn, **kwargs):\n     if os.environ.get('OPTIMIZE_EPILOGUE', '') == '1':\n         optimize_epilogue = True\n     #\n-    cluster_info = _triton.ClusterInfo()\n+    cluster_info = ClusterInfo()\n     if \"clusterDims\" in kwargs:\n         cluster_info.clusterDimX = kwargs[\"clusterDims\"][0]\n         cluster_info.clusterDimY = kwargs[\"clusterDims\"][1]\n         cluster_info.clusterDimZ = kwargs[\"clusterDims\"][2]\n-    tma_infos = _triton.TMAInfos()\n+    tma_infos = TMAInfos()\n     # build compilation stages\n     stages = dict()\n     stages[\"ast\"] = (lambda path: fn, None)\n@@ -479,7 +478,7 @@ def compile(fn, **kwargs):\n         first_stage = list(stages.keys()).index(ir_name)\n \n     # create cache manager\n-    fn_cache_manager = get_cache_manager(make_hash(fn, arch, _triton.get_env_vars(), **kwargs))\n+    fn_cache_manager = get_cache_manager(make_hash(fn, arch, get_env_vars(), **kwargs))\n     # determine name and extension type of provided function\n     if isinstance(fn, JITFunction):\n         name, ext = fn.__name__, \"ast\"\n@@ -512,7 +511,7 @@ def compile(fn, **kwargs):\n                     \"constants\": _get_jsonable_constants(constants),\n                     \"debug\": debug,\n                     \"arch\": arch, }\n-        metadata.update(_triton.get_env_vars())\n+        metadata.update(get_env_vars())\n         if ext == \"ptx\":\n             assert \"shared\" in kwargs, \"ptx compilation must provide shared memory size\"\n             metadata[\"shared\"] = kwargs[\"shared\"]\n@@ -558,7 +557,7 @@ def compile(fn, **kwargs):\n         if ir_name == \"llir\" and \"shared\" not in metadata:\n             metadata[\"shared\"] = get_shared_memory_size(module)\n         if ir_name == \"ttgir\":\n-            metadata[\"enable_warp_specialization\"] = _triton.ir.is_ws_supported(next_module)\n+            metadata[\"enable_warp_specialization\"] = ir.is_ws_supported(next_module)\n             if metadata[\"enable_warp_specialization\"]:\n                 metadata[\"num_warps\"] = get_num_warps(next_module)\n         if ir_name == \"ptx\":\n@@ -570,7 +569,7 @@ def compile(fn, **kwargs):\n             _device_backend.add_meta_info(ir_name, module, next_module, metadata, asm)\n         module = next_module\n \n-    ids_of_folded_args = tuple([int(k) for k in configs[0].ids_of_folded_args]) if isinstance(fn, triton.runtime.JITFunction) else ()\n+    ids_of_folded_args = tuple([int(k) for k in configs[0].ids_of_folded_args]) if isinstance(fn, JITFunction) else ()\n     if \"clusterDims\" not in metadata:\n         metadata[\"clusterDims\"] = [\n             cluster_info.clusterDimX,\n@@ -585,10 +584,10 @@ def compile(fn, **kwargs):\n             metadata[\"tensormaps_info\"][i].ids_of_folded_args = ids_of_folded_args\n \n     ids_of_tensormaps = get_ids_of_tensormaps(metadata.get(\"tensormaps_info\", None))\n-    if isinstance(fn, triton.runtime.JITFunction) and \"tensormaps_info\" in metadata:\n+    if isinstance(fn, JITFunction) and \"tensormaps_info\" in metadata:\n         fn.tensormaps_info = metadata[\"tensormaps_info\"]\n \n-    ids_of_const_exprs = tuple(fn.constexprs) if isinstance(fn, triton.runtime.JITFunction) else ()\n+    ids_of_const_exprs = tuple(fn.constexprs) if isinstance(fn, JITFunction) else ()\n     ids = {\"ids_of_tensormaps\": ids_of_tensormaps, \"ids_of_folded_args\": ids_of_folded_args, \"ids_of_const_exprs\": ids_of_const_exprs}\n     # cache manager\n     if is_cuda or is_hip:\n@@ -674,7 +673,7 @@ def __getattribute__(self, name):\n         return super().__getattribute__(name)\n \n     # capture args and expand args with cutensormap*\n-    def assemble_tensormap_to_arg(self, args, constants):\n+    def assemble_tensormap_to_arg(self, args):\n         args_with_tma = list(args)\n         if hasattr(self, 'tensormaps_info'):\n             # tuple for hashable\n@@ -687,7 +686,7 @@ def __getitem__(self, grid):\n         self._init_handles()\n \n         def runner(*args, stream=None):\n-            args_expand = self.assemble_tensormap_to_arg(args, self.constants)\n+            args_expand = self.assemble_tensormap_to_arg(args)\n             if stream is None:\n                 if self.device_type in [\"cuda\", \"hip\"]:\n                     stream = get_cuda_stream()"}, {"filename": "python/triton/compiler/make_launcher.py", "status": "modified", "additions": 28, "deletions": 2, "changes": 30, "file_content_changes": "@@ -250,6 +250,7 @@ def format_of(ty):\n #include \\\"cuda.h\\\"\n #include <stdbool.h>\n #include <Python.h>\n+#include <dlfcn.h>\n \n static inline void gpuAssert(CUresult code, const char *file, int line)\n {{\n@@ -267,9 +268,30 @@ def format_of(ty):\n \n #define CUDA_CHECK(ans) {{ gpuAssert((ans), __FILE__, __LINE__); }}\n \n+typedef CUresult (*cuLaunchKernelEx_t)(const CUlaunchConfig* config, CUfunction f, void** kernelParams, void** extra);\n+\n+static cuLaunchKernelEx_t getLaunchKernelExHandle() {{\n+  // Open the shared library\n+  void* handle = dlopen(\"libcuda.so\", RTLD_LAZY);\n+  if (!handle) {{\n+    PyErr_SetString(PyExc_RuntimeError, \"Failed to open libcuda.so\");\n+    return NULL;\n+  }}\n+  // Clear any existing error\n+  dlerror();\n+  cuLaunchKernelEx_t cuLaunchKernelExHandle = (cuLaunchKernelEx_t)dlsym(handle, \"cuLaunchKernelEx\");\n+  // Check for errors\n+  const char *dlsym_error = dlerror();\n+  if (dlsym_error) {{\n+    PyErr_SetString(PyExc_RuntimeError, \"Failed to retrieve cuLaunchKernelEx from libcuda.so\");\n+    return NULL;\n+  }}\n+  return cuLaunchKernelExHandle;\n+}}\n+\n static void _launch(int gridX, int gridY, int gridZ, int num_warps, int num_ctas, int clusterDimX, int clusterDimY, int clusterDimZ, int shared_memory, CUstream stream, CUfunction function{', ' + arg_decls if len(arg_decls) > 0 else ''}) {{\n   void *params[] = {{ {', '.join(f\"&arg{i}\" for i in params)} }};\n-  if(gridX*gridY*gridZ > 0){{\n+  if (gridX*gridY*gridZ > 0) {{\n     if (num_ctas == 1) {{\n       CUDA_CHECK(cuLaunchKernel(function, gridX, gridY, gridZ, 32*num_warps, 1, 1, shared_memory, stream, params, 0));\n     }} else {{\n@@ -291,7 +313,11 @@ def format_of(ty):\n       config.hStream = stream;\n       config.attrs = launchAttr;\n       config.numAttrs = 2;\n-      CUDA_CHECK(cuLaunchKernelEx(&config, function, params, 0));\n+      static cuLaunchKernelEx_t cuLaunchKernelExHandle = NULL;\n+      if (cuLaunchKernelExHandle == NULL) {{\n+        cuLaunchKernelExHandle = getLaunchKernelExHandle();\n+      }}\n+      CUDA_CHECK(cuLaunchKernelExHandle(&config, function, params, 0));\n     }}\n   }}\n }}"}, {"filename": "python/triton/language/__init__.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -50,6 +50,7 @@\n     float32,\n     float64,\n     float8e4b15,\n+    float8e4b15x4,\n     float8e4,\n     float8e5,\n     function_type,\n@@ -148,6 +149,7 @@\n     \"float32\",\n     \"float64\",\n     \"float8e4b15\",\n+    \"float8e4b15x4\",\n     \"float8e4\",\n     \"float8e5\",\n     \"full\","}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 25, "deletions": 15, "changes": 40, "file_content_changes": "@@ -76,7 +76,7 @@ def _to_tensor(x, builder):\n class dtype:\n     SINT_TYPES = ['int8', 'int16', 'int32', 'int64']\n     UINT_TYPES = ['int1', 'uint8', 'uint16', 'uint32', 'uint64']\n-    FP_TYPES = ['fp8e4b15', 'fp8e4', 'fp8e5', 'fp16', 'bf16', 'fp32', 'fp64']\n+    FP_TYPES = ['fp8e4b15', 'fp8e4b15x4', 'fp8e4', 'fp8e5', 'fp16', 'bf16', 'fp32', 'fp64']\n     STANDARD_FP_TYPES = ['fp16', 'bf16', 'fp32', 'fp64']\n     OTHER_TYPES = ['void']\n \n@@ -100,6 +100,10 @@ def __init__(self, name):\n                 self.fp_mantissa_width = 3\n                 self.primitive_bitwidth = 8\n                 self.exponent_bias = 15\n+            elif name == 'fp8e4b15x4':\n+                self.fp_mantissa_width = 3\n+                self.primitive_bitwidth = 8\n+                self.exponent_bias = 15\n             elif name == 'fp8e4':\n                 self.fp_mantissa_width = 3\n                 self.primitive_bitwidth = 8\n@@ -138,6 +142,9 @@ def is_fp8e4(self):\n     def is_fp8e4b15(self):\n         return self.name == 'fp8e4b15'\n \n+    def is_fp8e4b15x4(self):\n+        return self.name == 'fp8e4b15x4'\n+\n     def is_fp16(self):\n         return self.name == 'fp16'\n \n@@ -241,6 +248,8 @@ def to_ir(self, builder: ir.builder) -> ir.type:\n             return builder.get_fp8e4_ty()\n         elif self.name == 'fp8e4b15':\n             return builder.get_fp8e4b15_ty()\n+        elif self.name == 'fp8e4b15x4':\n+            return builder.get_fp8e4b15x4_ty()\n         elif self.name == 'fp16':\n             return builder.get_half_ty()\n         elif self.name == 'bf16':\n@@ -375,6 +384,7 @@ def to_ir(self, builder: ir.builder):\n float8e5 = dtype('fp8e5')\n float8e4 = dtype('fp8e4')\n float8e4b15 = dtype('fp8e4b15')\n+float8e4b15x4 = dtype('fp8e4b15x4')\n float16 = dtype('fp16')\n bfloat16 = dtype('bf16')\n float32 = dtype('fp32')\n@@ -1382,7 +1392,7 @@ def minimum(x, y):\n     :param other: the second input tensor\n     :type other: Block\n     \"\"\"\n-    return where(x < y, x, y)\n+    return math.min(x, y)\n \n \n @jit\n@@ -1395,7 +1405,7 @@ def maximum(x, y):\n     :param other: the second input tensor\n     :type other: Block\n     \"\"\"\n-    return where(x > y, x, y)\n+    return math.max(x, y)\n \n # max and argmax\n \n@@ -1422,11 +1432,6 @@ def _argmax_combine_tie_break_fast(value1, index1, value2, index2):\n     return _argmax_combine(value1, index1, value2, index2, False)\n \n \n-@jit\n-def _fast_max(x, y):\n-    return math.max(x, y)\n-\n-\n @jit\n @_add_reduction_docstr(\"maximum\",\n                        return_indices_arg=\"return_indices\",\n@@ -1445,7 +1450,7 @@ def max(input, axis=None, return_indices=False, return_indices_tie_break_left=Tr\n             else:\n                 assert input.dtype.is_integer_type()\n                 input = input.to(int32)\n-        return reduce(input, axis, _fast_max)\n+        return reduce(input, axis, maximum)\n \n \n @jit\n@@ -1479,11 +1484,6 @@ def _argmin_combine_tie_break_fast(value1, index1, value2, index2):\n     return _argmin_combine(value1, index1, value2, index2, False)\n \n \n-@jit\n-def _fast_min(x, y):\n-    return math.min(x, y)\n-\n-\n @jit\n @_add_reduction_docstr(\"minimum\",\n                        return_indices_arg=\"return_indices\",\n@@ -1502,7 +1502,7 @@ def min(input, axis=None, return_indices=False, return_indices_tie_break_left=Tr\n             else:\n                 assert input.dtype.is_integer_type()\n                 input = input.to(int32)\n-        return reduce(input, axis, _fast_min)\n+        return reduce(input, axis, minimum)\n \n \n @jit\n@@ -1926,6 +1926,16 @@ def extern_elementwise(lib_name: str, lib_path: str, args: list, arg_type_symbol\n     return dispatch(func, lib_name, lib_path, dispatch_args, arg_type_symbol_dict, ret_shape, is_pure, _builder)\n \n \n+def binary_op_type_legalization(lhs, rhs, builder):\n+    '''\n+        Convert both operands to a single common type\n+        :param lhs: the left operand\n+        :param rhs: the right operand\n+        :param builder: the builder\n+    '''\n+    return semantic.binary_op_type_checking_impl(lhs, rhs, builder)\n+\n+\n def extern(fn):\n     \"\"\"A decorator for external functions.\"\"\"\n     return builtin(fn)"}, {"filename": "python/triton/language/math.py", "status": "modified", "additions": 24, "deletions": 16, "changes": 40, "file_content_changes": "@@ -40,26 +40,34 @@ def byte_perm(arg0, arg1, arg2, _builder=None):\n \n @core.extern\n def min(arg0, arg1, _builder=None):\n-    return core.extern_elementwise(\"libdevice\", libdevice_path(), [arg0, arg1, ],\n-                                   {(core.dtype(\"int32\"), core.dtype(\"int32\"),): (\"__nv_min\", core.dtype(\"int32\")),\n-                                    (core.dtype(\"uint32\"), core.dtype(\"uint32\"),): (\"__nv_umin\", core.dtype(\"uint32\")),\n-                                    (core.dtype(\"int64\"), core.dtype(\"int64\"),): (\"__nv_llmin\", core.dtype(\"int64\")),\n-                                    (core.dtype(\"uint64\"), core.dtype(\"uint64\"),): (\"__nv_ullmin\", core.dtype(\"uint64\")),\n-                                    (core.dtype(\"fp32\"), core.dtype(\"fp32\"),): (\"__nv_fminf\", core.dtype(\"fp32\")),\n-                                    (core.dtype(\"fp64\"), core.dtype(\"fp64\"),): (\"__nv_fmin\", core.dtype(\"fp64\")),\n-                                    }, is_pure=True, _builder=_builder)\n+    arg0 = core._to_tensor(arg0, _builder)\n+    arg1 = core._to_tensor(arg1, _builder)\n+    arg0, arg1 = core.binary_op_type_legalization(arg0, arg1, _builder)\n+    dtype = arg0.dtype\n+    if dtype.is_floating():\n+        return core.tensor(_builder.create_minf(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_signed():\n+        return core.tensor(_builder.create_minsi(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_unsigned():\n+        return core.tensor(_builder.create_minui(arg0.handle, arg1.handle), arg0.dtype)\n+    else:\n+        assert False, f\"Unexpected dtype {dtype}\"\n \n \n @core.extern\n def max(arg0, arg1, _builder=None):\n-    return core.extern_elementwise(\"libdevice\", libdevice_path(), [arg0, arg1, ],\n-                                   {(core.dtype(\"int32\"), core.dtype(\"int32\"),): (\"__nv_max\", core.dtype(\"int32\")),\n-                                    (core.dtype(\"uint32\"), core.dtype(\"uint32\"),): (\"__nv_umax\", core.dtype(\"uint32\")),\n-                                    (core.dtype(\"int64\"), core.dtype(\"int64\"),): (\"__nv_llmax\", core.dtype(\"int64\")),\n-                                    (core.dtype(\"uint64\"), core.dtype(\"uint64\"),): (\"__nv_ullmax\", core.dtype(\"uint64\")),\n-                                    (core.dtype(\"fp32\"), core.dtype(\"fp32\"),): (\"__nv_fmaxf\", core.dtype(\"fp32\")),\n-                                    (core.dtype(\"fp64\"), core.dtype(\"fp64\"),): (\"__nv_fmax\", core.dtype(\"fp64\")),\n-                                    }, is_pure=True, _builder=_builder)\n+    arg0 = core._to_tensor(arg0, _builder)\n+    arg1 = core._to_tensor(arg1, _builder)\n+    arg0, arg1 = core.binary_op_type_legalization(arg0, arg1, _builder)\n+    dtype = arg0.dtype\n+    if dtype.is_floating():\n+        return core.tensor(_builder.create_maxf(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_signed():\n+        return core.tensor(_builder.create_maxsi(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_unsigned():\n+        return core.tensor(_builder.create_maxui(arg0.handle, arg1.handle), arg0.dtype)\n+    else:\n+        assert False, f\"Unexpected dtype {dtype}\"\n \n \n @core.extern"}, {"filename": "python/triton/language/random.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -55,7 +55,7 @@ def randint(seed, offset, n_rounds: tl.constexpr = N_ROUNDS_DEFAULT):\n     using `randint4x` is likely to be faster than calling `randint` 4 times.\n \n     :param seed: The seed for generating random numbers.\n-    :param offsets: The offsets to generate random numbers for.\n+    :param offset: The offsets to generate random numbers for.\n     \"\"\"\n     ret, _, _, _ = randint4x(seed, offset, n_rounds)\n     return ret\n@@ -120,7 +120,7 @@ def rand(seed, offset, n_rounds: tl.constexpr = N_ROUNDS_DEFAULT):\n def rand4x(seed, offsets, n_rounds: tl.constexpr = N_ROUNDS_DEFAULT):\n     \"\"\"\n     Given a :code:`seed` scalar and an :code:`offsets` block,\n-    returns a 4 blocks of random :code:`float32` in :math:`U(0, 1)`.\n+    returns 4 blocks of random :code:`float32` in :math:`U(0, 1)`.\n \n     :param seed: The seed for generating random numbers.\n     :param offsets: The offsets to generate random numbers for.\n@@ -167,7 +167,7 @@ def randn(seed, offset, n_rounds: tl.constexpr = N_ROUNDS_DEFAULT):\n def randn4x(seed, offset, n_rounds: tl.constexpr = N_ROUNDS_DEFAULT):\n     \"\"\"\n     Given a :code:`seed` scalar and an :code:`offset` block,\n-    returns a 4 blocks of random :code:`float32` in :math:`\\\\mathcal{N}(0, 1)`.\n+    returns 4 blocks of random :code:`float32` in :math:`\\\\mathcal{N}(0, 1)`.\n \n     :param seed: The seed for generating random numbers.\n     :param offsets: The offsets to generate random numbers for."}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -133,6 +133,8 @@ def add(input: tl.tensor,\n     # ptr + offset\n     if other_scalar_ty.is_ptr() and not input_scalar_ty.is_ptr():\n         input, other = other, input\n+        input_scalar_ty = input.type.scalar\n+        other_scalar_ty = other.type.scalar\n     if input_scalar_ty.is_ptr():\n         return tl.tensor(builder.create_addptr(input.handle, other.handle), input.type)\n     # float + float\n@@ -192,7 +194,7 @@ def truediv(input: tl.tensor,\n     elif input_scalar_ty.is_int() and other_scalar_ty.is_int():\n         input = cast(input, tl.float32, builder)\n         other = cast(other, tl.float32, builder)\n-    # float / float (cast to highest exponent type)\n+    # float / float (cast to the highest exponent type)\n     elif input_scalar_ty.is_floating() and other_scalar_ty.is_floating():\n         if input_scalar_ty.fp_mantissa_width > other_scalar_ty.fp_mantissa_width:\n             other = cast(other, input_scalar_ty, builder)\n@@ -1364,7 +1366,7 @@ def wrap_tensor(x, scalar_ty):\n \n def _check_dtype(dtypes: List[str]) -> T:\n     \"\"\"\n-    We following libdevice's convention to check accepted data types for math functions.\n+    We're following libdevice's convention to check accepted data types for math functions.\n     It is not a good practice to support all data types as accelerators/GPUs don't support\n     many float16 and bfloat16 math operations.\n     We should let the users know that they are using and invoke explicit cast to convert"}, {"filename": "python/triton/runtime/backends/cuda.c", "status": "modified", "additions": 39, "deletions": 5, "changes": 44, "file_content_changes": "@@ -1,4 +1,5 @@\n #include \"cuda.h\"\n+#include <dlfcn.h>\n #define PY_SSIZE_T_CLEAN\n #include <Python.h>\n \n@@ -338,6 +339,36 @@ static cuuint32_t *list_to_cuuint32_array(PyObject *listObj) {\n   return array;\n }\n \n+typedef CUresult (*cuTensorMapEncodeTiled_t)(\n+    CUtensorMap *tensorMap, CUtensorMapDataType tensorDataType,\n+    cuuint32_t tensorRank, void *globalAddress, const cuuint64_t *globalDim,\n+    const cuuint64_t *globalStrides, const cuuint32_t *boxDim,\n+    const cuuint32_t *elementStrides, CUtensorMapInterleave interleave,\n+    CUtensorMapSwizzle swizzle, CUtensorMapL2promotion l2Promotion,\n+    CUtensorMapFloatOOBfill oobFill);\n+\n+static cuTensorMapEncodeTiled_t getCuTensorMapEncodeTiledHandle() {\n+  // Open the shared library\n+  void *handle = dlopen(\"libcuda.so\", RTLD_LAZY);\n+  if (!handle) {\n+    PyErr_SetString(PyExc_RuntimeError, \"Failed to open libcuda.so\");\n+    return NULL;\n+  }\n+  // Clear any existing error\n+  dlerror();\n+  cuTensorMapEncodeTiled_t cuTensorMapEncodeTiledHandle =\n+      (cuTensorMapEncodeTiled_t)dlsym(handle, \"cuTensorMapEncodeTiled\");\n+  // Check for errors\n+  const char *dlsym_error = dlerror();\n+  if (dlsym_error) {\n+    PyErr_SetString(\n+        PyExc_RuntimeError,\n+        \"Failed to retrieve cuTensorMapEncodeTiled from libcuda.so\");\n+    return NULL;\n+  }\n+  return cuTensorMapEncodeTiledHandle;\n+}\n+\n static PyObject *tensorMapEncodeTiled(PyObject *self, PyObject *args) {\n   CUtensorMap *tensorMap = (CUtensorMap *)malloc(sizeof(CUtensorMap));\n   CUtensorMapDataType tensorDataType;\n@@ -364,18 +395,21 @@ static PyObject *tensorMapEncodeTiled(PyObject *self, PyObject *args) {\n   cuuint32_t *boxDim = list_to_cuuint32_array(boxDimObj);\n   cuuint32_t *elementStrides = list_to_cuuint32_array(elementStridesObj);\n \n+  static cuTensorMapEncodeTiled_t cuTensorMapEncodeTiledHandle = NULL;\n+  if (cuTensorMapEncodeTiledHandle == NULL) {\n+    cuTensorMapEncodeTiledHandle = getCuTensorMapEncodeTiledHandle();\n+  }\n   // Call the function\n-  CUDA_CHECK(cuTensorMapEncodeTiled(tensorMap, tensorDataType, tensorRank,\n-                                    globalAddress, globalDim, globalStrides,\n-                                    boxDim, elementStrides, interleave, swizzle,\n-                                    l2Promotion, oobFill));\n+  CUDA_CHECK(cuTensorMapEncodeTiledHandle(\n+      tensorMap, tensorDataType, tensorRank, globalAddress, globalDim,\n+      globalStrides, boxDim, elementStrides, interleave, swizzle, l2Promotion,\n+      oobFill));\n \n   // Clean up\n   free(globalDim);\n   free(globalStrides);\n   free(boxDim);\n   free(elementStrides);\n-\n   // Return the tensor map as a normal pointer\n   return PyLong_FromUnsignedLongLong((unsigned long long)tensorMap);\n }"}, {"filename": "python/triton/runtime/jit.py", "status": "modified", "additions": 5, "deletions": 9, "changes": 14, "file_content_changes": "@@ -11,7 +11,7 @@\n from typing import (Callable, Generic, Iterable, List, Optional, TypeVar, Union, cast,\n                     overload)\n \n-import triton\n+from .._C.libtriton.triton import TMAInfos\n from ..common.backend import get_backend, path_to_ptxas\n \n TRITON_PATH = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n@@ -248,6 +248,7 @@ def _type_of(key):\n             \"float8e4\": \"fp8e4\",\n             \"float8e5\": \"fp8e5\",\n             \"float8e4b15\": \"fp8e4b15\",\n+            \"float8e4b15x4\": \"fp8e4b15x4\",\n             \"float16\": \"fp16\",\n             \"bfloat16\": \"bf16\",\n             \"float32\": \"fp32\",\n@@ -406,13 +407,8 @@ def {self.fn.__name__}({args_signature}grid=None, num_warps=4, num_ctas=1, num_s\n     if bin is not None:\n       # build dict of constant values\n       args = [{args}]\n-      all_args = {', '.join([f'{arg}' for arg in self.arg_names]) + ', ' if len(self.arg_names) > 0 else ()}\n-      configs = self._get_config(*all_args),\n-      constants = self._make_constants(constexpr_key)\n-      constants.update({{i: None for i, arg in enumerate(all_args) if arg is None}})\n-      constants.update({{i: 1 for i in configs[0].equal_to_1}})\n       # Create tensormaps and append to args\n-      args = bin.assemble_tensormap_to_arg(args, constants)\n+      args = bin.assemble_tensormap_to_arg(args)\n       if not warmup:\n           bin.c_wrapper(grid_0, grid_1, grid_2, bin.num_warps, bin.num_ctas, bin.clusterDims[0], bin.clusterDims[1], bin.clusterDims[2], bin.shared, stream, bin.cu_function, CompiledKernel.launch_enter_hook, CompiledKernel.launch_exit_hook, bin, *args)\n       return bin\n@@ -434,7 +430,7 @@ def {self.fn.__name__}({args_signature}grid=None, num_warps=4, num_ctas=1, num_s\n       if not self._call_hook(key, signature, device, constants, num_warps, num_ctas, num_stages, enable_warp_specialization, extern_libs, configs):\n         bin = compile(self, signature=signature, device=device, constants=constants, num_warps=num_warps, num_ctas=num_ctas, num_stages=num_stages, enable_warp_specialization=enable_warp_specialization, extern_libs=extern_libs, configs=configs, debug=self.debug, device_type=device_type)\n         # Create tensormaps and append to args\n-        args = bin.assemble_tensormap_to_arg(args, constants)\n+        args = bin.assemble_tensormap_to_arg(args)\n         if not warmup:\n             bin.c_wrapper(grid_0, grid_1, grid_2, bin.num_warps, bin.num_ctas, bin.clusterDims[0], bin.clusterDims[1], bin.clusterDims[2], bin.shared, stream, bin.cu_function, CompiledKernel.launch_enter_hook, CompiledKernel.launch_exit_hook, bin, *args)\n         self.cache[device][key] = bin\n@@ -485,7 +481,7 @@ def __init__(self, fn, version=None, do_not_specialize=None, debug=None, noinlin\n         # index of constexprs\n         self.constexprs = [self.arg_names.index(name) for name, ty in self.__annotations__.items() if 'constexpr' in ty]\n         # tma info\n-        self.tensormaps_info = triton._C.libtriton.triton.TMAInfos()\n+        self.tensormaps_info = TMAInfos()\n         # launcher\n         self.run = self._make_launcher()\n         # re-use docs of wrapped function"}, {"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "file_content_changes": "@@ -87,10 +87,10 @@ def _fwd_kernel(\n         k = tl.load(K_block_ptr)\n         v = tl.load(V_block_ptr)\n         # -- compute qk ---\n-        qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n+        qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float16)\n         if IS_CAUSAL:\n             qk = tl.where(P_SEQ + offs_m[:, None] >= (start_n + offs_n[None, :]), qk, float(\"-inf\"))\n-        qk += tl.dot(q, k)\n+        qk += tl.dot(q, k, out_dtype=tl.float16)\n         # -- compute scaling constant ---\n         m_i_new = tl.maximum(m_i, tl.max(qk, 1))\n         alpha = tl.math.exp2(m_i - m_i_new)\n@@ -243,11 +243,12 @@ def forward(ctx, q, k, v, causal, sm_scale):\n         assert Lk in {16, 32, 64, 128}\n         o = torch.empty_like(q)\n         BLOCK_M = 128\n-        BLOCK_N = 64\n+        BLOCK_N = 64 if Lk <= 64 else 32\n+        num_stages = 4 if Lk <= 64 else 3\n+        num_warps = 4\n         grid = (triton.cdiv(q.shape[2], BLOCK_M), q.shape[0] * q.shape[1], 1)\n         L = torch.empty((q.shape[0] * q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32)\n         P_SEQ = 0 if q.shape[-2] == k.shape[-2] else k.shape[-2] - q.shape[-2]\n-        num_warps = 4 if Lk <= 64 else 8\n         _fwd_kernel[grid](\n             q, k, v, sm_scale,\n             L,\n@@ -260,7 +261,7 @@ def forward(ctx, q, k, v, causal, sm_scale):\n             BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_DMODEL=Lk,\n             IS_CAUSAL=causal,\n             num_warps=num_warps,\n-            num_stages=4)\n+            num_stages=num_stages)\n \n         ctx.save_for_backward(q, k, v, o, L)\n         ctx.grid = grid"}, {"filename": "python/tutorials/09-experimental-tma-matrix-multiplication.py", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "file_content_changes": "@@ -1,3 +1,10 @@\n+\"\"\"\n+Matrix Multiplication with TMA (Experimental)\n+================================================\n+In this tutorial, you will write a very short high-performance multiplication kernel that achieves\n+performance on parallel with cuBLAS.\n+\"\"\"\n+\n # Copyright (c) 2023 NVIDIA Corporation & Affiliates. All rights reserved.\n #\n # Permission is hereby granted, free of charge, to any person obtaining"}, {"filename": "python/tutorials/10-experimental-tmastg-matrix-multiplication.py", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "file_content_changes": "@@ -1,3 +1,10 @@\n+\"\"\"\n+Matrix Multiplication with TMASTG (Experimental)\n+================================================\n+In this tutorial, you will write a very short high-performance multiplication kernel that achieves\n+performance on parallel with cuBLAS.\n+\"\"\"\n+\n # Copyright (c) 2023 NVIDIA Corporation & Affiliates. All rights reserved.\n #\n # Permission is hereby granted, free of charge, to any person obtaining"}]