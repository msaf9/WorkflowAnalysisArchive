[{"filename": "python/triton/compiler.py", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "file_content_changes": "@@ -1035,10 +1035,10 @@ def format_of(ty):\n }}\n #define CUDA_CHECK(ans) {{ gpuAssert((ans), __FILE__, __LINE__); }}\n \n-CUmodule module = 0;\n-CUfunction function = 0;\n+static CUmodule module = 0;\n+static CUfunction function = 0;\n \n-void init_function(const char* name, const unsigned char* src, size_t n_shared_bytes, int64_t device){{\n+static void init_function(const char* name, const unsigned char* src, size_t n_shared_bytes, int64_t device){{\n   CUmodule mod;\n   CUfunction fun;\n   CUDA_CHECK(cuModuleLoadData(&mod, src));\n@@ -1060,7 +1060,7 @@ def format_of(ty):\n   function = fun;\n }}\n \n-void init_module(CUdevice device) {{\n+static void init_module(CUdevice device) {{\n   {func_init}\n }}\n \n@@ -1072,8 +1072,9 @@ def format_of(ty):\n   CUDA_CHECK(cuCtxGetDevice(&device));\n \n   // TODO: machine may have heterogeneous devices\n-  if(function == 0)\n+  if(function == 0){{\n     init_module(device);\n+  }}\n \n   void *params[] = {{ {', '.join(f\"&arg{i}\" for i in range(n_args) if i not in constants)} }};\n   CUDA_CHECK(cuLaunchKernel(function, gridX, gridY, gridZ, 32*{num_warps}, 1, 1, {name}_shmem, stream, params, 0));"}]