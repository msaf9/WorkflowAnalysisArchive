[{"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 43, "deletions": 28, "changes": 71, "file_content_changes": "@@ -258,7 +258,6 @@ struct StoreOpConversion\n   matchAndRewrite(triton::StoreOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Value ptr = op.getPtr();\n-    Value mask = op.getMask();\n     Value value = op.getValue();\n \n     Value llPtr = adaptor.getPtr();\n@@ -273,7 +272,7 @@ struct StoreOpConversion\n         typeConverter->convertType(getElementTypeOrSelf(valueTy));\n \n     unsigned vec = getVectorSize(ptr);\n-    unsigned numElems = getElemsPerThread(ptr.getType());\n+    unsigned elemsPerThread = getElemsPerThread(ptr.getType());\n \n     auto ptrElems = getTypeConverter()->unpackLLElements(loc, llPtr, rewriter,\n                                                          ptr.getType());\n@@ -284,6 +283,7 @@ struct StoreOpConversion\n     // Determine the vectorization size\n     SmallVector<Value> maskElems;\n     if (llMask) {\n+      Value mask = op.getMask();\n       maskElems = getTypeConverter()->unpackLLElements(loc, llMask, rewriter,\n                                                        mask.getType());\n       assert(valueElems.size() == maskElems.size());\n@@ -292,12 +292,26 @@ struct StoreOpConversion\n       vec = std::min(vec, maskAlign);\n     }\n \n+    // numElements = 1 for scalar\n+    auto tensorTy = valueTy.dyn_cast<RankedTensorType>();\n+    auto numElems = 1;\n+    // tensor\n+    if (tensorTy) {\n+      // mask\n+      auto shape = tensorTy.getShape();\n+      numElems = product(shape);\n+    }\n+    Value mask = int_val(1, 1);\n+    auto tid = tid_val();\n+    mask = and_(mask,\n+                icmp_slt(mul(tid, i32_val(elemsPerThread)), i32_val(numElems)));\n+\n     const size_t dtsize =\n         std::max<int>(1, valueElemTy.getIntOrFloatBitWidth() / 8);\n     const size_t valueElemNbits = dtsize * 8;\n \n-    const int numVecs = numElems / vec;\n-    for (size_t vecStart = 0; vecStart < numElems; vecStart += vec) {\n+    const int numVecs = elemsPerThread / vec;\n+    for (size_t vecStart = 0; vecStart < elemsPerThread; vecStart += vec) {\n       // TODO: optimization when ptr is AddPtr with constant offset\n       size_t in_off = 0;\n \n@@ -306,7 +320,7 @@ struct StoreOpConversion\n       const size_t width = std::min(totalWidth, maxWordWidth);\n       const size_t nWords = std::max<size_t>(1, totalWidth / width);\n       const size_t wordNElems = width / valueElemNbits;\n-      assert(wordNElems * nWords * numVecs == numElems);\n+      assert(wordNElems * nWords * numVecs == elemsPerThread);\n \n       // TODO(Superjomn) Add cache policy fields to StoreOp.\n       // TODO(Superjomn) Deal with cache policy here.\n@@ -339,7 +353,7 @@ struct StoreOpConversion\n       PTXBuilder ptxBuilder;\n       auto *asmArgList = ptxBuilder.newListOperand(asmArgs);\n \n-      Value maskVal = llMask ? maskElems[vecStart] : int_val(1, 1);\n+      Value maskVal = llMask ? and_(mask, maskElems[vecStart]) : mask;\n \n       auto *asmAddr =\n           ptxBuilder.newAddrOperand(ptrElems[vecStart], \"l\", in_off);\n@@ -392,10 +406,10 @@ struct AtomicCASOpConversion\n     auto valElements = getTypeConverter()->unpackLLElements(\n         loc, llVal, rewriter, op.getVal().getType());\n \n-    auto valueTy = op.getResult().getType().dyn_cast<RankedTensorType>();\n+    auto TensorTy = op.getResult().getType().dyn_cast<RankedTensorType>();\n     Type valueElemTy =\n-        valueTy ? getTypeConverter()->convertType(valueTy.getElementType())\n-                : op.getResult().getType();\n+        TensorTy ? getTypeConverter()->convertType(TensorTy.getElementType())\n+                 : op.getResult().getType();\n     auto tid = tid_val();\n     Value pred = icmp_eq(tid, i32_val(0));\n     PTXBuilder ptxBuilderMemfence;\n@@ -462,7 +476,6 @@ struct AtomicRMWOpConversion\n \n     Value val = op.getVal();\n     Value ptr = op.getPtr();\n-    Value _mask = op.getMask();\n \n     Value llPtr = adaptor.getPtr();\n     Value llVal = adaptor.getVal();\n@@ -472,29 +485,32 @@ struct AtomicRMWOpConversion\n         loc, llVal, rewriter, val.getType());\n     auto ptrElements = getTypeConverter()->unpackLLElements(\n         loc, llPtr, rewriter, ptr.getType());\n-    auto maskElements = getTypeConverter()->unpackLLElements(\n-        loc, llMask, rewriter, _mask.getType());\n+    SmallVector<Value> maskElements;\n+    if (llMask)\n+      maskElements = getTypeConverter()->unpackLLElements(\n+          loc, llMask, rewriter, op.getMask().getType());\n \n-    auto valueTy = op.getResult().getType().dyn_cast<RankedTensorType>();\n+    auto tensorTy = op.getResult().getType().dyn_cast<RankedTensorType>();\n     Type valueElemTy =\n-        valueTy ? getTypeConverter()->convertType(valueTy.getElementType())\n-                : op.getResult().getType();\n+        tensorTy ? getTypeConverter()->convertType(tensorTy.getElementType())\n+                 : op.getResult().getType();\n     const size_t valueElemNbits = valueElemTy.getIntOrFloatBitWidth();\n     auto elemsPerThread = getElemsPerThread(val.getType());\n-    // vec = 1 for scalar\n+    // vec = 1, numElements = 1 for scalar\n     auto vec = getVectorSize(ptr);\n-    Value mask = int_val(1, 1);\n-    auto tid = tid_val();\n+    int numElems = 1;\n     // tensor\n-    if (valueTy) {\n+    if (tensorTy) {\n       auto valTy = val.getType().cast<RankedTensorType>();\n       vec = std::min<unsigned>(vec, valTy.getElementType().isF16() ? 2 : 1);\n       // mask\n-      auto shape = valueTy.getShape();\n-      auto numElements = product(shape);\n-      mask = and_(mask, icmp_slt(mul(tid, i32_val(elemsPerThread)),\n-                                 i32_val(numElements)));\n+      auto shape = tensorTy.getShape();\n+      numElems = product(shape);\n     }\n+    Value mask = int_val(1, 1);\n+    auto tid = tid_val();\n+    mask = and_(mask,\n+                icmp_slt(mul(tid, i32_val(elemsPerThread)), i32_val(numElems)));\n \n     auto vecTy = vec_ty(valueElemTy, vec);\n     SmallVector<Value> resultVals(elemsPerThread);\n@@ -507,8 +523,7 @@ struct AtomicRMWOpConversion\n       }\n \n       Value rmwPtr = ptrElements[i];\n-      Value rmwMask = maskElements[i];\n-      rmwMask = and_(rmwMask, mask);\n+      Value rmwMask = llMask ? and_(mask, maskElements[i]) : mask;\n       std::string sTy;\n       PTXBuilder ptxBuilderAtomicRMW;\n       std::string tyId = valueElemNbits * vec == 64\n@@ -561,7 +576,7 @@ struct AtomicRMWOpConversion\n         return failure();\n       }\n       atom.o(rmwOp).o(sTy);\n-      if (valueTy) {\n+      if (tensorTy) {\n         atom(dstOpr, ptrOpr, valOpr).predicate(rmwMask);\n         auto retType = vec == 1 ? valueElemTy : vecTy;\n         auto ret = ptxBuilderAtomicRMW.launch(rewriter, loc, retType);\n@@ -587,8 +602,8 @@ struct AtomicRMWOpConversion\n         rewriter.replaceOp(op, {ret});\n       }\n     }\n-    if (valueTy) {\n-      Type structTy = getTypeConverter()->convertType(valueTy);\n+    if (tensorTy) {\n+      Type structTy = getTypeConverter()->convertType(tensorTy);\n       Value resultStruct = getTypeConverter()->packLLElements(\n           loc, resultVals, rewriter, structTy);\n       rewriter.replaceOp(op, {resultStruct});"}]