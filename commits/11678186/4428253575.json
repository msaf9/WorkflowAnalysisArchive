[{"filename": "python/triton/ops/matmul.py", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "file_content_changes": "@@ -133,17 +133,15 @@ def _call(a, b, dot_out_dtype):\n         # allocates output\n         c = torch.empty((M, N), device=device, dtype=a.dtype)\n         if dot_out_dtype is None:\n-            if a.dtype in [torch.float16, torch.bfloat16]:\n-                dot_out_dtype = tl.float16\n-            elif a.dtype == torch.float32:\n+            if a.dtype in [torch.float16, torch.float32, torch.bfloat16]:\n                 dot_out_dtype = tl.float32\n             else:\n                 dot_out_dtype = tl.int32\n         else:\n             assert isinstance(dot_out_dtype, torch.dtype), \"dot_out_dtype must be a torch.dtype\"\n-            if dot_out_dtype in [torch.float16, torch.bfloat16]:\n+            if dot_out_dtype == torch.float16:\n                 dot_out_dtype = tl.float16\n-            elif dot_out_dtype == torch.float32:\n+            elif dot_out_dtype in [torch.float32, torch.bfloat16]:\n                 dot_out_dtype = tl.float32\n             else:\n                 dot_out_dtype = tl.int32"}]