[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 16, "deletions": 2, "changes": 18, "file_content_changes": "@@ -752,7 +752,15 @@ def noinline_call_graph_fn(x, y, Z):\n     tl.store(Z, z)\n \n \n-@pytest.mark.parametrize(\"mode\", [\"simple\", \"call_graph\"])\n+@triton.jit(noinline=True)\n+def noinline_shared_fn(x, y, Z):\n+    offs = tl.arange(0, 16)[:, None] * 16 + tl.arange(0, 16)[None, :]\n+    z = tl.load(Z + offs)\n+    z = tl.dot(z, z) + x + y\n+    tl.store(Z + offs, z)\n+\n+\n+@pytest.mark.parametrize(\"mode\", [\"simple\", \"call_graph\", \"shared\"])\n def test_noinline(mode):\n     device = 'cuda'\n \n@@ -766,12 +774,18 @@ def kernel(X, Y, Z):\n     kernel = patch_kernel(kernel, {'GENERATE_TEST_HERE': func_name})\n     x = torch.tensor([1.0], device=device, dtype=torch.float32)\n     y = torch.tensor([2.0], device=device, dtype=torch.float32)\n-    z = torch.tensor([0.0], device=device, dtype=torch.float32)\n+    if mode == \"shared\":\n+        z = torch.ones((16, 16), device=device, dtype=torch.float32)\n+    else:\n+        z = torch.tensor([0.0], device=device, dtype=torch.float32)\n     kernel[(1,)](x, y, z, num_warps=1)\n     if mode == \"simple\":\n         assert torch.equal(z, x + y)\n     elif mode == \"call_graph\":\n         assert torch.equal(z, x + 1 + y + 2)\n+    elif mode == \"shared\":\n+        ref = torch.full((16, 16), 16, device=device, dtype=torch.float32)\n+        assert torch.equal(z, ref + x + y)\n \n \n # ---------------"}]