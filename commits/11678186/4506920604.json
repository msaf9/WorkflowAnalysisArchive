[{"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "file_content_changes": "@@ -122,6 +122,7 @@ struct LoadOpConversion\n       const size_t width = std::min(totalWidth, maxWordWidth);\n       const size_t nWords = std::max<size_t>(1, totalWidth / width);\n       const size_t wordNElems = width / valueElemNbits;\n+      const size_t movWidth = width < 16 ? 16 : width;\n       assert(wordNElems * nWords * numVecs == numElems);\n \n       // TODO(Superjomn) Add cache policy fields to StoreOp.\n@@ -137,11 +138,18 @@ struct LoadOpConversion\n       const std::string writeConstraint =\n           (width == 64) ? \"=l\" : ((width == 32) ? \"=r\" : \"=c\");\n \n+      PTXInstr &init =\n+          ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(movWidth));\n+      PTXInstr::Operand *zero = ptxBuilder.newConstantOperand(0);\n+\n       // prepare asm operands\n       auto *dstsOpr = ptxBuilder.newListOperand();\n       for (size_t wordIdx = 0; wordIdx < nWords; ++wordIdx) {\n         auto *opr = ptxBuilder.newOperand(writeConstraint); // =r operations\n         dstsOpr->listAppend(opr);\n+        // Initialize the destination register, otherwise the register will\n+        // be undefined if the predicate is false.\n+        init(opr, zero);\n       }\n \n       auto *addrOpr =\n@@ -175,7 +183,6 @@ struct LoadOpConversion\n       if (other) {\n         for (size_t ii = 0; ii < nWords; ++ii) {\n           // PTX doesn't support mov.u8, so we need to use mov.u16\n-          auto movWidth = width < 16 ? 16 : width;\n           PTXInstr &mov =\n               ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(movWidth));\n "}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 17, "deletions": 9, "changes": 26, "file_content_changes": "@@ -1,4 +1,4 @@\n-// RUN: triton-opt %s -split-input-file --convert-triton-gpu-to-llvm | FileCheck %s\n+// RUN: triton-opt %s -split-input-file --convert-scf-to-cf --convert-triton-gpu-to-llvm | FileCheck %s\n \n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK: llvm.func @test_empty_kernel(%arg0: i64, %arg1: !llvm.ptr<f16, 1>)\n@@ -97,16 +97,24 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n     %8 = tt.addptr %7, %4 : tensor<256x!tt.ptr<f32>, #blocked0>, tensor<256xi32, #blocked0>\n \n     // Load 4 elements from vector0\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n \n     // Load 4 elements from vector1\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n     %9 = tt.load %6 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<256xf32, #blocked0>\n     %10 = tt.load %8 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<256xf32, #blocked0>\n     %11 = arith.addf %9, %10 : tensor<256xf32, #blocked0>"}]