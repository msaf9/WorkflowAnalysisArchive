[{"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -21,11 +21,11 @@ template <typename Int> Int product(llvm::ArrayRef<Int> arr) {\n template <typename Int> Int ceil(Int m, Int n) { return (m + n - 1) / n; }\n \n // output[i] = input[order[i]]\n-template <typename T>\n-SmallVector<T> reorder(ArrayRef<T> input, ArrayRef<unsigned> order) {\n+template <typename T, typename RES_T = T>\n+SmallVector<RES_T> reorder(ArrayRef<T> input, ArrayRef<unsigned> order) {\n   size_t rank = order.size();\n   assert(input.size() == rank);\n-  SmallVector<T> result(rank);\n+  SmallVector<RES_T> result(rank);\n   for (auto it : llvm::enumerate(order)) {\n     result[it.index()] = input[it.value()];\n   }"}, {"filename": "lib/Analysis/Allocation.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -77,7 +77,7 @@ SmallVector<unsigned> getScratchConfigForReduce(triton::ReduceOp op) {\n   auto srcShape = srcTy.getShape();\n   auto axis = op.axis();\n \n-  bool fastReduce = axis == 1; // FIXME(Qingyi): The fastest-changing dimension\n+  bool fastReduce = axis == srcLayout.getOrder()[0];\n \n   SmallVector<unsigned> smemShape;\n   for (auto d : srcShape)"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 277, "deletions": 238, "changes": 515, "file_content_changes": "@@ -83,6 +83,11 @@ static Value createLLVMIntegerConstant(OpBuilder &builder, Location loc,\n \n } // namespace\n \n+// A helper function for using printf in LLVM conversion.\n+void llPrintf(StringRef msg, ValueRange args,\n+              ConversionPatternRewriter &rewriter);\n+\n+// Shortcuts for some commonly used LLVM ops to keep code simple and intuitive//\n // Shortcuts for some commonly used LLVM ops to keep code simple and intuitive\n #define zext(...) rewriter.create<LLVM::ZExtOp>(loc, __VA_ARGS__)\n #define udiv(...) rewriter.create<LLVM::UDivOp>(loc, __VA_ARGS__)\n@@ -338,6 +343,7 @@ Value getStructFromElements(Location loc, ValueRange resultVals,\n   return llvmStruct;\n }\n \n+// Delinearize on compile-time consts, assuming the order is [n, .. 2, 1, 0]\n template <typename T>\n static SmallVector<T> getMultiDimIndex(T linearIndex, ArrayRef<T> shape) {\n   // shape: {a, b, c, d}  ->  accMul: {b*c*d, c*d, d, 1}\n@@ -355,6 +361,7 @@ static SmallVector<T> getMultiDimIndex(T linearIndex, ArrayRef<T> shape) {\n   return multiDimIndex;\n }\n \n+// Linearize on compile-time consts, assuming the order is [n, .. 2, 1, 0]\n template <typename T>\n static T getLinearIndex(ArrayRef<T> multiDimIndex, ArrayRef<T> shape) {\n   assert(multiDimIndex.size() == shape.size());\n@@ -510,12 +517,12 @@ class ConvertTritonGPUOpToLLVMPattern\n       multiDim[0] = linear;\n     } else {\n       Value remained = linear;\n-      for (auto &&en : llvm::enumerate(llvm::reverse(shape.drop_front()))) {\n+      for (auto &&en : llvm::enumerate(shape.drop_back())) {\n         Value dimSize = idx_val(en.value());\n-        multiDim[rank - 1 - en.index()] = urem(remained, dimSize);\n+        multiDim[en.index()] = urem(remained, dimSize);\n         remained = udiv(remained, dimSize);\n       }\n-      multiDim[0] = remained;\n+      multiDim[rank - 1] = remained;\n     }\n     return multiDim;\n   }\n@@ -525,9 +532,9 @@ class ConvertTritonGPUOpToLLVMPattern\n     int rank = multiDim.size();\n     Value linear = idx_val(0);\n     if (rank > 0) {\n-      linear = multiDim.front();\n+      linear = multiDim.back();\n       for (auto [dim, shape] :\n-           llvm::zip(multiDim.drop_front(), shape.drop_front())) {\n+           llvm::reverse(llvm::zip(multiDim.drop_back(), shape.drop_back()))) {\n         Value dimSize = idx_val(shape);\n         linear = add(mul(linear, dimSize), dim);\n       }\n@@ -566,6 +573,7 @@ class ConvertTritonGPUOpToLLVMPattern\n         delinearize(rewriter, loc, warpId, warpsPerCTA, order);\n     SmallVector<Value> multiDimThreadId =\n         delinearize(rewriter, loc, laneId, threadsPerWarp, order);\n+\n     SmallVector<Value> multiDimBase(rank);\n     for (unsigned k = 0; k < rank; ++k) {\n       // Wrap around multiDimWarpId/multiDimThreadId incase\n@@ -1362,7 +1370,9 @@ struct ReduceOpConversion\n LogicalResult\n ReduceOpConversion::matchAndRewrite(triton::ReduceOp op, OpAdaptor adaptor,\n                                     ConversionPatternRewriter &rewriter) const {\n-  if (op.axis() == 1) // FIXME(Qingyi): The fastest-changing dimension\n+  auto srcTy = op.operand().getType().cast<RankedTensorType>();\n+  auto srcLayout = srcTy.getEncoding().cast<BlockedEncodingAttr>();\n+  if (op.axis() == srcLayout.getOrder()[0])\n     return matchAndRewriteFast(op, adaptor, rewriter);\n   return matchAndRewriteBasic(op, adaptor, rewriter);\n }\n@@ -1444,6 +1454,7 @@ LogicalResult ReduceOpConversion::matchAndRewriteBasic(\n \n   auto srcTy = op.operand().getType().cast<RankedTensorType>();\n   auto srcLayout = srcTy.getEncoding().cast<BlockedEncodingAttr>();\n+  auto srcOrd = srcLayout.getOrder();\n   auto srcShape = srcTy.getShape();\n \n   auto llvmElemTy = getTypeConverter()->convertType(srcTy.getElementType());\n@@ -1487,16 +1498,21 @@ LogicalResult ReduceOpConversion::matchAndRewriteBasic(\n     SmallVector<Value> writeIdx = indices[key];\n \n     writeIdx[axis] = udiv(writeIdx[axis], sizePerThread);\n-    Value writeOffset = linearize(rewriter, loc, writeIdx, smemShape);\n+    Value writeOffset =\n+        linearize(rewriter, loc, reorder<Value>(writeIdx, srcOrd),\n+                  reorder<unsigned>(smemShape, srcOrd));\n     Value writePtr = gep(elemPtrTy, smemBase, writeOffset);\n     store(acc, writePtr);\n \n     SmallVector<Value> readIdx(writeIdx.size(), ints[0]);\n     for (int N = smemShape[axis] / 2; N > 0; N >>= 1) {\n       readIdx[axis] = ints[N];\n       Value readMask = icmp_slt(writeIdx[axis], ints[N]);\n-      Value readOffset = select(\n-          readMask, linearize(rewriter, loc, readIdx, smemShape), ints[0]);\n+      Value readOffset =\n+          select(readMask,\n+                 linearize(rewriter, loc, reorder<Value>(readIdx, srcOrd),\n+                           reorder<unsigned>(smemShape, srcOrd)),\n+                 ints[0]);\n       Value readPtr = gep(elemPtrTy, writePtr, readOffset);\n       barrier();\n       accumulate(rewriter, loc, op.redOp(), acc, load(readPtr), false);\n@@ -1519,7 +1535,9 @@ LogicalResult ReduceOpConversion::matchAndRewriteBasic(\n     for (unsigned i = 0; i < resultElems; ++i) {\n       SmallVector<Value> readIdx = resultIndices[i];\n       readIdx.insert(readIdx.begin() + axis, ints[0]);\n-      Value readOffset = linearize(rewriter, loc, readIdx, smemShape);\n+      Value readOffset =\n+          linearize(rewriter, loc, reorder<Value>(readIdx, srcOrd),\n+                    reorder<unsigned>(smemShape, srcOrd));\n       Value readPtr = gep(elemPtrTy, smemBase, readOffset);\n       resultVals[i] = load(readPtr);\n     }\n@@ -1548,6 +1566,7 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n   auto srcTy = op.operand().getType().cast<RankedTensorType>();\n   auto srcLayout = srcTy.getEncoding().cast<BlockedEncodingAttr>();\n   auto srcShape = srcTy.getShape();\n+  auto srcRank = srcTy.getRank();\n \n   auto threadsPerWarp = srcLayout.getThreadsPerWarp();\n   auto warpsPerCTA = srcLayout.getWarpsPerCTA();\n@@ -1592,6 +1611,7 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n       delinearize(rewriter, loc, laneId, threadsPerWarp, order);\n   SmallVector<Value> multiDimWarpId =\n       delinearize(rewriter, loc, warpId, warpsPerCTA, order);\n+\n   Value laneIdAxis = multiDimLaneId[axis];\n   Value warpIdAxis = multiDimWarpId[axis];\n \n@@ -1609,56 +1629,77 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n       accumulate(rewriter, loc, op.redOp(), acc, shfl, false);\n     }\n \n-    if (sizeInterWarps == 1) {\n-      SmallVector<Value> writeIdx = indices[key];\n-      writeIdx[axis] = zero;\n-      Value writeOffset = linearize(rewriter, loc, writeIdx, smemShape);\n-      Value writePtr = gep(elemPtrTy, smemBase, writeOffset);\n-      storeShared(rewriter, loc, writePtr, acc, laneZero);\n-    } else {\n-      SmallVector<Value> writeIdx = indices[key];\n-      writeIdx[axis] =\n-          warpIdAxis; // axis must be the fastest-changing dimension\n-      Value writeOffset = linearize(rewriter, loc, writeIdx, smemShape);\n-      Value writePtr = gep(elemPtrTy, smemBase, writeOffset);\n-      storeShared(rewriter, loc, writePtr, acc, laneZero);\n-      barrier();\n+    SmallVector<Value> writeIdx = indices[key];\n+    writeIdx[axis] = (sizeInterWarps == 1) ? zero : warpIdAxis;\n+    Value writeOffset =\n+        linearize(rewriter, loc, reorder<Value>(writeIdx, order),\n+                  reorder<unsigned>(smemShape, order));\n+    Value writePtr = gep(elemPtrTy, smemBase, writeOffset);\n+    storeShared(rewriter, loc, writePtr, acc, laneZero);\n+  }\n \n-      SmallVector<Value> readIdx = writeIdx;\n-      readIdx[axis] = urem(laneId, i32_val(sizeInterWarps));\n-      Value readOffset = linearize(rewriter, loc, readIdx, smemShape);\n-      Value readPtr = gep(elemPtrTy, smemBase, readOffset);\n-      acc = load(readPtr);\n+  barrier();\n \n-      // reduce across warps\n-      for (unsigned N = sizeInterWarps / 2; N > 0; N >>= 1) {\n-        Value shfl = shflSync(rewriter, loc, acc, N);\n-        accumulate(rewriter, loc, op.redOp(), acc, shfl, false);\n-      }\n+  // the second round of shuffle reduction\n+  //   now the problem size: sizeInterWarps, s1, s2, .. , sn  =>\n+  //                                      1, s1, s2, .. , sn\n+  //   where sizeInterWarps is 2^m\n+  //\n+  // each thread needs to process:\n+  //   elemsPerThread = sizeInterWarps * s1 * s2 .. Sn / numThreads\n+  unsigned elems = product<unsigned>(smemShape);\n+  unsigned numThreads = product<unsigned>(srcLayout.getWarpsPerCTA()) * 32;\n+  unsigned elemsPerThread = std::max<unsigned>(elems / numThreads, 1);\n+  Value readOffset = threadId;\n+  for (unsigned round = 0; round < elemsPerThread; ++round) {\n+    Value readPtr = gep(elemPtrTy, smemBase, readOffset);\n+    Value acc = load(readPtr);\n+\n+    for (unsigned N = sizeInterWarps / 2; N > 0; N >>= 1) {\n+      Value shfl = shflSync(rewriter, loc, acc, N);\n+      accumulate(rewriter, loc, op.redOp(), acc, shfl, false);\n+    }\n \n-      writeIdx[axis] = zero;\n-      writeOffset = linearize(rewriter, loc, writeIdx, smemShape);\n-      writePtr = gep(elemPtrTy, smemBase, writeOffset);\n-      storeShared(rewriter, loc, writePtr, acc, and_(laneZero, warpZero));\n+    Value writeOffset = udiv(readOffset, i32_val(sizeInterWarps));\n+    Value writePtr = gep(elemPtrTy, smemBase, writeOffset);\n+    Value threadIsNeeded = icmp_slt(threadId, i32_val(elems));\n+    Value laneIdModSizeInterWarps = urem(laneId, i32_val(sizeInterWarps));\n+    Value laneIdModSizeInterWarpsIsZero =\n+        icmp_eq(laneIdModSizeInterWarps, zero);\n+    storeShared(rewriter, loc, writePtr, acc,\n+                and_(threadIsNeeded, laneIdModSizeInterWarpsIsZero));\n+\n+    if (round != elemsPerThread - 1) {\n+      readOffset = add(readOffset, i32_val(numThreads));\n     }\n   }\n \n+  // We could avoid this barrier in some of the layouts, however this is not\n+  // the general case. TODO: optimize the barrier incase the layouts are\n+  // accepted.\n+  barrier();\n+\n   // set output values\n   if (auto resultTy = op.getType().dyn_cast<RankedTensorType>()) {\n     // nd-tensor where n >= 1\n     auto resultLayout = resultTy.getEncoding().cast<SliceEncodingAttr>();\n     auto resultShape = resultTy.getShape();\n+    SmallVector<unsigned> resultOrd;\n+    for (auto ord : order) {\n+      if (ord != 0)\n+        resultOrd.push_back(ord - 1);\n+    }\n \n     unsigned resultElems = getElemsPerThread(resultTy);\n     auto resultIndices = emitIndices(loc, rewriter, resultLayout, resultShape);\n     assert(resultIndices.size() == resultElems);\n \n-    barrier();\n     SmallVector<Value> resultVals(resultElems);\n     for (size_t i = 0; i < resultElems; ++i) {\n       SmallVector<Value> readIdx = resultIndices[i];\n-      readIdx.insert(readIdx.begin() + axis, i32_val(0));\n-      Value readOffset = linearize(rewriter, loc, readIdx, smemShape);\n+      Value readOffset =\n+          linearize(rewriter, loc, reorder<Value>(readIdx, resultOrd),\n+                    reorder<long, unsigned>(resultShape, resultOrd));\n       Value readPtr = gep(elemPtrTy, smemBase, readOffset);\n       resultVals[i] = load(readPtr);\n     }\n@@ -1670,7 +1711,6 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n     rewriter.replaceOp(op, ret);\n   } else {\n     // 0d-tensor -> scalar\n-    barrier();\n     Value resultVal = load(smemBase);\n     rewriter.replaceOp(op, resultVal);\n   }\n@@ -1707,6 +1747,191 @@ struct ViewLikeOpConversion : public ConvertTritonGPUOpToLLVMPattern<SourceOp> {\n   }\n };\n \n+struct PrintfOpConversion\n+    : public ConvertTritonGPUOpToLLVMPattern<triton::PrintfOp> {\n+  using ConvertTritonGPUOpToLLVMPattern<\n+      triton::PrintfOp>::ConvertTritonGPUOpToLLVMPattern;\n+\n+  LogicalResult\n+  matchAndRewrite(triton::PrintfOp op, OpAdaptor adaptor,\n+                  ConversionPatternRewriter &rewriter) const override {\n+    auto loc = op->getLoc();\n+    SmallVector<Value, 16> operands;\n+    for (auto operand : adaptor.getOperands()) {\n+      auto sub_operands = this->getElementsFromStruct(loc, operand, rewriter);\n+      for (auto elem : sub_operands) {\n+        operands.push_back(elem);\n+      }\n+    }\n+    std::string formatStr;\n+    llvm::raw_string_ostream os(formatStr);\n+    os << op.prefix();\n+    if (operands.size() > 0) {\n+      os << getFormatSubstr(operands[0]);\n+    }\n+\n+    for (size_t i = 1; i < operands.size(); ++i) {\n+      os << \", \" << getFormatSubstr(operands[i]);\n+    }\n+    llPrintf(formatStr, operands, rewriter);\n+    rewriter.eraseOp(op);\n+    return success();\n+  }\n+  // get format specific for each input value\n+  // currently support pointer, i8, i16, i32, i64, f16, bf16, f32, f64\n+  std::string getFormatSubstr(Value value) const {\n+    Type type = value.getType();\n+    unsigned width = type.getIntOrFloatBitWidth();\n+\n+    if (type.isa<LLVM::LLVMPointerType>()) {\n+      return \"%p\";\n+    } else if (type.isBF16() || type.isF16() || type.isF32() || type.isF64()) {\n+      return \"%f\";\n+    } else if (type.isSignedInteger()) {\n+      return \"%i\";\n+    } else if (type.isUnsignedInteger() || type.isSignlessInteger()) {\n+      return \"%u\";\n+    }\n+    assert(false && \"not supported type\");\n+  }\n+\n+  // declare vprintf(i8*, i8*) as external function\n+  static LLVM::LLVMFuncOp\n+  getVprintfDeclaration(ConversionPatternRewriter &rewriter) {\n+    auto moduleOp =\n+        rewriter.getBlock()->getParent()->getParentOfType<ModuleOp>();\n+    StringRef funcName(\"vprintf\");\n+    Operation *funcOp = moduleOp.lookupSymbol(funcName);\n+    if (funcOp)\n+      return cast<LLVM::LLVMFuncOp>(*funcOp);\n+\n+    auto *context = rewriter.getContext();\n+\n+    SmallVector<Type> argsType{ptr_ty(IntegerType::get(context, 8)),\n+                               ptr_ty(IntegerType::get(context, 8))};\n+    auto funcType = LLVM::LLVMFunctionType::get(i32_ty, argsType);\n+\n+    ConversionPatternRewriter::InsertionGuard guard(rewriter);\n+    rewriter.setInsertionPointToStart(moduleOp.getBody());\n+\n+    return rewriter.create<LLVM::LLVMFuncOp>(UnknownLoc::get(context), funcName,\n+                                             funcType);\n+  }\n+\n+  // extend integer to int32, extend float to float64\n+  // this comes from vprintf alignment requirements.\n+  static std::pair<Type, Value>\n+  promoteValue(ConversionPatternRewriter &rewriter, Value value) {\n+    auto *context = rewriter.getContext();\n+    auto type = value.getType();\n+    type.dump();\n+    unsigned width = type.getIntOrFloatBitWidth();\n+    Value newOp = value;\n+    Type newType = type;\n+\n+    bool bUnsigned = type.isUnsignedInteger();\n+    if (type.isIntOrIndex() && width < 32) {\n+      if (bUnsigned) {\n+        newType = ui32_ty;\n+        newOp = rewriter.create<LLVM::ZExtOp>(UnknownLoc::get(context), newType,\n+                                              value);\n+      } else {\n+        newType = i32_ty;\n+        newOp = rewriter.create<LLVM::SExtOp>(UnknownLoc::get(context), newType,\n+                                              value);\n+      }\n+    } else if (type.isBF16() || type.isF16() || type.isF32()) {\n+      newType = f64_ty;\n+      newOp = rewriter.create<LLVM::FPExtOp>(UnknownLoc::get(context), newType,\n+                                             value);\n+    }\n+\n+    return {newType, newOp};\n+  }\n+\n+  static void llPrintf(StringRef msg, ValueRange args,\n+                       ConversionPatternRewriter &rewriter) {\n+    static const char formatStringPrefix[] = \"printfFormat_\";\n+    assert(!msg.empty() && \"printf with empty string not support\");\n+    Type int8Ptr = ptr_ty(i8_ty);\n+\n+    auto *context = rewriter.getContext();\n+    auto moduleOp =\n+        rewriter.getBlock()->getParent()->getParentOfType<ModuleOp>();\n+    auto funcOp = getVprintfDeclaration(rewriter);\n+\n+    Value one = rewriter.create<LLVM::ConstantOp>(\n+        UnknownLoc::get(context), i32_ty, rewriter.getI32IntegerAttr(1));\n+    Value zero = rewriter.create<LLVM::ConstantOp>(\n+        UnknownLoc::get(context), i32_ty, rewriter.getI32IntegerAttr(0));\n+\n+    unsigned stringNumber = 0;\n+    SmallString<16> stringConstName;\n+    do {\n+      stringConstName.clear();\n+      (formatStringPrefix + Twine(stringNumber++)).toStringRef(stringConstName);\n+    } while (moduleOp.lookupSymbol(stringConstName));\n+\n+    llvm::SmallString<64> formatString(msg);\n+    formatString.push_back('\\n');\n+    formatString.push_back('\\0');\n+    size_t formatStringSize = formatString.size_in_bytes();\n+    auto globalType = LLVM::LLVMArrayType::get(i8_ty, formatStringSize);\n+\n+    LLVM::GlobalOp global;\n+    {\n+      ConversionPatternRewriter::InsertionGuard guard(rewriter);\n+      rewriter.setInsertionPointToStart(moduleOp.getBody());\n+      global = rewriter.create<LLVM::GlobalOp>(\n+          UnknownLoc::get(context), globalType,\n+          /*isConstant=*/true, LLVM::Linkage::Internal, stringConstName,\n+          rewriter.getStringAttr(formatString));\n+    }\n+\n+    Value globalPtr =\n+        rewriter.create<LLVM::AddressOfOp>(UnknownLoc::get(context), global);\n+    Value stringStart =\n+        rewriter.create<LLVM::GEPOp>(UnknownLoc::get(context), int8Ptr,\n+                                     globalPtr, mlir::ValueRange({zero, zero}));\n+\n+    Value bufferPtr =\n+        rewriter.create<LLVM::NullOp>(UnknownLoc::get(context), int8Ptr);\n+\n+    SmallVector<Value, 16> newArgs;\n+    if (args.size() >= 1) {\n+      SmallVector<Type> argTypes;\n+      for (auto arg : args) {\n+        Type newType;\n+        Value newArg;\n+        std::tie(newType, newArg) = promoteValue(rewriter, arg);\n+        argTypes.push_back(newType);\n+        newArgs.push_back(newArg);\n+      }\n+\n+      Type structTy = LLVM::LLVMStructType::getLiteral(context, argTypes);\n+      auto allocated = rewriter.create<LLVM::AllocaOp>(UnknownLoc::get(context),\n+                                                       ptr_ty(structTy), one,\n+                                                       /*alignment=*/0);\n+\n+      for (const auto &entry : llvm::enumerate(newArgs)) {\n+        auto index = rewriter.create<LLVM::ConstantOp>(\n+            UnknownLoc::get(context), i32_ty,\n+            rewriter.getI32IntegerAttr(entry.index()));\n+        auto fieldPtr = rewriter.create<LLVM::GEPOp>(\n+            UnknownLoc::get(context), ptr_ty(argTypes[entry.index()]),\n+            allocated, ArrayRef<Value>{zero, index});\n+        rewriter.create<LLVM::StoreOp>(UnknownLoc::get(context), entry.value(),\n+                                       fieldPtr);\n+      }\n+      bufferPtr = rewriter.create<LLVM::BitcastOp>(UnknownLoc::get(context),\n+                                                   int8Ptr, allocated);\n+    }\n+\n+    ValueRange operands{stringStart, bufferPtr};\n+    rewriter.create<LLVM::CallOp>(UnknownLoc::get(context), funcOp, operands);\n+  }\n+};\n+\n struct MakeRangeOpConversion\n     : public ConvertTritonGPUOpToLLVMPattern<triton::MakeRangeOp> {\n \n@@ -2070,17 +2295,6 @@ struct ConvertLayoutOpConversion\n   }\n \n private:\n-  template <typename T>\n-  SmallVector<T> reorder(ArrayRef<T> input, ArrayRef<unsigned> order) const {\n-    size_t rank = order.size();\n-    assert(input.size() == rank);\n-    SmallVector<T> result(rank);\n-    for (auto it : llvm::enumerate(order)) {\n-      result[rank - 1 - it.value()] = input[it.index()];\n-    }\n-    return result;\n-  };\n-\n   // shared memory rd/st for blocked or mma layout with data padding\n   void processReplica(Location loc, ConversionPatternRewriter &rewriter,\n                       bool stNotRd, RankedTensorType type,\n@@ -4483,7 +4697,7 @@ struct InsertSliceAsyncOpConversion\n     auto numVecCols = std::max<unsigned>(inVec / outVec, 1);\n \n     auto srcIndices = emitIndices(loc, rewriter, srcBlockedLayout, srcShape);\n-    // <<tileVecIdxRow, tileVecIdxCol>, TileOffset>\n+    //  <<tileVecIdxRow, tileVecIdxCol>, TileOffset>\n     DenseMap<std::pair<unsigned, unsigned>, Value> tileOffsetMap;\n     for (unsigned elemIdx = 0; elemIdx < numElems; elemIdx += minVec) {\n       // minVec = 2, inVec = 4, outVec = 2\n@@ -4674,190 +4888,6 @@ struct FDivOpConversion\n   }\n };\n \n-struct PrintfOpConversion\n-    : public ConvertTritonGPUOpToLLVMPattern<triton::PrintfOp> {\n-  using ConvertTritonGPUOpToLLVMPattern<\n-      triton::PrintfOp>::ConvertTritonGPUOpToLLVMPattern;\n-\n-  LogicalResult\n-  matchAndRewrite(triton::PrintfOp op, OpAdaptor adaptor,\n-                  ConversionPatternRewriter &rewriter) const override {\n-    auto loc = op->getLoc();\n-    SmallVector<Value, 16> operands;\n-    for (auto operand : adaptor.getOperands()) {\n-      auto sub_operands = this->getElementsFromStruct(loc, operand, rewriter);\n-      for (auto elem : sub_operands) {\n-        operands.push_back(elem);\n-      }\n-    }\n-    std::string formatStr;\n-    llvm::raw_string_ostream os(formatStr);\n-    os << op.prefix();\n-    if (operands.size() > 0) {\n-      os << getFormatSubstr(operands[0]);\n-    }\n-\n-    for (size_t i = 1; i < operands.size(); ++i) {\n-      os << \", \" << getFormatSubstr(operands[i]);\n-    }\n-    llPrintf(formatStr, operands, rewriter);\n-    rewriter.eraseOp(op);\n-    return success();\n-  }\n-  // get format specific for each input value\n-  // currently support pointer, i8, i16, i32, i64, f16, bf16, f32, f64\n-  std::string getFormatSubstr(Value value) const {\n-    Type type = value.getType();\n-    unsigned width = type.getIntOrFloatBitWidth();\n-\n-    if (type.isa<LLVM::LLVMPointerType>()) {\n-      return \"%p\";\n-    } else if (type.isBF16() || type.isF16() || type.isF32() || type.isF64()) {\n-      return \"%f\";\n-    } else if (type.isSignedInteger()) {\n-      return \"%i\";\n-    } else if (type.isUnsignedInteger() || type.isSignlessInteger()) {\n-      return \"%u\";\n-    }\n-    assert(false && \"not supported type\");\n-  }\n-\n-  // declare vprintf(i8*, i8*) as external function\n-  LLVM::LLVMFuncOp\n-  getVprintfDeclaration(ConversionPatternRewriter &rewriter) const {\n-    auto moduleOp =\n-        rewriter.getBlock()->getParent()->getParentOfType<ModuleOp>();\n-    StringRef funcName(\"vprintf\");\n-    Operation *funcOp = moduleOp.lookupSymbol(funcName);\n-    if (funcOp)\n-      return cast<LLVM::LLVMFuncOp>(*funcOp);\n-\n-    auto *context = rewriter.getContext();\n-\n-    SmallVector<Type> argsType{ptr_ty(IntegerType::get(context, 8)),\n-                               ptr_ty(IntegerType::get(context, 8))};\n-    auto funcType = LLVM::LLVMFunctionType::get(i32_ty, argsType);\n-\n-    ConversionPatternRewriter::InsertionGuard guard(rewriter);\n-    rewriter.setInsertionPointToStart(moduleOp.getBody());\n-\n-    return rewriter.create<LLVM::LLVMFuncOp>(UnknownLoc::get(context), funcName,\n-                                             funcType);\n-  }\n-\n-  // extend integer to int32, extend float to float64\n-  // this comes from vprintf alignment requirements.\n-  std::pair<Type, Value> promoteValue(ConversionPatternRewriter &rewriter,\n-                                      Value value) const {\n-    auto *context = rewriter.getContext();\n-    auto type = value.getType();\n-    unsigned width = type.getIntOrFloatBitWidth();\n-    Value newOp = value;\n-    Type newType = type;\n-\n-    bool bUnsigned = type.isUnsignedInteger();\n-    if (type.isIntOrIndex() && width < 32) {\n-      if (bUnsigned) {\n-        newType = ui32_ty;\n-        newOp = rewriter.create<LLVM::ZExtOp>(UnknownLoc::get(context), newType,\n-                                              value);\n-      } else {\n-        newType = i32_ty;\n-        newOp = rewriter.create<LLVM::SExtOp>(UnknownLoc::get(context), newType,\n-                                              value);\n-      }\n-    } else if (type.isBF16() || type.isF16() || type.isF32()) {\n-      newType = f64_ty;\n-      newOp = rewriter.create<LLVM::FPExtOp>(UnknownLoc::get(context), newType,\n-                                             value);\n-    }\n-\n-    return {newType, newOp};\n-  }\n-\n-  void llPrintf(StringRef msg, ValueRange args,\n-                ConversionPatternRewriter &rewriter) const {\n-    static const char formatStringPrefix[] = \"printfFormat_\";\n-    assert(!msg.empty() && \"printf with empty string not support\");\n-    Type int8Ptr = ptr_ty(i8_ty);\n-\n-    auto *context = rewriter.getContext();\n-    auto moduleOp =\n-        rewriter.getBlock()->getParent()->getParentOfType<ModuleOp>();\n-    auto funcOp = getVprintfDeclaration(rewriter);\n-\n-    Value one = rewriter.create<LLVM::ConstantOp>(\n-        UnknownLoc::get(context), i32_ty, rewriter.getI32IntegerAttr(1));\n-    Value zero = rewriter.create<LLVM::ConstantOp>(\n-        UnknownLoc::get(context), i32_ty, rewriter.getI32IntegerAttr(0));\n-\n-    unsigned stringNumber = 0;\n-    SmallString<16> stringConstName;\n-    do {\n-      stringConstName.clear();\n-      (formatStringPrefix + Twine(stringNumber++)).toStringRef(stringConstName);\n-    } while (moduleOp.lookupSymbol(stringConstName));\n-\n-    llvm::SmallString<64> formatString(msg);\n-    formatString.push_back('\\n');\n-    formatString.push_back('\\0');\n-    size_t formatStringSize = formatString.size_in_bytes();\n-    auto globalType = LLVM::LLVMArrayType::get(i8_ty, formatStringSize);\n-\n-    LLVM::GlobalOp global;\n-    {\n-      ConversionPatternRewriter::InsertionGuard guard(rewriter);\n-      rewriter.setInsertionPointToStart(moduleOp.getBody());\n-      global = rewriter.create<LLVM::GlobalOp>(\n-          UnknownLoc::get(context), globalType,\n-          /*isConstant=*/true, LLVM::Linkage::Internal, stringConstName,\n-          rewriter.getStringAttr(formatString));\n-    }\n-\n-    Value globalPtr =\n-        rewriter.create<LLVM::AddressOfOp>(UnknownLoc::get(context), global);\n-    Value stringStart =\n-        rewriter.create<LLVM::GEPOp>(UnknownLoc::get(context), int8Ptr,\n-                                     globalPtr, mlir::ValueRange({zero, zero}));\n-\n-    Value bufferPtr =\n-        rewriter.create<LLVM::NullOp>(UnknownLoc::get(context), int8Ptr);\n-\n-    SmallVector<Value, 16> newArgs;\n-    if (args.size() >= 1) {\n-      SmallVector<Type> argTypes;\n-      for (auto arg : args) {\n-        Type newType;\n-        Value newArg;\n-        std::tie(newType, newArg) = promoteValue(rewriter, arg);\n-        argTypes.push_back(newType);\n-        newArgs.push_back(newArg);\n-      }\n-\n-      Type structTy = LLVM::LLVMStructType::getLiteral(context, argTypes);\n-      auto allocated = rewriter.create<LLVM::AllocaOp>(UnknownLoc::get(context),\n-                                                       ptr_ty(structTy), one,\n-                                                       /*alignment=*/0);\n-\n-      for (const auto &entry : llvm::enumerate(newArgs)) {\n-        auto index = rewriter.create<LLVM::ConstantOp>(\n-            UnknownLoc::get(context), i32_ty,\n-            rewriter.getI32IntegerAttr(entry.index()));\n-        auto fieldPtr = rewriter.create<LLVM::GEPOp>(\n-            UnknownLoc::get(context), ptr_ty(argTypes[entry.index()]),\n-            allocated, ArrayRef<Value>{zero, index});\n-        rewriter.create<LLVM::StoreOp>(UnknownLoc::get(context), entry.value(),\n-                                       fieldPtr);\n-      }\n-      bufferPtr = rewriter.create<LLVM::BitcastOp>(UnknownLoc::get(context),\n-                                                   int8Ptr, allocated);\n-    }\n-\n-    ValueRange operands{stringStart, bufferPtr};\n-    rewriter.create<LLVM::CallOp>(UnknownLoc::get(context), funcOp, operands);\n-  }\n-};\n-\n void populateTritonToLLVMPatterns(mlir::LLVMTypeConverter &typeConverter,\n                                   RewritePatternSet &patterns, int numWarps,\n                                   AxisInfoAnalysis &axisInfoAnalysis,\n@@ -5062,6 +5092,15 @@ void ConvertTritonGPUToLLVM::initSharedMemory(\n \n namespace mlir {\n \n+namespace LLVM {\n+\n+void llPrintf(StringRef msg, ValueRange args,\n+              ConversionPatternRewriter &rewriter) {\n+  PrintfOpConversion::llPrintf(msg, args, rewriter);\n+}\n+\n+} // namespace LLVM\n+\n TritonLLVMConversionTarget::TritonLLVMConversionTarget(\n     MLIRContext &ctx, mlir::LLVMTypeConverter &typeConverter)\n     : ConversionTarget(ctx) {"}, {"filename": "python/tests/test_reduce.py", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "file_content_changes": "@@ -97,9 +97,7 @@ def test_reduce1d(op, dtype, shape):\n     (op, dtype, shape, axis)\n     for op in ['sum', 'min', 'max']\n     for dtype in dtypes\n-    for shape in [(1, 4), (1, 8), (1, 16), (1, 32), (2, 32), (4, 32)]\n-    # TODO: fix and uncomment\n-    #, (4, 128), (32, 64)]\n+    for shape in [(1, 4), (1, 8), (1, 16), (1, 32), (2, 32), (4, 32), (4, 128), (32, 64)]\n     for axis in [0, 1]\n ]\n \n@@ -128,7 +126,6 @@ def test_reduce2d(op, dtype, shape, axis):\n         golden_z = torch.min(x, dim=axis, keepdim=False)[0].to(reduced_dtype)\n     else:\n         golden_z = torch.max(x, dim=axis, keepdim=False)[0].to(reduced_dtype)\n-\n     if dtype.is_floating_point and op == 'sum':\n         if shape[axis] >= 256:\n             assert_close(z, golden_z, rtol=0.05, atol=0.1)"}]