[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -3068,6 +3068,7 @@ DotOpConversion::convertMMA16816(triton::DotOp op, OpAdaptor adaptor,\n \n   Value A = op.a();\n   Value B = op.b();\n+  Value C = op.c();\n   auto ATensorTy = A.getType().cast<RankedTensorType>();\n   auto BTensorTy = B.getType().cast<RankedTensorType>();\n \n@@ -3089,8 +3090,8 @@ DotOpConversion::convertMMA16816(triton::DotOp op, OpAdaptor adaptor,\n   // mattered.\n   loadedC = mmaHelper.loadC(op.c());\n \n-  return mmaHelper.convertDot(op.a(), op.b(), op.c(), op.d(), loadedA, loadedB,\n-                              loadedC, op, adaptor);\n+  return mmaHelper.convertDot(A, B, C, op.d(), loadedA, loadedB, loadedC, op,\n+                              adaptor);\n }\n \n /// ====================== mma codegen end ============================"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 11, "deletions": 49, "changes": 60, "file_content_changes": "@@ -716,63 +716,25 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n }\n \n // -----\n-#blocked0 = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [32, 1], warpsPerCTA = [1, 4], order = [1, 0]}>\n-#blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [1, 4], order = [1, 0]}>\n-#blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [1, 4], order = [1, 0]}>\n-#mma = #triton_gpu.mma<{version = 2, warpsPerCTA = [2, 2]}>\n+#blocked = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [1, 4], order = [1, 0]}>\n #shared = #triton_gpu.shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>\n+#mma = #triton_gpu.mma<{version = 2, warpsPerCTA = [2, 2]}>\n #dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma}>\n #dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  func @matmul_kernel_dot_operand_layout(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}) {\n+  func @matmul_kernel_dot_operand_layout(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n+  %a:tensor<128x32xf16, #shared>, %b:tensor<32x256xf16, #shared>) {\n     %cst = arith.constant dense<0.000000e+00> : tensor<128x256xf32, #mma>\n-    %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked0}>>\n-    %1 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>\n-    %2 = tt.splat %arg3 : (i32) -> tensor<128x1xi32, #blocked0>\n-    %3 = tt.splat %arg0 : (!tt.ptr<f16>) -> tensor<128x1x!tt.ptr<f16>, #blocked0>\n-    %4 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked0}>>\n-    %5 = tt.expand_dims %4 {axis = 0 : i32} : (tensor<32xi32, #triton_gpu.slice<{dim = 0, parent = #blocked0}>>) -> tensor<1x32xi32, #blocked0>\n-    %6 = tt.broadcast %5 : (tensor<1x32xi32, #blocked0>) -> tensor<128x32xi32, #blocked0>\n-    %7 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>\n-    %8 = tt.splat %arg4 : (i32) -> tensor<32x1xi32, #blocked1>\n-    %9 = tt.splat %arg1 : (!tt.ptr<f16>) -> tensor<32x1x!tt.ptr<f16>, #blocked1>\n-    %10 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #triton_gpu.slice<{dim = 0, parent = #blocked1}>>\n-    %11 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #triton_gpu.slice<{dim = 0, parent = #blocked2}>>\n-    %12 = tt.expand_dims %7 {axis = 1 : i32} : (tensor<32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>) -> tensor<32x1xi32, #blocked1>\n-    %13 = arith.muli %12, %8 : tensor<32x1xi32, #blocked1>\n-    %14 = tt.addptr %9, %13 : tensor<32x1x!tt.ptr<f16>, #blocked1>\n-    %15 = tt.broadcast %14 : (tensor<32x1x!tt.ptr<f16>, #blocked1>) -> tensor<32x256x!tt.ptr<f16>, #blocked1>\n-    %16 = tt.expand_dims %10 {axis = 0 : i32} : (tensor<256xi32, #triton_gpu.slice<{dim = 0, parent = #blocked1}>>) -> tensor<1x256xi32, #blocked1>\n-    %17 = tt.broadcast %16 : (tensor<1x256xi32, #blocked1>) -> tensor<32x256xi32, #blocked1>\n-    %18 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked0}>>) -> tensor<128x1xi32, #blocked0>\n-    %19 = arith.muli %18, %2 : tensor<128x1xi32, #blocked0>\n-    %20 = tt.addptr %3, %19 : tensor<128x1x!tt.ptr<f16>, #blocked0>\n-    %21 = tt.broadcast %20 : (tensor<128x1x!tt.ptr<f16>, #blocked0>) -> tensor<128x32x!tt.ptr<f16>, #blocked0>\n-    %22 = tt.addptr %21, %6 : tensor<128x32x!tt.ptr<f16>, #blocked0>\n-    %23 = tt.load %22 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<128x32xf16, #blocked0>\n-    %24 = tt.addptr %15, %17 : tensor<32x256x!tt.ptr<f16>, #blocked1>\n-    %25 = tt.load %24 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<32x256xf16, #blocked1>\n-    %26 = triton_gpu.convert_layout %23 : (tensor<128x32xf16, #blocked0>) -> tensor<128x32xf16, #shared>\n-    %27 = triton_gpu.convert_layout %25 : (tensor<32x256xf16, #blocked1>) -> tensor<32x256xf16, #shared>\n-\n-    // add convert_layout[shared->dot_op] for dot's operands $a and $b.\n-\n     // CHECK: ldmatrix.sync.aligned.m8n8.x4.shared.b16\n-    %a_mat = triton_gpu.convert_layout %26 : (tensor<128x32xf16, #shared>) -> tensor<128x32xf16, #dot_operand_a>\n-    %b_mat = triton_gpu.convert_layout %27 : (tensor<32x256xf16, #shared>) -> tensor<32x256xf16, #dot_operand_b>\n+    %a_mat = triton_gpu.convert_layout %a : (tensor<128x32xf16, #shared>) -> tensor<128x32xf16, #dot_operand_a>\n+    %b_mat = triton_gpu.convert_layout %b : (tensor<32x256xf16, #shared>) -> tensor<32x256xf16, #dot_operand_b>\n \n     %28 = tt.dot %a_mat, %b_mat, %cst {allowTF32 = true, transA = false, transB = false} : tensor<128x32xf16, #dot_operand_a> * tensor<32x256xf16, #dot_operand_b> -> tensor<128x256xf32, #mma>\n-    %29 = tt.splat %arg5 : (i32) -> tensor<128x1xi32, #blocked2>\n-    %30 = tt.splat %arg2 : (!tt.ptr<f32>) -> tensor<128x1x!tt.ptr<f32>, #blocked2>\n-    %31 = tt.expand_dims %11 {axis = 0 : i32} : (tensor<256xi32, #triton_gpu.slice<{dim = 0, parent = #blocked2}>>) -> tensor<1x256xi32, #blocked2>\n-    %32 = tt.broadcast %31 : (tensor<1x256xi32, #blocked2>) -> tensor<128x256xi32, #blocked2>\n-    %33 = tt.expand_dims %1 {axis = 1 : i32} : (tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>) -> tensor<128x1xi32, #blocked2>\n-    %34 = arith.muli %33, %29 : tensor<128x1xi32, #blocked2>\n-    %35 = tt.addptr %30, %34 : tensor<128x1x!tt.ptr<f32>, #blocked2>\n-    %36 = tt.broadcast %35 : (tensor<128x1x!tt.ptr<f32>, #blocked2>) -> tensor<128x256x!tt.ptr<f32>, #blocked2>\n-    %37 = tt.addptr %36, %32 : tensor<128x256x!tt.ptr<f32>, #blocked2>\n-    %38 = triton_gpu.convert_layout %28 : (tensor<128x256xf32, #mma>) -> tensor<128x256xf32, #blocked2>\n-    tt.store %37, %38 : tensor<128x256xf32, #blocked2>\n+    %38 = triton_gpu.convert_layout %28 : (tensor<128x256xf32, #mma>) -> tensor<128x256xf32, #blocked>\n+\n+    %30 = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<128x1x!tt.ptr<f32>, #blocked>\n+    %36 = tt.broadcast %30 : (tensor<128x1x!tt.ptr<f32>, #blocked>) -> tensor<128x256x!tt.ptr<f32>, #blocked>\n+    tt.store %36, %38 : tensor<128x256xf32, #blocked>\n     return\n   }\n }"}]