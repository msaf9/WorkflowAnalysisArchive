[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -1501,7 +1501,7 @@ def test_store_op(M, src_layout, device='cuda'):\n     ir = f\"\"\"\n     #src = {src_layout}\n     module attributes {{\"triton_gpu.num-warps\" = 4 : i32}} {{\n-        tt.func public @load_kernel(%arg0: !tt.ptr<f32> {{tt.divisibility = 16 : i32}}, %arg1: !tt.ptr<f32> {{tt.divisibility = 16 : i32}}) {{\n+        tt.func public @kernel(%arg0: !tt.ptr<f32> {{tt.divisibility = 16 : i32}}, %arg1: !tt.ptr<f32> {{tt.divisibility = 16 : i32}}) {{\n             %0 = tt.make_range {{end = {M} : i32, start = 0 : i32}} : tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n             %1 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<{M}x!tt.ptr<f32>, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n             %2 = tt.addptr %1, %0 : tensor<{M}x!tt.ptr<f32>, #triton_gpu.slice<{{dim = 1, parent = #src}}>>, tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n@@ -1521,15 +1521,15 @@ def test_store_op(M, src_layout, device='cuda'):\n     with tempfile.NamedTemporaryFile(mode='w', suffix='.ttgir') as f:\n         f.write(ir)\n         f.flush()\n-        load_kernel = triton.compile(f.name)\n+        store_kernel = triton.compile(f.name)\n \n     rs = RandomState(17)\n     x = rs.randint(0, 4, (M, 1)).astype('float32')\n     y = np.zeros((M, 1), dtype='float32')\n     x_tri = torch.tensor(x, device=device)\n     y_tri = torch.tensor(y, device=device)\n \n-    pgm = load_kernel[(1, 1, 1)](x_tri, y_tri)\n+    pgm = store_kernel[(1, 1, 1)](x_tri, y_tri)\n     y_ref = x\n \n     np.testing.assert_allclose(y_ref, y_tri.cpu().numpy(), rtol=0.01, atol=1e-3)"}]