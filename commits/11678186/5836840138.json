[{"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "file_content_changes": "@@ -1181,7 +1181,11 @@ void populateElementwiseOpToLLVMPatterns(\n   POPULATE_BINARY_OP(arith::ShRSIOp, LLVM::AShrOp)  // >>\n   POPULATE_BINARY_OP(arith::ShRUIOp, LLVM::LShrOp)  // >>\n   POPULATE_BINARY_OP(arith::MinFOp, LLVM::MinNumOp) // fmin\n+  POPULATE_BINARY_OP(arith::MaxFOp, LLVM::MaxNumOp) // fmax\n   POPULATE_BINARY_OP(arith::MinSIOp, LLVM::SMinOp)  // smin\n+  POPULATE_BINARY_OP(arith::MaxSIOp, LLVM::SMaxOp)  // smax\n+  POPULATE_BINARY_OP(arith::MinUIOp, LLVM::UMinOp)  // umin\n+  POPULATE_BINARY_OP(arith::MaxUIOp, LLVM::UMaxOp)  // umax\n #undef POPULATE_BINARY_OP\n \n #define POPULATE_UNARY_OP(SRC_OP, DST_OP)                                      \\"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 8, "deletions": 11, "changes": 19, "file_content_changes": "@@ -321,17 +321,14 @@ struct ReduceOpConversion\n       return NVVM::ReduxKind::OR;\n     if (isa<arith::XOrIOp>(reduceOp))\n       return NVVM::ReduxKind::XOR;\n-    if (auto externalCall =\n-            dyn_cast<triton::PureExternElementwiseOp>(reduceOp)) {\n-      if (externalCall.getSymbol() == \"__nv_min\")\n-        return NVVM::ReduxKind::MIN;\n-      if (externalCall.getSymbol() == \"__nv_umin\")\n-        return NVVM::ReduxKind::UMIN;\n-      if (externalCall.getSymbol() == \"__nv_max\")\n-        return NVVM::ReduxKind::MAX;\n-      if (externalCall.getSymbol() == \"__nv_umax\")\n-        return NVVM::ReduxKind::UMAX;\n-    }\n+    if (isa<arith::MinSIOp>(reduceOp))\n+      return NVVM::ReduxKind::MIN;\n+    if (isa<arith::MinUIOp>(reduceOp))\n+      return NVVM::ReduxKind::UMIN;\n+    if (isa<arith::MaxSIOp>(reduceOp))\n+      return NVVM::ReduxKind::MAX;\n+    if (isa<arith::MaxUIOp>(reduceOp))\n+      return NVVM::ReduxKind::UMAX;\n     return std::nullopt;\n   }\n "}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 30, "deletions": 0, "changes": 30, "file_content_changes": "@@ -1066,6 +1066,36 @@ void init_triton_ir(py::module &&m) {\n               mlir::Value &rhs) -> mlir::Value {\n              return mlir::Value(self.create<mlir::arith::ShRSIOp>(lhs, rhs));\n            })\n+      .def(\"create_minsi\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MinSIOp>(lhs, rhs));\n+           })\n+      .def(\"create_minui\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MinUIOp>(lhs, rhs));\n+           })\n+      .def(\"create_minf\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MinFOp>(lhs, rhs));\n+           })\n+      .def(\"create_maxsi\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MaxSIOp>(lhs, rhs));\n+           })\n+      .def(\"create_maxui\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MaxUIOp>(lhs, rhs));\n+           })\n+      .def(\"create_maxf\",\n+           [](TritonOpBuilder &self, mlir::Value &lhs,\n+              mlir::Value &rhs) -> mlir::Value {\n+             return mlir::Value(self.create<mlir::arith::MaxFOp>(lhs, rhs));\n+           })\n       // AddPtr (similar to GEP)\n       .def(\"create_addptr\",\n            [](TritonOpBuilder &self, mlir::Value &ptr,"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 4, "deletions": 14, "changes": 18, "file_content_changes": "@@ -1382,7 +1382,7 @@ def minimum(x, y):\n     :param other: the second input tensor\n     :type other: Block\n     \"\"\"\n-    return where(x < y, x, y)\n+    return math.min(x, y)\n \n \n @jit\n@@ -1395,7 +1395,7 @@ def maximum(x, y):\n     :param other: the second input tensor\n     :type other: Block\n     \"\"\"\n-    return where(x > y, x, y)\n+    return math.max(x, y)\n \n # max and argmax\n \n@@ -1422,11 +1422,6 @@ def _argmax_combine_tie_break_fast(value1, index1, value2, index2):\n     return _argmax_combine(value1, index1, value2, index2, False)\n \n \n-@jit\n-def _fast_max(x, y):\n-    return math.max(x, y)\n-\n-\n @jit\n @_add_reduction_docstr(\"maximum\",\n                        return_indices_arg=\"return_indices\",\n@@ -1445,7 +1440,7 @@ def max(input, axis=None, return_indices=False, return_indices_tie_break_left=Tr\n             else:\n                 assert input.dtype.is_integer_type()\n                 input = input.to(int32)\n-        return reduce(input, axis, _fast_max)\n+        return reduce(input, axis, maximum)\n \n \n @jit\n@@ -1479,11 +1474,6 @@ def _argmin_combine_tie_break_fast(value1, index1, value2, index2):\n     return _argmin_combine(value1, index1, value2, index2, False)\n \n \n-@jit\n-def _fast_min(x, y):\n-    return math.min(x, y)\n-\n-\n @jit\n @_add_reduction_docstr(\"minimum\",\n                        return_indices_arg=\"return_indices\",\n@@ -1502,7 +1492,7 @@ def min(input, axis=None, return_indices=False, return_indices_tie_break_left=Tr\n             else:\n                 assert input.dtype.is_integer_type()\n                 input = input.to(int32)\n-        return reduce(input, axis, _fast_min)\n+        return reduce(input, axis, minimum)\n \n \n @jit"}, {"filename": "python/triton/language/math.py", "status": "modified", "additions": 18, "deletions": 16, "changes": 34, "file_content_changes": "@@ -40,26 +40,28 @@ def byte_perm(arg0, arg1, arg2, _builder=None):\n \n @core.extern\n def min(arg0, arg1, _builder=None):\n-    return core.extern_elementwise(\"libdevice\", libdevice_path(), [arg0, arg1, ],\n-                                   {(core.dtype(\"int32\"), core.dtype(\"int32\"),): (\"__nv_min\", core.dtype(\"int32\")),\n-                                    (core.dtype(\"uint32\"), core.dtype(\"uint32\"),): (\"__nv_umin\", core.dtype(\"uint32\")),\n-                                    (core.dtype(\"int64\"), core.dtype(\"int64\"),): (\"__nv_llmin\", core.dtype(\"int64\")),\n-                                    (core.dtype(\"uint64\"), core.dtype(\"uint64\"),): (\"__nv_ullmin\", core.dtype(\"uint64\")),\n-                                    (core.dtype(\"fp32\"), core.dtype(\"fp32\"),): (\"__nv_fminf\", core.dtype(\"fp32\")),\n-                                    (core.dtype(\"fp64\"), core.dtype(\"fp64\"),): (\"__nv_fmin\", core.dtype(\"fp64\")),\n-                                    }, is_pure=True, _builder=_builder)\n+    dtype = arg0.dtype\n+    if dtype.is_floating():\n+        return core.tensor(_builder.create_minf(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_signed():\n+        return core.tensor(_builder.create_minsi(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_unsigned():\n+        return core.tensor(_builder.create_minui(arg0.handle, arg1.handle), arg0.dtype)\n+    else:\n+        assert False, f\"Unexpected dtype {dtype}\"\n \n \n @core.extern\n def max(arg0, arg1, _builder=None):\n-    return core.extern_elementwise(\"libdevice\", libdevice_path(), [arg0, arg1, ],\n-                                   {(core.dtype(\"int32\"), core.dtype(\"int32\"),): (\"__nv_max\", core.dtype(\"int32\")),\n-                                    (core.dtype(\"uint32\"), core.dtype(\"uint32\"),): (\"__nv_umax\", core.dtype(\"uint32\")),\n-                                    (core.dtype(\"int64\"), core.dtype(\"int64\"),): (\"__nv_llmax\", core.dtype(\"int64\")),\n-                                    (core.dtype(\"uint64\"), core.dtype(\"uint64\"),): (\"__nv_ullmax\", core.dtype(\"uint64\")),\n-                                    (core.dtype(\"fp32\"), core.dtype(\"fp32\"),): (\"__nv_fmaxf\", core.dtype(\"fp32\")),\n-                                    (core.dtype(\"fp64\"), core.dtype(\"fp64\"),): (\"__nv_fmax\", core.dtype(\"fp64\")),\n-                                    }, is_pure=True, _builder=_builder)\n+    dtype = arg0.dtype\n+    if dtype.is_floating():\n+        return core.tensor(_builder.create_maxf(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_signed():\n+        return core.tensor(_builder.create_maxsi(arg0.handle, arg1.handle), arg0.type)\n+    elif dtype.is_int_unsigned():\n+        return core.tensor(_builder.create_maxui(arg0.handle, arg1.handle), arg0.dtype)\n+    else:\n+        assert False, f\"Unexpected dtype {dtype}\"\n \n \n @core.extern"}]