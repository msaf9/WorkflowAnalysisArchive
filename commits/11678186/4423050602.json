[{"filename": "lib/Conversion/TritonGPUToLLVM/DotOpHelpers.cpp", "status": "modified", "additions": 13, "deletions": 9, "changes": 22, "file_content_changes": "@@ -515,8 +515,8 @@ Type DotOpMmaV2ConversionHelper::getMmaRetType() const {\n       LLVM::LLVMStructType::getLiteral(ctx, SmallVector<Type>(4, fp32Ty));\n   Type i32x4Ty =\n       LLVM::LLVMStructType::getLiteral(ctx, SmallVector<Type>(4, i32Ty));\n-  Type fp16x2Pack2Ty =\n-      LLVM::LLVMStructType::getLiteral(ctx, SmallVector<Type>(2, vec_ty(fp16Ty, 2)));\n+  Type fp16x2Pack2Ty = LLVM::LLVMStructType::getLiteral(\n+      ctx, SmallVector<Type>(2, vec_ty(fp16Ty, 2)));\n   switch (mmaType) {\n   case TensorCoreType::FP32_FP16_FP16_FP32:\n     return fp32x4Ty;\n@@ -1050,14 +1050,16 @@ Value MMA16816ConversionHelper::loadC(Value tensor, Value llTensor) const {\n     for (int i = 0; i < fcSize; i += numCPackedElem) {\n       Value pack = rewriter.create<LLVM::UndefOp>(loc, cPackTy);\n       for (int j = 0; j < numCPackedElem; ++j) {\n-        pack = insert_element(cPackTy, pack, extract_val(cElemTy, llTensor, i + j), i32_val(j));\n+        pack = insert_element(\n+            cPackTy, pack, extract_val(cElemTy, llTensor, i + j), i32_val(j));\n       }\n       cPack.push_back(pack);\n     }\n \n     Type structTy = LLVM::LLVMStructType::getLiteral(\n-      ctx, SmallVector<Type>(cPack.size(), cPackTy));\n-    Value result = typeConverter->packLLElements(loc, cPack, rewriter, structTy);\n+        ctx, SmallVector<Type>(cPack.size(), cPackTy));\n+    Value result =\n+        typeConverter->packLLElements(loc, cPack, rewriter, structTy);\n     return result;\n   }\n   return llTensor;\n@@ -1098,7 +1100,8 @@ LogicalResult MMA16816ConversionHelper::convertDot(Value a, Value b, Value c,\n     // using =r for float32 works but leads to less readable ptx.\n     bool isIntMMA = dTensorTy.getElementType().isInteger(32);\n     bool isAccF16 = dTensorTy.getElementType().isF16();\n-    auto retArgs = builder.newListOperand(numMmaRets, isIntMMA || isAccF16 ? \"=r\" : \"=f\");\n+    auto retArgs =\n+        builder.newListOperand(numMmaRets, isIntMMA || isAccF16 ? \"=r\" : \"=f\");\n     auto aArgs = builder.newListOperand({\n         {ha[{m, k}], \"r\"},\n         {ha[{m + 1, k}], \"r\"},\n@@ -1138,9 +1141,10 @@ LogicalResult MMA16816ConversionHelper::convertDot(Value a, Value b, Value c,\n   SmallVector<Value> results(fc.size() * numCPackedElem);\n   for (int i = 0; i < fc.size(); ++i) {\n     for (int j = 0; j < numCPackedElem; ++j) {\n-      results[i * numCPackedElem + j] = numCPackedElem > 1\n-        ? bitcast(extract_element(fc[i], i32_val(j)), resElemTy)\n-        : bitcast(fc[i], resElemTy);\n+      results[i * numCPackedElem + j] =\n+          numCPackedElem > 1\n+              ? bitcast(extract_element(fc[i], i32_val(j)), resElemTy)\n+              : bitcast(fc[i], resElemTy);\n     }\n   }\n   Value res = typeConverter->packLLElements(loc, results, rewriter, structTy);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpHelpers.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -377,8 +377,8 @@ struct MMA16816ConversionHelper {\n     warp = udiv(thread, _32);\n   }\n \n-  MMA16816ConversionHelper(DotOp op, MmaEncodingAttr mmaLayout,\n-                           Value thread, ConversionPatternRewriter &rewriter,\n+  MMA16816ConversionHelper(DotOp op, MmaEncodingAttr mmaLayout, Value thread,\n+                           ConversionPatternRewriter &rewriter,\n                            TritonGPUToLLVMTypeConverter *typeConverter,\n                            Location loc)\n       : mmaLayout(mmaLayout), wpt(mmaLayout.getWarpsPerCTA()), thread(thread),"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -71,7 +71,6 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n                                        getThreadId(rewriter, loc), rewriter,\n                                        getTypeConverter(), loc);\n \n-\n     auto ATensorTy = A.getType().cast<RankedTensorType>();\n     auto BTensorTy = B.getType().cast<RankedTensorType>();\n "}]