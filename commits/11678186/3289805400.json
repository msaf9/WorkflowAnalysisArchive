[{"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 17, "deletions": 1, "changes": 18, "file_content_changes": "@@ -457,8 +457,24 @@ class BlockedToMMA : public mlir::RewritePattern {\n     auto oldAcc = dotOp.getOperand(2);\n     auto newAcc = rewriter.create<triton::gpu::ConvertLayoutOp>(\n         oldAcc.getLoc(), newRetType, oldAcc);\n+    Value a = dotOp.a();\n+    Value b = dotOp.b();\n+    auto oldAType = a.getType().cast<RankedTensorType>();\n+    auto oldBType = b.getType().cast<RankedTensorType>();\n+    auto newAType = RankedTensorType::get(\n+      oldAType.getShape(), oldAType.getElementType(),\n+      triton::gpu::DotOperandEncodingAttr::get(oldAType.getContext(), 0,\n+                                               newRetType.getEncoding())\n+    );\n+    auto newBType = RankedTensorType::get(\n+      oldBType.getShape(), oldBType.getElementType(),\n+      triton::gpu::DotOperandEncodingAttr::get(oldBType.getContext(), 1,\n+                                               newRetType.getEncoding())\n+    );\n+    a = rewriter.create<triton::gpu::ConvertLayoutOp>(a.getLoc(), newAType, a);\n+    b = rewriter.create<triton::gpu::ConvertLayoutOp>(b.getLoc(), newBType, b);\n     auto newDot = rewriter.create<triton::DotOp>(\n-        dotOp.getLoc(), newRetType, dotOp.getOperand(0), dotOp.getOperand(1),\n+        dotOp.getLoc(), newRetType, a, b,\n         newAcc, dotOp.allowTF32());\n \n     rewriter.replaceOpWithNewOp<triton::gpu::ConvertLayoutOp>("}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 42, "deletions": 36, "changes": 78, "file_content_changes": "@@ -158,44 +158,50 @@ RankedTensorType\n LoopPipeliner::getSwizzleType(ttg::DotOperandEncodingAttr dotOpEnc,\n                               RankedTensorType ty) {\n   int opIdx = dotOpEnc.getOpIdx();\n-  auto mmaEnc = dotOpEnc.getParent().cast<ttg::MmaEncodingAttr>();\n-  int version = mmaEnc.getVersion();\n-  auto tyEncoding = ty.getEncoding().cast<ttg::BlockedEncodingAttr>();\n-  auto order = tyEncoding.getOrder();\n-  // number of rows per phase\n-  int perPhase = 128 / (ty.getShape()[order[0]] *\n-                        (ty.getElementType().getIntOrFloatBitWidth() / 8));\n-  perPhase = std::max<int>(perPhase, 1);\n   int vec = 1;\n   int maxPhase = 1;\n-  // index of the inner dimension in `order`\n-  int inner = (opIdx == 0) ? 0 : 1;\n-  if (version == 1) {\n-    maxPhase = (order[inner] == 1 ? 8 : 4) / perPhase;\n-    // TODO: handle rep (see\n-    // https://github.com/openai/triton/blob/master/lib/codegen/analysis/layout.cc#L209)\n-  } else if (version == 2) {\n-    auto eltTy = ty.getElementType();\n-    std::vector<size_t> mat_shape = {8, 8,\n-                                      2 * 64 / eltTy.getIntOrFloatBitWidth()};\n-    // for now, disable swizzle when using transposed int8 tensor cores\n-    if (ty.getElementType().isInteger(8) && order[0] == inner)\n-      perPhase = 1;\n-    else {\n-      if (opIdx == 0) {  // compute swizzling for A operand\n-        vec = order[0] == 1 ? mat_shape[2] : mat_shape[0]; // k : m\n-        int mmaStride = order[0] == 1 ? mat_shape[0] : mat_shape[2];\n-        maxPhase = mmaStride / perPhase;\n-      } else if (opIdx == 1) {  // compute swizzling for B operand\n-        vec = order[0] == 1 ? mat_shape[1] : mat_shape[2]; // n : k\n-        int mmaStride = order[0] == 1 ? mat_shape[2] : mat_shape[1];\n-        maxPhase = mmaStride / perPhase;\n-      } else\n-        llvm_unreachable(\"invalid operand index\");\n-    }\n-  } else  // version not in [1, 2]\n-    llvm_unreachable(\"unsupported swizzling for provided MMA version\");\n-\n+  int perPhase = 1;\n+  llvm::ArrayRef<unsigned> order;\n+  if (auto mmaEnc = dotOpEnc.getParent().dyn_cast<ttg::MmaEncodingAttr>()) {\n+    int version = mmaEnc.getVersion();\n+    auto tyEncoding = ty.getEncoding().cast<ttg::BlockedEncodingAttr>();\n+    order = tyEncoding.getOrder();\n+    // number of rows per phase\n+    perPhase = 128 / (ty.getShape()[order[0]] *\n+                          (ty.getElementType().getIntOrFloatBitWidth() / 8));\n+    perPhase = std::max<int>(perPhase, 1);\n+\n+    // index of the inner dimension in `order`\n+    int inner = (opIdx == 0) ? 0 : 1;\n+    if (version == 1) {\n+      maxPhase = (order[inner] == 1 ? 8 : 4) / perPhase;\n+      // TODO: handle rep (see\n+      // https://github.com/openai/triton/blob/master/lib/codegen/analysis/layout.cc#L209)\n+    } else if (version == 2) {\n+      auto eltTy = ty.getElementType();\n+      std::vector<size_t> mat_shape = {8, 8,\n+                                        2 * 64 / eltTy.getIntOrFloatBitWidth()};\n+      // for now, disable swizzle when using transposed int8 tensor cores\n+      if (ty.getElementType().isInteger(8) && order[0] == inner)\n+        perPhase = 1;\n+      else {\n+        if (opIdx == 0) {  // compute swizzling for A operand\n+          vec = order[0] == 1 ? mat_shape[2] : mat_shape[0]; // k : m\n+          int mmaStride = order[0] == 1 ? mat_shape[0] : mat_shape[2];\n+          maxPhase = mmaStride / perPhase;\n+        } else if (opIdx == 1) {  // compute swizzling for B operand\n+          vec = order[0] == 1 ? mat_shape[1] : mat_shape[2]; // n : k\n+          int mmaStride = order[0] == 1 ? mat_shape[2] : mat_shape[1];\n+          maxPhase = mmaStride / perPhase;\n+        } else\n+          llvm_unreachable(\"invalid operand index\");\n+      }\n+    } else  // version not in [1, 2]\n+      llvm_unreachable(\"unsupported swizzling for provided MMA version\");\n+  } else {  // If the layout of dot is not mma, we don't need to swizzle\n+    auto blockedEnc = dotOpEnc.getParent().cast<ttg::BlockedEncodingAttr>();\n+    order = blockedEnc.getOrder();\n+  }\n   auto newEncoding = ttg::SharedEncodingAttr::get(\n     ty.getContext(), vec, perPhase, maxPhase, order\n   );"}]