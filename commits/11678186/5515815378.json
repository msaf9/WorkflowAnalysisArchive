[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -114,7 +114,7 @@ jobs:\n           cd python/test/regression\n           sudo nvidia-smi -i 0 -pm 1\n           sudo nvidia-smi -i 0 --lock-gpu-clocks=1350,1350\n-          python3 -m pytest -vs . --reruns 10 --reruns-delay 1\n+          python3 -m pytest -vs . --reruns 10\n           sudo nvidia-smi -i 0 -rgc\n \n   Integration-Tests-Third-Party:"}, {"filename": "python/triton/testing.py", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "file_content_changes": "@@ -16,7 +16,7 @@ def nvsmi(attrs):\n     return ret\n \n \n-def do_bench_cudagraph(fn, n_warmup=20, n_repeat=40, grad_to_none=None):\n+def do_bench_cudagraph(fn, n_repeat=20, grad_to_none=None):\n     import torch\n     \"\"\"\n     Benchmark the runtime of the provided function.\n@@ -50,13 +50,10 @@ def do_bench_cudagraph(fn, n_warmup=20, n_repeat=40, grad_to_none=None):\n     start_event = [torch.cuda.Event(enable_timing=True) for i in range(n_repeat)]\n     end_event = [torch.cuda.Event(enable_timing=True) for i in range(n_repeat)]\n     ret = []\n-    n_retries = 1\n+    n_retries = 20\n     for _ in range(n_retries):\n         # Benchmark\n         torch.cuda.synchronize()\n-        for i in range(n_warmup):\n-            fn()\n-        torch.cuda.synchronize()\n         for i in range(n_repeat):\n             # we don't want `fn` to accumulate gradient values\n             # if it contains a backward pass. So we clear the"}]