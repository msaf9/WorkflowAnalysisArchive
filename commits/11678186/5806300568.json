[{"filename": "lib/Analysis/Membar.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -138,8 +138,8 @@ void MembarAnalysis::update(Operation *op, BlockInfo *blockInfo,\n       barSync(*builder, op, barId, 128);\n     } else {\n       builder->create<gpu::BarrierOp>(op->getLoc());\n-      blockInfo->sync();\n     }\n+    blockInfo->sync();\n     return;\n   }\n \n@@ -203,8 +203,8 @@ void MembarAnalysis::update(Operation *op, BlockInfo *blockInfo,\n       barSync(*builder, op, barId, 128);\n     } else {\n       builder->create<gpu::BarrierOp>(op->getLoc());\n-      blockInfo->sync();\n     }\n+    blockInfo->sync();\n   }\n   // Update the region info, even if barrier is inserted, we have to maintain\n   // the current op's read/write buffers."}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 20, "deletions": 1, "changes": 21, "file_content_changes": "@@ -49,6 +49,14 @@ namespace ttng = mlir::triton::nvidia_gpu;\n \n namespace {\n \n+// pass ws related named attrs.\n+static void addWSNamedAttrs(Operation *op,\n+                            ArrayRef<mlir::NamedAttribute> attrs) {\n+  for (const NamedAttribute attr : attrs)\n+    if (attr.getName() == \"async_agent\" || attr.getName() == \"agent.mutex_role\")\n+      op->setAttr(attr.getName(), attr.getValue());\n+}\n+\n class TritonLLVMFunctionConversionTarget : public ConversionTarget {\n public:\n   explicit TritonLLVMFunctionConversionTarget(MLIRContext &ctx, bool isROCM)\n@@ -617,10 +625,13 @@ class ConvertTritonGPUToLLVM\n       auto newCvtType = RankedTensorType::get(shape, F16Ty, cvtEncoding);\n       auto newArg = builder.create<mlir::triton::FpToFpOp>(\n           cvtOp.getLoc(), newArgType, cvtOp.getOperand());\n+      addWSNamedAttrs(newArg, cvtOp->getAttrs());\n       auto newCvt = builder.create<mlir::triton::gpu::ConvertLayoutOp>(\n           cvtOp.getLoc(), newCvtType, newArg);\n+      addWSNamedAttrs(newCvt, cvtOp->getAttrs());\n       auto newRet = builder.create<mlir::triton::FpToFpOp>(\n           cvtOp.getLoc(), cvtOp.getType(), newCvt.getResult());\n+      addWSNamedAttrs(newRet, cvtOp->getAttrs());\n       cvtOp.replaceAllUsesWith(newRet.getResult());\n       cvtOp.erase();\n     });\n@@ -646,8 +657,10 @@ class ConvertTritonGPUToLLVM\n                 getOrder(srcMma), numWarps, threadsPerWarp, numCTAs));\n         auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), tmpType, cvtOp.getOperand());\n+        addWSNamedAttrs(tmp, cvtOp->getAttrs());\n         auto newConvert = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), dstType, tmp);\n+        addWSNamedAttrs(newConvert, cvtOp->getAttrs());\n         cvtOp.replaceAllUsesWith(newConvert.getResult());\n         cvtOp.erase();\n       }\n@@ -674,8 +687,10 @@ class ConvertTritonGPUToLLVM\n                 srcType.getElementType()));\n         auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), tmpType, cvtOp.getOperand());\n+        addWSNamedAttrs(tmp, cvtOp->getAttrs());\n         auto newConvert = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), dstType, tmp);\n+        addWSNamedAttrs(newConvert, cvtOp->getAttrs());\n         cvtOp.replaceAllUsesWith(newConvert.getResult());\n         cvtOp.erase();\n       }\n@@ -750,6 +765,7 @@ class ConvertTritonGPUToLLVM\n           /*boundaryCheck=*/nullptr, /*padding=*/nullptr,\n           insertSliceAsyncOp.getCache(), insertSliceAsyncOp.getEvict(),\n           insertSliceAsyncOp.getIsVolatile());\n+      addWSNamedAttrs(loadOp, insertSliceAsyncOp->getAttrs());\n \n       // insert_slice\n       auto axis = insertSliceAsyncOp.getAxis();\n@@ -765,6 +781,7 @@ class ConvertTritonGPUToLLVM\n       auto insertSliceOp = builder.create<tensor::InsertSliceOp>(\n           insertSliceAsyncOp.getLoc(), loadOp, insertSliceAsyncOp.getDst(),\n           offsets, sizes, strides);\n+      addWSNamedAttrs(insertSliceOp, insertSliceAsyncOp->getAttrs());\n \n       // Replace\n       insertSliceAsyncOp.replaceAllUsesWith(insertSliceOp.getResult());\n@@ -784,7 +801,9 @@ class ConvertTritonGPUToLLVM\n       } else if (decomposed) {\n         // Wait for all previous async ops\n         OpBuilder builder(asyncWaitOp);\n-        builder.create<triton::gpu::AsyncWaitOp>(asyncWaitOp.getLoc(), 0);\n+        auto newWaitOp =\n+            builder.create<triton::gpu::AsyncWaitOp>(asyncWaitOp.getLoc(), 0);\n+        addWSNamedAttrs(newWaitOp, asyncWaitOp->getAttrs());\n         asyncWaitOp.erase();\n       }\n     });"}, {"filename": "python/test/unit/hopper/test_persistent_warp_specialized_gemm.py", "status": "modified", "additions": 10, "deletions": 8, "changes": 18, "file_content_changes": "@@ -850,19 +850,11 @@ def full_static_persistent_matmul_kernel(\n @pytest.mark.skipif(torch.cuda.get_device_capability()\n                     [0] < 9, reason=\"Requires compute capability >= 9\")\n def test_full_static_persistent_matmul_kernel(BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, TRANS_A, TRANS_B, epilogue, out_dtype, USE_TMA_STORE, NUM_STAGES, ENABLE_WS):\n-    pytest.skip(\"known failure, will fix it later!!!\")\n     if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, epilogue, out_dtype, USE_TMA_STORE, NUM_STAGES, ENABLE_WS])) in [\n         '128-128-128-4-1-256-256-192-none-float32-True-3-True',\n     ]:\n         pytest.skip('out of resource: shared memory, Required: 263168')\n \n-    if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, USE_TMA_STORE, ENABLE_WS])) in ([\n-        '64-16-16-4-1-512-256-256-True-True',\n-    ] + [\n-        f'128-128-64-4-1-{m}-{n}-{k}-True-True' for m in range(512, 4096, 360) for n in range(512, 4096, 360) for k in [512, 1024]\n-    ]):\n-        pytest.skip('known kernel hang problem when tma store is enabled')\n-\n     if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, TRANS_A, TRANS_B])) in [\n         '16-32-64-4-4-512-256-64-True-False',\n         '16-32-64-4-4-512-256-64-True-True',\n@@ -871,6 +863,16 @@ def test_full_static_persistent_matmul_kernel(BLOCK_M, BLOCK_N, BLOCK_K, NUM_WAR\n     ]:\n         pytest.skip('shapePerCTA[1] < 16 not supported')\n \n+    # with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n+    if '-'.join(map(str, [BLOCK_M, BLOCK_N, BLOCK_K, NUM_WARPS, NUM_CTAS, M, N, K, TRANS_B])) in [\n+        '16-32-64-4-1-256-256-256-False',\n+        '16-32-64-4-2-256-256-256-False',\n+        '16-32-64-4-2-256-256-256-True',\n+        '16-32-64-8-2-256-256-256-False',\n+        '16-32-64-8-2-256-256-256-True',\n+    ]:\n+        pytest.skip('Known legacy issue, ldmatrix can only support x4')\n+\n     if epilogue == 'chain-dot':\n         pytest.skip('known failure: Assertion !region.empty() && unexpected empty region.')\n "}]