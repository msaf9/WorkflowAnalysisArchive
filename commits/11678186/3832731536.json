[{"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -289,7 +289,7 @@ def TT_CatOp : TT_Op<\"cat\", [NoSideEffect,\n }\n \n def TT_TransOp : TT_Op<\"trans\", [NoSideEffect,\n-                               SameOperandsAndResultElementType]> {\n+                                 SameOperandsAndResultElementType]> {\n \n     let summary = \"transpose a tensor\";\n "}, {"filename": "lib/Analysis/Alias.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -25,9 +25,10 @@ ChangeResult SharedMemoryAliasAnalysis::visitOperation(\n   if (maybeSharedAllocationOp(op)) {\n     // These ops may allocate a new shared memory buffer.\n     auto result = op->getResult(0);\n-    // FIXME(Keren): extract and insert are always alias for now\n+    // XXX(Keren): the following ops are always aliasing for now\n     if (isa<tensor::ExtractSliceOp, triton::TransOp>(op)) {\n       // extract_slice %src\n+      // trans %src\n       aliasInfo = AliasInfo(operands[0]->getValue());\n       pessimistic = false;\n     } else if (isa<tensor::InsertSliceOp, triton::gpu::InsertSliceAsyncOp>("}, {"filename": "test/Analysis/test-alias.mlir", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "file_content_changes": "@@ -52,6 +52,15 @@ func @convert(%A : !tt.ptr<f16>) {\n   return\n }\n \n+// CHECK-LABEL: trans\n+func @trans(%A : !tt.ptr<f16>) {\n+  // CHECK: %cst -> %cst\n+  %tensor = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n+  // CHECK: %0 -> %cst\n+  %b = tt.trans %tensor : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n+  return\n+}\n+\n // CHECK-LABEL: insert_slice_async\n func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>"}, {"filename": "test/Analysis/test-allocation.mlir", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "file_content_changes": "@@ -174,6 +174,14 @@ func @scratch() {\n   // CHECK-NEXT: size = 512\n }\n \n+// CHECK-LABEL: trans\n+func @trans(%A : !tt.ptr<f16>) {\n+  // CHECK: offset = 0, size = 1024\n+  %tensor = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n+  %b = tt.trans %tensor : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n+  return\n+}\n+\n // CHECK-LABEL: insert_slice_async\n func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>\n@@ -285,6 +293,25 @@ func @for_if_slice(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %\n   // CHECK-NEXT: size = 24576\n }\n \n+// c0 cannot be released in the loop\n+// CHECK-LABEL: for_use_ancestor\n+func @for_use_ancestor(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>, %i1 : i1) {\n+  // CHECK: offset = 0, size = 8192\n+  %a_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n+  // CHECK-NEXT: offset = 8192, size = 8192\n+  %b_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n+  // CHECK-NEXT: offset = 16384, size = 8192\n+  %c_shared_init = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n+  %a_shared, %b_shared = scf.for %iv = %lb to %ub step %step iter_args(%a_shared = %a_shared_init, %b_shared = %b_shared_init) -> (tensor<128x32xf16, #A_SHARED>, tensor<128x32xf16, #A_SHARED>) {\n+    %c0 = tt.trans %c_shared_init : (tensor<128x32xf16, #A_SHARED>) -> tensor<32x128xf16, #A_SHARED>\n+    // CHECK-NEXT: offset = 24576, size = 8192\n+    %c1 = arith.constant dense<0.00e+00> : tensor<128x32xf16, #A_SHARED>\n+    scf.yield %b_shared, %a_shared: tensor<128x32xf16, #A_SHARED>, tensor<128x32xf16, #A_SHARED>\n+  }\n+  return\n+  // CHECK-NEXT: size = 32768\n+}\n+\n // a_shared_init, b_shared_init, and c_shared_init's liveness ranges are span over the entire function before cst2.\n // So they cannot be reused by cst0 and cst1, but can be reused by cst2.\n // CHECK-LABEL: for_if_for"}, {"filename": "test/Analysis/test-membar.mlir", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "file_content_changes": "@@ -111,6 +111,13 @@ func @extract_slice() {\n   return\n }\n \n+// CHECK-LABEL: trans\n+func @trans() {\n+  %cst0 = arith.constant dense<0.000000e+00> : tensor<16x32xf16, #A_SHARED>\n+  %b = tt.trans %cst0 : (tensor<16x32xf16, #A_SHARED>) -> tensor<32x16xf16, #A_SHARED>\n+  return\n+}\n+\n // CHECK-LABEL: insert_slice_async\n func @insert_slice_async(%A : !tt.ptr<f16>, %i1 : i1) {\n   %a_ptr = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<16x16x!tt.ptr<f16>, #AL>"}]