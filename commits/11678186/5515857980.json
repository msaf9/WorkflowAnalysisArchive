[{"filename": "python/triton/testing.py", "status": "modified", "additions": 12, "deletions": 6, "changes": 18, "file_content_changes": "@@ -16,21 +16,17 @@ def nvsmi(attrs):\n     return ret\n \n \n-def do_bench_cudagraph(fn, n_repeat=20, grad_to_none=None):\n+def do_bench_cudagraph(fn, rep=20, grad_to_none=None):\n     import torch\n     \"\"\"\n     Benchmark the runtime of the provided function.\n \n     :param fn: Function to benchmark\n     :type fn: Callable\n-    :param warmup: Warmup time (in ms)\n-    :type warmup: int\n     :param rep: Repetition time (in ms)\n     :type rep: int\n     :param grad_to_none: Reset the gradient of the provided tensor to None\n     :type grad_to_none: torch.tensor, optional\n-    :param quantiles: Performance percentile to return in addition to the median.\n-    :type quantiles: list[float]\n     \"\"\"\n     if torch.cuda.current_stream() == torch.cuda.default_stream():\n         raise RuntimeError(\"Cannot capture graph in default stream. Please use side stream in benchmark code.\")\n@@ -46,11 +42,21 @@ def do_bench_cudagraph(fn, n_repeat=20, grad_to_none=None):\n         fn()\n     torch.cuda.synchronize()\n     fn = lambda: g.replay()\n+    # Estimate the runtime of the function\n+    start_event = torch.cuda.Event(enable_timing=True)\n+    end_event = torch.cuda.Event(enable_timing=True)\n+    start_event.record()\n+    fn()\n+    end_event.record()\n+    torch.cuda.synchronize()\n+    estimate_ms = start_event.elapsed_time(end_event)\n+    # compute number of repetition to last `rep` ms\n+    n_repeat = max(1, int(rep / estimate_ms))\n     # compute number of repetition to last `rep` ms\n     start_event = [torch.cuda.Event(enable_timing=True) for i in range(n_repeat)]\n     end_event = [torch.cuda.Event(enable_timing=True) for i in range(n_repeat)]\n     ret = []\n-    n_retries = 20\n+    n_retries = 25\n     for _ in range(n_retries):\n         # Benchmark\n         torch.cuda.synchronize()"}]