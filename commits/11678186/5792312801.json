[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 1, "deletions": 11, "changes": 12, "file_content_changes": "@@ -27,7 +27,7 @@ jobs:\n         run: |\n           if [ x\"${{ github.repository }}\" == x\"openai/triton\" ]; then\n             echo '::set-output name=matrix-required::[[\"self-hosted\", \"A100\"], [\"self-hosted\", \"H100\"]]'\n-            echo '::set-output name=matrix-optional::[[\"self-hosted\", \"gfx908\"], [\"self-hosted\", \"arc770\"]]'\n+            echo '::set-output name=matrix-optional::[]'\n           else\n             echo '::set-output name=matrix-required::[\"ubuntu-latest\"]'\n             echo '::set-output name=matrix-optional::[\"ubuntu-latest\"]'\n@@ -95,16 +95,6 @@ jobs:\n           # run runtime tests serially to avoid race condition with cache handling.\n           python3 -m pytest runtime/\n \n-      - name: Disable MMAV3 and TMA\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'H100')}}\n-        run: |\n-          echo \"ENABLE_TMA=0\" >> \"${GITHUB_ENV}\"\n-          echo \"ENABLE_MMA_V3=0\" >> \"${GITHUB_ENV}\"\n-\n-      - name: Clear cache\n-        run: |\n-          rm -rf ~/.triton\n-\n       - name: Run python tests on CUDA with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n         if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '0' && env.ENABLE_MMA_V3 == '0'}}\n         run: |"}, {"filename": "include/triton/Dialect/NVGPU/IR/NVGPUOps.td", "status": "modified", "additions": 0, "deletions": 9, "changes": 9, "file_content_changes": "@@ -344,15 +344,6 @@ def NVGPU_Sts64Op : NVGPU_Op<\"sts64\", [MemoryEffects<[MemWrite]>]> {\n   }];\n }\n \n-def NVGPU_CvtPackOp : NVGPU_Op<\"cvt_pack\", []> {\n-  let arguments = (ins AnyTypeOf<[F16, I16]>:$d0, AnyTypeOf<[F16, I16]>:$d1);\n-  let results = (outs I32:$result);\n-  let assemblyFormat = \"operands attr-dict `:` type(operands) `->` type($result)\";\n-  string llvmBuilder = [{\n-    $result = createCvtPack(builder, $d0, $d1);\n-  }];\n-}\n-\n def NVGPU_ClusterCTAIdOp : NVGPU_Op<\"cluster_id\", [Pure]> {\n   let results = (outs I32:$result);\n   let assemblyFormat = \"attr-dict\";"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 17, "deletions": 8, "changes": 25, "file_content_changes": "@@ -697,6 +697,15 @@ struct ConvertLayoutOpConversion\n     return success();\n   }\n \n+  // Pack two 16-bit values into a 32-bit register.\n+  static Value pack16bitsTo32(ConversionPatternRewriter &rewriter, Location loc,\n+                              Value hb, Value lb) {\n+    hb = zext(i32_ty, bitcast(hb, i16_ty));\n+    lb = zext(i32_ty, bitcast(lb, i16_ty));\n+    Value pack = or_(lb, shl(hb, i32_val(16)));\n+    return pack;\n+  }\n+\n   // blocked -> shared.\n   // Swizzling in shared memory to avoid bank conflict. Normally used for\n   // A/B operands of dots.\n@@ -768,14 +777,14 @@ struct ConvertLayoutOpConversion\n               numElemsPerSwizzlingRow, true);\n \n           Value addr = gep(elemPtrTy, smemBase, offset);\n-          Value data0 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 1], inVals[elemIdx + 0]);\n-          Value data1 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 3], inVals[elemIdx + 2]);\n-          Value data2 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 5], inVals[elemIdx + 4]);\n-          Value data3 = rewriter.create<triton::nvgpu::CvtPackOp>(\n-              loc, i32_ty, inVals[elemIdx + 7], inVals[elemIdx + 6]);\n+          Value data0 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 1],\n+                                       inVals[elemIdx + 0]);\n+          Value data1 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 3],\n+                                       inVals[elemIdx + 2]);\n+          Value data2 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 5],\n+                                       inVals[elemIdx + 4]);\n+          Value data3 = pack16bitsTo32(rewriter, loc, inVals[elemIdx + 7],\n+                                       inVals[elemIdx + 6]);\n \n           rewriter.create<triton::nvgpu::StoreMatrixOp>(\n               loc, bitcast(addr, ptrI8SharedTy),"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/WGMMA.cpp", "status": "modified", "additions": 59, "deletions": 19, "changes": 78, "file_content_changes": "@@ -216,6 +216,50 @@ DotOpMmaV3SmemLoader loadB(TritonGPUToLLVMTypeConverter *typeConverter,\n           loc};\n }\n \n+// Return a vector of Value of the accumulator start at startIndex and pack the\n+// values into 32bits in case the accumulator is fp16.\n+llvm::SmallVector<Value> loadC(ConversionPatternRewriter &rewriter,\n+                               Location loc, const SmallVector<Value> &elements,\n+                               int startIndex, int numElements) {\n+  if (!elements[0].getType().isF16()) {\n+    llvm::SmallVector<Value> mmaOut(numElements);\n+    for (int i = 0; i < numElements; ++i)\n+      mmaOut[i] = elements[startIndex + i];\n+    return mmaOut;\n+  }\n+  // For FP16 we need to pack accumulator into 32-bit integers.\n+  llvm::SmallVector<Value> mmaOut(numElements / 2);\n+  for (int i = 0; i < numElements / 2; ++i) {\n+    Value a0 = elements[startIndex + 2 * i];\n+    Value a1 = elements[startIndex + 2 * i + 1];\n+    Type cPackTy = vec_ty(rewriter.getF16Type(), 2);\n+    Value pack = rewriter.create<LLVM::UndefOp>(loc, cPackTy);\n+    pack = insert_element(cPackTy, pack, a0, i32_val(0));\n+    pack = insert_element(cPackTy, pack, a1, i32_val(1));\n+    pack = bitcast(pack, rewriter.getIntegerType(32));\n+    mmaOut[i] = pack;\n+  }\n+  return mmaOut;\n+}\n+\n+// If the accumulator is fp16 unpack it from 32-bit integers.\n+SmallVector<Value> unpackAccumulator(ConversionPatternRewriter &rewriter,\n+                                     Location loc,\n+                                     const SmallVector<Value> &packed,\n+                                     RankedTensorType tensorTy) {\n+  if (!tensorTy.getElementType().isF16())\n+    return packed;\n+  // For fp16 the accumualtor is pack into 32-bit integers so we need to unpack\n+  // it.\n+  SmallVector<Value> results;\n+  for (Value elem : packed) {\n+    elem = bitcast(elem, vec_ty(rewriter.getF16Type(), 2));\n+    results.push_back(extract_element(rewriter.getF16Type(), elem, i32_val(0)));\n+    results.push_back(extract_element(rewriter.getF16Type(), elem, i32_val(1)));\n+  }\n+  return results;\n+}\n+\n LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n                          ConversionPatternRewriter &rewriter, Location loc,\n                          Operation *op, Value a, Value b, Value c, Value d,\n@@ -236,11 +280,6 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   auto dShapePerCTA = getShapePerCTA(dTensorTy);\n   auto instrShape = mmaEncoding.getInstrShape();\n   auto accSize = 2 * (instrShape[1] / 4);\n-  Type resElemTy = dTensorTy.getElementType();\n-  llvm::SmallVector<Type> elemTypes(accSize, resElemTy);\n-  auto accTy =\n-      LLVM::LLVMStructType::getLiteral(rewriter.getContext(), elemTypes);\n-\n   int M = 4 * instrShape[0];\n   int N = instrShape[1];\n   int K = instrShape[2];\n@@ -258,9 +297,6 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   auto fc = typeConverter->unpackLLElements(loc, loadedC, rewriter, dTensorTy);\n \n   triton::nvgpu::WGMMAEltType eltTypeC = getMmaRetType(d);\n-  assert(eltTypeC != triton::nvgpu::WGMMAEltType::f16 &&\n-         \"TODO support f16 return type. This requires packing C into \"\n-         \"vector<2xf16> type.\");\n   triton::nvgpu::WGMMAEltType eltTypeA = getMmaOperandType(a, allowTF32);\n   triton::nvgpu::WGMMAEltType eltTypeB = eltTypeA;\n \n@@ -276,13 +312,16 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n     rewriter.create<triton::nvgpu::FenceAsyncSharedOp>(loc, 0);\n   rewriter.create<triton::nvgpu::WGMMAFenceOp>(loc);\n \n-  llvm::SmallVector<Value> mmaOut(accSize);\n+  SmallVector<Value> mmaResults;\n   for (int m = 0; m < numRepM; ++m) {\n     for (int n = 0; n < numRepN; ++n) {\n-      // reuse the same mmaOut\n-      for (int i = 0; i < accSize; ++i) {\n-        mmaOut[i] = fc[(m * numRepN + n) * accSize + i];\n-      }\n+      llvm::SmallVector<Value> mmaOut =\n+          loadC(rewriter, loc, fc, (m * numRepN + n) * accSize, accSize);\n+      llvm::SmallVector<Type> elemTypes;\n+      for (Value accEl : mmaOut)\n+        elemTypes.push_back(accEl.getType());\n+      auto accTy =\n+          LLVM::LLVMStructType::getLiteral(rewriter.getContext(), elemTypes);\n       Value d = typeConverter->packLLElements(loc, mmaOut, rewriter, accTy);\n       for (int k = 0; k < numRepK; ++k) {\n         auto a = aLoader.smemLoad(m, k);\n@@ -294,7 +333,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n       }\n       auto acc = typeConverter->unpackLLElements(loc, d, rewriter, accTy);\n       for (int i = 0; i < acc.size(); ++i) {\n-        fc[(m * numRepN + n) * accSize + i] = acc[i];\n+        mmaResults.push_back(acc[i]);\n       }\n     }\n   }\n@@ -303,13 +342,14 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   if (sync)\n     rewriter.create<triton::nvgpu::WGMMAWaitOp>(loc, 0);\n \n-  for (auto &elem : fc) {\n-    elem = bitcast(elem, resElemTy);\n-  }\n+  SmallVector<Value> results =\n+      unpackAccumulator(rewriter, loc, mmaResults, dTensorTy);\n+\n   // replace with new packed result\n   Type structTy = LLVM::LLVMStructType::getLiteral(\n-      mmaEncoding.getContext(), SmallVector<Type>(fc.size(), resElemTy));\n-  auto res = typeConverter->packLLElements(loc, fc, rewriter, structTy);\n+      mmaEncoding.getContext(),\n+      SmallVector<Type>(results.size(), dTensorTy.getElementType()));\n+  auto res = typeConverter->packLLElements(loc, results, rewriter, structTy);\n   rewriter.replaceOp(op, res);\n   return success();\n }"}, {"filename": "lib/Dialect/NVGPU/ToLLVMIR/NVGPUToLLVMIR.cpp", "status": "modified", "additions": 2, "deletions": 23, "changes": 25, "file_content_changes": "@@ -326,16 +326,15 @@ llvm::Value *createWGMMA(llvm::IRBuilderBase &builder, uint32_t m, uint32_t n,\n   uint32_t asmOpIdx = 0;\n \n   // Operand C\n-  uint32_t numCRegs = m * n / 128;\n-  assert(numCRegs == structTypeC->getStructNumElements());\n+  uint32_t numCRegs = structTypeC->getStructNumElements();\n   asmOs << \"{\";\n   for (uint32_t i = 0; i < numCRegs; ++i) {\n     argTypes.push_back(structTypeC->getElementType(i));\n     args.push_back(builder.CreateExtractValue(opC, {i}));\n     asmOs << \"$\" << asmOpIdx++ << (i == numCRegs - 1 ? \"\" : \",\");\n     // LLVM does not support `+` semantic, we must repeat the arguments for both\n     // input and outputs\n-    if (structTypeC->getElementType(0)->isFloatTy())\n+    if (structTypeC->getElementType(i)->isFloatTy())\n       conOs << \"=f,\";\n     else\n       conOs << \"=r,\";\n@@ -706,26 +705,6 @@ void createSts64(llvm::IRBuilderBase &builder, llvm::Value *offset,\n   return;\n }\n \n-llvm::Value *createCvtPack(llvm::IRBuilderBase &builder, llvm::Value *d0,\n-                           llvm::Value *d1) {\n-  std::string funcName(\"__nv_cvt_pack\");\n-\n-  llvm::Type *retTy = builder.getInt32Ty();\n-  llvm::SmallVector<llvm::Value *> args;\n-  llvm::SmallVector<llvm::Type *> argTys;\n-  auto i16Ty = builder.getInt16Ty();\n-\n-  argTys.push_back(i16Ty);\n-  args.push_back(builder.CreateBitCast(d0, i16Ty));\n-  argTys.push_back(i16Ty);\n-  args.push_back(builder.CreateBitCast(d1, i16Ty));\n-\n-  auto *module = builder.GetInsertBlock()->getModule();\n-  auto *func = dyn_cast<llvm::Function>(\n-      getExternalFuncOP(module, funcName, retTy, argTys).getCallee());\n-  return builder.CreateCall(func, args);\n-}\n-\n static llvm::Value *getSRegValue(llvm::IRBuilderBase &builder,\n                                  llvm::StringRef name) {\n   std::string ptxStr;"}, {"filename": "lib/Hopper/HopperHelpers.c", "status": "modified", "additions": 0, "deletions": 9, "changes": 9, "file_content_changes": "@@ -501,12 +501,3 @@ __nv_offset_of_sts64(uint32_t threadIdx, uint32_t rowOfWarp, int32_t elemIdx,\n \n   return offset;\n }\n-\n-__DEVICE__ __attribute__((__always_inline__)) uint32_t\n-__nv_cvt_pack(uint16_t d0, uint16_t d1) {\n-  uint32_t ret;\n-  asm volatile(\"cvt.pack.sat.u16.s32 %0, %1, %2;\\n\"\n-               : \"=r\"(ret)\n-               : \"r\"(d0), \"r\"(d1));\n-  return ret;\n-}"}, {"filename": "python/test/regression/test_performance.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -64,7 +64,7 @@ def nvsmi(attrs):\n @pytest.mark.parametrize('M, N, K, dtype_str',\n                          [(M, N, K, dtype_str)\n                           for M, N, K in matmul_data[DEVICE_NAME].keys()\n-                          for dtype_str in ['float16', 'float32']])\n+                          for dtype_str in ['float16']])\n def test_matmul(M, N, K, dtype_str):\n     stream = torch.cuda.Stream()\n     torch.cuda.set_stream(stream)"}, {"filename": "python/test/unit/language/print_helper.py", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "file_content_changes": "@@ -28,6 +28,11 @@ def kernel_static_print(X, Y, BLOCK: tl.constexpr):\n     tl.store(Y + tl.arange(0, BLOCK), x)\n \n \n+@triton.jit\n+def kernel_no_arg_print():\n+    print(\"\", tl.program_id(0))\n+\n+\n def test_print(func: str, data_type: str):\n     shape = (128, )\n     # limit the range of integers so that the sum does not overflow\n@@ -39,7 +44,11 @@ def test_print(func: str, data_type: str):\n         kernel_print[(1,)](x, y, BLOCK=shape[0])\n     elif func == \"static_print\":\n         kernel_static_print[(1,)](x, y, BLOCK=shape[0])\n-    assert_close(y, x)\n+    elif func == \"no_arg_print\":\n+        kernel_no_arg_print[(1,)](num_warps=4)\n+\n+    if func != \"no_arg_print\":\n+        assert_close(y, x)\n \n \n if __name__ == \"__main__\":"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "file_content_changes": "@@ -2139,9 +2139,6 @@ def test_dot(M, N, K, num_warps, col_a, col_b, epilogue, allow_tf32, in_dtype, o\n         if out_dtype == 'float16':\n             # TODO: support out_dtype=float16 for tl.dot on V100\n             pytest.skip(\"Only test out_dtype=float16 on devices with sm >=80\")\n-    if capability[0] == 9 and out_dtype == 'float16':\n-        # TODO: support out_dtype=float16 for tl.dot on H100\n-        pytest.skip(\"Only test out_dtype=float16 on devices with sm<90\")\n \n     torch.backends.cuda.matmul.allow_tf32 = allow_tf32\n \n@@ -2297,7 +2294,7 @@ def kernel(X, stride_xm, stride_xk,\n     elif in_dtype == 'float16' and out_dtype == tl.float32:\n         assert re.search(r'[mma|wgmma.mma_async].sync.aligned.m\\d+n\\d+k16(?:.row.col)?.f32.f16.f16', ptx)\n     elif in_dtype == 'float16' and out_dtype == tl.float16:\n-        assert 'mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16' in ptx\n+        assert re.search(r'[mma|wgmma.mma_async].sync.aligned.m\\d+n\\d+k16(?:.row.col)?.f16.f16.f16', ptx)\n     elif in_dtype == 'int8':\n         assert 'wgmma.mma_async.sync.aligned' in ptx or\\\n             'mma.sync.aligned.m16n8k32.row.col.satfinite.s32.s8.s8.s32' in ptx"}, {"filename": "python/test/unit/language/test_subprocess.py", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -15,7 +15,7 @@\n \n \n @pytest.mark.parametrize(\"func_type, data_type\",\n-                         [(\"device_print\", data_type) for data_type in torch_types] + [(\"print\", \"int32\"), (\"static_print\", \"int32\")])\n+                         [(\"device_print\", data_type) for data_type in torch_types] + [(\"print\", \"int32\"), (\"static_print\", \"int32\"), (\"no_arg_print\", \"int32\")])\n def test_print(func_type: str, data_type: str):\n     proc = subprocess.Popen([sys.executable, print_path, func_type, data_type], stdout=subprocess.PIPE, shell=False)\n     outs, _ = proc.communicate()\n@@ -29,10 +29,9 @@ def test_print(func_type: str, data_type: str):\n             new_lines.add(value)\n         except Exception as e:\n             print(e)\n-    if func_type != \"static_print\":\n+    if func_type != \"static_print\" and func_type != \"no_arg_print\":\n         for i in range(128):\n             assert i in new_lines\n-        assert len(new_lines) == 128\n     else:\n         assert len(new_lines) == 1\n "}, {"filename": "python/triton/compiler/make_launcher.py", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "file_content_changes": "@@ -198,7 +198,7 @@ def format_of(ty):\n       PyObject *compiled_kernel = NULL;\n \n       {' '.join([f\"{_extracted_type(ty)} _arg{i}; \" for i, ty in signature.items()])}\n-      if (!PyArg_ParseTuple(args, \\\"{format}\\\", &gridX, &gridY, &gridZ, &num_warps, &shared_memory, &_stream, &_function, &launch_enter_hook, &launch_exit_hook, &compiled_kernel, {', '.join(f\"&_arg{i}\" for i, ty in signature.items())})) {{\n+      if (!PyArg_ParseTuple(args, \\\"{format}\\\", &gridX, &gridY, &gridZ, &num_warps, &shared_memory, &_stream, &_function, &launch_enter_hook, &launch_exit_hook, &compiled_kernel{', ' + ', '.join(f\"&_arg{i}\" for i, ty in signature.items()) if len(signature) > 0 else ''})) {{\n         return NULL;\n       }}\n \n@@ -208,7 +208,7 @@ def format_of(ty):\n \n       // raise exception asap\n       {\"; \".join([f\"DevicePtrInfo ptr_info{i} = getPointer(_arg{i}, {i}); if (!ptr_info{i}.valid) return NULL;\" if ty[0] == \"*\" else \"\" for i, ty in signature.items()])};\n-      _launch(gridX, gridY, gridZ, num_warps, shared_memory, (hipStream_t)_stream, (hipFunction_t)_function, {', '.join(f\"ptr_info{i}.dev_ptr\" if ty[0]==\"*\" else f\"_arg{i}\" for i, ty in signature.items())});\n+      _launch(gridX, gridY, gridZ, num_warps, shared_memory, (hipStream_t)_stream, (hipFunction_t)_function{', ' + ', '.join(f\"ptr_info{i}.dev_ptr\" if ty[0]==\"*\" else f\"_arg{i}\" for i, ty in signature.items()) if len(signature) > 0 else ''});\n       if (launch_exit_hook != Py_None) {{\n         PyObject_CallObject(launch_exit_hook, args);\n       }}\n@@ -267,7 +267,7 @@ def format_of(ty):\n \n #define CUDA_CHECK(ans) {{ gpuAssert((ans), __FILE__, __LINE__); }}\n \n-static void _launch(int gridX, int gridY, int gridZ, int num_warps, int num_ctas, int clusterDimX, int clusterDimY, int clusterDimZ, int shared_memory, CUstream stream, CUfunction function, {arg_decls}) {{\n+static void _launch(int gridX, int gridY, int gridZ, int num_warps, int num_ctas, int clusterDimX, int clusterDimY, int clusterDimZ, int shared_memory, CUstream stream, CUfunction function{', ' + arg_decls if len(arg_decls) > 0 else ''}) {{\n   void *params[] = {{ {', '.join(f\"&arg{i}\" for i in params)} }};\n   if(gridX*gridY*gridZ > 0){{\n     if (num_ctas == 1) {{\n@@ -356,7 +356,7 @@ def format_of(ty):\n   PyObject *launch_exit_hook = NULL;\n   PyObject *compiled_kernel = NULL;\n   {' '.join([f\"{_extracted_type(ty)} _arg{i}; \" for i, ty in signature.items()])}\n-  if(!PyArg_ParseTuple(args, \\\"{format}\\\", &gridX, &gridY, &gridZ, &num_warps, &num_ctas, &clusterDimX, &clusterDimY, &clusterDimZ, &shared_memory, &_stream, &_function, &launch_enter_hook, &launch_exit_hook, &compiled_kernel, {', '.join(f\"&_arg{i}\" for i, ty in signature.items())})) {{\n+  if(!PyArg_ParseTuple(args, \\\"{format}\\\", &gridX, &gridY, &gridZ, &num_warps, &num_ctas, &clusterDimX, &clusterDimY, &clusterDimZ, &shared_memory, &_stream, &_function, &launch_enter_hook, &launch_exit_hook, &compiled_kernel{', ' + ', '.join(f\"&_arg{i}\" for i, ty in signature.items()) if len(signature) > 0 else ''})) {{\n     return NULL;\n   }}\n \n@@ -367,7 +367,7 @@ def format_of(ty):\n \n   // raise exception asap\n   {\"; \".join([f\"DevicePtrInfo ptr_info{i} = getPointer(_arg{i}, {i}); if (!ptr_info{i}.valid) return NULL;\" if ty[0] == \"*\" else \"\" for i, ty in signature.items()])};\n-  _launch(gridX, gridY, gridZ, num_warps, num_ctas, clusterDimX, clusterDimY, clusterDimZ, shared_memory, (CUstream)_stream, (CUfunction)_function, {', '.join(f\"ptr_info{i}.dev_ptr\" if ty[0]==\"*\" else f\"_arg{i}\"for i, ty in signature.items())});\n+  _launch(gridX, gridY, gridZ, num_warps, num_ctas, clusterDimX, clusterDimY, clusterDimZ, shared_memory, (CUstream)_stream, (CUfunction)_function{', ' + ', '.join(f\"ptr_info{i}.dev_ptr\" if ty[0]==\"*\" else f\"_arg{i}\"for i, ty in signature.items()) if len(signature) > 0 else ''});\n \n   if (launch_exit_hook != Py_None) {{\n     PyObject_CallObject(launch_exit_hook, args);"}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -980,7 +980,7 @@ def _store_block_pointer(ptr, val, mask, boundary_check, cache, eviction, builde\n         val = broadcast_impl_shape(val, block_shape, builder)\n     assert val.type.is_block(), \"Value argument must be block type or a scalar\"\n     assert block_shape == val.type.get_block_shapes(), \"Block shape and value shape mismatch\"\n-    assert ptr.type.element_ty.element_ty == val.type.element_ty, \"Block element type and value element type mismatch\"\n+    assert ptr.type.element_ty.element_ty == val.type.element_ty, f\"Block element type({ptr.type.element_ty.element_ty}) and value element type({val.type.element_ty}) mismatch\"\n \n     elt_ty = ptr.type.element_ty.element_ty\n     assert elt_ty != tl.int1, \"`tl.int1` should be rewrited in `tl.make_block_ptr`\""}, {"filename": "python/triton/runtime/jit.py", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "file_content_changes": "@@ -352,11 +352,12 @@ def _make_launcher(self):\n         spec_keys = ', '.join(specializations)\n         grid_args = ','.join([f'\"{arg}\": {arg}' for arg in self.arg_names])\n         args_signature = ', '.join(name if dflt == inspect._empty else f'{name} = {dflt}' for name, dflt in zip(self.arg_names, self.arg_defaults))\n+        args_signature = args_signature + ', ' if len(args_signature) > 0 else ''\n \n         src = f\"\"\"\n-def {self.fn.__name__}({args_signature}, grid=None, num_warps=4, num_ctas=1, num_stages=3, enable_warp_specialization=False, extern_libs=None, stream=None, warmup=False, device=None, device_type=None):\n+def {self.fn.__name__}({args_signature}grid=None, num_warps=4, num_ctas=1, num_stages=3, enable_warp_specialization=False, extern_libs=None, stream=None, warmup=False, device=None, device_type=None):\n     from ..compiler import compile, CompiledKernel\n-    sig_key =  {sig_keys},\n+    sig_key = {f'{sig_keys},' if len(sig_keys) > 0 else ()}\n     constexpr_key = {f'{constexpr_keys},' if len(constexpr_keys) > 0 else ()}\n     spec_key = {f'{spec_keys},' if len(spec_keys) > 0 else ()}\n     key = (version_key, sig_key, constexpr_key, spec_key, num_warps, num_ctas, num_stages, enable_warp_specialization, self.debug)\n@@ -399,7 +400,7 @@ def {self.fn.__name__}({args_signature}, grid=None, num_warps=4, num_ctas=1, num\n     if bin is not None:\n       # build dict of constant values\n       args = [{args}]\n-      all_args = {', '.join([f'{arg}' for arg in self.arg_names])},\n+      all_args = {', '.join([f'{arg}' for arg in self.arg_names]) + ', ' if len(self.arg_names) > 0 else ()}\n       configs = self._get_config(*all_args),\n       constants = self._make_constants(constexpr_key)\n       constants.update({{i: None for i, arg in enumerate(all_args) if arg is None}})\n@@ -413,7 +414,7 @@ def {self.fn.__name__}({args_signature}, grid=None, num_warps=4, num_ctas=1, num\n     else:\n       # build dict of constant values\n       args = [{args}]\n-      all_args = {', '.join([f'{arg}' for arg in self.arg_names])},\n+      all_args = {', '.join([f'{arg}' for arg in self.arg_names]) + ', ' if len(self.arg_names) > 0 else ()}\n       configs = self._get_config(*all_args),\n       constants = self._make_constants(constexpr_key)\n       constants.update({{i: None for i, arg in enumerate(all_args) if arg is None}})"}]