[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -104,14 +104,15 @@ jobs:\n       - name: Create artifacts archive\n         if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100')}}\n         run: |\n-          tar -czvf artifacts.tar.gz ~/.triton/cache\n+          cd ~/.triton\n+          tar -czvf artifacts.tar.gz cache\n \n       - name: Upload artifacts archive\n         if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100')}}\n         uses: actions/upload-artifact@v2\n         with:\n           name: artifacts\n-          path: artifacts.tar.gz\n+          path: ~/.triton/artifacts.tar.gz\n \n       - name: Run CXX unittests\n         if: ${{ env.BACKEND != 'ROCM'}}"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 20, "deletions": 11, "changes": 31, "file_content_changes": "@@ -18,7 +18,8 @@ using ::mlir::triton::gpu::SharedEncodingAttr;\n // Data loader for mma.16816 instruction.\n class MMA16816SmemLoader {\n public:\n-  MMA16816SmemLoader(int wpt, ArrayRef<uint32_t> order, uint32_t kOrder,\n+  MMA16816SmemLoader(int wpt, ArrayRef<uint32_t> order,\n+                     ArrayRef<uint32_t> warpsPerCTA, uint32_t kOrder,\n                      int kWidth, ArrayRef<Value> smemStrides,\n                      ArrayRef<int64_t> tileShape, ArrayRef<int> instrShape,\n                      ArrayRef<int> matShape, int perPhase, int maxPhase,\n@@ -54,6 +55,7 @@ class MMA16816SmemLoader {\n \n private:\n   SmallVector<uint32_t> order;\n+  SmallVector<uint32_t> warpsPerCTA;\n   int kOrder;\n   int kWidth;\n   SmallVector<int64_t> tileShape;\n@@ -128,7 +130,6 @@ MMA16816SmemLoader::computeLdmatrixMatOffs(Value warpId, Value lane,\n   Value cMatOff = matOff[order[0]];\n   Value sMatOff = matOff[order[1]];\n   Value cSwizzleMatOff = udiv(cSwizzleOffset, i32_val(cMatShape));\n-  cMatOff = add(cMatOff, cSwizzleMatOff);\n \n   // row offset inside a matrix, each matrix has 8 rows.\n   Value sOffInMat = c;\n@@ -142,8 +143,14 @@ MMA16816SmemLoader::computeLdmatrixMatOffs(Value warpId, Value lane,\n   //          ~~~~~~~ out-of-bound access\n   Value sOff = urem(add(sOffInMat, mul(sMatOff, i32_val(sMatShape))),\n                     i32_val(tileShape[order[1]]));\n+  auto totalNumMats = tileShape[order[0]] / matShape[order[0]];\n+\n   for (int i = 0; i < numPtrs; ++i) {\n     Value cMatOffI = add(cMatOff, i32_val(i * pLoadStrideInMat));\n+    if (warpsPerCTA[order[0]] > totalNumMats ||\n+        totalNumMats % warpsPerCTA[order[0]] != 0)\n+      cMatOffI = urem(cMatOffI, i32_val(totalNumMats));\n+    cMatOffI = add(cMatOffI, cSwizzleMatOff);\n     cMatOffI = xor_(cMatOffI, phase);\n     offs[i] = add(mul(cMatOffI, i32_val(cMatShape)), mul(sOff, sStride));\n   }\n@@ -363,13 +370,15 @@ MMA16816SmemLoader::loadX4(int mat0, int mat1, ArrayRef<Value> offs,\n }\n \n MMA16816SmemLoader::MMA16816SmemLoader(\n-    int wpt, ArrayRef<uint32_t> order, uint32_t kOrder, int kWidth,\n-    ArrayRef<Value> smemStrides, ArrayRef<int64_t> tileShape,\n-    ArrayRef<int> instrShape, ArrayRef<int> matShape, int perPhase,\n-    int maxPhase, int elemBytes, ConversionPatternRewriter &rewriter,\n+    int wpt, ArrayRef<uint32_t> order, ArrayRef<uint32_t> warpsPerCTA,\n+    uint32_t kOrder, int kWidth, ArrayRef<Value> smemStrides,\n+    ArrayRef<int64_t> tileShape, ArrayRef<int> instrShape,\n+    ArrayRef<int> matShape, int perPhase, int maxPhase, int elemBytes,\n+    ConversionPatternRewriter &rewriter,\n     TritonGPUToLLVMTypeConverter *typeConverter, const Location &loc)\n-    : order(order.begin(), order.end()), kOrder(kOrder), kWidth(kWidth),\n-      tileShape(tileShape.begin(), tileShape.end()),\n+    : order(order.begin(), order.end()),\n+      warpsPerCTA(warpsPerCTA.begin(), warpsPerCTA.end()), kOrder(kOrder),\n+      kWidth(kWidth), tileShape(tileShape.begin(), tileShape.end()),\n       instrShape(instrShape.begin(), instrShape.end()),\n       matShape(matShape.begin(), matShape.end()), perPhase(perPhase),\n       maxPhase(maxPhase), elemBytes(elemBytes), rewriter(rewriter), loc(loc),\n@@ -471,9 +480,9 @@ getLoadMatrixFn(Value tensor, const SharedMemoryObject &smemObj,\n   // (a, b) is the coordinate.\n   auto load = [=, &rewriter, &vals](int a, int b) {\n     MMA16816SmemLoader loader(\n-        wpt, sharedLayout.getOrder(), kOrder, kWidth, smemObj.strides,\n-        tensorTy.getShape() /*tileShape*/, instrShape, matShape, perPhase,\n-        maxPhase, elemBytes, rewriter, typeConverter, loc);\n+        wpt, sharedLayout.getOrder(), mmaLayout.getWarpsPerCTA(), kOrder,\n+        kWidth, smemObj.strides, tensorTy.getShape() /*tileShape*/, instrShape,\n+        matShape, perPhase, maxPhase, elemBytes, rewriter, typeConverter, loc);\n     Value cSwizzleOffset = smemObj.getCSwizzleOffset(order[0]);\n     SmallVector<Value> offs =\n         loader.computeOffsets(warpId, lane, cSwizzleOffset);"}, {"filename": "python/triton/compiler/compiler.py", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -445,7 +445,8 @@ def compile(fn, **kwargs):\n         metadata = {\"num_warps\": num_warps,\n                     \"num_stages\": num_stages,\n                     \"constants\": _get_jsonable_constants(constants),\n-                    \"debug\": debug}\n+                    \"debug\": debug,\n+                    \"arch\": arch, }\n         if ext == \"ptx\":\n             assert \"shared\" in kwargs, \"ptx compilation must provide shared memory size\"\n             metadata[\"shared\"] = kwargs[\"shared\"]"}]