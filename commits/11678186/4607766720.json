[{"filename": "include/triton/Dialect/Triton/IR/Dialect.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -37,14 +37,14 @@ class DialectInferLayoutInterface\n   virtual LogicalResult\n   inferExpandDimsOpEncoding(Attribute operandEncoding, unsigned axis,\n                             Attribute &resultEncoding,\n-                            Optional<Location> location) const = 0;\n+                            std::optional<Location> location) const = 0;\n \n   // Note: this function only verify operand encoding but doesn't infer result\n   // encoding\n   virtual LogicalResult\n   inferDotOpEncoding(Attribute operandEncoding, unsigned opIdx,\n                      Attribute retEncoding,\n-                     Optional<Location> location) const = 0;\n+                     std::optional<Location> location) const = 0;\n };\n \n } // namespace triton"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.cpp", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "file_content_changes": "@@ -17,21 +17,21 @@ TritonGPUToLLVMTypeConverter::TritonGPUToLLVMTypeConverter(\n     MLIRContext *ctx, LowerToLLVMOptions &option,\n     const DataLayoutAnalysis *analysis)\n     : LLVMTypeConverter(ctx, option, analysis) {\n-  addConversion([&](triton::PointerType type) -> llvm::Optional<Type> {\n+  addConversion([&](triton::PointerType type) -> std::optional<Type> {\n     return convertTritonPointerType(type);\n   });\n-  addConversion([&](RankedTensorType type) -> llvm::Optional<Type> {\n+  addConversion([&](RankedTensorType type) -> std::optional<Type> {\n     return convertTritonTensorType(type);\n   });\n   // Internally store float8 as int8\n-  addConversion([&](mlir::Float8E4M3FNType type) -> llvm::Optional<Type> {\n+  addConversion([&](mlir::Float8E4M3FNType type) -> std::optional<Type> {\n     return IntegerType::get(type.getContext(), 8);\n   });\n-  addConversion([&](mlir::Float8E5M2Type type) -> llvm::Optional<Type> {\n+  addConversion([&](mlir::Float8E5M2Type type) -> std::optional<Type> {\n     return IntegerType::get(type.getContext(), 8);\n   });\n   // Internally store bfloat16 as int16\n-  addConversion([&](BFloat16Type type) -> llvm::Optional<Type> {\n+  addConversion([&](BFloat16Type type) -> std::optional<Type> {\n     return IntegerType::get(type.getContext(), 16);\n   });\n }"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -257,7 +257,7 @@ void StoreOp::build(::mlir::OpBuilder &builder, ::mlir::OperationState &state,\n \n //-- TransOp --\n mlir::LogicalResult mlir::triton::TransOp::inferReturnTypes(\n-    MLIRContext *context, Optional<Location> location, ValueRange operands,\n+    MLIRContext *context, std::optional<Location> location, ValueRange operands,\n     DictionaryAttr attributes, RegionRange regions,\n     SmallVectorImpl<Type> &inferredReturnTypes) {\n   // type is the same as the input\n@@ -284,7 +284,7 @@ mlir::LogicalResult mlir::triton::TransOp::inferReturnTypes(\n \n //-- DotOp --\n mlir::LogicalResult mlir::triton::DotOp::inferReturnTypes(\n-    MLIRContext *context, Optional<Location> location, ValueRange operands,\n+    MLIRContext *context, std::optional<Location> location, ValueRange operands,\n     DictionaryAttr attributes, RegionRange regions,\n     SmallVectorImpl<Type> &inferredReturnTypes) {\n   // type is the same as the accumulator\n@@ -309,7 +309,7 @@ mlir::LogicalResult mlir::triton::DotOp::inferReturnTypes(\n \n //-- ReduceOp --\n mlir::LogicalResult mlir::triton::ReduceOp::inferReturnTypes(\n-    MLIRContext *context, Optional<Location> location, ValueRange operands,\n+    MLIRContext *context, std::optional<Location> location, ValueRange operands,\n     DictionaryAttr attributes, RegionRange regions,\n     SmallVectorImpl<Type> &inferredReturnTypes) {\n   // infer shape\n@@ -371,7 +371,7 @@ OpFoldResult SplatOp::fold(FoldAdaptor adaptor) {\n \n //-- ExpandDimsOp --\n mlir::LogicalResult mlir::triton::ExpandDimsOp::inferReturnTypes(\n-    MLIRContext *context, Optional<Location> loc, ValueRange operands,\n+    MLIRContext *context, std::optional<Location> loc, ValueRange operands,\n     DictionaryAttr attributes, RegionRange regions,\n     SmallVectorImpl<Type> &inferredReturnTypes) {\n   // infer shape"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "file_content_changes": "@@ -897,7 +897,7 @@ struct TritonGPUInferLayoutInterface\n   LogicalResult\n   inferExpandDimsOpEncoding(Attribute operandEncoding, unsigned axis,\n                             Attribute &resultEncoding,\n-                            Optional<Location> location) const override {\n+                            std::optional<Location> location) const override {\n     auto sliceEncoding = operandEncoding.dyn_cast<SliceEncodingAttr>();\n     if (!sliceEncoding)\n       return emitOptionalError(\n@@ -909,9 +909,10 @@ struct TritonGPUInferLayoutInterface\n     return success();\n   }\n \n-  LogicalResult inferDotOpEncoding(Attribute operandEncoding, unsigned opIdx,\n-                                   Attribute retEncoding,\n-                                   Optional<Location> location) const override {\n+  LogicalResult\n+  inferDotOpEncoding(Attribute operandEncoding, unsigned opIdx,\n+                     Attribute retEncoding,\n+                     std::optional<Location> location) const override {\n     if (auto dotOpEnc = operandEncoding.dyn_cast<DotOperandEncodingAttr>()) {\n       if (opIdx != dotOpEnc.getOpIdx())\n         return emitOptionalError(location, \"Wrong opIdx\");"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -63,8 +63,8 @@ class Prefetcher {\n \n   Value generatePrefetch(Value v, unsigned opIdx, bool isPrologue,\n                          Attribute dotEncoding, OpBuilder &builder,\n-                         llvm::Optional<int64_t> offsetK = std::nullopt,\n-                         llvm::Optional<int64_t> shapeK = std::nullopt);\n+                         std::optional<int64_t> offsetK = std::nullopt,\n+                         std::optional<int64_t> shapeK = std::nullopt);\n \n public:\n   Prefetcher() = delete;\n@@ -82,8 +82,8 @@ class Prefetcher {\n \n Value Prefetcher::generatePrefetch(Value v, unsigned opIdx, bool isPrologue,\n                                    Attribute dotEncoding, OpBuilder &builder,\n-                                   llvm::Optional<int64_t> offsetK,\n-                                   llvm::Optional<int64_t> shapeK) {\n+                                   std::optional<int64_t> offsetK,\n+                                   std::optional<int64_t> shapeK) {\n   // opIdx: 0 => a, 1 => b\n   auto type = v.getType().cast<RankedTensorType>();\n   SmallVector<int64_t> shape{type.getShape().begin(), type.getShape().end()};"}, {"filename": "lib/Dialect/TritonGPU/Transforms/TritonGPUConversion.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -40,7 +40,7 @@ TritonGPUTypeConverter::TritonGPUTypeConverter(MLIRContext *context,\n   // This will create newArg, and map(origArg, newArg)\n   addArgumentMaterialization([&](OpBuilder &builder,\n                                  RankedTensorType tensorType, ValueRange inputs,\n-                                 Location loc) -> llvm::Optional<Value> {\n+                                 Location loc) -> std::optional<Value> {\n     llvm_unreachable(\"Argument rematerialization should not happen in Triton \"\n                      \"-> TritonGPU conversion\");\n     return std::nullopt;\n@@ -50,7 +50,7 @@ TritonGPUTypeConverter::TritonGPUTypeConverter(MLIRContext *context,\n   // convert origValue to newValue\n   addSourceMaterialization([&](OpBuilder &builder, RankedTensorType tensorType,\n                                ValueRange inputs,\n-                               Location loc) -> llvm::Optional<Value> {\n+                               Location loc) -> std::optional<Value> {\n     llvm_unreachable(\"Source rematerialization should not happen in Triton -> \"\n                      \"TritonGPU Conversion\");\n     return std::nullopt;\n@@ -63,7 +63,7 @@ TritonGPUTypeConverter::TritonGPUTypeConverter(MLIRContext *context,\n                                ValueRange inputs, Location loc) {\n     auto cast =\n         builder.create<triton::gpu::ConvertLayoutOp>(loc, tensorType, inputs);\n-    return Optional<Value>(cast.getResult());\n+    return std::optional<Value>(cast.getResult());\n   });\n }\n "}]