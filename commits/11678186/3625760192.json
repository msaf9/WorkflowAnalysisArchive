[{"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -96,6 +96,9 @@ A_{3, 2}  A_{3, 3}  A_{3, 0}  A_{3, 1} ...   [phase 1] /\n           bool is_row = order[0] != 0;\n           bool is_vec4 = opIdx == 0 ? !is_row && (shape[order[0]] <= 16) :\n               is_row && (shape[order[0]] <= 16);\n+          // TODO[Superjomn]: Support the case when is_vec4=false later\n+          // Currently, we only support ld.v2, for the mma layout varies with different ld vector width.\n+          is_vec4 = true;\n           int pack_size = opIdx == 0 ? ((is_row || is_vec4) ? 1 : 2) :\n                                        ((is_row && !is_vec4) ? 2 : 1);\n           int rep = 2 * pack_size;"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotHelpers.h", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "file_content_changes": "@@ -1334,6 +1334,10 @@ Value DotOpMmaV1ConversionHelper::loadA(\n \n   bool isARow = order[0] != 0;\n   bool isAVec4 = !isARow && shape[order[0]] <= 16; // fp16*4 = 16bytes\n+  // TODO[Superjomn]: Support the case when isAVec4=false later\n+  // Currently, we only support ld.v2, for the mma layout varies with different\n+  // ld vector width.\n+  isAVec4 = true;\n   int packSize0 = (isARow || isAVec4) ? 1 : 2;\n \n   SmallVector<int> fpw({2, 2, 1});\n@@ -1462,6 +1466,10 @@ Value DotOpMmaV1ConversionHelper::loadB(\n \n   bool isBRow = order[0] != 0;\n   bool isBVec4 = isBRow && shape[order[0]] <= 16;\n+  // TODO[Superjomn]: Support the case when isBVec4=false later\n+  // Currently, we only support ld.v2, for the mma layout varies with different\n+  // ld vector width.\n+  isBVec4 = true;\n   int packSize1 = (isBRow && !isBVec4) ? 2 : 1;\n   SmallVector<int> fpw({2, 2, 1});\n   SmallVector<int> rep({0, 2 * packSize1, 1});       // pad M with 0"}, {"filename": "python/tests/test_gemm.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -301,6 +301,7 @@ def matmul_kernel(\n         [16, 16, 16],\n         [16, 16, 32],\n         [32, 16, 16],\n+        [32, 32, 32],\n         [128, 16, 16],\n         # diabled due to the wrong vec in shared layout, the backend works if right vec passed.\n         # [32, 32, 32],"}]