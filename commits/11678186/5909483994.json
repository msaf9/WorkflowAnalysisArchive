[{"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/MMAv2.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -211,7 +211,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   auto callMma = [&](unsigned m, unsigned n, unsigned k) {\n     unsigned colsPerThread = repN * 2;\n     PTXBuilder builder;\n-    auto &mma = *builder.create(mmaInstrPtx.at(mmaType));\n+    auto &mma = *builder.create(mmaInstructions.at(mmaType));\n     // using =r for float32 works but leads to less readable ptx.\n     bool isIntMMA = dTensorTy.getElementType().isInteger(32);\n     bool isAccF16 = dTensorTy.getElementType().isF16();\n@@ -254,7 +254,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n       mma(retArgs, aArgs, bArgs, cArgs);\n     }\n     Value mmaOut =\n-      builder.launch(rewriter, loc, getMmaRetType(mmaType, op.getContext()));\n+        builder.launch(rewriter, loc, getMmaRetType(mmaType, op.getContext()));\n \n     Type elemTy = mmaOut.getType().cast<LLVM::LLVMStructType>().getBody()[0];\n     for (int i = 0; i < numMmaRets; ++i) {"}]