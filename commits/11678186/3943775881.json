[{"filename": "lib/Target/LLVMIR/LLVMIRTranslation.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -258,7 +258,6 @@ translateTritonGPUToLLVMIR(llvm::LLVMContext *llvmContext,\n     return nullptr;\n   }\n \n-  // llvm::outs() << module << \"\\n\";\n   auto llvmIR = translateLLVMToLLVMIR(llvmContext, module);\n   if (!llvmIR) {\n     llvm::errs() << \"Translate to LLVM IR failed\";"}, {"filename": "python/test/unit/operators/test_matmul.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -46,7 +46,7 @@\n                 # variable input\n                 (128, 128, 32, 1, 4, 2, 1024, 1024, 1024, AT, BT, DTYPE),\n                 (128, 128, 32, 1, 4, 2, 384, 128, 640, AT, BT, DTYPE),\n-                (128, 128, 32, 1, 4, 2, 8107, 2233, 256, AT, BT, DTYPE),\n+                (128, 128, 32, 1, 4, 2, 107, 233, 256, AT, BT, DTYPE),\n                 (128, 128, 32, 1, 4, 2, 107, 233, 311, AT, BT, DTYPE),\n             ] for DTYPE in [\"float16\", \"bfloat16\", \"float32\"] for AT in [False, True] for BT in [False, True]\n         ],"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -1552,7 +1552,6 @@ def _init_handles(self):\n             raise OutOfResources(self.shared, max_shared, \"shared memory\")\n         mod, func, n_regs, n_spills = cuda_utils.load_binary(self.metadata[\"name\"], self.asm[\"cubin\"], self.shared, device)\n         # print(self.shared, n_regs, n_spills)\n-        # print(self.shared, n_regs, n_spills)\n         self.cu_module = mod\n         self.cu_function = func\n "}, {"filename": "python/triton/ops/matmul.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -134,7 +134,7 @@ def _call(a, b):\n         # accumulator types\n         ACC_TYPE = tl.float32 if a.dtype in [torch.float16, torch.bfloat16, torch.float32] else tl.int32\n         # launch kernel\n-        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']) * triton.cdiv(N, META['BLOCK_N']), META['SPLIT_K'], 1)\n+        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']) * triton.cdiv(N, META['BLOCK_N']), META['SPLIT_K'])\n         _kernel[grid](a, b, c, M, N, K,\n                       a.stride(0), a.stride(1),\n                       b.stride(0), b.stride(1),"}]