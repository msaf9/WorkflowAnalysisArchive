[{"filename": "python/triton/code_gen.py", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -24,6 +24,7 @@\n \n current_stream = lambda device: torch.cuda.current_stream(device).cuda_stream\n \n+\n def mangle_ty(ty):\n     if ty.is_ptr():\n         return 'P' + mangle_ty(ty.element_ty)\n@@ -932,8 +933,8 @@ def __call__(self, *wargs, grid, num_warps=4, num_stages=2, **kwargs):\n         cache_key = self.fn.cache_key + cc\n         # query current stream\n         stream = current_stream(device)\n-        return _triton.runtime.launch(wargs, self.fn.do_not_specialize, cache_key, self.fn.arg_names, \n-                                      device, stream, self.fn.bin_cache, num_warps, num_stages, self.add_to_cache, \n+        return _triton.runtime.launch(wargs, self.fn.do_not_specialize, cache_key, self.fn.arg_names,\n+                                      device, stream, self.fn.bin_cache, num_warps, num_stages, self.add_to_cache,\n                                       grid)\n \n "}]