[{"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "file_content_changes": "@@ -74,11 +74,9 @@ A_{3, 2}  A_{3, 3}  A_{3, 0}  A_{3, 1} ...   [phase 1] /\n   let builders = [\n     AttrBuilder<(ins \"DotOperandEncodingAttr\":$dotOpEnc,\n                      \"ArrayRef<int64_t>\":$shape,\n+                     \"ArrayRef<unsigned>\":$order,\n                      \"Type\":$eltTy), [{\n         auto mmaEnc = dotOpEnc.getParent().dyn_cast<MmaEncodingAttr>();\n-        // Only support row major for now\n-        // TODO(Keren): check why column major code crashes\n-        SmallVector<unsigned> order = {1, 0};\n \n         if(!mmaEnc)\n           return $_get(context, 1, 1, 1, order);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 28, "deletions": 23, "changes": 51, "file_content_changes": "@@ -464,21 +464,6 @@ struct SharedMemoryObject {\n     }\n   }\n \n-  // XXX(Keren): a special allocator for 3d tensors. It's a workaround for\n-  // now since we don't have a correct way to encoding 3d tensors in the\n-  // pipeline pass.\n-  SharedMemoryObject(Value base, ArrayRef<int64_t> shape, Location loc,\n-                     ConversionPatternRewriter &rewriter)\n-      : base(base) {\n-    auto stride = 1;\n-    for (auto dim : llvm::reverse(shape)) {\n-      strides.emplace_back(i32_val(stride));\n-      offsets.emplace_back(i32_val(0));\n-      stride *= dim;\n-    }\n-    strides = llvm::to_vector<4>(llvm::reverse(strides));\n-  }\n-\n   SmallVector<Value> getElems() const {\n     SmallVector<Value> elems;\n     elems.push_back(base);\n@@ -1453,9 +1438,10 @@ struct BroadcastOpConversion\n     SmallVector<int64_t> resultLogicalShape(2 * rank);\n     SmallVector<unsigned> broadcastDims;\n     for (unsigned d = 0; d < rank; ++d) {\n-      unsigned resultShapePerCTA = triton::gpu::getSizePerThread(resultLayout)[d] *\n-                                   triton::gpu::getThreadsPerWarp(resultLayout)[d] *\n-                                   triton::gpu::getWarpsPerCTA(resultLayout)[d];\n+      unsigned resultShapePerCTA =\n+          triton::gpu::getSizePerThread(resultLayout)[d] *\n+          triton::gpu::getThreadsPerWarp(resultLayout)[d] *\n+          triton::gpu::getWarpsPerCTA(resultLayout)[d];\n       int64_t numCtas = ceil<unsigned>(resultShape[d], resultShapePerCTA);\n       if (srcShape[d] != resultShape[d]) {\n         assert(srcShape[d] == 1);\n@@ -1465,10 +1451,12 @@ struct BroadcastOpConversion\n             std::max<unsigned>(1, triton::gpu::getSizePerThread(srcLayout)[d]);\n       } else {\n         srcLogicalShape[d] = numCtas;\n-        srcLogicalShape[d + rank] = triton::gpu::getSizePerThread(resultLayout)[d];\n+        srcLogicalShape[d + rank] =\n+            triton::gpu::getSizePerThread(resultLayout)[d];\n       }\n       resultLogicalShape[d] = numCtas;\n-      resultLogicalShape[d + rank] = triton::gpu::getSizePerThread(resultLayout)[d];\n+      resultLogicalShape[d + rank] =\n+          triton::gpu::getSizePerThread(resultLayout)[d];\n \n       srcLogicalOrder[d] = order[d] + rank;\n       srcLogicalOrder[d + rank] = order[d];\n@@ -1983,6 +1971,7 @@ struct PrintfOpConversion\n       return \"%u\";\n     }\n     assert(false && \"not supported type\");\n+    return \"\";\n   }\n \n   // declare vprintf(i8*, i8*) as external function\n@@ -2251,8 +2240,18 @@ struct AllocTensorOpConversion\n         getTypeConverter()->convertType(resultTy.getElementType());\n     auto elemPtrTy = ptr_ty(llvmElemTy, 3);\n     smemBase = bitcast(smemBase, elemPtrTy);\n+    auto order = resultTy.getEncoding().cast<SharedEncodingAttr>().getOrder();\n+    // workaround for 3D tensors\n+    // TODO: We need to modify the pipeline pass to give a proper shared encoding to 3D tensors\n+    SmallVector<unsigned> newOrder;\n+    if (resultTy.getShape().size() == 3) \n+      newOrder = {1 + order[0], 1 + order[1], 0};\n+    else\n+      newOrder = SmallVector<unsigned>(order.begin(), order.end());\n+\n+    \n     auto smemObj =\n-        SharedMemoryObject(smemBase, resultTy.getShape(), loc, rewriter);\n+        SharedMemoryObject(smemBase, resultTy.getShape(), newOrder, loc, rewriter);\n     auto retVal = getStructFromSharedMemoryObject(loc, smemObj, rewriter);\n     rewriter.replaceOp(op, retVal);\n     return success();\n@@ -2302,6 +2301,10 @@ struct ExtractSliceOpConversion\n         strideVals.emplace_back(smemObj.strides[i]);\n       }\n     }\n+\n+    // llvm::outs() << \"extract slice\\n\";\n+    // llvm::outs() << strideVals[0] << \" \" << smemObj.strides[1] << \"\\n\";\n+    // llvm::outs() << strideVals[1] << \" \" << smemObj.strides[2] << \"\\n\";\n     auto llvmElemTy = getTypeConverter()->convertType(srcTy.getElementType());\n     auto elemPtrTy = ptr_ty(llvmElemTy, 3);\n     auto resTy = op.getType().dyn_cast<RankedTensorType>();\n@@ -3258,8 +3261,8 @@ class MMA16816SmemLoader {\n     cMatShape = matShape[order[0]];\n     sMatShape = matShape[order[1]];\n \n-    cStride = smemStrides[1];\n-    sStride = smemStrides[0];\n+    cStride = smemStrides[order[0]];\n+    sStride = smemStrides[order[1]];\n \n     // rule: k must be the fast-changing axis.\n     needTrans = kOrder != order[0];\n@@ -5479,6 +5482,7 @@ Value convertSplatLikeOpWithMmaLayout(const MmaEncodingAttr &layout,\n   }\n \n   assert(false && \"Unsupported mma layout found\");\n+  return {};\n }\n \n class TritonGPUToLLVMTypeConverter : public LLVMTypeConverter {\n@@ -6198,6 +6202,7 @@ class ConvertTritonGPUToLLVM\n             dstType.getShape(), dstType.getElementType(),\n             triton::gpu::SharedEncodingAttr::get(mod.getContext(), dstDotOp,\n                                                  srcType.getShape(),\n+                                                 getOrder(srcBlocked),\n                                                  srcType.getElementType()));\n         auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), tmpType, cvtOp.getOperand());"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -201,7 +201,9 @@ LogicalResult LoopPipeliner::initialize() {\n                                              ty.getShape().end());\n             bufferShape.insert(bufferShape.begin(), numStages);\n             auto sharedEnc = ttg::SharedEncodingAttr::get(\n-                ty.getContext(), dotOpEnc, ty.getShape(), ty.getElementType());\n+                ty.getContext(), dotOpEnc, ty.getShape(),\n+                triton::gpu::getOrder(ty.getEncoding()),\n+                ty.getElementType());\n             loadsBufferType[loadOp] = RankedTensorType::get(\n                 bufferShape, ty.getElementType(), sharedEnc);\n           }"}, {"filename": "lib/Target/LLVMIR/LLVMIRTranslation.cpp", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "file_content_changes": "@@ -99,9 +99,6 @@ translateLLVMToLLVMIR(llvm::LLVMContext *llvmContext, mlir::ModuleOp module) {\n     return nullptr;\n   }\n \n-  // Initialize LLVM targets.\n-  mlir::ExecutionEngine::setupTargetTriple(llvmModule.get());\n-\n   auto optPipeline = mlir::makeOptimizingTransformer(\n       /*optLevel=*/3, /*sizeLevel=*/0,\n       /*targetMachine=*/nullptr);"}, {"filename": "lib/Target/PTX/PTXTranslation.cpp", "status": "modified", "additions": 45, "deletions": 49, "changes": 94, "file_content_changes": "@@ -12,29 +12,28 @@\n \n namespace triton {\n \n-static void init_llvm() {\n+static void initLLVM() {\n   LLVMInitializeNVPTXTargetInfo();\n   LLVMInitializeNVPTXTarget();\n   LLVMInitializeNVPTXTargetMC();\n   LLVMInitializeNVPTXAsmPrinter();\n }\n \n-static bool find_and_replace(std::string &str, const std::string &begin,\n-                             const std::string &end,\n-                             const std::string &target) {\n-  size_t start_replace = str.find(begin);\n-  if (start_replace == std::string::npos)\n+static bool findAndReplace(std::string &str, const std::string &begin,\n+                           const std::string &end, const std::string &target) {\n+  size_t startReplace = str.find(begin);\n+  if (startReplace == std::string::npos)\n     return false;\n-  size_t end_replace = str.find(end, start_replace);\n-  if (end_replace == std::string::npos)\n+  size_t endReplace = str.find(end, startReplace);\n+  if (endReplace == std::string::npos)\n     return false;\n-  str.replace(start_replace, end_replace + 1 - start_replace, target);\n+  str.replace(startReplace, endReplace + 1 - startReplace, target);\n   return true;\n }\n \n-static std::string llir_to_ptx(llvm::Module *module, int capability, int ptx) {\n+static void linkExternal(llvm::Module &module) {\n   bool hasExternal = false;\n-  for (auto &func : *module) {\n+  for (auto &func : module) {\n     if (func.hasExternalLinkage()) {\n       hasExternal = true;\n       break;\n@@ -51,98 +50,95 @@ static std::string llir_to_ptx(llvm::Module *module, int capability, int ptx) {\n                                           .parent_path() /\n                                       \"python\" / \"triton\" / \"language\" /\n                                       \"libdevice.10.bc\";\n-    if (mlir::triton::linkExternLib(*module, libdevice.string()))\n+    if (mlir::triton::linkExternLib(module, libdevice.string()))\n       llvm::errs() << \"link failed for: \" << libdevice.string();\n-  }\n \n-  // please check https://llvm.org/docs/NVPTXUsage.html#reflection-parameters\n-  // this will enable fast math path in libdevice\n-  // for example, when enable nvvm-reflect-ftz, sqrt.approx.f32 will change to\n-  // sqrt.approx.ftz.f32\n-  {\n-    auto &ctx = module->getContext();\n+    // please check https://llvm.org/docs/NVPTXUsage.html#reflection-parameters\n+    // this will enable fast math path in libdevice\n+    // for example, when enable nvvm-reflect-ftz, sqrt.approx.f32 will change to\n+    // sqrt.approx.ftz.f32\n+    auto &ctx = module.getContext();\n     llvm::Type *I32 = llvm::Type::getInt32Ty(ctx);\n     llvm::Metadata *mdFour =\n         llvm::ConstantAsMetadata::get(llvm::ConstantInt::getSigned(I32, 4));\n     llvm::Metadata *mdName = llvm::MDString::get(ctx, \"nvvm-reflect-ftz\");\n     llvm::Metadata *mdOne =\n         llvm::ConstantAsMetadata::get(llvm::ConstantInt::getSigned(I32, 1));\n     llvm::MDNode *reflect = llvm::MDNode::get(ctx, {mdFour, mdName, mdOne});\n-    module->addModuleFlag(reflect);\n+    module.addModuleFlag(reflect);\n   }\n+}\n+\n+std::string translateLLVMIRToPTX(llvm::Module &module, int cc, int version) {\n+  linkExternal(module);\n+\n   // LLVM version in use may not officially support target hardware\n-  int max_nvvm_cc = 75;\n-  // int max_nvvm_ptx = 74;\n+  int maxNNVMCC = 75;\n   // options\n   auto options = llvm::cl::getRegisteredOptions();\n-  auto *short_ptr =\n+  auto *shortPtr =\n       static_cast<llvm::cl::opt<bool> *>(options[\"nvptx-short-ptr\"]);\n-  assert(short_ptr);\n-  short_ptr->setValue(true);\n+  assert(shortPtr);\n+  shortPtr->setValue(true);\n   // compute capability\n-  std::string sm = \"sm_\" + std::to_string(capability);\n+  std::string sm = \"sm_\" + std::to_string(cc);\n   // max PTX version\n-  int ptx_major = ptx / 10;\n-  int ptx_minor = ptx % 10;\n+  int ptxMajor = version / 10;\n+  int ptxMinor = version % 10;\n   // create\n   llvm::SmallVector<char, 0> buffer;\n   std::string triple = \"nvptx64-nvidia-cuda\";\n-  std::string proc = \"sm_\" + std::to_string(std::min(capability, max_nvvm_cc));\n+  std::string proc = \"sm_\" + std::to_string(std::min(cc, maxNNVMCC));\n   std::string layout = \"\";\n   std::string features = \"\";\n   // std::string features = \"+ptx\" + std::to_string(std::min(ptx,\n   // max_nvvm_ptx));\n-  init_llvm();\n+  initLLVM();\n   // verify and store llvm\n   llvm::legacy::PassManager pm;\n   pm.add(llvm::createVerifierPass());\n-  pm.run(*module);\n+  pm.run(module);\n   // module->print(llvm::outs(), nullptr);\n \n   // create machine\n-  module->setTargetTriple(triple);\n+  module.setTargetTriple(triple);\n   std::string error;\n   auto target =\n-      llvm::TargetRegistry::lookupTarget(module->getTargetTriple(), error);\n+      llvm::TargetRegistry::lookupTarget(module.getTargetTriple(), error);\n   llvm::TargetOptions opt;\n   opt.AllowFPOpFusion = llvm::FPOpFusion::Fast;\n   opt.UnsafeFPMath = false;\n   opt.NoInfsFPMath = false;\n   opt.NoNaNsFPMath = true;\n   llvm::TargetMachine *machine = target->createTargetMachine(\n-      module->getTargetTriple(), proc, features, opt, llvm::Reloc::PIC_,\n+      module.getTargetTriple(), proc, features, opt, llvm::Reloc::PIC_,\n       llvm::None, llvm::CodeGenOpt::Aggressive);\n   // set data layout\n   if (layout.empty())\n-    module->setDataLayout(machine->createDataLayout());\n+    module.setDataLayout(machine->createDataLayout());\n   else\n-    module->setDataLayout(layout);\n+    module.setDataLayout(layout);\n   // emit machine code\n-  for (llvm::Function &f : module->functions())\n+  for (llvm::Function &f : module.functions())\n     f.addFnAttr(llvm::Attribute::AlwaysInline);\n   llvm::legacy::PassManager pass;\n   llvm::raw_svector_ostream stream(buffer);\n   // emit\n   machine->addPassesToEmitFile(pass, stream, nullptr,\n                                llvm::CodeGenFileType::CGFT_AssemblyFile);\n-  pass.run(*module);\n+  pass.run(module);\n \n   // post-process\n   std::string result(buffer.begin(), buffer.end());\n-  find_and_replace(result, \".version\", \"\\n\",\n-                   \".version \" + std::to_string(ptx_major) + \".\" +\n-                       std::to_string(ptx_minor) + \"\\n\");\n-  find_and_replace(result, \".target\", \"\\n\", \".target \" + sm + \"\\n\");\n-  while (find_and_replace(result, \"\\t// begin inline asm\", \"\\n\", \"\"))\n+  findAndReplace(result, \".version\", \"\\n\",\n+                 \".version \" + std::to_string(ptxMajor) + \".\" +\n+                     std::to_string(ptxMinor) + \"\\n\");\n+  findAndReplace(result, \".target\", \"\\n\", \".target \" + sm + \"\\n\");\n+  while (findAndReplace(result, \"\\t// begin inline asm\", \"\\n\", \"\"))\n     ;\n-  while (find_and_replace(result, \"\\t// end inline asm\", \"\\n\", \"\"))\n+  while (findAndReplace(result, \"\\t// end inline asm\", \"\\n\", \"\"))\n     ;\n   return result;\n }\n \n-std::string translateLLVMIRToPTX(llvm::Module &module, int cc, int version) {\n-  auto ptxCode = llir_to_ptx(&module, cc, version);\n-  return ptxCode;\n-}\n-\n } // namespace triton"}, {"filename": "python/setup.py", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "file_content_changes": "@@ -6,7 +6,6 @@\n import subprocess\n import sys\n import tarfile\n-import tempfile\n import urllib.request\n from distutils.version import LooseVersion\n from typing import NamedTuple\n@@ -26,7 +25,9 @@ def get_build_type():\n     elif check_env_flag(\"REL_WITH_DEB_INFO\"):\n         return \"RelWithDebInfo\"\n     else:\n-        return \"Release\"\n+        return \"Debug\"\n+        # TODO(Keren): Restore this before we merge into master\n+        #return \"Release\"\n \n \n # --- third party packages -----\n@@ -124,19 +125,14 @@ def run(self):\n             self.build_extension(ext)\n \n     def build_extension(self, ext):\n-        self.debug = True\n         lit_dir = shutil.which('lit')\n         triton_cache_path = os.path.join(os.environ[\"HOME\"], \".triton\")\n         # lit is used by the test suite\n         thirdparty_cmake_args = get_thirdparty_packages(triton_cache_path)\n         extdir = os.path.abspath(os.path.dirname(self.get_ext_fullpath(ext.path)))\n         # create build directories\n-        build_suffix = 'debug' if self.debug else 'release'\n-        llvm_build_dir = os.path.join(tempfile.gettempdir(), \"llvm-\" + build_suffix)\n         if not os.path.exists(self.build_temp):\n             os.makedirs(self.build_temp)\n-        if not os.path.exists(llvm_build_dir):\n-            os.makedirs(llvm_build_dir)\n         # python directories\n         python_include_dir = distutils.sysconfig.get_python_inc()\n         cmake_args = [\n@@ -145,13 +141,13 @@ def build_extension(self, ext):\n             \"-DTRITON_BUILD_TUTORIALS=OFF\",\n             \"-DTRITON_BUILD_PYTHON_MODULE=ON\",\n             # '-DPYTHON_EXECUTABLE=' + sys.executable,\n-            # '-DCMAKE_VERBOSE_MAKEFILE:BOOL=ON',\n+            '-DCMAKE_VERBOSE_MAKEFILE:BOOL=ON',\n             \"-DPYTHON_INCLUDE_DIRS=\" + python_include_dir,\n             \"-DLLVM_EXTERNAL_LIT=\" + lit_dir\n         ] + thirdparty_cmake_args\n \n         # configuration\n-        cfg = \"Debug\" if self.debug else \"Release\"\n+        cfg = get_build_type()\n         build_args = [\"--config\", cfg]\n \n         if platform.system() == \"Windows\":\n@@ -183,7 +179,11 @@ def build_extension(self, ext):\n         \"torch\",\n         \"lit\",\n     ],\n-    package_data={\"triton/ops\": [\"*.c\"], \"triton/ops/blocksparse\": [\"*.c\"]},\n+    package_data={\n+        \"triton/ops\": [\"*.c\"],\n+        \"triton/ops/blocksparse\": [\"*.c\"],\n+        \"triton/language\": [\"*.bc\"]\n+    },\n     include_package_data=True,\n     ext_modules=[CMakeExtension(\"triton\", \"triton/_C/\")],\n     cmdclass={\"build_ext\": CMakeBuild},"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -551,7 +551,7 @@ void init_triton_ir(py::module &&m) {\n                return llvm::dyn_cast<mlir::FuncOp>(funcOperation);\n              auto loc = self.getUnknownLoc();\n              if (auto funcTy = funcType.dyn_cast<mlir::FunctionType>()) {\n-               mlir::ArrayRef<mlir::NamedAttribute> attrs = {\n+               llvm::SmallVector<mlir::NamedAttribute> attrs = {\n                    mlir::NamedAttribute(self.getStringAttr(\"sym_visibility\"),\n                                         self.getStringAttr(visibility))};\n                return self.create<mlir::FuncOp>(loc, funcName, funcTy, attrs);"}, {"filename": "python/tests/test_gemm.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -186,9 +186,9 @@ def get_proper_err(a, b, golden):\n     [128, 256, 128, 4, 128, 256, 32, False, False],\n     [256, 128, 64, 4, 256, 128, 16, False, False],\n     [128, 64, 128, 4, 128, 64, 32, False, False],\n-    # TODO[goostavz]: fix these cases\n-    #[128, 64, 128, 4, 128, 64, 32, True, False],\n-    #[128, 64, 128, 4, 128, 64, 32, False, True],\n+    # trans\n+    [128, 64, 128, 4, 128, 64, 32, True, False],\n+    [128, 64, 128, 4, 128, 64, 32, False, True],\n ])\n def test_gemm(SIZE_M, SIZE_N, SIZE_K, NUM_WARPS, BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K, TRANS_A, TRANS_B):\n     if (TRANS_A):"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 19, "deletions": 18, "changes": 37, "file_content_changes": "@@ -472,8 +472,6 @@ def visit_UnaryOp(self, node):\n         if type(node.op) == ast.Not:\n             assert isinstance(op, triton.language.constexpr), \"`not` only supported for constexpr at the moment\"\n             return triton.language.constexpr(not op)\n-        if isinstance(op, triton.language.constexpr):\n-            op = op.value\n         fn = {\n             ast.USub: '__neg__',\n             ast.UAdd: '__pos__',\n@@ -563,27 +561,30 @@ def visit_For(self, node):\n         iterator = self.visit(node.iter.func)\n         if iterator != self.builtins['range']:\n             raise RuntimeError('Only `range` iterator currently supported')\n-        # static for loops: all iterator arguments are constexpr\n+        # visit iterator arguments\n+        # note: only `range` iterator is supported now\n         iter_args = [self.visit(arg) for arg in node.iter.args]\n-        static_unrolling = os.environ.get('TRITON_STATIC_LOOP_UNROLLING', False)\n-        is_static = False\n-        if static_unrolling:\n-            is_static = all([isinstance(x, triton.language.constexpr) for x in iter_args])\n-        if is_static:\n-            iter_args = [arg.value for arg in iter_args]\n-            range = iterator(*iter_args)\n-            if len(range) <= 10:\n-                for i in iterator(*iter_args):\n+        # collect lower bound (lb), upper bound (ub), and step\n+        lb = iter_args[0] if len(iter_args) > 1 else self.visit(ast.Num(0))\n+        ub = iter_args[1] if len(iter_args) > 1 else self.visit(node.iter.args[0])\n+        step = iter_args[2] if len(iter_args) > 2 else self.visit(ast.Num(1))\n+        # static for loops: all iterator arguments are constexpr\n+        if isinstance(lb, triton.language.constexpr) and \\\n+           isinstance(ub, triton.language.constexpr) and \\\n+           isinstance(step, triton.language.constexpr):\n+            sta_range = iterator(lb.value, ub.value, step.value)\n+            static_unrolling = os.environ.get('TRITON_STATIC_LOOP_UNROLLING', False)\n+            if static_unrolling and len(range) <= 10:\n+                for i in sta_range:\n                     self.lscope[node.target.id] = triton.language.constexpr(i)\n                     self.visit_compound_statement(node.body)\n                     for stmt in node.orelse:\n                         ast.NodeVisitor.generic_visit(self, stmt)\n                 return\n-\n-        # collect lower bound (lb), upper bound (ub), and step\n-        lb = self.visit(node.iter.args[0] if len(node.iter.args) > 1 else ast.Num(0))\n-        ub = self.visit(node.iter.args[1] if len(node.iter.args) > 1 else node.iter.args[0])\n-        step = self.visit(node.iter.args[2] if len(node.iter.args) > 2 else ast.Num(1))\n+        # handle negative constant step (not supported by scf.for in MLIR)\n+        if isinstance(step, triton.language.constexpr) and step.value < 0:\n+            step = triton.language.constexpr(-step.value)\n+            lb, ub = ub, lb\n         # lb/ub/step might be constexpr, we need to cast them to tensor\n         lb = triton.language.core._to_tensor(lb, self.builder).handle\n         ub = triton.language.core._to_tensor(ub, self.builder).handle\n@@ -881,14 +882,14 @@ def ttir_to_ttgir(mod, num_warps, num_stages):\n     pm.enable_debug()\n     # Convert blocked layout to mma layout for dot ops so that pipeline\n     # can get shared memory swizzled correctly.\n+    pm.add_coalesce_pass()\n     pm.add_triton_gpu_combine_pass()\n     pm.add_tritongpu_pipeline_pass(num_stages)\n     # Prefetch must be done after pipeline pass because pipeline pass\n     # extracts slices from the original tensor.\n     pm.add_tritongpu_prefetch_pass()\n     pm.add_canonicalizer_pass()\n     pm.add_cse_pass()\n-    pm.add_coalesce_pass()\n     pm.add_triton_gpu_combine_pass()\n     pm.add_licm_pass()\n     pm.add_triton_gpu_combine_pass()"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 30, "deletions": 21, "changes": 51, "file_content_changes": "@@ -345,67 +345,76 @@ def __repr__(self) -> str:\n         return f\"constexpr[{self.value}]\"\n \n     def __add__(self, other):\n-        return self.value + other.value\n+        return constexpr(self.value + other.value)\n \n     def __radd__(self, other):\n-        return other.value + self.value\n+        return constexpr(other.value + self.value)\n \n     def __sub__(self, other):\n-        return self.value - other.value\n+        return constexpr(self.value - other.value)\n \n     def __rsub__(self, other):\n-        return other.value - self.value\n+        return constexpr(other.value - self.value)\n \n     def __mul__(self, other):\n-        return self.value * other.value\n+        return constexpr(self.value * other.value)\n \n     def __rmul__(self, other):\n-        return other.value * self.value\n+        return constexpr(other.value * self.value)\n \n     def __truediv__(self, other):\n-        return self.value / other.value\n+        return constexpr(self.value / other.value)\n \n     def __rtruediv__(self, other):\n-        return other.value / self.value\n+        return constexpr(other.value / self.value)\n \n     def __floordiv__(self, other):\n-        return self.value // other.value\n+        return constexpr(self.value // other.value)\n \n     def __rfloordiv__(self, other):\n-        return other.value // self.value\n+        return constexpr(other.value // self.value)\n \n     def __gt__(self, other):\n-        return self.value > other.value\n+        return constexpr(self.value > other.value)\n \n     def __rgt__(self, other):\n-        return other.value > self.value\n+        return constexpr(other.value > self.value)\n \n     def __ge__(self, other):\n-        return self.value >= other.value\n+        return constexpr(self.value >= other.value)\n \n     def __rge__(self, other):\n-        return other.value >= self.value\n+        return constexpr(other.value >= self.value)\n \n     def __lt__(self, other):\n-        return self.value < other.value\n+        return constexpr(self.value < other.value)\n \n     def __rlt__(self, other):\n-        return other.value < self.value\n+        return constexpr(other.value < self.value)\n \n     def __le__(self, other):\n-        return self.value <= other.value\n+        return constexpr(self.value <= other.value)\n \n     def __rle__(self, other):\n-        return other.value <= self.value\n+        return constexpr(other.value <= self.value)\n \n     def __eq__(self, other):\n-        return self.value == other.value\n+        return constexpr(self.value == other.value)\n \n     def __ne__(self, other):\n-        return self.value != other.value\n+        return constexpr(self.value != other.value)\n \n     def __bool__(self):\n-        return bool(self.value)\n+        return constexpr(bool(self.value))\n+\n+    def __neg__(self):\n+        return constexpr(-self.value)\n+    \n+    def __pos__(self):\n+        return constexpr(+self.value)\n+    \n+    def __invert__(self):\n+        return constexpr(~self.value)\n \n     def __call__(self, *args, **kwds):\n         return self.value(*args, **kwds)"}, {"filename": "unittest/Dialect/TritonGPU/SwizzleTest.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -34,7 +34,7 @@ TEST_P(SwizzleDotOperandTestFixture, DotOperands) {\n \n   // create element type\n   Type eltType = IntegerType::get(&ctx, params.typeWidth);\n-  auto layout = SharedEncodingAttr::get(&ctx, encoding, params.shape, eltType);\n+  auto layout = SharedEncodingAttr::get(&ctx, encoding, params.shape, {1, 0}, eltType);\n \n   ASSERT_EQ(layout.getVec(), params.refSwizzle.vec);\n   ASSERT_EQ(layout.getPerPhase(), params.refSwizzle.perPhase);"}]