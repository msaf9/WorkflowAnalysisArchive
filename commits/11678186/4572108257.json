[{"filename": "include/triton/Dialect/Triton/IR/Types.h", "status": "modified", "additions": 17, "deletions": 1, "changes": 18, "file_content_changes": "@@ -10,10 +10,26 @@\n \n namespace mlir {\n \n-unsigned getPointeeBitWidth(RankedTensorType tensorTy);\n+namespace triton {\n \n bool isTensorPointerType(Type type);\n \n+unsigned getPointeeBitWidth(Type type);\n+\n+Type getPointeeType(Type type);\n+\n+Type getPointerType(Type type);\n+\n+Type getElementTypeOfTensorPointerType(Type type);\n+\n+Type getI1SameShape(Type type);\n+\n+Type getI32SameShape(Type type);\n+\n+Type getPointerTypeSameShape(Type type);\n+\n+} // namespace triton\n+\n } // namespace mlir\n \n #endif // TRITON_IR_TYPES_H_"}, {"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -910,7 +910,7 @@ unsigned AxisInfoAnalysis::getPtrAlignment(Value ptr) {\n   auto order = triton::gpu::getOrder(layout);\n   auto maxMultipleBytes = axisInfo.getDivisibility(order[0]);\n   auto maxContig = axisInfo.getContiguity(order[0]);\n-  auto elemNumBits = getPointeeBitWidth(tensorTy);\n+  auto elemNumBits = triton::getPointeeBitWidth(tensorTy);\n   auto elemNumBytes = std::max<unsigned>(elemNumBits / 8, 1);\n   auto maxMultiple = std::max<int64_t>(maxMultipleBytes / elemNumBytes, 1);\n   unsigned alignment = std::min(maxMultiple, maxContig);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -28,7 +28,7 @@ struct LoadStoreConversionBase {\n     if (!tensorTy)\n       return 1;\n     auto contiguity = getContiguity(ptr);\n-    auto pointeeBitWidth = getPointeeBitWidth(tensorTy);\n+    auto pointeeBitWidth = triton::getPointeeBitWidth(tensorTy);\n     // The maximum vector size is 128 bits on NVIDIA GPUs.\n     return std::min<unsigned>(128 / pointeeBitWidth, contiguity);\n   }"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 0, "deletions": 37, "changes": 37, "file_content_changes": "@@ -8,43 +8,6 @@\n namespace mlir {\n namespace triton {\n \n-// Type inference\n-static Type getI1SameShape(Type type) {\n-  auto i1Type = IntegerType::get(type.getContext(), 1);\n-  if (auto tensorType = type.dyn_cast<RankedTensorType>())\n-    return RankedTensorType::get(tensorType.getShape(), i1Type,\n-                                 tensorType.getEncoding());\n-  return i1Type;\n-}\n-\n-static Type getI32SameShape(Type type) {\n-  auto i32Type = IntegerType::get(type.getContext(), 32);\n-  if (auto tensorType = type.dyn_cast<RankedTensorType>())\n-    return RankedTensorType::get(tensorType.getShape(), i32Type,\n-                                 tensorType.getEncoding());\n-  return i32Type;\n-}\n-\n-static Type getPointerTypeSameShape(Type type) {\n-  if (auto tensorType = type.dyn_cast<RankedTensorType>()) {\n-    Type elementType = tensorType.getElementType();\n-    auto shape = tensorType.getShape();\n-    PointerType ptrType = PointerType::get(elementType, 1);\n-    return RankedTensorType::get(shape, ptrType, tensorType.getEncoding());\n-  } else {\n-    return PointerType::get(type, 1);\n-  }\n-}\n-\n-static Type getPointerType(Type type) { return PointerType::get(type, 1); }\n-\n-static Type getElementTypeOfTensorPointerType(Type type) {\n-  if (auto ptrType = type.dyn_cast<PointerType>())\n-    if (auto tensorType = ptrType.getPointeeType().dyn_cast<RankedTensorType>())\n-      return tensorType.getElementType();\n-  return {};\n-}\n-\n // Parser & printer for assembly forms\n ParseResult LoadOp::parse(OpAsmParser &parser, OperationState &result) {\n   // Parse operands"}, {"filename": "lib/Dialect/Triton/IR/Traits.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -13,7 +13,7 @@ static LogicalResult verifySameEncoding(Type typeA, Type typeB,\n       if (auto ptrType = type.dyn_cast<triton::PointerType>())\n         rankedType = ptrType.getPointeeType().dyn_cast<RankedTensorType>();\n     } else {\n-      assert(!isTensorPointerType(type));\n+      assert(!triton::isTensorPointerType(type));\n     }\n     return rankedType ? rankedType.getEncoding() : Attribute();\n   };\n@@ -123,7 +123,7 @@ OpTrait::impl::verifySameLoadStoreOperandsAndResultShape(Operation *op) {\n \n bool OpTrait::impl::verifyLoadStorePointerAndValueType(Type valueType,\n                                                        Type ptrType) {\n-  if (isTensorPointerType(ptrType)) {\n+  if (triton::isTensorPointerType(ptrType)) {\n     return ptrType.cast<triton::PointerType>().getPointeeType() == valueType;\n   } else if (auto rankedType = ptrType.dyn_cast<RankedTensorType>()) {\n     if (auto elementPtrType ="}, {"filename": "lib/Dialect/Triton/IR/Types.cpp", "status": "modified", "additions": 59, "deletions": 3, "changes": 62, "file_content_changes": "@@ -40,16 +40,72 @@ void PointerType::print(AsmPrinter &printer) const {\n \n namespace mlir {\n \n-unsigned getPointeeBitWidth(RankedTensorType tensorTy) {\n-  auto ptrTy = tensorTy.getElementType().cast<triton::PointerType>();\n-  auto pointeeType = ptrTy.getPointeeType();\n+namespace triton {\n+\n+unsigned getPointeeBitWidth(Type type) {\n+  auto pointeeType = getPointeeType(type);\n+  if (auto tensorTy = pointeeType.dyn_cast<RankedTensorType>())\n+    return tensorTy.getElementType().getIntOrFloatBitWidth();\n   return pointeeType.getIntOrFloatBitWidth();\n }\n \n+Type getI1SameShape(Type type) {\n+  auto i1Type = IntegerType::get(type.getContext(), 1);\n+  if (auto tensorTy = type.dyn_cast<RankedTensorType>())\n+    return RankedTensorType::get(tensorTy.getShape(), i1Type,\n+                                 tensorTy.getEncoding());\n+  return i1Type;\n+}\n+\n+Type getPointeeType(Type type) {\n+  if (auto tensorTy = type.dyn_cast<RankedTensorType>()) {\n+    // Tensor of pointers\n+    auto shape = tensorTy.getShape();\n+    auto ptrType = tensorTy.getElementType().dyn_cast<PointerType>();\n+    Type pointeeType = ptrType.getPointeeType();\n+    return RankedTensorType::get(shape, pointeeType, tensorTy.getEncoding());\n+  } else if (auto ptrType = type.dyn_cast<PointerType>()) {\n+    // scalar pointer\n+    Type pointeeType = ptrType.getPointeeType();\n+    return pointeeType;\n+  }\n+  return type;\n+}\n+\n+Type getI32SameShape(Type type) {\n+  auto i32Type = IntegerType::get(type.getContext(), 32);\n+  if (auto tensorTy = type.dyn_cast<RankedTensorType>())\n+    return RankedTensorType::get(tensorTy.getShape(), i32Type,\n+                                 tensorTy.getEncoding());\n+  return i32Type;\n+}\n+\n+Type getPointerTypeSameShape(Type type) {\n+  if (auto tensorTy = type.dyn_cast<RankedTensorType>()) {\n+    Type elementType = tensorTy.getElementType();\n+    auto shape = tensorTy.getShape();\n+    PointerType ptrType = PointerType::get(elementType, 1);\n+    return RankedTensorType::get(shape, ptrType, tensorTy.getEncoding());\n+  } else {\n+    return PointerType::get(type, 1);\n+  }\n+}\n+\n+Type getPointerType(Type type) { return PointerType::get(type, 1); }\n+\n bool isTensorPointerType(Type type) {\n   if (auto ptrType = type.dyn_cast<PointerType>())\n     return ptrType.getPointeeType().isa<RankedTensorType>();\n   return false;\n }\n \n+Type getElementTypeOfTensorPointerType(Type type) {\n+  if (auto ptrType = type.dyn_cast<PointerType>())\n+    if (auto tensorTy = ptrType.getPointeeType().dyn_cast<RankedTensorType>())\n+      return tensorTy.getElementType();\n+  return {};\n+}\n+\n+} // namespace triton\n+\n } // namespace mlir"}, {"filename": "lib/Dialect/Triton/Transforms/RewriteTensorPointer.cpp", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "file_content_changes": "@@ -197,9 +197,10 @@ class RewriteTensorPointerPass\n       : computeCapability(computeCapability) {}\n \n   static bool needRewrite(Operation *op) {\n-    return std::any_of(\n-        op->getOperands().begin(), op->getOperands().end(),\n-        [](Value operand) { return isTensorPointerType(operand.getType()); });\n+    return std::any_of(op->getOperands().begin(), op->getOperands().end(),\n+                       [](Value operand) {\n+                         return triton::isTensorPointerType(operand.getType());\n+                       });\n   }\n \n   static SmallVector<Value>\n@@ -273,7 +274,7 @@ class RewriteTensorPointerPass\n \n     // We only have to rewrite load/stores with tensor pointers\n     auto ptr = op->getOperand(0);\n-    if (!isTensorPointerType(ptr.getType()))\n+    if (!triton::isTensorPointerType(ptr.getType()))\n       return nullptr;\n \n     // Get info from previous results\n@@ -324,7 +325,7 @@ class RewriteTensorPointerPass\n     SmallVector<Value> newIterOperands = op.getIterOperands();\n     for (unsigned i = 0, oldI = 0, size = op.getNumIterOperands(); i < size;\n          ++i, ++oldI) {\n-      if (!isTensorPointerType(newIterOperands[i].getType()))\n+      if (!triton::isTensorPointerType(newIterOperands[i].getType()))\n         continue;\n \n       // Expand the tensor pointer into offsets\n@@ -348,7 +349,7 @@ class RewriteTensorPointerPass\n     for (unsigned i = 0, oldI = 0; oldI < op.getNumIterOperands();\n          ++i, ++oldI) {\n       auto oldRegionIterArg = op.getRegionIterArg(oldI);\n-      if (isTensorPointerType(oldRegionIterArg.getType())) {\n+      if (triton::isTensorPointerType(oldRegionIterArg.getType())) {\n         // Pass rewrited info inside\n         assert(rewritedInfo.count(oldIterOperands[oldI]));\n         auto info = rewritedInfo[oldIterOperands[oldI]];\n@@ -375,7 +376,7 @@ class RewriteTensorPointerPass\n     assert(op.getNumResults() == op.getNumIterOperands());\n     for (unsigned i = 0, oldI = 0; oldI < op.getNumResults(); ++i, ++oldI) {\n       auto oldResult = op.getResult(oldI);\n-      if (isTensorPointerType(oldResult.getType())) {\n+      if (triton::isTensorPointerType(oldResult.getType())) {\n         // Pack new offsets into rewrited info\n         assert(rewritedInfo.count(oldIterOperands[oldI]));\n         auto info = rewritedInfo[oldIterOperands[oldI]];\n@@ -398,7 +399,7 @@ class RewriteTensorPointerPass\n     // Replace tensor pointers with offsets\n     SmallVector<Value> newOperands = op->getOperands();\n     for (unsigned i = 0, size = op.getNumOperands(); i < size; ++i) {\n-      if (!isTensorPointerType(newOperands[i].getType()))\n+      if (!triton::isTensorPointerType(newOperands[i].getType()))\n         continue;\n \n       assert(rewritedInfo.count(newOperands[i]));"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 0, "deletions": 24, "changes": 24, "file_content_changes": "@@ -16,30 +16,6 @@ using namespace mlir::triton::gpu;\n namespace mlir {\n namespace triton {\n \n-// Type inference\n-static Type getI1SameShape(Type type) {\n-  auto i1Type = IntegerType::get(type.getContext(), 1);\n-  if (auto tensorType = type.dyn_cast<RankedTensorType>())\n-    return RankedTensorType::get(tensorType.getShape(), i1Type,\n-                                 tensorType.getEncoding());\n-  return Type();\n-}\n-\n-static Type getPointeeType(Type type) {\n-  if (auto tensorType = type.dyn_cast<RankedTensorType>()) {\n-    // Tensor of pointers\n-    auto shape = tensorType.getShape();\n-    auto ptrType = tensorType.getElementType().dyn_cast<PointerType>();\n-    Type pointeeType = ptrType.getPointeeType();\n-    return RankedTensorType::get(shape, pointeeType, tensorType.getEncoding());\n-  } else if (auto ptrType = type.dyn_cast<PointerType>()) {\n-    // scalar pointer\n-    Type pointeeType = ptrType.getPointeeType();\n-    return pointeeType;\n-  }\n-  return Type();\n-}\n-\n namespace gpu {\n \n // TODO: Inheritance of layout attributes"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Coalesce.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -53,7 +53,7 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     int numElemsPerThread = std::max(numElems / numThreads, 1);\n     // Thread tile size depends on memory alignment\n     SmallVector<unsigned, 4> sizePerThread(rank, 1);\n-    unsigned elemNumBits = getPointeeBitWidth(origType);\n+    unsigned elemNumBits = triton::getPointeeBitWidth(origType);\n     unsigned elemNumBytes = std::max(elemNumBits / 8, 1u);\n     unsigned perThread = 1;\n     for (Value val : withSameOrder) {"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 1, "deletions": 10, "changes": 11, "file_content_changes": "@@ -22,15 +22,6 @@ namespace ttg = triton::gpu;\n #define GEN_PASS_CLASSES\n #include \"triton/Dialect/TritonGPU/Transforms/Passes.h.inc\"\n \n-static Type getI1SameShape(Value v) {\n-  Type vType = v.getType();\n-  auto i1Type = IntegerType::get(vType.getContext(), 1);\n-  if (auto tensorType = vType.dyn_cast<RankedTensorType>())\n-    return RankedTensorType::get(tensorType.getShape(), i1Type,\n-                                 tensorType.getEncoding());\n-  return i1Type;\n-}\n-\n // pass named attrs (e.g., tt.contiguity) from Triton to Triton\n static void addNamedAttrs(Operation *op, DictionaryAttr dictAttrs) {\n   for (const NamedAttribute attr : dictAttrs.getValue())\n@@ -321,7 +312,7 @@ LogicalResult LoopPipeliner::initialize() {\n \n Value LoopPipeliner::getLoadMask(triton::LoadOp loadOp, Value mappedMask,\n                                  Value loopCond, OpBuilder &builder) {\n-  Type maskType = getI1SameShape(loadOp);\n+  Type maskType = triton::getI1SameShape(loadOp.getType());\n   Value mask = loadOp.getMask();\n   Value newMask;\n   if (mask) {"}]