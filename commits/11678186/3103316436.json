[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 62, "deletions": 43, "changes": 105, "file_content_changes": "@@ -304,6 +304,13 @@ class ConvertTritonGPUOpToLLVMPattern\n                                            PatternBenefit benefit = 1)\n       : ConvertOpToLLVMPattern<SourceOp>(typeConverter, benefit) {}\n \n+  explicit ConvertTritonGPUOpToLLVMPattern(LLVMTypeConverter &typeConverter,\n+                                           const Allocation *allocation,\n+                                           Value smem,\n+                                           PatternBenefit benefit = 1)\n+      : ConvertOpToLLVMPattern<SourceOp>(typeConverter, benefit),\n+        allocation(allocation), smem(smem) {}\n+\n   SmallVector<Value> delinearize(ConversionPatternRewriter &rewriter,\n                                  Location loc, Value linear,\n                                  ArrayRef<unsigned> shape,\n@@ -554,19 +561,23 @@ class ConvertTritonGPUOpToLLVMPattern\n     return multiDimIdx;\n   }\n \n+  template <typename T>\n   Value getSharedMemoryBase(Location loc, ConversionPatternRewriter &rewriter,\n-                            Value smem, const Allocation *allocation,\n-                            Operation *op) const {\n+                            T value) const {\n     auto ptrTy = LLVM::LLVMPointerType::get(\n-        this->getTypeConverter()->convertType(rewriter.getIntegerType(8)), 3);\n-    auto bufferId = allocation->getBufferId(op);\n+        this->getTypeConverter()->convertType(rewriter.getI8Type()), 3);\n+    auto bufferId = allocation->getBufferId(value);\n     assert(bufferId != Allocation::InvalidBufferId && \"BufferId not found\");\n     size_t offset = allocation->getOffset(bufferId);\n     auto llvmIndexTy = this->getTypeConverter()->getIndexType();\n     Value offVal = createIndexAttrConstant(rewriter, loc, llvmIndexTy, offset);\n     Value base = rewriter.create<LLVM::GEPOp>(loc, ptrTy, smem, offVal);\n     return base;\n   }\n+\n+protected:\n+  const Allocation *allocation;\n+  Value smem;\n };\n \n // Convert SplatOp or arith::ConstantOp with SplatElementsAttr to a\n@@ -1307,6 +1318,27 @@ struct AddPtrOpConversion\n   }\n };\n \n+struct AllocTensorOpConversion\n+    : public ConvertTritonGPUOpToLLVMPattern<triton::gpu::AllocTensorOp> {\n+  using ConvertTritonGPUOpToLLVMPattern<\n+      triton::gpu::AllocTensorOp>::ConvertTritonGPUOpToLLVMPattern;\n+\n+  LogicalResult\n+  matchAndRewrite(triton::gpu::AllocTensorOp op, OpAdaptor adaptor,\n+                  ConversionPatternRewriter &rewriter) const override {\n+    Location loc = op->getLoc();\n+    Value smemBase = getSharedMemoryBase(loc, rewriter, op.getResult());\n+    auto resultTy = op.getType().dyn_cast<RankedTensorType>();\n+    auto llvmElemTy =\n+        getTypeConverter()->convertType(resultTy.getElementType());\n+    auto elemPtrTy = LLVM::LLVMPointerType::get(llvmElemTy, 3);\n+    Value resultVal =\n+        rewriter.create<LLVM::BitcastOp>(loc, elemPtrTy, smemBase);\n+    rewriter.replaceOp(op, resultVal);\n+    return success();\n+  }\n+};\n+\n struct ExtractSliceOpConversion\n     : public ConvertTritonGPUOpToLLVMPattern<triton::gpu::ExtractSliceOp> {\n   using ConvertTritonGPUOpToLLVMPattern<\n@@ -1320,31 +1352,26 @@ struct ExtractSliceOpConversion\n     auto srcLayout = srcTy.getEncoding().dyn_cast<SharedEncodingAttr>();\n     assert(srcLayout && \"Unexpected resultLayout in ExtractSliceOpConversion\");\n \n-    // Example:\n-    // %dst = extract_slice %src, %index {axis = 2}\n-    // src.shape = [11, 2, 3, 4, 1]\n-    // dst.offset = [11, 2, %index, 4, 1]\n-    auto srcShape = srcTy.getShape();\n+    // axis > 0 will result in non-contiguous memory access if the result tensor\n+    // is an alias of the source tensor.\n     auto axis =\n         op->getAttrOfType<IntegerAttr>(\"axis\").cast<IntegerAttr>().getInt();\n-    SmallVector<Value> indices;\n-    for (unsigned i = 0; i < srcShape.size(); ++i) {\n-      if (i == axis) {\n-        indices.push_back(adaptor.index());\n-      } else {\n-        auto mlirI32Attr = rewriter.getI32IntegerAttr(srcShape[i]);\n-        auto llvmI32Type =\n-            typeConverter->convertType(rewriter.getIntegerType(32));\n-        indices.push_back(\n-            rewriter.create<LLVM::ConstantOp>(loc, llvmI32Type, mlirI32Attr));\n-      }\n-    }\n+    assert(axis == 0 && \"Only axis=0 is supported for now\");\n \n-    auto resultTy = op.getType().dyn_cast<RankedTensorType>();\n-    Type elemTy =\n-        this->getTypeConverter()->convertType(resultTy.getElementType());\n+    // Example:\n+    // %dst = extract_slice %src, %index {axis = 0}\n+    // src.shape = [11, 2, 3, 4, 1]\n+    // offset = %index * 2 * 3 * 4 * 1\n+    auto dstTy = op.getType().dyn_cast<RankedTensorType>();\n+    auto base = product<int64_t>(dstTy.getShape());\n+    auto baseVal = createIndexAttrConstant(\n+        rewriter, loc, getTypeConverter()->getIndexType(), base);\n+    Value offset = rewriter.create<LLVM::MulOp>(loc, adaptor.index(), baseVal);\n+\n+    auto llvmElemTy = getTypeConverter()->convertType(dstTy.getElementType());\n+    auto elemPtrTy = LLVM::LLVMPointerType::get(llvmElemTy, 3);\n     Value resultVal =\n-        rewriter.create<LLVM::GEPOp>(loc, elemTy, adaptor.src(), indices);\n+        rewriter.create<LLVM::GEPOp>(loc, elemPtrTy, adaptor.src(), offset);\n     rewriter.replaceOp(op, resultVal);\n     return success();\n   }\n@@ -1397,13 +1424,6 @@ struct ConvertLayoutOpConversion\n   using ConvertTritonGPUOpToLLVMPattern<\n       triton::gpu::ConvertLayoutOp>::ConvertTritonGPUOpToLLVMPattern;\n \n-  ConvertLayoutOpConversion(LLVMTypeConverter &converter,\n-                            const Allocation *allocation, Value smem,\n-                            PatternBenefit benefit)\n-      : ConvertTritonGPUOpToLLVMPattern<triton::gpu::ConvertLayoutOp>(converter,\n-                                                                      benefit),\n-        allocation_(allocation), smem_(smem) {}\n-\n   LogicalResult\n   matchAndRewrite(triton::gpu::ConvertLayoutOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n@@ -1422,8 +1442,7 @@ struct ConvertLayoutOpConversion\n       return failure();\n     }\n     auto llvmElemTy = getTypeConverter()->convertType(dstTy.getElementType());\n-    Value smemBase = getSharedMemoryBase(loc, rewriter, smem_, allocation_,\n-                                         op.getOperation());\n+    Value smemBase = getSharedMemoryBase(loc, rewriter, op.getOperation());\n     auto elemPtrTy = LLVM::LLVMPointerType::get(llvmElemTy, 3);\n     smemBase = rewriter.create<LLVM::BitcastOp>(loc, elemPtrTy, smemBase);\n \n@@ -1608,9 +1627,6 @@ struct ConvertLayoutOpConversion\n       }\n     }\n   }\n-\n-  const Allocation *allocation_;\n-  Value smem_;\n };\n \n class TritonGPUToLLVMTypeConverter : public LLVMTypeConverter {\n@@ -1642,12 +1658,12 @@ class TritonGPUToLLVMTypeConverter : public LLVMTypeConverter {\n       SmallVector<Type, 4> types(numElementsPerThread,\n                                  convertType(type.getElementType()));\n       return LLVM::LLVMStructType::getLiteral(&getContext(), types);\n-    } else if (auto mma_layout = layout.dyn_cast<MmaEncodingAttr>()) {\n-      // TODO: Not implemented\n-      return llvm::None;\n-    } else if (auto shared_layout = layout.dyn_cast<SharedEncodingAttr>()) {\n+    } else if (auto mma_layout = layout.dyn_cast_or_null<MmaEncodingAttr>()) {\n       // TODO: Not implemented\n-      return llvm::None;\n+      return type;\n+    } else if (auto shared_layout =\n+                   layout.dyn_cast_or_null<SharedEncodingAttr>()) {\n+      return LLVM::LLVMPointerType::get(convertType(type.getElementType()), 3);\n     }\n     return llvm::None;\n   }\n@@ -1669,7 +1685,10 @@ void populateTritonToLLVMPatterns(mlir::LLVMTypeConverter &typeConverter,\n                                                                 benefit);\n   patterns.add<BroadcastOpConversion>(typeConverter, benefit);\n   patterns.add<AddPtrOpConversion>(typeConverter, benefit);\n-  patterns.add<ExtractSliceOpConversion>(typeConverter, benefit);\n+  patterns.add<AllocTensorOpConversion>(typeConverter, allocation, smem,\n+                                        benefit);\n+  patterns.add<ExtractSliceOpConversion>(typeConverter, allocation, smem,\n+                                         benefit);\n   patterns.add<ConvertLayoutOpConversion>(typeConverter, allocation, smem,\n                                           benefit);\n   patterns.add<GetProgramIdOpConversion>(typeConverter, benefit);"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "file_content_changes": "@@ -431,9 +431,10 @@ mlir::LogicalResult ExtractSliceOp::inferReturnTypes(\n   auto axis = attributes.get(\"axis\").cast<IntegerAttr>().getInt();\n   if (axis < 0 || axis > srcShape.size())\n     return failure();\n-  // Since we only extract a slice from a certain index on the axis,\n-  // the dims before the axis can be dropped.\n-  auto dstShape = srcShape.drop_front(axis + 1);\n+  SmallVector<int64_t, 4> dstShape;\n+  for (int i = 0; i < srcShape.size(); i++)\n+    if (i != axis)\n+      dstShape.push_back(srcShape[i]);\n   auto returnType =\n       RankedTensorType::get(dstShape, srcType.getElementType(), encoding);\n   inferredReturnTypes.assign({returnType});"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 38, "deletions": 0, "changes": 38, "file_content_changes": "@@ -293,6 +293,44 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n // -----\n \n+#shared0 = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n+  // CHECK: llvm.mlir.global internal @global_smem\n+  // CHECK-LABEL: basic_alloc_tensor\n+  func @basic_alloc_tensor() {\n+    // CHECK: llvm.mlir.addressof @global_smem\n+    // CHECK-NEXT: llvm.mlir.constant\n+    // CHECK-NEXT: llvm.getelementptr\n+    // CHECK-NEXT: llvm.bitcast\n+    %0 = triton_gpu.alloc_tensor : tensor<16x16xf16, #shared0>\n+    return\n+  }\n+}\n+\n+// -----\n+\n+#shared0 = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n+  // CHECK: llvm.mlir.global internal @global_smem\n+  // CHECK-LABEL: basic_extract_slice\n+  func @basic_extract_slice() {\n+    // CHECK: %[[BASE0:.*]] = llvm.mlir.addressof @global_smem\n+    // CHECK-NEXT: %[[OFFSET0:.*]] = llvm.mlir.constant\n+    // CHECK-NEXT: %[[OFFSET1:.*]] = llvm.mlir.constant\n+    // CHECK-NEXT: llvm.getelementptr %[[BASE0]][%[[OFFSET1]]]\n+    // CHECK-NEXT: %[[BASE1:.*]] = llvm.bitcast\n+    // CHECK-NEXT: %[[OFFSET2:.*]] = llvm.mlir.constant\n+    // CHECK-NEXT: %[[OFFSET3:.*]] = llvm.mul %[[OFFSET0]], %[[OFFSET2]]\n+    // CHECK-NEXT: llvm.getelementptr %[[BASE1]][%[[OFFSET3]]]\n+    %index = arith.constant 1 : i32\n+    %0 = triton_gpu.alloc_tensor : tensor<128x16x32xf32, #shared0>\n+    %1 = triton_gpu.extract_slice %0, %index {axis = 0: i32} : tensor<128x16x32xf32, #shared0> -> tensor<16x32xf32, #shared0>\n+    return\n+  }\n+}\n+\n+// -----\n+\n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK: basic_splat"}]