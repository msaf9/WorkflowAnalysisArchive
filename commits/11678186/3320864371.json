[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 65, "deletions": 11, "changes": 76, "file_content_changes": "@@ -2673,15 +2673,21 @@ struct DotOpConversionHelper {\n     return mmaInstrShape.at(mmaType);\n   }\n \n+  static ArrayRef<int> getMmaInstrShape(TensorCoreType tensorCoreType) {\n+    assert(tensorCoreType != TensorCoreType::NOT_APPLICABLE &&\n+           \"Unknown mma type found.\");\n+    return mmaInstrShape.at(tensorCoreType);\n+  }\n+\n   ArrayRef<int> getMmaMatShape() const {\n     assert(mmaType != TensorCoreType::NOT_APPLICABLE &&\n            \"Unknown mma type found.\");\n     return mmaMatShape.at(mmaType);\n   }\n \n   // Deduce the TensorCoreType from either $a or $b's type. This method is not\n-  // safe, but we cannot get the DotOp in some getmaMatShape usage case.\n-  TensorCoreType getTensorCoreTypeFromOperand(Type operandTy) const {\n+  // safe, but we cannot get the DotOp in some getjmaMatShape usage case.\n+  static TensorCoreType getTensorCoreTypeFromOperand(Type operandTy) {\n     auto tensorTy = operandTy.cast<RankedTensorType>();\n     auto elemTy = tensorTy.getElementType();\n     if (elemTy.isF16())\n@@ -2903,9 +2909,6 @@ struct MMA16816ConversionHelper {\n \n     // step2. Format the values to LLVM::Struct to passing to mma codegen.\n     Value result = composeValuesToDotOperandLayoutStruct(ha, numRepM, numRepK);\n-\n-    // TODO[Superjomn]: Replace the convert_layout op with the result once the\n-    // DotOperandEncodingAttr is ready.\n     return result;\n   }\n \n@@ -3019,6 +3022,11 @@ struct MMA16816ConversionHelper {\n         for (unsigned n = 0; n < numRepN; ++n)\n           callMma(2 * m, n, 2 * k);\n \n+    // NOTE, the barrier here is a temporary trick making the gemm with a\n+    // k-forloop pass the precision test, or it will fail.\n+    // TODO[Superjomn]: Fix with a more general and performance-friendly way.\n+    barrier;\n+\n     // replace with new packed result\n     Type structTy = LLVM::LLVMStructType::getLiteral(\n         ctx, SmallVector<Type>(fc.size(), type::f32Ty(ctx)));\n@@ -3168,9 +3176,6 @@ LogicalResult ConvertLayoutOpConversion::lowerSharedToDotOperand(\n   } else if (dotOperandLayout.getOpIdx() == 1) {\n     // operand $b\n     res = mmaHelper.loadB(src, adaptor.src());\n-  } else if (dotOperandLayout.getOpIdx() == 2) {\n-    // operand $c\n-    res = mmaHelper.loadC(src, adaptor.src());\n   }\n \n   rewriter.replaceOp(op, res);\n@@ -3261,6 +3266,7 @@ class TritonGPUToLLVMTypeConverter : public LLVMTypeConverter {\n   }\n \n   llvm::Optional<Type> convertTritonTensorType(RankedTensorType type) {\n+    auto ctx = type.getContext();\n     Attribute layout = type.getEncoding();\n     if (layout &&\n         (layout.isa<BlockedEncodingAttr>() || layout.isa<SliceEncodingAttr>() ||\n@@ -3269,11 +3275,59 @@ class TritonGPUToLLVMTypeConverter : public LLVMTypeConverter {\n           getElemsPerThread(layout, type.getShape());\n       SmallVector<Type, 4> types(numElementsPerThread,\n                                  convertType(type.getElementType()));\n-      return LLVM::LLVMStructType::getLiteral(&getContext(), types);\n+      return LLVM::LLVMStructType::getLiteral(ctx, types);\n     } else if (auto shared_layout =\n                    layout.dyn_cast_or_null<SharedEncodingAttr>()) {\n       return LLVM::LLVMPointerType::get(convertType(type.getElementType()), 3);\n+    } else if (auto mmaLayout = layout.dyn_cast_or_null<MmaEncodingAttr>()) {\n+      if (mmaLayout.getVersion() == 2) {\n+        auto [repM, repN] = DotOpConversionHelper::getRepMN(type);\n+        size_t fcSize = 4 * repM * repN;\n+        return LLVM::LLVMStructType::getLiteral(\n+            ctx, SmallVector<Type>(fcSize, type.getElementType()));\n+      }\n+\n+      llvm::errs() << \"Unexpected mma layout detected in TypeConverter\";\n+      return llvm::None;\n+\n+    } else if (auto dot_op_layout =\n+                   layout.dyn_cast_or_null<DotOperandEncodingAttr>()) {\n+      auto mmaLayout = dot_op_layout.getParent().cast<MmaEncodingAttr>();\n+      if (mmaLayout.getVersion() == 2) {\n+        auto wpt = mmaLayout.getWarpsPerCTA();\n+        auto tensorCoreType =\n+            DotOpConversionHelper::getTensorCoreTypeFromOperand(type);\n+        // {M, N, K}\n+        auto mmaInstrShape =\n+            DotOpConversionHelper::getMmaInstrShape(tensorCoreType);\n+        Type elemTy = type.getElementType();\n+\n+        if (dot_op_layout.getOpIdx() == 0) { // $a\n+          int M = type.getShape()[0];\n+          int K = type.getShape()[1];\n+          int repM = std::max<int>(M / (wpt[0] * mmaInstrShape[0]), 1);\n+          int repK = std::max<int>(K / mmaInstrShape[2], 1);\n+          int elems = 4 * repM * repK;\n+          Type x2Ty = vec_ty(elemTy, 2);\n+          return LLVM::LLVMStructType::getLiteral(\n+              ctx, SmallVector<Type>(elems, x2Ty));\n+        }\n+        if (dot_op_layout.getOpIdx() == 1) { // $b\n+          int K = type.getShape()[0];\n+          int N = type.getShape()[1];\n+          int repN = std::max<int>(N / (wpt[1] * mmaInstrShape[1]), 1);\n+          int repK = std::max<int>(K / mmaInstrShape[2], 1);\n+          int elems = 4 * std::max(repN / 2, 1) * repK;\n+          Type x2Ty = vec_ty(elemTy, 2);\n+          return LLVM::LLVMStructType::getLiteral(\n+              ctx, SmallVector<Type>(elems, x2Ty));\n+        }\n+      }\n+\n+      llvm::errs() << \"Unexpected dot operand layout detected in TypeConverter\";\n+      return llvm::None;\n     }\n+\n     return llvm::None;\n   }\n };\n@@ -3665,8 +3719,8 @@ TritonLLVMConversionTarget::TritonLLVMConversionTarget(\n     : ConversionTarget(ctx), typeConverter(typeConverter) {\n   addLegalDialect<LLVM::LLVMDialect>();\n   addLegalDialect<NVVM::NVVMDialect>();\n-  // addIllegalDialect<triton::TritonDialect>();\n-  // addIllegalDialect<triton::gpu::TritonGPUDialect>();\n+  addIllegalDialect<triton::TritonDialect>();\n+  addIllegalDialect<triton::gpu::TritonGPUDialect>();\n   addIllegalDialect<mlir::gpu::GPUDialect>();\n   addIllegalDialect<mlir::StandardOpsDialect>();\n   addLegalOp<mlir::UnrealizedConversionCastOp>();"}, {"filename": "python/tests/test_gemm.py", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "file_content_changes": "@@ -96,14 +96,12 @@ def matmul_kernel(\n     [64, 128, 64, 4, 64, 128, 32],  # n can't be 128\n     [128, 128, 64, 4, 128, 128, 32],\n \n-    # The following cases failed\n-    # TODO[Superjomn]: Fix later.\n-    # [64, 64, 128, 4, 64, 64, 32],\n-    # [128, 128, 128, 4, 128, 128, 32],\n-    # [128, 128, 256, 4, 128, 128, 64],\n-    # [128, 256, 128, 4, 128, 256, 32],\n-    # [256, 128, 64, 4, 256, 128, 16],\n-    # [128, 64, 128, 4, 128, 64, 32],\n+    [64, 64, 128, 4, 64, 64, 32],\n+    [128, 128, 128, 4, 128, 128, 32],\n+    [128, 128, 256, 4, 128, 128, 64],\n+    [128, 256, 128, 4, 128, 256, 32],\n+    [256, 128, 64, 4, 256, 128, 16],\n+    [128, 64, 128, 4, 128, 64, 32],\n ])\n def test_gemm(SIZE_M, SIZE_N, SIZE_K, NUM_WARPS, BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K):\n     a = torch.randn((SIZE_M, SIZE_K), device='cuda', dtype=torch.float16)\n@@ -120,3 +118,6 @@ def test_gemm(SIZE_M, SIZE_N, SIZE_K, NUM_WARPS, BLOCK_SIZE_M, BLOCK_SIZE_N, BLO\n     golden = torch.matmul(a, b)\n     torch.set_printoptions(profile=\"full\")\n     assert_close(c, golden, rtol=1e-3, atol=1e-3, check_dtype=False)\n+\n+\n+test_gemm_no_scf(*[32, 32, 32, 4])"}]