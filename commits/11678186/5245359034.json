[{"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -73,7 +73,7 @@ getShapePerCTA(Attribute layout,\n \n SmallVector<unsigned> getOrder(Attribute layout);\n \n-bool isDistributedLayout(Attribute layout);\n+bool isaDistributedLayout(Attribute layout);\n \n bool isSharedEncoding(Value value);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "file_content_changes": "@@ -9,7 +9,7 @@ using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n-using ::mlir::triton::gpu::isDistributedLayout;\n+using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n // Forward declarations\n@@ -62,21 +62,23 @@ struct ConvertLayoutOpConversion\n     auto dstTy = dst.getType().cast<RankedTensorType>();\n     Attribute srcLayout = srcTy.getEncoding();\n     Attribute dstLayout = dstTy.getEncoding();\n-    if (isDistributedLayout(srcLayout) && dstLayout.isa<SharedEncodingAttr>()) {\n+    if (isaDistributedLayout(srcLayout) &&\n+        dstLayout.isa<SharedEncodingAttr>()) {\n       return lowerDistributedToShared(op, adaptor, rewriter);\n     }\n     if (srcLayout.isa<SharedEncodingAttr>() &&\n         dstLayout.isa<DotOperandEncodingAttr>()) {\n       return lowerSharedToDotOperand(op, adaptor, rewriter);\n     }\n-    if (isDistributedLayout(srcLayout) && isDistributedLayout(dstLayout)) {\n+    if (isaDistributedLayout(srcLayout) && isaDistributedLayout(dstLayout)) {\n       return lowerDistributedToDistributed(op, adaptor, rewriter);\n     }\n     if (srcLayout.isa<MmaEncodingAttr>() &&\n         dstLayout.isa<DotOperandEncodingAttr>()) {\n       return lowerMmaToDotOperand(op, adaptor, rewriter);\n     }\n-    if (srcLayout.isa<SharedEncodingAttr>() && isDistributedLayout(dstLayout)) {\n+    if (srcLayout.isa<SharedEncodingAttr>() &&\n+        isaDistributedLayout(dstLayout)) {\n       return lowerSharedToDistributed(op, adaptor, rewriter);\n     }\n     // TODO: to be implemented"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandFMA.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -10,7 +10,7 @@ using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n-using ::mlir::triton::gpu::isDistributedLayout;\n+using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n SmallVector<Value>"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv1.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -11,7 +11,7 @@ using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n-using ::mlir::triton::gpu::isDistributedLayout;\n+using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n // Compute the offset of the matrix to load."}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -12,7 +12,7 @@ using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n-using ::mlir::triton::gpu::isDistributedLayout;\n+using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n \n // Data loader for mma.16816 instruction."}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -350,7 +350,7 @@ SmallVector<unsigned> getOrder(Attribute layout) {\n   }\n }\n \n-bool isDistributedLayout(Attribute layout) {\n+bool isaDistributedLayout(Attribute layout) {\n   return layout.isa<BlockedEncodingAttr>() || layout.isa<MmaEncodingAttr>() ||\n          layout.isa<SliceEncodingAttr>();\n }"}]