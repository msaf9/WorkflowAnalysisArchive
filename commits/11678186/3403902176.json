[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 48, "deletions": 13, "changes": 61, "file_content_changes": "@@ -4161,6 +4161,12 @@ DotOpMmaV1ConversionHelper::extractLoadedOperand(\n   return rcds;\n }\n \n+template <typename T> void print_vec(ArrayRef<T> vec) {\n+  for (int v : vec)\n+    llvm::outs() << v << \" \";\n+  llvm::outs() << \"\\n\";\n+}\n+\n LogicalResult\n DotOpConversion::convertFMADot(triton::DotOp op, OpAdaptor adaptor,\n                                ConversionPatternRewriter &rewriter) const {\n@@ -4213,28 +4219,54 @@ DotOpConversion::convertFMADot(triton::DotOp op, OpAdaptor adaptor,\n   int bMaxPhase = bLayout.getMaxPhase();\n   int aNumPtr = 8;\n   int bNumPtr = 8;\n-  int aVec = 2;\n-  int bVec = 4;\n-  int NK = aShape[isARow ? 1 : 0];\n+  int NK = aShape[1];\n+\n+  auto shapePerCTA = getShapePerCTA(dLayout);\n \n-  auto cShapePerCTA = getShapePerCTA(cLayout);\n   auto sizePerThread = getSizePerThread(dLayout);\n \n+  llvm::outs() << \"strideA: \" << strideAM << \" \" << strideAK << \"\\n\";\n+  llvm::outs() << \"strideB: \" << strideBN << \" \" << strideBK << \"\\n\";\n+  llvm::outs() << \"shapePerCTA: \";\n+  print_vec<unsigned>(shapePerCTA);\n+  llvm::outs() << \"\\n\";\n+\n+  llvm::outs() << \"sizePerThread: \";\n+  print_vec<unsigned>(sizePerThread);\n+  llvm::outs() << \"\\n\";\n+\n   Value _0 = i32_val(0);\n-  Value _1 = i32_val(1);\n \n-  Value mContig = _1;\n-  Value nContig = _1;\n+  Value mContig = i32_val(sizePerThread[order[1]]);\n+  Value nContig = i32_val(sizePerThread[order[0]]);\n \n-  Value offA0 = isARow ? _0 : mul(threadId, mContig);\n-  Value offA1 = isARow ? mul(threadId, mContig) : _0;\n+  // threadId in blocked layout\n+  SmallVector<Value> threadIds;\n+  {\n+    int dim = cShape.size();\n+    threadIds.resize(dim);\n+    for (unsigned k = 0; k < dim - 1; k++) {\n+      Value dimK = i32_val(shapePerCTA[order[k]]);\n+      Value rem = urem(threadId, dimK);\n+      threadId = udiv(threadId, dimK);\n+      threadIds[order[k]] = rem;\n+    }\n+    Value dimK = i32_val(shapePerCTA[order[dim - 1]]);\n+    threadIds[order[dim - 1]] = urem(threadId, dimK);\n+  }\n+\n+  Value threadIdM = threadIds[0];\n+  Value threadIdN = threadIds[1];\n+\n+  Value offA0 = isARow ? _0 : mul(threadIdM, mContig);\n+  Value offA1 = isARow ? mul(threadIdM, mContig) : _0;\n   SmallVector<Value> aOff(aNumPtr);\n   for (int i = 0; i < aNumPtr; ++i) {\n     aOff[i] = add(mul(offA0, i32_val(strideA0)), mul(offA1, i32_val(strideA1)));\n   }\n \n-  Value offB0 = isBRow ? mul(threadId, nContig) : _0;\n-  Value offB1 = isBRow ? _0 : mul(threadId, nContig);\n+  Value offB0 = isBRow ? mul(threadIdN, nContig) : _0;\n+  Value offB1 = isBRow ? _0 : mul(threadIdN, nContig);\n   SmallVector<Value> bOff(bNumPtr);\n   for (int i = 0; i < bNumPtr; ++i) {\n     bOff[i] = add(mul(offB0, i32_val(strideB0)), mul(offB1, i32_val(strideB1)));\n@@ -4252,11 +4284,12 @@ DotOpConversion::convertFMADot(triton::DotOp op, OpAdaptor adaptor,\n   ValueTable has, hbs;\n   auto cc = getElementsFromStruct(loc, adaptor.c(), rewriter);\n   SmallVector<Value> ret = cc;\n+  // is this compatible with blocked layout?\n \n   for (unsigned k = 0; k < NK; k++) {\n     int z = 0;\n-    for (unsigned i = 0; i < cShape[order[1]]; i += cShapePerCTA[order[1]])\n-      for (unsigned j = 0; j < cShape[order[0]]; j += cShapePerCTA[order[0]])\n+    for (unsigned i = 0; i < cShape[order[1]]; i += shapePerCTA[order[1]])\n+      for (unsigned j = 0; j < cShape[order[0]]; j += shapePerCTA[order[0]])\n         for (unsigned ii = 0; ii < sizePerThread[order[1]]; ++ii)\n           for (unsigned jj = 0; jj < sizePerThread[order[0]]; ++jj) {\n             unsigned m = order[0] == 1 ? i : j;\n@@ -4275,6 +4308,8 @@ DotOpConversion::convertFMADot(triton::DotOp op, OpAdaptor adaptor,\n               Value vb = load(pb);\n               hbs[{n + nn, k}] = vb;\n             }\n+\n+            llvm::outs() << z << \": \" << m + mm << \" \" << n + nn << \"\\n\";\n             ret[z] = rewriter.create<LLVM::FMulAddOp>(loc, has[{m + mm, k}],\n                                                       hbs[{n + nn, k}], ret[z]);\n             ++z;"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "file_content_changes": "@@ -570,6 +570,14 @@ class BlockedToMMA : public mlir::RewritePattern {\n     auto oldRetType = dotOp.getResult().getType().cast<RankedTensorType>();\n     if (oldRetType.getEncoding().isa<triton::gpu::MmaEncodingAttr>())\n       return failure();\n+\n+    auto A = dotOp.getOperand(0).getType().cast<RankedTensorType>();\n+    auto B = dotOp.getOperand(1).getType().cast<RankedTensorType>();\n+    // for FMA, should retain the blocked layout.\n+    if (A.getElementType().isF32() && B.getElementType().isF32() &&\n+        !dotOp.allowTF32())\n+      return failure();\n+\n     // get MMA encoding for the given number of warps\n     auto retShape = oldRetType.getShape();\n     auto mod = op->getParentOfType<mlir::ModuleOp>();\n@@ -623,4 +631,4 @@ class TritonGPUCombineOpsPass\n \n std::unique_ptr<Pass> mlir::createTritonGPUCombineOpsPass() {\n   return std::make_unique<TritonGPUCombineOpsPass>();\n-}\n\\ No newline at end of file\n+}"}, {"filename": "python/tests/test_gemm.py", "status": "modified", "additions": 6, "deletions": 10, "changes": 16, "file_content_changes": "@@ -146,12 +146,10 @@ def test_gemm(SIZE_M, SIZE_N, SIZE_K, NUM_WARPS, BLOCK_SIZE_M, BLOCK_SIZE_N, BLO\n     assert_close(c, golden, rtol=max(1e-4, 1.5 * golden_rel_err), atol=max(1e-4, 1.5 * golden_abs_err), check_dtype=False)\n \n \n-# Precession regression for FMADot is not done yet due to some issue on the optimizer failed to give a blocked layout to dot op.\n-# TODO[Superjomn]: Uncomment this test and continue to finish precession regression latter.\n+# TODO[Superjomn]: Precession bug when rep in k is greater than 1\n @pytest.mark.parametrize('M,N,K,num_warps,block_M,block_N,block_K', [\n-    [128, 256, 128, 4, 128, 256, 32],\n-    [256, 128, 64, 4, 256, 128, 16],\n-    [128, 64, 128, 4, 128, 64, 32],\n+    [32, 32, 16, 1, 32, 32, 16],\n+    [32, 16, 16, 1, 32, 16, 16],\n ])\n def test_gemm_fmadot(M, N, K, num_warps, block_M, block_N, block_K):\n     @triton.jit\n@@ -181,7 +179,7 @@ def matmul_kernel(\n         tl.store(c_ptrs, accumulator)\n \n     a = torch.randn((M, K), device='cuda', dtype=torch.float32)\n-    b = torch.randn((K, N), device='cuda', dtype=torch.float)\n+    b = torch.randn((K, N), device='cuda', dtype=torch.float32)\n     c = torch.empty((M, N), device=a.device, dtype=torch.float32)\n     grid = lambda META: (1, )\n     matmul_kernel[grid](a_ptr=a, b_ptr=b, c_ptr=c,\n@@ -191,8 +189,6 @@ def matmul_kernel(\n                         K=a.shape[1], BLOCK_SIZE_M=block_M, BLOCK_SIZE_N=block_N,\n                         BLOCK_SIZE_K=block_K, num_warps=num_warps)\n     golden = torch.matmul(a, b)\n+    print(c)\n+    print(golden)\n     torch.testing.assert_close(c, golden)\n-\n-\n-#test_gemm_no_scf(*[64, 128, 128, 2])\n-test_gemm_fmadot(*[128, 64, 128, 4, 128, 64, 32])"}]