[{"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 80, "deletions": 42, "changes": 122, "file_content_changes": "@@ -21,6 +21,13 @@ using namespace mlir::triton;\n \n namespace {\n \n+// pass named attrs (e.g., tt.contiguity) from Triton to Triton\n+static void addNamedAttrs(Operation *op, DictionaryAttr dictAttrs) {\n+  for (const NamedAttribute attr : dictAttrs.getValue())\n+    if (!op->hasAttr(attr.getName()))\n+      op->setAttr(attr.getName(), attr.getValue());\n+}\n+\n template <class Op> class GenericOpPattern : public OpConversionPattern<Op> {\n public:\n   using OpConversionPattern<Op>::OpConversionPattern;\n@@ -29,7 +36,9 @@ template <class Op> class GenericOpPattern : public OpConversionPattern<Op> {\n   matchAndRewrite(Op op, typename Op::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Type retType = this->getTypeConverter()->convertType(op.getType());\n-    rewriter.replaceOpWithNewOp<Op>(op, retType, adaptor.getOperands());\n+    addNamedAttrs(\n+        rewriter.replaceOpWithNewOp<Op>(op, retType, adaptor.getOperands()),\n+        adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -43,8 +52,10 @@ class ArithCmpPattern : public OpConversionPattern<SrcOp> {\n   matchAndRewrite(SrcOp op, typename SrcOp::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Type retType = this->getTypeConverter()->convertType(op.getType());\n-    rewriter.replaceOpWithNewOp<DstOp>(op, retType, adaptor.getPredicate(),\n-                                       adaptor.getLhs(), adaptor.getRhs());\n+    addNamedAttrs(\n+        rewriter.replaceOpWithNewOp<DstOp>(op, retType, adaptor.getPredicate(),\n+                                           adaptor.getLhs(), adaptor.getRhs()),\n+        adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -65,7 +76,9 @@ class ArithConstantPattern : public OpConversionPattern<arith::ConstantOp> {\n     else\n       // This is a hack. We just want to add encoding\n       value = value.reshape(retType);\n-    rewriter.replaceOpWithNewOp<arith::ConstantOp>(op, retType, value);\n+    addNamedAttrs(\n+        rewriter.replaceOpWithNewOp<arith::ConstantOp>(op, retType, value),\n+        adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -137,9 +150,10 @@ class StdSelectPattern : public OpConversionPattern<arith::SelectOp> {\n   matchAndRewrite(arith::SelectOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Type retType = this->getTypeConverter()->convertType(op.getType());\n-    rewriter.replaceOpWithNewOp<triton::gpu::SelectOp>(\n-        op, retType, adaptor.getCondition(), adaptor.getTrueValue(),\n-        adaptor.getFalseValue());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::gpu::SelectOp>(\n+                      op, retType, adaptor.getCondition(),\n+                      adaptor.getTrueValue(), adaptor.getFalseValue()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -176,8 +190,9 @@ struct TritonMakeRangePattern\n   matchAndRewrite(triton::MakeRangeOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Type retType = getTypeConverter()->convertType(op.getType());\n-    rewriter.replaceOpWithNewOp<triton::MakeRangeOp>(\n-        op, retType, adaptor.getStart(), adaptor.getEnd());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::MakeRangeOp>(\n+                      op, retType, adaptor.getStart(), adaptor.getEnd()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -220,8 +235,9 @@ struct TritonExpandDimsPattern\n     // construct new op\n     auto newSrc = rewriter.create<triton::gpu::ConvertLayoutOp>(\n         op.getLoc(), newArgType, adaptor.getSrc());\n-    rewriter.replaceOpWithNewOp<triton::ExpandDimsOp>(op, newSrc,\n-                                                      adaptor.getAxis());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::ExpandDimsOp>(\n+                      op, newSrc, adaptor.getAxis()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -273,8 +289,9 @@ struct TritonDotPattern : public OpConversionPattern<triton::DotOp> {\n     }\n     c = rewriter.create<triton::gpu::ConvertLayoutOp>(c.getLoc(), retType, c);\n \n-    rewriter.replaceOpWithNewOp<triton::DotOp>(op, retType, a, b, c,\n-                                               adaptor.getAllowTF32());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::DotOp>(\n+                      op, retType, a, b, c, adaptor.getAllowTF32()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -289,8 +306,9 @@ struct TritonCatPattern : public OpConversionPattern<triton::CatOp> {\n     // For now, this behaves like generic, but this will evolve when\n     // we add support for `can_reorder=False`\n     Type retType = this->getTypeConverter()->convertType(op.getType());\n-    rewriter.replaceOpWithNewOp<triton::CatOp>(op, retType,\n-                                               adaptor.getOperands());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::CatOp>(\n+                      op, retType, adaptor.getOperands()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -322,7 +340,8 @@ struct TritonTransPattern : public OpConversionPattern<triton::TransOp> {\n       src = rewriter.create<triton::gpu::ConvertLayoutOp>(src.getLoc(), srcType,\n                                                           src);\n     }\n-    rewriter.replaceOpWithNewOp<triton::TransOp>(op, src);\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::TransOp>(op, src),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -333,10 +352,12 @@ struct TritonLoadPattern : public OpConversionPattern<triton::LoadOp> {\n   LogicalResult\n   matchAndRewrite(triton::LoadOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<triton::LoadOp>(\n-        op, typeConverter->convertType(op.getType()), adaptor.getPtr(),\n-        adaptor.getMask(), adaptor.getOther(), adaptor.getCache(),\n-        adaptor.getEvict(), adaptor.getIsVolatile());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::LoadOp>(\n+                      op, typeConverter->convertType(op.getType()),\n+                      adaptor.getPtr(), adaptor.getMask(), adaptor.getOther(),\n+                      adaptor.getCache(), adaptor.getEvict(),\n+                      adaptor.getIsVolatile()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -347,9 +368,11 @@ struct TritonStorePattern : public OpConversionPattern<triton::StoreOp> {\n   LogicalResult\n   matchAndRewrite(triton::StoreOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<triton::StoreOp>(\n-        op, adaptor.getPtr(), adaptor.getValue(), adaptor.getMask(),\n-        adaptor.getCache(), adaptor.getEvict());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::StoreOp>(\n+                      op, adaptor.getPtr(), adaptor.getValue(),\n+                      adaptor.getMask(), adaptor.getCache(),\n+                      adaptor.getEvict()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -361,9 +384,10 @@ struct TritonAtomicCASPattern\n   LogicalResult\n   matchAndRewrite(triton::AtomicCASOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<triton::AtomicCASOp>(\n-        op, typeConverter->convertType(op.getType()), adaptor.getPtr(),\n-        adaptor.getCmp(), adaptor.getVal());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::AtomicCASOp>(\n+                      op, typeConverter->convertType(op.getType()),\n+                      adaptor.getPtr(), adaptor.getCmp(), adaptor.getVal()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -375,9 +399,11 @@ struct TritonAtomicRMWPattern\n   LogicalResult\n   matchAndRewrite(triton::AtomicRMWOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<triton::AtomicRMWOp>(\n-        op, typeConverter->convertType(op.getType()), adaptor.getAtomicRmwOp(),\n-        adaptor.getPtr(), adaptor.getVal(), adaptor.getMask());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::AtomicRMWOp>(\n+                      op, typeConverter->convertType(op.getType()),\n+                      adaptor.getAtomicRmwOp(), adaptor.getPtr(),\n+                      adaptor.getVal(), adaptor.getMask()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -389,9 +415,11 @@ struct TritonExtElemwisePattern\n   LogicalResult\n   matchAndRewrite(triton::ExtElemwiseOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<triton::ExtElemwiseOp>(\n-        op, typeConverter->convertType(op.getType()), adaptor.getArgs(),\n-        adaptor.getLibname(), adaptor.getLibpath(), adaptor.getSymbol());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::ExtElemwiseOp>(\n+                      op, typeConverter->convertType(op.getType()),\n+                      adaptor.getArgs(), adaptor.getLibname(),\n+                      adaptor.getLibpath(), adaptor.getSymbol()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -404,7 +432,9 @@ struct TritonGenericPattern : public OpConversionPattern<Op> {\n   matchAndRewrite(Op op, typename Op::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Type retType = this->getTypeConverter()->convertType(op.getType());\n-    rewriter.replaceOpWithNewOp<Op>(op, retType, adaptor.getOperands());\n+    addNamedAttrs(\n+        rewriter.replaceOpWithNewOp<Op>(op, retType, adaptor.getOperands()),\n+        adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -425,8 +455,9 @@ struct TritonBroadcastPattern\n     Type retType = RankedTensorType::get(opType.getShape(),\n                                          opType.getElementType(), srcEncoding);\n     // Type retType = this->getTypeConverter()->convertType(op.getType());\n-    rewriter.replaceOpWithNewOp<triton::BroadcastOp>(op, retType,\n-                                                     adaptor.getOperands());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::BroadcastOp>(\n+                      op, retType, adaptor.getOperands()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -437,8 +468,10 @@ struct TritonReducePattern : public OpConversionPattern<triton::ReduceOp> {\n   LogicalResult\n   matchAndRewrite(triton::ReduceOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<triton::ReduceOp>(\n-        op, adaptor.getRedOp(), adaptor.getOperand(), adaptor.getAxis());\n+    addNamedAttrs(\n+        rewriter.replaceOpWithNewOp<triton::ReduceOp>(\n+            op, adaptor.getRedOp(), adaptor.getOperand(), adaptor.getAxis()),\n+        adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -449,8 +482,9 @@ struct TritonPrintfPattern : public OpConversionPattern<triton::PrintfOp> {\n   LogicalResult\n   matchAndRewrite(PrintfOp op, typename PrintfOp::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<triton::PrintfOp>(op, op.getPrefixAttr(),\n-                                                  adaptor.getOperands());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<triton::PrintfOp>(\n+                      op, op.getPrefixAttr(), adaptor.getOperands()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -529,7 +563,9 @@ struct SCFYieldPattern : public OpConversionPattern<scf::YieldOp> {\n     // rewriter.setInsertionPointToEnd(rewriter.getInsertionBlock());\n     // rewriter.create<scf::YieldOp>(op.getLoc(), adaptor.getOperands());\n     // op.erase();\n-    rewriter.replaceOpWithNewOp<scf::YieldOp>(op, adaptor.getOperands());\n+    addNamedAttrs(\n+        rewriter.replaceOpWithNewOp<scf::YieldOp>(op, adaptor.getOperands()),\n+        adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -634,8 +670,9 @@ class CFBranchPattern : public OpConversionPattern<cf::BranchOp> {\n   LogicalResult\n   matchAndRewrite(cf::BranchOp op, cf::BranchOp::Adaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<cf::BranchOp>(op, op.getSuccessor(),\n-                                              adaptor.getOperands());\n+    addNamedAttrs(rewriter.replaceOpWithNewOp<cf::BranchOp>(\n+                      op, op.getSuccessor(), adaptor.getOperands()),\n+                  adaptor.getAttributes());\n     return success();\n   }\n };\n@@ -652,6 +689,7 @@ class CFCondBranchPattern : public OpConversionPattern<cf::CondBranchOp> {\n         op, adaptor.getCondition(), op.getTrueDest(),\n         adaptor.getTrueDestOperands(), op.getFalseDest(),\n         adaptor.getFalseDestOperands());\n+    addNamedAttrs(newOp, adaptor.getAttributes());\n \n     if (failed(rewriter.convertRegionTypes(newOp.getTrueDest()->getParent(),\n                                            *converter)))"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "file_content_changes": "@@ -1409,6 +1409,28 @@ def _kernel(dst, src, N, BLOCK_SIZE: tl.constexpr):\n         assert \"ld.global.b32\" in ptx\n     # triton.testing.assert_almost_equal(dst, src[:N])\n \n+\n+@pytest.mark.parametrize(\"has_hints\", [False, True])\n+def test_vectorization_hints(has_hints):\n+    src = torch.empty(1024, device='cuda')\n+    dst = torch.empty(1024, device='cuda')\n+    off = torch.zeros(1, device='cuda', dtype=torch.int32)\n+\n+    @triton.jit\n+    def _kernel(dst, src, off, N, BLOCK_SIZE: tl.constexpr, HINT: tl.constexpr):\n+        offsets = tl.program_id(0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n+        offsets = offsets + tl.load(off)\n+        if HINT:\n+            tl.max_contiguous(tl.multiple_of(offsets, 1024), 1024)\n+        x = tl.load(src + offsets, mask=offsets < N)\n+        tl.store(dst + offsets, x, mask=offsets < N)\n+    pgm = _kernel[(1,)](dst, src, off, N=1024, BLOCK_SIZE=src.shape[0], HINT=has_hints)\n+    ptx = pgm.asm[\"ptx\"]\n+    if has_hints:\n+        assert \"ld.global.v4.b32\" in ptx\n+    else:\n+        assert \"ld.global.v4.b32\" not in ptx\n+\n # ---------------\n # test store\n # ---------------"}]