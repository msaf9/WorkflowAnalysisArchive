[{"filename": "python/src/triton.cc", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -1756,6 +1756,7 @@ void init_triton_translation(py::module &m) {\n   });\n   m.def(\"get_num_warps\", [](mlir::ModuleOp mod) {\n     auto shared = mod->getAttrOfType<mlir::IntegerAttr>(\"triton_gpu.num-warps\");\n+    assert(shared);\n     return shared.getInt();\n   });\n "}, {"filename": "python/triton/compiler/compiler.py", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -558,15 +558,15 @@ def compile(fn, **kwargs):\n             asm[ir_name] = str(next_module)\n         if ir_name == \"llir\" and \"shared\" not in metadata:\n             metadata[\"shared\"] = get_shared_memory_size(module)\n-        if ir_name == \"ttgir\" and enable_warp_specialization:\n-            metadata[\"num_warps\"] = get_num_warps(module)\n+        if ir_name == \"ttgir\":\n+            metadata[\"enable_warp_specialization\"] = _triton.ir.is_ws_supported(next_module)\n+            if metadata[\"enable_warp_specialization\"]:\n+                metadata[\"num_warps\"] = get_num_warps(module)\n         if ir_name == \"ptx\":\n             metadata[\"name\"] = get_kernel_name(next_module, pattern='// .globl')\n         if ir_name == \"amdgcn\":\n             metadata[\"name\"] = get_kernel_name(next_module[0], pattern='.globl')\n             asm[\"hsaco_path\"] = next_module[1]\n-        if ir_name == \"ttgir\":\n-            metadata[\"enable_warp_specialization\"] = _triton.ir.is_ws_supported(next_module)\n         if not is_cuda and not is_hip:\n             _device_backend.add_meta_info(ir_name, module, next_module, metadata, asm)\n         module = next_module"}]