[{"filename": "lib/Conversion/NVGPUToLLVM/NVGPUToLLVMPass.cpp", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "file_content_changes": "@@ -935,10 +935,9 @@ class WGMMAOpPattern : public mlir::RewritePattern {\n     uint32_t asmOpIdx = 0;\n \n     // Operand C\n-    uint32_t numCRegs = m * n / 128;\n-    assert(numCRegs == structTypeC.getBody().size());\n-    std::string args = \"\";\n+    uint32_t numCRegs = structTypeC.getBody().size();\n \n+    std::string args = \"\";\n     args += \"{\";\n     for (uint32_t i = 0; i < numCRegs; ++i) {\n       args += \"$\" + std::to_string(asmOpIdx++) + (i == numCRegs - 1 ? \"\" : \",\");\n@@ -1437,7 +1436,7 @@ class ConvertNVGPUToLLVM : public ConvertNVGPUToLLVMBase<ConvertNVGPUToLLVM> {\n     // patterns.add<OffsetOfSts64OpPattern>(context);\n     // patterns.add<CGABarrierWaitOpPattern>(context);\n     // patterns.add<CGABarrierArriveOpPattern>(context);\n-    // patterns.add<NamedBarrierWaitOpPattern>(context);\n+    patterns.add<NamedBarrierWaitOpPattern>(context);\n     // patterns.add<NamedBarrierArriveOpPattern>(context);\n     // patterns.add<FenceMBarrierInitOpPattern>(context);\n "}, {"filename": "lib/Hopper/HopperHelpers.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -32,4 +32,4 @@\n #define __DEVICE__ __device__ inline\n #else\n #define __DEVICE__\n-#endif\n\\ No newline at end of file\n+#endif"}, {"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -172,7 +172,7 @@ def _bwd_kernel(\n             lo = 0\n         # initialize row/col offsets\n         offs_qm = lo + tl.arange(0, BLOCK_M)\n-        offs_n = start_n * BLOCK_M + tl.arange(0, BLOCK_M) \n+        offs_n = start_n * BLOCK_M + tl.arange(0, BLOCK_M)\n         offs_m = tl.arange(0, BLOCK_N)\n         offs_k = tl.arange(0, BLOCK_DMODEL)\n         # initialize pointers to value-like data"}]