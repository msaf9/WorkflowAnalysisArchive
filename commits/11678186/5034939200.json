[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -1971,6 +1971,9 @@ def kernel_dynamic(out, val, dtype: tl.constexpr):\n \n @pytest.mark.parametrize(\"literal, dtype_str\",\n                          [(1e+50, \"f64\"), (1e+10, \"f32\"), (1.0, \"f32\"),\n+                          ('float(\"inf\")', \"f32\"), ('float(\"-inf\")', \"f32\"),\n+                          ('float(\"nan\")', \"f32\"), ('float(\"-nan\")', \"f32\"),\n+                          (0., \"f32\"),\n                           (5, \"i32\"), (2**40, \"i64\"),])\n def test_constexpr(literal, dtype_str):\n     @triton.jit"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "file_content_changes": "@@ -58,7 +58,10 @@ def _to_tensor(x, builder):\n         min_float32 = 2 ** -126\n         max_float32 = (2 - 2**-23) * 2**127\n         abs_x = __builtins__['abs'](x)\n-        if abs_x == float(\"inf\") or min_float32 <= abs_x <= max_float32:\n+        if abs_x == float(\"inf\") or\\\n+           abs_x == 0.0 or \\\n+           x != x or \\\n+           min_float32 <= abs_x <= max_float32:\n             return tensor(builder.get_fp32(x), float32)\n         else:\n             return tensor(builder.get_fp64(x), float64)"}]