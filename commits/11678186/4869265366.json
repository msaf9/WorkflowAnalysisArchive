[{"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 1, "deletions": 37, "changes": 38, "file_content_changes": "@@ -298,43 +298,7 @@ struct StoreOpConversion\n       vec = std::min(vec, maskAlign);\n     }\n \n-    auto tensorTy = valueTy.dyn_cast<RankedTensorType>();\n-    Value mask = int_val(1, 1);\n-    auto tid = tid_val();\n-    if (tensorTy) {\n-      auto layout = tensorTy.getEncoding();\n-      auto shape = tensorTy.getShape();\n-      unsigned rank = shape.size();\n-      auto sizePerThread = triton::gpu::getSizePerThread(layout);\n-      auto threadsPerWarp = triton::gpu::getThreadsPerWarp(layout);\n-      auto warpsPerCTA = triton::gpu::getWarpsPerCTA(layout);\n-      auto order = triton::gpu::getOrder(layout);\n-      auto shapePerCTA = triton::gpu::getShapePerCTA(layout, shape);\n-      for (unsigned dim = 0; dim < rank; ++dim) {\n-        // if there is no data replication across threads on this dimension\n-        if (shape[dim] >= shapePerCTA[dim])\n-          continue;\n-        // Otherwise, we need to mask threads that will replicate data on this\n-        // dimension\n-        Value warpSize = i32_val(32);\n-        Value laneId = urem(tid, warpSize);\n-        Value warpId = udiv(tid, warpSize);\n-        SmallVector<Value> multiDimWarpId =\n-            delinearize(rewriter, loc, warpId, warpsPerCTA, order);\n-        SmallVector<Value> multiDimThreadId =\n-            delinearize(rewriter, loc, laneId, threadsPerWarp, order);\n-        // Calculate the thread index on this dimension for the CTA\n-        Value threadDim =\n-            add(mul(multiDimWarpId[dim], i32_val(threadsPerWarp[dim])),\n-                multiDimThreadId[dim]);\n-        mask = and_(mask, icmp_slt(mul(threadDim, i32_val(sizePerThread[dim])),\n-                                   i32_val(shape[dim])));\n-      }\n-    } else {\n-      // If the tensor is not ranked, then it is a scalar and only thread 0 can\n-      // write\n-      mask = and_(mask, icmp_slt(tid, i32_val(1)));\n-    }\n+    Value mask = getMask(valueTy, rewriter, loc);\n     const size_t dtsize =\n         std::max<int>(1, valueElemTy.getIntOrFloatBitWidth() / 8);\n     const size_t valueElemNBits = dtsize * 8;"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 41, "deletions": 0, "changes": 41, "file_content_changes": "@@ -421,6 +421,47 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n   // -----------------------------------------------------------------------\n   // Utilities\n   // -----------------------------------------------------------------------\n+  Value getMask(Type valueTy, ConversionPatternRewriter &rewriter,\n+                Location loc) const {\n+    auto tensorTy = valueTy.dyn_cast<RankedTensorType>();\n+    Value mask = int_val(1, 1);\n+    auto tid = tid_val();\n+    if (tensorTy) {\n+      auto layout = tensorTy.getEncoding();\n+      auto shape = tensorTy.getShape();\n+      unsigned rank = shape.size();\n+      auto sizePerThread = triton::gpu::getSizePerThread(layout);\n+      auto threadsPerWarp = triton::gpu::getThreadsPerWarp(layout);\n+      auto warpsPerCTA = triton::gpu::getWarpsPerCTA(layout);\n+      auto order = triton::gpu::getOrder(layout);\n+      auto shapePerCTA = triton::gpu::getShapePerCTA(layout, shape);\n+      for (unsigned dim = 0; dim < rank; ++dim) {\n+        // if there is no data replication across threads on this dimension\n+        if (shape[dim] >= shapePerCTA[dim])\n+          continue;\n+        // Otherwise, we need to mask threads that will replicate data on this\n+        // dimension\n+        Value warpSize = i32_val(32);\n+        Value laneId = urem(tid, warpSize);\n+        Value warpId = udiv(tid, warpSize);\n+        SmallVector<Value> multiDimWarpId =\n+            delinearize(rewriter, loc, warpId, warpsPerCTA, order);\n+        SmallVector<Value> multiDimThreadId =\n+            delinearize(rewriter, loc, laneId, threadsPerWarp, order);\n+        // Calculate the thread index on this dimension for the CTA\n+        Value threadDim =\n+            add(mul(multiDimWarpId[dim], i32_val(threadsPerWarp[dim])),\n+                multiDimThreadId[dim]);\n+        mask = and_(mask, icmp_slt(mul(threadDim, i32_val(sizePerThread[dim])),\n+                                   i32_val(shape[dim])));\n+      }\n+    } else {\n+      // If the tensor is not ranked, then it is a scalar and only thread 0 can\n+      // write\n+      mask = and_(mask, icmp_slt(tid, i32_val(1)));\n+    }\n+    return mask;\n+  }\n \n   // Convert an \\param index to a multi-dim coordinate given \\param shape and\n   // \\param order."}]