[{"filename": "python/tests/test_gemm.py", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -98,12 +98,12 @@ def matmul_kernel(\n \n     # The following cases failed\n     # TODO[Superjomn]: Fix later.\n-    #[64, 64, 128, 4, 64, 64, 32],\n-    #[128, 128, 128, 4, 128, 128, 32],\n-    #[128, 128, 256, 4, 128, 128, 64],\n-    #[128, 256, 128, 4, 128, 256, 32],\n-    #[256, 128, 64, 4, 256, 128, 16],\n-    #[128, 64, 128, 4, 128, 64, 32],\n+    # [64, 64, 128, 4, 64, 64, 32],\n+    # [128, 128, 128, 4, 128, 128, 32],\n+    # [128, 128, 256, 4, 128, 128, 64],\n+    # [128, 256, 128, 4, 128, 256, 32],\n+    # [256, 128, 64, 4, 256, 128, 16],\n+    # [128, 64, 128, 4, 128, 64, 32],\n ])\n def test_gemm(SIZE_M, SIZE_N, SIZE_K, NUM_WARPS, BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K):\n     a = torch.randn((SIZE_M, SIZE_K), device='cuda', dtype=torch.float16)"}]