[{"filename": "lib/Dialect/TritonGPU/Transforms/OptimizeDotOperands.cpp", "status": "modified", "additions": 9, "deletions": 3, "changes": 12, "file_content_changes": "@@ -87,9 +87,15 @@ class MoveOpAfterLayoutConversion : public mlir::RewritePattern {\n     auto cvt = cast<triton::gpu::ConvertLayoutOp>(op);\n     auto srcTy = cvt.getOperand().getType().cast<RankedTensorType>();\n     auto retTy = cvt.getResult().getType().dyn_cast<RankedTensorType>();\n+    auto retEncoding =\n+        retTy.getEncoding().dyn_cast<triton::gpu::DotOperandEncodingAttr>();\n     if (!retTy)\n       return failure();\n-    if (!isa<triton::gpu::DotOperandEncodingAttr>(retTy.getEncoding()))\n+    if (!retEncoding)\n+      return failure();\n+    auto retEncodingParent =\n+        retEncoding.getParent().dyn_cast<triton::gpu::MmaEncodingAttr>();\n+    if (!retEncodingParent || retEncodingParent.isVolta())\n       return failure();\n     if (isa<triton::gpu::SharedEncodingAttr>(srcTy.getEncoding()))\n       return failure();\n@@ -102,8 +108,8 @@ class MoveOpAfterLayoutConversion : public mlir::RewritePattern {\n     SetVector<Operation *> processed;\n     SetVector<Attribute> layout;\n     llvm::MapVector<Value, Attribute> toConvert;\n-    int numCvts = simulateBackwardRematerialization(\n-        cvt, processed, layout, toConvert, retTy.getEncoding());\n+    int numCvts = simulateBackwardRematerialization(cvt, processed, layout,\n+                                                    toConvert, retEncoding);\n     if (numCvts > 1 || toConvert.size() == 1)\n       return failure();\n     for (Operation *op : processed) {"}, {"filename": "test/TritonGPU/dot-operands.mlir", "status": "modified", "additions": 32, "deletions": 8, "changes": 40, "file_content_changes": "@@ -1,8 +1,11 @@\n // RUN: triton-opt %s -split-input-file -tritongpu-optimize-dot-operands -tritongpu-remove-layout-conversions -canonicalize | FileCheck %s\n \n-#C = #triton_gpu.mma<{versionMajor = 2, warpsPerCTA = [4, 1]}>\n-#A = #triton_gpu.dot_op<{opIdx = 0, parent = #C, kWidth=2}>\n-#B = #triton_gpu.dot_op<{opIdx = 1, parent = #C, kWidth=2}>\n+#Cv2 = #triton_gpu.mma<{versionMajor = 2, warpsPerCTA = [4, 1]}>\n+#Av2 = #triton_gpu.dot_op<{opIdx = 0, parent = #Cv2, kWidth=2}>\n+#Bv2 = #triton_gpu.dot_op<{opIdx = 1, parent = #Cv2, kWidth=2}>\n+#Cv1 = #triton_gpu.mma<{versionMajor = 1, warpsPerCTA = [4, 1]}>\n+#Av1 = #triton_gpu.dot_op<{opIdx = 0, parent = #Cv1}>\n+#Bv1 = #triton_gpu.dot_op<{opIdx = 1, parent = #Cv1}>\n #AL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n #BL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>\n \n@@ -16,13 +19,34 @@\n tt.func @push_elementwise1(\n                    %pa: tensor<16x16x!tt.ptr<i8>, #AL> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n                    %pb: tensor<16x16x!tt.ptr<f16>, #BL> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n-                   %c: tensor<16x16xf32, #C>) -> tensor<16x16xf32, #C>{\n+                   %c: tensor<16x16xf32, #Cv2>) -> tensor<16x16xf32, #Cv2>{\n   %ai8 = tt.load %pa {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xi8, #AL>\n   %b = tt.load %pb {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #BL>\n   %af8 = tt.bitcast %ai8: tensor<16x16xi8, #AL> -> tensor<16x16xf8E5M2, #AL>\n   %a = tt.fp_to_fp %af8: tensor<16x16xf8E5M2, #AL> -> tensor<16x16xf16, #AL>\n-  %dota = triton_gpu.convert_layout %a : (tensor<16x16xf16, #AL>) -> tensor<16x16xf16, #A>\n-  %dotb = triton_gpu.convert_layout %b : (tensor<16x16xf16, #BL>) -> tensor<16x16xf16, #B>\n-  %newc = tt.dot %dota, %dotb, %c {allowTF32 = true, transA = false, transB = false} : tensor<16x16xf16, #A> * tensor<16x16xf16, #B> -> tensor<16x16xf32, #C>\n-  tt.return %newc : tensor<16x16xf32, #C>\n+  %dota = triton_gpu.convert_layout %a : (tensor<16x16xf16, #AL>) -> tensor<16x16xf16, #Av2>\n+  %dotb = triton_gpu.convert_layout %b : (tensor<16x16xf16, #BL>) -> tensor<16x16xf16, #Bv2>\n+  %newc = tt.dot %dota, %dotb, %c {allowTF32 = true, transA = false, transB = false} : tensor<16x16xf16, #Av2> * tensor<16x16xf16, #Bv2> -> tensor<16x16xf32, #Cv2>\n+  tt.return %newc : tensor<16x16xf32, #Cv2>\n+}\n+\n+// CHECK: tt.func @push_elementwise2\n+// CHECK: %[[ALOAD:.*]] = tt.load %arg0\n+// CHECK: %[[AF8E5:.*]] = tt.bitcast %[[ALOAD]]\n+// CHECK: %[[AF16:.*]] = tt.fp_to_fp %[[AF8E5]]\n+// CHECK: %[[ACVT:.*]] = triton_gpu.convert_layout %[[AF16]]\n+// CHECK: %[[C:.*]] = tt.dot %[[ACVT]]\n+// CHECK: tt.return %[[C]] : tensor<16x16xf32, #mma1>\n+tt.func @push_elementwise2(\n+                   %pa: tensor<16x16x!tt.ptr<i8>, #AL> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n+                   %pb: tensor<16x16x!tt.ptr<f16>, #BL> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n+                   %c: tensor<16x16xf32, #Cv1>) -> tensor<16x16xf32, #Cv1>{\n+  %ai8 = tt.load %pa {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xi8, #AL>\n+  %b = tt.load %pb {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #BL>\n+  %af8 = tt.bitcast %ai8: tensor<16x16xi8, #AL> -> tensor<16x16xf8E5M2, #AL>\n+  %a = tt.fp_to_fp %af8: tensor<16x16xf8E5M2, #AL> -> tensor<16x16xf16, #AL>\n+  %dota = triton_gpu.convert_layout %a : (tensor<16x16xf16, #AL>) -> tensor<16x16xf16, #Av1>\n+  %dotb = triton_gpu.convert_layout %b : (tensor<16x16xf16, #BL>) -> tensor<16x16xf16, #Bv1>\n+  %newc = tt.dot %dota, %dotb, %c {allowTF32 = true, transA = false, transB = false} : tensor<16x16xf16, #Av1> * tensor<16x16xf16, #Bv1> -> tensor<16x16xf32, #Cv1>\n+  tt.return %newc : tensor<16x16xf32, #Cv1>\n }"}]