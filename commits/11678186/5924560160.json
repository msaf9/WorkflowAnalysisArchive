[{"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -333,7 +333,6 @@ template <typename T> class CallGraph {\n std::unique_ptr<DataFlowSolver> createDataFlowSolver();\n \n triton::MakeTensorPtrOp getMakeTensorPtrOp(Value v);\n-\n } // namespace mlir\n \n #endif // TRITON_ANALYSIS_UTILITY_H"}, {"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -36,7 +36,8 @@ SmallVector<unsigned> getThreadsPerWarp(Attribute layout);\n // elements. If you want non-replicated warps, use getWarpsPerCTAWithUniqueData.\n SmallVector<unsigned> getWarpsPerCTA(Attribute layout);\n \n-SmallVector<unsigned> getSizePerThread(Attribute layout);\n+SmallVector<unsigned> getSizePerThread(Attribute layout,\n+                                       ArrayRef<int64_t> shapePerCTA);\n \n // Returns the number of contiguous elements that each thread\n // has access to, on each dimension of the tensor. E.g."}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "file_content_changes": "@@ -516,15 +516,14 @@ For example, the matrix L corresponding to blockTileSize=[32,16] is:\n     \"unsigned\":$versionMinor,\n     ArrayRefParameter<\"unsigned\">:$warpsPerCTA,\n     \"CTALayoutAttr\":$CTALayout,\n-    ArrayRefParameter<\"unsigned\">:$instrShape\n+    \"bool\":$isInt8Input\n   );\n \n   let builders = [\n     // Specially for MMAV1(Volta)\n     AttrBuilder<(ins \"int\":$versionMajor,\n                      \"int\":$numWarps,\n                      \"CTALayoutAttr\":$CTALayout,\n-                     \"ArrayRef<unsigned>\":$instrShape,\n                      \"ArrayRef<int64_t>\":$shapeC,\n                      \"bool\":$isARow,\n                      \"bool\":$isBRow,\n@@ -562,14 +561,13 @@ For example, the matrix L corresponding to blockTileSize=[32,16] is:\n           wpt[1] = std::clamp<int>(wpt[1] * 2, 1, shapeC[1] / spw[1]);\n       } while (wpt_nm1 != wpt);\n \n-      return $_get(context, versionMajor, versionMinor, wpt, CTALayout, instrShape);\n+      return $_get(context, versionMajor, versionMinor, wpt, CTALayout, false);\n     }]>,\n \n \n     AttrBuilder<(ins \"int\":$versionMajor,\n                      \"int\":$numWarps,\n                      \"CTALayoutAttr\":$CTALayout,\n-                     \"ArrayRef<unsigned>\":$instrShape,\n                      \"ArrayRef<int64_t>\":$shapeA,\n                      \"ArrayRef<int64_t>\":$shapeB,\n                      \"ArrayRef<int64_t>\":$shapeC,\n@@ -579,7 +577,7 @@ For example, the matrix L corresponding to blockTileSize=[32,16] is:\n       assert(versionMajor == 1 && \"This builder is specially for versionMajor==1\");\n       bool isAVec4 = !isARow && (shapeA[isARow] <= 16);\n       bool isBVec4 = isBRow && (shapeB[isBRow] <= 16);\n-      return get(context, versionMajor, numWarps, CTALayout, instrShape, shapeC, isARow, isBRow, isAVec4, isBVec4, id);\n+      return get(context, versionMajor, numWarps, CTALayout, shapeC, isARow, isBRow, isAVec4, isBVec4, id);\n     }]>\n   ];\n "}, {"filename": "include/triton/Dialect/TritonGPU/Transforms/Utility.h", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "file_content_changes": "@@ -7,6 +7,7 @@\n \n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/Transforms/Utility.h\"\n \n namespace mlir {\n \n@@ -22,6 +23,12 @@ class SharedEncodingAttr;\n SmallVector<unsigned, 3> mmaVersionToInstrShape(int version,\n                                                 const ArrayRef<int64_t> &shape,\n                                                 RankedTensorType type);\n+SmallVector<unsigned, 3>\n+mmaVersionToInstrShape(triton::gpu::MmaEncodingAttr mma,\n+                       const ArrayRef<int64_t> shapePerCTA);\n+SmallVector<unsigned, 3>\n+mmaVersionToInstrShape(triton::gpu::MmaEncodingAttr mma, unsigned opIdx,\n+                       RankedTensorType type);\n \n /// Returns true if the Load is for TMA\n bool isLoadFromTensorPtr(triton::LoadOp op);"}, {"filename": "lib/Analysis/Allocation.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -17,7 +17,6 @@ using ::mlir::triton::gpu::getContigPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n using ::mlir::triton::gpu::getShapePerCTATile;\n-using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::MmaEncodingAttr;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n using ::mlir::triton::gpu::SliceEncodingAttr;"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "file_content_changes": "@@ -232,7 +232,8 @@ unsigned ScanLoweringHelper::getAxisNumWarps() {\n \n unsigned ScanLoweringHelper::getAxisNumBlocks() {\n   auto type = scanOp.getOperand(0).getType().cast<RankedTensorType>();\n-  auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding);\n+  auto shapePerCTA = triton::gpu::getShapePerCTA(type);\n+  auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding, shapePerCTA);\n   auto threadsPerWarp = triton::gpu::getThreadsPerWarp(srcEncoding);\n   auto warpsPerCTA = triton::gpu::getWarpsPerCTA(srcEncoding);\n   unsigned axis = getAxis();\n@@ -243,7 +244,8 @@ unsigned ScanLoweringHelper::getAxisNumBlocks() {\n \n unsigned ScanLoweringHelper::getNonAxisNumBlocks() {\n   auto type = scanOp.getOperand(0).getType().cast<RankedTensorType>();\n-  auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding);\n+  auto shapePerCTA = triton::gpu::getShapePerCTA(type);\n+  auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding, shapePerCTA);\n   auto threadsPerWarp = triton::gpu::getThreadsPerWarp(srcEncoding);\n   auto warpsPerCTA = triton::gpu::getWarpsPerCTA(srcEncoding);\n   unsigned axis = getAxis();\n@@ -311,7 +313,8 @@ unsigned ScanLoweringHelper::getAxisBlockStride() {\n   auto order = triton::gpu::getOrder(srcEncoding);\n   unsigned stride = 1;\n   auto type = scanOp.getOperand(0).getType().cast<RankedTensorType>();\n-  auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding);\n+  auto shapePerCTA = triton::gpu::getShapePerCTA(type);\n+  auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding, shapePerCTA);\n   auto threadsPerWarp = triton::gpu::getThreadsPerWarp(srcEncoding);\n   auto warpsPerCTA = triton::gpu::getWarpsPerCTA(srcEncoding);\n   for (unsigned dim : order) {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 18, "deletions": 19, "changes": 37, "file_content_changes": "@@ -103,19 +103,19 @@ struct ConvertLayoutOpConversion\n \n private:\n   SmallVector<Value>\n-  getMultiDimOffset(Attribute layout, Location loc,\n-                    ConversionPatternRewriter &rewriter, unsigned elemId,\n-                    RankedTensorType type,\n+  getMultiDimOffset(Location loc, ConversionPatternRewriter &rewriter,\n+                    unsigned elemId, RankedTensorType type,\n                     ArrayRef<unsigned> multiDimCTAInRepId,\n                     ArrayRef<unsigned> shapePerCTATile) const {\n     auto shape = type.getShape();\n     unsigned rank = shape.size();\n+    auto layout = type.getEncoding();\n     if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n       auto multiDimOffsetFirstElem =\n           emitBaseIndexForLayout(loc, rewriter, blockedLayout, type, false);\n       SmallVector<Value> multiDimOffset(rank);\n       SmallVector<unsigned> multiDimElemId = getMultiDimIndex<unsigned>(\n-          elemId, getSizePerThread(layout), getOrder(layout));\n+          elemId, blockedLayout.getSizePerThread(), getOrder(layout));\n       for (unsigned d = 0; d < rank; ++d) {\n         multiDimOffset[d] =\n             add(multiDimOffsetFirstElem[d],\n@@ -127,10 +127,11 @@ struct ConvertLayoutOpConversion\n     if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n       unsigned dim = sliceLayout.getDim();\n       auto parentEncoding = sliceLayout.getParent();\n-      auto parentSizePerThread = getSizePerThread(parentEncoding);\n       auto parentShape = sliceLayout.paddedShape(shape);\n       auto parentTy = RankedTensorType::get(parentShape, type.getElementType(),\n                                             parentEncoding);\n+      auto parentSizePerThread =\n+          getSizePerThread(parentEncoding, getShapePerCTA(parentTy));\n       auto offsets = emitOffsetForLayout(layout, type);\n       auto parentOffset = emitOffsetForLayout(parentEncoding, parentTy);\n       SmallVector<int> idxs;\n@@ -139,10 +140,10 @@ struct ConvertLayoutOpConversion\n         auto it = std::find(parentOffset.begin(), parentOffset.end(), off);\n         idxs.push_back(std::distance(parentOffset.begin(), it));\n       }\n-      auto multiDimOffsetParent = getMultiDimOffset(\n-          parentEncoding, loc, rewriter, idxs[elemId], parentTy,\n-          sliceLayout.paddedShape(multiDimCTAInRepId),\n-          sliceLayout.paddedShape(shapePerCTATile));\n+      auto multiDimOffsetParent =\n+          getMultiDimOffset(loc, rewriter, idxs[elemId], parentTy,\n+                            sliceLayout.paddedShape(multiDimCTAInRepId),\n+                            sliceLayout.paddedShape(shapePerCTATile));\n       SmallVector<Value> multiDimOffset(rank);\n       for (unsigned d = 0; d < rank + 1; ++d) {\n         if (d == dim)\n@@ -154,7 +155,7 @@ struct ConvertLayoutOpConversion\n     }\n     if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n       auto shapePerCTA = getShapePerCTA(mmaLayout, shape);\n-      auto instrShape = mmaLayout.getInstrShape();\n+      auto instrShape = mmaVersionToInstrShape(mmaLayout, shapePerCTA);\n       SmallVector<Value> mmaColIdx(4);\n       SmallVector<Value> mmaRowIdx(2);\n       Value threadId = getThreadId(rewriter, loc);\n@@ -248,11 +249,11 @@ struct ConvertLayoutOpConversion\n     auto accumNumCTAsEachRep = product<unsigned>(numCTAsEachRep);\n     auto layout = type.getEncoding();\n     auto rank = type.getRank();\n-    auto sizePerThread = getSizePerThread(layout);\n+    auto shapePerCTA = getShapePerCTA(layout, type.getShape());\n+    auto sizePerThread = getSizePerThread(layout, shapePerCTA);\n     auto accumSizePerThread = product<unsigned>(sizePerThread);\n     SmallVector<unsigned> numCTATiles(rank);\n     auto shapePerCTATile = getShapePerCTATile(layout);\n-    auto shapePerCTA = getShapePerCTA(layout, type.getShape());\n     auto order = getOrder(layout);\n     for (unsigned d = 0; d < rank; ++d) {\n       numCTATiles[d] = ceil<unsigned>(shapePerCTA[d], shapePerCTATile[d]);\n@@ -283,9 +284,8 @@ struct ConvertLayoutOpConversion\n       //       consider of caching the index calculation result in case\n       //       of performance issue observed.\n       for (unsigned elemId = 0; elemId < accumSizePerThread; elemId += vec) {\n-        SmallVector<Value> multiDimOffset =\n-            getMultiDimOffset(layout, loc, rewriter, elemId, type,\n-                              multiDimCTAInRepId, shapePerCTATile);\n+        SmallVector<Value> multiDimOffset = getMultiDimOffset(\n+            loc, rewriter, elemId, type, multiDimCTAInRepId, shapePerCTATile);\n         Value offset =\n             linearize(rewriter, loc, multiDimOffset, paddedRepShape, outOrd);\n         auto elemPtrTy = ptr_ty(llvmElemTy, 3);\n@@ -373,9 +373,8 @@ struct ConvertLayoutOpConversion\n       for (unsigned elemId = 0; elemId < accumSizePerThread; ++elemId) {\n         // TODO[Superjomn]: Move the coordinate computation out of loop, it is\n         // duplicate in Volta.\n-        SmallVector<Value> multiDimOffset =\n-            getMultiDimOffset(layout, loc, rewriter, elemId, type,\n-                              multiDimCTAInRepId, shapePerCTATile);\n+        SmallVector<Value> multiDimOffset = getMultiDimOffset(\n+            loc, rewriter, elemId, type, multiDimCTAInRepId, shapePerCTATile);\n         coord2val[elemId] = std::make_pair(multiDimOffset, vals[elemId]);\n       }\n \n@@ -741,7 +740,7 @@ struct ConvertLayoutOpConversion\n                                                          rewriter, srcTy);\n \n       auto srcShapePerCTA = getShapePerCTA(mmaLayout, srcShape);\n-      auto instrShape = mmaLayout.getInstrShape();\n+      auto instrShape = mmaVersionToInstrShape(mmaLayout, srcShapePerCTA);\n       auto warpsPerCTA = mmaLayout.getWarpsPerCTA();\n       uint32_t repM =\n           ceil<unsigned>(srcShapePerCTA[0], instrShape[0] * warpsPerCTA[0]);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandFMA.cpp", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "file_content_changes": "@@ -10,7 +10,6 @@ using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getContigPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n-using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;\n@@ -47,7 +46,7 @@ int getShapePerCTATileForMN(BlockedEncodingAttr layout, bool isM) {\n // Get sizePerThread for M or N axis.\n int getSizePerThreadForMN(BlockedEncodingAttr layout, bool isM) {\n   auto order = layout.getOrder();\n-  auto sizePerThread = getSizePerThread(layout);\n+  auto sizePerThread = layout.getSizePerThread();\n \n   int mSizePerThread =\n       order[0] == 1 ? sizePerThread[order[1]] : sizePerThread[order[0]];\n@@ -111,7 +110,7 @@ Value loadAFMA(Value A, Value llA, BlockedEncodingAttr dLayout, Value thread,\n   int M = aShapePerCTA[0];\n \n   auto shapePerCTATile = getShapePerCTATile(dLayout);\n-  auto sizePerThread = getSizePerThread(dLayout);\n+  auto sizePerThread = dLayout.getSizePerThread();\n \n   Value _0 = i32_val(0);\n \n@@ -175,7 +174,7 @@ Value loadBFMA(Value B, Value llB, BlockedEncodingAttr dLayout, Value thread,\n   int N = bShapePerCTA[1];\n \n   auto shapePerCTATile = getShapePerCTATile(dLayout);\n-  auto sizePerThread = getSizePerThread(dLayout);\n+  auto sizePerThread = dLayout.getSizePerThread();\n \n   Value _0 = i32_val(0);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv1.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -9,7 +9,6 @@ using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getContigPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n-using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -11,7 +11,6 @@ using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getContigPerThread;\n using ::mlir::triton::gpu::getOrder;\n using ::mlir::triton::gpu::getShapePerCTA;\n-using ::mlir::triton::gpu::getSizePerThread;\n using ::mlir::triton::gpu::getTotalElemsPerThread;\n using ::mlir::triton::gpu::isaDistributedLayout;\n using ::mlir::triton::gpu::SharedEncodingAttr;"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/FMA.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -53,7 +53,7 @@ LogicalResult convertFMADot(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n   Value llA = adaptor.getA();\n   Value llB = adaptor.getB();\n \n-  auto sizePerThread = getSizePerThread(dLayout);\n+  auto sizePerThread = dLayout.getSizePerThread();\n   auto shapePerCTATile = getShapePerCTATile(dLayout);\n \n   int K = aShapePerCTA[1];"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/WGMMA.cpp", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -160,11 +160,11 @@ DotOpMmaV3SmemLoader loadA(TritonGPUToLLVMTypeConverter *typeConverter,\n   auto aTensorTy = tensor.getType().cast<RankedTensorType>();\n   auto aSharedLayout = aTensorTy.getEncoding().dyn_cast<SharedEncodingAttr>();\n   assert(aSharedLayout && \"only support load dot operand from shared.\");\n-  auto instrShape = mmaEncoding.getInstrShape();\n+  auto shapePerCTA = getShapePerCTA(aTensorTy);\n+  auto instrShape = mmaVersionToInstrShape(mmaEncoding, 0, aTensorTy);\n   auto wpt = mmaEncoding.getWarpsPerCTA();\n   auto aOrd = aSharedLayout.getOrder();\n   bool transA = aOrd[0] == 0;\n-  auto shapePerCTA = getShapePerCTA(aTensorTy);\n \n   int numRepM = ceil<unsigned>(shapePerCTA[0], instrShape[0] * wpt[0]);\n   int numRepK = ceil<unsigned>(shapePerCTA[1], instrShape[2]);\n@@ -191,7 +191,7 @@ DotOpMmaV3SmemLoader loadB(TritonGPUToLLVMTypeConverter *typeConverter,\n   auto bTensorTy = tensor.getType().cast<RankedTensorType>();\n   auto bSharedLayout = bTensorTy.getEncoding().cast<SharedEncodingAttr>();\n   assert(bSharedLayout && \"only support load B from shared.\");\n-  auto instrShape = mmaEncoding.getInstrShape();\n+  auto instrShape = mmaVersionToInstrShape(mmaEncoding, 1, bTensorTy);\n   auto wpt = mmaEncoding.getWarpsPerCTA();\n   auto bOrd = bSharedLayout.getOrder();\n   bool transB = bOrd[0] == 1;\n@@ -278,7 +278,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   bool transA = aOrd[0] == 0;\n   bool transB = bOrd[0] == 1;\n   auto dShapePerCTA = getShapePerCTA(dTensorTy);\n-  auto instrShape = mmaEncoding.getInstrShape();\n+  auto instrShape = mmaVersionToInstrShape(mmaEncoding, dShapePerCTA);\n   auto accSize = 2 * (instrShape[1] / 4);\n   int M = 4 * instrShape[0];\n   int N = instrShape[1];\n@@ -359,9 +359,9 @@ Value loadC(Value tensor, Value llTensor) {\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n   auto mmaEncoding = tensorTy.getEncoding().dyn_cast<MmaEncodingAttr>();\n   assert(mmaEncoding && \"Currently, we only support $c with a mma layout.\");\n-  auto instrShape = mmaEncoding.getInstrShape();\n-  auto wpt = mmaEncoding.getWarpsPerCTA();\n   auto shapePerCTA = getShapePerCTA(tensorTy);\n+  auto instrShape = mmaVersionToInstrShape(mmaEncoding, shapePerCTA);\n+  auto wpt = mmaEncoding.getWarpsPerCTA();\n   auto shapePerCTATile = getShapePerCTATile(mmaEncoding);\n \n   int numRepM = ceil<unsigned>(shapePerCTA[0], shapePerCTATile[0]);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 11, "deletions": 7, "changes": 18, "file_content_changes": "@@ -93,21 +93,23 @@ struct ReduceOpConversion\n   // the full tensor, whereas `writeIdx` is the mapped-to index in the shared\n   // memory\n   void getWriteIndexBasic(ConversionPatternRewriter &rewriter, Location loc,\n-                          Attribute layout, SmallVector<Value> &index,\n+                          Attribute layout, ArrayRef<int64_t> shapePerCTA,\n+                          SmallVector<Value> &index,\n                           SmallVector<Value> &writeIdx,\n                           std::map<int, Value> &ints, unsigned originalAxis,\n                           unsigned axis) const {\n     if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n       // Recover the axis in the parent layout\n       auto parentAxis = axis < sliceLayout.getDim() ? axis : axis + 1;\n       auto parentLayout = sliceLayout.getParent();\n-      getWriteIndexBasic(rewriter, loc, parentLayout, index, writeIdx, ints,\n-                         originalAxis, parentAxis);\n+      auto parentShapePerCTA = sliceLayout.paddedShape(shapePerCTA);\n+      getWriteIndexBasic(rewriter, loc, parentLayout, parentShapePerCTA, index,\n+                         writeIdx, ints, originalAxis, parentAxis);\n       return;\n     }\n \n     writeIdx = index;\n-    auto sizePerThread = triton::gpu::getSizePerThread(layout);\n+    auto sizePerThread = triton::gpu::getSizePerThread(layout, shapePerCTA);\n     Value axisSizePerThread = ints[sizePerThread[axis]];\n     Value _8 = ints[8];\n     Value _16 = ints[16];\n@@ -153,8 +155,10 @@ struct ReduceOpConversion\n     }\n     // The order of the axes for the the threads within the warp\n     auto srcOrd = triton::gpu::getOrder(srcLayout);\n-    auto sizePerThread = triton::gpu::getSizePerThread(srcLayout);\n     auto srcShape = helper.getSrcShape();\n+    auto srcShapePerCTA = triton::gpu::getShapePerCTA(srcLayout, srcShape);\n+    auto sizePerThread =\n+        triton::gpu::getSizePerThread(srcLayout, srcShapePerCTA);\n \n     SmallVector<Type> elemPtrTys(srcTys.size());\n     for (unsigned i = 0; i < op.getNumOperands(); ++i) {\n@@ -196,8 +200,8 @@ struct ReduceOpConversion\n       auto &acc = it.second;\n       // get the writeIdx at which to write in smem\n       SmallVector<Value> writeIdx;\n-      getWriteIndexBasic(rewriter, loc, srcLayout, indices[key], writeIdx, ints,\n-                         axis, axis);\n+      getWriteIndexBasic(rewriter, loc, srcLayout, srcShapePerCTA, indices[key],\n+                         writeIdx, ints, axis, axis);\n \n       // calculate the offset in smem for that writeIdx\n       Value writeOffset = linearize(rewriter, loc, writeIdx, smemShape, srcOrd);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "file_content_changes": "@@ -11,6 +11,7 @@\n #include \"Utility.h\"\n #include \"mlir/IR/TypeUtilities.h\"\n #include \"triton/Analysis/AxisInfo.h\"\n+#include \"triton/Dialect/TritonGPU/Transforms/Utility.h\"\n #include \"triton/Dialect/TritonNvidiaGPU/IR/Dialect.h\"\n #include \"triton/Target/PTX/TmaMetadata.h\"\n #include <set>\n@@ -545,7 +546,8 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n       auto layout = tensorTy.getEncoding();\n       auto shape = tensorTy.getShape();\n       unsigned rank = shape.size();\n-      auto sizePerThread = triton::gpu::getSizePerThread(layout);\n+      auto shapePerCTA = triton::gpu::getShapePerCTA(tensorTy);\n+      auto sizePerThread = triton::gpu::getSizePerThread(layout, shapePerCTA);\n       auto threadsPerWarp = triton::gpu::getThreadsPerWarp(layout);\n       auto warpsPerCTA = triton::gpu::getWarpsPerCTA(layout);\n       auto order = triton::gpu::getOrder(layout);\n@@ -1035,10 +1037,11 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     auto _warpsPerCTA = mmaLayout.getWarpsPerCTA();\n     assert(_warpsPerCTA.size() == 2);\n     auto order = triton::gpu::getOrder(mmaLayout);\n-    ArrayRef<unsigned int> instrShape = mmaLayout.getInstrShape();\n+    auto shapePerCTA = getShapePerCTA(mmaLayout, shape);\n+    ArrayRef<unsigned int> instrShape =\n+        mmaVersionToInstrShape(mmaLayout, shapePerCTA);\n     SmallVector<Value> warpsPerCTA = {i32_val(_warpsPerCTA[0]),\n                                       i32_val(_warpsPerCTA[1])};\n-    auto shapePerCTA = getShapePerCTA(mmaLayout, shape);\n \n     Value threadId = getThreadId(rewriter, loc);\n     Value warpSize = i32_val(32);\n@@ -1090,7 +1093,8 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     auto shape = type.getShape();\n     auto shapePerCTA = getShapePerCTA(mmaLayout, shape);\n     SmallVector<SmallVector<unsigned>> ret;\n-    ArrayRef<unsigned int> instrShape = mmaLayout.getInstrShape();\n+    ArrayRef<unsigned int> instrShape =\n+        mmaVersionToInstrShape(mmaLayout, shapePerCTA);\n \n     for (unsigned i = 0; i < shapePerCTA[0];\n          i += getShapePerCTATile(mmaLayout)[0]) {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -658,7 +658,9 @@ struct ConvertTritonGPUToLLVM\n         auto tmpType = RankedTensorType::get(\n             dstType.getShape(), dstType.getElementType(),\n             triton::gpu::BlockedEncodingAttr::get(\n-                mod.getContext(), srcType.getShape(), getSizePerThread(srcMma),\n+                mod.getContext(), srcType.getShape(),\n+                getSizePerThread(srcMma,\n+                                 getShapePerCTA(srcMma, srcType.getShape())),\n                 getOrder(srcMma), numWarps, threadsPerWarp, numCTAs));\n         auto tmp = builder.create<triton::gpu::ConvertLayoutOp>(\n             cvtOp.getLoc(), tmpType, cvtOp.getOperand());"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 20, "deletions": 15, "changes": 35, "file_content_changes": "@@ -7,6 +7,7 @@\n #include \"triton/Analysis/Utility.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.cpp.inc\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/Transforms/Utility.h\"\n #include \"llvm/ADT/TypeSwitch.h\"\n \n using namespace mlir;\n@@ -173,22 +174,26 @@ getWarpsPerCTAWithUniqueData(Attribute layout, ArrayRef<int64_t> tensorShape) {\n   auto warpsPerCTA = getWarpsPerCTA(layout);\n   assert(warpsPerCTA.size() == tensorShape.size() &&\n          \"layout and tensor shape must have the same rank\");\n+  auto shapePerCTA = getShapePerCTA(layout, tensorShape);\n   for (unsigned i = 0; i < warpsPerCTA.size(); i++) {\n     auto sizePerWarp =\n-        getSizePerThread(layout)[i] * getThreadsPerWarp(layout)[i];\n+        getSizePerThread(layout, shapePerCTA)[i] * getThreadsPerWarp(layout)[i];\n     auto maxWarpsPerDim = ceil<unsigned>(tensorShape[i], sizePerWarp);\n     warpsPerCTA[i] = std::min<unsigned>(warpsPerCTA[i], maxWarpsPerDim);\n   }\n \n   return warpsPerCTA;\n }\n \n-SmallVector<unsigned> getSizePerThread(Attribute layout) {\n+SmallVector<unsigned> getSizePerThread(Attribute layout,\n+                                       ArrayRef<int64_t> shapePerCTA) {\n   if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n     return SmallVector<unsigned>(blockedLayout.getSizePerThread().begin(),\n                                  blockedLayout.getSizePerThread().end());\n   } else if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n-    auto sizePerThread = getSizePerThread(sliceLayout.getParent());\n+    auto parentShapePerCTA = sliceLayout.paddedShape(shapePerCTA);\n+    auto sizePerThread =\n+        getSizePerThread(sliceLayout.getParent(), parentShapePerCTA);\n     sizePerThread.erase(sizePerThread.begin() + sliceLayout.getDim());\n     return sizePerThread;\n   } else if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n@@ -197,7 +202,7 @@ SmallVector<unsigned> getSizePerThread(Attribute layout) {\n     } else if (mmaLayout.isVolta()) {\n       return {1, 2};\n     } else if (mmaLayout.isHopper()) {\n-      auto instrShape = mmaLayout.getInstrShape();\n+      auto instrShape = mmaVersionToInstrShape(mmaLayout, shapePerCTA);\n       // TODO(thomas): what are those magic numbers?\n       return SmallVector<unsigned>{instrShape[0] * 4 / 32, instrShape[1] / 4};\n     } else {\n@@ -237,7 +242,7 @@ SmallVector<unsigned> getContigPerThread(Attribute layout) {\n     auto parentLayout = sliceLayout.getParent();\n     return getContigPerThread(parentLayout);\n   } else {\n-    return getSizePerThread(layout);\n+    return getSizePerThread(layout, {});\n   }\n }\n \n@@ -308,7 +313,8 @@ SmallVector<unsigned> getShapePerCTATile(Attribute layout,\n               static_cast<unsigned>(tensorShape[1])};\n     }\n     if (mmaLayout.isHopper()) {\n-      auto instrShape = mmaLayout.getInstrShape();\n+      auto shapePerCTA = getShapePerCTA(layout, tensorShape);\n+      auto instrShape = mmaVersionToInstrShape(mmaLayout, shapePerCTA);\n       return {16 * mmaLayout.getWarpsPerCTA()[0],\n               instrShape[1] * mmaLayout.getWarpsPerCTA()[1]};\n     }\n@@ -762,7 +768,7 @@ MmaEncodingAttr::getElemsPerThread(ArrayRef<int64_t> shape, Type eltTy) const {\n     elemsPerThread[1] = elemsCol;\n   } else if (isHopper()) {\n     auto wpt = getWarpsPerCTA();\n-    auto instrMNK = getInstrShape();\n+    auto instrMNK = mmaVersionToInstrShape(*this, shapePerCTA);\n     int repM = ceil<unsigned>(shapePerCTA[0], instrMNK[0] * wpt[0]);\n     int repN = ceil<unsigned>(shapePerCTA[1], instrMNK[1] * wpt[1]);\n     elemsPerThread[0] = 2 * repM;\n@@ -789,7 +795,7 @@ MmaEncodingAttr::getElemsPerThreadOfOperand(int opIdx,\n         \"getElemsPerThreadOfOperand() not supported for version 2\");\n   } else if (isHopper()) {\n     auto wpt = getWarpsPerCTA();\n-    auto instrMNK = getInstrShape();\n+    auto instrMNK = mmaVersionToInstrShape(*this, shapePerCTA);\n     if (opIdx == 0) {\n       int repM = ceil<unsigned>(shapePerCTA[0], instrMNK[0] * wpt[0]);\n       int repK = ceil<unsigned>(shapePerCTA[1], instrMNK[2]);\n@@ -925,7 +931,7 @@ unsigned DotOperandEncodingAttr::getTotalElemsPerThread(ArrayRef<int64_t> shape,\n   if (auto blockedLayout = getParent().dyn_cast<BlockedEncodingAttr>()) {\n     auto shapePerCTATile = getShapePerCTATile(blockedLayout);\n     auto order = blockedLayout.getOrder();\n-    auto sizePerThread = getSizePerThread(blockedLayout);\n+    auto sizePerThread = blockedLayout.getSizePerThread();\n \n     int K = getOpIdx() == 0 ? shapePerCTA[1] : shapePerCTA[0];\n     int otherDim = getOpIdx() == 1 ? shapePerCTA[1] : shapePerCTA[0];\n@@ -1047,6 +1053,7 @@ Attribute MmaEncodingAttr::parse(AsmParser &parser, Type type) {\n   SmallVector<unsigned> CTASplitNum;\n   SmallVector<unsigned> CTAOrder;\n   SmallVector<unsigned> instrShape;\n+  bool isInt8Input = false;\n \n   for (const NamedAttribute &attr : dict) {\n     if (attr.getName() == \"versionMajor\") {\n@@ -1073,10 +1080,9 @@ Attribute MmaEncodingAttr::parse(AsmParser &parser, Type type) {\n       if (parseIntArrayAttr(parser, attr, CTAOrder, \"CTAOrder\").failed())\n         return {};\n     }\n-    if (attr.getName() == \"instrShape\") {\n-      if (parseIntArrayAttr(parser, attr, instrShape, \"instrShape\").failed()) {\n+    if (attr.getName() == \"isInt8Input\") {\n+      if (parseBool(parser, attr, isInt8Input, \"isInt8Input\").failed())\n         return {};\n-      }\n     }\n   }\n \n@@ -1085,7 +1091,7 @@ Attribute MmaEncodingAttr::parse(AsmParser &parser, Type type) {\n \n   return parser.getChecked<MmaEncodingAttr>(parser.getContext(), versionMajor,\n                                             versionMinor, warpsPerCTA,\n-                                            CTALayout, instrShape);\n+                                            CTALayout, isInt8Input);\n }\n \n void MmaEncodingAttr::print(AsmPrinter &printer) const {\n@@ -1096,8 +1102,7 @@ void MmaEncodingAttr::print(AsmPrinter &printer) const {\n           << \"CTAsPerCGA = [\" << getCTALayout().getCTAsPerCGA() << \"], \"\n           << \"CTASplitNum = [\" << getCTALayout().getCTASplitNum() << \"], \"\n           << \"CTAOrder = [\" << getCTALayout().getCTAOrder() << \"], \"\n-          << \"instrShape = [\" << getInstrShape() << \"]\"\n-          << \"}>\";\n+          << \"isInt8Input = \" << getIsInt8Input() << \"}>\";\n }\n \n //===----------------------------------------------------------------------===//"}, {"filename": "lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -239,15 +239,15 @@ class BlockedToMMA : public mlir::RewritePattern {\n \n       mmaEnc = ttg::MmaEncodingAttr::get(\n           oldRetType.getContext(), versionMajor, numWarps, CTALayout,\n-          instrShape, oldAType.getShape(), oldBType.getShape(), retShapePerCTA,\n-          isARow, isBRow, mmaV1Counter++);\n+          oldAType.getShape(), oldBType.getShape(), retShapePerCTA, isARow,\n+          isBRow, mmaV1Counter++);\n     } else if (versionMajor == 2 || versionMajor == 3) {\n       int versionMinor = computeCapability == 75 ? 1 : 0;\n       auto warpsPerTile = getWarpsPerTile(dotOp, retShapePerCTA, versionMajor,\n                                           numWarps, instrShape);\n       mmaEnc = ttg::MmaEncodingAttr::get(oldRetType.getContext(), versionMajor,\n-                                         versionMinor, warpsPerTile,\n-                                         CTALayout, instrShape);\n+                                         versionMinor, warpsPerTile, CTALayout,\n+                                         AType.getElementType().isInteger(8));\n     }\n     auto newRetType = RankedTensorType::get(\n         oldRetType.getShape(), oldRetType.getElementType(), mmaEnc);"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Utility.cpp", "status": "modified", "additions": 74, "deletions": 30, "changes": 104, "file_content_changes": "@@ -9,47 +9,91 @@\n \n namespace mlir {\n \n-SmallVector<unsigned, 3> mmaVersionToInstrShape(int version,\n-                                                const ArrayRef<int64_t> &shape,\n-                                                RankedTensorType type) {\n+static unsigned getValidNOfMmaV3(const int64_t N, Type eltType) {\n+  SmallVector<unsigned> validN;\n+\n+  // MMAv3 with larger instruction shape is preferred.\n+  if (eltType.isFloat8E5M2() || eltType.isFloat8E4M3FNUZ() || eltType.isF16() ||\n+      eltType.isBF16() || eltType.isF32()) {\n+    validN.assign({256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176,\n+                   168, 160, 152, 144, 136, 128, 120, 112, 104, 96,  88,\n+                   80,  72,  64,  56,  48,  40,  32,  24,  16,  8});\n+  }\n+\n+  if (eltType.isInteger(8)) {\n+    validN.assign({224, 208, 192, 176, 160, 144, 128, 112, 96, 80, 64, 48, 32,\n+                   24, 16, 8});\n+  }\n+\n+  for (auto n : validN) {\n+    if (N % n == 0) {\n+      return n;\n+    }\n+  }\n+  return 0;\n+}\n+\n+static SmallVector<unsigned, 3>\n+mmaVersionToInstrShapeImpl(int version, const ArrayRef<int64_t> &shape,\n+                           Type eltType) {\n   if (version == 1)\n     return {16, 16};\n   else if (version == 2)\n     return {16, 8};\n   else if (version == 3) {\n-    unsigned k = 256 / type.getElementTypeBitWidth();\n+    unsigned k = 256 / eltType.getIntOrFloatBitWidth();\n+    unsigned n = getValidNOfMmaV3(shape[1], eltType);\n+    return {16, n, k};\n+  } else {\n+    assert(false && \"version not supported\");\n+    return {0, 0};\n+  }\n+}\n+\n+SmallVector<unsigned, 3> mmaVersionToInstrShape(int version,\n+                                                const ArrayRef<int64_t> &shape,\n+                                                RankedTensorType type) {\n+  auto instrShape =\n+      mmaVersionToInstrShapeImpl(version, shape, type.getElementType());\n+  if (version == 3) {\n     if (shape[0] % 64 != 0 || shape[1] % 8 != 0) {\n       assert(false && \"type not supported\");\n       return {0, 0, 0};\n     }\n-    auto eltType = type.getElementType();\n-    SmallVector<unsigned> validN;\n-\n-    // MMAv3 with larger instruction shape is preferred.\n-    if (eltType.isFloat8E5M2() || eltType.isFloat8E4M3FNUZ() ||\n-        eltType.isF16() || eltType.isBF16() || eltType.isF32()) {\n-      validN.assign({256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176,\n-                     168, 160, 152, 144, 136, 128, 120, 112, 104, 96,  88,\n-                     80,  72,  64,  56,  48,  40,  32,  24,  16,  8});\n-    }\n-\n-    if (eltType.isInteger(8)) {\n-      validN.assign({224, 208, 192, 176, 160, 144, 128, 112, 96, 80, 64, 48, 32,\n-                     24, 16, 8});\n-    }\n-\n-    for (auto n : validN) {\n-      if (shape[1] % n == 0) {\n-        return {16, n, k};\n-      }\n-    }\n-\n-    assert(false && \"type not supported\");\n-    return {0, 0, 0};\n+  }\n+  assert(instrShape[1] > 0 && \"type not supported\");\n+  return instrShape;\n+}\n+\n+SmallVector<unsigned, 3>\n+mmaVersionToInstrShape(triton::gpu::MmaEncodingAttr mma,\n+                       const ArrayRef<int64_t> shapePerCTA) {\n+  Type eltType;\n+  auto ctx = mma.getContext();\n+  OpBuilder builder(ctx);\n+  if (mma.getIsInt8Input())\n+    eltType = builder.getIntegerType(8);\n+  else\n+    eltType = builder.getF16Type();\n+  return mmaVersionToInstrShapeImpl(\n+      mma.getVersionMajor(), shapePerCTA,\n+      RankedTensorType::get({1, 1}, eltType, mma));\n+}\n+SmallVector<unsigned, 3>\n+mmaVersionToInstrShape(triton::gpu::MmaEncodingAttr mma, unsigned opIdx,\n+                       RankedTensorType type) {\n+  auto shapePerCTA =\n+      triton::gpu::getShapePerCTA(type.getEncoding(), type.getShape());\n+  auto instrShape = mmaVersionToInstrShapeImpl(\n+      mma.getVersionMajor(), shapePerCTA, type.getElementType());\n+  if (opIdx == 0) {\n+    instrShape[1] = 0;\n+    assert(shapePerCTA[0] % 64 == 0 && \"M direction not compatible\");\n   } else {\n-    assert(false && \"version not supported\");\n-    return {0, 0};\n+    instrShape[0] = 0;\n+    assert(shapePerCTA[1] % 8 == 0 && \"N direction not compatible\");\n   }\n+  return instrShape;\n }\n \n bool isLoadFromTensorPtr(triton::LoadOp op) {"}, {"filename": "lib/Dialect/TritonNvidiaGPU/Transforms/PlanCTA.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -301,7 +301,8 @@ bool CTAPlanner::processReduce(triton::FuncOp &funcOp) {\n \n     auto rank = srcShape.size();\n     auto order = ttg::getOrder(srcLayout);\n-    auto sizePerThread = ttg::getSizePerThread(srcLayout);\n+    auto sizePerThread =\n+        ttg::getSizePerThread(srcLayout, ttg::getShapePerCTA(srcTy));\n     auto CTAOrder = ttg::getCTAOrder(srcLayout);\n \n     llvm::SmallVector<unsigned> CTAsPerCGA(rank, 0);"}, {"filename": "unittest/Conversion/TritonGPUToLLVM/EmitIndicesTest.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -122,7 +122,7 @@ class EmitIndicesTest : public ::testing::Test {\n                        const std::string &refStr) {\n     auto layout =\n         MmaEncodingAttr::get(&context, versionMajor, versionMinor, warpsPerCTA,\n-                             getSingleCTALayout2d(), instrShape);\n+                             getSingleCTALayout2d(), false);\n     runDistributed2d(row, col, layout, /*multiCTA=*/false, refStr);\n   }\n \n@@ -133,7 +133,7 @@ class EmitIndicesTest : public ::testing::Test {\n                          const std::string &refStr) {\n     auto parent =\n         MmaEncodingAttr::get(&context, versionMajor, versionMinor, warpsPerCTA,\n-                             getSingleCTALayout2d(), instrShape);\n+                             getSingleCTALayout2d(), false);\n     auto layout = DotOperandEncodingAttr::get(&context, opIdx, parent, 0);\n     runDistributed2d(row, col, layout, /*multiCTA=*/false, refStr);\n   }\n@@ -638,7 +638,7 @@ TEST_F(EmitIndicesTest, LayoutVisualizer_Mma) {\n \n   Attribute mmaLayout = MmaEncodingAttr::get(\n       /*context=*/&context, /*versionMajor=*/2, /*versionMinor=*/1,\n-      /*warpsPerCTA=*/{1, 1}, /*CTALayout=*/CTALayout, /*instrShape=*/{16, 8});\n+      /*warpsPerCTA=*/{1, 1}, /*CTALayout=*/CTALayout, false);\n \n   llvm::SmallVector<int64_t> shape = {/*row=*/16, /*col=*/8};\n "}, {"filename": "unittest/Dialect/TritonGPU/SwizzleTest.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -32,8 +32,8 @@ TEST_P(SwizzleDotOperandTestFixture, DotOperands) {\n       triton::gpu::CTALayoutAttr::get(&ctx, {1, 1}, {1, 1}, {0, 1});\n \n   // create encoding\n-  auto parent = triton::gpu::MmaEncodingAttr::get(&ctx, 2, 0, {1, 1}, CTALayout,\n-                                                  {16, 64, 16});\n+  auto parent =\n+      triton::gpu::MmaEncodingAttr::get(&ctx, 2, 0, {1, 1}, CTALayout, false);\n   auto encoding = triton::gpu::DotOperandEncodingAttr::get(\n       &ctx, params.opIdx, parent, 32 / params.typeWidth);\n "}]