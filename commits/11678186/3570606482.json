[{"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "file_content_changes": "@@ -58,11 +58,6 @@ SmallVector<SmallVector<unsigned>> ReduceOpHelper::getScratchConfigsFast() {\n   unsigned numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n   smemShapes[1].push_back(numWarps * 32);\n \n-  /// FIXME(Qingyi): This requirement is actually not necessary, because it is\n-  /// always smaller than smemShapes[0] shared memory block2\n-  smemShapes[2] = convertType<unsigned>(getSrcShape());\n-  smemShapes[2].erase(smemShapes[2].begin() + axis);\n-\n   return smemShapes;\n }\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 14, "deletions": 62, "changes": 76, "file_content_changes": "@@ -43,6 +43,8 @@ using ::mlir::LLVM::getStridesFromShapeAndOrder;\n using ::mlir::LLVM::getStructFromElements;\n using ::mlir::LLVM::MMA16816ConversionHelper;\n using ::mlir::LLVM::SharedMemoryObject;\n+using ::mlir::LLVM::shflSync;\n+using ::mlir::LLVM::storeShared;\n using ::mlir::triton::gpu::BlockedEncodingAttr;\n using ::mlir::triton::gpu::DotOperandEncodingAttr;\n using ::mlir::triton::gpu::getElemsPerThread;\n@@ -307,20 +309,6 @@ T getLinearIndex(ArrayRef<T> multiDimIndex, ArrayRef<T> shape,\n                                reorder(shape, order));\n }\n \n-Value storeShared(ConversionPatternRewriter &rewriter, Location loc, Value ptr,\n-                  Value val, Value pred) {\n-  MLIRContext *ctx = rewriter.getContext();\n-  unsigned bits = val.getType().getIntOrFloatBitWidth();\n-  const char *c = bits == 64 ? \"l\" : (bits == 16 ? \"h\" : \"r\");\n-\n-  PTXBuilder builder;\n-  auto *ptrOpr = builder.newAddrOperand(ptr, \"r\");\n-  auto *valOpr = builder.newOperand(val, c);\n-  auto &st = builder.create<>(\"st\")->shared().b(bits);\n-  st(ptrOpr, valOpr).predicate(pred, \"b\");\n-  return builder.launch(rewriter, loc, void_ty(ctx));\n-}\n-\n struct ConvertTritonGPUOpToLLVMPatternBase {\n   static Value\n   getStructFromSharedMemoryObject(Location loc,\n@@ -1342,9 +1330,6 @@ struct ReduceOpConversion\n                            RedOp redOp, Value &acc, Value &accIndex, Value cur,\n                            Value curIndex, bool isFirst) const;\n \n-  Value shflSync(ConversionPatternRewriter &rewriter, Location loc, Value val,\n-                 int i) const;\n-\n   // Use shared memory for reduction within warps and across warps\n   LogicalResult matchAndRewriteBasic(triton::ReduceOp op, OpAdaptor adaptor,\n                                      ConversionPatternRewriter &rewriter) const;\n@@ -1472,34 +1457,6 @@ void ReduceOpConversion::accumulateWithIndex(\n   }\n }\n \n-Value ReduceOpConversion::shflSync(ConversionPatternRewriter &rewriter,\n-                                   Location loc, Value val, int i) const {\n-  unsigned bits = val.getType().getIntOrFloatBitWidth();\n-\n-  if (bits == 64) {\n-    Type vecTy = vec_ty(f32_ty, 2);\n-    Value vec = bitcast(val, vecTy);\n-    Value val0 = extract_element(f32_ty, vec, i32_val(0));\n-    Value val1 = extract_element(f32_ty, vec, i32_val(1));\n-    val0 = shflSync(rewriter, loc, val0, i);\n-    val1 = shflSync(rewriter, loc, val1, i);\n-    vec = undef(vecTy);\n-    vec = insert_element(vecTy, vec, val0, i32_val(0));\n-    vec = insert_element(vecTy, vec, val1, i32_val(1));\n-    return bitcast(vec, val.getType());\n-  }\n-\n-  PTXBuilder builder;\n-  auto &shfl = builder.create(\"shfl.sync\")->o(\"bfly\").o(\"b32\");\n-  auto *dOpr = builder.newOperand(\"=r\");\n-  auto *aOpr = builder.newOperand(val, \"r\");\n-  auto *bOpr = builder.newConstantOperand(i);\n-  auto *cOpr = builder.newConstantOperand(\"0x1f\");\n-  auto *maskOpr = builder.newConstantOperand(\"0xffffffff\");\n-  shfl(dOpr, aOpr, bOpr, cOpr, maskOpr);\n-  return builder.launch(rewriter, loc, val.getType(), false);\n-}\n-\n LogicalResult ReduceOpConversion::matchAndRewriteBasic(\n     triton::ReduceOp op, OpAdaptor adaptor,\n     ConversionPatternRewriter &rewriter) const {\n@@ -1665,7 +1622,6 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n   auto smemShapes = helper.getScratchConfigsFast();\n   unsigned elems = product<unsigned>(smemShapes[0]);\n   unsigned maxElems = std::max(elems, product<unsigned>(smemShapes[1]));\n-  maxElems = std::max(maxElems, product<unsigned>(smemShapes[2]));\n   Value indexSmemBase = gep(elemPtrTy, smemBase, i32_val(maxElems));\n   indexSmemBase = bitcast(indexSmemBase, indexPtrTy);\n \n@@ -1725,11 +1681,11 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n \n     // reduce within warps\n     for (unsigned N = sizeIntraWarps / 2; N > 0; N >>= 1) {\n-      Value shfl = shflSync(rewriter, loc, acc, N);\n+      Value shfl = shflSync(loc, rewriter, acc, N);\n       if (!withIndex) {\n         accumulate(rewriter, loc, op.redOp(), acc, shfl, false);\n       } else {\n-        Value shflIndex = shflSync(rewriter, loc, accIndex, N);\n+        Value shflIndex = shflSync(loc, rewriter, accIndex, N);\n         accumulateWithIndex(rewriter, loc, op.redOp(), acc, accIndex, shfl,\n                             shflIndex, false);\n       }\n@@ -1750,8 +1706,7 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n   barrier();\n \n   // the second round of shuffle reduction\n-  //   now the problem size: sizeInterWarps, s1, s2, .. , sn  =>\n-  //                                      1, s1, s2, .. , sn\n+  //   now the problem size: sizeInterWarps, s1, s2, .. , sn\n   //   where sizeInterWarps is 2^m\n   //\n   // each thread needs to process:\n@@ -1762,6 +1717,7 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n   Value readOffset = threadId;\n   for (unsigned round = 0; round < elemsPerThread; ++round) {\n     Value readPtr = gep(elemPtrTy, smemBase, readOffset);\n+    // FIXME(Qingyi): need predicate icmp_slt(threadId, i32_val(sizeInerWarps))\n     Value acc = load(readPtr);\n     Value accIndex;\n     if (withIndex) {\n@@ -1770,17 +1726,18 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n     }\n \n     for (unsigned N = sizeInterWarps / 2; N > 0; N >>= 1) {\n-      Value shfl = shflSync(rewriter, loc, acc, N);\n+      Value shfl = shflSync(loc, rewriter, acc, N);\n       if (!withIndex) {\n         accumulate(rewriter, loc, op.redOp(), acc, shfl, false);\n       } else {\n-        Value shflIndex = shflSync(rewriter, loc, accIndex, N);\n+        Value shflIndex = shflSync(loc, rewriter, accIndex, N);\n         accumulateWithIndex(rewriter, loc, op.redOp(), acc, accIndex, shfl,\n                             shflIndex, false);\n       }\n     }\n \n-    Value writeOffset = udiv(readOffset, i32_val(sizeInterWarps));\n+    // only the first thread in each sizeInterWarps is writing\n+    Value writeOffset = readOffset;\n     Value writePtr = gep(elemPtrTy, smemBase, writeOffset);\n     Value threadIsNeeded = icmp_slt(threadId, i32_val(elems));\n     Value laneIdModSizeInterWarps = urem(laneId, i32_val(sizeInterWarps));\n@@ -1807,22 +1764,17 @@ LogicalResult ReduceOpConversion::matchAndRewriteFast(\n   if (auto resultTy = op.getType().dyn_cast<RankedTensorType>()) {\n     // nd-tensor where n >= 1\n     auto resultLayout = resultTy.getEncoding().cast<SliceEncodingAttr>();\n-    SmallVector<unsigned> resultOrd;\n-    for (auto ord : order) {\n-      if (ord != 0)\n-        resultOrd.push_back(ord - 1);\n-    }\n-\n+    auto resultShape = resultTy.getShape();\n     unsigned resultElems = getElemsPerThread(resultTy);\n-    auto resultIndices =\n-        emitIndices(loc, rewriter, resultLayout, resultTy.getShape());\n+    auto resultIndices = emitIndices(loc, rewriter, resultLayout, resultShape);\n     assert(resultIndices.size() == resultElems);\n \n     SmallVector<Value> resultVals(resultElems);\n     for (size_t i = 0; i < resultElems; ++i) {\n       SmallVector<Value> readIdx = resultIndices[i];\n+      readIdx.insert(readIdx.begin() + axis, i32_val(0));\n       Value readOffset =\n-          linearize(rewriter, loc, readIdx, smemShapes[2], resultOrd);\n+          linearize(rewriter, loc, readIdx, smemShapes[0], order);\n       Value readPtr = gep(elemPtrTy, smemBase, readOffset);\n       Value indexReadPtr = gep(indexPtrTy, indexSmemBase, readOffset);\n       resultVals[i] = withIndex ? load(indexReadPtr) : load(readPtr);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/Utility.h", "status": "modified", "additions": 42, "deletions": 0, "changes": 42, "file_content_changes": "@@ -269,6 +269,48 @@ getSharedMemoryObjectFromStruct(Location loc, Value llvmStruct,\n           /*offsets=*/{elems.begin() + 1 + rank, elems.end()}};\n }\n \n+Value storeShared(ConversionPatternRewriter &rewriter, Location loc, Value ptr,\n+                  Value val, Value pred) {\n+  MLIRContext *ctx = rewriter.getContext();\n+  unsigned bits = val.getType().getIntOrFloatBitWidth();\n+  const char *c = bits == 64 ? \"l\" : (bits == 16 ? \"h\" : \"r\");\n+\n+  PTXBuilder builder;\n+  auto *ptrOpr = builder.newAddrOperand(ptr, \"r\");\n+  auto *valOpr = builder.newOperand(val, c);\n+  auto &st = builder.create<>(\"st\")->shared().b(bits);\n+  st(ptrOpr, valOpr).predicate(pred, \"b\");\n+  return builder.launch(rewriter, loc, void_ty(ctx));\n+}\n+\n+Value shflSync(Location loc, ConversionPatternRewriter &rewriter, Value val,\n+               int i) {\n+  unsigned bits = val.getType().getIntOrFloatBitWidth();\n+\n+  if (bits == 64) {\n+    Type vecTy = vec_ty(f32_ty, 2);\n+    Value vec = bitcast(val, vecTy);\n+    Value val0 = extract_element(f32_ty, vec, i32_val(0));\n+    Value val1 = extract_element(f32_ty, vec, i32_val(1));\n+    val0 = shflSync(loc, rewriter, val0, i);\n+    val1 = shflSync(loc, rewriter, val1, i);\n+    vec = undef(vecTy);\n+    vec = insert_element(vecTy, vec, val0, i32_val(0));\n+    vec = insert_element(vecTy, vec, val1, i32_val(1));\n+    return bitcast(vec, val.getType());\n+  }\n+\n+  PTXBuilder builder;\n+  auto &shfl = builder.create(\"shfl.sync\")->o(\"bfly\").o(\"b32\");\n+  auto *dOpr = builder.newOperand(\"=r\");\n+  auto *aOpr = builder.newOperand(val, \"r\");\n+  auto *bOpr = builder.newConstantOperand(i);\n+  auto *cOpr = builder.newConstantOperand(\"0x1f\");\n+  auto *maskOpr = builder.newConstantOperand(\"0xffffffff\");\n+  shfl(dOpr, aOpr, bOpr, cOpr, maskOpr);\n+  return builder.launch(rewriter, loc, val.getType(), false);\n+}\n+\n } // namespace LLVM\n } // namespace mlir\n "}]