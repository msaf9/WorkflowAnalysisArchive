[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 14, "deletions": 4, "changes": 18, "file_content_changes": "@@ -3667,7 +3667,7 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n \n     // Here we assume the DotOp's operands always comes from shared memory.\n     auto AShape = A.getType().cast<RankedTensorType>().getShape();\n-    size_t reduceAxis = 1;\n+    size_t reduceAxis = op.transA() ? 0 : 1;\n     unsigned K = AShape[reduceAxis];\n     bool isOuter = K == 1;\n \n@@ -4247,8 +4247,10 @@ struct MMA16816ConversionHelper {\n   // Loading $a from smem to registers, returns a LLVM::Struct.\n   Value loadA(Value tensor, const SharedMemoryObject &smemObj) const {\n     auto aTensorTy = tensor.getType().cast<RankedTensorType>();\n-    auto shape = aTensorTy.getShape();\n+    auto layout = aTensorTy.getEncoding().cast<SharedEncodingAttr>();\n \n+    SmallVector<int64_t> shape(aTensorTy.getShape().begin(),\n+                               aTensorTy.getShape().end());\n     ValueTable ha;\n     std::function<void(int, int)> loadFn;\n     auto [matShapeM, matShapeN, matShapeK] = getMmaMatShape(aTensorTy);\n@@ -4286,7 +4288,11 @@ struct MMA16816ConversionHelper {\n   Value loadB(Value tensor, const SharedMemoryObject &smemObj) {\n     ValueTable hb;\n     auto tensorTy = tensor.getType().cast<RankedTensorType>();\n-    auto shape = tensorTy.getShape();\n+    auto layout = tensorTy.getEncoding().cast<SharedEncodingAttr>();\n+\n+    SmallVector<int64_t> shape(tensorTy.getShape().begin(),\n+                               tensorTy.getShape().end());\n+\n     auto [matShapeM, matShapeN, matShapeK] = getMmaMatShape(tensorTy);\n     auto [mmaInstrM, mmaInstrN, mmaInstrK] = getMmaInstrShape(tensorTy);\n     int numRepK = getNumRepK(tensorTy, shape[0]);\n@@ -4338,7 +4344,11 @@ struct MMA16816ConversionHelper {\n     auto aTensorTy = a.getType().cast<RankedTensorType>();\n     auto dTensorTy = d.getType().cast<RankedTensorType>();\n \n-    auto aShape = aTensorTy.getShape();\n+    SmallVector<int64_t> aShape(aTensorTy.getShape().begin(),\n+                                aTensorTy.getShape().end());\n+    if (op.transA())\n+      std::swap(aShape[0], aShape[1]);\n+\n     auto dShape = dTensorTy.getShape();\n \n     // shape / shape_per_cta"}]