[{"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 27, "deletions": 28, "changes": 55, "file_content_changes": "@@ -789,13 +789,26 @@ class BlockedToMMA : public mlir::RewritePattern {\n     if (oldRetType.getEncoding().isa<triton::gpu::MmaEncodingAttr>())\n       return failure();\n \n-    auto A = dotOp.getOperand(0).getType().cast<RankedTensorType>();\n-    auto B = dotOp.getOperand(1).getType().cast<RankedTensorType>();\n+    Value oldA = dotOp.a();\n+    Value oldB = dotOp.b();\n+    auto oldAType = oldA.getType().cast<RankedTensorType>();\n+    auto oldBType = oldB.getType().cast<RankedTensorType>();\n     // for FMA, should retain the blocked layout.\n-    if (A.getElementType().isF32() && B.getElementType().isF32() &&\n-        !dotOp.allowTF32())\n+    if (oldAType.getElementType().isF32() &&\n+        oldBType.getElementType().isF32() && !dotOp.allowTF32())\n       return failure();\n \n+    auto oldAOrder = oldAType.getEncoding()\n+                         .cast<triton::gpu::DotOperandEncodingAttr>()\n+                         .getParent()\n+                         .cast<triton::gpu::BlockedEncodingAttr>()\n+                         .getOrder();\n+    auto oldBOrder = oldBType.getEncoding()\n+                         .cast<triton::gpu::DotOperandEncodingAttr>()\n+                         .getParent()\n+                         .cast<triton::gpu::BlockedEncodingAttr>()\n+                         .getOrder();\n+\n     // get MMA encoding for the given number of warps\n     auto retShape = oldRetType.getShape();\n     auto mod = op->getParentOfType<mlir::ModuleOp>();\n@@ -805,12 +818,10 @@ class BlockedToMMA : public mlir::RewritePattern {\n         getWarpsPerTile(dotOp, retShape, versionMajor, numWarps);\n     triton::gpu::MmaEncodingAttr mmaEnc;\n     if (versionMajor == 1) {\n-      auto shapeA = A.getShape();\n-      auto shapeB = B.getShape();\n-      auto ADotOp = A.getEncoding().cast<triton::gpu::DotOperandEncodingAttr>();\n-      auto BDotOp = B.getEncoding().cast<triton::gpu::DotOperandEncodingAttr>();\n-      bool isARow = ADotOp.getIsMMAv1Row().cast<BoolAttr>().getValue();\n-      bool isBRow = BDotOp.getIsMMAv1Row().cast<BoolAttr>().getValue();\n+      auto shapeA = oldAType.getShape();\n+      auto shapeB = oldBType.getShape();\n+      bool isARow = oldAOrder[0] != 0;\n+      bool isBRow = oldBOrder[0] != 0;\n       mmaEnc = triton::gpu::MmaEncodingAttr::get(\n           oldRetType.getContext(), versionMajor, warpsPerTile, shapeA, shapeB,\n           isARow, isBRow);\n@@ -828,20 +839,6 @@ class BlockedToMMA : public mlir::RewritePattern {\n     auto oldAcc = dotOp.getOperand(2);\n     auto newAcc = rewriter.create<triton::gpu::ConvertLayoutOp>(\n         oldAcc.getLoc(), newRetType, oldAcc);\n-    Value a = dotOp.a();\n-    Value b = dotOp.b();\n-    auto oldAType = a.getType().cast<RankedTensorType>();\n-    auto oldBType = b.getType().cast<RankedTensorType>();\n-    auto oldAOrder = oldAType.getEncoding()\n-                         .cast<triton::gpu::DotOperandEncodingAttr>()\n-                         .getParent()\n-                         .cast<triton::gpu::BlockedEncodingAttr>()\n-                         .getOrder();\n-    auto oldBOrder = oldBType.getEncoding()\n-                         .cast<triton::gpu::DotOperandEncodingAttr>()\n-                         .getParent()\n-                         .cast<triton::gpu::BlockedEncodingAttr>()\n-                         .getOrder();\n     Attribute isMMAv1RowA;\n     Attribute isMMAv1RowB;\n     if (versionMajor == 1) {\n@@ -858,10 +855,12 @@ class BlockedToMMA : public mlir::RewritePattern {\n         triton::gpu::DotOperandEncodingAttr::get(\n             oldBType.getContext(), 1, newRetType.getEncoding(), isMMAv1RowB));\n \n-    a = rewriter.create<triton::gpu::ConvertLayoutOp>(a.getLoc(), newAType, a);\n-    b = rewriter.create<triton::gpu::ConvertLayoutOp>(b.getLoc(), newBType, b);\n-    auto newDot = rewriter.create<triton::DotOp>(dotOp.getLoc(), newRetType, a,\n-                                                 b, newAcc, dotOp.allowTF32());\n+    Value newA = rewriter.create<triton::gpu::ConvertLayoutOp>(oldA.getLoc(),\n+                                                               newAType, oldA);\n+    Value newB = rewriter.create<triton::gpu::ConvertLayoutOp>(oldB.getLoc(),\n+                                                               newBType, oldB);\n+    auto newDot = rewriter.create<triton::DotOp>(\n+        dotOp.getLoc(), newRetType, newA, newB, newAcc, dotOp.allowTF32());\n \n     rewriter.replaceOpWithNewOp<triton::gpu::ConvertLayoutOp>(\n         op, oldRetType, newDot.getResult());"}, {"filename": "python/tests/test_backend.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -28,9 +28,9 @@ def __str__(self):\n \n \n layouts = [\n-    # MmaLayout(version=1, warps_per_cta=[1, 4]),\n+    # MmaLayout(version_major=1, warps_per_cta=[1, 4]),\n     MmaLayout(version_major=2, warps_per_cta=[1, 4]),\n-    # MmaLayout(version=1, warps_per_cta=[4, 1]),\n+    # MmaLayout(version_major=1, warps_per_cta=[4, 1]),\n     MmaLayout(version_major=2, warps_per_cta=[4, 1]),\n     BlockedLayout([1, 8], [2, 16], [4, 1], [1, 0]),\n     BlockedLayout([1, 4], [4, 8], [2, 2], [1, 0]),"}]