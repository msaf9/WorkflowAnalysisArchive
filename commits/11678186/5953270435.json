[{"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandFMA.cpp", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -128,7 +128,8 @@ Value loadAFMA(Value A, Value llA, BlockedEncodingAttr dLayout, Value thread,\n   for (int i = 0; i < aNumPtr; ++i) {\n     aOff[i] = add(mul(offA0, strideA0), mul(offA1, strideA1));\n   }\n-  auto elemTy = A.getType().cast<RankedTensorType>().getElementType();\n+  auto elemTy = typeConverter->convertType(\n+      A.getType().cast<RankedTensorType>().getElementType());\n \n   Type ptrTy = ptr_ty(elemTy, 3);\n   SmallVector<Value> aPtrs(aNumPtr);\n@@ -192,7 +193,8 @@ Value loadBFMA(Value B, Value llB, BlockedEncodingAttr dLayout, Value thread,\n   for (int i = 0; i < bNumPtr; ++i) {\n     bOff[i] = add(mul(offB0, strideB0), mul(offB1, strideB1));\n   }\n-  auto elemTy = B.getType().cast<RankedTensorType>().getElementType();\n+  auto elemTy = typeConverter->convertType(\n+      B.getType().cast<RankedTensorType>().getElementType());\n \n   Type ptrTy = ptr_ty(elemTy, 3);\n   SmallVector<Value> bPtrs(bNumPtr);"}]