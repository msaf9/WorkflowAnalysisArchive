[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -973,8 +973,10 @@ struct LoadOpConversion\n \n       if (other) {\n         for (size_t ii = 0; ii < nWords; ++ii) {\n+          // PTX doesn't support mov.u8, so we need to use mov.u16\n+          auto movWidth = width < 16 ? 16 : width;\n           PTXInstr &mov =\n-              ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(width));\n+              ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(movWidth));\n \n           size_t size = width / valueElemNbits;\n "}, {"filename": "python/tests/test_core.py", "status": "modified", "additions": 36, "deletions": 3, "changes": 39, "file_content_changes": "@@ -20,6 +20,7 @@\n dtypes = int_dtypes + uint_dtypes + float_dtypes\n # TODO: handle bfloat16\n dtypes_with_bfloat16 = dtypes  # + ['bfloat16']\n+torch_dtypes = ['bool'] + int_dtypes + ['uint8'] + float_dtypes  # + ['bfloat16']\n \n \n def _bitwidth(dtype: str) -> int:\n@@ -1233,9 +1234,41 @@ def _kernel(z, BLOCK: tl.constexpr,\n     z_ref = torch.arange(start, BLOCK + start, dtype=torch.int32, device=device)\n     triton.testing.assert_almost_equal(z_tri, z_ref)\n \n-# # ---------------\n-# # test load\n-# # ---------------\n+# ---------------\n+# test load\n+# ---------------\n+\n+\n+@pytest.mark.parametrize(\"dtype_str, size, size_diff\", [(dtype_str, size, size_diff) for dtype_str in torch_dtypes for size in [128, 512] for size_diff in [1, 2, 3, 4]])\n+def test_masked_load(dtype_str, size, size_diff, device='cuda'):\n+    dtype = getattr(torch, dtype_str)\n+    check_type_supported(dtype)  # bfloat16 on cc < 80 will not be tested\n+\n+    input_size = size - size_diff\n+    output_size = size\n+    if dtype_str == 'bool':\n+        input = torch.randint(0, 2, (input_size,), dtype=dtype, device=device)\n+    elif dtype_str in int_dtypes or dtype_str in uint_dtypes:\n+        input = torch.randint(0, 127, (input_size,), dtype=dtype, device=device)\n+    else:\n+        input = torch.rand(input_size, dtype=dtype, device=device)\n+    output = torch.zeros((output_size,), dtype=dtype, device=device)\n+\n+    @triton.jit\n+    def _kernel(in_ptr, out_ptr, in_size: tl.constexpr, out_size: tl.constexpr):\n+        in_offsets = tl.arange(0, out_size)\n+        # Load inputs.\n+        x = tl.load(in_ptr + in_offsets, mask=in_offsets < in_size, other=1)\n+        # Store output\n+        output_offsets = tl.arange(0, out_size)\n+        tl.store(out_ptr + output_offsets, x)\n+\n+    _kernel[(1,)](input, output, input_size, output_size)\n+\n+    reference_out = input\n+    reference_out = torch.cat((reference_out, torch.ones((size_diff,), dtype=dtype, device=device)))\n+    triton.testing.allclose(output, reference_out)\n+\n # # 'bfloat16': torch.bfloat16,\n # # Testing masked loads with an intermate copy to shared memory run.\n "}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -738,16 +738,18 @@ def load(ptr: tl.tensor,\n         if other:\n             other = broadcast_impl_shape(other, ptr.type.get_block_shapes(), builder)\n \n-    if other:\n-        other = cast(other, ptr.type.scalar.element_ty, builder)\n     ptr_ty = ptr.type.scalar\n     elt_ty = ptr_ty.element_ty\n+\n     # treat bool* as tl.int8*\n     if elt_ty == tl.int1:\n         elt_ty = tl.int8\n         ptr_ty = tl.pointer_type(elt_ty, ptr_ty.address_space)\n         ptr = cast(ptr, ptr_ty, builder)\n \n+    if other:\n+        other = cast(other, elt_ty, builder)\n+\n     # cache modifier\n     cache = ir.CACHE_MODIFIER.NONE  # default\n     if cache_modifier:"}]