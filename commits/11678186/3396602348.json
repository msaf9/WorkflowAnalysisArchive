[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 61, "deletions": 54, "changes": 115, "file_content_changes": "@@ -2481,8 +2481,14 @@ class MMA16816SmemLoader {\n     cMatShape = matShape[order[0]];\n     sMatShape = matShape[order[1]];\n \n-    cTileStride = smemStrides[order[0]];\n-    sTileStride = smemStrides[order[1]];\n+    // TODO(Keren): this is a temporary hack to make sure the strides are\n+    // integers so that we can get rid of performance issues caused by the use\n+    // of constant Value.\n+    // We'll have to fix this later when integrating the prefetch branch.\n+    // cTileStride = smemStrides[order[0]];\n+    // sTileStride = smemStrides[order[1]];\n+    cTileStride = tileShape[order[1]];\n+    sTileStride = tileShape[order[0]];\n \n     // rule: k must be the fast-changing axis.\n     needTrans = kOrder != order[0];\n@@ -2585,7 +2591,8 @@ class MMA16816SmemLoader {\n     for (int i = 0; i < numPtr; ++i) {\n       Value cMatOffI = add(cMatOff, i32_val(i * pLoadStrideInMat));\n       cMatOffI = xor_(cMatOffI, phase);\n-      offs[i] = add(mul(cMatOffI, i32_val(cMatShape)), mul(sOff, sTileStride));\n+      offs[i] = add(mul(cMatOffI, i32_val(cMatShape)),\n+                    mul(sOff, i32_val(sTileStride)));\n     }\n \n     return offs;\n@@ -2621,7 +2628,7 @@ class MMA16816SmemLoader {\n         Value cOff = add(cOffInMat, mul(cMatOffI, i32_val(cMatShape)));\n         cOff = urem(cOff, i32_val(tileShape[order[0]]));\n         sOff = urem(sOff, i32_val(tileShape[order[1]]));\n-        offs[2 * i + nkMatArrInt] = add(cOff, mul(sOff, sTileStride));\n+        offs[2 * i + nkMatArrInt] = add(cOff, mul(sOff, i32_val(sTileStride)));\n       }\n     }\n     return offs;\n@@ -2661,7 +2668,7 @@ class MMA16816SmemLoader {\n           // To prevent out-of-bound access when tile is too small.\n           cOff = urem(cOff, i32_val(tileShape[order[0]]));\n           sOff = urem(sOff, i32_val(tileShape[order[1]]));\n-          offs[ptrOff] = add(cOff, mul(sOff, sTileStride));\n+          offs[ptrOff] = add(cOff, mul(sOff, i32_val(sTileStride)));\n         }\n       }\n     }\n@@ -2695,15 +2702,14 @@ class MMA16816SmemLoader {\n     Value ptr = getPtr(ptrIdx);\n \n     if (canUseLdmatrix) {\n-      Value sOffset =\n-          mul(i32_val(matIdx[order[1]] * sMatStride * sMatShape), sTileStride);\n-      Value sOffsetPtr = gep(shemPtrTy, ptr, sOffset);\n+      int sOffset =\n+          matIdx[order[1]] * sMatStride * sMatShape * sTileStride * elemBytes;\n       PTXBuilder builder;\n \n       // ldmatrix.m8n8.x4 returns 4x2xfp16(that is 4xb32) elements for a\n       // thread.\n       auto resArgs = builder.newListOperand(4, \"=r\");\n-      auto addrArg = builder.newAddrOperand(sOffsetPtr, \"r\");\n+      auto addrArg = builder.newAddrOperand(ptr, \"r\", sOffset);\n \n       auto ldmatrix = builder.create(\"ldmatrix.sync.aligned.m8n8.x4\")\n                           ->o(\"trans\", needTrans /*predicate*/)\n@@ -2728,24 +2734,26 @@ class MMA16816SmemLoader {\n                needTrans) { // Use lds.32 to load tf32 matrices\n       Value ptr2 = getPtr(ptrIdx + 1);\n       assert(sMatStride == 1);\n-      int sOffsetElem = matIdx[order[1]] * (sMatStride * sMatShape);\n-      Value sOffsetElemVal = mul(i32_val(sOffsetElem), sTileStride);\n-      int sOffsetArrElem = sMatStride * sMatShape;\n-      Value sOffsetArrElemVal =\n-          add(sOffsetElemVal, mul(i32_val(sOffsetArrElem), sTileStride));\n+      int sOffsetElem =\n+          matIdx[order[1]] * (sMatStride * sMatShape) * sTileStride;\n+      int sOffsetArrElem = 1 * (sMatStride * sMatShape) * sTileStride;\n \n       Value elems[4];\n       Type elemTy = type::f32Ty(ctx);\n       if (kOrder == 1) {\n-        elems[0] = load(gep(elemTy, ptr, sOffsetElemVal));\n-        elems[1] = load(gep(elemTy, ptr2, sOffsetElemVal));\n-        elems[2] = load(gep(elemTy, ptr, sOffsetArrElemVal));\n-        elems[3] = load(gep(elemTy, ptr2, sOffsetArrElemVal));\n+        elems[0] = load(gep(elemTy, ptr, i32_val(sOffsetElem)));\n+        elems[1] = load(gep(elemTy, ptr2, i32_val(sOffsetElem)));\n+        elems[2] =\n+            load(gep(elemTy, ptr, i32_val(sOffsetElem + sOffsetArrElem)));\n+        elems[3] =\n+            load(gep(elemTy, ptr2, i32_val(sOffsetElem + sOffsetArrElem)));\n       } else {\n-        elems[0] = load(gep(elemTy, ptr, sOffsetElemVal));\n-        elems[2] = load(gep(elemTy, ptr2, sOffsetElemVal));\n-        elems[1] = load(gep(elemTy, ptr, sOffsetArrElemVal));\n-        elems[3] = load(gep(elemTy, ptr2, sOffsetArrElemVal));\n+        elems[0] = load(gep(elemTy, ptr, i32_val(sOffsetElem)));\n+        elems[2] = load(gep(elemTy, ptr2, i32_val(sOffsetElem)));\n+        elems[1] =\n+            load(gep(elemTy, ptr, i32_val(sOffsetElem + sOffsetArrElem)));\n+        elems[3] =\n+            load(gep(elemTy, ptr2, i32_val(sOffsetElem + sOffsetArrElem)));\n       }\n \n       return {elems[0], elems[1], elems[2], elems[3]};\n@@ -2766,11 +2774,9 @@ class MMA16816SmemLoader {\n       };\n \n       assert(sMatStride == 1);\n-      int sOffsetElem = matIdx[order[1]] * (sMatStride * sMatShape);\n-      Value sOffsetElemVal = mul(i32_val(sOffsetElem), sTileStride);\n-      int sOffsetArrElem = 1 * (sMatStride * sMatShape);\n-      Value sOffsetArrElemVal =\n-          add(sOffsetElemVal, mul(i32_val(sOffsetArrElem), sTileStride));\n+      int sOffsetElem =\n+          matIdx[order[1]] * (sMatStride * sMatShape) * sTileStride;\n+      int sOffsetArrElem = 1 * (sMatStride * sMatShape) * sTileStride;\n \n       std::array<Value, 4> i8v4Elems;\n       std::array<Value, 4> i32Elems;\n@@ -2780,14 +2786,15 @@ class MMA16816SmemLoader {\n       Value i8Elems[4][4];\n       Type elemTy = type::i8Ty(ctx);\n       if (kOrder == 1) {\n+        Value offset = i32_val(sOffsetElem);\n+\n         for (int i = 0; i < 2; ++i)\n           for (int j = 0; j < 4; ++j)\n-            i8Elems[i][j] = load(gep(elemTy, ptrs[i][j], sOffsetElemVal));\n+            i8Elems[i][j] = load(gep(elemTy, ptrs[i][j], offset));\n \n         for (int i = 2; i < 4; ++i)\n           for (int j = 0; j < 4; ++j)\n-            i8Elems[i][j] =\n-                load(gep(elemTy, ptrs[i - 2][j], sOffsetArrElemVal));\n+            i8Elems[i][j] = load(gep(elemTy, ptrs[i - 2][j], offset));\n \n         for (int m = 0; m < 4; ++m) {\n           for (int e = 0; e < 4; ++e)\n@@ -2796,14 +2803,16 @@ class MMA16816SmemLoader {\n           i32Elems[m] = bitcast(i8v4Elems[m], i32_ty);\n         }\n       } else { // k first\n+        Value offset = i32_val(sOffsetElem);\n         for (int j = 0; j < 4; ++j)\n-          i8Elems[0][j] = load(gep(elemTy, ptrs[0][j], sOffsetElemVal));\n+          i8Elems[0][j] = load(gep(elemTy, ptrs[0][j], offset));\n         for (int j = 0; j < 4; ++j)\n-          i8Elems[2][j] = load(gep(elemTy, ptrs[1][j], sOffsetElemVal));\n+          i8Elems[2][j] = load(gep(elemTy, ptrs[1][j], offset));\n+        offset = i32_val(sOffsetElem + sOffsetArrElem);\n         for (int j = 0; j < 4; ++j)\n-          i8Elems[1][j] = load(gep(elemTy, ptrs[0][j], sOffsetArrElemVal));\n+          i8Elems[1][j] = load(gep(elemTy, ptrs[0][j], offset));\n         for (int j = 0; j < 4; ++j)\n-          i8Elems[3][j] = load(gep(elemTy, ptrs[1][j], sOffsetArrElemVal));\n+          i8Elems[3][j] = load(gep(elemTy, ptrs[1][j], offset));\n \n         for (int m = 0; m < 4; ++m) {\n           for (int e = 0; e < 4; ++e)\n@@ -2836,8 +2845,8 @@ class MMA16816SmemLoader {\n   int cMatShape;\n   int sMatShape;\n \n-  Value cTileStride;\n-  Value sTileStride;\n+  int cTileStride;\n+  int sTileStride;\n \n   bool needTrans;\n   bool canUseLdmatrix;\n@@ -3890,7 +3899,6 @@ Value DotOpMmaV1ConversionHelper::loadA(\n     ConversionPatternRewriter &rewriter) const {\n   // smem\n   Value smem = smemObj.base;\n-  auto strides = smemObj.strides;\n \n   auto *ctx = rewriter.getContext();\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n@@ -3911,10 +3919,10 @@ Value DotOpMmaV1ConversionHelper::loadA(\n \n   int vecA = sharedLayout.getVec();\n \n-  Value strideAM = isARow ? strides[0] : i32_val(1);\n-  Value strideAK = isARow ? i32_val(1) : strides[1];\n-  Value strideA0 = isARow ? strideAK : strideAM;\n-  Value strideA1 = isARow ? strideAM : strideAK;\n+  int strideAM = isARow ? shape[1] : 1;\n+  int strideAK = isARow ? 1 : shape[0];\n+  int strideA0 = isARow ? strideAK : strideAM;\n+  int strideA1 = isARow ? strideAM : strideAK;\n \n   int strideRepM = wpt[0] * fpw[0] * 8;\n   int strideRepK = 1;\n@@ -3940,7 +3948,8 @@ Value DotOpMmaV1ConversionHelper::loadA(\n     offA0I = udiv(offA0I, i32_val(vecA));\n     offA0I = xor_(offA0I, phaseA);\n     offA0I = xor_(offA0I, i32_val(vecA));\n-    offA[i] = add(mul(offA0I, strideA0), mul(offA1, strideA1));\n+    offA[i] =\n+        add(mul(offA0I, i32_val(strideA0)), mul(offA1, i32_val(strideA1)));\n   }\n \n   Type f16x2Ty = vec_ty(f16_ty, 2);\n@@ -3969,9 +3978,8 @@ Value DotOpMmaV1ConversionHelper::loadA(\n \n     int stepAM = isARow ? m : m / numPtrA * numPtrA;\n     int stepAK = isARow ? k / (numPtrA * vecA) * (numPtrA * vecA) : k;\n-    Value offset = add(mul(i32_val(stepAM * strideRepM), strideAM),\n-                       mul(i32_val(stepAK), strideAK));\n-    Value pa = gep(f16PtrTy, thePtrA, offset);\n+    Value pa = gep(f16PtrTy, thePtrA,\n+                   i32_val(stepAM * strideRepM * strideAM + stepAK * strideAK));\n     Type aPtrTy = ptr_ty(vec_ty(i32_ty, std::max<int>(vecA / 2, 1)), 3);\n     Value ha = load(bitcast(pa, aPtrTy));\n     // record lds that needs to be moved\n@@ -4012,7 +4020,6 @@ Value DotOpMmaV1ConversionHelper::loadB(\n     ConversionPatternRewriter &rewriter) const {\n   // smem\n   Value smem = smemObj.base;\n-  auto strides = smemObj.strides;\n \n   auto *ctx = rewriter.getContext();\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n@@ -4026,10 +4033,10 @@ Value DotOpMmaV1ConversionHelper::loadB(\n   SmallVector<int> rep({0, 2 * packSize1, 1});       // pad M with 0\n   SmallVector<int> spw({0, fpw[1] * 4 * rep[1], 1}); // pad M with 0\n   int vecB = sharedLayout.getVec();\n-  Value strideBN = isBRow ? i32_val(1) : strides[1];\n-  Value strideBK = isBRow ? strides[0] : i32_val(1);\n-  Value strideB0 = isBRow ? strideBN : strideBK;\n-  Value strideB1 = isBRow ? strideBK : strideBN;\n+  int strideBN = isBRow ? 1 : shape[0];\n+  int strideBK = isBRow ? shape[1] : 1;\n+  int strideB0 = isBRow ? strideBN : strideBK;\n+  int strideB1 = isBRow ? strideBK : strideBN;\n   int strideRepN = wpt[1] * fpw[1] * 8;\n   int strideRepK = 1;\n \n@@ -4054,7 +4061,8 @@ Value DotOpMmaV1ConversionHelper::loadB(\n     offB0I = udiv(offB0I, i32_val(vecB));\n     offB0I = xor_(offB0I, phaseB);\n     offB0I = mul(offB0I, i32_val(vecB));\n-    offB[i] = add(mul(offB0I, strideB0), mul(offB1, strideB1));\n+    offB[i] =\n+        add(mul(offB0I, i32_val(strideB0)), mul(offB1, i32_val(strideB1)));\n   }\n \n   Type f16PtrTy = ptr_ty(f16_ty);\n@@ -4075,9 +4083,8 @@ Value DotOpMmaV1ConversionHelper::loadB(\n \n     int stepBN = isBRow ? n / numPtrB * numPtrB : n;\n     int stepBK = isBRow ? K : K / (numPtrB * vecB) * (numPtrB * vecB);\n-    Value offset = add(mul(i32_val(stepBN * strideRepN), strideBN),\n-                       mul(i32_val(stepBK), strideBK));\n-    Value pb = gep(f16PtrTy, thePtrB, offset);\n+    Value pb = gep(f16PtrTy, thePtrB,\n+                   i32_val(stepBN * strideRepN * strideBN + stepBK * strideBK));\n     Value hb =\n         load(bitcast(pb, ptr_ty(vec_ty(i32_ty, std::max(vecB / 2, 1)), 3)));\n     // record lds that needs to be moved"}]