[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -3167,6 +3167,9 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n     auto mmaLayout = dTensorTy.getEncoding().cast<MmaEncodingAttr>();\n     auto aElemTy = aTensorTy.getElementType();\n     auto bElemTy = bTensorTy.getElementType();\n+\n+    assert((mmaLayout.getVersion() == 1 || mmaLayout.getVersion() == 2) &&\n+           \"Unexpected MMA layout version found\");\n     // Refer to mma section for the data type supported by Volta and Hopper\n     // Tensor Core in\n     // https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-fragment-mma-884-f16"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -123,6 +123,7 @@ SmallVector<unsigned> getShapePerCTA(const Attribute &layout) {\n     if (mmaLayout.getVersion() == 1)\n       return {16 * mmaLayout.getWarpsPerCTA()[0],\n               16 * mmaLayout.getWarpsPerCTA()[1]};\n+    assert(0 && \"Unexpected MMA layout version found\");\n   } else {\n     assert(0 && \"Unimplemented usage of getShapePerCTA\");\n   }"}]