[{"filename": "python/src/triton.cc", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "file_content_changes": "@@ -236,12 +236,13 @@ void parse_args(py::list& args, py::list do_not_specialize, const std::string& f\n         continue;\n       }\n       // argument is `constexpr`\n-      if(py::hasattr(arg, \"value\")){\n+      if (py::hasattr(arg, \"value\")) {\n         py::object value = arg.attr(\"value\");\n-        std::string ty_str = value.attr(\"__class__\").attr(\"__name__\").cast<std::string>();\n-        if (ty_str == \"JITFunction\") {\n+        // check if value is a callable object using PyCallable_Check\n+        if (PyCallable_Check(value.ptr())) {\n           throw std::runtime_error(\n-              \"JITFunction is not supported as a constexpr argument\");\n+              \"constant argument cannot be a callable object: \" +\n+              std::string(py::str(arg)));\n         }\n         py::object name = arg_names[i];\n         constants[name] = value;"}, {"filename": "python/test/unit/runtime/test_cache.py", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "file_content_changes": "@@ -130,3 +130,23 @@ def get_cache_str(*args, **kwargs):\n     cache_str_match = re.match(r'_(\\w+)\\[multipleof\\(\\d+\\)]_float32\\*\\[multipleof\\(16\\)\\]', cache_str[-1])\n     spec_type = None if cache_str_match is None else cache_str_match.group(1)\n     assert spec_type == value_type\n+\n+\n+def test_constexpr_not_callable() -> None:\n+    @triton.jit\n+    def kernel(X, c: tl.constexpr):\n+        tl.store(X, 2)\n+\n+    x = torch.empty(1, dtype=torch.int32, device='cuda')\n+    error = False\n+    try:\n+        kernel[(1, )](x, c=\"str\")\n+    except BaseException:\n+        error = True\n+    assert error == False\n+    # try and catch\n+    try:\n+        kernel[(1, )](x, c=tl.abs)\n+    except BaseException:\n+        error = True\n+    assert error == True"}, {"filename": "python/tutorials/03-matrix-multiplication.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -261,7 +261,7 @@ def leaky_relu(x):\n # and (1) checks any shape constraint; (2) allocates the output; (3) launches the above kernel\n \n \n-def matmul(a, b, activation=None):\n+def matmul(a, b, activation=\"\"):\n     # checks constraints\n     assert a.shape[1] == b.shape[0], \"incompatible dimensions\"\n     assert a.is_contiguous(), \"matrix A must be contiguous\""}]