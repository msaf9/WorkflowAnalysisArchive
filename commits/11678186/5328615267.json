[{"filename": "python/tutorials/01-vector-add.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -29,9 +29,9 @@ def add_kernel(\n     x_ptr,  # *Pointer* to first input vector.\n     y_ptr,  # *Pointer* to second input vector.\n     output_ptr,  # *Pointer* to output vector.\n+    n_elements,  # Size of the vector.\n     BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process.\n                  # NOTE: `constexpr` so it can be used as a shape value.\n-    n_elements,  # Size of the vector.\n ):\n     # There are multiple 'programs' processing different data. We identify which program\n     # we are here:\n@@ -71,7 +71,7 @@ def add(x: torch.Tensor, y: torch.Tensor):\n     #  - Each torch.tensor object is implicitly converted into a pointer to its first element.\n     #  - `triton.jit`'ed functions can be indexed with a launch grid to obtain a callable GPU kernel.\n     #  - Don't forget to pass meta-parameters as keywords arguments.\n-    add_kernel[grid](x, y, output, 1024, n_elements)\n+    add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)\n     # We return a handle to z but, since `torch.cuda.synchronize()` hasn't been called, the kernel is still\n     # running asynchronously at this point.\n     return output"}]