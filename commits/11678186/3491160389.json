[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "file_content_changes": "@@ -1428,10 +1428,8 @@ struct BroadcastOpConversion\n     Value result = op.result();\n     auto srcTy = op.src().getType().cast<RankedTensorType>();\n     auto resultTy = result.getType().cast<RankedTensorType>();\n-    auto srcLayout = srcTy.getEncoding().dyn_cast<BlockedEncodingAttr>();\n-    auto resultLayout = resultTy.getEncoding().dyn_cast<BlockedEncodingAttr>();\n-    assert(srcLayout && (srcLayout == resultLayout) &&\n-           \"Unexpected layout of BroadcastOp\");\n+    auto srcLayout = srcTy.getEncoding();\n+    auto resultLayout = resultTy.getEncoding();\n     auto srcShape = srcTy.getShape();\n     auto resultShape = resultTy.getShape();\n     unsigned rank = srcTy.getRank();\n@@ -1441,22 +1439,22 @@ struct BroadcastOpConversion\n     SmallVector<int64_t, 4> resultLogicalShape(2 * rank);\n     SmallVector<unsigned, 2> broadcastDims;\n     for (unsigned d = 0; d < rank; ++d) {\n-      unsigned resultShapePerCTA = resultLayout.getSizePerThread()[d] *\n-                                   resultLayout.getThreadsPerWarp()[d] *\n-                                   resultLayout.getWarpsPerCTA()[d];\n+      unsigned resultShapePerCTA = triton::gpu::getSizePerThread(resultLayout)[d] *\n+                                   triton::gpu::getThreadsPerWarp(resultLayout)[d] *\n+                                   triton::gpu::getWarpsPerCTA(resultLayout)[d];\n       int64_t numCtas = ceil<unsigned>(resultShape[d], resultShapePerCTA);\n       if (srcShape[d] != resultShape[d]) {\n         assert(srcShape[d] == 1);\n         broadcastDims.push_back(d);\n         srcLogicalShape[d] = 1;\n         srcLogicalShape[d + rank] =\n-            std::max<unsigned>(1, srcLayout.getSizePerThread()[d]);\n+            std::max<unsigned>(1, triton::gpu::getSizePerThread(srcLayout)[d]);\n       } else {\n         srcLogicalShape[d] = numCtas;\n-        srcLogicalShape[d + rank] = resultLayout.getSizePerThread()[d];\n+        srcLogicalShape[d + rank] = triton::gpu::getSizePerThread(resultLayout)[d];\n       }\n       resultLogicalShape[d] = numCtas;\n-      resultLogicalShape[d + rank] = resultLayout.getSizePerThread()[d];\n+      resultLogicalShape[d + rank] = triton::gpu::getSizePerThread(resultLayout)[d];\n     }\n     int64_t duplicates = 1;\n     SmallVector<int64_t, 2> broadcastSizes(broadcastDims.size() * 2);"}]