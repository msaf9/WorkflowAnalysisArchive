[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "file_content_changes": "@@ -801,14 +801,15 @@ def kernel(output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n def test_load_store_same_ptr():\n     @triton.jit()\n     def kernel(in_out_ptr):\n-        x = tl.load(in_out_ptr)\n+        pid = tl.program_id(axis=0)\n+        x = tl.load(in_out_ptr + pid)\n         out = x * 2\n-        tl.store(in_out_ptr, out)\n+        tl.store(in_out_ptr + pid, out)\n \n     for _ in range(1000):\n-        x = torch.ones((1,), device=\"cuda\", dtype=torch.float32)\n-        kernel[(1,)](x, num_warps=32)\n-        assert x[0] == 2.0\n+        x = torch.ones((65536,), device=\"cuda\", dtype=torch.float32)\n+        kernel[(65536,)](x, num_warps=32)\n+        assert torch.all(x == 2)\n \n \n @pytest.mark.parametrize(\"dtype\", [torch.float16, torch.bfloat16])"}]