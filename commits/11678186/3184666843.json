[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "file_content_changes": "@@ -421,6 +421,16 @@ def where_kernel(cond_ptr, a_ptr, out_ptr, BLOCK_SIZE: tl.constexpr):\n         res = tl.where(mask, vals, 0.)\n         tl.store(out_ptr + yoffsets + BLOCK_SIZE * xoffsets, res)\n \n+    @triton.jit\n+    def where_scalar_condition(a_ptr, out_ptr, BLOCK_SIZE: tl.constexpr):\n+        xoffsets = tl.reshape(tl.arange(0, BLOCK_SIZE), [BLOCK_SIZE, 1])\n+        yoffsets = tl.reshape(tl.arange(0, BLOCK_SIZE), [1, BLOCK_SIZE])\n+        mask = 0\n+        vals = tl.load(a_ptr + yoffsets + BLOCK_SIZE * xoffsets)\n+        res = tl.where(mask, vals, 0.)\n+        tl.store(out_ptr + yoffsets + BLOCK_SIZE * xoffsets, res)\n+\n+\n     SIZE = 32\n     dtype = 'float32'\n     rs = RandomState(17)\n@@ -432,6 +442,9 @@ def where_kernel(cond_ptr, a_ptr, out_ptr, BLOCK_SIZE: tl.constexpr):\n     z_tri = to_triton(np.empty((SIZE, SIZE), dtype=z.dtype), device='cuda', dst_type=dtype)\n     where_kernel[(1,)](cond_tri, x_tri, z_tri, SIZE)\n     assert (z == to_numpy(z_tri)).all()\n+    where_scalar_condition[(1,)](x_tri, z_tri, SIZE)\n+    z = np.where(0, x, 0)\n+    assert (z == to_numpy(z_tri)).all()\n \n # ---------------\n # test unary ops"}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -978,6 +978,8 @@ def where(condition: tl.tensor,\n         condition, x = broadcast_impl_value(condition, x, builder)\n \n     x, y = binary_op_type_checking_impl(x, y, builder, True, True)\n+    if not condition.type.is_block():\n+        condition, _ = broadcast_impl_value(condition, x, builder)\n     ret_ty = x.type\n     return tl.tensor(builder.create_select(condition.handle, x.handle, y.handle), ret_ty)\n "}]