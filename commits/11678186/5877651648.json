[{"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -371,6 +371,8 @@ SmallVector<unsigned, 3>\n mmaVersionToInstrShape(triton::gpu::MmaEncodingAttr mma,\n                        ArrayRef<int64_t> shape);\n \n+Value getParentValueWithSameEncoding(Attribute layout, Value value);\n+\n } // namespace mlir\n \n #endif // TRITON_ANALYSIS_UTILITY_H"}, {"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "file_content_changes": "@@ -36,6 +36,9 @@ SmallVector<unsigned> getThreadsPerWarp(Attribute layout);\n // elements. If you want non-replicated warps, use getWarpsPerCTAWithUniqueData.\n SmallVector<unsigned> getWarpsPerCTA(Attribute layout);\n \n+SmallVector<unsigned> getSizePerThread(BlockedEncodingAttr layout);\n+SmallVector<unsigned> getSizePerThread(Value value);\n+\n SmallVector<unsigned> getSizePerThread(Attribute layout,\n                                        ArrayRef<int64_t> shapePerCTA);\n \n@@ -90,6 +93,11 @@ SmallVector<unsigned> getCTAOrder(Attribute layout);\n  * (3) In the implementation of emitIndices, ShapePerCTATile will\n  *     be replicated or wraped to fit ShapePerCTA.\n  */\n+SmallVector<unsigned> getShapePerCTATile(BlockedEncodingAttr layout);\n+SmallVector<unsigned> getShapePerCTATile(MmaEncodingAttr layout,\n+                                         RankedTensorType inputType);\n+SmallVector<unsigned> getShapePerCTATile(Value value);\n+\n SmallVector<unsigned> getShapePerCTATile(Attribute layout,\n                                          ArrayRef<int64_t> shapePerCTA);\n "}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -750,5 +750,8 @@ mmaVersionToInstrShape(triton::gpu::MmaEncodingAttr mma,\n                        ArrayRef<int64_t> shape) {\n   return {0};\n }\n+Value getParentValueWithSameEncoding(Attribute layout, Value value) {\n+  return {};\n+}\n \n } // namespace mlir"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -238,7 +238,7 @@ struct ConvertLayoutOpConversion\n \n   // shared memory rd/st for blocked or mma layout with data padding\n   void processReplica(Location loc, ConversionPatternRewriter &rewriter,\n-                      bool stNotRd, RankedTensorType type,\n+                      bool stNotRd, Value value, RankedTensorType type,\n                       ArrayRef<unsigned> numCTAsEachRep,\n                       ArrayRef<unsigned> multiDimRepId, unsigned vec,\n                       ArrayRef<unsigned> paddedRepShape,\n@@ -323,7 +323,7 @@ struct ConvertLayoutOpConversion\n   // structure, add a new simple but clear implementation for it to avoid\n   // modifying the logic of the existing one.\n   void processReplicaForMMAV1(Location loc, ConversionPatternRewriter &rewriter,\n-                              bool stNotRd, RankedTensorType type,\n+                              bool stNotRd, Value value, RankedTensorType type,\n                               ArrayRef<unsigned> multiDimRepId, unsigned vec,\n                               ArrayRef<unsigned> paddedRepShape,\n                               ArrayRef<unsigned> outOrd,\n@@ -613,11 +613,11 @@ struct ConvertLayoutOpConversion\n           srcLayout.isa<SliceEncodingAttr>() ||\n           srcLayout.isa<MmaEncodingAttr>()) {\n         if (isSrcMmaV1)\n-          processReplicaForMMAV1(loc, rewriter, /*stNotRd*/ true, srcTy,\n+          processReplicaForMMAV1(loc, rewriter, /*stNotRd*/ true, src, srcTy,\n                                  multiDimRepId, inVec, paddedRepShape, outOrd,\n                                  vals, smemBase, shape);\n         else\n-          processReplica(loc, rewriter, /*stNotRd*/ true, srcTy,\n+          processReplica(loc, rewriter, /*stNotRd*/ true, src, srcTy,\n                          inNumCTAsEachRep, multiDimRepId, inVec, paddedRepShape,\n                          outOrd, vals, smemBase);\n       } else {\n@@ -646,11 +646,11 @@ struct ConvertLayoutOpConversion\n           dstLayout.isa<SliceEncodingAttr>() ||\n           dstLayout.isa<MmaEncodingAttr>()) {\n         if (isDstMmaV1)\n-          processReplicaForMMAV1(loc, rewriter, /*stNotRd*/ false, dstTy,\n+          processReplicaForMMAV1(loc, rewriter, /*stNotRd*/ false, dst, dstTy,\n                                  multiDimRepId, outVec, paddedRepShape, outOrd,\n                                  outVals, smemBase, shape, /*isDestMma=*/true);\n         else\n-          processReplica(loc, rewriter, /*stNotRd*/ false, dstTy,\n+          processReplica(loc, rewriter, /*stNotRd*/ false, dst, dstTy,\n                          outNumCTAsEachRep, multiDimRepId, outVec,\n                          paddedRepShape, outOrd, outVals, smemBase);\n       } else {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandFMA.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -35,7 +35,7 @@ getThreadIds(Value threadId, ArrayRef<unsigned int> shapePerCTATile,\n // Get shapePerCTATile for M or N axis.\n int getShapePerCTATileForMN(BlockedEncodingAttr layout, bool isM) {\n   auto order = layout.getOrder();\n-  auto shapePerCTATile = getShapePerCTATile(layout, {});\n+  auto shapePerCTATile = getShapePerCTATile(layout);\n \n   int mShapePerCTATile =\n       order[0] == 1 ? shapePerCTATile[order[1]] : shapePerCTATile[order[0]];\n@@ -110,7 +110,7 @@ Value loadAFMA(Value A, Value llA, BlockedEncodingAttr dLayout, Value thread,\n   int K = aShapePerCTA[1];\n   int M = aShapePerCTA[0];\n \n-  auto shapePerCTATile = getShapePerCTATile(dLayout, {});\n+  auto shapePerCTATile = getShapePerCTATile(dLayout);\n   auto sizePerThread = getSizePerThread(dLayout, {});\n \n   Value _0 = i32_val(0);\n@@ -174,7 +174,7 @@ Value loadBFMA(Value B, Value llB, BlockedEncodingAttr dLayout, Value thread,\n   int K = bShapePerCTA[0];\n   int N = bShapePerCTA[1];\n \n-  auto shapePerCTATile = getShapePerCTATile(dLayout, {});\n+  auto shapePerCTATile = getShapePerCTATile(dLayout);\n   auto sizePerThread = getSizePerThread(dLayout, {});\n \n   Value _0 = i32_val(0);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/FMA.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -54,7 +54,7 @@ LogicalResult convertFMADot(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n   Value llB = adaptor.getB();\n \n   auto sizePerThread = getSizePerThread(dLayout, {});\n-  auto shapePerCTATile = getShapePerCTATile(dLayout, {});\n+  auto shapePerCTATile = mlir::triton::gpu::getShapePerCTATile(D);\n \n   int K = aShapePerCTA[1];\n   int M = aShapePerCTA[0];"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpToLLVM/WGMMA.cpp", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "file_content_changes": "@@ -286,7 +286,7 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n   int N = instrShape[1];\n   int K = instrShape[2];\n \n-  auto shapePerCTATile = getShapePerCTATile(mmaEncoding, dShapePerCTA);\n+  auto shapePerCTATile = getShapePerCTATile(d);\n   int numRepM = ceil<unsigned>(dShapePerCTA[0], shapePerCTATile[0]);\n   int numRepN = ceil<unsigned>(dShapePerCTA[1], shapePerCTATile[1]);\n   int numRepK = ceil<unsigned>(aTensorTy.getShape()[1], instrShape[2]);\n@@ -357,14 +357,15 @@ LogicalResult convertDot(TritonGPUToLLVMTypeConverter *typeConverter,\n }\n \n // Loading $c to registers, returns a Value.\n-Value loadC(Value tensor, Value llTensor) {\n+Value loadC(Value dTensor, Value tensor, Value llTensor) {\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n   auto mmaEncoding = tensorTy.getEncoding().dyn_cast<MmaEncodingAttr>();\n   assert(mmaEncoding && \"Currently, we only support $c with a mma layout.\");\n   auto shapePerCTA = getShapePerCTA(tensorTy);\n   auto instrShape = mmaVersionToInstrShape(mmaEncoding, shapePerCTA);\n   auto wpt = mmaEncoding.getWarpsPerCTA();\n-  auto shapePerCTATile = getShapePerCTATile(mmaEncoding, shapePerCTA);\n+  // benzh@need from ACC\n+  auto shapePerCTATile = getShapePerCTATile(dTensor);\n \n   int numRepM = ceil<unsigned>(shapePerCTA[0], shapePerCTATile[0]);\n   int numRepN = ceil<unsigned>(shapePerCTA[1], shapePerCTATile[1]);\n@@ -395,7 +396,7 @@ LogicalResult convertWGMMA(triton::DotOp op, triton::DotOp::Adaptor adaptor,\n   Value llA, llB, llC;\n   llA = adaptor.getA();\n   llB = adaptor.getB();\n-  llC = loadC(C, adaptor.getC());\n+  llC = loadC(op.getD(), C, adaptor.getC());\n \n   auto smemObjA = getSharedMemoryObjectFromStruct(loc, llA, rewriter);\n   auto smemObjB = getSharedMemoryObjectFromStruct(loc, llB, rewriter);\n@@ -423,7 +424,7 @@ LogicalResult convertAsyncWGMMA(triton::nvidia_gpu::DotAsyncOp op,\n   Value llA, llB, llC;\n   llA = adaptor.getA();\n   llB = adaptor.getB();\n-  llC = loadC(C, adaptor.getC());\n+  llC = loadC(op.getD(), C, adaptor.getC());\n \n   auto smemObjA = getSharedMemoryObjectFromStruct(loc, llA, rewriter);\n   auto smemObjB = getSharedMemoryObjectFromStruct(loc, llB, rewriter);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -306,7 +306,7 @@ struct StoreOpConversion\n       vec = std::min(vec, maskAlign);\n     }\n \n-    Value mask = getMask(valueTy, rewriter, loc);\n+    Value mask = getMask(value, rewriter, loc);\n     const size_t dtsize =\n         std::max<int>(1, valueElemTy.getIntOrFloatBitWidth() / 8);\n     const size_t valueElemNBits = dtsize * 8;\n@@ -669,7 +669,7 @@ struct AtomicCASOpConversion\n         TensorTy ? getTypeConverter()->convertType(TensorTy.getElementType())\n                  : valueTy;\n     auto valueElemNBits = valueElemTy.getIntOrFloatBitWidth();\n-    Value mask = getMask(valueTy, rewriter, loc);\n+    Value mask = getMask(op.getResult(), rewriter, loc);\n \n     Value atomPtr = getSharedMemoryBase(loc, rewriter, op.getOperation());\n     atomPtr = bitcast(atomPtr, ptr_ty(valueElemTy, 3));\n@@ -762,7 +762,7 @@ struct AtomicRMWOpConversion\n       // mask\n       numElems = tensorTy.getNumElements();\n     }\n-    Value mask = getMask(valueTy, rewriter, loc);\n+    Value mask = getMask(op.getResult(), rewriter, loc);\n \n     auto vecTy = vec_ty(valueElemTy, vec);\n     SmallVector<Value> resultVals(elemsPerThread);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -391,7 +391,7 @@ struct ReduceOpConversion\n     RankedTensorType operandType = op.getInputTypes()[0];\n     // Assumes offsets don't actually depend on type\n     SmallVector<SmallVector<unsigned>> offset =\n-        emitOffsetForLayout(helper.getSrcLayout(), operandType);\n+        emitOffsetForLayout(helper.getSrcValue());\n     unsigned srcElems = getTotalElemsPerThread(operandType);\n     auto *combineOp = &op.getCombineOp();\n     auto srcIndices =\n@@ -473,7 +473,7 @@ struct ReduceOpConversion\n         auto resultLayout = resultTy.getEncoding().cast<SliceEncodingAttr>();\n         unsigned resultElems = getTotalElemsPerThread(resultTy);\n         SmallVector<SmallVector<unsigned>> resultOffset =\n-            emitOffsetForLayout(resultLayout, resultTy);\n+            emitOffsetForLayout(op.getResult()[i]);\n         SmallVector<Value> resultVals;\n         for (int j = 0; j < resultElems; j++) {\n           auto key = resultOffset[j];"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -65,8 +65,8 @@ struct BroadcastOpConversion\n \n     assert(rank == resultTy.getRank());\n     auto order = triton::gpu::getOrder(srcLayout);\n-    auto srcOffsets = emitOffsetForLayout(srcLayout, srcTy);\n-    auto resultOffsets = emitOffsetForLayout(resultLayout, resultTy);\n+    auto srcOffsets = emitOffsetForLayout(op.getSrc());\n+    auto resultOffsets = emitOffsetForLayout(result);\n     SmallVector<Value> srcVals =\n         getTypeConverter()->unpackLLElements(loc, src, rewriter, srcTy);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "file_content_changes": "@@ -536,8 +536,9 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n   // -----------------------------------------------------------------------\n   // Utilities\n   // -----------------------------------------------------------------------\n-  Value getMask(Type valueTy, ConversionPatternRewriter &rewriter,\n+  Value getMask(Value value, ConversionPatternRewriter &rewriter,\n                 Location loc) const {\n+    Type valueTy = value.getType();\n     auto tensorTy = valueTy.dyn_cast<RankedTensorType>();\n     Value mask = int_val(1, 1);\n     auto tid = tid_val();\n@@ -550,8 +551,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n       auto threadsPerWarp = triton::gpu::getThreadsPerWarp(layout);\n       auto warpsPerCTA = triton::gpu::getWarpsPerCTA(layout);\n       auto order = triton::gpu::getOrder(layout);\n-      auto shapePerCTATile =\n-          triton::gpu::getShapePerCTATile(layout, shapePerCTA);\n+      auto shapePerCTATile = triton::gpu::getShapePerCTATile(value);\n       Value warpSize = i32_val(32);\n       Value laneId = urem(tid, warpSize);\n       Value warpId = udiv(tid, warpSize);\n@@ -695,6 +695,10 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     }\n   }\n \n+  SmallVector<SmallVector<unsigned>> emitOffsetForLayout(Value value) const {\n+    return {};\n+  }\n+\n   SmallVector<SmallVector<unsigned>>\n   emitOffsetForLayout(Attribute layout, RankedTensorType type) const {\n     if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>())\n@@ -818,7 +822,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     auto warpsPerCTA = blockedLayout.getWarpsPerCTA();\n     auto order = blockedLayout.getOrder();\n     auto shapePerCTA = triton::gpu::getShapePerCTA(blockedLayout, shape);\n-    auto shapePerCTATile = getShapePerCTATile(blockedLayout, shapePerCTA);\n+    auto shapePerCTATile = getShapePerCTATile(blockedLayout);\n \n     unsigned rank = shape.size();\n     SmallVector<unsigned> tilesPerDim(rank);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ViewOpToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -180,8 +180,8 @@ struct ExpandDimsOpConversion\n     auto srcLayout = srcTy.getEncoding().dyn_cast<SliceEncodingAttr>();\n     auto resultLayout = resultTy.getEncoding();\n \n-    auto srcOffsets = emitOffsetForLayout(srcLayout, srcTy);\n-    auto resultOffsets = emitOffsetForLayout(resultLayout, resultTy);\n+    auto srcOffsets = emitOffsetForLayout(op.getSrc());\n+    auto resultOffsets = emitOffsetForLayout(op.getResult());\n     DenseMap<SmallVector<unsigned>, Value, SmallVectorKeyInfo> srcValues;\n     for (size_t i = 0; i < srcOffsets.size(); i++) {\n       srcValues[srcOffsets[i]] = srcVals[i];"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 77, "deletions": 0, "changes": 77, "file_content_changes": "@@ -286,6 +286,83 @@ SmallVector<unsigned> getThreadsPerCTA(Attribute layout) {\n   return threads;\n }\n \n+SmallVector<unsigned> getShapePerCTATile(BlockedEncodingAttr blockedLayout) {\n+  SmallVector<unsigned> shape;\n+  for (unsigned d = 0, n = blockedLayout.getOrder().size(); d < n; ++d)\n+    shape.push_back(blockedLayout.getSizePerThread()[d] *\n+                    blockedLayout.getThreadsPerWarp()[d] *\n+                    blockedLayout.getWarpsPerCTA()[d]);\n+\n+  return shape;\n+}\n+\n+static SmallVector<unsigned> getMMAShapePerCTATile_(MmaEncodingAttr mmaLayout,\n+                                                    Value value,\n+                                                    bool fromInput = false) {\n+  SmallVector<unsigned> shape;\n+  auto tensorShape = getShapePerCTA(value.getType());\n+  Type inputType;\n+\n+  if (mmaLayout.isAmpere())\n+    return {16 * mmaLayout.getWarpsPerCTA()[0],\n+            8 * mmaLayout.getWarpsPerCTA()[1]};\n+  if (mmaLayout.isVolta()) {\n+    assert(!tensorShape.empty() && \"Volta needs the tensorShape\");\n+    if (tensorShape.size() == 1) // must be SliceEncoding\n+      return {static_cast<unsigned>(tensorShape[0]),\n+              static_cast<unsigned>(tensorShape[0])};\n+    return {static_cast<unsigned>(tensorShape[0]),\n+            static_cast<unsigned>(tensorShape[1])};\n+  }\n+  if (mmaLayout.isHopper()) {\n+    auto instrShape = mmaVersionToInstrShape(mmaLayout.getVersionMajor(),\n+                                             tensorShape, inputType);\n+    return {16 * mmaLayout.getWarpsPerCTA()[0],\n+            instrShape[1] * mmaLayout.getWarpsPerCTA()[1]};\n+  }\n+  assert(0 && \"Unexpected MMA layout version found\");\n+  return shape;\n+}\n+\n+SmallVector<unsigned> getShapePerCTATile(Value value) {\n+  SmallVector<unsigned> shape;\n+  auto layout = value.getType().cast<RankedTensorType>().getEncoding();\n+\n+  if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n+    return getShapePerCTATile(blockedLayout);\n+  } else if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n+    Value newValue =\n+        mlir::getParentValueWithSameEncoding(sliceLayout.getParent(), value);\n+    shape = getShapePerCTATile(newValue);\n+    shape.erase(shape.begin() + sliceLayout.getDim());\n+  } else if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n+    getMMAShapePerCTATile_(mmaLayout, value);\n+  } else if (auto dotLayout = layout.dyn_cast<DotOperandEncodingAttr>()) {\n+    auto parentLayout = dotLayout.getParent();\n+    assert(parentLayout && \"DotOperandEncodingAttr must have a parent\");\n+    if (auto parentMmaLayout = parentLayout.dyn_cast<MmaEncodingAttr>()) {\n+      assert((parentMmaLayout.isAmpere() || parentMmaLayout.isHopper()) &&\n+             \"mmaLayout version = 1 is not implemented yet\");\n+      auto parentShapePerCTATile =\n+          getMMAShapePerCTATile_(parentMmaLayout, value, true);\n+      auto opIdx = dotLayout.getOpIdx();\n+      if (opIdx == 0) {\n+        return {parentShapePerCTATile[0], 16};\n+      } else if (opIdx == 1) {\n+        return {16, parentShapePerCTATile[1]};\n+      } else {\n+        assert(0 && \"DotOperandEncodingAttr opIdx must be 0 or 1\");\n+      }\n+    } else {\n+      assert(0 && \"DotOperandEncodingAttr non-MmaEncodingAttr parent not \"\n+                  \"supported yet\");\n+    }\n+  } else {\n+    assert(0 && \"Unimplemented usage of getShapePerCTATile\");\n+  }\n+  return shape;\n+}\n+\n SmallVector<unsigned> getShapePerCTATile(Attribute layout,\n                                          ArrayRef<int64_t> tensorShape) {\n   SmallVector<unsigned> shape;"}]