[{"filename": "lib/Dialect/TritonGPU/Transforms/RemoveLayoutConversions.cpp", "status": "modified", "additions": 33, "deletions": 0, "changes": 33, "file_content_changes": "@@ -77,6 +77,39 @@ class DecomposeDotOperand : public mlir::RewritePattern {\n       rewriter.replaceOpWithNewOp<triton::gpu::ConvertLayoutOp>(op, dstType,\n                                                                 tmp);\n       return mlir::success();\n+    } else if (srcType.getEncoding().isa<triton::gpu::BlockedEncodingAttr>() &&\n+               dstType.getEncoding().isa<triton::gpu::SharedEncodingAttr>()) {\n+      auto result = convert.getResult();\n+      if (!result.hasOneUse())\n+        return mlir::failure();\n+\n+      if (!llvm::isa<triton::DotOp>(*(result.user_begin())))\n+        return mlir::failure();\n+\n+      if (result.use_begin()->getOperandNumber() != 0)\n+        return mlir::failure();\n+\n+      SetVector<Operation *> bwdSlices;\n+      mlir::getBackwardSlice(result, &bwdSlices);\n+      auto firstDotOp = llvm::find_if(\n+          bwdSlices, [](Operation *op) { return isa<triton::DotOp>(op); });\n+      if (firstDotOp == bwdSlices.end())\n+        return mlir::failure();\n+\n+      auto firstDotType =\n+          (*firstDotOp)->getResult(0).getType().cast<RankedTensorType>();\n+      auto firstMma =\n+          firstDotType.getEncoding().cast<triton::gpu::MmaEncodingAttr>();\n+      if (!firstMma.isHopper()) {\n+        return mlir::failure();\n+      }\n+\n+      auto tmpType = RankedTensorType::get(dstType.getShape(),\n+                                           dstType.getElementType(), firstMma);\n+      auto tmp = rewriter.create<triton::gpu::ConvertLayoutOp>(\n+          convert.getLoc(), tmpType, convert.getOperand());\n+      rewriter.replaceOpWithNewOp<triton::gpu::ConvertLayoutOp>(op, dstType,\n+                                                                tmp);\n     }\n     return mlir::failure();\n   }"}]