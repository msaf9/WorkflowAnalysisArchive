[{"filename": "include/triton/codegen/analysis/layout.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "file_content_changes": "@@ -103,6 +103,7 @@ class distributed_layout: public data_layout{\n \n   int shape_per_cta(size_t k) { return shape_per_cta_.at(k); }\n   int rep_per_cta(size_t k) { return shape_[k] / shape_per_cta_[k]; }\n+  virtual int contig_per_thread(size_t k) = 0;\n \n protected:\n   std::vector<int> shape_per_cta_;\n@@ -181,6 +182,7 @@ class mma_layout: public distributed_layout {\n   int wpt(size_t k) { return wpt_.at(k); }\n   int spw(size_t k) { return spw_.at(k); }\n   int rep(size_t k) { return rep_.at(k); }\n+  int contig_per_thread(size_t k) { return contig_per_thread_.at(k); }\n \n   // helpers for generator.cc\n   std::string get_ptx_instr() const { return mma_instr_ptx_.at(tensor_core_type_); }\n@@ -203,6 +205,8 @@ class mma_layout: public distributed_layout {\n   std::vector<int> spt_;\n   // repetitions\n   std::vector<int> rep_;\n+  // contiguous per thread\n+  std::vector<int> contig_per_thread_;\n \n   TensorCoreType tensor_core_type_ = FP32_FP16_FP16_FP32;\n };\n@@ -218,6 +222,7 @@ struct scanline_layout: public distributed_layout {\n   // accessor\n   int mts(size_t k) { return mts_.at(k); }\n   int nts(size_t k) { return nts_.at(k); }\n+  int contig_per_thread(size_t k) { return nts_.at(k); }\n \n public:\n   // micro tile size. The size of a tile held by a thread block."}, {"filename": "lib/codegen/analysis/layout.cc", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "file_content_changes": "@@ -208,10 +208,12 @@ mma_layout::mma_layout(size_t num_warps,\n     int pack_size_1 = (is_b_row && !is_b_vec4) ? 2 : 1;\n     rep_ = {2*pack_size_0, 2*pack_size_1, 1};\n     spw_ = {fpw_[0]*4*rep_[0], fpw_[1]*4*rep_[1], 1};\n+    contig_per_thread_ = {1, 1};\n   }\n   else{\n     // fpw_ = {1, 1, 1};\n     spw_ = mma_instr_shape_.at(tensor_core_type_); // e.g., {16, 8, 16} for f32.f16.f16.f32\n+    contig_per_thread_ = {1, 2};\n     // rep_ = {2,  2, 1};\n   }\n   order_ = {0, 1};\n@@ -628,6 +630,12 @@ void layouts::run(ir::module &mod) {\n         shape[k] = std::max(in_layout->shape_per_cta(k),\n                             out_layout->shape_per_cta(k));\n       }\n+      auto in_ord = in_layout->get_order();\n+      auto out_ord = out_layout->get_order();\n+      int in_vec = in_layout->contig_per_thread(in_ord[0]);\n+      int out_vec = out_layout->contig_per_thread(out_ord[0]);\n+      int pad = std::max(in_vec, out_vec);\n+      shape[out_ord[0]] += pad;\n       layouts_[id] = new shared_layout(out_layout, axes_->get(val), shape, {val}, val->get_type()->get_scalar_ty(), align_, tgt_);\n       tmp_[val] = id;\n     }"}, {"filename": "lib/codegen/analysis/swizzle.cc", "status": "modified", "additions": 24, "deletions": 23, "changes": 47, "file_content_changes": "@@ -14,41 +14,42 @@ void swizzle::run(ir::module &) {\n     max_phase_.clear();\n \n     for(auto &x: layouts_->get_all()){\n-      shared_layout* layout = dynamic_cast<shared_layout*>(x.second);\n-      if(!layout)\n+      shared_layout* out_layout = dynamic_cast<shared_layout*>(x.second);\n+      if(!out_layout)\n         continue;\n-      ir::value* mma_dot_a = layout->hmma_dot_a();\n-      ir::value* mma_dot_b = layout->hmma_dot_b();\n+      scanline_layout* in_layout = dynamic_cast<scanline_layout*>(out_layout->get_arg_layout());\n+      if(!in_layout)\n+        continue;\n+\n+      ir::value* mma_dot_a = out_layout->hmma_dot_a();\n+      ir::value* mma_dot_b = out_layout->hmma_dot_b();\n \n       if(!mma_dot_a && !mma_dot_b){\n-        per_phase_[layout] = 1;\n-        max_phase_[layout] = 1;\n-        vec_[layout] = 1;\n+        per_phase_[out_layout] = 1;\n+        max_phase_[out_layout] = 1;\n+        vec_[out_layout] = 1;\n         continue;\n       }\n-      auto ord = layout->get_order();\n-      scanline_layout* in_layout = dynamic_cast<scanline_layout*>(layout->get_arg_layout());\n-      if(!in_layout)\n-        continue;\n-      int dtsize = layout->get_type()->get_scalar_ty()->get_primitive_size_in_bits() / 8;\n+      auto ord = out_layout->get_order();\n+      int dtsize = out_layout->get_type()->get_scalar_ty()->get_primitive_size_in_bits() / 8;\n       if(tgt_->as_nvidia() && tgt_->as_nvidia()->sm() < 80){\n         int inner = mma_dot_a ? 0 : 1;\n-        per_phase_[layout] = std::max<int>(128 / (in_layout->mts(ord[0])*in_layout->nts(ord[0])*dtsize), 1);\n-        max_phase_[layout] = (ord[inner] == 1 ? 8 : 4) / per_phase_[layout];\n+        per_phase_[out_layout] = std::max<int>(128 / (in_layout->mts(ord[0])*in_layout->nts(ord[0])*dtsize), 1);\n+        max_phase_[out_layout] = (ord[inner] == 1 ? 8 : 4) / per_phase_[out_layout];\n         if(mma_dot_a)\n-          vec_[layout] = 2*layouts_->get(mma_dot_a)->to_mma()->rep(0);\n+          vec_[out_layout] = 2*layouts_->get(mma_dot_a)->to_mma()->rep(0);\n         else\n-          vec_[layout] = 2*layouts_->get(mma_dot_b)->to_mma()->rep(1);\n+          vec_[out_layout] = 2*layouts_->get(mma_dot_b)->to_mma()->rep(1);\n       }\n       else {\n-        if (!layout->allow_swizzle()) {\n-          per_phase_[layout] = 1;\n-          max_phase_[layout] = 1;\n-          vec_[layout] = 1;\n+        if (!out_layout->allow_swizzle()) {\n+          per_phase_[out_layout] = 1;\n+          max_phase_[out_layout] = 1;\n+          vec_[out_layout] = 1;\n         } else {\n-          per_phase_[layout] = std::max<int>(128 / (in_layout->mts(ord[0])*in_layout->nts(ord[0])*dtsize), 1);\n-          max_phase_[layout] = layout->get_mma_strided() / per_phase_[layout];\n-          vec_[layout]       = layout->get_mma_vec();\n+          per_phase_[out_layout] = std::max<int>(128 / (in_layout->mts(ord[0])*in_layout->nts(ord[0])*dtsize), 1);\n+          max_phase_[out_layout] = out_layout->get_mma_strided() / per_phase_[out_layout];\n+          vec_[out_layout]       = out_layout->get_mma_vec();\n         }\n       }\n     }"}, {"filename": "lib/codegen/selection/generator.cc", "status": "modified", "additions": 23, "deletions": 10, "changes": 33, "file_content_changes": "@@ -2377,38 +2377,51 @@ void generator::visit_layout_convert(ir::value *out, ir::value *in){\n   }\n   in_ord = in_layout->to_mma() ? out_ord : in_ord;\n   out_ord = out_layout->to_mma() ? in_ord : out_ord;\n-  Value *in_ld = i32(shape[in_ord[0]]);\n-  Value *out_ld = i32(shape[out_ord[0]]);\n+  int in_vec = in_layout->contig_per_thread(in_ord[0]);\n+  int out_vec = out_layout->contig_per_thread(out_ord[0]);\n+  int pad = std::max(in_vec, out_vec);\n+  Value *in_ld = i32(shape[in_ord[0]] + pad);\n+  Value *out_ld = i32(shape[out_ord[0]] + pad);\n   for(int i = 0; i < n_reps[0]; i++)\n   for(int j = 0; j < n_reps[1]; j++){\n     int max_ii, max_jj;\n     add_barrier();\n     max_ii = in_ax[0].size()/n_reps[0];\n     max_jj = in_ax[1].size()/n_reps[1];\n     for(int ii = 0; ii < max_ii; ii++)\n-    for(int jj = 0; jj < max_jj; jj++){\n+    for(int jj = 0; jj < max_jj; jj+=in_vec){\n       // shared mem pointer\n       indices_t offs = {in_ax[0][ii], in_ax[1][jj]};\n       Value *off  = add(offs[out_ord[0]], mul(out_ld, offs[out_ord[1]]));\n       Value *ptr = gep(base, off);\n       // stash value to shared mem\n-      indices_t idxs = {in_ax[0][i*max_ii + ii],\n-                        in_ax[1][j*max_jj + jj]};\n-      store(bit_cast(vals_[in][idxs], ty), ptr);\n+      Value* vals = UndefValue::get(vec_ty(ty, in_vec));\n+      for(int jjj = 0; jjj < in_vec; jjj++){\n+        indices_t idxs = {in_ax[0][i*max_ii + ii],\n+                          in_ax[1][j*max_jj + jj + jjj]};\n+        Value* val = bit_cast(vals_[in][idxs], ty);\n+        vals = insert_elt(vals, val, jjj);\n+      }\n+      ptr = bit_cast(ptr, ptr_ty(vals->getType(), ptr->getType()->getPointerAddressSpace()));\n+      store(vals, ptr);\n     }\n     add_barrier();\n     max_ii = out_ax[0].size()/n_reps[0];\n     max_jj = out_ax[1].size()/n_reps[1];\n     for(int ii = 0; ii < max_ii; ii++)\n-    for(int jj = 0; jj < max_jj; jj++){\n+    for(int jj = 0; jj < max_jj; jj+=out_vec){\n       // shared mem pointer\n       indices_t offs = {out_ax[0][ii], out_ax[1][jj]};\n       Value *off  = add(offs[out_ord[0]], mul(out_ld, offs[out_ord[1]]));\n       Value *ptr = gep(base, off);\n+      ptr = bit_cast(ptr, ptr_ty(vec_ty(ty, out_vec), ptr->getType()->getPointerAddressSpace()));\n       // load value from shared rem\n-      indices_t idxs = {out_ax[0][i*max_ii + ii],\n-                        out_ax[1][j*max_jj + jj]};\n-      vals_[out][idxs] = load(ptr);\n+      Value* vals = load(ptr);\n+      for(int jjj = 0; jjj < out_vec; jjj++){\n+        indices_t idxs = {out_ax[0][i*max_ii + ii],\n+                          out_ax[1][j*max_jj + jj + jjj]};\n+        vals_[out][idxs] = extract_elt(vals, jjj);\n+      }\n     }\n \n   }"}]