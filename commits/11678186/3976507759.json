[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -1664,6 +1664,7 @@ def system_libdevice_path() -> str:\n \n @pytest.mark.parametrize(\"dtype_str, expr, lib_path\",\n                          [('int32', 'libdevice.ffs', ''),\n+                          ('float32', 'libdevice.log2', ''),\n                           ('float32', 'libdevice.pow', system_libdevice_path()),\n                           ('float64', 'libdevice.norm4d', '')])\n def test_libdevice_tensor(dtype_str, expr, lib_path):\n@@ -1679,7 +1680,10 @@ def kernel(X, Y, BLOCK: tl.constexpr):\n     # limit the range of integers so that the sum does not overflow\n     x = numpy_random(shape, dtype_str=dtype_str, rs=rs)\n \n-    if expr == 'libdevice.ffs':\n+    if expr == 'libdevice.log2':\n+        kernel = patch_kernel(kernel, {'GENERATE_TEST_HERE': 'tl.broadcast_to(tl.libdevice.log2(5.0), x.shape)'})\n+        y_ref = np.log2(5.0)\n+    elif expr == 'libdevice.ffs':\n         kernel = patch_kernel(kernel, {'GENERATE_TEST_HERE': 'tl.libdevice.ffs(x)'})\n         y_ref = np.zeros(shape, dtype=x.dtype)\n         for i in range(shape[0]):"}, {"filename": "python/triton/language/extern.py", "status": "modified", "additions": 13, "deletions": 24, "changes": 37, "file_content_changes": "@@ -58,31 +58,20 @@ def elementwise(lib_name: str, lib_path: str, args: list, arg_type_symbol_dict:\n     dispatch_args = args.copy()\n     all_scalar = True\n     ret_shape = None\n-    for dispatch_arg in dispatch_args:\n-        if dispatch_arg.type.is_block():\n+    for i in range(len(dispatch_args)):\n+        dispatch_args[i] = core._to_tensor(dispatch_args[i], _builder)\n+        if dispatch_args[i].type.is_block():\n             all_scalar = False\n     if not all_scalar:\n-        if len(args) == 1:\n-            dispatch_args[0] = core._to_tensor(dispatch_args[0], _builder)\n-            ret_shape = dispatch_args[0].shape\n-        elif len(args) == 2:\n-            dispatch_args[0] = core._to_tensor(dispatch_args[0], _builder)\n-            dispatch_args[1] = core._to_tensor(dispatch_args[1], _builder)\n-            dispatch_args[0], dispatch_args[1] = semantic.binary_op_type_checking_impl(\n-                dispatch_args[0], dispatch_args[1], _builder)\n-            ret_shape = dispatch_args[0].shape\n-        else:\n-            for i in range(len(dispatch_args)):\n-                dispatch_args[i] = core._to_tensor(dispatch_args[i], _builder)\n-            broadcast_arg = dispatch_args[0]\n-            # Get the broadcast shape over all the arguments\n-            for i in range(len(dispatch_args)):\n-                _, broadcast_arg = semantic.binary_op_type_checking_impl(\n-                    dispatch_args[i], broadcast_arg, _builder)\n-            # Change the shape of each argument based on the broadcast shape\n-            for i in range(len(dispatch_args)):\n-                dispatch_args[i], _ = semantic.binary_op_type_checking_impl(\n-                    dispatch_args[i], broadcast_arg, _builder)\n-            ret_shape = broadcast_arg.shape\n+        broadcast_arg = dispatch_args[0]\n+        # Get the broadcast shape over all the arguments\n+        for i in range(len(dispatch_args)):\n+            _, broadcast_arg = semantic.binary_op_type_checking_impl(\n+                dispatch_args[i], broadcast_arg, _builder)\n+        # Change the shape of each argument based on the broadcast shape\n+        for i in range(len(dispatch_args)):\n+            dispatch_args[i], _ = semantic.binary_op_type_checking_impl(\n+                dispatch_args[i], broadcast_arg, _builder)\n+        ret_shape = broadcast_arg.shape\n     func = getattr(_builder, \"create_external_elementwise\")\n     return dispatch(func, lib_name, lib_path, dispatch_args, arg_type_symbol_dict, ret_shape, _builder)"}]