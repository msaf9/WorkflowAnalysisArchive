[{"filename": ".github/workflows/torchinductor/scripts/check_perf.py", "status": "modified", "additions": 14, "deletions": 2, "changes": 16, "file_content_changes": "@@ -23,7 +23,9 @@ def parse_output(file_path: str) -> dict:\n     return entries\n \n \n-def compare(baseline: dict, new: dict, threshold: float) -> bool:\n+def compare(baseline: dict, new: dict, threshold: float, geomean_threshold: float) -> bool:\n+    baseline_geomean = 1.0\n+    new_geomean = 1.0\n     for key in new:\n         if key not in baseline:\n             print(f\"New benchmark {key} not found in baseline\")\n@@ -35,17 +37,27 @@ def compare(baseline: dict, new: dict, threshold: float) -> bool:\n         elif new_latency > baseline_latency * (1 + threshold):\n             print(\n                 f\"New benchmark {key} is slower than baseline: {new_latency} vs {baseline_latency}\")\n+        baseline_geomean *= baseline[key].speedup\n+        new_geomean *= new[key].speedup\n+\n+    baseline_geomean = baseline_geomean ** (1 / len(baseline))\n+    new_geomean = new_geomean ** (1 / len(new))\n+    print(f\"Baseline geomean: {baseline_geomean}\")\n+    print(f\"New geomean: {new_geomean}\")\n+    assert new_geomean > baseline_geomean * (1 - geomean_threshold), \\\n+        f\"New geomean is slower than baseline: {new_geomean} vs {baseline_geomean}\"\n \n \n def main():\n     parser = argparse.ArgumentParser()\n     parser.add_argument('--baseline', required=True)\n     parser.add_argument('--new', required=True)\n     parser.add_argument('--threshold', type=float, default=0.1)\n+    parser.add_argument('--geomean-threshold', type=float, default=0.02)\n     args = parser.parse_args()\n     baseline = parse_output(args.baseline)\n     new = parse_output(args.new)\n-    compare(baseline, new, args.threshold)\n+    compare(baseline, new, args.threshold, args.geomean_threshold)\n \n \n main()"}]