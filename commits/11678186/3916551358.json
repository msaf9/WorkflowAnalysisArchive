[{"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 0, "deletions": 140, "changes": 140, "file_content_changes": "@@ -1169,7 +1169,6 @@ class BlockedToMMA : public mlir::RewritePattern {\n   }\n };\n \n-\n // Convert + trans + convert\n // x = convert_layout distributed -> #shared_x\n // y = trans x -> #shared_y\n@@ -1274,145 +1273,6 @@ class ConvertDotConvert : public mlir::RewritePattern {\n   }\n };\n \n-// Correct the versionMinor field in MmaEncodingAttr for Volta.\n-class UpdateMMAVersionMinorForVolta : public mlir::RewritePattern {\n-  const DenseMap<MmaEncodingAttr, MmaEncodingAttr> &mmaToUpdate;\n-  enum class Kind {\n-    kUnk,\n-    kCvtToMma,\n-    kCvtToDotOp,\n-    kDot,\n-    kConstant,\n-  };\n-  mutable Kind rewriteKind{Kind::kUnk};\n-\n-public:\n-  UpdateMMAVersionMinorForVolta(\n-      mlir::MLIRContext *ctx, llvm::StringRef opName,\n-      const DenseMap<MmaEncodingAttr, MmaEncodingAttr> &mmaToUpdate)\n-      : RewritePattern(opName, 1 /*benefit*/, ctx), mmaToUpdate(mmaToUpdate) {}\n-\n-  LogicalResult match(Operation *op) const override {\n-    MmaEncodingAttr mma;\n-    if (mmaToUpdate.empty())\n-      return failure();\n-    if (op->getNumResults() != 1)\n-      return failure();\n-    auto tensorTy = op->getResult(0).getType().dyn_cast<RankedTensorType>();\n-    if (!tensorTy)\n-      return failure();\n-\n-    // ConvertLayoutOp\n-    if (auto cvt = llvm::dyn_cast<ConvertLayoutOp>(op)) {\n-      // cvt X -> dot_operand\n-      if (auto dotOperand =\n-              tensorTy.getEncoding().dyn_cast<DotOperandEncodingAttr>()) {\n-        mma = dotOperand.getParent().dyn_cast<MmaEncodingAttr>();\n-        rewriteKind = Kind::kCvtToDotOp;\n-        if (mma && mmaToUpdate.count(mma))\n-          return success();\n-      }\n-      if ((mma = tensorTy.getEncoding().dyn_cast<MmaEncodingAttr>())) {\n-        // cvt X -> mma\n-        rewriteKind = Kind::kCvtToMma;\n-        if (mma && mmaToUpdate.count(mma))\n-          return success();\n-      }\n-    } else if (auto dot = llvm::dyn_cast<DotOp>(op)) {\n-      // DotOp\n-      mma = dot.d()\n-                .getType()\n-                .cast<RankedTensorType>()\n-                .getEncoding()\n-                .dyn_cast<MmaEncodingAttr>();\n-      rewriteKind = Kind::kDot;\n-    } else if (auto constant = llvm::dyn_cast<arith::ConstantOp>(op)) {\n-      // ConstantOp\n-      mma = tensorTy.getEncoding().dyn_cast<MmaEncodingAttr>();\n-      rewriteKind = Kind::kConstant;\n-    }\n-\n-    return success(mma && mmaToUpdate.count(mma));\n-  }\n-\n-  void rewrite(Operation *op, PatternRewriter &rewriter) const override {\n-    switch (rewriteKind) {\n-    case Kind::kDot:\n-      rewriteDot(op, rewriter);\n-      break;\n-    case Kind::kConstant:\n-      rewriteConstant(op, rewriter);\n-      break;\n-    case Kind::kCvtToDotOp:\n-      rewriteCvtDotOp(op, rewriter);\n-      break;\n-    case Kind::kCvtToMma:\n-      rewriteCvtToMma(op, rewriter);\n-      break;\n-    default:\n-      llvm::report_fatal_error(\"Not supported rewrite kind\");\n-    }\n-  }\n-\n-private:\n-  void rewriteCvtDotOp(Operation *op, PatternRewriter &rewriter) const {\n-    auto *ctx = op->getContext();\n-    auto cvt = llvm::cast<ConvertLayoutOp>(op);\n-    auto tensorTy = cvt.result().getType().cast<RankedTensorType>();\n-    auto dotOperand = tensorTy.getEncoding().cast<DotOperandEncodingAttr>();\n-    MmaEncodingAttr newMma =\n-        mmaToUpdate.lookup(dotOperand.getParent().cast<MmaEncodingAttr>());\n-    auto newDotOperand = DotOperandEncodingAttr::get(\n-        ctx, dotOperand.getOpIdx(), newMma, dotOperand.getIsMMAv1Row());\n-    auto newTensorTy = RankedTensorType::get(\n-        tensorTy.getShape(), tensorTy.getElementType(), newDotOperand);\n-    rewriter.replaceOpWithNewOp<ConvertLayoutOp>(op, newTensorTy,\n-                                                 cvt.getOperand());\n-  }\n-\n-  void rewriteDot(Operation *op, PatternRewriter &rewriter) const {\n-    auto *ctx = op->getContext();\n-    auto dot = llvm::cast<DotOp>(op);\n-    auto tensorTy = dot.d().getType().cast<RankedTensorType>();\n-    auto mma = tensorTy.getEncoding().cast<MmaEncodingAttr>();\n-    auto newMma = mmaToUpdate.lookup(mma);\n-    auto newTensorTy = RankedTensorType::get(tensorTy.getShape(),\n-                                             tensorTy.getElementType(), newMma);\n-    rewriter.replaceOpWithNewOp<DotOp>(op, newTensorTy, dot.a(), dot.b(),\n-                                       dot.c(), dot.allowTF32());\n-  }\n-\n-  void rewriteCvtToMma(Operation *op, PatternRewriter &rewriter) const {\n-    auto *ctx = op->getContext();\n-    auto cvt = llvm::cast<ConvertLayoutOp>(op);\n-    auto tensorTy = cvt.result().getType().cast<RankedTensorType>();\n-    auto mma = tensorTy.getEncoding().cast<MmaEncodingAttr>();\n-    auto newMma = mmaToUpdate.lookup(mma);\n-    auto newTensorTy = RankedTensorType::get(tensorTy.getShape(),\n-                                             tensorTy.getElementType(), newMma);\n-    rewriter.replaceOpWithNewOp<ConvertLayoutOp>(op, newTensorTy,\n-                                                 cvt.getOperand());\n-  }\n-\n-  void rewriteConstant(Operation *op, PatternRewriter &rewriter) const {\n-    auto *ctx = op->getContext();\n-    auto constant = llvm::cast<arith::ConstantOp>(op);\n-    auto tensorTy = constant.getResult().getType().dyn_cast<RankedTensorType>();\n-    auto mma = tensorTy.getEncoding().cast<MmaEncodingAttr>();\n-    auto newMma = mmaToUpdate.lookup(mma);\n-    auto newTensorTy = RankedTensorType::get(tensorTy.getShape(),\n-                                             tensorTy.getElementType(), newMma);\n-    if (auto attr = constant.getValue().dyn_cast<SplatElementsAttr>()) {\n-      auto newRet =\n-          SplatElementsAttr::get(newTensorTy, attr.getSplatValue<Attribute>());\n-      rewriter.replaceOpWithNewOp<arith::ConstantOp>(op, newTensorTy, newRet);\n-      return;\n-    }\n-\n-    assert(false && \"Not supported ConstantOp value type\");\n-  }\n-};\n-\n } // namespace\n \n #define GEN_PASS_CLASSES"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -891,9 +891,6 @@ def ttir_to_ttgir(mod, num_warps, num_stages, compute_capability):\n     # The combine pass converts blocked layout to mma layout\n     # for dot ops so that pipeline can get shared memory swizzled correctly.\n     pm.add_tritongpu_combine_pass(compute_capability)\n-    if compute_capability // 10 == 7:\n-        # The update_mma_for_volta pass helps to compute some information for MMA encoding specifically for MMAv1\n-        pm.add_triton_gpu_update_mma_for_volta_pass()\n     pm.add_tritongpu_pipeline_pass(num_stages)\n     # Prefetch must be done after pipeline pass because pipeline pass\n     # extracts slices from the original tensor.\n@@ -903,6 +900,9 @@ def ttir_to_ttgir(mod, num_warps, num_stages, compute_capability):\n     pm.add_tritongpu_combine_pass(compute_capability)\n     pm.add_licm_pass()\n     pm.add_tritongpu_combine_pass(compute_capability)\n+    if compute_capability // 10 == 7:\n+        # The update_mma_for_volta pass helps to compute some information for MMA encoding specifically for MMAv1\n+        pm.add_triton_gpu_update_mma_for_volta_pass()\n     pm.add_cse_pass()\n     pm.add_tritongpu_decompose_conversions_pass()\n     pm.add_cse_pass()"}]