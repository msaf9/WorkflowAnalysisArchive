[{"filename": ".github/workflows/compare-artifacts.yml", "status": "modified", "additions": 31, "deletions": 146, "changes": 177, "file_content_changes": "@@ -11,156 +11,41 @@ jobs:\n     runs-on: ubuntu-latest\n     if: ${{ github.event.workflow_run.conclusion == 'success' }}\n     steps:\n-      - name: Checkout\n-        uses: actions/checkout@v2\n-\n-      - name: Install gh CLI\n-        run: |\n-          sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key 23F3D4EA75716059\n-          echo \"deb [arch=$(dpkg --print-architecture)] https://cli.github.com/packages focal main\" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null\n-          sudo apt update\n-          sudo apt install gh\n-\n-      - name: Create artifacts directory\n-        run: |\n-          mkdir /tmp/artifacts\n-\n-      - name: Get the PR Number artifact\n-        uses: dawidd6/action-download-artifact@v2\n+      - name: 'Download artifact'\n+        uses: actions/github-script@v6\n         with:\n-          workflow: ${{ github.event.workflow_run.workflow_id }}\n-          workflow_conclusion: \"\"\n-          name: pr-number\n-          path: /tmp/artifacts\n-      - name: Read PR Number into GitHub environment variables\n-        run: echo \"PR_NUMBER=$(cat /tmp/artifacts/pr-number.txt)\" >> $GITHUB_ENV\n-      - name: Confirm the PR Number (Debugging)\n-        run: echo $PR_NUMBER\n-\n-      - name: Download latest main artifacts\n-        env:\n-          ARTIFACT_NAME: artifacts A100\n-          ARTIFACT_JOB_NAME: Integration-Tests-Nvidia\n-          MAX_NUM_ACTIONS_PAGES: 30\n-          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n-        run: |\n-          OWNER_REPO=\"${{ github.repository }}\"\n-          echo \"OWNER_REPO: $OWNER_REPO\"\n-          PR_NUMBERS=($(gh api --method GET repos/$OWNER_REPO/pulls -f state=closed | jq -r \".[] | select(.merged_at != null) | .number\"))\n-\n-          # Not all PRs go through integration tests\n-          success=0\n-          for PR_NUMBER in \"${PR_NUMBERS[@]}\"\n-          do\n-            echo \"Last merged PR number: $PR_NUMBER\"\n-            BRANCH_NAME=$(gh api repos/$OWNER_REPO/pulls/$PR_NUMBER --jq '.head.ref')\n-            echo \"BRANCH_NAME: $BRANCH_NAME\"\n-            USER_ID=$(gh api repos/$OWNER_REPO/pulls/$PR_NUMBER --jq '.user.id')\n-            echo \"USER_ID: $USER_ID\"\n-\n-            run_id_found=false\n-            page=1\n-            while true; do\n-              if [ \"$page\" -gt $MAX_NUM_ACTIONS_PAGES ]; then\n-                break\n-              fi\n-\n-              run_id=$(gh api --method GET \"repos/$OWNER_REPO/actions/runs?page=$page&per_page=100\" | jq --arg branch_name \"$BRANCH_NAME\" --arg run_name \"Integration Tests\" --arg user_id \"$USER_ID\" '.workflow_runs[] | select(.head_branch == $branch_name and .name == $run_name and .actor.id == ($user_id | tonumber))' | jq '.id' | head -1)\n-              if [ \"$run_id\" != \"\" ]; then\n-                echo \"First run ID on branch $BRANCH_NAME is: $run_id\"\n-                WORKFLOW_RUN_ID=$run_id\n-                run_id_found=true\n-                break\n-              fi\n-\n-              ((page++))\n-            done\n-            if ! $run_id_found; then\n-              echo \"No run_id found for PR ${PR_NUMBER}, moving to the next PR.\"\n-              continue\n-            fi\n-            echo \"WORKFLOW_RUN_ID: $WORKFLOW_RUN_ID\"\n-            ARTIFACT_URL=$(gh api repos/$OWNER_REPO/actions/runs/$WORKFLOW_RUN_ID/artifacts | jq --arg artifact_name \"$ARTIFACT_NAME\" '.artifacts[] | select(.name == $artifact_name).archive_download_url' --raw-output)\n-            echo \"ARTIFACT_URL: $ARTIFACT_URL\"\n-\n-            if [ -n \"$ARTIFACT_URL\" ]; then\n-              echo \"Downloading artifact: $ARTIFACT_URL\"\n-              cd /tmp/artifacts\n-              curl --location --remote-header-name -H \"Authorization: token $GH_TOKEN\" -o reference.zip \"$ARTIFACT_URL\"\n-              # Print the size of the downloaded artifact\n-              echo \"Artifact size (stat): $(stat --printf=\"%s bytes\" reference.zip)\"\n-              echo \"Artifact size (du): $(du -sh reference.zip)\"\n-              unzip reference.zip\n-              tar -xzf artifacts.tar.gz\n-              rm reference.zip\n-              rm artifacts.tar.gz\n-              mv cache reference\n-              success=1\n-              break\n-            fi\n-          done\n-\n-          if [ $success -eq 0 ]; then\n-            echo \"No artifact found with the name: $ARTIFACT_NAME\"\n-            exit 1\n-          fi\n-      - name: Download current job artifacts\n-        uses: dawidd6/action-download-artifact@v2\n-        with:\n-          workflow: ${{ github.event.workflow_run.workflow_id }}\n-          workflow_conclusion: \"\"\n-          name: artifacts A100\n-          path: /tmp/artifacts\n-      - name: Unzip current job artifacts\n-        run: |\n-          cd /tmp/artifacts\n-          # Print the size of the downloaded artifact\n-          echo \"Artifact size (stat): $(stat --printf=\"%s bytes\" artifacts.tar.gz)\"\n-          echo \"Artifact size (du): $(du -sh artifacts.tar.gz)\"\n-          tar -xzf artifacts.tar.gz\n-          rm artifacts.tar.gz\n-          mv cache current\n-      - name: Compare artifacts\n-        run: |\n-          set +e\n-          python3 python/test/tools/compare_files.py --path1 /tmp/artifacts/reference --path2 /tmp/artifacts/current\n-          exit_code=$?\n-          set -e\n-          echo $exit_code\n-          if [ $exit_code -eq 0 ]; then\n-            echo \"Artifacts are identical\"\n-            echo \"COMPARISON_RESULT=true\" >> $GITHUB_ENV\n-          elif [ $exit_code -eq 1 ]; then\n-            echo \"Artifacts are different\"\n-            echo \"COMPARISON_RESULT=false\" >> $GITHUB_ENV\n-          else\n-            echo \"Error while comparing artifacts\"\n-            echo \"COMPARISON_RESULT=error\" >> $GITHUB_ENV\n-          fi\n-          echo \"COMPARISON_RESULT=${env.COMPARISON_RESULT}\"\n-      - name: Check exit code and handle failure\n-        if: ${{ env.COMPARISON_RESULT == 'error' }}\n-        run: |\n-          echo \"Error while comparing artifacts\"\n-          exit 1\n+          script: |\n+            let allArtifacts = await github.rest.actions.listWorkflowRunArtifacts({\n+               owner: context.repo.owner,\n+               repo: context.repo.repo,\n+               run_id: context.payload.workflow_run.id,\n+            });\n+            let matchArtifact = allArtifacts.data.artifacts.filter((artifact) => {\n+              return artifact.name == \"pr_number\"\n+            })[0];\n+            let download = await github.rest.actions.downloadArtifact({\n+               owner: context.repo.owner,\n+               repo: context.repo.repo,\n+               artifact_id: matchArtifact.id,\n+               archive_format: 'zip',\n+            });\n+            let fs = require('fs');\n+            fs.writeFileSync(`${process.env.GITHUB_WORKSPACE}/pr_number.zip`, Buffer.from(download.data));\n \n-      - name: Upload results as artifact\n-        uses: actions/upload-artifact@v2\n-        with:\n-          name: kernels-reference-check\n-          path: kernels_reference_check.txt\n+      - name: 'Unzip artifact'\n+        run: unzip pr_number.zip\n \n-      - name: Check output and comment on PR\n-        if: ${{ env.COMPARISON_RESULT == 'false' }}\n-        uses: actions/github-script@v5\n+      - name: 'Comment on PR'\n+        uses: actions/github-script@v6\n         with:\n-          github-token: ${{ secrets.CI_ACCESS_TOKEN }}\n+          github-token: ${{ secrets.GITHUB_TOKEN }}\n           script: |\n-            const issue_number = context.payload.pull_request.number;\n-            const message = `:warning: **This PR does not produce bitwise identical kernels as the branch it's merged against.** Please check artifacts for details.`;\n+            let fs = require('fs');\n+            let issue_number = Number(fs.readFileSync('./pr_number'));\n+            echo $issue_number\n             await github.rest.issues.createComment({\n-                owner: context.repo.owner,\n-                repo: context.repo.repo,\n-                issue_number: issue_number,\n-                body: message\n+              owner: context.repo.owner,\n+              repo: context.repo.repo,\n+              issue_number: issue_number,\n+              body: 'Thank you for the PR!'\n             });"}, {"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 212, "deletions": 204, "changes": 416, "file_content_changes": "@@ -43,209 +43,217 @@ jobs:\n         runner: ${{fromJson(needs.Runner-Preparation.outputs.matrix-required)}}\n \n     steps:\n-      - name: Checkout\n-        uses: actions/checkout@v2\n-\n-      - name: Set CUDA ENV\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n-        run: |\n-          echo \"BACKEND=CUDA\" >> \"${GITHUB_ENV}\"\n-          echo \"ENABLE_TMA=0\" >> \"${GITHUB_ENV}\"\n-          echo \"ENABLE_MMA_V3=0\" >> \"${GITHUB_ENV}\"\n-          echo \"TRITON_DISABLE_LINE_INFO=1\" >> \"${GITHUB_ENV}\"\n-\n-      - name: Clear cache\n-        run: |\n-          rm -rf ~/.triton\n-\n-      - name: Update PATH\n-        run: |\n-          echo \"PATH=${HOME}/.local/bin:${PATH}\" >> \"${GITHUB_ENV}\"\n-\n-      - name: Install Triton\n-        if: ${{ env.BACKEND == 'CUDA'}}\n-        run: |\n-          cd python\n-          python3 -m pip install --upgrade pip\n-          python3 -m pip install cmake==3.24\n-          python3 -m pip install --no-build-isolation -vvv '.[tests]'\n-          python3 -m pip install pytest-xdist\n-\n-      - name: Run lit tests\n-        if: ${{ env.BACKEND == 'CUDA'}}\n-        run: |\n-          python3 -m pip install lit\n-          cd python\n-          LIT_TEST_DIR=\"build/$(ls build | grep -i cmake)/test\"\n-          if [ ! -d \"${LIT_TEST_DIR}\" ]; then\n-            echo \"Coult not find '${LIT_TEST_DIR}'\" ; exit -1\n-          fi\n-          lit -v \"${LIT_TEST_DIR}\"\n-\n-      - name: Enable MMAV3 and TMA\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'H100')}}\n-        run: |\n-          echo \"ENABLE_TMA=1\" >> \"${GITHUB_ENV}\"\n-          echo \"ENABLE_MMA_V3=1\" >> \"${GITHUB_ENV}\"\n-\n-      - name: Run python tests on CUDA with ENABLE_TMA=1 and ENABLE_MMA_V3=1\n-        if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '1' && env.ENABLE_MMA_V3 == '1'}}\n-        run: |\n-          cd python/test/unit\n-          python3 -m pytest -n 8 --ignore=runtime --ignore=operators --ignore=language/test_line_info.py\n-          # run runtime tests serially to avoid race condition with cache handling.\n-          python3 -m pytest runtime/\n-          # run test_line_info.py separately with TRITON_DISABLE_LINE_INFO=0\n-          TRITON_DISABLE_LINE_INFO=0 python3 -m pytest language/test_line_info.py\n-\n-      - name: Run python tests on CUDA with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n-        if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '0' && env.ENABLE_MMA_V3 == '0'}}\n+      # - name: Checkout\n+      #   uses: actions/checkout@v2\n+\n+      # - name: Set CUDA ENV\n+      #   if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n+      #   run: |\n+      #     echo \"BACKEND=CUDA\" >> \"${GITHUB_ENV}\"\n+      #     echo \"ENABLE_TMA=0\" >> \"${GITHUB_ENV}\"\n+      #     echo \"ENABLE_MMA_V3=0\" >> \"${GITHUB_ENV}\"\n+      #     echo \"TRITON_DISABLE_LINE_INFO=1\" >> \"${GITHUB_ENV}\"\n+\n+      # - name: Clear cache\n+      #   run: |\n+      #     rm -rf ~/.triton\n+\n+      # - name: Update PATH\n+      #   run: |\n+      #     echo \"PATH=${HOME}/.local/bin:${PATH}\" >> \"${GITHUB_ENV}\"\n+\n+      # - name: Install Triton\n+      #   if: ${{ env.BACKEND == 'CUDA'}}\n+      #   run: |\n+      #     cd python\n+      #     python3 -m pip install --upgrade pip\n+      #     python3 -m pip install cmake==3.24\n+      #     python3 -m pip install --no-build-isolation -vvv '.[tests]'\n+      #     python3 -m pip install pytest-xdist\n+\n+      # - name: Run lit tests\n+      #   if: ${{ env.BACKEND == 'CUDA'}}\n+      #   run: |\n+      #     python3 -m pip install lit\n+      #     cd python\n+      #     LIT_TEST_DIR=\"build/$(ls build | grep -i cmake)/test\"\n+      #     if [ ! -d \"${LIT_TEST_DIR}\" ]; then\n+      #       echo \"Coult not find '${LIT_TEST_DIR}'\" ; exit -1\n+      #     fi\n+      #     lit -v \"${LIT_TEST_DIR}\"\n+\n+      # - name: Enable MMAV3 and TMA\n+      #   if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'H100')}}\n+      #   run: |\n+      #     echo \"ENABLE_TMA=1\" >> \"${GITHUB_ENV}\"\n+      #     echo \"ENABLE_MMA_V3=1\" >> \"${GITHUB_ENV}\"\n+\n+      # - name: Run python tests on CUDA with ENABLE_TMA=1 and ENABLE_MMA_V3=1\n+      #   if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '1' && env.ENABLE_MMA_V3 == '1'}}\n+      #   run: |\n+      #     cd python/test/unit\n+      #     python3 -m pytest -n 8 --ignore=runtime --ignore=operators --ignore=language/test_line_info.py\n+      #     # run runtime tests serially to avoid race condition with cache handling.\n+      #     python3 -m pytest runtime/\n+      #     # run test_line_info.py separately with TRITON_DISABLE_LINE_INFO=0\n+      #     TRITON_DISABLE_LINE_INFO=0 python3 -m pytest language/test_line_info.py\n+\n+      # - name: Run python tests on CUDA with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n+      #   if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '0' && env.ENABLE_MMA_V3 == '0'}}\n+      #   run: |\n+      #     cd python/test/unit\n+      #     python3 -m pytest -n 8 --ignore=runtime --ignore=hopper --ignore=operators --ignore=language/test_line_info.py\n+      #     # run runtime tests serially to avoid race condition with cache handling.\n+      #     python3 -m pytest runtime/\n+      #     # run test_line_info.py separately with TRITON_DISABLE_LINE_INFO=0\n+      #     TRITON_DISABLE_LINE_INFO=0 python3 -m pytest language/test_line_info.py\n+\n+      # - name: Clear cache\n+      #   run: |\n+      #     rm -rf ~/.triton\n+\n+      # - name: Run partial tests on CUDA with ENABLE_TMA=1 and ENABLE_MMA_V3=1\n+      #   if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '1' && env.ENABLE_MMA_V3 == '1'}}\n+      #   run: |\n+      #     cd python/test/unit\n+      #     python3 -m pytest -n 8 operators\n+\n+      # - name: Run partial tests on CUDA with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n+      #   if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '0' && env.ENABLE_MMA_V3 == '0'}}\n+      #   run: |\n+      #     cd python/test/unit\n+      #     python3 -m pytest -n 8 operators\n+\n+      # - name: Create artifacts archive\n+      #   if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n+      #   run: |\n+      #     cd ~/.triton\n+      #     tar -czf artifacts.tar.gz cache\n+\n+      - name: Save PR number\n+        env:\n+          PR_NUMBER: ${{ github.event.number }}\n         run: |\n-          cd python/test/unit\n-          python3 -m pytest -n 8 --ignore=runtime --ignore=hopper --ignore=operators --ignore=language/test_line_info.py\n-          # run runtime tests serially to avoid race condition with cache handling.\n-          python3 -m pytest runtime/\n-          # run test_line_info.py separately with TRITON_DISABLE_LINE_INFO=0\n-          TRITON_DISABLE_LINE_INFO=0 python3 -m pytest language/test_line_info.py\n-\n-      - name: Clear cache\n-        run: |\n-          rm -rf ~/.triton\n-\n-      - name: Run partial tests on CUDA with ENABLE_TMA=1 and ENABLE_MMA_V3=1\n-        if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '1' && env.ENABLE_MMA_V3 == '1'}}\n-        run: |\n-          cd python/test/unit\n-          python3 -m pytest -n 8 operators\n-\n-      - name: Run partial tests on CUDA with ENABLE_TMA=0 and ENABLE_MMA_V3=0\n-        if: ${{ env.BACKEND == 'CUDA' && env.ENABLE_TMA == '0' && env.ENABLE_MMA_V3 == '0'}}\n-        run: |\n-          cd python/test/unit\n-          python3 -m pytest -n 8 operators\n-\n-      - name: Create artifacts archive\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n-        run: |\n-          cd ~/.triton\n-          tar -czf artifacts.tar.gz cache\n-\n-      - name: Save PR number to file\n-        run: echo ${{ github.event.pull_request.number }} > pr-number.txt\n-\n-      - name: Upload artifacts archive\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n-        uses: actions/upload-artifact@v2\n-        with:\n-          name: artifacts ${{ matrix.runner[1] }}\n-          path: ~/.triton/artifacts.tar.gz\n-\n-      - name: Upload PR number artifact\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n-        uses: actions/upload-artifact@v2\n+          mkdir -p ./pr\n+          echo $PR_NUMBER > ./pr/pr_number\n+      - uses: actions/upload-artifact@v3\n         with:\n-          name: pr-number\n-          path: pr-number.txt\n-\n-      - name: Run CXX unittests\n-        if: ${{ env.BACKEND == 'CUDA'}}\n-        run: |\n-          cd python\n-          cd \"build/$(ls build | grep -i cmake)\"\n-          ctest\n-\n-      - name: Regression tests\n-        if: ${{ contains(matrix.runner, 'A100') }}\n-        run: |\n-          python3 -m pip install pytest-rerunfailures\n-          cd python/test/regression\n-          sudo nvidia-smi -i 0 -pm 1\n-          sudo nvidia-smi -i 0 --lock-gpu-clocks=1280,1280\n-          python3 -m pytest -vs . --reruns 10\n-          sudo nvidia-smi -i 0 -rgc\n-\n-  Integration-Tests-Third-Party:\n-    needs: Runner-Preparation\n-    if: false\n-\n-    runs-on: ${{ matrix.runner }}\n-\n-    strategy:\n-      matrix:\n-        runner: ${{fromJson(needs.Runner-Preparation.outputs.matrix-optional)}}\n-\n-    steps:\n-      - name: Checkout\n-        uses: actions/checkout@v2\n-\n-      - name: Set ROCM ENV\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'gfx908')}}\n-        run: |\n-          echo \"BACKEND=ROCM\" >> \"${GITHUB_ENV}\"\n-\n-      - name: Set XPU ENV\n-        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'arc770')}}\n-        run: |\n-          echo \"BACKEND=XPU\" >> \"${GITHUB_ENV}\"\n-\n-      - name: Clear cache\n-        run: |\n-          rm -rf ~/.triton\n-\n-      - name: Update PATH\n-        run: |\n-          echo \"PATH=${HOME}/.local/bin:${PATH}\" >> \"${GITHUB_ENV}\"\n-\n-      - name: Check pre-commit\n-        if: ${{ matrix.runner != 'macos-10.15' && (matrix.runner[1] != 'arc770') }}\n-        run: |\n-          python3 -m pip install --upgrade pre-commit\n-          python3 -m pre_commit run --all-files --verbose\n-\n-      - name: Check pre-commit arc770\n-        if: ${{ matrix.runner != 'macos-10.15' && (matrix.runner[1] == 'arc770') }}\n-        run: |\n-          source ${HOME}/triton_vars.sh\n-          source ${HOME}/miniconda3/bin/activate\n-          conda activate triton-xpu-ci\n-          python3 -m pip install --upgrade pre-commit\n-          python3 -m pre_commit run --all-files\n-\n-      - name: Install Triton on ROCM\n-        if: ${{ env.BACKEND == 'ROCM'}}\n-        run: |\n-          cd python\n-          python3 -m pip install --upgrade pip\n-          python3 -m pip install cmake==3.24\n-          python3 -m pip install torch==1.13.1 --index-url https://download.pytorch.org/whl/rocm5.2\n-          python3 -m pip install --no-build-isolation -vvv '.[tests]'\n-\n-      - name: Install Triton on XPU\n-        if: ${{ env.BACKEND == 'XPU'}}\n-        run: |\n-          source ${HOME}/triton_vars.sh\n-          source ${HOME}/miniconda3/bin/activate\n-          conda activate triton-xpu-ci\n-          git submodule update --init --recursive\n-          cd python\n-          python3 -m pip install --upgrade pip\n-          python3 -m pip install cmake==3.24\n-          export TRITON_CODEGEN_INTEL_XPU_BACKEND=1\n-          python3 -m pip uninstall -y triton\n-          python3 setup.py build\n-          python3 -m pip install --no-build-isolation -vvv '.[tests]'\n-\n-      - name: Run python tests on ROCM\n-        if: ${{ env.BACKEND == 'ROCM'}}\n-        run: |\n-          cd python/test/unit/language\n-          python3 -m pytest --capture=tee-sys -rfs --verbose \"test_core.py::test_empty_kernel\"\n-\n-      - name: Run python tests on XPU\n-        if: ${{ env.BACKEND == 'XPU'}}\n-        run: |\n-          source ${HOME}/triton_vars.sh\n-          source ${HOME}/miniconda3/bin/activate\n-          conda activate triton-xpu-ci\n-          cd python/test/backend/third_party_backends\n-          python3 -m pytest --capture=tee-sys -rfs --verbose --backend xpu\n+          name: pr_number\n+          path: pr/\n+\n+      # - name: Upload artifacts archive\n+      #   if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n+      #   uses: actions/upload-artifact@v2\n+      #   with:\n+      #     name: artifacts ${{ matrix.runner[1] }}\n+      #     path: ~/.triton/artifacts.tar.gz\n+\n+      # - name: Upload PR number artifact\n+      #   if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n+      #   uses: actions/upload-artifact@v2\n+      #   with:\n+      #     name: pr-number\n+      #     path: pr-number.txt\n+\n+      # - name: Run CXX unittests\n+      #   if: ${{ env.BACKEND == 'CUDA'}}\n+      #   run: |\n+      #     cd python\n+      #     cd \"build/$(ls build | grep -i cmake)\"\n+      #     ctest\n+\n+      # - name: Regression tests\n+      #   if: ${{ contains(matrix.runner, 'A100') }}\n+      #   run: |\n+      #     python3 -m pip install pytest-rerunfailures\n+      #     cd python/test/regression\n+      #     sudo nvidia-smi -i 0 -pm 1\n+      #     sudo nvidia-smi -i 0 --lock-gpu-clocks=1280,1280\n+      #     python3 -m pytest -vs . --reruns 10\n+      #     sudo nvidia-smi -i 0 -rgc\n+\n+  # Integration-Tests-Third-Party:\n+  #   needs: Runner-Preparation\n+  #   if: false\n+\n+  #   runs-on: ${{ matrix.runner }}\n+\n+  #   strategy:\n+  #     matrix:\n+  #       runner: ${{fromJson(needs.Runner-Preparation.outputs.matrix-optional)}}\n+\n+  #   steps:\n+  #     - name: Checkout\n+  #       uses: actions/checkout@v2\n+\n+  #     - name: Set ROCM ENV\n+  #       if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'gfx908')}}\n+  #       run: |\n+  #         echo \"BACKEND=ROCM\" >> \"${GITHUB_ENV}\"\n+\n+  #     - name: Set XPU ENV\n+  #       if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'arc770')}}\n+  #       run: |\n+  #         echo \"BACKEND=XPU\" >> \"${GITHUB_ENV}\"\n+\n+  #     - name: Clear cache\n+  #       run: |\n+  #         rm -rf ~/.triton\n+\n+  #     - name: Update PATH\n+  #       run: |\n+  #         echo \"PATH=${HOME}/.local/bin:${PATH}\" >> \"${GITHUB_ENV}\"\n+\n+  #     - name: Check pre-commit\n+  #       if: ${{ matrix.runner != 'macos-10.15' && (matrix.runner[1] != 'arc770') }}\n+  #       run: |\n+  #         python3 -m pip install --upgrade pre-commit\n+  #         python3 -m pre_commit run --all-files --verbose\n+\n+  #     - name: Check pre-commit arc770\n+  #       if: ${{ matrix.runner != 'macos-10.15' && (matrix.runner[1] == 'arc770') }}\n+  #       run: |\n+  #         source ${HOME}/triton_vars.sh\n+  #         source ${HOME}/miniconda3/bin/activate\n+  #         conda activate triton-xpu-ci\n+  #         python3 -m pip install --upgrade pre-commit\n+  #         python3 -m pre_commit run --all-files\n+\n+  #     - name: Install Triton on ROCM\n+  #       if: ${{ env.BACKEND == 'ROCM'}}\n+  #       run: |\n+  #         cd python\n+  #         python3 -m pip install --upgrade pip\n+  #         python3 -m pip install cmake==3.24\n+  #         python3 -m pip install torch==1.13.1 --index-url https://download.pytorch.org/whl/rocm5.2\n+  #         python3 -m pip install --no-build-isolation -vvv '.[tests]'\n+\n+  #     - name: Install Triton on XPU\n+  #       if: ${{ env.BACKEND == 'XPU'}}\n+  #       run: |\n+  #         source ${HOME}/triton_vars.sh\n+  #         source ${HOME}/miniconda3/bin/activate\n+  #         conda activate triton-xpu-ci\n+  #         git submodule update --init --recursive\n+  #         cd python\n+  #         python3 -m pip install --upgrade pip\n+  #         python3 -m pip install cmake==3.24\n+  #         export TRITON_CODEGEN_INTEL_XPU_BACKEND=1\n+  #         python3 -m pip uninstall -y triton\n+  #         python3 setup.py build\n+  #         python3 -m pip install --no-build-isolation -vvv '.[tests]'\n+\n+  #     - name: Run python tests on ROCM\n+  #       if: ${{ env.BACKEND == 'ROCM'}}\n+  #       run: |\n+  #         cd python/test/unit/language\n+  #         python3 -m pytest --capture=tee-sys -rfs --verbose \"test_core.py::test_empty_kernel\"\n+\n+  #     - name: Run python tests on XPU\n+  #       if: ${{ env.BACKEND == 'XPU'}}\n+  #       run: |\n+  #         source ${HOME}/triton_vars.sh\n+  #         source ${HOME}/miniconda3/bin/activate\n+  #         conda activate triton-xpu-ci\n+  #         cd python/test/backend/third_party_backends\n+  #         python3 -m pytest --capture=tee-sys -rfs --verbose --backend xpu"}]