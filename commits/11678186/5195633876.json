[{"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -139,7 +139,7 @@ struct ConvertLayoutOpConversion\n       SmallVector<Value> mmaColIdx(4);\n       SmallVector<Value> mmaRowIdx(2);\n       Value threadId = getThreadId(rewriter, loc);\n-      Value warpSize = i32_val(32);\n+      Value warpSize = i32_val(getTypeConverter()->getThreadsPerWarp());\n       Value laneId = urem(threadId, warpSize);\n       Value warpId = udiv(threadId, warpSize);\n       // TODO: fix the bug in MMAEncodingAttr document"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -363,7 +363,7 @@ struct ReduceOpConversion\n     }\n \n     Value threadId = getThreadId(rewriter, loc);\n-    Value warpSize = i32_val(32);\n+    Value warpSize = i32_val(getTypeConverter()->getThreadsPerWarp());\n     Value warpId = udiv(threadId, warpSize);\n     Value laneId = urem(threadId, warpSize);\n \n@@ -413,7 +413,7 @@ struct ReduceOpConversion\n     // Each thread needs to process:\n     //   elemsPerThread = sizeInterWarps * s1 * s2 .. Sn / numThreads\n     unsigned numThreads =\n-        product<unsigned>(triton::gpu::getWarpsPerCTA(srcLayout)) * 32;\n+        product<unsigned>(triton::gpu::getWarpsPerCTA(srcLayout)) * getTypeConverter()->getThreadsPerWarp();\n     unsigned elemsPerThread = std::max<unsigned>(elems / numThreads, 1);\n     Value readOffset = threadId;\n     for (unsigned round = 0; round < elemsPerThread; ++round) {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -478,7 +478,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n       auto warpsPerCTA = triton::gpu::getWarpsPerCTA(layout);\n       auto order = triton::gpu::getOrder(layout);\n       auto shapePerCTA = triton::gpu::getShapePerCTA(layout, shape);\n-      Value warpSize = i32_val(32);\n+      Value warpSize = i32_val(getTypeConverter()->getThreadsPerWarp());\n       Value laneId = urem(tid, warpSize);\n       Value warpId = udiv(tid, warpSize);\n       SmallVector<Value> multiDimWarpId =\n@@ -707,7 +707,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n       const BlockedEncodingAttr &blocked_layout, RankedTensorType type) const {\n     auto shape = type.getShape();\n     Value threadId = getThreadId(rewriter, loc);\n-    Value warpSize = i32_val(32);\n+    Value warpSize = i32_val(getTypeConverter()->getThreadsPerWarp());\n     Value laneId = urem(threadId, warpSize);\n     Value warpId = udiv(threadId, warpSize);\n     auto sizePerThread = blocked_layout.getSizePerThread();\n@@ -933,7 +933,7 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     SmallVector<Value> warpsPerCTA = {i32_val(_warpsPerCTA[0]),\n                                       i32_val(_warpsPerCTA[1])};\n     Value threadId = getThreadId(rewriter, loc);\n-    Value warpSize = i32_val(32);\n+    Value warpSize = i32_val(getTypeConverter()->getThreadsPerWarp());\n     Value laneId = urem(threadId, warpSize);\n     Value warpId = udiv(threadId, warpSize);\n     Value warpId0 = urem(urem(warpId, warpsPerCTA[0]), i32_val(shape[0] / 16));"}]