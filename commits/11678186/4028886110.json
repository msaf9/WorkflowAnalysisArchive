[{"filename": "lib/Conversion/TritonGPUToLLVM/DotOpHelpers.h", "status": "modified", "additions": 20, "deletions": 2, "changes": 22, "file_content_changes": "@@ -1123,8 +1123,23 @@ class MMA16816SmemLoader {\n     Value ptr = getPtr(ptrIdx);\n \n     // The struct should have exactly the same element types.\n+    auto resTy = matTy.cast<LLVM::LLVMStructType>();\n     Type elemTy = matTy.cast<LLVM::LLVMStructType>().getBody()[0];\n \n+    // For some reasons, LLVM's NVPTX backend inserts unnecessary (?) integer\n+    // instructions to pack & unpack sub-word integers. A workaround is to\n+    // store the results of ldmatrix in i32\n+    if (auto vecElemTy = elemTy.dyn_cast<VectorType>()) {\n+      Type elemElemTy = vecElemTy.getElementType();\n+      if (auto intTy = elemElemTy.dyn_cast<IntegerType>()) {\n+        if (intTy.getWidth() <= 16) {\n+          elemTy = rewriter.getI32Type();\n+          resTy = LLVM::LLVMStructType::getLiteral(\n+              ctx, SmallVector<Type>(4, elemTy));\n+        }\n+      }\n+    }\n+\n     if (canUseLdmatrix) {\n       Value sOffset =\n           mul(i32_val(matIdx[order[1]] * sMatStride * sMatShape), sStride);\n@@ -1143,7 +1158,7 @@ class MMA16816SmemLoader {\n \n       // The result type is 4xi32, each i32 is composed of 2xf16\n       // elements (adjacent two columns in a row) or a single f32 element.\n-      Value resV4 = builder.launch(rewriter, loc, matTy);\n+      Value resV4 = builder.launch(rewriter, loc, resTy);\n       return {extract_val(elemTy, resV4, i32_arr_attr(0)),\n               extract_val(elemTy, resV4, i32_arr_attr(1)),\n               extract_val(elemTy, resV4, i32_arr_attr(2)),\n@@ -1177,6 +1192,8 @@ class MMA16816SmemLoader {\n       }\n       return {retElems[0], retElems[1], retElems[2], retElems[3]};\n     } else if (elemBytes == 1 && needTrans) { // work with int8\n+      // Can't use i32 here. Use LLVM's VectorType\n+      elemTy = matTy.cast<LLVM::LLVMStructType>().getBody()[0];\n       std::array<std::array<Value, 4>, 2> ptrs;\n       ptrs[0] = {\n           getPtr(ptrIdx),\n@@ -1235,7 +1252,8 @@ class MMA16816SmemLoader {\n         }\n       }\n \n-      return {i8v4Elems[0], i8v4Elems[1], i8v4Elems[2], i8v4Elems[3]};\n+      return {bitcast(i8v4Elems[0], i32_ty), bitcast(i8v4Elems[1], i32_ty),\n+              bitcast(i8v4Elems[2], i32_ty), bitcast(i8v4Elems[3], i32_ty)};\n     }\n \n     assert(false && \"Invalid smem load\");"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "file_content_changes": "@@ -97,6 +97,15 @@ class TritonGPUToLLVMTypeConverter : public LLVMTypeConverter {\n           Type targetTy;\n           if (targetTyMap.count(elemTy.getIntOrFloatBitWidth())) {\n             targetTy = targetTyMap.lookup(elemTy.getIntOrFloatBitWidth());\n+            // <2xi16>/<4xi8> => i32\n+            // We are doing this because NVPTX inserts extra integer instrs to\n+            // pack & unpack vectors of sub-word integers\n+            // Note: this needs to be synced with\n+            //       DotOpMmaV2ConversionHelper::loadX4\n+            if (elemTy.isa<IntegerType>() &&\n+                (elemTy.getIntOrFloatBitWidth() == 8 ||\n+                 elemTy.getIntOrFloatBitWidth() == 16))\n+              targetTy = IntegerType::get(ctx, 32);\n           } else {\n             assert(false && \"Unsupported element type\");\n           }"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -159,6 +159,12 @@ LogicalResult Prefetcher::initialize() {\n \n   for (triton::DotOp dot : dotsInFor) {\n     auto kSize = dot.a().getType().cast<RankedTensorType>().getShape()[1];\n+\n+    // works better with nvidia tensor cores\n+    unsigned elementWidth =\n+        dot.a().getType().cast<RankedTensorType>().getElementTypeBitWidth();\n+    prefetchWidth = 256 / elementWidth;\n+\n     // Skip prefetching if kSize is less than prefetchWidth\n     if (kSize < prefetchWidth)\n       continue;"}, {"filename": "python/setup.py", "status": "modified", "additions": 21, "deletions": 7, "changes": 28, "file_content_changes": "@@ -144,8 +144,10 @@ def build_extension(self, ext):\n             \"-DPython3_EXECUTABLE:FILEPATH=\" + sys.executable,\n             \"-DCMAKE_VERBOSE_MAKEFILE:BOOL=ON\",\n             \"-DPYTHON_INCLUDE_DIRS=\" + python_include_dir,\n-            \"-DLLVM_EXTERNAL_LIT=\" + lit_dir,\n-        ] + thirdparty_cmake_args\n+        ]\n+        if lit_dir is not None:\n+            cmake_args.append(\"-DLLVM_EXTERNAL_LIT=\" + lit_dir)\n+        cmake_args.extend(thirdparty_cmake_args)\n \n         # configuration\n         cfg = get_build_type()\n@@ -166,6 +168,22 @@ def build_extension(self, ext):\n         subprocess.check_call([\"cmake\", \"--build\", \".\"] + build_args, cwd=self.build_temp)\n \n \n+package_data = {\n+    \"triton/ops\": [\"*.c\"],\n+    \"triton/ops/blocksparse\": [\"*.c\"],\n+    \"triton/language\": [\"*.bc\"],\n+}\n+\n+if os.getenv(\"TRITION_PACKAGE_CUDA_DEPS\"):\n+    base_dir = os.path.dirname(__file__)\n+    cuda_dir = os.getenv(\"CUDA_HOME\", \"/usr/local/cuda\")\n+    triton_dir = os.path.join(base_dir, \"triton\")\n+    os.makedirs(os.path.join(triton_dir, \"include\"), exist_ok=True)\n+    os.makedirs(os.path.join(triton_dir, \"bin\"), exist_ok=True)\n+    shutil.copy(os.path.join(cuda_dir, \"include\", \"cuda.h\"), os.path.join(triton_dir, \"include\"))\n+    shutil.copy(os.path.join(cuda_dir, \"bin\", \"ptxas\"), os.path.join(triton_dir, \"bin\"))\n+    package_data[\"triton\"] = [\"include/cuda.h\", \"bin/ptxas\"]\n+\n setup(\n     name=\"triton\",\n     version=\"2.0.0\",\n@@ -180,11 +198,7 @@ def build_extension(self, ext):\n         \"torch\",\n         \"lit\",\n     ],\n-    package_data={\n-        \"triton/ops\": [\"*.c\"],\n-        \"triton/ops/blocksparse\": [\"*.c\"],\n-        \"triton/language\": [\"*.bc\"]\n-    },\n+    package_data=package_data,\n     include_package_data=True,\n     ext_modules=[CMakeExtension(\"triton\", \"triton/_C/\")],\n     cmdclass={\"build_ext\": CMakeBuild},"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "file_content_changes": "@@ -987,6 +987,9 @@ def path_to_ptxas():\n         \"/usr\",\n         os.environ.get('CUDA_PATH', default_cuda_dir())\n     ]\n+    if not os.getenv(\"TRITON_IGNORE_BUNDLED_PTXAS\"):\n+        prefixes.insert(0, os.path.dirname(__file__))\n+\n     for prefix in prefixes:\n         ptxas = os.path.join(prefix, \"bin\", \"ptxas\")\n         if os.path.exists(ptxas):\n@@ -1287,6 +1290,11 @@ def _build(name, src, srcdir):\n     cuda_lib_dirs = libcuda_dirs()\n     cuda_path = os.environ.get('CUDA_PATH', default_cuda_dir())\n     cu_include_dir = os.path.join(cuda_path, \"include\")\n+    triton_include_dir = os.path.join(os.path.dirname(__file__), \"include\")\n+    cuda_header = os.path.join(cu_include_dir, \"cuda.h\")\n+    triton_cuda_header = os.path.join(triton_include_dir, \"cuda.h\")\n+    if not os.path.exists(cuda_header) and os.path.exists(triton_cuda_header):\n+        cu_include_dir = triton_include_dir\n     suffix = sysconfig.get_config_var('EXT_SUFFIX')\n     so = os.path.join(srcdir, '{name}{suffix}'.format(name=name, suffix=suffix))\n     # try to avoid setuptools if possible\n@@ -1296,6 +1304,8 @@ def _build(name, src, srcdir):\n         clang = shutil.which(\"clang\")\n         gcc = shutil.which(\"gcc\")\n         cc = gcc if gcc is not None else clang\n+        if cc is None:\n+            raise RuntimeError(\"Failed to find C compiler. Please specify via CC environment variable.\")\n     py_include_dir = get_paths()[\"include\"]\n \n     cc_cmd = [cc, src, \"-O3\", f\"-I{cu_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", \"-lcuda\", \"-o\", so]"}]