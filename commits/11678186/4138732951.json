[{"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -162,7 +162,8 @@ def TT_StoreOp : TT_Op<\"store\",\n     let summary = \"store\";\n \n     let arguments = (ins TT_PtrLike:$ptr, TT_Type:$value, Optional<TT_BoolLike>:$mask,\n-                     TT_CacheModifierAttr:$cache, TT_EvictionPolicyAttr:$evict);\n+                     DefaultValuedAttr<TT_CacheModifierAttr, \"triton::CacheModifier::NONE\">:$cache, \n+                     DefaultValuedAttr<TT_EvictionPolicyAttr, \"triton::EvictionPolicy::NORMAL\">:$evict);\n \n     let builders = [\n         OpBuilder<(ins \"Value\":$ptr, \"Value\":$value, \"triton::CacheModifier\":$cache,"}, {"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -851,7 +851,7 @@ ChangeResult AxisInfoAnalysis::visitOperation(\n     auto vals = attr.cast<DenseElementsAttr>().getValues<int>();\n     newConstancy = AxisInfo::DimVectorT(vals.begin(), vals.end());\n   }\n-  curr = mlir::AxisInfo(newContiguity, newDivisibility, newConstancy);\n+  curr = mlir::AxisInfo(newContiguity, newDivisibility, newConstancy, curr.getConstantValue());\n   // join all lattice elements\n   ChangeResult result = ChangeResult::NoChange;\n   for (Value value : op->getResults()) {"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -402,9 +402,10 @@ Operation *cloneWithInferType(mlir::PatternRewriter &rewriter, Operation *op,\n                               BlockAndValueMapping &mapping) {\n   Operation *newOp = rewriter.clone(*op, mapping);\n   auto origType = op->getResult(0).getType().cast<RankedTensorType>();\n+  auto argType = newOp->getOperand(0).getType().cast<RankedTensorType>();\n   auto newType = RankedTensorType::get(\n       origType.getShape(), origType.getElementType(),\n-      newOp->getOperand(0).getType().cast<RankedTensorType>().getEncoding());\n+      argType.getEncoding());\n   newOp->getResult(0).setType(newType);\n   auto typeInfer = dyn_cast<InferTypeOpInterface>(newOp);\n   if (typeInfer) {\n@@ -595,8 +596,7 @@ class FoldConvertAndReduce : public mlir::RewritePattern {\n       }\n       // don't rematerialize non-element-wise\n       if (!op->hasTrait<mlir::OpTrait::SameOperandsAndResultEncoding>() &&\n-          !op->hasTrait<mlir::OpTrait::Elementwise>() &&\n-          !isa<triton::StoreOp>(op)) {\n+          !op->hasTrait<mlir::OpTrait::Elementwise>()) {\n         return failure();\n       }\n       // don't rematerialize if it adds an extra conversion that can't"}]