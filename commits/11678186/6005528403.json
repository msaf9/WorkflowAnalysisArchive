[{"filename": "include/triton/Dialect/TritonGPU/Transforms/Utility.h", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "file_content_changes": "@@ -116,9 +116,10 @@ Operation *cloneWithInferType(mlir::OpBuilder &rewriter, Operation *op,\n \n // Get backward slice of tensor values starting from the root node along with\n // encoding propagation.\n-LogicalResult getConvertBackwardSlice(Value root, SetVector<Value> &slice,\n-                                      Attribute rootEncoding,\n-                                      DenseMap<Value, Attribute> &layout);\n+LogicalResult getConvertBackwardSlice(\n+    Value root, SetVector<Value> &slice, Attribute rootEncoding,\n+    DenseMap<Value, Attribute> &layout,\n+    std::function<bool(Operation *)> stopPropagation = nullptr);\n \n // Populate pattern to remove dead cycles in ForOp.\n void populateForOpDeadArgumentElimination(RewritePatternSet &patterns);"}, {"filename": "lib/Dialect/TritonGPU/Transforms/RemoveLayoutConversions.cpp", "status": "modified", "additions": 80, "deletions": 3, "changes": 83, "file_content_changes": "@@ -659,8 +659,7 @@ static scf::ForOp replaceForOpWithNewSignature(OpBuilder &rewriter,\n \n static void rewriteSlice(SetVector<Value> &slice,\n                          DenseMap<Value, Attribute> &layout,\n-                         ConvertLayoutOp convertOp) {\n-\n+                         ConvertLayoutOp convertOp, IRMapping &mapping) {\n   SetVector<Operation *> opsToRewrite;\n   for (Value v : slice) {\n     if (v.getDefiningOp()) {\n@@ -673,7 +672,6 @@ static void rewriteSlice(SetVector<Value> &slice,\n   }\n   opsToRewrite = multiRootTopologicalSort(opsToRewrite);\n \n-  IRMapping mapping;\n   SmallVector<Operation *> deadLoops;\n   OpBuilder builder(slice.begin()->getContext());\n   for (Operation *op : opsToRewrite) {\n@@ -743,6 +741,13 @@ static void rewriteSlice(SetVector<Value> &slice,\n     op->erase();\n }\n \n+static void rewriteSlice(SetVector<Value> &slice,\n+                         DenseMap<Value, Attribute> &layout,\n+                         ConvertLayoutOp convertOp) {\n+  IRMapping mapping;\n+  rewriteSlice(slice, layout, convertOp, mapping);\n+}\n+\n static void backwardRematerialization(ConvertLayoutOp convertOp) {\n   // we don't want to rematerialize any conversion to/from shared\n   if (triton::gpu::isSharedEncoding(convertOp.getResult()) ||\n@@ -773,6 +778,61 @@ static void backwardRematerialization(ConvertLayoutOp convertOp) {\n   rewriteSlice(slice, layout, convertOp);\n }\n \n+// For convert left we try to hoist them above type extension to reduce the cost\n+// of the convert.\n+static void hoistConvertOnTopOfExt(ConvertLayoutOp convertOp) {\n+  // we don't want to rematerialize any conversion to/from shared\n+  if (triton::gpu::isSharedEncoding(convertOp.getResult()) ||\n+      triton::gpu::isSharedEncoding(convertOp.getOperand()))\n+    return;\n+  // we don't handle conversions to DotOperandEncodingAttr\n+  // this is a heuristics to accommodate fused attention\n+  auto targetType = convertOp->getResultTypes()[0].cast<RankedTensorType>();\n+  if (targetType.getEncoding().isa<triton::gpu::DotOperandEncodingAttr>())\n+    return;\n+\n+  // 1. Take a backward slice of all the tensor dependencies.\n+  SetVector<Value> slice;\n+  DenseMap<Value, Attribute> layout;\n+  auto isExtOp = [](Operation *op) {\n+    return isa<arith::ExtSIOp, arith::ExtUIOp, arith::ExtFOp>(op);\n+  };\n+  // Get a backward slice but don't go past ext ops\n+  LogicalResult result = getConvertBackwardSlice(\n+      convertOp.getOperand(), slice, targetType.getEncoding(), layout, isExtOp);\n+  if (result.failed() || slice.empty())\n+    return;\n+  Operation *extOp = nullptr;\n+  // 2. Check if all the operations in the slice can be rematerialized.\n+  for (Value v : slice) {\n+    if (Operation *op = v.getDefiningOp()) {\n+      if (!canBeRemat(op))\n+        return;\n+      if (isExtOp(op)) {\n+        // Only apply it if there is a single ext op otherwise we would have to\n+        // duplicate the convert.\n+        if (extOp != nullptr)\n+          return;\n+        extOp = op;\n+      }\n+    }\n+  }\n+  if (extOp == nullptr)\n+    return;\n+  // Move the convert before the ext op and rewrite the slice.\n+  OpBuilder builder(extOp);\n+  auto tensorType = extOp->getOperand(0).getType().cast<RankedTensorType>();\n+  auto newType =\n+      RankedTensorType::get(tensorType.getShape(), tensorType.getElementType(),\n+                            layout[extOp->getResult(0)]);\n+  auto newConvertOp = builder.create<ConvertLayoutOp>(\n+      convertOp.getLoc(), newType, extOp->getOperand(0));\n+  IRMapping mapping;\n+  mapping.map(extOp->getOperand(0), newConvertOp.getResult());\n+  // 3. Rewrite the slice.\n+  rewriteSlice(slice, layout, convertOp, mapping);\n+}\n+\n static void backwardRematerialization(ModuleOp module) {\n   SmallVector<ConvertLayoutOp> convertOps;\n   module.walk(\n@@ -782,6 +842,15 @@ static void backwardRematerialization(ModuleOp module) {\n   }\n }\n \n+static void hoistConvert(ModuleOp module) {\n+  SmallVector<ConvertLayoutOp> convertOps;\n+  module.walk(\n+      [&](ConvertLayoutOp convertOp) { convertOps.push_back(convertOp); });\n+  for (ConvertLayoutOp convertOp : convertOps) {\n+    hoistConvertOnTopOfExt(convertOp);\n+  }\n+}\n+\n #define GEN_PASS_CLASSES\n #include \"triton/Dialect/TritonGPU/Transforms/Passes.h.inc\"\n \n@@ -795,6 +864,7 @@ class TritonGPURemoveLayoutConversionsPass\n     MLIRContext *context = &getContext();\n     ModuleOp m = getOperation();\n \n+    // 1. Propagate layout forward starting from \"anchor\" ops.\n     m.walk([](triton::FuncOp funcOp) {\n       LayoutPropagation layoutPropagation(funcOp);\n       layoutPropagation.initAnchorLayout();\n@@ -810,7 +880,12 @@ class TritonGPURemoveLayoutConversionsPass\n       signalPassFailure();\n     }\n \n+    // 2. For convert ops left try to rematerialize the slice of producer\n+    // operation to avoid having to convert.\n     backwardRematerialization(m);\n+    // 3. For converts left try to hoist them above cast generating larger size\n+    // types in order to reduce the cost of the convert op.\n+    hoistConvert(m);\n \n     mlir::RewritePatternSet decomposePatterns(context);\n     decomposePatterns.add<DecomposeDotOperand>(context);\n@@ -820,6 +895,8 @@ class TritonGPURemoveLayoutConversionsPass\n       signalPassFailure();\n     }\n \n+    // 4. Apply clean up patterns to remove remove dead convert and dead code\n+    // generated by the previous transformations.\n     mlir::RewritePatternSet cleanUpPatterns2(context);\n     populateForOpDeadArgumentElimination(cleanUpPatterns2);\n     scf::ForOp::getCanonicalizationPatterns(cleanUpPatterns2, context);"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Utility.cpp", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "file_content_changes": "@@ -382,9 +382,11 @@ Operation *cloneWithInferType(mlir::OpBuilder &rewriter, Operation *op,\n   return newOp;\n }\n \n-LogicalResult getConvertBackwardSlice(Value root, SetVector<Value> &slice,\n-                                      Attribute rootEncoding,\n-                                      DenseMap<Value, Attribute> &layout) {\n+LogicalResult\n+getConvertBackwardSlice(Value root, SetVector<Value> &slice,\n+                        Attribute rootEncoding,\n+                        DenseMap<Value, Attribute> &layout,\n+                        std::function<bool(Operation *)> stopPropagation) {\n   SmallVector<std::pair<Value, Attribute>> queue = {{root, rootEncoding}};\n   while (!queue.empty()) {\n     auto [currentValue, encoding] = queue.back();\n@@ -400,6 +402,8 @@ LogicalResult getConvertBackwardSlice(Value root, SetVector<Value> &slice,\n     if (auto *definingOp = currentValue.getDefiningOp()) {\n       if (canFoldIntoConversion(definingOp, encoding))\n         continue;\n+      if (stopPropagation && stopPropagation(definingOp))\n+        continue;\n       if (isa<triton::CatOp>(definingOp))\n         return failure();\n       for (Value operand : definingOp->getOperands()) {"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "file_content_changes": "@@ -77,6 +77,20 @@ tt.func @remat_fast_load(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   tt.return\n }\n \n+// Hoist the convert on top of ext to make it cheaper.\n+// CHECK-LABEL: hoist_above_ext\n+tt.func @hoist_above_ext(%arg0: tensor<1024xf16, #layout0>, %arg1: f32) -> tensor<1024xf32, #layout1> {\n+// CHECK: %[[CVT:.+]] = triton_gpu.convert_layout\n+// CHECK: arith.extf %[[CVT]]\n+// CHECK-NOT: triton_gpu.convert_layout\n+// CHECK: tt.return\n+  %0 = arith.extf %arg0 : tensor<1024xf16, #layout0> to tensor<1024xf32, #layout0>\n+  %1 = tt.splat %arg1 : (f32) -> tensor<1024xf32, #layout1>\n+  %2 = triton_gpu.convert_layout %0 : (tensor<1024xf32, #layout0>) -> tensor<1024xf32, #layout1>\n+  %3 = arith.addf %1, %2 : tensor<1024xf32, #layout1>\n+  tt.return %3 : tensor<1024xf32, #layout1>\n+}\n+\n // CHECK-LABEL: if\n tt.func @if(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   // CHECK-NOT: triton_gpu.convert_layout\n@@ -278,6 +292,19 @@ tt.func @loop(%arg0: !tt.ptr<f32>, %arg1: i32, %arg2: !tt.ptr<f32>, %arg3: i32,\n }\n \n // CHECK-LABEL: loop_if\n+// CHECK-NOT: triton_gpu.convert_layout\n+//     CHECK: scf.for\n+// CHECK-NOT: triton_gpu.convert_layout\n+//     CHECK:   scf.if\n+// CHECK-NOT: triton_gpu.convert_layout\n+//     CHECK:     scf.yield\n+//     CHECK:   else\n+//     CHECK:     scf.yield\n+// CHECK-NOT: triton_gpu.convert_layout\n+//     CHECK:   scf.yield\n+//     CHECK: triton_gpu.convert_layout\n+// CHECK-NOT: triton_gpu.convert_layout\n+//     CHECK: tt.store\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n tt.func @loop_if(%arg0: !tt.ptr<f32>, %arg1: i32, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32) {\n   %cst = arith.constant dense<true> : tensor<64x64xi1, #blocked1>"}]