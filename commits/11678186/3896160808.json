[{"filename": "python/src/triton.cc", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "file_content_changes": "@@ -474,11 +474,14 @@ void init_triton_ir(py::module &&m) {\n              return mlir::Value(self.create<mlir::arith::ConstantIntOp>(\n                  loc, v, self.getI32Type()));\n            })\n+      .def(\"get_int64\",\n+           [](mlir::OpBuilder &self, int64_t v) -> mlir::Value {\n+             auto loc = self.getUnknownLoc();\n+             return mlir::Value(self.create<mlir::arith::ConstantIntOp>(\n+                 loc, v, self.getI64Type()));\n+           })\n       // .def(\"get_uint32\", &ir::builder::get_int32, ret::reference)\n-      // .def(\"get_int64\", [](ir::builder *self, int64_t v) { return\n-      // self->get_int64((uint64_t)v); }, ret::reference) .def(\"get_uint64\",\n-      // &ir::builder::get_int64, ret::reference) .def(\"get_float16\",\n-      // &ir::builder::get_float16, ret::reference)\n+      // .def(\"get_float16\", &ir::builder::get_float16, ret::reference)\n       .def(\"get_float32\",\n            [](mlir::OpBuilder &self, float v) -> mlir::Value {\n              auto loc = self.getUnknownLoc();"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 11, "deletions": 10, "changes": 21, "file_content_changes": "@@ -773,23 +773,24 @@ def kernel(X, Z, BITCAST: tl.constexpr):\n         assert to_numpy(z_tri) == z_ref\n \n \n-def test_store_bool():\n+@pytest.mark.parametrize(\"dtype_str\", [dtype_str for dtype_str in torch_dtypes])\n+def test_store_constant(dtype_str):\n     \"\"\"Tests that boolean True is stored as 1\"\"\"\n     @triton.jit\n-    def copy_kernel(input_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n+    def kernel(output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n         offsets = tl.program_id(axis=0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n         mask = offsets < n_elements\n-        input = tl.load(input_ptr + offsets, mask=mask)\n-        output = input\n+        output = GENERATE_TEST_HERE\n         tl.store(output_ptr + offsets, output, mask=mask)\n \n-    src = torch.tensor([True, False], dtype=torch.bool, device='cuda')\n-    n_elements = src.numel()\n-    dst = torch.empty_like(src)\n-    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n-    copy_kernel[grid](src, dst, n_elements, BLOCK_SIZE=1024)\n+    triton_dtype_str = 'uint8' if dtype_str == 'bool' else dtype_str\n+    kernel = patch_kernel(kernel, {'GENERATE_TEST_HERE': f'tl.zeros([BLOCK_SIZE], dtype=tl.{triton_dtype_str}) + 1'})\n+    block_size = 128\n+    ref = torch.ones([block_size], dtype=getattr(torch, dtype_str), device='cuda')\n+    output = torch.zeros([block_size], dtype=getattr(torch, dtype_str), device='cuda')\n+    kernel[(1,)](output, block_size, BLOCK_SIZE=block_size)\n \n-    assert (to_numpy(src).view('uint8') == to_numpy(dst).view('uint8')).all()\n+    assert torch.all(output == ref)\n \n \n @pytest.mark.parametrize(\"dtype\", [torch.float16, torch.bfloat16])"}]