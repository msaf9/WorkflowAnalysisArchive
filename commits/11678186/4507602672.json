[{"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "file_content_changes": "@@ -122,6 +122,7 @@ struct LoadOpConversion\n       const size_t width = std::min(totalWidth, maxWordWidth);\n       const size_t nWords = std::max<size_t>(1, totalWidth / width);\n       const size_t wordNElems = width / valueElemNbits;\n+      const size_t movWidth = width < 16 ? 16 : width;\n       assert(wordNElems * nWords * numVecs == numElems);\n \n       // TODO(Superjomn) Add cache policy fields to StoreOp.\n@@ -137,11 +138,18 @@ struct LoadOpConversion\n       const std::string writeConstraint =\n           (width == 64) ? \"=l\" : ((width == 32) ? \"=r\" : \"=c\");\n \n+      PTXInstr &init =\n+          ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(movWidth));\n+      PTXInstr::Operand *zero = ptxBuilder.newConstantOperand(0);\n+\n       // prepare asm operands\n       auto *dstsOpr = ptxBuilder.newListOperand();\n       for (size_t wordIdx = 0; wordIdx < nWords; ++wordIdx) {\n         auto *opr = ptxBuilder.newOperand(writeConstraint); // =r operations\n         dstsOpr->listAppend(opr);\n+        // Initialize the destination register, otherwise the register will\n+        // be undefined if the predicate is false.\n+        init(opr, zero);\n       }\n \n       auto *addrOpr =\n@@ -175,7 +183,6 @@ struct LoadOpConversion\n       if (other) {\n         for (size_t ii = 0; ii < nWords; ++ii) {\n           // PTX doesn't support mov.u8, so we need to use mov.u16\n-          auto movWidth = width < 16 ? 16 : width;\n           PTXInstr &mov =\n               ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(movWidth));\n "}, {"filename": "python/test/unit/operators/test_inductor.py", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "file_content_changes": "@@ -0,0 +1,55 @@\n+import torch\n+\n+import triton\n+import triton.language as tl\n+\n+\n+def test_normalization_with_remat():\n+\n+    @triton.jit\n+    def triton_(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, rnumel, XBLOCK: tl.constexpr, RBLOCK: tl.constexpr):\n+        xnumel = 512\n+        rnumel = 4096\n+        xoffset = tl.program_id(0) * XBLOCK\n+        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n+        xmask = xindex < xnumel\n+        rbase = tl.arange(0, RBLOCK)[None, :]\n+        x3 = xindex\n+        x0 = xindex % 64\n+        tmp1 = tl.load(in_ptr0 + (x0), xmask)\n+        tmp3 = tl.load(in_ptr1 + (x0), xmask)\n+        tmp11 = tl.load(in_ptr2 + (x0), xmask)\n+        tmp13 = tl.load(in_ptr3 + (x0), xmask)\n+        _tmp17 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0\n+        for roffset in range(0, rnumel, RBLOCK):\n+            rindex = roffset + rbase\n+            rmask = rindex < rnumel\n+            r2 = rindex\n+            tmp0 = tl.load(in_out_ptr0 + (r2 + (4096 * x3)), rmask & xmask, eviction_policy='evict_last', other=0)\n+            tmp2 = tmp0 - tmp1\n+            tmp4 = 1e-05\n+            tmp5 = tmp3 + tmp4\n+            tmp6 = tl.sqrt(tmp5)\n+            tmp7 = 1 / tmp6\n+            tmp8 = 1.0\n+            tmp9 = tmp7 * tmp8\n+            tmp10 = tmp2 * tmp9\n+            tmp12 = tmp10 * tmp11\n+            tmp14 = tmp12 + tmp13\n+            _tmp17 = tl.where(rmask & xmask, _tmp17 + tmp14, _tmp17)\n+            tl.store(in_out_ptr0 + (r2 + (4096 * x3) + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp14, rmask & xmask)\n+        tmp17 = tl.sum(_tmp17, 1)[:, None]\n+        tmp18 = 4096.0\n+        tmp19 = tmp17 / tmp18\n+        tl.store(in_out_ptr1 + (x3 + tl.zeros([XBLOCK, 1], tl.int32)), tmp19, xmask)\n+\n+    torch.manual_seed(123)\n+\n+    buf14 = torch.rand(8, 64, 64, 64, device=\"cuda\")\n+    buf16 = torch.rand(8, 1, 64, device=\"cuda\")\n+    arg114_1 = torch.rand(64, device=\"cuda\")\n+    arg115_1 = torch.rand(64, device=\"cuda\")\n+    arg8_1 = torch.rand(64, device=\"cuda\")\n+    arg9_1 = torch.rand(64, device=\"cuda\")\n+    triton_[(512,)](buf14, buf16, arg114_1, arg115_1, arg8_1, arg9_1, 512, 4096, 1, 2048)\n+    triton.testing.allclose(buf16.mean(), buf14.mean().item(), atol=1e-7, rtol=0)"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 17, "deletions": 9, "changes": 26, "file_content_changes": "@@ -1,4 +1,4 @@\n-// RUN: triton-opt %s -split-input-file --convert-triton-gpu-to-llvm | FileCheck %s\n+// RUN: triton-opt %s -split-input-file --convert-scf-to-cf --convert-triton-gpu-to-llvm | FileCheck %s\n \n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK: llvm.func @test_empty_kernel(%arg0: i64, %arg1: !llvm.ptr<f16, 1>)\n@@ -97,16 +97,24 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n     %8 = tt.addptr %7, %4 : tensor<256x!tt.ptr<f32>, #blocked0>, tensor<256xi32, #blocked0>\n \n     // Load 4 elements from vector0\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n \n     // Load 4 elements from vector1\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n-    // CHECK: \"@${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n+    // CHECK: mov.u32 $0, 0x0\n+    // CHECK: @${{.*}} ld.global.b32 { ${{.*}} }, [ ${{.*}} + 0 ];\n     %9 = tt.load %6 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<256xf32, #blocked0>\n     %10 = tt.load %8 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<256xf32, #blocked0>\n     %11 = arith.addf %9, %10 : tensor<256xf32, #blocked0>"}]