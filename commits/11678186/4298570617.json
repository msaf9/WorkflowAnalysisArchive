[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 51, "deletions": 104, "changes": 155, "file_content_changes": "@@ -62,6 +62,27 @@ class TritonLLVMFunctionConversionTarget : public ConversionTarget {\n \n namespace {\n \n+struct ReturnOpConversion : public ConvertOpToLLVMPattern<func::ReturnOp> {\n+  using ConvertOpToLLVMPattern<func::ReturnOp>::ConvertOpToLLVMPattern;\n+\n+  LogicalResult\n+  matchAndRewrite(func::ReturnOp op, OpAdaptor adaptor,\n+                  ConversionPatternRewriter &rewriter) const override {\n+    unsigned numArguments = op.getNumOperands();\n+\n+    // Currently, Triton kernel function always return nothing.\n+    // TODO(Superjomn) add support for non-inline device function\n+    if (numArguments > 0) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"Only kernel function with nothing returned is supported.\");\n+    }\n+\n+    rewriter.replaceOpWithNewOp<LLVM::ReturnOp>(op, TypeRange(), ValueRange(),\n+                                                op->getAttrs());\n+    return success();\n+  }\n+};\n+\n /// FuncOp legalization pattern that converts MemRef arguments to pointers to\n /// MemRef descriptors (LLVM struct data types) containing all the MemRef type\n /// information.\n@@ -106,43 +127,40 @@ class ConvertTritonGPUToLLVM\n   void runOnOperation() override {\n     MLIRContext *context = &getContext();\n     ModuleOp mod = getOperation();\n-\n-    mlir::LowerToLLVMOptions option(context);\n-    option.overrideIndexBitwidth(32);\n-    TritonGPUToLLVMTypeConverter typeConverter(context, option);\n-    TritonLLVMFunctionConversionTarget funcTarget(*context);\n-    TritonLLVMConversionTarget target(*context);\n-\n     int numWarps = triton::gpu::TritonGPUDialect::getNumWarps(mod);\n \n-    // Step 1: Decompose unoptimized layout conversions to use shared memory\n-    // Step 2: Decompose insert_slice_async to use load + insert_slice for\n-    //   pre-Ampere architectures or unsupported vectorized load sizes\n-    // Step 3: Allocate shared memories and insert barriers\n-    // Step 4: Convert FuncOp to LLVMFuncOp via partial conversion\n-    // Step 5: Get axis and shared memory info\n-    // Step 6: Convert the rest of ops via partial conversion\n-    //\n-    // The reason for a separation between 4/6 is that, step 5 is out of the\n-    // scope of Dialect Conversion, thus we need to make sure the smem is not\n-    // revised during the conversion of step 6.\n-\n-    // Step 1\n+    // Step 1: Do some pre-processing\n     decomposeMmaToDotOperand(mod, numWarps);\n     decomposeBlockedToDotOperand(mod);\n-\n-    // Step 2\n     if (failed(decomposeInsertSliceAsyncOp(mod)))\n       return signalPassFailure();\n \n-    // Step 3\n+    // Step 2: rewrite control flow ops. We do it separately because we need\n+    // int64 indices there\n+    {\n+      mlir::LowerToLLVMOptions cfOptions(context);\n+      TritonGPUToLLVMTypeConverter typeConverter(context, cfOptions);\n+      RewritePatternSet patterns(context);\n+      TritonLLVMFunctionConversionTarget target(*context);\n+      patterns.add<FuncOpConversion>(typeConverter, numWarps, 1);\n+      patterns.add<ReturnOpConversion>(typeConverter);\n+      mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n+                                                            patterns);\n+      mlir::arith::populateArithToLLVMConversionPatterns(typeConverter,\n+                                                         patterns);\n+      if (failed(applyPartialConversion(mod, target, std::move(patterns))))\n+        return signalPassFailure();\n+    }\n+\n+    // Step 3: Allocate shared memopry and set barriers\n+    mlir::LowerToLLVMOptions option(context);\n+    option.overrideIndexBitwidth(32);\n+    TritonGPUToLLVMTypeConverter typeConverter(context, option);\n+    TritonLLVMFunctionConversionTarget funcTarget(*context);\n+\n     Allocation allocation(mod);\n     MembarAnalysis membarPass(&allocation);\n     membarPass.run();\n-\n-    // Step 4\n-\n-    // Step 5 - get axis and shared memory info\n     std::unique_ptr<DataFlowSolver> solver = createDataFlowSolver();\n     AxisInfoAnalysis *axisInfoAnalysis = solver->load<AxisInfoAnalysis>();\n     if (failed(solver->initializeAndRun(mod)))\n@@ -152,53 +170,39 @@ class ConvertTritonGPUToLLVM\n                  mlir::IntegerAttr::get(mlir::IntegerType::get(context, 32),\n                                         allocation.getSharedMemorySize()));\n \n-    // Step 6 - rewrite rest of ops\n+    // Step 4: rewrite rest of ops\n     // We set a higher benefit here to ensure triton's patterns runs before\n     // arith patterns for some encoding not supported by the community\n     // patterns.\n     OpBuilder::InsertPoint indexInsertPoint;\n     ConvertTritonGPUOpToLLVMPatternBase::IndexCacheInfo indexCacheInfo{\n         &baseIndexCache, &indexCache, &indexInsertPoint};\n-\n     RewritePatternSet patterns(context);\n-\n-    // Normal conversions\n-    populateTritonGPUToLLVMPatterns(typeConverter, patterns, numWarps,\n-                                    *axisInfoAnalysis, &allocation, smem,\n-                                    indexCacheInfo, /*benefit=*/10);\n-    // ConvertLayoutOp\n     populateConvertLayoutOpToLLVMPatterns(typeConverter, patterns, numWarps,\n                                           *axisInfoAnalysis, &allocation, smem,\n                                           indexCacheInfo, /*benefit=*/10);\n-    // DotOp\n     populateDotOpToLLVMPatterns(typeConverter, patterns, numWarps,\n                                 *axisInfoAnalysis, &allocation, smem,\n                                 /*benefit=*/10);\n-    // ElementwiseOp\n     populateElementwiseOpToLLVMPatterns(typeConverter, patterns, numWarps,\n                                         *axisInfoAnalysis, &allocation, smem,\n                                         /*benefit=*/10);\n-    // LoadStoreOp\n     populateLoadStoreOpToLLVMPatterns(typeConverter, patterns, numWarps,\n                                       *axisInfoAnalysis, &allocation, smem,\n                                       indexCacheInfo, /*benefit=*/10);\n-    // ReduceOp\n     populateReduceOpToLLVMPatterns(typeConverter, patterns, numWarps,\n                                    *axisInfoAnalysis, &allocation, smem,\n                                    indexCacheInfo, /*benefit=*/10);\n-    // ViewOp\n     populateViewOpToLLVMPatterns(typeConverter, patterns, numWarps,\n                                  *axisInfoAnalysis, &allocation, smem,\n                                  /*benefit=*/10);\n-\n-    // Add arith/math's patterns to help convert scalar expression to LLVM.\n-    mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n-                                                          patterns);\n+    // Misc. Conversions\n+    populateTritonGPUToLLVMPatterns(typeConverter, patterns, numWarps,\n+                                    *axisInfoAnalysis, &allocation, smem,\n+                                    indexCacheInfo, /*benefit=*/10);\n     mlir::populateGpuToNVVMConversionPatterns(typeConverter, patterns);\n-    // mlir::arith::populateArithToLLVMConversionPatterns(typeConverter,\n-    // patterns);\n-    mlir::populateMathToLLVMConversionPatterns(typeConverter, patterns);\n \n+    TritonLLVMConversionTarget target(*context);\n     if (failed(applyPartialConversion(mod, target, std::move(patterns))))\n       return signalPassFailure();\n   }\n@@ -398,63 +402,6 @@ class ConvertTritonGPUToLLVM\n   }\n };\n \n-struct ReturnOpConversion : public ConvertOpToLLVMPattern<func::ReturnOp> {\n-  using ConvertOpToLLVMPattern<func::ReturnOp>::ConvertOpToLLVMPattern;\n-\n-  LogicalResult\n-  matchAndRewrite(func::ReturnOp op, OpAdaptor adaptor,\n-                  ConversionPatternRewriter &rewriter) const override {\n-    unsigned numArguments = op.getNumOperands();\n-\n-    // Currently, Triton kernel function always return nothing.\n-    // TODO(Superjomn) add support for non-inline device function\n-    if (numArguments > 0) {\n-      return rewriter.notifyMatchFailure(\n-          op, \"Only kernel function with nothing returned is supported.\");\n-    }\n-\n-    rewriter.replaceOpWithNewOp<LLVM::ReturnOp>(op, TypeRange(), ValueRange(),\n-                                                op->getAttrs());\n-    return success();\n-  }\n-};\n-\n-class CFBranchPattern : public OpConversionPattern<cf::BranchOp> {\n-public:\n-  using OpConversionPattern<cf::BranchOp>::OpConversionPattern;\n-\n-  LogicalResult\n-  matchAndRewrite(cf::BranchOp op, cf::BranchOp::Adaptor adaptor,\n-                  ConversionPatternRewriter &rewriter) const override {\n-    rewriter.replaceOpWithNewOp<cf::BranchOp>(op, op.getSuccessor(),\n-                                              adaptor.getOperands());\n-    return success();\n-  }\n-};\n-\n-class CFCondBranchPattern : public OpConversionPattern<cf::CondBranchOp> {\n-public:\n-  using OpConversionPattern<cf::CondBranchOp>::OpConversionPattern;\n-\n-  LogicalResult\n-  matchAndRewrite(cf::CondBranchOp op, cf::CondBranchOp::Adaptor adaptor,\n-                  ConversionPatternRewriter &rewriter) const override {\n-    auto converter = getTypeConverter();\n-    auto newOp = rewriter.replaceOpWithNewOp<cf::CondBranchOp>(\n-        op, adaptor.getCondition(), op.getTrueDest(),\n-        adaptor.getTrueDestOperands(), op.getFalseDest(),\n-        adaptor.getFalseDestOperands());\n-\n-    if (failed(rewriter.convertRegionTypes(newOp.getTrueDest()->getParent(),\n-                                           *converter)))\n-      return failure();\n-    if (failed(rewriter.convertRegionTypes(newOp.getFalseDest()->getParent(),\n-                                           *converter)))\n-      return failure();\n-    return success();\n-  }\n-};\n-\n class ConvertTritonFuncToLLVM\n     : public ConvertTritonFuncToLLVMBase<ConvertTritonFuncToLLVM> {\n public:"}, {"filename": "lib/Target/LLVMIR/LLVMIRTranslation.cpp", "status": "modified", "additions": 0, "deletions": 7, "changes": 7, "file_content_changes": "@@ -294,14 +294,7 @@ translateTritonGPUToLLVMIR(llvm::LLVMContext *llvmContext,\n       /*printAfterOnlyOnChange=*/true,\n       /*printAfterOnlyOnFailure*/ false, llvm::dbgs(), printingFlags);\n \n-  mlir::ConvertControlFlowToLLVMPassOptions cfOpt;\n-  mlir::ArithToLLVMConversionPassOptions arithOpt;\n-  mlir::ConvertFuncToLLVMPassOptions funcOpt;\n-  mlir::ConvertIndexToLLVMPassOptions indexOpt;\n-  arithOpt.indexBitwidth = 64;\n   pm.addPass(mlir::createConvertSCFToCFPass());\n-  pm.addPass(mlir::triton::createConvertTritonFuncToLLVMPass());\n-  pm.addPass(mlir::createArithToLLVMConversionPass(arithOpt));\n   pm.addPass(createConvertTritonGPUToLLVMPass(computeCapability));\n   pm.addPass(mlir::createCanonicalizerPass());\n   // Simplify the IR"}]