[{"filename": "python/triton/tools/aot.py", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -42,7 +42,8 @@\n         raise argparse.ArgumentError(None, \"Must specify --sm for PTX compilation\")\n \n     # triton-ir -> triton-gpu-ir\n-    module = triton.compiler.ttir_to_ttgir(module, num_warps=4, num_stages=3, compute_capability=args.sm)\n+    module = triton.compiler.ttir_to_ttgir(module, num_warps=4)\n+    module = triton.compiler.optimize_ttgir(module, num_stages=3, compute_capability=args.sm)\n     if args.target == 'triton-gpu-ir':\n         print(module.str())\n         sys.exit(0)"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,4 +1,4 @@\n-// RUN: triton-opt %s -split-input-file -tritongpu-combine 2>&1 | FileCheck %s\n+// RUN: triton-opt %s -split-input-file -tritongpu-remove-layout-conversions 2>&1 | FileCheck %s\n \n #layout0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n #layout1 = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>"}, {"filename": "test/TritonGPU/matmul.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,4 +1,4 @@\n-// RUN: triton-opt %s -split-input-file -convert-triton-to-tritongpu -tritongpu-combine -tritongpu-pipeline=num-stages=3 -tritongpu-combine -test-print-allocation 2>&1 | FileCheck %s\n+// RUN: triton-opt %s -split-input-file -convert-triton-to-tritongpu -tritongpu-remove-layout-conversions -tritongpu-pipeline=num-stages=3 -test-print-allocation 2>&1 | FileCheck %s\n \n // CHECK: offset = 0, size = 49152\n // CHECK: offset = 49152, size = 49152"}]