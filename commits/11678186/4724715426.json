[{"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -478,8 +478,8 @@ struct TritonReducePattern : public OpConversionPattern<triton::ReduceOp> {\n     addNamedAttrs(newReduce, adaptor.getAttributes());\n \n     auto &newCombineOp = newReduce.getCombineOp();\n-    rewriter.inlineRegionBefore(op.getCombineOp(), newCombineOp,\n-                                newCombineOp.end());\n+    rewriter.cloneRegionBefore(op.getCombineOp(), newCombineOp,\n+                               newCombineOp.end());\n     rewriter.replaceOp(op, newReduce.getResult());\n     return success();\n   }"}, {"filename": "lib/Dialect/TritonGPU/Transforms/RemoveLayoutConversions.cpp", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -137,11 +137,12 @@ class SimplifyReduceCvt : public mlir::RewritePattern {\n           op->getLoc(), newTy, newOperands[i]);\n     }\n \n+    rewriter.setInsertionPoint(reduce);\n     auto newReduce = rewriter.create<triton::ReduceOp>(\n         op->getLoc(), newOperands, reduce.getAxis());\n     auto &newCombineOp = newReduce.getCombineOp();\n-    rewriter.inlineRegionBefore(reduce.getCombineOp(), newCombineOp,\n-                                newCombineOp.end());\n+    rewriter.cloneRegionBefore(reduce.getCombineOp(), newCombineOp,\n+                               newCombineOp.end());\n \n     SmallVector<Value> newRet = newReduce.getResult();\n     auto oldTypes = reduce.getResult().getType();"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1183,7 +1183,7 @@ def kernel(X, Z, BLOCK: tl.constexpr):\n # TODO: [Qingyi] Fix argmin / argmax\n reduce_configs1 = [\n     (op, dtype, (1, 1024), axis) for dtype in dtypes_with_bfloat16\n-    for op in ['min', 'max', 'sum']\n+    for op in ['min', 'max', 'sum', 'argmin', 'argmax']\n     for axis in [1]\n ]\n \n@@ -1199,7 +1199,7 @@ def kernel(X, Z, BLOCK: tl.constexpr):\n \n reduce_configs2 = [\n     (op, 'float32', shape, axis)\n-    for op in ['min', 'max', 'sum']\n+    for op in ['min', 'max', 'sum', 'argmin', 'argmax']\n     for shape in reduce2d_shapes\n     for axis in [0, 1]\n ]"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -704,7 +704,7 @@ def __getitem__(self, slices, _builder=None):\n             elif sl == slice(None, None, None):\n                 pass\n             else:\n-                assert False, \"unsupported\"\n+                assert False, f\"unsupported tensor index: {sl}\"\n         return ret\n \n     @property\n@@ -1281,7 +1281,7 @@ def _argreduce(input, axis, combine_fn, _builder=None, _generator=None):\n \n     if len(input.shape) > 1:\n         # Broadcast index across the non-reduced axes\n-        expand_dims_index = [None] * len(input.shape)\n+        expand_dims_index = [constexpr(None)] * len(input.shape)\n         expand_dims_index[axis] = slice(None)\n         index = index.__getitem__(expand_dims_index, _builder=_builder)\n         index = broadcast_to(index, input.shape, _builder=_builder)"}]