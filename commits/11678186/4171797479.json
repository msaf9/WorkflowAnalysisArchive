[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "file_content_changes": "@@ -840,14 +840,9 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n \n   // Emit indices calculation within each ConversionPattern, and returns a\n   // [elemsPerThread X rank] index matrix.\n-\n   SmallVector<SmallVector<Value>> emitIndicesForDistributedLayout(\n       Location loc, ConversionPatternRewriter &rewriter,\n       const Attribute &layout, ArrayRef<int64_t> shape) const {\n-    // if (auto mmaLayout = layout.template dyn_cast<MmaEncodingAttr>()) {\n-    //   assert(!mmaLayout.isVolta());\n-    // }\n-\n     // step 1, delinearize threadId to get the base index\n     auto multiDimBase = emitBaseIndexForLayout(loc, rewriter, layout, shape);\n     // step 2, get offset of each element\n@@ -861,7 +856,6 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     for (unsigned n = 0; n < elemsPerThread; ++n)\n       for (unsigned k = 0; k < rank; ++k)\n         multiDimIdx[n][k] = add(multiDimBase[k], idx_val(offset[n][k]));\n-\n     return multiDimIdx;\n   }\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/Utility.cpp", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "file_content_changes": "@@ -12,11 +12,6 @@ Value getStructFromElements(Location loc, ValueRange resultVals,\n     return *resultVals.begin();\n   }\n \n-  int n0 = structType.cast<LLVM::LLVMStructType>().getBody().size();\n-  int n1 = resultVals.size();\n-  if (n0 != n1) {\n-    llvm::outs() << n0 << \" \" << n1 << \"\\n\";\n-  }\n   Value llvmStruct = rewriter.create<LLVM::UndefOp>(loc, structType);\n   for (const auto &v : llvm::enumerate(resultVals)) {\n     assert(v.value() && \"can not insert null values\");"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1559,9 +1559,9 @@ def compile(fn, **kwargs):\n         \"ttir\": (lambda path: parse_mlir_module(path, context),\n                  lambda src: ast_to_ttir(src, signature, configs[0], constants)),\n         \"ttgir\": (lambda path: parse_mlir_module(path, context),\n-                  lambda src: ttir_to_ttgir(src, num_warps, num_stages, 70)),\n+                  lambda src: ttir_to_ttgir(src, num_warps, num_stages, capability)),\n         \"llir\": (lambda path: Path(path).read_text(),\n-                 lambda src: ttgir_to_llir(src, extern_libs, 70)),\n+                 lambda src: ttgir_to_llir(src, extern_libs, capability)),\n         \"ptx\": (lambda path: Path(path).read_text(),\n                 lambda src: llir_to_ptx(src, capability)),\n         \"cubin\": (lambda path: Path(path).read_bytes(),"}, {"filename": "python/tutorials/03-matrix-multiplication.py", "status": "modified", "additions": 7, "deletions": 17, "changes": 24, "file_content_changes": "@@ -156,15 +156,14 @@\n \n @triton.autotune(\n     configs=[\n-        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=2, num_warps=4),\n+        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n     ],\n     key=['M', 'N', 'K'],\n )\n @triton.jit\n def matmul_kernel(\n     # Pointers to matrices\n     a_ptr, b_ptr, c_ptr,\n-    bias_ptr,\n     # Matrix dimensions\n     M, N, K,\n     # The stride variables represent how much to increase the ptr by when moving by 1\n@@ -230,20 +229,13 @@ def matmul_kernel(\n     # while the accumulator is still in FP32!\n     if ACTIVATION:\n         accumulator = ACTIVATION(accumulator)\n+    c = accumulator.to(tl.float16)\n+\n     # -----------------------------------------------------------\n     # Write back the block of the output matrix C\n     offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n     offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n-    # exponentiate\n-    # accumulator = tl.exp(accumulator)\n-    # add bias\n-    bias_ptrs = bias_ptr + offs_cm\n-    bias = tl.load(bias_ptrs)\n-    accumulator += bias[:, None]\n-    accumulator += (offs_cm[:, None] + offs_cn[None, :])\n-    # write-back result\n     c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n-    c = accumulator.to(tl.float16)\n     c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n     tl.store(c_ptrs, c, mask=c_mask)\n \n@@ -259,7 +251,7 @@ def leaky_relu(x):\n # and (1) checks any shape constraint; (2) allocates the output; (3) launches the above kernel\n \n \n-def matmul(a, b, bias, activation=None):\n+def matmul(a, b, activation=None):\n     # checks constraints\n     assert a.shape[1] == b.shape[0], \"incompatible dimensions\"\n     assert a.is_contiguous(), \"matrix A must be contiguous\"\n@@ -275,9 +267,8 @@ def matmul(a, b, bias, activation=None):\n     grid = lambda META: (\n         triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\n     )\n-    h = matmul_kernel[grid](\n+    matmul_kernel[grid](\n         a, b, c,\n-        bias,\n         M, N, K,\n         a.stride(0), a.stride(1),\n         b.stride(0), b.stride(1),\n@@ -296,9 +287,8 @@ def matmul(a, b, bias, activation=None):\n torch.manual_seed(0)\n a = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n b = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n-bias = torch.randn((512, ), device='cuda', dtype=torch.float16)\n-triton_output = matmul(a, b, bias, activation=None)\n-torch_output = torch.matmul(a, b) + bias[:, None]\n+triton_output = matmul(a, b, activation=None)\n+torch_output = torch.matmul(a, b)\n print(f\"triton_output={triton_output}\")\n print(f\"torch_output={torch_output}\")\n if triton.testing.allclose(triton_output, torch_output):"}]