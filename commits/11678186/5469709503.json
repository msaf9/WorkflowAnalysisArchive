[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -83,7 +83,9 @@ jobs:\n         if: ${{ env.BACKEND == 'CUDA'}}\n         run: |\n           cd python/test/unit\n-          python3 -m pytest -n 8\n+          # some tests currently don't run in parallel so run them serially separately.\n+          python3 -m pytest -m \"serial\"          \n+          python3 -m pytest -n 8 -m \"not serial\"\n \n       - name: Create artifacts archive\n         if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}"}, {"filename": "python/test/unit/operators/test_cross_entropy.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -5,6 +5,7 @@\n import triton.ops\n \n \n+@pytest.mark.serial\n @pytest.mark.parametrize(\"M, N, dtype, mode\",\n                          [\n                              (M, N, dtype, mode) for M in [1024, 821]"}, {"filename": "python/test/unit/runtime/test_subproc.py", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -3,6 +3,7 @@\n import shutil\n from collections import namedtuple\n \n+import pytest\n import torch\n \n import triton\n@@ -68,6 +69,7 @@ def kernel_dot(Z):\n     )\n \n \n+@pytest.mark.serial\n def test_compile_in_forked_subproc() -> None:\n     reset_tmp_dir()\n     major, minor = torch.cuda.get_device_capability(0)"}]