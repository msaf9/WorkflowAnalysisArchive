[{"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -481,7 +481,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #A = #triton_gpu.shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v4\n-  func @basic_insert_slice_async_v4(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n+  func @basic_insert_slice_async_v4(%arg0: !tt.ptr<f32> {tt.divisibility = 32 : i32}) {\n     %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #slice2d1>\n     %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<64xi32, #slice3d0>\n     %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #slice2d1>) -> tensor<16x1xi32, #block2>\n@@ -502,7 +502,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n     // CHECK: llvm.inline_asm has_side_effects asm_dialect = att\n     // CHECK-SAME: cp.async.cg.shared.global [ ${{.*}} + 0 ], [ ${{.*}} + 0 ], 0x10, 0x10\n     // CHECK: llvm.inline_asm has_side_effects asm_dialect = att\n-    // CHECK-SAME: cp.async.cg.shared.global [ ${{.*}} + 0 ], [ ${{.*}} + 0 ], 0x10, 0x10\n+    // CHECK-SAME: cp.async.cg.shared.global [ ${{.*}} + 16 ], [ ${{.*}} + 0 ], 0x10, 0x10\n     // CHECK: llvm.inline_asm has_side_effects asm_dialect = att\n     // CHECK-SAME: cp.async.commit_group\n     %a = triton_gpu.insert_slice_async %a_ptr, %tensor, %index {axis = 0 : i32, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x64x!tt.ptr<f32>, #AL> -> tensor<2x16x64xf32, #A>"}]