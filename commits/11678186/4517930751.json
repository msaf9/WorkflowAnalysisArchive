[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 30, "deletions": 3, "changes": 33, "file_content_changes": "@@ -22,7 +22,7 @@ jobs:\n         id: set-matrix\n         run: |\n           if [ x\"${{ github.repository }}\" == x\"openai/triton\" ]; then\n-            echo '::set-output name=matrix::[[\"self-hosted\", \"A100\"], [\"self-hosted\", \"V100\"], \"macos-10.15\"]'\n+            echo '::set-output name=matrix::[[\"self-hosted\", \"A100\"], [\"self-hosted\", \"V100\"], [\"self-hosted\", \"gfx908\"], \"macos-10.15\"]'\n           else\n             echo '::set-output name=matrix::[\"ubuntu-latest\", \"macos-10.15\"]'\n           fi\n@@ -40,6 +40,16 @@ jobs:\n       - name: Checkout\n         uses: actions/checkout@v2\n \n+      - name: Set CUDA ENV\n+        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100')}}\n+        run: |\n+          echo \"BACKEND=CUDA\" >> $GITHUB_ENV\n+\n+      - name: Set ROCM ENV\n+        if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'gfx908')}}\n+        run: |\n+          echo \"BACKEND=ROCM\" >> $GITHUB_ENV\n+\n       - name: Clear cache\n         run: |\n           rm -rf ~/.triton/\n@@ -74,12 +84,22 @@ jobs:\n           flake8 --config ./python/setup.cfg ./python || ( echo '::error::Flake8 failed; see logs for errors.' ; exit 1 )\n \n       - name: Install Triton\n+        if: ${{ env.BACKEND != 'ROCM'}}\n         run: |\n           cd python\n           pip3 install cmake==3.24\n           TRITON_USE_ASSERT_ENABLED_LLVM=TRUE pip3 install -e '.[tests]'\n \n+      - name: Install Triton on ROCM\n+        if: ${{ env.BACKEND == 'ROCM'}}\n+        run: |\n+          cd python\n+          pip3 uninstall --yes torch torchvision torchaudio\n+          pip3 install --no-cache-dir --force-reinstall torch==1.13.1 --extra-index-url https://download.pytorch.org/whl/rocm5.2\n+          TRITON_USE_ASSERT_ENABLED_LLVM=TRUE pip3 install -e '.[tests]'\n+\n       - name: Run lit tests\n+        if: ${{ env.BACKEND != 'ROCM'}}\n         run: |\n           pip3 install lit\n           cd python\n@@ -89,13 +109,20 @@ jobs:\n           fi\n           lit -v \"$LIT_TEST_DIR\"\n \n-      - name: Run python tests\n-        if: ${{matrix.runner[0] == 'self-hosted'}}\n+      - name: Run python tests on CUDA\n+        if: ${{ env.BACKEND == 'CUDA'}}\n         run: |\n           cd python/test/unit/\n           pytest\n+      \n+      - name: Run python tests on ROCM\n+        if: ${{ env.BACKEND == 'ROCM'}}\n+        run: |\n+          cd python/test/unit/language/\n+          pytest --capture=tee-sys -rfs --verbose \"test_core.py::test_empty_kernel\"\n \n       - name: Run CXX unittests\n+        if: ${{ env.BACKEND != 'ROCM'}}\n         run: |\n           cd python/\n           cd \"build/$(ls build)\""}, {"filename": ".gitignore", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "CMakeLists.txt", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -216,6 +216,7 @@ if(TRITON_BUILD_PYTHON_MODULE)\n     TritonGPUTransforms\n     TritonLLVMIR\n     TritonPTX\n+    TritonHSACO\n     ${dialect_libs}\n     ${conversion_libs}\n \n@@ -228,6 +229,7 @@ if(TRITON_BUILD_PYTHON_MODULE)\n     MLIRExecutionEngine\n     MLIRMathToLLVM\n     MLIRNVVMToLLVMIRTranslation\n+    MLIRROCDLToLLVMIRTranslation\n     MLIRIR\n   )\n "}, {"filename": "bin/CMakeLists.txt", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -30,6 +30,7 @@ llvm_update_compile_flags(triton-translate)\n          TritonGPUTransforms\n          TritonLLVMIR\n          TritonPTX\n+         TritonHSACO\n          ${dialect_libs}\n          ${conversion_libs}\n          # tests\n@@ -53,5 +54,6 @@ llvm_update_compile_flags(triton-translate)\n          MLIRTransformUtils\n          MLIRLLVMToLLVMIRTranslation\n          MLIRNVVMToLLVMIRTranslation\n+         MLIRROCDLToLLVMIRTranslation\n          )\n mlir_check_all_link_libraries(triton-translate)"}, {"filename": "bin/triton-opt.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -4,7 +4,8 @@\n #include \"triton/Dialect/Triton/Transforms/Passes.h\"\n #include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n \n-#include \"triton/Conversion/Passes.h\"\n+#include \"triton/Conversion/TritonGPUToLLVM/Passes.h\"\n+#include \"triton/Conversion/TritonToTritonGPU/Passes.h\"\n \n #include \"mlir/IR/Dialect.h\"\n #include \"mlir/InitAllPasses.h\""}, {"filename": "bin/triton-translate.cpp", "status": "modified", "additions": 24, "deletions": 2, "changes": 26, "file_content_changes": "@@ -14,14 +14,14 @@\n #include \"triton/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+#include \"triton/Target/HSACO/HSACOTranslation.h\"\n #include \"triton/Target/LLVMIR/LLVMIRTranslation.h\"\n #include \"triton/Target/PTX/PTXTranslation.h\"\n #include \"llvm/IR/LLVMContext.h\"\n #include \"llvm/Support/CommandLine.h\"\n #include \"llvm/Support/InitLLVM.h\"\n #include \"llvm/Support/SourceMgr.h\"\n #include \"llvm/Support/ToolOutputFile.h\"\n-#include <iostream>\n \n namespace mlir {\n namespace triton {\n@@ -79,7 +79,8 @@ LogicalResult tritonTranslateMain(int argc, char **argv,\n       llvm::cl::init(\"-\"));\n \n   static llvm::cl::opt<std::string> targetKind(\n-      \"target\", llvm::cl::desc(\"<translation target, options: llvmir/ptx>\"),\n+      \"target\",\n+      llvm::cl::desc(\"<translation target, options: llvmir/ptx/hsaco>\"),\n       llvm::cl::value_desc(\"target\"), llvm::cl::init(\"llvmir\"));\n \n   static llvm::cl::opt<int> SMArch(\"sm\", llvm::cl::desc(\"sm arch\"),\n@@ -88,6 +89,18 @@ LogicalResult tritonTranslateMain(int argc, char **argv,\n   static llvm::cl::opt<int> ptxVersion(\n       \"ptx-version\", llvm::cl::desc(\"PTX version\"), llvm::cl::init(10000));\n \n+  static llvm::cl::opt<std::string> GCNArch(\n+      \"gfx\", llvm::cl::desc(\"AMDGCN target. e.g. '90a'\"),\n+      llvm::cl::value_desc(\"architecture\"), llvm::cl::init(\"90a\"));\n+\n+  static llvm::cl::opt<std::string> GCNTriple(\n+      \"amdgcn\", llvm::cl::desc(\"AMDGCN triple. e.g. '-amd-amdhsa'\"),\n+      llvm::cl::value_desc(\"target triple\"), llvm::cl::init(\"-amd-amdhsa\"));\n+\n+  static llvm::cl::opt<std::string> GCNFeatures(\n+      \"\", llvm::cl::desc(\"AMDGCN features. e.g. '+sramecc,-xnack'\"),\n+      llvm::cl::value_desc(\"features\"), llvm::cl::init(\"+sramecc,-xnack\"));\n+\n   llvm::InitLLVM y(argc, argv);\n \n   registerAsmPrinterCLOptions();\n@@ -119,6 +132,15 @@ LogicalResult tritonTranslateMain(int argc, char **argv,\n   else if (targetKind == \"ptx\")\n     llvm::outs() << ::triton::translateLLVMIRToPTX(*llvmir, SMArch.getValue(),\n                                                    ptxVersion.getValue());\n+  else if (targetKind == \"hsaco\") {\n+    auto [module, hsaco] = ::triton::translateLLVMIRToHSACO(\n+        *llvmir, GCNArch.getValue(), GCNTriple.getValue(),\n+        GCNFeatures.getValue());\n+    llvm::outs() << hsaco;\n+  } else {\n+    llvm::errs() << \"Error: Unknown target specified: \" << targetKind << \"\\n\";\n+    return failure();\n+  }\n \n   return success();\n }"}, {"filename": "docs/python-api/triton.language.rst", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -79,6 +79,7 @@ Math Ops\n     :toctree: generated\n     :nosignatures:\n \n+    abs\n     exp\n     log\n     cos"}, {"filename": "include/triton/Conversion/CMakeLists.txt", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -1,3 +1,2 @@\n-set(LLVM_TARGET_DEFINITIONS Passes.td)\n-mlir_tablegen(Passes.h.inc -gen-pass-decls)\n-add_public_tablegen_target(TritonConversionPassIncGen)\n+add_subdirectory(TritonToTritonGPU)\n+add_subdirectory(TritonGPUToLLVM)"}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/AsmFormat.h", "status": "added", "additions": 33, "deletions": 0, "changes": 33, "file_content_changes": "@@ -0,0 +1,33 @@\n+#ifndef TRITON_CONVERSION_TRITON_GPU_TO_LLVM_ASM_FORMAT_H_\n+#define TRITON_CONVERSION_TRITON_GPU_TO_LLVM_ASM_FORMAT_H_\n+\n+#include \"mlir/IR/Value.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/ADT/StringRef.h\"\n+#include <memory>\n+#include <string>\n+\n+namespace mlir {\n+class ConversionPatternRewriter;\n+class Location;\n+\n+namespace triton {\n+using llvm::StringRef;\n+\n+inline std::string strJoin(llvm::ArrayRef<std::string> strs,\n+                           llvm::StringRef delimiter) {\n+  std::string osStr;\n+  llvm::raw_string_ostream os(osStr);\n+  for (size_t i = 0; !strs.empty() && i < strs.size() - 1; ++i)\n+    os << strs[i] << delimiter;\n+  if (!strs.empty())\n+    os << strs.back();\n+  os.flush();\n+  return osStr;\n+}\n+\n+} // namespace triton\n+} // namespace mlir\n+\n+#endif // TRITON_CONVERSION_TRITON_GPU_TO_LLVM_ASM_FORMAT_H_"}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/CMakeLists.txt", "status": "added", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -0,0 +1,3 @@\n+set(LLVM_TARGET_DEFINITIONS Passes.td)\n+mlir_tablegen(Passes.h.inc -gen-pass-decls --name TritonGPUToLLVM)\n+add_public_tablegen_target(TritonGPUConversionPassIncGen)"}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/GCNAsmFormat.h", "status": "added", "additions": 318, "deletions": 0, "changes": 318, "file_content_changes": "@@ -0,0 +1,318 @@\n+#ifndef TRITON_CONVERSION_TRITON_GPU_TO_LLVM_GCN_FORMAT_H_\n+#define TRITON_CONVERSION_TRITON_GPU_TO_LLVM_GCN_FORMAT_H_\n+\n+#include \"mlir/IR/Value.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/ADT/StringRef.h\"\n+#include <memory>\n+#include <string>\n+\n+namespace mlir {\n+class ConversionPatternRewriter;\n+class Location;\n+\n+namespace triton {\n+using llvm::StringRef;\n+\n+class GCNInstr;\n+class GCNInstrCommon;\n+class GCNInstrExecution;\n+\n+struct GCNBuilder {\n+  struct Operand {\n+    std::string constraint;\n+    Value value;\n+    int idx{-1};\n+    llvm::SmallVector<Operand *> list;\n+    std::function<std::string(int idx)> repr;\n+\n+    // for list\n+    Operand() = default;\n+    Operand(const Operation &) = delete;\n+    Operand(Value value, StringRef constraint)\n+        : value(value), constraint(constraint) {}\n+\n+    bool isList() const { return !value && constraint.empty(); }\n+\n+    Operand *listAppend(Operand *arg) {\n+      list.push_back(arg);\n+      return this;\n+    }\n+\n+    Operand *listGet(size_t nth) const {\n+      assert(nth < list.size());\n+      return list[nth];\n+    }\n+\n+    std::string dump() const;\n+  };\n+\n+  struct Modifier {\n+    Value value;\n+    std::string modifier;\n+    std::string arg;\n+    llvm::SmallVector<Modifier *> list;\n+\n+    Modifier() = default;\n+    Modifier(const Operation &) = delete;\n+    Modifier(Value value, StringRef arg) : value(value), arg(arg) {}\n+\n+    bool isList() const { return !value && modifier.empty(); }\n+\n+    Modifier *listAppend(Modifier *arg) {\n+      list.push_back(arg);\n+      return this;\n+    }\n+\n+    Modifier *listGet(size_t index) const {\n+      assert(index < list.size());\n+      return list[index];\n+    }\n+\n+    std::string to_str() const {\n+      std::string str = modifier;\n+      if (!arg.empty()) {\n+        str += \":\" + arg;\n+      }\n+      return str;\n+    }\n+\n+    std::string dump() const;\n+  };\n+\n+  template <typename INSTR = GCNInstr, typename... Args>\n+  INSTR *create(Args &&...args) {\n+    instrs.emplace_back(std::make_unique<INSTR>(this, args...));\n+    return static_cast<INSTR *>(instrs.back().get());\n+  }\n+\n+  // Create a list of operands.\n+  Operand *newListOperand() { return newOperand(); }\n+\n+  Operand *newListOperand(ArrayRef<std::pair<mlir::Value, std::string>> items) {\n+    auto *list = newOperand();\n+    for (auto &item : items) {\n+      list->listAppend(newOperand(item.first, item.second));\n+    }\n+    return list;\n+  }\n+\n+  Operand *newListOperand(unsigned count, mlir::Value val,\n+                          const std::string &constraint) {\n+    auto *list = newOperand();\n+    for (int i = 0; i < count; ++i) {\n+      list->listAppend(newOperand(val, constraint));\n+    }\n+    return list;\n+  }\n+\n+  Operand *newListOperand(unsigned count, const std::string &constraint) {\n+    auto *list = newOperand();\n+    for (int i = 0; i < count; ++i) {\n+      list->listAppend(newOperand(constraint));\n+    }\n+    return list;\n+  }\n+\n+  // Create a new operand. It will not add to operand list.\n+  // @value: the MLIR value bind to this operand.\n+  // @constraint: ASM operand constraint, .e.g. \"=r\"\n+  // @formatter: extra format to represent this operand in ASM code, default is\n+  //             \"%{0}\".format(operand.idx).\n+  Operand *newOperand(mlir::Value value, StringRef constraint,\n+                      std::function<std::string(int idx)> formatter = nullptr);\n+\n+  // Create a new operand which is written to, that is, the constraint starts\n+  // with \"=\", e.g. \"=r\".\n+  Operand *newOperand(StringRef constraint);\n+\n+  // Create a constant integer operand.\n+  Operand *newConstantOperand(int v);\n+  // Create a constant operand with explicit code specified.\n+  Operand *newConstantOperand(const std::string &v);\n+\n+  Operand *newAddrOperand(mlir::Value addr, StringRef constraint);\n+\n+  Modifier *newModifier(StringRef modifier, StringRef arg);\n+\n+  llvm::SmallVector<Operand *, 4> getAllArgs() const;\n+\n+  llvm::SmallVector<Value, 4> getAllMLIRArgs() const;\n+\n+  std::string getConstraints() const;\n+\n+  std::string dump() const;\n+\n+  mlir::Value launch(ConversionPatternRewriter &rewriter, Location loc,\n+                     Type resTy, bool hasSideEffect = true,\n+                     bool isAlignStack = false,\n+                     ArrayRef<Attribute> attrs = {}) const;\n+\n+private:\n+  Operand *newOperand() {\n+    argArchive.emplace_back(std::make_unique<Operand>());\n+    return argArchive.back().get();\n+  }\n+\n+  Modifier *newModifier() {\n+    modArchive.emplace_back(std::make_unique<Modifier>());\n+    return modArchive.back().get();\n+  }\n+\n+  friend class GCNInstr;\n+  friend class GCNInstrCommon;\n+\n+protected:\n+  llvm::SmallVector<std::unique_ptr<Operand>, 6> argArchive;\n+  llvm::SmallVector<std::unique_ptr<Modifier>, 2> modArchive;\n+  llvm::SmallVector<std::unique_ptr<GCNInstrCommon>, 2> instrs;\n+  llvm::SmallVector<std::unique_ptr<GCNInstrExecution>, 4> executions;\n+  int oprCounter{};\n+};\n+\n+// GCN instruction common interface.\n+// Put the generic logic for all the instructions here.\n+struct GCNInstrCommon {\n+  explicit GCNInstrCommon(GCNBuilder *builder) : builder(builder) {}\n+\n+  using Operand = GCNBuilder::Operand;\n+  using Modifier = GCNBuilder::Modifier;\n+\n+  // clang-format off\n+  GCNInstrExecution& operator()() { return call({}, {}); }\n+  GCNInstrExecution& operator()(Operand* a) { return call({a}, {}); }\n+  GCNInstrExecution& operator()(Operand* a, Operand* b) { return call({a, b}, {}); }\n+  GCNInstrExecution& operator()(Operand* a, Operand* b, Operand* c) { return call({a, b, c}, {}); }\n+  GCNInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d) { return call({a, b, c, d}, {}); }\n+  GCNInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d, Operand * e) { return call({a, b, c, d, e}, {}); }\n+  GCNInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d, Operand * e, Operand* f) { return call({a, b, c, d, e, f}, {}); }\n+  GCNInstrExecution& operator()(Operand* a, Operand* b, Operand* c, Operand* d, Operand * e, Operand* f, Operand* g) { return call({a, b, c, d, e, f, g}, {}); }\n+  // clang-format on\n+\n+  // Set operands of this instruction.\n+  GCNInstrExecution &operator()(llvm::ArrayRef<Operand *> oprs,\n+                                llvm::ArrayRef<Modifier *> mods);\n+\n+protected:\n+  GCNInstrExecution &call(llvm::ArrayRef<Operand *> oprs,\n+                          ArrayRef<Modifier *> mods);\n+\n+  GCNBuilder *builder{};\n+  llvm::SmallVector<std::string, 4> instrParts;\n+\n+  friend class GCNInstrExecution;\n+};\n+\n+template <class ConcreteT> struct GCNInstrBase : public GCNInstrCommon {\n+  using Operand = GCNBuilder::Operand;\n+  using Modifier = GCNBuilder::Modifier;\n+\n+  explicit GCNInstrBase(GCNBuilder *builder, const std::string &name)\n+      : GCNInstrCommon(builder) {\n+    o(name);\n+  }\n+\n+  ConcreteT &o(const std::string &suffix, bool predicate = true) {\n+    if (predicate)\n+      instrParts.push_back(suffix);\n+    return *static_cast<ConcreteT *>(this);\n+  }\n+};\n+\n+enum VectorWidth { Byte = 8, Short = 16, Dword = 32, Qword = 64 };\n+\n+struct GCNInstr : public GCNInstrBase<GCNInstr> {\n+  using GCNInstrBase<GCNInstr>::GCNInstrBase;\n+\n+  GCNInstr &float_op_type(int width) {\n+    switch (width) {\n+    case Byte:\n+      assert(Byte != width);\n+      break;\n+    case Short:\n+      o(\"f16\");\n+      break;\n+    case Dword:\n+      o(\"f32\");\n+      break;\n+    case Qword:\n+      o(\"f64\");\n+      break;\n+    default:\n+      break;\n+    }\n+    return *this;\n+  }\n+};\n+\n+struct GCNInstrExecution {\n+  using Operand = GCNBuilder::Operand;\n+  using Modifier = GCNBuilder::Modifier;\n+\n+  llvm::SmallVector<Operand *> argsInOrder;\n+  llvm::SmallVector<Modifier *> mods;\n+\n+  GCNInstrExecution() = default;\n+  explicit GCNInstrExecution(GCNInstrCommon *instr,\n+                             llvm::ArrayRef<Operand *> oprs,\n+                             llvm::ArrayRef<Modifier *> modifiers)\n+      : instr(instr), argsInOrder(oprs.begin(), oprs.end()),\n+        mods(modifiers.begin(), modifiers.end()) {}\n+\n+  std::string dump() const;\n+\n+  SmallVector<Operand *> getArgList() const;\n+\n+  GCNInstrCommon *instr{};\n+};\n+\n+struct GCNMemInstr : public GCNInstrBase<GCNMemInstr> {\n+  using GCNInstrBase<GCNMemInstr>::GCNInstrBase;\n+  // Add specific type suffix to instruction\n+\n+  GCNMemInstr &load_type(int width) {\n+    switch (width) {\n+    case Byte:\n+      o(\"ubyte\");\n+      break;\n+    case Short:\n+      o(\"ushort\");\n+      break;\n+    case Dword:\n+      o(\"dword\");\n+      break;\n+    case Qword:\n+      o(\"dwordx2\");\n+      break;\n+    default:\n+      break;\n+    }\n+    return *this;\n+  }\n+\n+  GCNMemInstr &store_type(int width) {\n+    switch (width) {\n+    case Byte:\n+      o(\"byte\");\n+      break;\n+    case Short:\n+      o(\"short\");\n+      break;\n+    case Dword:\n+      o(\"dword\");\n+      break;\n+    case Qword:\n+      o(\"dwordx2\");\n+      break;\n+    default:\n+      break;\n+    }\n+    return *this;\n+  }\n+};\n+\n+} // namespace triton\n+} // namespace mlir\n+\n+#endif // TRITON_CONVERSION_TRITON_GPU_TO_LLVM_ASM_FORMAT_H_"}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/PTXAsmFormat.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1,5 +1,5 @@\n-#ifndef TRITON_CONVERSION_TRITONGPU_TO_LLVM_ASM_FORMAT_H\n-#define TRITON_CONVERSION_TRITONGPU_TO_LLVM_ASM_FORMAT_H\n+#ifndef TRITON_CONVERSION_TRITON_GPU_TO_LLVM_PTX_ASM_FORMAT_H_\n+#define TRITON_CONVERSION_TRITON_GPU_TO_LLVM_PTX_ASM_FORMAT_H_\n \n #include \"mlir/IR/Value.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\""}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/Passes.h", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "file_content_changes": "@@ -0,0 +1,16 @@\n+#ifndef TRITONGPU_CONVERSION_PASSES_H\n+#define TRITONGPU_CONVERSION_PASSES_H\n+\n+#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n+#include \"triton/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.h\"\n+\n+namespace mlir {\n+namespace triton {\n+\n+#define GEN_PASS_REGISTRATION\n+#include \"triton/Conversion/TritonGPUToLLVM/Passes.h.inc\"\n+\n+} // namespace triton\n+} // namespace mlir\n+\n+#endif"}, {"filename": "include/triton/Conversion/TritonGPUToLLVM/Passes.td", "status": "renamed", "additions": 3, "deletions": 23, "changes": 26, "file_content_changes": "@@ -1,29 +1,8 @@\n-#ifndef TRITON_CONVERSION_PASSES\n-#define TRITON_CONVERSION_PASSES\n+#ifndef TRITONGPU_CONVERSION_PASSES\n+#define TRITONGPU_CONVERSION_PASSES\n \n include \"mlir/Pass/PassBase.td\"\n \n-def ConvertTritonToTritonGPU: Pass<\"convert-triton-to-tritongpu\", \"mlir::ModuleOp\"> {\n-    let summary = \"Convert Triton to TritonGPU\";\n-    let description = [{\n-\n-    }];\n-    let constructor = \"mlir::triton::createConvertTritonToTritonGPUPass()\";\n-\n-    let dependentDialects = [\"mlir::arith::ArithDialect\",\n-                             \"mlir::math::MathDialect\",\n-                             // TODO: Does this pass depend on SCF?\n-                             \"mlir::scf::SCFDialect\",\n-                             \"mlir::triton::TritonDialect\",\n-                             \"mlir::triton::gpu::TritonGPUDialect\"];\n-\n-   let options = [\n-       Option<\"numWarps\", \"num-warps\",\n-              \"int32_t\", /*default*/\"4\",\n-              \"number of warps\">\n-   ];\n-}\n-\n \n def ConvertTritonGPUToLLVM : Pass<\"convert-triton-gpu-to-llvm\", \"mlir::ModuleOp\"> {\n     let summary = \"Convert TritonGPU to LLVM\";\n@@ -40,6 +19,7 @@ def ConvertTritonGPUToLLVM : Pass<\"convert-triton-gpu-to-llvm\", \"mlir::ModuleOp\"\n                              \"mlir::tensor::TensorDialect\",\n                              \"mlir::triton::TritonDialect\",\n                              \"mlir::triton::gpu::TritonGPUDialect\",\n+                             \"mlir::ROCDL::ROCDLDialect\",\n                              \"mlir::NVVM::NVVMDialect\"];\n \n     let options = ["}, {"filename": "include/triton/Conversion/TritonToTritonGPU/CMakeLists.txt", "status": "added", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -0,0 +1,3 @@\n+set(LLVM_TARGET_DEFINITIONS Passes.td)\n+mlir_tablegen(Passes.h.inc -gen-pass-decls --name TritonToTritonGPU)\n+add_public_tablegen_target(TritonConversionPassIncGen)"}, {"filename": "include/triton/Conversion/TritonToTritonGPU/Passes.h", "status": "renamed", "additions": 1, "deletions": 3, "changes": 4, "file_content_changes": "@@ -1,15 +1,13 @@\n #ifndef TRITON_CONVERSION_PASSES_H\n #define TRITON_CONVERSION_PASSES_H\n \n-#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n-#include \"triton/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.h\"\n #include \"triton/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.h\"\n \n namespace mlir {\n namespace triton {\n \n #define GEN_PASS_REGISTRATION\n-#include \"triton/Conversion/Passes.h.inc\"\n+#include \"triton/Conversion/TritonToTritonGPU/Passes.h.inc\"\n \n } // namespace triton\n } // namespace mlir"}, {"filename": "include/triton/Conversion/TritonToTritonGPU/Passes.td", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "file_content_changes": "@@ -0,0 +1,27 @@\n+#ifndef TRITON_CONVERSION_PASSES\n+#define TRITON_CONVERSION_PASSES\n+\n+include \"mlir/Pass/PassBase.td\"\n+\n+def ConvertTritonToTritonGPU: Pass<\"convert-triton-to-tritongpu\", \"mlir::ModuleOp\"> {\n+    let summary = \"Convert Triton to TritonGPU\";\n+    let description = [{\n+\n+    }];\n+    let constructor = \"mlir::triton::createConvertTritonToTritonGPUPass()\";\n+\n+    let dependentDialects = [\"mlir::arith::ArithDialect\",\n+                             \"mlir::math::MathDialect\",\n+                             // TODO: Does this pass depend on SCF?\n+                             \"mlir::scf::SCFDialect\",\n+                             \"mlir::triton::TritonDialect\",\n+                             \"mlir::triton::gpu::TritonGPUDialect\"];\n+\n+   let options = [\n+       Option<\"numWarps\", \"num-warps\",\n+              \"int32_t\", /*default*/\"4\",\n+              \"number of warps\">\n+   ];\n+}\n+\n+#endif"}, {"filename": "include/triton/Target/AMDGCN/AMDGCNTranslation.h", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "file_content_changes": "@@ -0,0 +1,19 @@\n+#ifndef TRITON_TARGET_AMDGCNTRANSLATION_H\n+#define TRITON_TARGET_AMDGCNTRANSLATION_H\n+\n+#include <string>\n+#include <tuple>\n+\n+namespace llvm {\n+class Module;\n+} // namespace llvm\n+\n+namespace triton {\n+\n+// Translate LLVM IR to AMDGCN code.\n+std::tuple<std::string, std::string>\n+translateLLVMIRToAMDGCN(llvm::Module &module, std::string cc);\n+\n+} // namespace triton\n+\n+#endif"}, {"filename": "include/triton/Target/HSACO/HSACOTranslation.h", "status": "added", "additions": 21, "deletions": 0, "changes": 21, "file_content_changes": "@@ -0,0 +1,21 @@\n+#ifndef TRITON_TARGET_HSACOTRANSLATION_H\n+#define TRITON_TARGET_HSACOTRANSLATION_H\n+\n+#include <memory>\n+#include <string>\n+#include <tuple>\n+\n+namespace llvm {\n+class Module;\n+} // namespace llvm\n+\n+namespace triton {\n+\n+// Translate TritonGPU IR to HSACO code.\n+std::tuple<std::string, std::string>\n+translateLLVMIRToHSACO(llvm::Module &module, std::string gfx_arch,\n+                       std::string gfx_triple, std::string gfx_features);\n+\n+} // namespace triton\n+\n+#endif"}, {"filename": "include/triton/Tools/Sys/GetPlatform.hpp", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "file_content_changes": "@@ -0,0 +1,36 @@\n+/*\n+ * Copyright (c) 2015, PHILIPPE TILLET. All rights reserved.\n+ *\n+ * This file is part of ISAAC.\n+ *\n+ * ISAAC is free software; you can redistribute it and/or\n+ * modify it under the terms of the GNU Lesser General Public\n+ * License as published by the Free Software Foundation; either\n+ * version 2.1 of the License, or (at your option) any later version.\n+ *\n+ * This library is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+ * Lesser General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Lesser General Public\n+ * License along with this library; if not, write to the Free Software\n+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n+ * MA 02110-1301  USA\n+ */\n+\n+#ifndef TDL_TOOLS_SYS_GETPLATFORM_HPP\n+#define TDL_TOOLS_SYS_GETPLATFORM_HPP\n+\n+#include <algorithm>\n+#include <cstdlib>\n+#include <iostream>\n+#include <map>\n+#include <memory>\n+#include <string>\n+\n+inline bool _isROCM = false;\n+inline void setROCM() { _isROCM = true; }\n+inline bool isROCM() { return _isROCM; }\n+\n+#endif"}, {"filename": "lib/Conversion/TritonGPUToLLVM/CMakeLists.txt", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "file_content_changes": "@@ -1,4 +1,8 @@\n add_mlir_conversion_library(TritonGPUToLLVM\n+    TritonGPUToLLVM.cpp\n+    GCNAsmFormat.cpp\n+    PTXAsmFormat.cpp\n+    TritonGPUToLLVMPass.cpp\n     ConvertLayoutOpToLLVM/SharedToDotOperandFMA.cpp\n     ConvertLayoutOpToLLVM/SharedToDotOperandMMAv1.cpp\n     ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp\n@@ -19,9 +23,10 @@ add_mlir_conversion_library(TritonGPUToLLVM\n \n     ADDITIONAL_HEADER_DIRS\n     ${PROJECT_SOURCE_DIR}/include/triton/Conversion/TritonGPUToLLVM\n+    ${PROJECT_BINARY_DIR}/include/triton/Conversion/TritonGPUToLLVM\n \n     DEPENDS\n-    TritonConversionPassIncGen\n+    TritonGPUConversionPassIncGen\n \n     LINK_COMPONENTS\n     Core\n@@ -31,6 +36,7 @@ add_mlir_conversion_library(TritonGPUToLLVM\n     MLIRPass\n     MLIRGPUOps\n     MLIRGPUToNVVMTransforms\n+    MLIRGPUToROCDLTransforms\n     MLIRGPUTransforms\n     TritonAnalysis\n     TritonIR"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 44, "deletions": 0, "changes": 44, "file_content_changes": "@@ -1011,6 +1011,48 @@ struct ExpOpConversionApprox\n   }\n };\n \n+struct AbsIOpConversion\n+    : ElementwiseOpConversionBase<mlir::math::AbsIOp, AbsIOpConversion> {\n+  using Base =\n+      ElementwiseOpConversionBase<mlir::math::AbsIOp, AbsIOpConversion>;\n+  using Base::Base;\n+  using Adaptor = typename Base::OpAdaptor;\n+\n+  Value createDestOp(mlir::math::AbsIOp op, OpAdaptor adaptor,\n+                     ConversionPatternRewriter &rewriter, Type elemTy,\n+                     ValueRange operands, Location loc) const {\n+    auto boolFalse = rewriter.getBoolAttr(false);\n+    auto constFalse = rewriter.create<LLVM::ConstantOp>(loc, boolFalse);\n+    return rewriter.create<LLVM::AbsOp>(loc, elemTy, operands[0],\n+                                        /*is_int_min_poison=*/constFalse);\n+  }\n+};\n+\n+struct AbsFOpConversion\n+    : ElementwiseOpConversionBase<mlir::math::AbsFOp, AbsFOpConversion> {\n+  using Base =\n+      ElementwiseOpConversionBase<mlir::math::AbsFOp, AbsFOpConversion>;\n+  using Base::Base;\n+  using Adaptor = typename Base::OpAdaptor;\n+\n+  Value createDestOp(mlir::math::AbsFOp op, OpAdaptor adaptor,\n+                     ConversionPatternRewriter &rewriter, Type elemTy,\n+                     ValueRange operands, Location loc) const {\n+    if (llvm::isa<IntegerType>(elemTy)) {\n+      // Mask out the sign bit\n+      auto num_bits =\n+          getElementTypeOrSelf(op.getType()).getIntOrFloatBitWidth();\n+      assert(num_bits <= 16);\n+      auto mask = (1u << (num_bits - 1u)) - 1u;\n+      auto maskAttr = rewriter.getIntegerAttr(elemTy, mask);\n+      auto maskConst = rewriter.create<LLVM::ConstantOp>(loc, maskAttr);\n+      return and_(operands[0], maskConst);\n+    }\n+\n+    return rewriter.create<LLVM::FAbsOp>(loc, elemTy, operands[0]);\n+  }\n+};\n+\n void populateElementwiseOpToLLVMPatterns(\n     TritonGPUToLLVMTypeConverter &typeConverter, RewritePatternSet &patterns,\n     int numWarps, AxisInfoAnalysis &axisInfoAnalysis,\n@@ -1056,6 +1098,8 @@ void populateElementwiseOpToLLVMPatterns(\n   POPULATE_UNARY_OP(triton::PtrToIntOp, LLVM::PtrToIntOp)\n #undef POPULATE_UNARY_OP\n \n+  patterns.add<AbsIOpConversion>(typeConverter, benefit);\n+  patterns.add<AbsFOpConversion>(typeConverter, benefit);\n   patterns.add<CmpIOpConversion>(typeConverter, benefit);\n   patterns.add<CmpFOpConversion>(typeConverter, benefit);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/GCNAsmFormat.cpp", "status": "added", "additions": 191, "deletions": 0, "changes": 191, "file_content_changes": "@@ -0,0 +1,191 @@\n+#include \"triton/Conversion/TritonGPUToLLVM/GCNAsmFormat.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n+#include \"triton/Conversion/TritonGPUToLLVM/AsmFormat.h\"\n+#include \"llvm/Support/raw_ostream.h\"\n+#include <sstream> // unify to llvm::raw_string_ostream ?\n+\n+namespace mlir {\n+namespace triton {\n+\n+GCNInstr::Operand *\n+GCNBuilder::newOperand(mlir::Value value, StringRef constraint,\n+                       std::function<std::string(int)> formatter) {\n+  argArchive.emplace_back(std::make_unique<Operand>(value, constraint));\n+  auto *opr = argArchive.back().get();\n+  opr->repr = formatter;\n+  opr->idx = oprCounter++;\n+  return opr;\n+}\n+\n+GCNBuilder::Operand *GCNBuilder::newOperand(StringRef constraint) {\n+  // Constraint should be something like \"=r\"\n+  assert(!constraint.empty() && constraint[0] == '=');\n+  auto *opr = newOperand();\n+  opr->idx = oprCounter++;\n+  opr->constraint = constraint;\n+  return opr;\n+}\n+\n+GCNBuilder::Modifier *GCNBuilder::newModifier(StringRef modifier,\n+                                              StringRef arg) {\n+  assert(!modifier.empty());\n+  auto *mod = newModifier();\n+  mod->modifier = modifier;\n+  mod->arg = arg;\n+  return mod;\n+}\n+\n+GCNBuilder::Operand *GCNBuilder::newConstantOperand(const std::string &v) {\n+  argArchive.emplace_back(std::make_unique<Operand>());\n+  argArchive.back()->repr = [v](int idx) { return v; };\n+  return argArchive.back().get();\n+}\n+\n+GCNBuilder::Operand *GCNBuilder::newConstantOperand(int v) {\n+  std::stringstream ss;\n+  ss << \"0x\" << std::hex << v;\n+  return newConstantOperand(ss.str());\n+}\n+\n+std::string GCNBuilder::getConstraints() const {\n+  auto args = getAllArgs();\n+  llvm::SmallVector<std::string, 4> argReprs;\n+  for (auto arg : args)\n+    argReprs.push_back(arg->constraint);\n+  return strJoin(argReprs, \",\");\n+}\n+\n+llvm::SmallVector<Value, 4> GCNBuilder::getAllMLIRArgs() const {\n+  llvm::SmallVector<Value, 4> res;\n+  for (auto &arg : argArchive) {\n+    if (!arg->isList() && arg->value)\n+      res.push_back(arg->value);\n+  }\n+  return res;\n+}\n+\n+SmallVector<GCNBuilder::Operand *, 4> GCNBuilder::getAllArgs() const {\n+  llvm::SmallVector<Operand *, 4> res;\n+  for (auto &x : argArchive)\n+    if (!x->isList())\n+      res.push_back(x.get());\n+  return res;\n+}\n+\n+mlir::Value GCNBuilder::launch(ConversionPatternRewriter &rewriter,\n+                               Location loc, Type resTy, bool hasSideEffect,\n+                               bool isAlignStack,\n+                               ArrayRef<Attribute> attrs) const {\n+  auto *ctx = rewriter.getContext();\n+  auto inlineAsm = rewriter.create<LLVM::InlineAsmOp>(\n+      loc, resTy, getAllMLIRArgs(), // operands\n+      dump(),                       // asm_string\n+      getConstraints(),             // constraints\n+      hasSideEffect,                // has_side_effects\n+      isAlignStack,                 // is_align_stack\n+      LLVM::AsmDialectAttr::get(ctx,\n+                                LLVM::AsmDialect::AD_ATT), // asm_dialect\n+      ArrayAttr::get(ctx, attrs)                           // operand_attrs\n+  );\n+\n+  return inlineAsm.getRes();\n+}\n+\n+std::string GCNInstr::Operand::dump() const {\n+  if (repr)\n+    return repr(idx);\n+  if (!isList())\n+    return \"$\" + std::to_string(idx);\n+\n+  llvm::SmallVector<std::string> oprs;\n+  for (auto *opr : list)\n+    oprs.push_back(opr->dump());\n+  return strJoin(oprs, \", \");\n+}\n+\n+std::string GCNInstr::Modifier::dump() const {\n+  if (!isList())\n+    return to_str();\n+\n+  llvm::SmallVector<std::string> mods;\n+  for (auto *mod : list)\n+    mods.push_back(mod->dump());\n+  return strJoin(mods, \" \");\n+}\n+\n+GCNInstr::Operand *GCNBuilder::newAddrOperand(mlir::Value addr,\n+                                              StringRef constraint) {\n+  auto *opr = newOperand(addr, constraint);\n+  opr->repr = [](int idx) -> std::string {\n+    std::stringstream ss;\n+    ss << \"$\" << idx;\n+    return ss.str();\n+  };\n+\n+  return opr;\n+}\n+\n+std::string GCNBuilder::dump() const {\n+  llvm::SmallVector<std::string> lines;\n+  for (auto &exec : executions) {\n+    lines.push_back(exec->dump());\n+  }\n+\n+  return strJoin(lines, \"\\n\\t\");\n+}\n+\n+GCNInstrExecution &GCNInstrCommon::call(ArrayRef<Operand *> oprs,\n+                                        ArrayRef<Modifier *> mods) {\n+  builder->executions.emplace_back(\n+      std::make_unique<GCNInstrExecution>(this, oprs, mods));\n+  return *builder->executions.back();\n+}\n+\n+GCNInstrExecution &GCNInstrCommon::operator()(ArrayRef<Operand *> oprs,\n+                                              ArrayRef<Modifier *> mods) {\n+  return call(oprs, mods);\n+}\n+\n+std::string GCNInstrExecution::dump() const {\n+  std::string osStr;\n+  llvm::raw_string_ostream os(osStr);\n+\n+  std::string instrRepr = strJoin(instr->instrParts, \"_\");\n+\n+  llvm::SmallVector<std::string, 4> argReprs;\n+  for (auto *arg : argsInOrder) {\n+    argReprs.push_back(arg->dump());\n+  }\n+\n+  std::string argsRepr = strJoin(argReprs, \", \");\n+\n+  llvm::SmallVector<std::string, 4> modReprs;\n+  for (auto *mod : mods) {\n+    modReprs.push_back(mod->dump());\n+  }\n+\n+  std::string modsRepr = strJoin(modReprs, \" \");\n+  if (!modsRepr.empty()) {\n+    os << instrRepr << \" \" << argsRepr << \" \" << modsRepr;\n+  } else {\n+    os << instrRepr << \" \" << argsRepr;\n+  }\n+  os.flush();\n+  return osStr;\n+}\n+\n+SmallVector<GCNInstrExecution::Operand *>\n+GCNInstrExecution::getArgList() const {\n+  SmallVector<Operand *> args;\n+  for (auto *arg : argsInOrder) {\n+    if (arg->isList())\n+      args.insert(args.end(), arg->list.begin(), arg->list.end());\n+    else\n+      args.push_back(arg);\n+  }\n+  return args;\n+}\n+\n+} // namespace triton\n+} // namespace mlir"}, {"filename": "lib/Conversion/TritonGPUToLLVM/PTXAsmFormat.cpp", "status": "modified", "additions": 1, "deletions": 14, "changes": 15, "file_content_changes": "@@ -1,27 +1,14 @@\n #include \"triton/Conversion/TritonGPUToLLVM/PTXAsmFormat.h\"\n-\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Transforms/DialectConversion.h\"\n+#include \"triton/Conversion/TritonGPUToLLVM/AsmFormat.h\"\n #include \"llvm/Support/raw_ostream.h\"\n // TODO(Superjomn): unify to llvm::raw_string_ostream\n #include <sstream>\n \n namespace mlir {\n namespace triton {\n \n-// TODO(Superjomn) Move to a global utility file?\n-std::string strJoin(llvm::ArrayRef<std::string> strs,\n-                    llvm::StringRef delimiter) {\n-  std::string osStr;\n-  llvm::raw_string_ostream os(osStr);\n-  for (size_t i = 0; !strs.empty() && i < strs.size() - 1; ++i)\n-    os << strs[i] << delimiter;\n-  if (!strs.empty())\n-    os << strs.back();\n-  os.flush();\n-  return osStr;\n-}\n-\n PTXInstr::Operand *\n PTXBuilder::newOperand(mlir::Value value, StringRef constraint,\n                        std::function<std::string(int)> formatter) {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 56, "deletions": 16, "changes": 72, "file_content_changes": "@@ -4,19 +4,22 @@\n #include \"mlir/Conversion/ArithToLLVM/ArithToLLVM.h\"\n #include \"mlir/Conversion/ControlFlowToLLVM//ControlFlowToLLVM.h\"\n #include \"mlir/Conversion/GPUToNVVM/GPUToNVVMPass.h\"\n+#include \"mlir/Conversion/GPUToROCDL/GPUToROCDLPass.h\"\n #include \"mlir/Conversion/LLVMCommon/VectorPattern.h\"\n #include \"mlir/Conversion/MathToLLVM/MathToLLVM.h\"\n #include \"mlir/Conversion/SCFToControlFlow/SCFToControlFlow.h\"\n #include \"mlir/Dialect/Index/IR/IndexDialect.h\"\n #include \"mlir/Dialect/Index/IR/IndexOps.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n+#include \"mlir/Dialect/LLVMIR/ROCDLDialect.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"triton/Analysis/Allocation.h\"\n #include \"triton/Analysis/AxisInfo.h\"\n #include \"triton/Analysis/Membar.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+#include \"triton/Tools/Sys/GetPlatform.hpp\"\n \n #include \"ConvertLayoutOpToLLVM.h\"\n #include \"DotOpToLLVM.h\"\n@@ -33,7 +36,7 @@ using namespace mlir;\n using namespace mlir::triton;\n \n #define GEN_PASS_CLASSES\n-#include \"triton/Conversion/Passes.h.inc\"\n+#include \"triton/Conversion/TritonGPUToLLVM/Passes.h.inc\"\n \n namespace {\n \n@@ -43,7 +46,11 @@ class TritonLLVMFunctionConversionTarget : public ConversionTarget {\n       : ConversionTarget(ctx) {\n     addLegalDialect<index::IndexDialect>();\n     addLegalDialect<LLVM::LLVMDialect>();\n-    addLegalDialect<NVVM::NVVMDialect>();\n+    if (isROCM()) {\n+      addLegalDialect<ROCDL::ROCDLDialect>();\n+    } else {\n+      addLegalDialect<NVVM::NVVMDialect>();\n+    }\n     addIllegalOp<mlir::func::FuncOp>();\n     addLegalOp<mlir::UnrealizedConversionCastOp>();\n   }\n@@ -54,11 +61,23 @@ class TritonPTXConversionTarget : public ConversionTarget {\n   explicit TritonPTXConversionTarget(MLIRContext &ctx) : ConversionTarget(ctx) {\n     addDynamicallyLegalDialect<LLVM::LLVMDialect>(\n         [&](Operation *op) { return isLegalElementwiseOp(op); });\n+\n     addLegalDialect<NVVM::NVVMDialect>();\n     addLegalOp<mlir::UnrealizedConversionCastOp>();\n   }\n };\n \n+class TritonGCNConversionTarget : public ConversionTarget {\n+public:\n+  explicit TritonGCNConversionTarget(MLIRContext &ctx) : ConversionTarget(ctx) {\n+    addDynamicallyLegalDialect<LLVM::LLVMDialect>(\n+        [&](Operation *op) { return isLegalElementwiseOp(op); });\n+\n+    addLegalDialect<ROCDL::ROCDLDialect>();\n+    addLegalOp<mlir::UnrealizedConversionCastOp>();\n+  }\n+};\n+\n struct ReturnOpConversion : public ConvertOpToLLVMPattern<func::ReturnOp> {\n   using ConvertOpToLLVMPattern<func::ReturnOp>::ConvertOpToLLVMPattern;\n \n@@ -119,7 +138,11 @@ class TritonLLVMConversionTarget : public ConversionTarget {\n   explicit TritonLLVMConversionTarget(MLIRContext &ctx)\n       : ConversionTarget(ctx) {\n     addLegalDialect<LLVM::LLVMDialect>();\n-    addLegalDialect<NVVM::NVVMDialect>();\n+    if (isROCM()) {\n+      addLegalDialect<ROCDL::ROCDLDialect>();\n+    } else {\n+      addLegalDialect<NVVM::NVVMDialect>();\n+    }\n     addIllegalDialect<triton::TritonDialect>();\n     addIllegalDialect<triton::gpu::TritonGPUDialect>();\n     addIllegalDialect<mlir::gpu::GPUDialect>();\n@@ -200,25 +223,42 @@ class ConvertTritonGPUToLLVM\n     populatePatterns1(populateLoadStoreOpToLLVMPatterns);\n     populatePatterns1(populateReduceOpToLLVMPatterns);\n     populatePatterns2(populateViewOpToLLVMPatterns);\n+\n     // Native lowering patterns\n-    mlir::populateGpuToNVVMConversionPatterns(typeConverter, patterns);\n+    if (isROCM()) {\n+      mlir::populateGpuToROCDLConversionPatterns(typeConverter, patterns,\n+                                                 mlir::gpu::amd::HIP);\n+    } else {\n+      mlir::populateGpuToNVVMConversionPatterns(typeConverter, patterns);\n+    }\n+\n     mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n                                                           patterns);\n     if (failed(applyPartialConversion(mod, target, std::move(patterns))))\n       return signalPassFailure();\n \n-    // Use our custom converters to convert some operations to PTX to avoid\n-    // using NVPTX for two reasons:\n-    // 1. NVPTX backend is flaky on data types like float16 and bfloat16\n-    // 2. In some cases, we may generate faster PTX code than NVPTX backend\n-    TritonPTXConversionTarget ptxTarget(*context);\n-    RewritePatternSet ptxPatterns(context);\n-    // Add patterns to convert LLVM to PTX\n-    populateElementwiseOpToPTXPatterns(typeConverter, ptxPatterns,\n-                                       /*benefits=*/10);\n-\n-    if (failed(applyPartialConversion(mod, ptxTarget, std::move(ptxPatterns))))\n-      return signalPassFailure();\n+    if (isROCM()) {\n+      TritonGCNConversionTarget gcnTarget(*context);\n+      RewritePatternSet gcnPatterns(context);\n+      populateElementwiseOpToPTXPatterns(typeConverter, gcnPatterns,\n+                                         /*benefits=*/10);\n+      if (failed(\n+              applyPartialConversion(mod, gcnTarget, std::move(gcnPatterns))))\n+        return signalPassFailure();\n+    } else {\n+      // Use our custom converters to convert some operations to PTX to avoid\n+      // using NVPTX for two reasons:\n+      // 1. NVPTX backend is flaky on data types like float16 and bfloat16\n+      // 2. In some cases, we may generate faster PTX code than NVPTX backend\n+      TritonPTXConversionTarget ptxTarget(*context);\n+      RewritePatternSet ptxPatterns(context);\n+      // Add patterns to convert LLVM to PTX\n+      populateElementwiseOpToPTXPatterns(typeConverter, ptxPatterns,\n+                                         /*benefits=*/10);\n+      if (failed(\n+              applyPartialConversion(mod, ptxTarget, std::move(ptxPatterns))))\n+        return signalPassFailure();\n+    }\n   }\n \n private:"}, {"filename": "lib/Conversion/TritonToTritonGPU/CMakeLists.txt", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -3,6 +3,7 @@ add_mlir_conversion_library(TritonToTritonGPU\n \n     ADDITIONAL_HEADER_DIRS\n     ${PROJECT_SOURCE_DIR}/include/triton/Conversion/TritonToTritonGPU\n+    ${PROJECT_BINARY_DIR}/include/triton/Conversion/TritonToTritonGPU\n \n     DEPENDS\n     TritonConversionPassIncGen"}, {"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPUPass.cpp", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -4,8 +4,6 @@\n #include \"mlir/Dialect/ControlFlow/IR/ControlFlowOps.h\"\n #include \"mlir/Dialect/GPU/IR/GPUDialect.h\"\n #include \"mlir/Dialect/Index/IR/IndexDialect.h\"\n-#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n-#include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Transforms/DialectConversion.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n@@ -18,7 +16,7 @@ using namespace mlir;\n using namespace mlir::triton;\n \n #define GEN_PASS_CLASSES\n-#include \"triton/Conversion/Passes.h.inc\"\n+#include \"triton/Conversion/TritonToTritonGPU/Passes.h.inc\"\n \n namespace {\n \n@@ -176,6 +174,7 @@ void populateMathPatternsAndLegality(TritonGPUTypeConverter &typeConverter,\n   // Rewrite rule\n   patterns.add<GenericOpPattern<math::ExpOp>, GenericOpPattern<math::CosOp>,\n                GenericOpPattern<math::SinOp>, GenericOpPattern<math::LogOp>,\n+               GenericOpPattern<math::AbsFOp>, GenericOpPattern<math::AbsIOp>,\n                GenericOpPattern<math::SqrtOp>>(typeConverter, context);\n }\n "}, {"filename": "lib/Target/CMakeLists.txt", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -1,2 +1,3 @@\n add_subdirectory(LLVMIR)\n add_subdirectory(PTX)\n+add_subdirectory(HSACO)"}, {"filename": "lib/Target/HSACO/CMakeLists.txt", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "file_content_changes": "@@ -0,0 +1,9 @@\n+add_mlir_translation_library(TritonHSACO\n+        HSACOTranslation.cpp\n+\n+        LINK_COMPONENTS\n+        Core\n+\n+        LINK_LIBS PUBLIC\n+        TritonLLVMIR\n+        )"}, {"filename": "lib/Target/HSACO/HSACOTranslation.cpp", "status": "added", "additions": 182, "deletions": 0, "changes": 182, "file_content_changes": "@@ -0,0 +1,182 @@\n+#include \"triton/Target/HSACO/HSACOTranslation.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n+#include \"mlir/ExecutionEngine/ExecutionEngine.h\"\n+#include \"mlir/ExecutionEngine/OptUtils.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/Dialect.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Pass/PassManager.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h\"\n+#include \"mlir/Target/LLVMIR/Export.h\"\n+#include \"mlir/Target/LLVMIR/LLVMTranslationInterface.h\"\n+#include \"triton/Target/LLVMIR/LLVMIRTranslation.h\"\n+#include \"triton/Tools/Sys/GetEnv.hpp\"\n+\n+#include \"llvm/ExecutionEngine/ExecutionEngine.h\"\n+#include \"llvm/ExecutionEngine/SectionMemoryManager.h\"\n+#include \"llvm/IR/IRBuilder.h\"\n+#include \"llvm/IR/IRPrintingPasses.h\"\n+#include \"llvm/IR/LegacyPassManager.h\"\n+#include \"llvm/IR/Module.h\"\n+#include \"llvm/IR/Verifier.h\"\n+#include \"llvm/MC/TargetRegistry.h\"\n+#include \"llvm/Support/CodeGen.h\"\n+#include \"llvm/Support/CommandLine.h\"\n+#include \"llvm/Support/SourceMgr.h\"\n+#include \"llvm/Support/TargetSelect.h\"\n+#include \"llvm/Support/raw_ostream.h\"\n+#include \"llvm/Target/TargetMachine.h\"\n+#include \"llvm/Target/TargetOptions.h\"\n+#include \"llvm/Transforms/Scalar.h\"\n+#include \"llvm/Transforms/Utils/Cloning.h\"\n+#include <filesystem>\n+#include <iostream>\n+#include <memory>\n+#include <random>\n+\n+namespace {\n+\n+void init_llvm() {\n+  LLVMInitializeAMDGPUTarget();\n+  LLVMInitializeAMDGPUTargetInfo();\n+  LLVMInitializeAMDGPUTargetMC();\n+  LLVMInitializeAMDGPUAsmParser();\n+  LLVMInitializeAMDGPUAsmPrinter();\n+}\n+\n+std::unique_ptr<llvm::TargetMachine>\n+initialize_module(llvm::Module *module, const std::string &triple,\n+                  const std::string &proc, const std::string &features) {\n+  // verify and store llvm\n+  llvm::legacy::PassManager pm;\n+  pm.add(llvm::createVerifierPass());\n+  pm.run(*module);\n+\n+  module->setTargetTriple(triple);\n+\n+  std::string error;\n+  auto target =\n+      llvm::TargetRegistry::lookupTarget(module->getTargetTriple(), error);\n+  llvm::TargetOptions opt;\n+  opt.AllowFPOpFusion = llvm::FPOpFusion::Fast;\n+  opt.UnsafeFPMath = false;\n+  opt.NoInfsFPMath = false;\n+  opt.NoNaNsFPMath = true;\n+  llvm::TargetMachine *machine = target->createTargetMachine(\n+      module->getTargetTriple(), proc, features, opt, llvm::Reloc::PIC_,\n+      std::nullopt, llvm::CodeGenOpt::Aggressive);\n+\n+  module->setDataLayout(machine->createDataLayout());\n+\n+  for (llvm::Function &f : module->functions())\n+    f.addFnAttr(llvm::Attribute::AlwaysInline);\n+\n+  return std::unique_ptr<llvm::TargetMachine>(machine);\n+}\n+\n+std::string generate_amdgcn_assembly(llvm::Module *module,\n+                                     const std::string &triple,\n+                                     const std::string &proc,\n+                                     const std::string &features) {\n+  auto machine = initialize_module(module, triple, proc, features);\n+  llvm::SmallVector<char, 0> buffer;\n+  llvm::legacy::PassManager pass;\n+  llvm::raw_svector_ostream stream(buffer);\n+\n+  // emit\n+  machine->addPassesToEmitFile(pass, stream, nullptr,\n+                               llvm::CodeGenFileType::CGFT_AssemblyFile);\n+  pass.run(*module);\n+\n+  std::string amdgcn(buffer.begin(), buffer.end());\n+  if (::triton::tools::getBoolEnv(\"AMDGCN_ENABLE_DUMP\")) {\n+    std::cout << \"// -----// AMDGCN Dump //----- //\\n\" << amdgcn << std::endl;\n+  }\n+\n+  return amdgcn;\n+}\n+\n+std::string generate_hsaco(llvm::Module *module, const std::string &triple,\n+                           const std::string &proc,\n+                           const std::string &features) {\n+  auto machine = initialize_module(module, triple, proc, features);\n+\n+  // create unique dir for kernel's binary and hsaco\n+  std::error_code ec;\n+  std::string kernel_name_base = \"amd_triton_kernel\";\n+  std::filesystem::path tmp = std::filesystem::temp_directory_path();\n+  std::filesystem::path kernel_dir_base(kernel_name_base);\n+  llvm::SmallString<256> unique_dir;\n+  ec = llvm::sys::fs::createUniqueDirectory((tmp / kernel_dir_base).string(),\n+                                            unique_dir);\n+  if (ec) {\n+    std::cerr << \"Directory for \" << kernel_name_base\n+              << \" was not created. error code: \" << ec << std::endl;\n+  }\n+  std::filesystem::path kernel_dir(unique_dir.data());\n+  std::string kernel_name = kernel_dir.stem();\n+\n+  // Save GCN ISA binary.\n+  std::filesystem::path isa_binary(kernel_name + \".o\");\n+  std::string isabin_path = (kernel_dir / isa_binary).string();\n+  std::unique_ptr<llvm::raw_fd_ostream> isabin_fs(\n+      new llvm::raw_fd_ostream(isabin_path, ec, llvm::sys::fs::OF_Text));\n+  if (ec) {\n+    std::cerr << isabin_path << \" was not created. error code: \" << ec\n+              << std::endl;\n+  }\n+\n+  // emit\n+  llvm::legacy::PassManager pass;\n+  machine->addPassesToEmitFile(pass, *isabin_fs, nullptr,\n+                               llvm::CGFT_ObjectFile);\n+  pass.run(*module);\n+\n+  // generate HASCO file\n+  std::filesystem::path hsaco(kernel_name + \".hsaco\");\n+  std::string hsaco_path = (kernel_dir / hsaco).string();\n+  std::string error_message;\n+  std::string lld_path = \"/opt/rocm/llvm/bin/ld.lld\";\n+  int lld_result = llvm::sys::ExecuteAndWait(\n+      lld_path,\n+      {lld_path, \"-flavor\", \"gnu\", \"-shared\", \"-o\", hsaco_path, isabin_path},\n+      std::nullopt, {}, 0, 0, &error_message);\n+  if (lld_result) {\n+    std::cout << \"ld.lld execute fail: \" << std::endl;\n+    std::cout << error_message << std::endl;\n+    std::cout << lld_result << std::endl;\n+  }\n+\n+  return hsaco_path;\n+}\n+\n+std::tuple<std::string, std::string>\n+llir_to_amdgcn_and_hsaco(llvm::Module *module, std::string gfx_arch,\n+                         std::string gfx_triple, std::string gfx_features) {\n+\n+  init_llvm();\n+\n+  // verify and store llvm\n+  auto module_obj = llvm::CloneModule(*module);\n+  auto amdgcn =\n+      generate_amdgcn_assembly(module, gfx_triple, gfx_arch, gfx_features);\n+  auto hsaco_path =\n+      generate_hsaco(module_obj.get(), gfx_triple, gfx_arch, gfx_features);\n+\n+  return std::make_tuple(amdgcn, hsaco_path);\n+}\n+\n+} // namespace\n+\n+namespace triton {\n+\n+std::tuple<std::string, std::string>\n+translateLLVMIRToHSACO(llvm::Module &module, std::string gfx_arch,\n+                       std::string gfx_triple, std::string gfx_features) {\n+  auto hsacoCode =\n+      llir_to_amdgcn_and_hsaco(&module, gfx_arch, gfx_triple, gfx_features);\n+  return hsacoCode;\n+}\n+\n+} // namespace triton"}, {"filename": "lib/Target/LLVMIR/LLVMIRTranslation.cpp", "status": "modified", "additions": 32, "deletions": 10, "changes": 42, "file_content_changes": "@@ -9,14 +9,17 @@\n #include \"mlir/Pass/PassManager.h\"\n #include \"mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Dialect/NVVM/NVVMToLLVMIRTranslation.h\"\n+#include \"mlir/Target/LLVMIR/Dialect/ROCDL/ROCDLToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Export.h\"\n #include \"mlir/Target/LLVMIR/LLVMTranslationInterface.h\"\n #include \"mlir/Transforms/Passes.h\"\n #include \"triton/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.h\"\n #include \"triton/Tools/Sys/GetEnv.hpp\"\n+#include \"triton/Tools/Sys/GetPlatform.hpp\"\n #include \"llvm/ADT/APInt.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/IR/CallingConv.h\"\n #include \"llvm/IR/Constants.h\"\n #include \"llvm/IRReader/IRReader.h\"\n #include \"llvm/Linker/Linker.h\"\n@@ -67,12 +70,17 @@ static void amendLLVMFunc(llvm::Function *func, const NVVMMetadata &metadata) {\n   }\n \n   if (metadata.isKernel) {\n-    llvm::Metadata *mdArgs[] = {\n-        llvm::ValueAsMetadata::get(func), llvm::MDString::get(ctx, \"kernel\"),\n-        llvm::ValueAsMetadata::get(\n-            llvm::ConstantInt::get(llvm::Type::getInt32Ty(ctx), 1))};\n-    module->getOrInsertNamedMetadata(\"nvvm.annotations\")\n-        ->addOperand(llvm::MDNode::get(ctx, mdArgs));\n+    if (isROCM()) {\n+      func->setCallingConv(llvm::CallingConv::AMDGPU_KERNEL);\n+      func->addFnAttr(\"amdgpu-flat-work-group-size\", \"1, 1024\");\n+    } else {\n+      llvm::Metadata *mdArgs[] = {\n+          llvm::ValueAsMetadata::get(func), llvm::MDString::get(ctx, \"kernel\"),\n+          llvm::ValueAsMetadata::get(\n+              llvm::ConstantInt::get(llvm::Type::getInt32Ty(ctx), 1))};\n+      module->getOrInsertNamedMetadata(\"nvvm.annotations\")\n+          ->addOperand(llvm::MDNode::get(ctx, mdArgs));\n+    }\n   }\n }\n \n@@ -220,10 +228,13 @@ static bool linkExternLib(llvm::Module &module, llvm::StringRef name,\n     return true;\n   }\n \n-  if (name == \"libdevice\") {\n-    linkLibdevice(module);\n-  } else {\n-    assert(false && \"unknown extern lib: \");\n+  // check if ROCM\n+  if (!isROCM()) {\n+    if (name == \"libdevice\") {\n+      linkLibdevice(module);\n+    } else {\n+      assert(false && \"unknown extern lib: \");\n+    }\n   }\n \n   return false;\n@@ -233,6 +244,7 @@ std::unique_ptr<llvm::Module>\n translateLLVMToLLVMIR(llvm::LLVMContext *llvmContext, mlir::ModuleOp module) {\n   DialectRegistry registry;\n   mlir::registerLLVMDialectTranslation(registry);\n+  mlir::registerROCDLDialectTranslation(registry);\n   mlir::registerNVVMDialectTranslation(registry);\n   module->getContext()->appendDialectRegistry(registry);\n \n@@ -313,6 +325,16 @@ translateTritonGPUToLLVMIR(llvm::LLVMContext *llvmContext,\n     llvm::errs() << \"Translate to LLVM IR failed\";\n     return nullptr;\n   }\n+\n+  if (::triton::tools::getBoolEnv(\"LLVM_IR_ENABLE_DUMP\")) {\n+    std::string mod_string;\n+    std::unique_ptr<llvm::raw_string_ostream> ir_ss(\n+        new llvm::raw_string_ostream(mod_string));\n+    llvmIR->print(*ir_ss, nullptr);\n+    std::cout << \"// -----// LLVM IR Dump //----- //\\n\"\n+              << mod_string << std::endl;\n+  }\n+\n   return llvmIR;\n }\n "}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 34, "deletions": 1, "changes": 35, "file_content_changes": "@@ -23,9 +23,11 @@\n #include \"triton/Dialect/Triton/IR/Types.h\"\n #include \"triton/Dialect/Triton/Transforms/Passes.h\"\n #include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n+#include \"triton/Target/HSACO/HSACOTranslation.h\"\n #include \"triton/Target/LLVMIR/LLVMIRTranslation.h\"\n #include \"triton/Target/PTX/PTXTranslation.h\"\n #include \"triton/Tools/Sys/GetEnv.hpp\"\n+#include \"triton/Tools/Sys/GetPlatform.hpp\"\n \n #include \"llvm/IR/LegacyPassManager.h\"\n #include \"llvm/IR/Module.h\"\n@@ -64,7 +66,7 @@ void init_triton_runtime(py::module &&m) {\n   py::enum_<backend_t>(m, \"backend\")\n       .value(\"HOST\", HOST)\n       .value(\"CUDA\", CUDA)\n-      // .value(\"ROCM\", ROCM)\n+      .value(\"ROCM\", ROCM)\n       .export_values();\n }\n \n@@ -1309,6 +1311,16 @@ void init_triton_ir(py::module &&m) {\n              auto loc = self.getUnknownLoc();\n              return self.create<mlir::math::SqrtOp>(loc, val);\n            })\n+      .def(\"create_fabs\",\n+           [](mlir::OpBuilder &self, mlir::Value &val) -> mlir::Value {\n+             auto loc = self.getUnknownLoc();\n+             return self.create<mlir::math::AbsFOp>(loc, val);\n+           })\n+      .def(\"create_iabs\",\n+           [](mlir::OpBuilder &self, mlir::Value &val) -> mlir::Value {\n+             auto loc = self.getUnknownLoc();\n+             return self.create<mlir::math::AbsIOp>(loc, val);\n+           })\n       .def(\"create_reduce\",\n            [](mlir::OpBuilder &self, mlir::Value &operand,\n               mlir::triton::RedOp redOp, int axis) -> mlir::Value {\n@@ -1487,6 +1499,9 @@ void init_triton_translation(py::module &m) {\n     return shared.getInt();\n   });\n \n+  m.def(\n+      \"set_rocm\", []() { setROCM(); }, ret::take_ownership);\n+\n   m.def(\n       \"translate_triton_gpu_to_llvmir\",\n       [](mlir::ModuleOp op, int computeCapability) {\n@@ -1587,6 +1602,24 @@ void init_triton_translation(py::module &m) {\n            const std::vector<std::string> &paths) {\n           ::mlir::triton::addExternalLibs(op, names, paths);\n         });\n+\n+  m.def(\n+      \"translate_llvmir_to_hsaco\",\n+      [](const std::string llvmIR, std::string gfx_arch, std::string gfx_triple,\n+         std::string gfx_features) -> std::tuple<std::string, std::string> {\n+        // create LLVM module from C++\n+        llvm::LLVMContext context;\n+        std::unique_ptr<llvm::MemoryBuffer> buffer =\n+            llvm::MemoryBuffer::getMemBuffer(llvmIR.c_str());\n+        llvm::SMDiagnostic error;\n+        std::unique_ptr<llvm::Module> module =\n+            llvm::parseIR(buffer->getMemBufferRef(), error, context);\n+        // translate module to HSACO\n+        auto hsacoCode = triton::translateLLVMIRToHSACO(\n+            *module, gfx_arch, gfx_triple, gfx_features);\n+        return hsacoCode;\n+      },\n+      ret::take_ownership);\n }\n \n void init_triton(py::module &m) {"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "file_content_changes": "@@ -532,6 +532,33 @@ def test_math_op(expr, device='cuda'):\n def test_abs(dtype_x, device='cuda'):\n     _test_unary(dtype_x, 'tl.abs(x)', 'np.abs(x) ', device=device)\n \n+\n+@pytest.mark.parametrize(\"in_dtype\", [tl.float8e4, tl.float8e5])\n+def test_abs_f8(in_dtype):\n+\n+    @triton.jit\n+    def abs_kernel(Z, X, SIZE: tl.constexpr):\n+        off = tl.arange(0, SIZE)\n+        x = tl.load(X + off)\n+        z = tl.abs(x)\n+        tl.store(Z + off, z)\n+\n+    f8_tensor = torch.tensor(range(-128, 128), dtype=torch.int8, device='cuda')\n+    # f32_to_f8 doesn't handle nan, so we make sure f8_tensor doesn't contain any nan\n+    all_exp_ones = (f8_tensor & 0b01111100) == 128 - 2**in_dtype.fp_mantissa_width\n+    f8_tensor[all_exp_ones] = 0\n+    f8 = triton.reinterpret(f8_tensor, in_dtype)\n+    n_elements = f8_tensor.numel()\n+    out_f8 = torch.empty_like(f8_tensor)\n+    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n+    abs_kernel[(1,)](f8, triton.reinterpret(out_f8, in_dtype), n_elements)\n+\n+    f32_tensor = convert_float_to_float32(f8_tensor, in_dtype)\n+    expect = f32_tensor.abs()\n+    actual_f8 = convert_float_to_float32(out_f8, in_dtype)\n+    torch.testing.assert_allclose(expect, actual_f8)\n+\n+\n # ----------------\n # test indexing\n # ----------------"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 490, "deletions": 45, "changes": 535, "file_content_changes": "@@ -19,6 +19,7 @@\n from typing import Any, Callable, Dict, Optional, Tuple, Type, Union\n \n import setuptools\n+import torch\n from filelock import FileLock\n \n import triton\n@@ -27,6 +28,14 @@\n from .tools.disasm import extract\n \n \n+def static_vars(**kwargs):\n+    def decorate(func):\n+        for k in kwargs:\n+            setattr(func, k, kwargs[k])\n+        return func\n+    return decorate\n+\n+\n def str_to_ty(name):\n     if name[0] == \"*\":\n         ty = str_to_ty(name[1:])\n@@ -1136,13 +1145,11 @@ def ttgir_to_llir(mod, extern_libs, compute_capability):\n     return _triton.translate_triton_gpu_to_llvmir(mod, compute_capability)\n \n \n-def llir_to_ptx(mod: Any, compute_capability: int, ptx_version: int = None) -> Tuple[str, int]:\n+def llir_to_ptx(mod: Any, compute_capability: int, ptx_version: int = None) -> str:\n     '''\n     Translate TritonGPU module to PTX code.\n     :param mod: a TritonGPU dialect module\n-    :return:\n-        - PTX code\n-        - shared memory allocation size\n+    :return: PTX code\n     '''\n     if ptx_version is None:\n         _, cuda_version = path_to_ptxas()\n@@ -1174,6 +1181,29 @@ def ptx_get_kernel_name(ptx: str) -> str:\n             return line.split()[-1]\n \n \n+def amdgcn_get_kernel_name(amdgcn: str) -> str:\n+    '''\n+    Get kernel name from AMDGCN code.\n+    This Kernel name is required when launching the kernel.\n+    '''\n+    assert amdgcn\n+    for line in amdgcn.split('\\n'):\n+        line = line.strip()\n+        if line.startswith('.globl'):\n+            return line.split()[-1].strip()\n+\n+\n+def llir_to_amdgcn_and_hsaco(mod: Any, gfx_arch: str, gfx_triple: str, gfx_features: str) -> Tuple[str, str]:\n+    '''\n+    Translate TritonGPU module to HSACO code based on full details of gpu architecture.\n+    :param mod: a TritonGPU dialect module\n+    :return:\n+        - AMDGCN code\n+        - Path to HSACO object\n+    '''\n+    return _triton.translate_llvmir_to_hsaco(mod, gfx_arch, gfx_triple, gfx_features)\n+\n+\n @functools.lru_cache\n def ptx_get_version(cuda_version) -> int:\n     '''\n@@ -1217,7 +1247,7 @@ def path_to_ptxas():\n \n def ty_to_cpp(ty):\n     if ty[0] == '*':\n-        return \"CUdeviceptr\"\n+        return \"hipDeviceptr_t\" if torch.version.hip is not None else \"CUdeviceptr\"\n     return {\n         \"i1\": \"int32_t\",\n         \"i8\": \"int8_t\",\n@@ -1282,7 +1312,148 @@ def format_of(ty):\n     format = \"iiiiiKKOOO\" + ''.join([format_of(_extracted_type(ty)) for ty in signature.values()])\n \n     # generate glue code\n-    src = f\"\"\"\n+    if torch.version.hip is not None:\n+        src = f\"\"\"\n+    #define __HIP_PLATFORM_AMD__\n+    #include <hip/hip_runtime.h>\n+    #include <Python.h>\n+    #include <stdio.h>\n+\n+    static inline void gpuAssert(hipError_t code, const char *file, int line)\n+    {{\n+      if (code != HIP_SUCCESS)\n+      {{\n+         const char* prefix = \"Triton Error [HIP]: \";\n+         const char* str = hipGetErrorString(code);\n+         char err[1024] = {{0}};\n+         snprintf(err, 1024, \"%s Code: %d, Messsage: %s\", prefix, code, str );\n+         PyErr_SetString(PyExc_RuntimeError, err);\n+      }}\n+    }}\n+\n+    #define HIP_CHECK(ans) {{ gpuAssert((ans), __FILE__, __LINE__); }}\n+\n+    static void _launch(int gridX, int gridY, int gridZ, int num_warps, int shared_memory, hipStream_t stream, hipFunction_t function, {arg_decls}) {{\n+      void *params[] = {{ {', '.join(f\"&arg{i}\" for i in signature.keys() if i not in constants)} }};\n+      if (gridX*gridY*gridZ > 0) {{\n+          HIP_CHECK(hipModuleLaunchKernel(function, gridX, gridY, gridZ, 64*num_warps, 1, 1, shared_memory, stream, params, 0));\n+      }}\n+    }}\n+\n+    typedef struct _DevicePtrInfo {{\n+      hipDeviceptr_t dev_ptr;\n+      bool valid;\n+    }} DevicePtrInfo;\n+\n+    static inline DevicePtrInfo getPointer(PyObject *obj, int idx) {{\n+      DevicePtrInfo ptr_info;\n+      ptr_info.dev_ptr = 0;\n+      ptr_info.valid = true;\n+\n+      if (PyLong_Check(obj)) {{\n+        ptr_info.dev_ptr = (hipDeviceptr_t)PyLong_AsUnsignedLongLong(obj);\n+        return ptr_info;\n+      }}\n+\n+      if (obj == Py_None) {{\n+        // valid nullptr\n+        return ptr_info;\n+      }}\n+\n+      PyObject *ptr = PyObject_GetAttrString(obj, \"data_ptr\");\n+\n+      if (ptr) {{\n+        PyObject *empty_tuple = PyTuple_New(0);\n+        PyObject *ret = PyObject_Call(ptr, empty_tuple, NULL);\n+        Py_DECREF(empty_tuple);\n+        Py_DECREF(ptr);\n+\n+        if (!PyLong_Check(ret)) {{\n+          PyErr_SetString(PyExc_TypeError, \"data_ptr method of Pointer object must return 64-bit int\");\n+          ptr_info.valid = false;\n+          return ptr_info;\n+        }}\n+\n+        ptr_info.dev_ptr = (hipDeviceptr_t)PyLong_AsUnsignedLongLong(ret);\n+\n+        if (!ptr_info.dev_ptr)\n+          return ptr_info;\n+\n+        uint64_t dev_ptr;\n+        hipError_t status = hipPointerGetAttribute(&dev_ptr, HIP_POINTER_ATTRIBUTE_DEVICE_POINTER, ptr_info.dev_ptr);\n+        if (status == hipErrorInvalidValue) {{\n+            PyErr_Format(PyExc_ValueError,\n+                         \"Pointer argument (at %d) cannot be accessed from Triton (cpu tensor?)\", idx);\n+            ptr_info.valid = false;\n+        }}\n+\n+        ptr_info.dev_ptr = (hipDeviceptr_t)dev_ptr;\n+        return ptr_info;\n+      }}\n+\n+      PyErr_SetString(PyExc_TypeError, \"Pointer argument must be either uint64 or have data_ptr method\");\n+      return ptr_info;\n+    }}\n+\n+    static PyObject* launch(PyObject* self, PyObject* args) {{\n+\n+      int gridX, gridY, gridZ;\n+      uint64_t _stream;\n+      uint64_t _function;\n+      int num_warps;\n+      int shared_memory;\n+      PyObject *launch_enter_hook = NULL;\n+      PyObject *launch_exit_hook = NULL;\n+      PyObject *compiled_kernel = NULL;\n+\n+      {' '.join([f\"{_extracted_type(ty)} _arg{i}; \" for i, ty in signature.items()])}\n+      if (!PyArg_ParseTuple(args, \\\"{format}\\\", &gridX, &gridY, &gridZ, &num_warps, &shared_memory, &_stream, &_function, &launch_enter_hook, &launch_exit_hook, &compiled_kernel, {', '.join(f\"&_arg{i}\" for i, ty in signature.items())})) {{\n+        return NULL;\n+      }}\n+\n+      if (launch_enter_hook != Py_None) {{\n+        PyObject_CallObject(launch_enter_hook, args);\n+      }}\n+\n+      // raise exception asap\n+      {\"; \".join([f\"DevicePtrInfo ptr_info{i} = getPointer(_arg{i}, {i}); if (!ptr_info{i}.valid) return NULL;\" if ty[0] == \"*\" else \"\" for i, ty in signature.items()])};\n+      _launch(gridX, gridY, gridZ, num_warps, shared_memory, (hipStream_t)_stream, (hipFunction_t)_function, {', '.join(f\"ptr_info{i}.dev_ptr\" if ty[0]==\"*\" else f\"_arg{i}\" for i, ty in signature.items())});\n+      if (launch_exit_hook != Py_None) {{\n+        PyObject_CallObject(launch_exit_hook, args);\n+      }}\n+      if (PyErr_Occurred()) {{\n+        return NULL;\n+      }}\n+\n+      // return None\n+      Py_INCREF(Py_None);\n+      return Py_None;\n+    }}\n+\n+    static PyMethodDef ModuleMethods[] = {{\n+      {{\"launch\", launch, METH_VARARGS, \"Entry point for all kernels with this signature\"}},\n+      {{NULL, NULL, 0, NULL}} // sentinel\n+    }};\n+\n+    static struct PyModuleDef ModuleDef = {{\n+      PyModuleDef_HEAD_INIT,\n+      \\\"__triton_launcher\\\",\n+      NULL, //documentation\n+      -1, //size\n+      ModuleMethods\n+    }};\n+\n+    PyMODINIT_FUNC PyInit___triton_launcher(void) {{\n+      PyObject *m = PyModule_Create(&ModuleDef);\n+      if(m == NULL) {{\n+        return NULL;\n+      }}\n+      PyModule_AddFunctions(m, ModuleMethods);\n+      return m;\n+    }}\n+    \"\"\"\n+    else:\n+        src = f\"\"\"\n #include \\\"cuda.h\\\"\n #include <stdbool.h>\n #include <Python.h>\n@@ -1413,7 +1584,6 @@ def format_of(ty):\n   return m;\n }}\n \"\"\"\n-\n     return src\n \n \n@@ -1476,17 +1646,26 @@ def quiet():\n         sys.stdout, sys.stderr = old_stdout, old_stderr\n \n \n+@functools.lru_cache()\n+def rocm_path_dir():\n+    return os.getenv(\"ROCM_PATH\", default=\"/opt/rocm\")\n+\n+\n def _build(name, src, srcdir):\n-    cuda_lib_dirs = libcuda_dirs()\n-    base_dir = os.path.dirname(__file__)\n-    cuda_path = os.path.join(base_dir, \"third_party\", \"cuda\")\n-\n-    cu_include_dir = os.path.join(cuda_path, \"include\")\n-    triton_include_dir = os.path.join(os.path.dirname(__file__), \"include\")\n-    cuda_header = os.path.join(cu_include_dir, \"cuda.h\")\n-    triton_cuda_header = os.path.join(triton_include_dir, \"cuda.h\")\n-    if not os.path.exists(cuda_header) and os.path.exists(triton_cuda_header):\n-        cu_include_dir = triton_include_dir\n+    if torch.version.hip is not None:\n+        hip_lib_dir = os.path.join(rocm_path_dir(), \"lib\")\n+        hip_include_dir = os.path.join(rocm_path_dir(), \"include\")\n+    else:\n+        cuda_lib_dirs = libcuda_dirs()\n+        base_dir = os.path.dirname(__file__)\n+        cuda_path = os.path.join(base_dir, \"third_party\", \"cuda\")\n+\n+        cu_include_dir = os.path.join(cuda_path, \"include\")\n+        triton_include_dir = os.path.join(os.path.dirname(__file__), \"include\")\n+        cuda_header = os.path.join(cu_include_dir, \"cuda.h\")\n+        triton_cuda_header = os.path.join(triton_include_dir, \"cuda.h\")\n+        if not os.path.exists(cuda_header) and os.path.exists(triton_cuda_header):\n+            cu_include_dir = triton_include_dir\n     suffix = sysconfig.get_config_var('EXT_SUFFIX')\n     so = os.path.join(srcdir, '{name}{suffix}'.format(name=name, suffix=suffix))\n     # try to avoid setuptools if possible\n@@ -1509,9 +1688,12 @@ def _build(name, src, srcdir):\n         scheme = 'posix_prefix'\n     py_include_dir = sysconfig.get_paths(scheme=scheme)[\"include\"]\n \n-    cc_cmd = [cc, src, \"-O3\", f\"-I{cu_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", \"-lcuda\", \"-o\", so]\n-    cc_cmd += [f\"-L{dir}\" for dir in cuda_lib_dirs]\n-    ret = subprocess.check_call(cc_cmd)\n+    if torch.version.hip is not None:\n+        ret = subprocess.check_call([cc, src, f\"-I{hip_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", f\"-L{hip_lib_dir}\", \"-lamdhip64\", \"-o\", so])\n+    else:\n+        cc_cmd = [cc, src, \"-O3\", f\"-I{cu_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", \"-lcuda\", \"-o\", so]\n+        cc_cmd += [f\"-L{dir}\" for dir in cuda_lib_dirs]\n+        ret = subprocess.check_call(cc_cmd)\n \n     if ret == 0:\n         return so\n@@ -1581,7 +1763,26 @@ def read_or_execute(cache_manager, force_compile, file_name, metadata,\n     cache_manager.put(data, file_name, True if isinstance(data, bytes) else data)\n     return module, md5, True, False\n \n-#\n+\n+def get_amdgpu_arch_fulldetails():\n+    \"\"\"\n+    get the amdgpu fulll ISA details for compiling:\n+    i.e., arch_triple: amdgcn-amd-amdhsa; arch_name: gfx906; arch_features: sramecc+:xnack-\n+    \"\"\"\n+    try:\n+        rocminfo = subprocess.check_output(rocm_path_dir() + '/bin/rocminfo').decode()\n+        gfx_arch_details = re.search('amd.*', rocminfo).group(0).strip().split('--')\n+        arch_triple = gfx_arch_details[0]\n+        arch_name_features = gfx_arch_details[1].split(':')\n+        arch_name = arch_name_features[0]\n+        arch_features = \"\"\n+\n+        if (len(arch_name_features) == 3):\n+            arch_features = \"+\" + re.search('\\\\w+', arch_name_features[1]).group(0) + \",\"\\\n+                            \"-\" + re.search('\\\\w+', arch_name_features[2]).group(0)\n+        return [arch_triple, arch_name, arch_features]\n+    except BaseException:\n+        return None\n \n \n def make_stub(name, signature, constants):\n@@ -1665,6 +1866,7 @@ def _is_jsonable(x):\n # def compile(fn, signature: str, device: int = -1, constants=dict(), num_warps: int = 4, num_stages: int = 3, extern_libs=None, configs=None):\n \n \n+@static_vars(discovered_gfx_arch_fulldetails=get_amdgpu_arch_fulldetails())\n def compile(fn, **kwargs):\n     capability = kwargs.get(\"cc\", None)\n     if capability is None:\n@@ -1682,19 +1884,49 @@ def compile(fn, **kwargs):\n     extern_libs = kwargs.get(\"extern_libs\", dict())\n     debug = kwargs.get(\"debug\", False)\n     # build compilation stages\n-    stages = {\n-        \"ast\": (lambda path: fn, None),\n-        \"ttir\": (lambda path: parse_mlir_module(path, context),\n-                 lambda src: ast_to_ttir(src, signature, configs[0], constants, debug)),\n-        \"ttgir\": (lambda path: parse_mlir_module(path, context),\n-                  lambda src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, capability)),\n-        \"llir\": (lambda path: Path(path).read_text(),\n-                 lambda src: ttgir_to_llir(src, extern_libs, capability)),\n-        \"ptx\": (lambda path: Path(path).read_text(),\n-                lambda src: llir_to_ptx(src, capability)),\n-        \"cubin\": (lambda path: Path(path).read_bytes(),\n-                  lambda src: ptx_to_cubin(src, capability))\n-    }\n+    if torch.version.hip is not None:\n+        _triton.set_rocm()\n+        if extern_libs is None:\n+            extern_libs = get_amdgcn_bitcode_paths()\n+        else:\n+            extern_libs.update(get_amdgcn_bitcode_paths())\n+\n+        for key in list(extern_libs):\n+            if extern_libs[key] == '' or extern_libs[key] is None:\n+                extern_libs.pop(key)\n+\n+        gfx_arch_full_details = compile.discovered_gfx_arch_fulldetails\n+        gfx_arch = os.environ.get('MI_GPU_ARCH', gfx_arch_full_details[1])\n+        if gfx_arch is None:\n+            raise RuntimeError('gfx_arch is None (not specified)')\n+        stages = {\n+            \"ast\": (lambda path: fn, None),\n+            \"ttir\": (lambda path: parse_mlir_module(path, context),\n+                     lambda src: ast_to_ttir(src, signature, configs[0], constants)),\n+            \"ttgir\": (lambda path: parse_mlir_module(path, context),\n+                      lambda src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, capability)),\n+            \"llir\": (lambda path: Path(path).read_text(),\n+                     lambda src: ttgir_to_llir(src, extern_libs, capability)),\n+            \"amdgcn\": (lambda path: Path(path).read_text(),\n+                       lambda src: llir_to_amdgcn_and_hsaco(src, gfx_arch,\n+                                                            gfx_arch_full_details[0],\n+                                                            gfx_arch_full_details[2])),\n+        }\n+    else:\n+        stages = {\n+            \"ast\": (lambda path: fn, None),\n+            \"ttir\": (lambda path: parse_mlir_module(path, context),\n+                     lambda src: ast_to_ttir(src, signature, configs[0], constants, debug)),\n+            \"ttgir\": (lambda path: parse_mlir_module(path, context),\n+                      lambda src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, capability)),\n+            \"llir\": (lambda path: Path(path).read_text(),\n+                     lambda src: ttgir_to_llir(src, extern_libs, capability)),\n+            \"ptx\": (lambda path: Path(path).read_text(),\n+                    lambda src: llir_to_ptx(src, capability)),\n+            \"cubin\": (lambda path: Path(path).read_bytes(),\n+                      lambda src: ptx_to_cubin(src, capability))\n+        }\n+\n     # find out the signature of the function\n     if isinstance(fn, triton.runtime.JITFunction):\n         configs = kwargs.get(\"configs\", None)\n@@ -1748,31 +1980,85 @@ def compile(fn, **kwargs):\n     asm = dict()\n     module = fn\n     # run compilation pipeline  and populate metadata\n-    for ir, (parse, compile) in list(stages.items())[first_stage:]:\n+    for ir, (parse, compile_kernel) in list(stages.items())[first_stage:]:\n         path = fn_cache_manager._make_path(f\"{name}.{ir}\")\n         if ir == ext:\n             next_module = parse(fn)\n         elif os.path.exists(path) and\\\n                 ir in metadata[\"ctime\"] and\\\n                 os.path.getctime(path) == metadata[\"ctime\"][ir]:\n-            next_module = parse(path)\n+            if ir == \"amdgcn\":\n+                next_module = (parse(path), parse(fn_cache_manager._make_path(f\"{name}.hsaco_path\")))\n+            else:\n+                next_module = parse(path)\n         else:\n-            next_module = compile(module)\n-            fn_cache_manager.put(next_module, f\"{name}.{ir}\")\n+            next_module = compile_kernel(module)\n+            if ir == \"amdgcn\":\n+                fn_cache_manager.put(next_module[0], f\"{name}.{ir}\")\n+                fn_cache_manager.put(next_module[1], f\"{name}.hsaco_path\")\n+            else:\n+                fn_cache_manager.put(next_module, f\"{name}.{ir}\")\n         if os.path.exists(path):\n             metadata[\"ctime\"][ir] = os.path.getctime(path)\n-        asm[ir] = next_module if ir == \"cubin\" else str(next_module)\n+        if ir == \"cubin\":\n+            asm[ir] = next_module\n+        elif ir == \"amdgcn\":\n+            asm[ir] = str(next_module[0])\n+        else:\n+            asm[ir] = str(next_module)\n         if ir == \"llir\" and \"shared\" not in metadata:\n             metadata[\"shared\"] = _triton.get_shared_memory_size(module)\n         if ir == \"ptx\":\n             metadata[\"name\"] = ptx_get_kernel_name(next_module)\n+        if ir == \"amdgcn\":\n+            metadata[\"name\"] = amdgcn_get_kernel_name(next_module[0])\n+            asm[\"hsaco_path\"] = next_module[1]\n         module = next_module\n     # write-back metadata\n     fn_cache_manager.put(json.dumps(metadata), f\"{name}.json\", binary=False)\n     # return handle to compiled kernel\n     return CompiledKernel(fn, so_path, metadata, asm)\n \n \n+@static_vars(discovered_gfx_arch_fulldetails=get_amdgpu_arch_fulldetails())\n+def _get_amdgcn_bitcode_paths():\n+    if torch.version.hip is not None:\n+        gpu_arch_agnostic_bitcode_libraries = [\"opencl.bc\",\n+                                               \"ocml.bc\",\n+                                               \"ockl.bc\",\n+                                               \"oclc_finite_only_off.bc\",\n+                                               \"oclc_daz_opt_off.bc\",\n+                                               \"oclc_correctly_rounded_sqrt_on.bc\",\n+                                               \"oclc_unsafe_math_off.bc\",\n+                                               \"oclc_wavefrontsize64_on.bc\"]\n+\n+        gfx_arch = _get_amdgcn_bitcode_paths.discovered_gfx_arch_fulldetails[1]\n+        gfx_arch_id = re.search('gfx(\\\\w+)', gfx_arch).group(1).strip()\n+\n+        gpu_arch_specific_bitcode_library = 'oclc_isa_version_' + gfx_arch_id + \".bc\"\n+        bitcode_path_dir = os.path.join(Path(__file__).parent.resolve(), \"third_party/rocm/lib/bitcode/\")\n+\n+        amdgcn_bitcode_paths = {}\n+        i = 1\n+        for bc_lib in gpu_arch_agnostic_bitcode_libraries:\n+            bc_path = bitcode_path_dir + bc_lib\n+            if os.path.exists(bc_path):\n+                amdgcn_bitcode_paths['library_' + str(i)] = bc_path\n+                i += 1\n+        bc_gfx_path = bitcode_path_dir + gpu_arch_specific_bitcode_library\n+        if os.path.exists(bc_gfx_path):\n+            amdgcn_bitcode_paths['library_' + str(i)] = bc_gfx_path\n+\n+        return amdgcn_bitcode_paths\n+    else:\n+        return {}\n+\n+\n+@static_vars(amdgcn_bitcode_paths=_get_amdgcn_bitcode_paths())\n+def get_amdgcn_bitcode_paths():\n+    return get_amdgcn_bitcode_paths.amdgcn_bitcode_paths\n+\n+\n class CompiledKernel:\n \n     # Hooks for external tools to monitor the execution of triton kernels\n@@ -1805,12 +2091,21 @@ def _init_handles(self):\n         if self.cu_module is not None:\n             return\n         device = triton.runtime.jit.get_current_device()\n-        global cuda_utils\n-        init_cuda_utils()\n-        max_shared = cuda_utils.get_device_properties(device)[\"max_shared_mem\"]\n-        if self.shared > max_shared:\n-            raise OutOfResources(self.shared, max_shared, \"shared memory\")\n-        mod, func, n_regs, n_spills = cuda_utils.load_binary(self.metadata[\"name\"], self.asm[\"cubin\"], self.shared, device)\n+        if torch.version.hip is not None:\n+            global hip_utils\n+            init_hip_utils()\n+            max_shared = hip_utils.get_device_properties(device)[\"max_shared_mem\"]\n+            if self.shared > max_shared:\n+                raise OutOfResources(self.shared, max_shared, \"shared memory\")\n+            mod, func, n_regs, n_spills = hip_utils.load_binary(self.metadata[\"name\"], self.asm[\"hsaco_path\"], self.shared, device)\n+        else:\n+            global cuda_utils\n+            init_cuda_utils()\n+            max_shared = cuda_utils.get_device_properties(device)[\"max_shared_mem\"]\n+            if self.shared > max_shared:\n+                raise OutOfResources(self.shared, max_shared, \"shared memory\")\n+            mod, func, n_regs, n_spills = cuda_utils.load_binary(self.metadata[\"name\"], self.asm[\"cubin\"], self.shared, device)\n+\n         self.n_spills = n_spills\n         self.n_regs = n_regs\n         self.cu_module = mod\n@@ -1994,3 +2289,153 @@ def init_cuda_utils():\n \n \n cuda_utils = None\n+\n+\n+def init_hip_utils():\n+    global hip_utils\n+    if hip_utils is None:\n+        hip_utils = HIPUtils()\n+\n+\n+hip_utils = None\n+\n+\n+class HIPUtils(object):\n+    def __new__(cls):\n+        if not hasattr(cls, 'instance'):\n+            cls.instance = super(HIPUtils, cls).__new__(cls)\n+        return cls.instance\n+\n+    def _generate_src(self):\n+        return \"\"\"\n+        #define __HIP_PLATFORM_AMD__\n+        #include <hip/hip_runtime.h>\n+        #define PY_SSIZE_T_CLEAN\n+        #include <Python.h>\n+        #include <stdio.h>\n+        #include <stdlib.h>\n+        static inline void gpuAssert(hipError_t code, const char *file, int line)\n+        {{\n+          if (code != HIP_SUCCESS)\n+          {{\n+             const char* prefix = \"Triton Error [HIP]: \";\n+             const char* str = hipGetErrorString(code);\n+             char err[1024] = {0};\n+             snprintf(err, 1024, \"%s Code: %d, Messsage: %s\", prefix, code, str );\n+             PyErr_SetString(PyExc_RuntimeError, err);\n+          }}\n+        }}\n+\n+        #define HIP_CHECK(ans) { gpuAssert((ans), __FILE__, __LINE__); if (PyErr_Occurred()) return NULL; }\n+\n+        static PyObject* getDeviceProperties(PyObject* self, PyObject* args){\n+            int device_id;\n+            if (!PyArg_ParseTuple(args, \"i\", &device_id))\n+                return NULL;\n+\n+            hipDeviceProp_t props;\n+            HIP_CHECK(hipGetDeviceProperties(&props, device_id));\n+\n+            // create a struct to hold device properties\n+            return Py_BuildValue(\"{s:i, s:i, s:i, s:i, s:i}\", \"max_shared_mem\", props.sharedMemPerBlock,\n+                                       \"multiprocessor_count\", props.multiProcessorCount,\n+                                       \"sm_clock_rate\", props.clockRate,\n+                                       \"mem_clock_rate\", props.memoryClockRate,\n+                                       \"mem_bus_width\", props.memoryBusWidth);\n+        }\n+\n+        static PyObject* loadBinary(PyObject* self, PyObject* args) {\n+            const char* name;\n+            const char* data;\n+            Py_ssize_t data_size;\n+            int shared;\n+            int device;\n+            if (!PyArg_ParseTuple(args, \"ss#ii\", &name, &data, &data_size, &shared, &device)) {\n+                return NULL;\n+            }\n+\n+            // Open HSACO file\n+            FILE* hsaco_file;\n+            if ((hsaco_file = fopen(data, \"rb\")) == NULL) {\n+                return NULL;\n+            }\n+\n+            // Read HSCAO file into Buffer\n+            fseek(hsaco_file, 0L, SEEK_END);\n+            size_t hsaco_file_size = ftell(hsaco_file);\n+            unsigned char* hsaco = (unsigned char*) malloc(hsaco_file_size * sizeof(unsigned char));\n+            rewind(hsaco_file);\n+            fread(hsaco, sizeof(unsigned char), hsaco_file_size, hsaco_file);\n+            fclose(hsaco_file);\n+\n+            // set HIP options\n+            hipJitOption opt[] = {hipJitOptionErrorLogBufferSizeBytes, hipJitOptionErrorLogBuffer,\n+                                  hipJitOptionInfoLogBufferSizeBytes, hipJitOptionInfoLogBuffer,\n+                                  hipJitOptionLogVerbose};\n+            const unsigned int errbufsize = 8192;\n+            const unsigned int logbufsize = 8192;\n+            char _err[errbufsize];\n+            char _log[logbufsize];\n+            void *optval[] = {(void *)(uintptr_t)errbufsize,\n+                              (void *)_err, (void *)(uintptr_t)logbufsize,\n+                              (void *)_log, (void *)1};\n+\n+            // launch HIP Binary\n+            hipModule_t mod;\n+            hipFunction_t fun;\n+            hipModuleLoadDataEx(&mod, hsaco, 5, opt, optval);\n+            hipModuleGetFunction(&fun, mod, name);\n+            free(hsaco);\n+\n+            // get allocated registers and spilled registers from the function\n+            int n_regs = 0;\n+            int n_spills = 0;\n+            if (PyErr_Occurred()) {\n+              return NULL;\n+            }\n+            return Py_BuildValue(\"(KKii)\", (uint64_t)mod, (uint64_t)fun, n_regs, n_spills);\n+        }\n+\n+        static PyMethodDef ModuleMethods[] = {\n+          {\"load_binary\", loadBinary, METH_VARARGS, \"Load provided hsaco into HIP driver\"},\n+          {\"get_device_properties\", getDeviceProperties, METH_VARARGS, \"Get the properties for a given device\"},\n+          {NULL, NULL, 0, NULL} // sentinel\n+        };\n+\n+        static struct PyModuleDef ModuleDef = {\n+          PyModuleDef_HEAD_INIT,\n+          \"hip_utils\",\n+          NULL, //documentation\n+          -1, //size\n+          ModuleMethods\n+        };\n+\n+        PyMODINIT_FUNC PyInit_hip_utils(void) {\n+          PyObject *m = PyModule_Create(&ModuleDef);\n+          if (m == NULL) {\n+            return NULL;\n+          }\n+          PyModule_AddFunctions(m, ModuleMethods);\n+          return m;\n+        }\n+        \"\"\"\n+\n+    def __init__(self):\n+        src = self._generate_src()\n+        key = hashlib.md5(src.encode(\"utf-8\")).hexdigest()\n+        cache = CacheManager(key)\n+        fname = \"hip_utils.so\"\n+        if not cache.has_file(fname):\n+            with tempfile.TemporaryDirectory() as tmpdir:\n+                src_path = os.path.join(tmpdir, \"main.c\")\n+                with open(src_path, \"w\") as f:\n+                    f.write(src)\n+                so = _build(\"hip_utils\", src_path, tmpdir)\n+                with open(so, \"rb\") as f:\n+                    cache.put(f.read(), fname, binary=True)\n+        import importlib.util\n+        spec = importlib.util.spec_from_file_location(\"hip_utils\", cache._make_path(fname))\n+        mod = importlib.util.module_from_spec(spec)\n+        spec.loader.exec_module(mod)\n+        self.load_binary = mod.load_binary\n+        self.get_device_properties = mod.get_device_properties"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 6, "deletions": 13, "changes": 19, "file_content_changes": "@@ -1107,6 +1107,12 @@ def sqrt(x, _builder=None):\n     return semantic.sqrt(x, _builder)\n \n \n+@builtin\n+@_add_math_1arg_docstr(\"absolute value\")\n+def abs(x, _builder=None):\n+    return semantic.abs(x, _builder)\n+\n+\n # -----------------------\n # Reductions\n # -----------------------\n@@ -1214,19 +1220,6 @@ def max_contiguous(input, values, _builder=None):\n # Standard library\n # -----------------------\n \n-@triton.jit\n-def abs(x):\n-    x_dtype = x.dtype\n-    if x_dtype.is_floating():\n-        num_bits: constexpr = x.dtype.primitive_bitwidth\n-        int_dtype = dtype(f'int{num_bits}')\n-        mask = 2 ** (num_bits - 1) - 1\n-        ret = x.to(int_dtype, bitcast=True) & mask.to(int_dtype)\n-        ret = ret.to(x_dtype, bitcast=True)\n-    else:\n-        ret = where(x >= 0, x, -x)\n-    return ret\n-\n \n @triton.jit\n def cdiv(x, div):"}, {"filename": "python/triton/language/math.py", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "file_content_changes": "@@ -1,9 +1,14 @@\n import os\n \n+import torch\n+\n from .. import impl\n from . import core, extern\n \n-LOCAL_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"..\", \"third_party\", \"cuda\", \"lib\", \"libdevice.10.bc\")\n+if torch.version.hip is not None:\n+    LOCAL_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"cuda2gcn.bc\")\n+else:\n+    LOCAL_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"..\", \"third_party\", \"cuda\", \"lib\", \"libdevice.10.bc\")\n LIBDEVICE_PATH = os.getenv(\"TRITON_LIBDEVICE_PATH\", LOCAL_PATH)\n \n "}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "file_content_changes": "@@ -1223,8 +1223,21 @@ def sqrt(x: tl.tensor, builder: ir.builder) -> tl.tensor:\n     return tl.tensor(builder.create_sqrt(x.handle), x.type)\n \n \n+def abs(x: tl.tensor, builder: ir.builder) -> tl.tensor:\n+    dtype = x.dtype\n+    if dtype.is_floating():\n+        return tl.tensor(builder.create_fabs(x.handle), x.type)\n+    elif dtype.is_int_signed():\n+        return tl.tensor(builder.create_iabs(x.handle), x.type)\n+    elif dtype.is_int_unsigned():\n+        return x  # no-op\n+    else:\n+        assert False, f\"Unexpected dtype {dtype}\"\n+\n+\n ##\n \n+\n def multiple_of(x: tl.tensor, values: List[int]) -> tl.tensor:\n     if len(x.shape) != len(values):\n         raise ValueError(\"Shape of input to multiple_of does not match the length of values\")"}, {"filename": "python/triton/tools/aot.py", "status": "modified", "additions": 59, "deletions": 7, "changes": 66, "file_content_changes": "@@ -3,11 +3,12 @@\n \n import triton\n import triton._C.libtriton.triton as libtriton\n+import triton.compiler as tc\n \n if __name__ == '__main__':\n \n     # valid source and target formats\n-    VALID_FORMATS = ['triton-ir', 'triton-gpu-ir', 'llvm-ir', 'ptx']\n+    VALID_FORMATS = ['triton-ir', 'triton-gpu-ir', 'llvm-ir', 'ptx', 'amdgcn']\n \n     # set up the argument parser\n     # TODO: conditional requirements\n@@ -17,6 +18,10 @@\n                         help=\"Target format, one of: \" + ', '.join(VALID_FORMATS))\n     parser.add_argument('--sm', type=int, help=\"Compute capability to compile for\")\n     parser.add_argument('--ptx-version', type=int, help=\"PTX version to compile for\")\n+    parser.add_argument('--gfx', type=str, help=\"AMDGPU target to compile for\")\n+    parser.add_argument('--triple', type=str, help=\"target triple, for example: amdgcn-amd-amdhsa\")\n+    parser.add_argument('--features', type=str, help=\"target features, for example: +sramecc,-xnack\")\n+    parser.add_argument('--num_warps', type=int, help=\"number of warps to compile ttgir for\")\n \n     # parse the args\n     args = parser.parse_args()\n@@ -38,11 +43,52 @@\n         print(module.str())\n         sys.exit(0)\n \n+    if not args.num_warps:\n+        args.num_warps = 4\n+\n+    # llvm-ir -> amdgcn\n+    if args.target == 'amdgcn':\n+        # auto detect available architecture and features\n+        # if nothing detected, set with default values\n+        arch_details = tc.get_amdgpu_arch_fulldetails()\n+        if not arch_details:\n+            arch_name = \"\"\n+            arch_triple = \"amdgcn-amd-amdhsa\"\n+            arch_features = \"\"\n+        else:\n+            arch_triple, arch_name, arch_features = arch_details\n+\n+        # stop processing if architecture name is not automatically detected and is not set manually\n+        if not args.gfx and not arch_name:\n+            raise argparse.ArgumentError(None, \"Must specify --gfx for AMDGCN compilation\")\n+\n+        # rewrite default and automatically detected values with manually provided data\n+        if args.gfx:\n+            arch_name = args.gfx\n+        if args.triple:\n+            arch_triple = args.triple\n+        if args.features:\n+            arch_features = args.features\n+\n+        # triton-ir -> triton-gpu-ir\n+        # use compute_capability == 80\n+        module = triton.compiler.ttir_to_ttgir(module, num_warps=args.num_warps)  # num_stages=3, compute_capability=80)\n+        module = triton.compiler.optimize_ttgir(module, num_stages=3, compute_capability=80)\n+        # triton-gpu-ir -> llvm-ir\n+        # use compute_capability == 80\n+        module = triton.compiler.ttgir_to_llir(module, extern_libs=None, compute_capability=80)\n+        # llvm-ir -> amdgcn asm, hsaco binary\n+        module, hsaco_path = triton.compiler.llir_to_amdgcn_and_hsaco(module, arch_name, arch_triple, arch_features)\n+\n+        print(hsaco_path)\n+        print(module)\n+        sys.exit(0)\n+\n     if not args.sm:\n         raise argparse.ArgumentError(None, \"Must specify --sm for PTX compilation\")\n \n     # triton-ir -> triton-gpu-ir\n-    module = triton.compiler.ttir_to_ttgir(module, num_warps=4)\n+    module = triton.compiler.ttir_to_ttgir(module, num_warps=args.num_warps)\n     module = triton.compiler.optimize_ttgir(module, num_stages=3, compute_capability=args.sm)\n     if args.target == 'triton-gpu-ir':\n         print(module.str())\n@@ -54,10 +100,16 @@\n         print(module)\n         sys.exit(0)\n \n-    if not args.ptx_version:\n-        raise argparse.ArgumentError(None, \"Must specify --ptx-version for PTX compilation\")\n-\n     # llvm-ir -> ptx\n-    module = triton.compiler.llir_to_ptx(module, compute_capability=args.sm, ptx_version=args.ptx_version)\n-    assert args.target == 'ptx'\n+    if args.target == 'ptx':\n+        if not args.ptx_version:\n+            raise argparse.ArgumentError(None, \"Must specify --ptx-version for PTX compilation\")\n+        module = triton.compiler.llir_to_ptx(module, compute_capability=args.sm, ptx_version=args.ptx_version)\n+\n+    # llvm-ir -> amdgcn\n+    if args.target == 'amdgcn':\n+        if not args.gfx:\n+            raise argparse.ArgumentError(None, \"Must specify --gfx for AMDGCN compilation\")\n+        module, hsaco_path = triton.compiler.llir_to_amdgcn_and_hsaco(module, args.gfx)\n+\n     print(module)"}]