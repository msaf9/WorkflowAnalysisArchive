[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 18, "changes": 21, "file_content_changes": "@@ -3044,24 +3044,9 @@ LogicalResult ConvertLayoutOpConversion::lowerSharedToDotOperand(\n   auto sharedLayout = srcTensorTy.getEncoding().cast<SharedEncodingAttr>();\n   auto dotOperandLayout =\n       dstTensorTy.getEncoding().cast<DotOperandEncodingAttr>();\n-\n-  auto uses = op.getResult().getUses();\n-  // check all the mma layout in uses are the same.\n-  MmaEncodingAttr preMmaLayout;\n-  for (auto &op : uses) {\n-    auto dotOp = cast<DotOp>(op.getOwner());\n-    auto mmaLayout = dotOp.getResult()\n-                         .getType()\n-                         .cast<RankedTensorType>()\n-                         .getEncoding()\n-                         .cast<MmaEncodingAttr>();\n-    if (preMmaLayout)\n-      assert(preMmaLayout == mmaLayout);\n-    preMmaLayout = mmaLayout;\n-  }\n-\n-  // We randomly get a mmaLayout for all of them are the same.\n-  auto mmaLayout = preMmaLayout;\n+  MmaEncodingAttr mmaLayout =\n+      dotOperandLayout.getParent().dyn_cast_or_null<MmaEncodingAttr>();\n+  assert(mmaLayout);\n \n   MMA16816ConversionHelper mmaHelper(mmaLayout, getThreadId(rewriter, loc),\n                                      rewriter, getTypeConverter(), op.getLoc());"}]