[{"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 29, "deletions": 15, "changes": 44, "file_content_changes": "@@ -19,7 +19,7 @@ using ::mlir::triton::gpu::SharedEncodingAttr;\n // Data loader for mma.16816 instruction.\n class MMA16816SmemLoader {\n public:\n-  MMA16816SmemLoader(int warpsPerTile, ArrayRef<uint32_t> order,\n+  MMA16816SmemLoader(int nPerWarp, int warpsPerTile, ArrayRef<uint32_t> order,\n                      ArrayRef<uint32_t> warpsPerCTA, uint32_t kOrder,\n                      int kWidth, ArrayRef<Value> smemStrides,\n                      ArrayRef<int64_t> tileShape, ArrayRef<int> instrShape,\n@@ -93,6 +93,8 @@ class MMA16816SmemLoader {\n   int inWarpMatOffset;\n   // Offset in number of matrices to increment on non-k dim across warps\n   int warpMatOffset;\n+\n+  int nPerWarp;\n };\n \n SmallVector<Value>\n@@ -131,10 +133,18 @@ MMA16816SmemLoader::computeLdmatrixMatOffs(Value warpId, Value lane,\n   // address (s0,s1) annotates.\n \n   Value matOff[2];\n-  matOff[kOrder ^ 1] = add(\n-      mul(warpId, i32_val(warpMatOffset)), // warp offset (kOrder=1)\n-      mul(nkMatArr,\n-          i32_val(inWarpMatOffset))); // matrix offset inside a warp (kOrder=1)\n+  // When B's shape(k, n) is (16, 8) and ldmatrix.x4 is used, the shared memory\n+  // access will be out of bound. In the future we should change this case to\n+  // ldmatrix.x2\n+  if (kOrder == 0 && nPerWarp == 8) {\n+    matOff[kOrder ^ 1] = mul(warpId, i32_val(warpMatOffset));\n+  } else {\n+    matOff[kOrder ^ 1] = add(\n+        mul(warpId, i32_val(warpMatOffset)), // warp offset (kOrder=1)\n+        mul(nkMatArr,\n+            i32_val(\n+                inWarpMatOffset))); // matrix offset inside a warp (kOrder=1)\n+  }\n   matOff[kOrder] = kMatArr;\n \n   // Physical offset (before swizzling)\n@@ -390,13 +400,13 @@ MMA16816SmemLoader::loadX4(int mat0, int mat1, ArrayRef<Value> ptrs, Type matTy,\n }\n \n MMA16816SmemLoader::MMA16816SmemLoader(\n-    int warpsPerTile, ArrayRef<uint32_t> order, ArrayRef<uint32_t> warpsPerCTA,\n-    uint32_t kOrder, int kWidth, ArrayRef<Value> smemStrides,\n-    ArrayRef<int64_t> tileShape, ArrayRef<int> instrShape,\n-    ArrayRef<int> matShape, int perPhase, int maxPhase, int elemBytes,\n-    ConversionPatternRewriter &rewriter,\n+    int nPerWarp, int warpsPerTile, ArrayRef<uint32_t> order,\n+    ArrayRef<uint32_t> warpsPerCTA, uint32_t kOrder, int kWidth,\n+    ArrayRef<Value> smemStrides, ArrayRef<int64_t> tileShape,\n+    ArrayRef<int> instrShape, ArrayRef<int> matShape, int perPhase,\n+    int maxPhase, int elemBytes, ConversionPatternRewriter &rewriter,\n     TritonGPUToLLVMTypeConverter *typeConverter, const Location &loc)\n-    : order(order.begin(), order.end()),\n+    : nPerWarp(nPerWarp), order(order.begin(), order.end()),\n       warpsPerCTA(warpsPerCTA.begin(), warpsPerCTA.end()), kOrder(kOrder),\n       kWidth(kWidth), tileShape(tileShape.begin(), tileShape.end()),\n       instrShape(instrShape.begin(), instrShape.end()),\n@@ -490,6 +500,7 @@ std::function<void(int, int)> getLoadMatrixFn(\n     bool isA, TritonGPUToLLVMTypeConverter *typeConverter,\n     ConversionPatternRewriter &rewriter, Location loc) {\n   auto tensorTy = tensor.getType().cast<RankedTensorType>();\n+  auto shapePerCTA = getShapePerCTA(tensorTy);\n   Type eltTy = tensorTy.getElementType();\n   // We assumes that the input operand of Dot should be from shared layout.\n   // TODO(Superjomn) Consider other layouts if needed later.\n@@ -511,13 +522,16 @@ std::function<void(int, int)> getLoadMatrixFn(\n   if (kWidth != (4 / elemBytes))\n     assert(vecPhase == 1 || vecPhase == 4 * kWidth);\n \n+  int nPerWarp =\n+      std::max<int>(shapePerCTA[1] / mmaLayout.getWarpsPerCTA()[1], 8);\n+\n   // (a, b) is the coordinate.\n   auto load = [=, &rewriter, &vals](int a, int b) {\n     MMA16816SmemLoader loader(\n-        warpsPerTile, sharedLayout.getOrder(), mmaLayout.getWarpsPerCTA(),\n-        kOrder, kWidth, smemObj.strides, tensorTy.getShape() /*tileShape*/,\n-        instrShape, matShape, perPhase, maxPhase, elemBytes, rewriter,\n-        typeConverter, loc);\n+        nPerWarp, warpsPerTile, sharedLayout.getOrder(),\n+        mmaLayout.getWarpsPerCTA(), kOrder, kWidth, smemObj.strides,\n+        tensorTy.getShape() /*tileShape*/, instrShape, matShape, perPhase,\n+        maxPhase, elemBytes, rewriter, typeConverter, loc);\n     // Offset of a slice within the original tensor in shared memory\n     Value cSwizzleOffset = smemObj.getCSwizzleOffset(order[0]);\n     SmallVector<Value> offs ="}]