[{"filename": "lib/Conversion/NVGPUToLLVM/NVGPUToLLVMPass.cpp", "status": "modified", "additions": 72, "deletions": 68, "changes": 140, "file_content_changes": "@@ -21,8 +21,7 @@ using ::mlir::LLVM::getSRegValue;\n \n namespace {\n \n-using Constraint = std::variant<int, std::string>;\n-using OperandsAndConstraints = std::vector<std::pair<mlir::Value, Constraint>>;\n+using OperandsAndConstraints = std::vector<std::pair<mlir::Value, std::string>>;\n \n const std::string Reg_Alloc_Op = \"setmaxnreg.inc.sync.aligned.u32 #regCount;\";\n const std::string Wgmma_Fence_Op = \"wgmma.fence.sync.aligned;\";\n@@ -62,36 +61,59 @@ const std::string Cluster_Cta_Id_Op = \"{\\n\"\n                                       \"mad.lo.u32 $0, a1, a3, a0;     \\n\"\n                                       \"}\";\n \n+bool isNumber(const std::string &s) {\n+  return !s.empty() && std::find_if(s.begin(), s.end(), [](unsigned char c) {\n+                         return !std::isdigit(c);\n+                       }) == s.end();\n+}\n+\n+Type getTypeFromConstraint(char constraint, mlir::PatternRewriter &rewriter) {\n+  Type ty;\n+  if (constraint == 'b')\n+    ty = IntegerType::get(rewriter.getContext(), 1);\n+  else if (constraint == 'h')\n+    ty = IntegerType::get(rewriter.getContext(), 16);\n+  else if (constraint == 'r')\n+    ty = IntegerType::get(rewriter.getContext(), 32);\n+  else if (constraint == 'l')\n+    ty = IntegerType::get(rewriter.getContext(), 64);\n+  else if (constraint == 'f')\n+    ty = FloatType::getF32(rewriter.getContext());\n+  else if (constraint == 'd')\n+    ty = FloatType::getF64(rewriter.getContext());\n+  else {\n+    assert(false && \"Unsupported constraint\");\n+  }\n+  return ty;\n+}\n+\n template <typename SourceOp, typename ConcreteT>\n class NVGPUOpPatternBase : public mlir::RewritePattern {\n public:\n   explicit NVGPUOpPatternBase(mlir::MLIRContext *context)\n       : mlir::RewritePattern(SourceOp::getOperationName(), 1, context) {}\n \n-  mlir::Value convertToType(mlir::Value val, Constraint constraint,\n+  // Converts the given value to the type represented by the constraint\n+  // E.g. if val is of type llvmptr and constraint is 'r', then we convert\n+  // val to i32 using ptrtoint(i32_ty, val)\n+  mlir::Value convertToType(mlir::Value val, std::string constraint,\n                             Location &loc,\n                             mlir::PatternRewriter &rewriter) const {\n-    if (val.getType().isa<LLVM::LLVMPointerType>()) {\n-      if (std::holds_alternative<std::string>(constraint)) {\n-        auto constraintStr = std::get<std::string>(constraint);\n-        if (constraintStr == \"r\") {\n-          return ptrtoint(i32_ty, val);\n-        } else if (constraintStr == \"l\") {\n-          return ptrtoint(i64_ty, val);\n-        } else {\n-          return val;\n-        }\n-      }\n-      return val;\n-    } else {\n-      if (std::holds_alternative<std::string>(constraint)) {\n-        auto bitwidth = val.getType().getIntOrFloatBitWidth();\n-        auto constraintStr = std::get<std::string>(constraint);\n-        return zext(IntegerType::get(rewriter.getContext(), bitwidth), val);\n+    auto isConstraintNumber = isNumber(constraint);\n+    if (!isConstraintNumber) {\n+      auto ty = getTypeFromConstraint(constraint[0], rewriter);\n+      if (val.getType().isa<LLVM::LLVMPointerType>()) {\n+        return ptrtoint(ty, val);\n+      } else {\n+        assert(val.getType().getIntOrFloatBitWidth() <=\n+                   ty.getIntOrFloatBitWidth() &&\n+               \"Cannot convert to a smaller type\");\n+        return zext(ty, val);\n       }\n     }\n     return val;\n   }\n+\n   SmallVector<PTXBuilder::Operand *>\n   getPtxOutputs(std::vector<std::string> &outputConstraints,\n                 PTXBuilder &ptxBuilder) const {\n@@ -110,13 +132,21 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n     OperandsAndConstraints unpackedOperands;\n     for (auto &[operand, constraint] : operandsAndConstraints) {\n       auto llvmStruct = llvm::dyn_cast<LLVM::LLVMStructType>(operand.getType());\n+      // if a constraint is a number, then we are doing input/output tying\n+      // if the operand is a struct, then we need to unpack it, and\n+      // add the constraint to each of the unpacked operands uses the constraint\n+      // as an offset\n+      auto isConstraintNumber = isNumber(constraint);\n       if (llvmStruct) {\n         for (unsigned i = 0; i < llvmStruct.getBody().size(); i++) {\n-          if (std::holds_alternative<int>(constraint)) {\n-            auto constraintInt = std::get<int>(constraint);\n+          if (isConstraintNumber) {\n+            auto constraintInt = std::stoi(constraint) + i;\n             unpackedOperands.push_back(\n                 {extract_val(llvmStruct.getBody()[i], operand, i),\n-                 constraintInt + i});\n+                 std::to_string(constraintInt)});\n+          } else {\n+            unpackedOperands.push_back(\n+                {extract_val(llvmStruct.getBody()[i], operand, i), constraint});\n           }\n         }\n       } else {\n@@ -135,15 +165,8 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n         unpackOperands(operandsAndConstraints, ptxBuilder, loc, rewriter);\n     for (auto &[operand, constraint] : unpackedOperandsAndConstraints) {\n       auto convertedOperand = convertToType(operand, constraint, loc, rewriter);\n-      if (std::holds_alternative<int>(constraint)) {\n-        auto *ptxOperand = ptxBuilder.newOperand(\n-            convertedOperand, std::to_string(std::get<int>(constraint)));\n-        ptxOperands.push_back(ptxOperand);\n-      } else {\n-        auto *ptxOperand = ptxBuilder.newOperand(\n-            convertedOperand, std::get<std::string>(constraint));\n-        ptxOperands.push_back(ptxOperand);\n-      }\n+      auto *ptxOperand = ptxBuilder.newOperand(convertedOperand, constraint);\n+      ptxOperands.push_back(ptxOperand);\n     }\n     return ptxOperands;\n   }\n@@ -167,27 +190,7 @@ class NVGPUOpPatternBase : public mlir::RewritePattern {\n       for (auto &outputConstraint : outputConstraints) {\n         assert(outputConstraint[0] == '=' &&\n                \"Constraint must be for an output\");\n-        Type retTy;\n-        switch (outputConstraint[1]) {\n-        case 'h':\n-          retTy = IntegerType::get(ctx, 16);\n-          break;\n-        case 'r':\n-          retTy = IntegerType::get(ctx, 32);\n-          break;\n-        case 'l':\n-          retTy = IntegerType::get(ctx, 64);\n-          break;\n-        case 'f':\n-          retTy = FloatType::getF32(ctx);\n-          break;\n-        case 'd':\n-          retTy = FloatType::getF64(ctx);\n-          break;\n-        default:\n-          assert(false && \"Unsupported output constraint\");\n-          break;\n-        }\n+        Type retTy = getTypeFromConstraint(outputConstraint[1], rewriter);\n         retTys.push_back(retTy);\n       }\n       if (retTys.size() == 1) {\n@@ -278,7 +281,6 @@ template <typename SourceOp>\n class NVGPUOpGenericPattern\n     : public NVGPUOpPatternBase<SourceOp, NVGPUOpGenericPattern<SourceOp>> {\n public:\n-  using Base = NVGPUOpPatternBase<SourceOp, NVGPUOpGenericPattern<SourceOp>>;\n   explicit NVGPUOpGenericPattern(mlir::MLIRContext *context, std::string ptxAsm,\n                                  std::vector<std::string> outputConstraints,\n                                  std::vector<std::string> inputConstraints)\n@@ -705,7 +707,7 @@ class WGMMAOpPattern : public NVGPUOpPatternBase<ttn::WGMMAOp, WGMMAOpPattern> {\n     auto structTypeA = typeA.dyn_cast<LLVM::LLVMStructType>();\n \n     // TODO (zahi): is this the best way to tie inputs/outputs ?\n-    operandsAndConstraints.push_back({opC, 0});\n+    operandsAndConstraints.push_back({opC, \"0\"});\n \n     if (structTypeA) {\n       operandsAndConstraints.push_back({opA, \"f\"});\n@@ -930,6 +932,8 @@ class OffsetOfSts64OpPattern\n     } else if (rowStride == 32) {\n       perPhase = 4;\n       maxPhase = 2;\n+    } else {\n+      assert(false && \"Unsupported rowStride\");\n     }\n \n     auto ptxAsm = \"{\\n\"\n@@ -1087,19 +1091,6 @@ class ConvertNVGPUToLLVM : public ConvertNVGPUToLLVMBase<ConvertNVGPUToLLVM> {\n     ModuleOp mod = getOperation();\n     RewritePatternSet patterns(context);\n \n-    patterns.add<FenceAsyncSharedOpPattern>(context);\n-    patterns.add<StoreMatrixOpPattern>(context);\n-    patterns.add<OffsetOfStmatrixV4OpPattern>(context);\n-    patterns.add<WGMMADescCreateOpPattern>(context);\n-    patterns.add<MBarrierArriveOpPattern>(context);\n-    patterns.add<ClusterArriveOpPattern>(context);\n-    patterns.add<TMALoadTiledOpPattern>(context);\n-    patterns.add<TMAStoreTiledOpPattern>(context);\n-    patterns.add<LoadDSmemOpPattern>(context);\n-    patterns.add<WGMMAOpPattern>(context);\n-    patterns.add<StoreDSmemOpPattern>(context);\n-    patterns.add<OffsetOfSts64OpPattern>(context);\n-\n #define POPULATE_NVGPU_OP(SRC_OP, ASM)                                         \\\n   patterns.add<NVGPUOpGenericPattern<SRC_OP>>(                                 \\\n       context, ASM, std::vector<std::string>(), std::vector<std::string>());\n@@ -1133,6 +1124,19 @@ class ConvertNVGPUToLLVM : public ConvertNVGPUToLLVMBase<ConvertNVGPUToLLVM> {\n         context, Cluster_Cta_Id_Op, std::vector<std::string>({\"=r\"}),\n         std::vector<std::string>());\n \n+    patterns.add<FenceAsyncSharedOpPattern>(context);\n+    patterns.add<StoreMatrixOpPattern>(context);\n+    patterns.add<OffsetOfStmatrixV4OpPattern>(context);\n+    patterns.add<WGMMADescCreateOpPattern>(context);\n+    patterns.add<MBarrierArriveOpPattern>(context);\n+    patterns.add<ClusterArriveOpPattern>(context);\n+    patterns.add<TMALoadTiledOpPattern>(context);\n+    patterns.add<TMAStoreTiledOpPattern>(context);\n+    patterns.add<LoadDSmemOpPattern>(context);\n+    patterns.add<WGMMAOpPattern>(context);\n+    patterns.add<StoreDSmemOpPattern>(context);\n+    patterns.add<OffsetOfSts64OpPattern>(context);\n+\n     if (applyPatternsAndFoldGreedily(mod, std::move(patterns)).failed())\n       signalPassFailure();\n   }"}]