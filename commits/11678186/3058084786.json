[{"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "file_content_changes": "@@ -347,16 +347,13 @@ void LoopPipeliner::emitPrologue() {\n   // async.wait & extract_slice\n   Operation *asyncWait = builder.create<triton::gpu::AsyncWaitOp>(\n       loads[0].getLoc(), loads.size() * (numStages - 2));\n+  loopIterIdx = builder.create<arith::ConstantIntOp>(iv.getLoc(), 0, 32);\n   for (Value loadOp : loads) {\n     Value extractSlice = builder.create<triton::gpu::ExtractSliceOp>(\n         loadOp.getLoc(), loadsMapping[loadOp].getType(),\n-        loadStageBuffer[loadOp][numStages - 1],\n-        builder.create<arith::ConstantIntOp>(loadOp.getLoc(), 0, 32),\n-        /*axis*/ 0);\n+        loadStageBuffer[loadOp][numStages - 1], loopIterIdx, /*axis*/ 0);\n     loadsExtract[loadOp] = extractSlice;\n   }\n-\n-  loopIterIdx = builder.create<arith::ConstantIntOp>(iv.getLoc(), 0, 32);\n }\n \n scf::ForOp LoopPipeliner::createNewForOp() {"}, {"filename": "test/TritonGPU/loop-pipeline.mlir", "status": "modified", "additions": 54, "deletions": 30, "changes": 84, "file_content_changes": "@@ -9,23 +9,31 @@\n #C = #triton_gpu.mma<{version = 2, warpsPerCTA = [4, 1]}>\n \n // CHECK: func @matmul_loop\n+// CHECK-DAG: %[[CONSTANT_0:.*]] = arith.constant 0 : i32\n+// CHECK-DAG: %[[CONSTANT_1:.*]] = arith.constant 1 : i32\n+// CHECK-DAG: %[[CONSTANT_2:.*]] = arith.constant 2 : i32\n+// CHECK-DAG: %[[CONSTANT_3:.*]] = arith.constant 3 : i32\n // CHECK: %[[ABUFFER:.*]] = triton_gpu.alloc_tensor\n-// CHECK: %[[A0BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK: %[[A0BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_0]]\n // CHECK: %[[BBUFFER:.*]] = triton_gpu.alloc_tensor\n-// CHECK: %[[B0BUFFER:.*]] = triton_gpu.insert_slice_async\n-// CHECK: %[[A1BUFFER:.*]] = triton_gpu.insert_slice_async\n-// CHECK: %[[B1BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK: %[[B0BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_0]]\n+// CHECK: %[[A1BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_1]]\n+// CHECK: %[[B1BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_1]]\n // CHECK:   triton_gpu.async_wait {num = 2 : i32}\n-// CHECK: %[[A0:.*]] = triton_gpu.extract_slice %[[A1BUFFER]]\n-// CHECK: %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]]\n-// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}})\n+// CHECK: %[[A0:.*]] = triton_gpu.extract_slice %[[A1BUFFER]], %[[CONSTANT_0]]\n+// CHECK: %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]], %[[CONSTANT_0]]\n+// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_0]]\n // CHECK:   tt.dot %[[arg_a0]], %[[arg_b0]], {{.*}}\n-// CHECK:   %[[NEXT_A_BUFFER:.*]] = triton_gpu.insert_slice_async\n-// CHECK:   %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n+// CHECK:   %[[NEXT_A_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n+// CHECK:   %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:   triton_gpu.async_wait {num = 2 : i32}\n-// CHECK:   %[[NEXT_A:.*]] = triton_gpu.extract_slice %[[NEXT_A_BUFFER]]\n-// CHECK:   %[[NEXT_B:.*]] = triton_gpu.extract_slice %[[NEXT_B_BUFFER]]\n-// CHECK:   scf.yield {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_BUFFER]], %[[NEXT_B_BUFFER]], %[[NEXT_A]], %[[NEXT_B]]\n+// CHECK:   %[[NEXT_A:.*]] = triton_gpu.extract_slice %[[NEXT_A_BUFFER]], %[[EXTRACT_IDX]]\n+// CHECK:   %[[NEXT_B:.*]] = triton_gpu.extract_slice %[[NEXT_B_BUFFER]], %[[EXTRACT_IDX]]\n+// CHECK-DAG: %[[NEXT_PIPELINE_IDX:.*]] = arith.addi %[[PIPELINE_IDX]], %[[CONSTANT_1]]\n+// CHECK-DAG: %[[NEXT_LOOP_IDX:.*]] = arith.addi %[[LOOP_IDX]], %[[CONSTANT_1]]\n+// CHECK:   scf.yield {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_BUFFER]], %[[NEXT_B_BUFFER]], %[[NEXT_A]], %[[NEXT_B]], {{.*}}, {{.*}}, {{.*}}, %[[NEXT_PIPELINE_IDX]], %[[NEXT_LOOP_IDX]]\n func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n   %b_ptr_init = tt.broadcast %B : (!tt.ptr<f16>) -> tensor<32x128x!tt.ptr<f16>, #BL>\n@@ -56,24 +64,32 @@ func @matmul_loop(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B\n \n \n // CHECK: func @matmul_loop_nested\n+// CHECK-DAG: %[[CONSTANT_0:.*]] = arith.constant 0 : i32\n+// CHECK-DAG: %[[CONSTANT_1:.*]] = arith.constant 1 : i32\n+// CHECK-DAG: %[[CONSTANT_2:.*]] = arith.constant 2 : i32\n+// CHECK-DAG: %[[CONSTANT_3:.*]] = arith.constant 3 : i32\n // CHECK: scf.for\n // CHECK:   %[[ABUFFER:.*]] = triton_gpu.alloc_tensor\n-// CHECK:   %[[A0BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK:   %[[A0BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_0]]\n // CHECK:   %[[BBUFFER:.*]] = triton_gpu.alloc_tensor\n-// CHECK:   %[[B0BUFFER:.*]] = triton_gpu.insert_slice_async\n-// CHECK:   %[[A1BUFFER:.*]] = triton_gpu.insert_slice_async\n-// CHECK:   %[[B1BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK:   %[[B0BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_0]]\n+// CHECK:   %[[A1BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_1]]\n+// CHECK:   %[[B1BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_1]]\n // CHECK:   triton_gpu.async_wait {num = 2 : i32}\n-// CHECK:   %[[A0:.*]] = triton_gpu.extract_slice %[[A1BUFFER]]\n-// CHECK:   %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]]\n-// CHECK:   scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}})\n+// CHECK:   %[[A0:.*]] = triton_gpu.extract_slice %[[A1BUFFER]], %[[CONSTANT_0]]\n+// CHECK:   %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]], %[[CONSTANT_0]]\n+// CHECK:   scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, {{.*}}, {{.*}}, %[[arg_a0:.*]] = %[[A0]], %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_0]]\n // CHECK:     tt.dot %[[arg_a0]], %[[arg_b0]], {{.*}}\n-// CHECK:     %[[NEXT_A_BUFFER:.*]] = triton_gpu.insert_slice_async\n-// CHECK:     %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n+// CHECK:     %[[NEXT_A_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n+// CHECK:     %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:     triton_gpu.async_wait {num = 2 : i32}\n-// CHECK:     %[[NEXT_A:.*]] = triton_gpu.extract_slice %[[NEXT_A_BUFFER]]\n-// CHECK:     %[[NEXT_B:.*]] = triton_gpu.extract_slice %[[NEXT_B_BUFFER]]\n-// CHECK:     scf.yield {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_BUFFER]], %[[NEXT_B_BUFFER]], %[[NEXT_A]], %[[NEXT_B]]\n+// CHECK:     %[[NEXT_A:.*]] = triton_gpu.extract_slice %[[NEXT_A_BUFFER]], %[[EXTRACT_IDX]]\n+// CHECK:     %[[NEXT_B:.*]] = triton_gpu.extract_slice %[[NEXT_B_BUFFER]], %[[EXTRACT_IDX]]\n+// CHECK-DAG: %[[NEXT_PIPELINE_IDX:.*]] = arith.addi %[[PIPELINE_IDX]], %[[CONSTANT_1]]\n+// CHECK-DAG: %[[NEXT_LOOP_IDX:.*]] = arith.addi %[[LOOP_IDX]], %[[CONSTANT_1]]\n+// CHECK:     scf.yield {{.*}}, {{.*}}, {{.*}}, %[[NEXT_A_BUFFER]], %[[NEXT_B_BUFFER]], %[[NEXT_A]], %[[NEXT_B]], {{.*}}, {{.*}}, {{.*}}, %[[NEXT_PIPELINE_IDX]], %[[NEXT_LOOP_IDX]]\n func @matmul_loop_nested(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   scf.for %iv0 = %lb to %ub step %step {\n     %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n@@ -106,17 +122,25 @@ func @matmul_loop_nested(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f\n \n \n // CHECK: func @matmul_loop_single_pipeline\n+// CHECK-DAG: %[[CONSTANT_0:.*]] = arith.constant 0 : i32\n+// CHECK-DAG: %[[CONSTANT_1:.*]] = arith.constant 1 : i32\n+// CHECK-DAG: %[[CONSTANT_2:.*]] = arith.constant 2 : i32\n+// CHECK-DAG: %[[CONSTANT_3:.*]] = arith.constant 3 : i32\n // CHECK: %[[BBUFFER:.*]] = triton_gpu.alloc_tensor\n-// CHECK: %[[B0BUFFER:.*]] = triton_gpu.insert_slice_async\n-// CHECK: %[[B1BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK: %[[B0BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_0]]\n+// CHECK: %[[B1BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[CONSTANT_1]]\n // CHECK: triton_gpu.async_wait {num = 1 : i32}\n-// CHECK: %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]]\n-// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, %[[arg_b0:.*]] = %[[B0]], {{.*}})\n+// CHECK: %[[B0:.*]] = triton_gpu.extract_slice %[[B1BUFFER]], %[[CONSTANT_0]]\n+// CHECK: scf.for {{.*}} iter_args({{.*}}, {{.*}}, {{.*}}, %[[arg_b0:.*]] = %[[B0]], {{.*}}, {{.*}}, %[[PIPELINE_IDX:.*]] = %[[CONSTANT_2]], %[[LOOP_IDX:.*]] = %[[CONSTANT_0]]\n // CHECK:   tt.dot {{.*}}, %[[arg_b0]], {{.*}}\n-// CHECK:   %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async\n+// CHECK-DAG: %[[INSERT_IDX:.*]] = arith.remsi %[[PIPELINE_IDX]], %[[CONSTANT_3]]\n+// CHECK-DAG: %[[EXTRACT_IDX:.*]] = arith.remsi %[[LOOP_IDX]], %[[CONSTANT_3]]\n+// CHECK:   %[[NEXT_B_BUFFER:.*]] = triton_gpu.insert_slice_async {{.*}}, {{.*}}, %[[INSERT_IDX]]\n // CHECK:   triton_gpu.async_wait {num = 1 : i32}\n // CHECK:   %[[NEXT_B:.*]] = triton_gpu.extract_slice %[[NEXT_B_BUFFER]]\n-// CHECK:   scf.yield {{.*}}, {{.*}}, %[[NEXT_B_BUFFER]], %[[NEXT_B]]\n+// CHECK-DAG: %[[NEXT_PIPELINE_IDX:.*]] = arith.addi %[[PIPELINE_IDX]], %[[CONSTANT_1]]\n+// CHECK-DAG: %[[NEXT_LOOP_IDX:.*]] = arith.addi %[[LOOP_IDX]], %[[CONSTANT_1]]\n+// CHECK:   scf.yield {{.*}}, {{.*}}, %[[NEXT_B_BUFFER]], %[[NEXT_B]], {{.*}}, {{.*}}, %[[NEXT_PIPELINE_IDX]], %[[NEXT_LOOP_IDX]]\n func @matmul_loop_single_pipeline(%lb : index, %ub : index, %step : index, %A : !tt.ptr<f16>, %B : !tt.ptr<f16>) {\n   %a_ptr_init = tt.broadcast %A : (!tt.ptr<f16>) -> tensor<128x32x!tt.ptr<f16>, #AL>\n   %b_ptr_init = tt.broadcast %B : (!tt.ptr<f16>) -> tensor<32x128x!tt.ptr<f16>, #BL>"}]