[{"filename": "python/tests/test_backend.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -64,12 +64,12 @@ def test_convert2d(dtype, shape, src_layout, dst_layout, device='cuda'):\n     %7 = tt.broadcast %6 : (tensor<1x128xi32, #src>) -> tensor<128x128xi32, #src>\n     %8 = tt.broadcast %5 : (tensor<128x1xi32, #src>) -> tensor<128x128xi32, #src>\n     %9 = arith.addi %8, %7 : tensor<128x128xi32, #src>\n-    %10 = tt.addptr %2, %9 : tensor<128x128x!tt.ptr<f16>, #src>\n+    %10 = tt.addptr %2, %9 : tensor<128x128x!tt.ptr<f16>, #src>, tensor<128x128xi32, #src>\n     %11 = tt.load %10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<128x128xf16, #src>\n     %3 = tt.splat %arg1 : (!tt.ptr<f16>) -> tensor<128x128x!tt.ptr<f16>, #dst>\n     %12 = triton_gpu.convert_layout %9 : (tensor<128x128xi32, #src>) -> tensor<128x128xi32, #dst>\n     %13 = triton_gpu.convert_layout %11 : (tensor<128x128xf16, #src>) -> tensor<128x128xf16, #dst>\n-    %14 = tt.addptr %3, %12 : tensor<128x128x!tt.ptr<f16>, #dst>\n+    %14 = tt.addptr %3, %12 : tensor<128x128x!tt.ptr<f16>, #dst>, tensor<128x128xi32, #dst>\n     tt.store %14, %13 : tensor<128x128xf16, #dst>\n     return\n   }"}]