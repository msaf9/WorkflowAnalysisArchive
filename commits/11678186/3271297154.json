[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 17, "deletions": 12, "changes": 29, "file_content_changes": "@@ -1566,13 +1566,18 @@ struct ConvertLayoutOpConversion\n         dstLayout.isa<SharedEncodingAttr>()) {\n       return lowerBlockedToShared(op, adaptor, rewriter);\n     }\n+    if (srcLayout.isa<SharedEncodingAttr>() &&\n+        dstLayout.isa<DotOperandEncodingAttr>()) {\n+      return lowerSharedToDotOperand(op, adaptor, rewriter);\n+    }\n     if ((!srcLayout.isa<BlockedEncodingAttr>() &&\n          !srcLayout.isa<MmaEncodingAttr>()) ||\n         (!dstLayout.isa<BlockedEncodingAttr>() &&\n          !dstLayout.isa<MmaEncodingAttr>())) {\n       // TODO: to be implemented\n       return failure();\n     }\n+\n     return lowerDistributedToDistributed(op, adaptor, rewriter);\n   }\n \n@@ -1613,7 +1618,7 @@ struct ConvertLayoutOpConversion\n \n   // shared -> mma_operand\n   LogicalResult\n-  lowerSharedToDotOperand(triton::gpu::ConvertLayoutOp op, OpAdaptor adapter,\n+  lowerSharedToDotOperand(triton::gpu::ConvertLayoutOp op, OpAdaptor adaptor,\n                           ConversionPatternRewriter &rewriter) const;\n };\n \n@@ -2390,16 +2395,16 @@ struct DotOpConversion : public ConvertTritonGPUOpToLLVMPattern<triton::DotOp> {\n \n private:\n   // Convert to mma.m16n8k16\n-  LogicalResult convertMMA16816(triton::DotOp a, OpAdaptor adapter,\n+  LogicalResult convertMMA16816(triton::DotOp a, OpAdaptor adaptor,\n                                 ConversionPatternRewriter &rewriter) const;\n   /// Convert to mma.m8n8k4\n-  LogicalResult convertMMA884(triton::DotOp op, OpAdaptor adapter,\n+  LogicalResult convertMMA884(triton::DotOp op, OpAdaptor adaptor,\n                               ConversionPatternRewriter &rewriter) const {\n     assert(false && \"Not implemented yet.\");\n     return failure();\n   }\n \n-  LogicalResult convertFMADot(triton::DotOp op, OpAdaptor adapter,\n+  LogicalResult convertFMADot(triton::DotOp op, OpAdaptor adaptor,\n                               ConversionPatternRewriter &rewriter) const {\n     assert(false && \"Not implemented yet.\");\n     return failure();\n@@ -2841,7 +2846,7 @@ struct MMA16816ConversionHelper {\n   // loading.\n   LogicalResult convertDot(Value a, Value b, Value c, Value d, Value loadedA,\n                            Value loadedB, Value loadedC, DotOp op,\n-                           DotOpAdaptor adapter) const {\n+                           DotOpAdaptor adaptor) const {\n     helper.deduceMmaType(op);\n \n     auto aTensorTy = a.getType().cast<RankedTensorType>();\n@@ -3028,7 +3033,7 @@ struct MMA16816ConversionHelper {\n };\n \n LogicalResult ConvertLayoutOpConversion::lowerSharedToDotOperand(\n-    triton::gpu::ConvertLayoutOp op, OpAdaptor adapter,\n+    triton::gpu::ConvertLayoutOp op, OpAdaptor adaptor,\n     ConversionPatternRewriter &rewriter) const {\n   auto loc = op.getLoc();\n   Value src = op.src();\n@@ -3064,10 +3069,10 @@ LogicalResult ConvertLayoutOpConversion::lowerSharedToDotOperand(\n   Value res;\n   if (dotOperandLayout.getOpIdx() == 0) {\n     // operand $a\n-    res = mmaHelper.loadA(src, adapter.src());\n+    res = mmaHelper.loadA(src, adaptor.src());\n   } else if (dotOperandLayout.getOpIdx() == 1) {\n     // operand $b\n-    res = mmaHelper.loadB(src, adapter.src());\n+    res = mmaHelper.loadB(src, adaptor.src());\n   } else if (dotOperandLayout.getOpIdx() == 2) {\n     // operand $c\n     res = mmaHelper.loadC(src);\n@@ -3078,7 +3083,7 @@ LogicalResult ConvertLayoutOpConversion::lowerSharedToDotOperand(\n }\n \n LogicalResult\n-DotOpConversion::convertMMA16816(triton::DotOp op, OpAdaptor adapter,\n+DotOpConversion::convertMMA16816(triton::DotOp op, OpAdaptor adaptor,\n                                  ConversionPatternRewriter &rewriter) const {\n   auto loc = op.getLoc();\n   auto mmaLayout = op.getResult()\n@@ -3089,12 +3094,12 @@ DotOpConversion::convertMMA16816(triton::DotOp op, OpAdaptor adapter,\n   MMA16816ConversionHelper mmaHelper(mmaLayout, getThreadId(rewriter, loc),\n                                      rewriter, getTypeConverter(), loc);\n \n-  auto A = mmaHelper.loadA(op.a(), adapter.a());\n-  auto B = mmaHelper.loadB(op.b(), adapter.b());\n+  auto A = mmaHelper.loadA(op.a(), adaptor.a());\n+  auto B = mmaHelper.loadB(op.b(), adaptor.b());\n   auto C = mmaHelper.loadC(op.c());\n \n   return mmaHelper.convertDot(op.a(), op.b(), op.c(), op.d(), A, B, C, op,\n-                              adapter);\n+                              adaptor);\n }\n \n /// ====================== mma codegen end ============================"}]