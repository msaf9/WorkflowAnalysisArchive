[{"filename": "include/triton/Analysis/Allocation.h", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "file_content_changes": "@@ -67,12 +67,12 @@ class Allocation {\n \n   /// Returns the offset of the given buffer in the shared memory.\n   size_t getOffset(BufferId bufferId) const {\n-    return bufferSet.lookup(bufferId).offset;\n+    return bufferSet.at(bufferId).offset;\n   }\n \n   /// Returns the size of the given buffer in the shared memory.\n   size_t getAllocatedSize(BufferId bufferId) const {\n-    return bufferSet.lookup(bufferId).size;\n+    return bufferSet.at(bufferId).size;\n   }\n \n   /// Returns the buffer id of the given value.\n@@ -115,8 +115,8 @@ class Allocation {\n   bool isIntersected(BufferId lhsId, BufferId rhsId) const {\n     if (lhsId == InvalidBufferId || rhsId == InvalidBufferId)\n       return false;\n-    auto lhsBuffer = bufferSet.lookup(lhsId);\n-    auto rhsBuffer = bufferSet.lookup(rhsId);\n+    auto lhsBuffer = bufferSet.at(lhsId);\n+    auto rhsBuffer = bufferSet.at(rhsId);\n     return lhsBuffer.intersects(rhsBuffer);\n   }\n \n@@ -137,7 +137,8 @@ class Allocation {\n     bool operator<(const BufferT &other) const { return id < other.id; }\n \n     BufferT() : BufferT(BufferKind::Explicit) {}\n-    BufferT(BufferKind kind) : BufferT(kind, 0, 0) {}\n+    BufferT(BufferKind kind)\n+        : kind(kind), id(InvalidBufferId), size(0), offset(0) {}\n     BufferT(BufferKind kind, size_t size) : BufferT(kind, size, 0) {}\n     BufferT(BufferKind kind, size_t size, size_t offset)\n         : kind(kind), id(nextId++), size(size), offset(offset) {}\n@@ -156,7 +157,7 @@ class Allocation {\n   /// Value -> Alias Buffer\n   using AliasBufferMapT = llvm::MapVector<Value, llvm::SetVector<BufferT *>>;\n   /// BufferId -> Buffer\n-  using BufferSetT = DenseMap<BufferId, BufferT>;\n+  using BufferSetT = std::map<BufferId, BufferT>;\n   /// Runs allocation analysis on the given top-level operation.\n   void run();\n "}, {"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "file_content_changes": "@@ -65,7 +65,7 @@ template <typename Int> Int product(llvm::ArrayRef<Int> arr) {\n \n template <typename Int> Int ceil(Int m, Int n) { return (m + n - 1) / n; }\n \n-// output[i] = input[order[i]]\n+/// output[i] = input[order[i]]\n template <typename T, typename RES_T = T>\n SmallVector<RES_T> reorder(ArrayRef<T> input, ArrayRef<unsigned> order) {\n   size_t rank = order.size();\n@@ -80,6 +80,14 @@ SmallVector<RES_T> reorder(ArrayRef<T> input, ArrayRef<unsigned> order) {\n bool isMmaToDotShortcut(triton::gpu::MmaEncodingAttr &mmaLayout,\n                         triton::gpu::DotOperandEncodingAttr &dotOperandLayout);\n \n+/// Multi-root DAG topological sort.\n+/// Performs a topological sort of the Operation in the `toSort` SetVector.\n+/// Returns a topologically sorted SetVector.\n+/// It is faster than mlir::topologicalSort because it prunes nodes that have\n+/// been visited before.\n+SetVector<Operation *>\n+multiRootTopologicalSort(const SetVector<Operation *> &toSort);\n+\n } // namespace mlir\n \n #endif // TRITON_ANALYSIS_UTILITY_H"}, {"filename": "include/triton/Conversion/MLIRTypes.h", "status": "modified", "additions": 14, "deletions": 15, "changes": 29, "file_content_changes": "@@ -1,5 +1,5 @@\n-#ifndef TRITON_CONVERSION_MLIR_TYPES_H_\n-#define TRITON_CONVERSION_MLIR_TYPES_H_\n+#ifndef TRITON_CONVERSION_MLIR_TYPES_H\n+#define TRITON_CONVERSION_MLIR_TYPES_H\n \n #include \"mlir/Transforms/DialectConversion.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n@@ -10,31 +10,30 @@ namespace triton {\n namespace type {\n \n // Integer types\n-// TODO(Superjomn): may change `static` into better implementations\n-static Type i32Ty(MLIRContext *ctx) { return IntegerType::get(ctx, 32); }\n-static Type i16Ty(MLIRContext *ctx) { return IntegerType::get(ctx, 16); }\n-static Type i8Ty(MLIRContext *ctx) { return IntegerType::get(ctx, 8); }\n-static Type u32Ty(MLIRContext *ctx) {\n+inline Type i32Ty(MLIRContext *ctx) { return IntegerType::get(ctx, 32); }\n+inline Type i16Ty(MLIRContext *ctx) { return IntegerType::get(ctx, 16); }\n+inline Type i8Ty(MLIRContext *ctx) { return IntegerType::get(ctx, 8); }\n+inline Type u32Ty(MLIRContext *ctx) {\n   return IntegerType::get(ctx, 32, IntegerType::Unsigned);\n }\n-static Type u1Ty(MLIRContext *ctx) {\n+inline Type u1Ty(MLIRContext *ctx) {\n   return IntegerType::get(ctx, 1, IntegerType::Unsigned);\n }\n \n // Float types\n-static Type f16Ty(MLIRContext *ctx) { return FloatType::getF16(ctx); }\n-static Type f32Ty(MLIRContext *ctx) { return FloatType::getF32(ctx); }\n-static Type f64Ty(MLIRContext *ctx) { return FloatType::getF64(ctx); }\n-static Type bf16Ty(MLIRContext *ctx) { return FloatType::getBF16(ctx); }\n+inline Type f16Ty(MLIRContext *ctx) { return FloatType::getF16(ctx); }\n+inline Type f32Ty(MLIRContext *ctx) { return FloatType::getF32(ctx); }\n+inline Type f64Ty(MLIRContext *ctx) { return FloatType::getF64(ctx); }\n+inline Type bf16Ty(MLIRContext *ctx) { return FloatType::getBF16(ctx); }\n \n-static bool isFloat(Type type) {\n+inline bool isFloat(Type type) {\n   return type.isF32() || type.isF64() || type.isF16() || type.isF128();\n }\n \n-static bool isInt(Type type) { return type.isIntOrFloat() && !isFloat(type); }\n+inline bool isInt(Type type) { return type.isIntOrFloat() && !isFloat(type); }\n \n } // namespace type\n } // namespace triton\n } // namespace mlir\n \n-#endif // TRITON_CONVERSION_MLIR_TYPES_H_\n+#endif // TRITON_CONVERSION_MLIR_TYPES_H"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 61, "deletions": 0, "changes": 61, "file_content_changes": "@@ -164,4 +164,65 @@ bool isMmaToDotShortcut(triton::gpu::MmaEncodingAttr &mmaLayout,\n          dotOperandLayout.getParent() == mmaLayout;\n }\n \n+namespace {\n+/// DFS post-order implementation that maintains a global count to work across\n+/// multiple invocations, to help implement topological sort on multi-root DAGs.\n+/// We traverse all operations but only record the ones that appear in\n+/// `toSort` for the final result.\n+struct DFSState {\n+  DFSState(const SetVector<Operation *> &set) : toSort(set), seen() {}\n+  const SetVector<Operation *> &toSort;\n+  SmallVector<Operation *, 16> topologicalCounts;\n+  DenseSet<Operation *> seen;\n+};\n+\n+void dfsPostorder(Operation *root, DFSState *state) {\n+  SmallVector<Operation *> queue(1, root);\n+  std::vector<Operation *> ops;\n+  while (!queue.empty()) {\n+    Operation *current = queue.pop_back_val();\n+    if (!state->seen.insert(current).second)\n+      continue;\n+    ops.push_back(current);\n+    for (Value result : current->getResults()) {\n+      for (Operation *op : result.getUsers())\n+        queue.push_back(op);\n+    }\n+    for (Region &region : current->getRegions()) {\n+      for (Operation &op : region.getOps())\n+        queue.push_back(&op);\n+    }\n+  }\n+\n+  for (Operation *op : llvm::reverse(ops)) {\n+    if (state->toSort.count(op) > 0)\n+      state->topologicalCounts.push_back(op);\n+  }\n+}\n+\n+} // namespace\n+\n+SetVector<Operation *>\n+multiRootTopologicalSort(const SetVector<Operation *> &toSort) {\n+  if (toSort.empty()) {\n+    return toSort;\n+  }\n+\n+  // Run from each root with global count and `seen` set.\n+  DFSState state(toSort);\n+  for (auto *s : toSort) {\n+    assert(toSort.count(s) == 1 && \"NYI: multi-sets not supported\");\n+    dfsPostorder(s, &state);\n+  }\n+\n+  // Reorder and return.\n+  SetVector<Operation *> res;\n+  for (auto it = state.topologicalCounts.rbegin(),\n+            eit = state.topologicalCounts.rend();\n+       it != eit; ++it) {\n+    res.insert(*it);\n+  }\n+  return res;\n+}\n+\n } // namespace mlir"}, {"filename": "lib/Conversion/TritonGPUToLLVM/CMakeLists.txt", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "file_content_changes": "@@ -1,13 +1,14 @@\n add_mlir_conversion_library(TritonGPUToLLVM\n-    TritonGPUToLLVM.cpp\n-    TritonGPUToLLVMPass.cpp\n-    PTXAsmFormat.cpp\n     ConvertLayoutOpToLLVM.cpp\n+    DotOpToLLVM.cpp\n     ElementwiseOpToLLVM.cpp\n-    ViewOpToLLVM.cpp\n     LoadStoreOpToLLVM.cpp\n-    DotOpToLLVM.cpp\n+    TritonGPUToLLVM.cpp\n+    TritonGPUToLLVMPass.cpp\n+    PTXAsmFormat.cpp\n     ReduceOpToLLVM.cpp\n+    Utility.cpp\n+    ViewOpToLLVM.cpp\n \n     ADDITIONAL_HEADER_DIRS\n     ${PROJECT_SOURCE_DIR}/include/triton/Conversion/TritonGPUToLLVM"}, {"filename": "lib/Conversion/TritonGPUToLLVM/DotOpHelpers.h", "status": "modified", "additions": 20, "deletions": 2, "changes": 22, "file_content_changes": "@@ -1123,8 +1123,23 @@ class MMA16816SmemLoader {\n     Value ptr = getPtr(ptrIdx);\n \n     // The struct should have exactly the same element types.\n+    auto resTy = matTy.cast<LLVM::LLVMStructType>();\n     Type elemTy = matTy.cast<LLVM::LLVMStructType>().getBody()[0];\n \n+    // For some reasons, LLVM's NVPTX backend inserts unnecessary (?) integer\n+    // instructions to pack & unpack sub-word integers. A workaround is to\n+    // store the results of ldmatrix in i32\n+    if (auto vecElemTy = elemTy.dyn_cast<VectorType>()) {\n+      Type elemElemTy = vecElemTy.getElementType();\n+      if (auto intTy = elemElemTy.dyn_cast<IntegerType>()) {\n+        if (intTy.getWidth() <= 16) {\n+          elemTy = rewriter.getI32Type();\n+          resTy = LLVM::LLVMStructType::getLiteral(\n+              ctx, SmallVector<Type>(4, elemTy));\n+        }\n+      }\n+    }\n+\n     if (canUseLdmatrix) {\n       Value sOffset =\n           mul(i32_val(matIdx[order[1]] * sMatStride * sMatShape), sStride);\n@@ -1143,7 +1158,7 @@ class MMA16816SmemLoader {\n \n       // The result type is 4xi32, each i32 is composed of 2xf16\n       // elements (adjacent two columns in a row) or a single f32 element.\n-      Value resV4 = builder.launch(rewriter, loc, matTy);\n+      Value resV4 = builder.launch(rewriter, loc, resTy);\n       return {extract_val(elemTy, resV4, i32_arr_attr(0)),\n               extract_val(elemTy, resV4, i32_arr_attr(1)),\n               extract_val(elemTy, resV4, i32_arr_attr(2)),\n@@ -1177,6 +1192,8 @@ class MMA16816SmemLoader {\n       }\n       return {retElems[0], retElems[1], retElems[2], retElems[3]};\n     } else if (elemBytes == 1 && needTrans) { // work with int8\n+      // Can't use i32 here. Use LLVM's VectorType\n+      elemTy = matTy.cast<LLVM::LLVMStructType>().getBody()[0];\n       std::array<std::array<Value, 4>, 2> ptrs;\n       ptrs[0] = {\n           getPtr(ptrIdx),\n@@ -1235,7 +1252,8 @@ class MMA16816SmemLoader {\n         }\n       }\n \n-      return {i8v4Elems[0], i8v4Elems[1], i8v4Elems[2], i8v4Elems[3]};\n+      return {bitcast(i8v4Elems[0], i32_ty), bitcast(i8v4Elems[1], i32_ty),\n+              bitcast(i8v4Elems[2], i32_ty), bitcast(i8v4Elems[3], i32_ty)};\n     }\n \n     assert(false && \"Invalid smem load\");"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -70,7 +70,6 @@ struct BroadcastOpConversion\n     auto resultOffsets = emitOffsetForLayout(resultLayout, resultShape);\n     SmallVector<Value> srcVals = getElementsFromStruct(loc, src, rewriter);\n     if (auto srcMma = srcLayout.dyn_cast<MmaEncodingAttr>()) {\n-\n       // NOTE: This is just an naive fix, but for MMA layout, and 2-d fix should\n       // be all right.\n       // TODO[Superjomn]: Replace this with a generic implementation."}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "file_content_changes": "@@ -97,6 +97,15 @@ class TritonGPUToLLVMTypeConverter : public LLVMTypeConverter {\n           Type targetTy;\n           if (targetTyMap.count(elemTy.getIntOrFloatBitWidth())) {\n             targetTy = targetTyMap.lookup(elemTy.getIntOrFloatBitWidth());\n+            // <2xi16>/<4xi8> => i32\n+            // We are doing this because NVPTX inserts extra integer instrs to\n+            // pack & unpack vectors of sub-word integers\n+            // Note: this needs to be synced with\n+            //       DotOpMmaV2ConversionHelper::loadX4\n+            if (elemTy.isa<IntegerType>() &&\n+                (elemTy.getIntOrFloatBitWidth() == 8 ||\n+                 elemTy.getIntOrFloatBitWidth() == 16))\n+              targetTy = IntegerType::get(ctx, 32);\n           } else {\n             assert(false && \"Unsupported element type\");\n           }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/Utility.cpp", "status": "added", "additions": 140, "deletions": 0, "changes": 140, "file_content_changes": "@@ -0,0 +1,140 @@\n+#include \"Utility.h\"\n+\n+namespace mlir {\n+\n+namespace LLVM {\n+using namespace mlir::triton;\n+\n+Value getStructFromElements(Location loc, ValueRange resultVals,\n+                            ConversionPatternRewriter &rewriter,\n+                            Type structType) {\n+  if (!structType.isa<LLVM::LLVMStructType>()) {\n+    return *resultVals.begin();\n+  }\n+\n+  Value llvmStruct = rewriter.create<LLVM::UndefOp>(loc, structType);\n+  for (const auto &v : llvm::enumerate(resultVals)) {\n+    assert(v.value() && \"can not insert null values\");\n+    llvmStruct = insert_val(structType, llvmStruct, v.value(),\n+                            rewriter.getI64ArrayAttr(v.index()));\n+  }\n+  return llvmStruct;\n+}\n+\n+SmallVector<Value> getElementsFromStruct(Location loc, Value llvmStruct,\n+                                         ConversionPatternRewriter &rewriter) {\n+  if (llvmStruct.getType().isIntOrIndexOrFloat() ||\n+      llvmStruct.getType().isa<triton::PointerType>() ||\n+      llvmStruct.getType().isa<LLVM::LLVMPointerType>())\n+    return {llvmStruct};\n+  ArrayRef<Type> types =\n+      llvmStruct.getType().cast<LLVM::LLVMStructType>().getBody();\n+  SmallVector<Value> results(types.size());\n+  for (unsigned i = 0; i < types.size(); ++i) {\n+    Type type = types[i];\n+    results[i] = extract_val(type, llvmStruct, i64_arr_attr(i));\n+  }\n+  return results;\n+}\n+\n+Value createConstantI32(Location loc, PatternRewriter &rewriter, int32_t v) {\n+  auto i32ty = rewriter.getIntegerType(32);\n+  return rewriter.create<LLVM::ConstantOp>(loc, i32ty,\n+                                           IntegerAttr::get(i32ty, v));\n+}\n+\n+Value createConstantF32(Location loc, PatternRewriter &rewriter, float v) {\n+  auto type = type::f32Ty(rewriter.getContext());\n+  return rewriter.create<LLVM::ConstantOp>(loc, type,\n+                                           rewriter.getF32FloatAttr(v));\n+}\n+\n+Value createConstantF64(Location loc, PatternRewriter &rewriter, float v) {\n+  auto type = type::f64Ty(rewriter.getContext());\n+  return rewriter.create<LLVM::ConstantOp>(loc, type,\n+                                           rewriter.getF64FloatAttr(v));\n+}\n+\n+// Create an index type constant.\n+Value createIndexConstant(OpBuilder &builder, Location loc,\n+                          TypeConverter *converter, int64_t value) {\n+  Type ty = converter->convertType(builder.getIndexType());\n+  return builder.create<LLVM::ConstantOp>(loc, ty,\n+                                          builder.getIntegerAttr(ty, value));\n+}\n+\n+// Create an integer constant of \\param width bits.\n+Value createLLVMIntegerConstant(OpBuilder &builder, Location loc, short width,\n+                                int64_t value) {\n+  Type ty = builder.getIntegerType(width);\n+  return builder.create<LLVM::ConstantOp>(loc, ty,\n+                                          builder.getIntegerAttr(ty, value));\n+}\n+\n+SharedMemoryObject\n+getSharedMemoryObjectFromStruct(Location loc, Value llvmStruct,\n+                                ConversionPatternRewriter &rewriter) {\n+  auto elems = getElementsFromStruct(loc, llvmStruct, rewriter);\n+  auto rank = (elems.size() - 1) / 2;\n+  return {/*base=*/elems[0],\n+          /*strides=*/{elems.begin() + 1, elems.begin() + 1 + rank},\n+          /*offsets=*/{elems.begin() + 1 + rank, elems.end()}};\n+}\n+\n+SmallVector<Value>\n+getStridesFromShapeAndOrder(ArrayRef<int64_t> shape, ArrayRef<unsigned> order,\n+                            Location loc, ConversionPatternRewriter &rewriter) {\n+  auto rank = shape.size();\n+  SmallVector<Value> strides(rank);\n+  int64_t stride = 1;\n+  for (auto idx : order) {\n+    strides[idx] = i32_val(stride);\n+    stride *= shape[idx];\n+  }\n+  return strides;\n+}\n+\n+Value storeShared(ConversionPatternRewriter &rewriter, Location loc, Value ptr,\n+                  Value val, Value pred) {\n+  MLIRContext *ctx = rewriter.getContext();\n+  unsigned bits = val.getType().getIntOrFloatBitWidth();\n+  const char *c = bits == 64 ? \"l\" : (bits == 16 ? \"h\" : \"r\");\n+\n+  PTXBuilder builder;\n+  auto *ptrOpr = builder.newAddrOperand(ptr, \"r\");\n+  auto *valOpr = builder.newOperand(val, c);\n+  auto &st = builder.create<>(\"st\")->shared().b(bits);\n+  st(ptrOpr, valOpr).predicate(pred, \"b\");\n+  return builder.launch(rewriter, loc, void_ty(ctx));\n+}\n+\n+Value shflSync(Location loc, ConversionPatternRewriter &rewriter, Value val,\n+               int i) {\n+  unsigned bits = val.getType().getIntOrFloatBitWidth();\n+\n+  if (bits == 64) {\n+    Type vecTy = vec_ty(f32_ty, 2);\n+    Value vec = bitcast(val, vecTy);\n+    Value val0 = extract_element(f32_ty, vec, i32_val(0));\n+    Value val1 = extract_element(f32_ty, vec, i32_val(1));\n+    val0 = shflSync(loc, rewriter, val0, i);\n+    val1 = shflSync(loc, rewriter, val1, i);\n+    vec = undef(vecTy);\n+    vec = insert_element(vecTy, vec, val0, i32_val(0));\n+    vec = insert_element(vecTy, vec, val1, i32_val(1));\n+    return bitcast(vec, val.getType());\n+  }\n+\n+  PTXBuilder builder;\n+  auto &shfl = builder.create(\"shfl.sync\")->o(\"bfly\").o(\"b32\");\n+  auto *dOpr = builder.newOperand(\"=r\");\n+  auto *aOpr = builder.newOperand(val, \"r\");\n+  auto *bOpr = builder.newConstantOperand(i);\n+  auto *cOpr = builder.newConstantOperand(\"0x1f\");\n+  auto *maskOpr = builder.newConstantOperand(\"0xffffffff\");\n+  shfl(dOpr, aOpr, bOpr, cOpr, maskOpr);\n+  return builder.launch(rewriter, loc, val.getType(), false);\n+}\n+\n+} // namespace LLVM\n+} // namespace mlir"}, {"filename": "lib/Conversion/TritonGPUToLLVM/Utility.h", "status": "modified", "additions": 28, "deletions": 129, "changes": 157, "file_content_changes": "@@ -137,8 +137,7 @@ llvm::SmallVector<T> getMultiDimIndex(T linearIndex, llvm::ArrayRef<T> shape,\n \n // Linearize supposing order is [0, 1, .. , n]\n template <typename T>\n-static T getLinearIndexImpl(llvm::ArrayRef<T> multiDimIndex,\n-                            llvm::ArrayRef<T> shape) {\n+T getLinearIndexImpl(llvm::ArrayRef<T> multiDimIndex, llvm::ArrayRef<T> shape) {\n   assert(multiDimIndex.size() == shape.size());\n   // shape: {a, b, c, d}  ->  accMul: {1, a, a*b, a*b*c}\n   size_t rank = shape.size();\n@@ -154,9 +153,8 @@ static T getLinearIndexImpl(llvm::ArrayRef<T> multiDimIndex,\n }\n \n template <typename T>\n-static T getLinearIndex(llvm::ArrayRef<T> multiDimIndex,\n-                        llvm::ArrayRef<T> shape,\n-                        llvm::ArrayRef<unsigned> order) {\n+T getLinearIndex(llvm::ArrayRef<T> multiDimIndex, llvm::ArrayRef<T> shape,\n+                 llvm::ArrayRef<unsigned> order) {\n   assert(shape.size() == order.size());\n   return getLinearIndexImpl<T>(reorder(multiDimIndex, order),\n                                reorder(shape, order));\n@@ -167,91 +165,34 @@ static T getLinearIndex(llvm::ArrayRef<T> multiDimIndex,\n namespace LLVM {\n using namespace mlir::triton;\n \n-static Value getStructFromElements(Location loc, ValueRange resultVals,\n-                                   ConversionPatternRewriter &rewriter,\n-                                   Type structType) {\n-  if (!structType.isa<LLVM::LLVMStructType>()) {\n-    return *resultVals.begin();\n-  }\n+Value getStructFromElements(Location loc, ValueRange resultVals,\n+                            ConversionPatternRewriter &rewriter,\n+                            Type structType);\n \n-  Value llvmStruct = rewriter.create<LLVM::UndefOp>(loc, structType);\n-  for (const auto &v : llvm::enumerate(resultVals)) {\n-    assert(v.value() && \"can not insert null values\");\n-    llvmStruct = insert_val(structType, llvmStruct, v.value(),\n-                            rewriter.getI64ArrayAttr(v.index()));\n-  }\n-  return llvmStruct;\n-}\n+SmallVector<Value> getElementsFromStruct(Location loc, Value llvmStruct,\n+                                         ConversionPatternRewriter &rewriter);\n \n-static SmallVector<Value>\n-getElementsFromStruct(Location loc, Value llvmStruct,\n-                      ConversionPatternRewriter &rewriter) {\n-  if (llvmStruct.getType().isIntOrIndexOrFloat() ||\n-      llvmStruct.getType().isa<triton::PointerType>() ||\n-      llvmStruct.getType().isa<LLVM::LLVMPointerType>())\n-    return {llvmStruct};\n-  ArrayRef<Type> types =\n-      llvmStruct.getType().cast<LLVM::LLVMStructType>().getBody();\n-  SmallVector<Value> results(types.size());\n-  for (unsigned i = 0; i < types.size(); ++i) {\n-    Type type = types[i];\n-    results[i] = extract_val(type, llvmStruct, i64_arr_attr(i));\n-  }\n-  return results;\n-}\n+/// Create a 32-bit integer constant.\n+Value createConstantI32(Location loc, PatternRewriter &rewriter, int32_t v);\n \n-// Create a 32-bit integer constant.\n-static Value createConstantI32(Location loc, PatternRewriter &rewriter,\n-                               int32_t v) {\n-  auto i32ty = rewriter.getIntegerType(32);\n-  return rewriter.create<LLVM::ConstantOp>(loc, i32ty,\n-                                           IntegerAttr::get(i32ty, v));\n-}\n+/// Create a 32-bit float constant.\n+Value createConstantF32(Location loc, PatternRewriter &rewriter, float v);\n \n-static Value createConstantF32(Location loc, PatternRewriter &rewriter,\n-                               float v) {\n-  auto type = type::f32Ty(rewriter.getContext());\n-  return rewriter.create<LLVM::ConstantOp>(loc, type,\n-                                           rewriter.getF32FloatAttr(v));\n-}\n+/// Create a 64-bit float constant.\n+Value createConstantF64(Location loc, PatternRewriter &rewriter, float v);\n \n-static Value createConstantF64(Location loc, PatternRewriter &rewriter,\n-                               float v) {\n-  auto type = type::f64Ty(rewriter.getContext());\n-  return rewriter.create<LLVM::ConstantOp>(loc, type,\n-                                           rewriter.getF64FloatAttr(v));\n-}\n+/// Create an index type constant.\n+Value createIndexConstant(OpBuilder &builder, Location loc,\n+                          TypeConverter *converter, int64_t value);\n \n-// Create an index type constant.\n-static Value createIndexConstant(OpBuilder &builder, Location loc,\n-                                 TypeConverter *converter, int64_t value) {\n-  Type ty = converter->convertType(builder.getIndexType());\n-  return builder.create<LLVM::ConstantOp>(loc, ty,\n-                                          builder.getIntegerAttr(ty, value));\n-}\n-\n-// Create an integer constant of \\param width bits.\n-static Value createLLVMIntegerConstant(OpBuilder &builder, Location loc,\n-                                       short width, int64_t value) {\n-  Type ty = builder.getIntegerType(width);\n-  return builder.create<LLVM::ConstantOp>(loc, ty,\n-                                          builder.getIntegerAttr(ty, value));\n-}\n+/// Create an integer constant of \\param width bits.\n+Value createLLVMIntegerConstant(OpBuilder &builder, Location loc, short width,\n+                                int64_t value);\n \n /// Helper function to get strides from a given shape and its order\n-static SmallVector<Value>\n+SmallVector<Value>\n getStridesFromShapeAndOrder(ArrayRef<int64_t> shape, ArrayRef<unsigned> order,\n-                            Location loc, ConversionPatternRewriter &rewriter) {\n-  auto rank = shape.size();\n-  SmallVector<Value> strides(rank);\n-  int64_t stride = 1;\n-  for (auto idx : order) {\n-    strides[idx] = i32_val(stride);\n-    stride *= shape[idx];\n-  }\n-  return strides;\n-}\n-\n+                            Location loc, ConversionPatternRewriter &rewriter);\n struct SharedMemoryObject {\n   Value base; // i32 ptr. The start address of the shared memory object.\n   // We need to store strides as Values but not integers because the\n@@ -315,57 +256,15 @@ struct SharedMemoryObject {\n   }\n };\n \n-static SharedMemoryObject\n+SharedMemoryObject\n getSharedMemoryObjectFromStruct(Location loc, Value llvmStruct,\n-                                ConversionPatternRewriter &rewriter) {\n-  auto elems = getElementsFromStruct(loc, llvmStruct, rewriter);\n-  auto rank = (elems.size() - 1) / 2;\n-  return {/*base=*/elems[0],\n-          /*strides=*/{elems.begin() + 1, elems.begin() + 1 + rank},\n-          /*offsets=*/{elems.begin() + 1 + rank, elems.end()}};\n-}\n+                                ConversionPatternRewriter &rewriter);\n \n-static Value storeShared(ConversionPatternRewriter &rewriter, Location loc,\n-                         Value ptr, Value val, Value pred) {\n-  MLIRContext *ctx = rewriter.getContext();\n-  unsigned bits = val.getType().getIntOrFloatBitWidth();\n-  const char *c = bits == 64 ? \"l\" : (bits == 16 ? \"h\" : \"r\");\n-\n-  PTXBuilder builder;\n-  auto *ptrOpr = builder.newAddrOperand(ptr, \"r\");\n-  auto *valOpr = builder.newOperand(val, c);\n-  auto &st = builder.create<>(\"st\")->shared().b(bits);\n-  st(ptrOpr, valOpr).predicate(pred, \"b\");\n-  return builder.launch(rewriter, loc, void_ty(ctx));\n-}\n-\n-static Value shflSync(Location loc, ConversionPatternRewriter &rewriter,\n-                      Value val, int i) {\n-  unsigned bits = val.getType().getIntOrFloatBitWidth();\n-\n-  if (bits == 64) {\n-    Type vecTy = vec_ty(f32_ty, 2);\n-    Value vec = bitcast(val, vecTy);\n-    Value val0 = extract_element(f32_ty, vec, i32_val(0));\n-    Value val1 = extract_element(f32_ty, vec, i32_val(1));\n-    val0 = shflSync(loc, rewriter, val0, i);\n-    val1 = shflSync(loc, rewriter, val1, i);\n-    vec = undef(vecTy);\n-    vec = insert_element(vecTy, vec, val0, i32_val(0));\n-    vec = insert_element(vecTy, vec, val1, i32_val(1));\n-    return bitcast(vec, val.getType());\n-  }\n+Value storeShared(ConversionPatternRewriter &rewriter, Location loc, Value ptr,\n+                  Value val, Value pred);\n \n-  PTXBuilder builder;\n-  auto &shfl = builder.create(\"shfl.sync\")->o(\"bfly\").o(\"b32\");\n-  auto *dOpr = builder.newOperand(\"=r\");\n-  auto *aOpr = builder.newOperand(val, \"r\");\n-  auto *bOpr = builder.newConstantOperand(i);\n-  auto *cOpr = builder.newConstantOperand(\"0x1f\");\n-  auto *maskOpr = builder.newConstantOperand(\"0xffffffff\");\n-  shfl(dOpr, aOpr, bOpr, cOpr, maskOpr);\n-  return builder.launch(rewriter, loc, val.getType(), false);\n-}\n+Value shflSync(Location loc, ConversionPatternRewriter &rewriter, Value val,\n+               int i);\n \n } // namespace LLVM\n } // namespace mlir"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -635,7 +635,7 @@ class RematerializeBackward : public mlir::RewritePattern {\n       else\n         sortedValues.push_back(v);\n     }\n-    tmp = mlir::topologicalSort(tmp);\n+    tmp = mlir::multiRootTopologicalSort(tmp);\n     for (Operation *op : tmp)\n       sortedValues.push_back(op->getResult(0));\n "}, {"filename": "lib/Dialect/TritonGPU/Transforms/Prefetch.cpp", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -159,6 +159,12 @@ LogicalResult Prefetcher::initialize() {\n \n   for (triton::DotOp dot : dotsInFor) {\n     auto kSize = dot.a().getType().cast<RankedTensorType>().getShape()[1];\n+\n+    // works better with nvidia tensor cores\n+    unsigned elementWidth =\n+        dot.a().getType().cast<RankedTensorType>().getElementTypeBitWidth();\n+    prefetchWidth = 256 / elementWidth;\n+\n     // Skip prefetching if kSize is less than prefetchWidth\n     if (kSize < prefetchWidth)\n       continue;"}, {"filename": "python/setup.py", "status": "modified", "additions": 21, "deletions": 7, "changes": 28, "file_content_changes": "@@ -144,8 +144,10 @@ def build_extension(self, ext):\n             \"-DPython3_EXECUTABLE:FILEPATH=\" + sys.executable,\n             \"-DCMAKE_VERBOSE_MAKEFILE:BOOL=ON\",\n             \"-DPYTHON_INCLUDE_DIRS=\" + python_include_dir,\n-            \"-DLLVM_EXTERNAL_LIT=\" + lit_dir,\n-        ] + thirdparty_cmake_args\n+        ]\n+        if lit_dir is not None:\n+            cmake_args.append(\"-DLLVM_EXTERNAL_LIT=\" + lit_dir)\n+        cmake_args.extend(thirdparty_cmake_args)\n \n         # configuration\n         cfg = get_build_type()\n@@ -166,6 +168,22 @@ def build_extension(self, ext):\n         subprocess.check_call([\"cmake\", \"--build\", \".\"] + build_args, cwd=self.build_temp)\n \n \n+package_data = {\n+    \"triton/ops\": [\"*.c\"],\n+    \"triton/ops/blocksparse\": [\"*.c\"],\n+    \"triton/language\": [\"*.bc\"],\n+}\n+\n+if os.getenv(\"TRITION_PACKAGE_CUDA_DEPS\"):\n+    base_dir = os.path.dirname(__file__)\n+    cuda_dir = os.getenv(\"CUDA_HOME\", \"/usr/local/cuda\")\n+    triton_dir = os.path.join(base_dir, \"triton\")\n+    os.makedirs(os.path.join(triton_dir, \"include\"), exist_ok=True)\n+    os.makedirs(os.path.join(triton_dir, \"bin\"), exist_ok=True)\n+    shutil.copy(os.path.join(cuda_dir, \"include\", \"cuda.h\"), os.path.join(triton_dir, \"include\"))\n+    shutil.copy(os.path.join(cuda_dir, \"bin\", \"ptxas\"), os.path.join(triton_dir, \"bin\"))\n+    package_data[\"triton\"] = [\"include/cuda.h\", \"bin/ptxas\"]\n+\n setup(\n     name=\"triton\",\n     version=\"2.0.0\",\n@@ -180,11 +198,7 @@ def build_extension(self, ext):\n         \"torch\",\n         \"lit\",\n     ],\n-    package_data={\n-        \"triton/ops\": [\"*.c\"],\n-        \"triton/ops/blocksparse\": [\"*.c\"],\n-        \"triton/language\": [\"*.bc\"]\n-    },\n+    package_data=package_data,\n     include_package_data=True,\n     ext_modules=[CMakeExtension(\"triton\", \"triton/_C/\")],\n     cmdclass={\"build_ext\": CMakeBuild},"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "file_content_changes": "@@ -987,6 +987,9 @@ def path_to_ptxas():\n         \"/usr\",\n         os.environ.get('CUDA_PATH', default_cuda_dir())\n     ]\n+    if not os.getenv(\"TRITON_IGNORE_BUNDLED_PTXAS\"):\n+        prefixes.insert(0, os.path.dirname(__file__))\n+\n     for prefix in prefixes:\n         ptxas = os.path.join(prefix, \"bin\", \"ptxas\")\n         if os.path.exists(ptxas):\n@@ -1287,6 +1290,11 @@ def _build(name, src, srcdir):\n     cuda_lib_dirs = libcuda_dirs()\n     cuda_path = os.environ.get('CUDA_PATH', default_cuda_dir())\n     cu_include_dir = os.path.join(cuda_path, \"include\")\n+    triton_include_dir = os.path.join(os.path.dirname(__file__), \"include\")\n+    cuda_header = os.path.join(cu_include_dir, \"cuda.h\")\n+    triton_cuda_header = os.path.join(triton_include_dir, \"cuda.h\")\n+    if not os.path.exists(cuda_header) and os.path.exists(triton_cuda_header):\n+        cu_include_dir = triton_include_dir\n     suffix = sysconfig.get_config_var('EXT_SUFFIX')\n     so = os.path.join(srcdir, '{name}{suffix}'.format(name=name, suffix=suffix))\n     # try to avoid setuptools if possible\n@@ -1296,6 +1304,8 @@ def _build(name, src, srcdir):\n         clang = shutil.which(\"clang\")\n         gcc = shutil.which(\"gcc\")\n         cc = gcc if gcc is not None else clang\n+        if cc is None:\n+            raise RuntimeError(\"Failed to find C compiler. Please specify via CC environment variable.\")\n     py_include_dir = get_paths()[\"include\"]\n \n     cc_cmd = [cc, src, \"-O3\", f\"-I{cu_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", \"-lcuda\", \"-o\", so]"}]