[{"filename": "python/test/regression/test_performance.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -248,22 +248,22 @@ def _sum(x_ptr, y_ptr, output_ptr, n_elements,\n     tl.store(output_ptr + offsets, x, mask=mask)\n \n \n-elementwise_data = {\n+reduction_data = {\n     'a100': {\n         1024 * 16384: {'float16': 0.016, 'float32': 0.031, 'int16': 0.015, 'int32': 0.031},\n         1024 * 65536: {'float16': 0.016, 'float32': 0.032, 'int16': 0.015, 'int32': 0.032},\n     }\n }\n \n \n-@pytest.mark.parametrize('N', elementwise_data[DEVICE_NAME].keys())\n+@pytest.mark.parametrize('N', reduction_data[DEVICE_NAME].keys())\n @pytest.mark.parametrize(\"dtype_str\", ['float16', 'float32', 'int16', 'int32'])\n def test_reductions(N, dtype_str):\n     stream = torch.cuda.Stream()\n     torch.cuda.set_stream(stream)\n     torch.manual_seed(0)\n     dtype = {'float16': torch.float16, 'float32': torch.float32, 'int16': torch.int16, 'int32': torch.int32}[dtype_str]\n-    ref_gpu_util = elementwise_data[DEVICE_NAME][N][dtype_str]\n+    ref_gpu_util = reduction_data[DEVICE_NAME][N][dtype_str]\n     cur_sm_clock = nvsmi(['clocks.current.sm'])[0]\n     max_gpu_perf = get_max_tensorcore_tflops(dtype, clock_rate=cur_sm_clock * 1e3)\n     z = torch.empty((N, ), dtype=dtype, device='cuda')"}]