[{"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 9, "deletions": 4, "changes": 13, "file_content_changes": "@@ -87,6 +87,15 @@ struct ReduceOpConversion\n                           Attribute layout, SmallVector<Value> &index,\n                           SmallVector<Value> &writeIdx,\n                           std::map<int, Value> &ints, unsigned axis) const {\n+    if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n+      auto dim = sliceLayout.getDim();\n+      assert(dim != axis && \"Reduction axis cannot be sliced\");\n+      auto parentLayout = sliceLayout.getParent();\n+      getWriteIndexBasic(rewriter, loc, parentLayout, index, writeIdx, ints,\n+                         axis);\n+      return;\n+    }\n+\n     writeIdx = index;\n     auto sizePerThread = triton::gpu::getSizePerThread(layout);\n     Value axisSizePerThread = ints[sizePerThread[axis]];\n@@ -114,10 +123,6 @@ struct ReduceOpConversion\n         // Same as BlockedEncodingAttr case\n         writeIdx[axis] = udiv(index[axis], axisSizePerThread);\n       }\n-    } else if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n-      auto parentLayout = sliceLayout.getParent();\n-      getWriteIndexBasic(rewriter, loc, parentLayout, index, writeIdx, ints,\n-                         axis);\n     } else {\n       llvm::report_fatal_error(\"Unsupported layout\");\n     }"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 2, "deletions": 22, "changes": 24, "file_content_changes": "@@ -95,25 +95,14 @@ SmallVector<unsigned> getThreadsPerWarp(Attribute layout) {\n }\n \n SmallVector<unsigned> getThreadsPerWarpWithUniqueData(Attribute layout) {\n-  if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n-    return SmallVector<unsigned>(blockedLayout.getThreadsPerWarp().begin(),\n-                                 blockedLayout.getThreadsPerWarp().end());\n-  }\n-  if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n-    if (mmaLayout.isVolta())\n-      return {4, 8};\n-    if (mmaLayout.isAmpere())\n-      return {8, 4};\n-  }\n   if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n     auto parent = sliceLayout.getParent();\n     auto parentThreadsPerWarp = getThreadsPerWarpWithUniqueData(parent);\n     SmallVector<unsigned> threadsPerWarp = parentThreadsPerWarp;\n     threadsPerWarp.erase(threadsPerWarp.begin() + sliceLayout.getDim());\n     return threadsPerWarp;\n   }\n-  assert(0 && \"getThreadsPerWarp not implemented\");\n-  return {};\n+  return getThreadsPerWarp(layout);\n }\n \n SmallVector<unsigned> getWarpsPerCTA(Attribute layout) {\n@@ -139,23 +128,14 @@ SmallVector<unsigned> getWarpsPerCTA(Attribute layout) {\n }\n \n SmallVector<unsigned> getWarpsPerCTAWithUniqueData(Attribute layout) {\n-  if (auto blockedLayout = layout.dyn_cast<BlockedEncodingAttr>()) {\n-    return SmallVector<unsigned>(blockedLayout.getWarpsPerCTA().begin(),\n-                                 blockedLayout.getWarpsPerCTA().end());\n-  }\n-  if (auto mmaLayout = layout.dyn_cast<MmaEncodingAttr>()) {\n-    return SmallVector<unsigned>(mmaLayout.getWarpsPerCTA().begin(),\n-                                 mmaLayout.getWarpsPerCTA().end());\n-  }\n   if (auto sliceLayout = layout.dyn_cast<SliceEncodingAttr>()) {\n     auto parent = sliceLayout.getParent();\n     auto parentWarpsPerCTA = getWarpsPerCTAWithUniqueData(parent);\n     SmallVector<unsigned> warpsPerCTA = parentWarpsPerCTA;\n     warpsPerCTA.erase(warpsPerCTA.begin() + sliceLayout.getDim());\n     return warpsPerCTA;\n   }\n-  assert(0 && \"getWarpsPerCTA not implemented\");\n-  return {};\n+  return getWarpsPerCTA(layout);\n }\n \n SmallVector<unsigned> getSizePerThread(Attribute layout) {"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 50, "deletions": 73, "changes": 123, "file_content_changes": "@@ -1346,91 +1346,68 @@ def _welford_combine(mean_1, m2_1, weight_1, mean_2, m2_2, weight_2):\n     )\n \n \n-@pytest.mark.skip\n-def test_sum_kernel_ttgir():\n-    ir = \"\"\"\n-#blocked = #triton_gpu.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 32], warpsPerCTA = [2, 2], order = [1, 0]}>\n-module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-  tt.func public @sum_kernel_0d1d(%arg0: !tt.ptr<i32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n-    %cst = arith.constant dense<128> : tensor<128x1xi32, #blocked>\n-    %0 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>\n-    %1 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>) -> tensor<128x1xi32, #blocked>\n-    %2 = arith.muli %1, %cst : tensor<128x1xi32, #blocked>\n-    %3 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>\n-    %4 = tt.expand_dims %3 {axis = 0 : i32} : (tensor<128xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>) -> tensor<1x128xi32, #blocked>\n-    %5 = tt.broadcast %2 : (tensor<128x1xi32, #blocked>) -> tensor<128x128xi32, #blocked>\n-    %6 = tt.broadcast %4 : (tensor<1x128xi32, #blocked>) -> tensor<128x128xi32, #blocked>\n-    %7 = arith.addi %5, %6 : tensor<128x128xi32, #blocked>\n-    %8 = tt.splat %arg0 : (!tt.ptr<i32>) -> tensor<128x128x!tt.ptr<i32>, #blocked>\n-    %9 = tt.addptr %8, %7 : tensor<128x128x!tt.ptr<i32>, #blocked>, tensor<128x128xi32, #blocked>\n-    %10 = tt.load %9 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<128x128xi32, #blocked>\n-    %11 = \"tt.reduce\"(%10) ({\n-    ^bb0(%arg2: i32, %arg3: i32):\n-      %13 = arith.addi %arg2, %arg3 : i32\n-      tt.reduce.return %13 : i32\n-    }) {axis = 1 : i32} : (tensor<128x128xi32, #blocked>) -> tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>\n-    %12 = tt.expand_dims %11 {axis = 1 : i32} : (tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>) -> tensor<128x1xi32, #blocked>\n-    %13 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>\n-    %14 = tt.expand_dims %13 {axis = 1 : i32} : (tensor<128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>) -> tensor<128x1xi32, #blocked>\n-    %18 = tt.splat %arg1 : (!tt.ptr<i32>) -> tensor<128x1x!tt.ptr<i32>, #blocked>\n-    %20 = tt.addptr %18, %14 : tensor<128x1x!tt.ptr<i32>, #blocked>, tensor<128x1xi32, #blocked>\n-    tt.store %20, %12 {cache = 1 : i32, evict = 1 : i32} : tensor<128x1xi32, #blocked>\n-    tt.return\n-  }\n-}\n-    \"\"\"\n+layouts = [\n+    BlockedLayout([1, 4], [1, 32], [4, 1], [1, 0]),\n+    BlockedLayout([1, 4], [1, 32], [2, 2], [1, 0]),\n+    BlockedLayout([1, 4], [1, 32], [1, 4], [1, 0]),\n+    BlockedLayout([1, 4], [8, 4], [2, 2], [0, 1])\n+]\n \n+\n+@pytest.mark.parametrize(\"M, N\", [[32, 128], [128, 128], [128, 32]])\n+@pytest.mark.parametrize(\"src_layout\", layouts)\n+def test_reduce_2d(M, N, src_layout, device='cuda'):\n+    ir = f\"\"\"\n+    #src = {src_layout}\n+    module attributes {{\"triton_gpu.num-warps\" = 4 : i32}} {{\n+    tt.func public @sum_kernel_0d1d(%arg0: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}, %arg1: !tt.ptr<i32> {{tt.divisibility = 16 : i32}}) {{\n+        %cst = arith.constant dense<{M}> : tensor<{M}x1xi32, #src>\n+        %0 = tt.make_range {{end = {M} : i32, start = 0 : i32}} : tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n+        %1 = tt.expand_dims %0 {{axis = 1 : i32}} : (tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>) -> tensor<{M}x1xi32, #src>\n+        %2 = arith.muli %1, %cst : tensor<{M}x1xi32, #src>\n+        %3 = tt.make_range {{end = {N} : i32, start = 0 : i32}} : tensor<{N}xi32, #triton_gpu.slice<{{dim = 0, parent = #src}}>>\n+        %4 = tt.expand_dims %3 {{axis = 0 : i32}} : (tensor<{N}xi32, #triton_gpu.slice<{{dim = 0, parent = #src}}>>) -> tensor<1x{N}xi32, #src>\n+        %5 = tt.broadcast %2 : (tensor<{M}x1xi32, #src>) -> tensor<{M}x{N}xi32, #src>\n+        %6 = tt.broadcast %4 : (tensor<1x{N}xi32, #src>) -> tensor<{M}x{N}xi32, #src>\n+        %7 = arith.addi %5, %6 : tensor<{M}x{N}xi32, #src>\n+        %8 = tt.splat %arg0 : (!tt.ptr<i32>) -> tensor<{M}x{N}x!tt.ptr<i32>, #src>\n+        %9 = tt.addptr %8, %7 : tensor<{M}x{N}x!tt.ptr<i32>, #src>, tensor<{M}x{N}xi32, #src>\n+        %10 = tt.load %9 {{cache = 1 : i32, evict = 1 : i32, isVolatile = false}} : tensor<{M}x{N}xi32, #src>\n+        %11 = \"tt.reduce\"(%10) ({{\n+        ^bb0(%arg2: i32, %arg3: i32):\n+        %13 = arith.addi %arg2, %arg3 : i32\n+        tt.reduce.return %13 : i32\n+        }}) {{axis = 1 : i32}} : (tensor<{M}x{N}xi32, #src>) -> tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>\n+        %12 = \"tt.reduce\"(%11) ({{\n+        ^bb0(%arg2: i32, %arg3: i32):\n+        %13 = arith.addi %arg2, %arg3 : i32\n+        tt.reduce.return %13 : i32\n+        }}) {{axis = 0 : i32}} : (tensor<{M}xi32, #triton_gpu.slice<{{dim = 1, parent = #src}}>>) -> i32\n+        tt.store %arg1, %12 {{cache = 1 : i32, evict = 1 : i32}} : i32\n+        tt.return\n+    }}\n+    }}\n+    \"\"\"\n     import tempfile\n     with tempfile.NamedTemporaryFile(mode='w', suffix='.ttgir') as f:\n         f.write(ir)\n         f.flush()\n         kernel = triton.compile(f.name)\n \n-    BLOCK_SIZE = 128\n-    x = np.ones((BLOCK_SIZE, BLOCK_SIZE), dtype=np.int32)\n-    y = np.zeros((BLOCK_SIZE, 1), dtype=np.int32)\n-    x_tri = torch.tensor(x, device='cuda')\n-    y_tri = torch.tensor(y, device='cuda')\n-\n-    kernel[(1, 1, 1)](x_tri, y_tri)\n-    y_ref = np.sum(x, axis=1, keepdims=True)\n-\n-    np.testing.assert_allclose(y_ref, y_tri.cpu().numpy(), rtol=0.01, atol=1e-3)\n-\n-\n-def test_sum_kernel():\n-\n-    @triton.jit\n-    def sum_kernel(\n-        x_ptr,\n-        y_ptr,\n-        STRIDE: tl.constexpr,\n-        BLOCK_SIZE: tl.constexpr\n-    ):\n-        arange = tl.arange(0, BLOCK_SIZE)\n-        off = arange[:, None] * STRIDE + arange[None, :]\n-        x_val = tl.load(x_ptr + off)\n-\n-        # This 2D reduction doesn't work\n-        x_sum = tl.sum(x_val, axis=1)\n-        x_sum = tl.sum(x_sum, axis=0)\n-\n-        # This 1D reduction works\n-        #x_sum = tl.sum(tl.view(x_val, (BLOCK_SIZE*BLOCK_SIZE,)), axis=0)\n+    rs = RandomState(17)\n+    x = rs.randint(0, 4, (M, N)).astype('int32')\n+    x = (x.view('uint32') & np.uint32(0xffffe000)).view('int32')\n \n-        tl.store(y_ptr, x_sum)\n+    z = np.zeros((1,)).astype('int32')\n \n-    BLOCK_SIZE = 128\n-    x = np.ones((BLOCK_SIZE, BLOCK_SIZE), dtype=np.int32)\n-    y = np.zeros((1,), dtype=np.int32)\n-    x_tri = torch.tensor(x, device='cuda')\n-    y_tri = torch.tensor(y, device='cuda')\n+    x_tri = torch.tensor(x, device=device)\n+    z_tri = torch.tensor(z, device=device)\n \n-    sum_kernel[(1,)](x_tri, y_tri, x_tri.stride(0), BLOCK_SIZE)\n+    pgm = kernel[(1, 1, 1)](x_tri, z_tri)\n \n-    y_ref = np.sum(x)\n+    z_ref = np.sum(x)\n \n-    np.testing.assert_allclose(y_ref, y_tri.cpu().numpy(), rtol=0.01, atol=1e-3)\n+    np.testing.assert_allclose(z_ref, z_tri.cpu().numpy(), rtol=0.01, atol=1e-3)\n \n \n def test_generic_reduction(device='cuda'):"}]