[{"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 76, "deletions": 1, "changes": 77, "file_content_changes": "@@ -994,7 +994,7 @@ func.func public @if_no_tensor(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32},\n #blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [2, 1], order = [0, 1]}>\n #blocked3 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [16, 2], warpsPerCTA = [2, 1], order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n-  func.func public @reduce_cvt(%arg0: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32) {\n+  func.func public @reduce_cvt1(%arg0: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32) {\n     %cst = arith.constant dense<0> : tensor<1x2xi32, #blocked>\n     %cst_0 = arith.constant dense<2> : tensor<1x2xi32, #blocked>\n     %0 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #blocked1>\n@@ -1017,3 +1017,78 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n     return\n   }\n }\n+\n+// -----\n+\n+// Check if the SimplifyReduceCvt handles convert_layout lifted from the for loop.\n+// CHECK-LABEL: reduce_cvt2\n+// CHECK: tt.reduce\n+// CHECK-NEXT: triton_gpu.convert_layout\n+// CHECK-NOT: triton_gpu.convert_layout\n+#blocked = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>\n+#blocked1 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n+#blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>\n+#blocked3 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n+  func.func public @reduce_cvt2(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}) {\n+    %cst = arith.constant dense<0.000000e+00> : tensor<1x256xf32, #blocked>\n+    %c3136_i32 = arith.constant 3136 : i32\n+    %c256_i32 = arith.constant 256 : i32\n+    %c0_i32 = arith.constant 0 : i32\n+    %cst_0 = arith.constant dense<3.136000e+03> : tensor<1x1xf32, #blocked>\n+    %cst_1 = arith.constant dense<50176> : tensor<1x256xi32, #blocked>\n+    %cst_2 = arith.constant dense<196> : tensor<1x1xi32, #blocked>\n+    %cst_3 = arith.constant dense<196> : tensor<1x256xi32, #blocked>\n+    %cst_4 = arith.constant dense<3136> : tensor<1x256xi32, #blocked>\n+    %cst_5 = arith.constant dense<256> : tensor<1x1xi32, #blocked>\n+    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %1 = tt.make_range {end = 1 : i32, start = 0 : i32} : tensor<1xi32, #blocked1>\n+    %2 = triton_gpu.convert_layout %1 : (tensor<1xi32, #blocked1>) -> tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>\n+    %3 = tt.expand_dims %2 {axis = 1 : i32} : (tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>) -> tensor<1x1xi32, #blocked2>\n+    %4 = triton_gpu.convert_layout %3 : (tensor<1x1xi32, #blocked2>) -> tensor<1x1xi32, #blocked>\n+    %5 = tt.splat %0 : (i32) -> tensor<1x1xi32, #blocked>\n+    %6 = arith.addi %5, %4 : tensor<1x1xi32, #blocked>\n+    %7 = \"triton_gpu.cmpi\"(%6, %cst_5) {predicate = 2 : i64} : (tensor<1x1xi32, #blocked>, tensor<1x1xi32, #blocked>) -> tensor<1x1xi1, #blocked>\n+    %8 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked1>\n+    %9 = triton_gpu.convert_layout %8 : (tensor<256xi32, #blocked1>) -> tensor<256xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>\n+    %10 = tt.expand_dims %9 {axis = 0 : i32} : (tensor<256xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>) -> tensor<1x256xi32, #blocked>\n+    %11 = arith.muli %6, %cst_2 : tensor<1x1xi32, #blocked>\n+    %12 = tt.broadcast %11 : (tensor<1x1xi32, #blocked>) -> tensor<1x256xi32, #blocked>\n+    %13 = tt.splat %arg1 : (!tt.ptr<f32>) -> tensor<1x256x!tt.ptr<f32>, #blocked>\n+    %14 = tt.broadcast %7 : (tensor<1x1xi1, #blocked>) -> tensor<1x256xi1, #blocked>\n+    %15 = scf.for %arg5 = %c0_i32 to %c3136_i32 step %c256_i32 iter_args(%arg6 = %cst) -> (tensor<1x256xf32, #blocked>)  : i32 {\n+      %43 = tt.splat %arg5 : (i32) -> tensor<1x256xi32, #blocked>\n+      %44 = arith.addi %43, %10 : tensor<1x256xi32, #blocked>\n+      %45 = \"triton_gpu.cmpi\"(%44, %cst_4) {predicate = 2 : i64} : (tensor<1x256xi32, #blocked>, tensor<1x256xi32, #blocked>) -> tensor<1x256xi1, #blocked>\n+      %46 = arith.remsi %44, %cst_3 : tensor<1x256xi32, #blocked>\n+      %47 = arith.divsi %44, %cst_3 : tensor<1x256xi32, #blocked>\n+      %48 = arith.addi %46, %12 : tensor<1x256xi32, #blocked>\n+      %49 = arith.muli %47, %cst_1 : tensor<1x256xi32, #blocked>\n+      %50 = arith.addi %48, %49 : tensor<1x256xi32, #blocked>\n+      %51 = tt.addptr %13, %50 : tensor<1x256x!tt.ptr<f32>, #blocked>, tensor<1x256xi32, #blocked>\n+      %52 = arith.andi %45, %14 : tensor<1x256xi1, #blocked>\n+      %53 = triton_gpu.convert_layout %51 : (tensor<1x256x!tt.ptr<f32>, #blocked>) -> tensor<1x256x!tt.ptr<f32>, #blocked3>\n+      %54 = triton_gpu.convert_layout %52 : (tensor<1x256xi1, #blocked>) -> tensor<1x256xi1, #blocked3>\n+      %55 = triton_gpu.convert_layout %cst : (tensor<1x256xf32, #blocked>) -> tensor<1x256xf32, #blocked3>\n+      %56 = tt.load %53, %54, %55 {cache = 1 : i32, evict = 3 : i32, isVolatile = false} : tensor<1x256xf32, #blocked3>\n+      %57 = triton_gpu.convert_layout %56 : (tensor<1x256xf32, #blocked3>) -> tensor<1x256xf32, #blocked>\n+      %58 = arith.addf %arg6, %57 : tensor<1x256xf32, #blocked>\n+      %59 = \"triton_gpu.select\"(%52, %58, %arg6) : (tensor<1x256xi1, #blocked>, tensor<1x256xf32, #blocked>, tensor<1x256xf32, #blocked>) -> tensor<1x256xf32, #blocked>\n+      scf.yield %59 : tensor<1x256xf32, #blocked>\n+    }\n+    %16 = tt.reduce %15 {axis = 1 : i32, redOp = 2 : i32} : tensor<1x256xf32, #blocked> -> tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>\n+    %17 = triton_gpu.convert_layout %16 : (tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>) -> tensor<1xf32, #blocked1>\n+    %18 = triton_gpu.convert_layout %17 : (tensor<1xf32, #blocked1>) -> tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>\n+    %19 = tt.expand_dims %18 {axis = 1 : i32} : (tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>) -> tensor<1x1xf32, #blocked2>\n+    %20 = triton_gpu.convert_layout %19 : (tensor<1x1xf32, #blocked2>) -> tensor<1x1xf32, #blocked>\n+    %21 = arith.divf %20, %cst_0 : tensor<1x1xf32, #blocked>\n+    %22 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<1x1x!tt.ptr<f32>, #blocked>\n+    %23 = tt.addptr %22, %6 : tensor<1x1x!tt.ptr<f32>, #blocked>, tensor<1x1xi32, #blocked>\n+    %24 = triton_gpu.convert_layout %23 : (tensor<1x1x!tt.ptr<f32>, #blocked>) -> tensor<1x1x!tt.ptr<f32>, #blocked>\n+    %25 = triton_gpu.convert_layout %21 : (tensor<1x1xf32, #blocked>) -> tensor<1x1xf32, #blocked>\n+    %26 = triton_gpu.convert_layout %7 : (tensor<1x1xi1, #blocked>) -> tensor<1x1xi1, #blocked>\n+    tt.store %24, %25, %26 {cache = 1 : i32, evict = 1 : i32} : tensor<1x1xf32, #blocked>\n+    return\n+  }\n+}\n+"}]