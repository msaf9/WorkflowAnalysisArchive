[{"filename": "python/triton/compiler.py", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -1385,18 +1385,18 @@ def make_hash(fn, **kwargs):\n \n # def compile(fn, signature: str, device: int = -1, constants=dict(), num_warps: int = 4, num_stages: int = 3, extern_libs=None, configs=None):\n def compile(fn, **kwargs):\n+    capability = torch.cuda.get_device_capability()\n+    capability = capability[0] * 10 + capability[1]\n     # we get the kernel, i.e. the first function generated in the module\n     # if fn is not a JITFunction, then it\n     # has to be a path to a file\n     context = _triton.ir.context()\n     asm = dict()\n     constants = kwargs.get(\"constants\", dict())\n     num_warps = kwargs.get(\"num_warps\", 4)\n-    num_stages = kwargs.get(\"num_stages\", 3)\n+    num_stages = kwargs.get(\"num_stages\", 3 if capability >= 75 else 2)\n     extern_libs = kwargs.get(\"extern_libs\", dict())\n     device = kwargs.get(\"device\", torch.cuda.current_device())\n-    capability = torch.cuda.get_device_capability()\n-    capability = capability[0] * 10 + capability[1]\n     # build compilation stages\n     stages = {\n         \"ast\": (lambda path: fn, None),"}]