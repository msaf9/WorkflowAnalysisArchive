[{"filename": "python/triton/compiler.py", "status": "modified", "additions": 354, "deletions": 209, "changes": 563, "file_content_changes": "@@ -16,7 +16,6 @@\n import warnings\n from collections import namedtuple\n from pathlib import Path\n-from sysconfig import get_paths\n from typing import Any, Callable, Dict, Tuple, Union\n \n import setuptools\n@@ -97,16 +96,17 @@ def __enter__(self):\n         self.prev_defs = self.generator.local_defs.copy()\n         self.generator.local_defs = {}\n         self.insert_block = self.generator.builder.get_insertion_block()\n+        self.insert_point = self.generator.builder.get_insertion_point()\n         return self.liveins, self.insert_block\n \n     def __exit__(self, *args, **kwargs):\n-        self.generator.builder.set_insertion_point_to_end(self.insert_block)\n+        self.generator.builder.restore_insertion_point(self.insert_point)\n         self.generator.lscope = self.liveins\n         self.generator.local_defs = self.prev_defs\n \n \n class CodeGenerator(ast.NodeVisitor):\n-    def __init__(self, context, prototype, gscope, attributes, constants, function_name, module=None, is_kernel=False, function_types=dict()):\n+    def __init__(self, context, prototype, gscope, attributes, constants, function_name, module=None, is_kernel=False, function_types=dict(), debug=False):\n         self.builder = _triton.ir.builder(context)\n         self.module = self.builder.create_module() if module is None else module\n         self.function_ret_types = function_types\n@@ -118,15 +118,20 @@ def __init__(self, context, prototype, gscope, attributes, constants, function_n\n         self.function_name = function_name\n         self.is_kernel = is_kernel\n         self.last_node = None\n+        self.debug = debug\n         self.builtins = {\n             'range': range,\n             'min': triton.language.minimum,\n             'float': float,\n             'int': int,\n-            'print': print,\n+            'print': triton.language.core.device_print,\n             'isinstance': isinstance,\n             'getattr': getattr,\n         }\n+        self.static_functions = [\n+            'static_print', 'static_assert'\n+        ]\n+        self.scf_stack = []\n         # SSA-construction\n         # name => triton.language.tensor\n         self.local_defs: Dict[str, triton.language.tensor] = {}\n@@ -177,6 +182,18 @@ def visit_compound_statement(self, stmts):\n                 break\n         return stmts and isinstance(stmt, ast.Return)\n \n+    def contains_return_op(self, node):\n+        if isinstance(node, ast.Return):\n+            return True\n+        elif isinstance(node, ast.If):\n+            pred = lambda s: self.contains_return_op(s)\n+            ret = any(pred(s) for s in node.body)\n+            if node.orelse:\n+                ret = ret or any(pred(s) for s in node.orelse)\n+            return ret\n+        else:\n+            return False\n+\n     def visit_Module(self, node):\n         ast.NodeVisitor.generic_visit(self, node)\n \n@@ -189,18 +206,25 @@ def visit_List(self, node):\n     # By design, only non-kernel functions can return\n     def visit_Return(self, node):\n         ret_value = self.visit(node.value)\n+        # ret_block = self.builder.create_block()\n+        # post_ret_block = self.builder.create_block()\n+        # self.builder.create_branch(ret_block)\n+        # self.builder.set_insertion_point_to_end(ret_block)\n         if ret_value is None:\n             self.builder.ret([])\n-            return None\n-        if isinstance(ret_value, tuple):\n+            ret_ty = None\n+        elif isinstance(ret_value, tuple):\n             ret_values = [triton.language.core._to_tensor(v, self.builder) for v in ret_value]\n             ret_types = [v.type for v in ret_values]\n             self.builder.ret([v.handle for v in ret_values])\n-            return tuple(ret_types)\n+            ret_ty = tuple(ret_types)\n         else:\n             ret = triton.language.core._to_tensor(ret_value, self.builder)\n             self.builder.ret([ret.handle])\n-            return ret.type\n+            ret_ty = ret.type\n+        # self.builder.create_branch(post_ret_block)\n+        # self.builder.set_insertion_point_to_end(post_ret_block)\n+        return ret_ty\n \n     def visit_FunctionDef(self, node):\n         arg_names, kwarg_names = self.visit(node.args)\n@@ -350,81 +374,126 @@ def visit_BinOp(self, node):\n         else:\n             return getattr(lhs, fn)(rhs)\n \n+    def visit_then_else_blocks(self, node, liveins, then_block, else_block):\n+        # then block\n+        self.builder.set_insertion_point_to_start(then_block)\n+        self.visit_compound_statement(node.body)\n+        then_block = self.builder.get_insertion_block()\n+        then_defs = self.local_defs.copy()\n+        # else block\n+        else_defs = {}\n+        if node.orelse:\n+            self.builder.set_insertion_point_to_start(else_block)\n+            self.lscope = liveins.copy()\n+            self.local_defs = {}\n+            self.visit_compound_statement(node.orelse)\n+            else_defs = self.local_defs.copy()\n+            else_block = self.builder.get_insertion_block()\n+\n+        # update block arguments\n+        names = []\n+        ret_types = []\n+        ir_ret_types = []\n+        # variables in livein whose value is updated in `if`\n+        for name in liveins:\n+            # check type\n+            for defs, block_name in [(then_defs, 'then'), (else_defs, 'else')]:\n+                if name in defs:\n+                    assert defs[name].type == liveins[name].type,\\\n+                        f'initial value for `{name}` is of type {liveins[name].type}, '\\\n+                        f'but the {block_name} block redefines it as {defs[name].type}'\n+            if name in then_defs or name in else_defs:\n+                names.append(name)\n+                ret_types.append(then_defs[name].type if name in then_defs else else_defs[name].type)\n+                ir_ret_types.append(then_defs[name].handle.get_type() if name in then_defs else else_defs[name].handle.get_type())\n+            # variable defined in then but not in else\n+            if name in then_defs and name not in else_defs:\n+                else_defs[name] = liveins[name]\n+            # variable defined in else but not in then\n+            if name in else_defs and name not in then_defs:\n+                then_defs[name] = liveins[name]\n+        # variables that are both in then and else but not in liveins\n+        # TODO: could probably be cleaned up\n+        for name in then_defs.keys() & else_defs.keys():\n+            if name in names:\n+                continue\n+            then_ty = then_defs[name].type\n+            else_ty = else_defs[name].type\n+            assert then_ty == else_ty,\\\n+                f'mismatched type for {name} between then block ({then_ty}) '\\\n+                f'and else block ({else_ty})'\n+            names.append(name)\n+            ret_types.append(then_ty)\n+            ir_ret_types.append(then_defs[name].handle.get_type())\n+\n+        return then_defs, else_defs, then_block, else_block, names, ret_types, ir_ret_types\n+\n+    def visit_if_top_level(self, cond, node):\n+        with enter_sub_region(self) as sr:\n+            liveins, ip_block = sr\n+            then_block = self.builder.create_block()\n+            else_block = self.builder.create_block()\n+            # create basic-block after conditional\n+            endif_block = self.builder.create_block()\n+            # create branch\n+            self.builder.set_insertion_point_to_end(ip_block)\n+            self.builder.create_cond_branch(cond.handle, then_block, else_block)\n+            # visit then and else blocks\n+            then_defs, else_defs, then_block, else_block, names, ret_types, ir_ret_types = \\\n+                self.visit_then_else_blocks(node, liveins, then_block, else_block)\n+            # then terminator\n+            self.builder.set_insertion_point_to_end(then_block)\n+            if not then_block.has_terminator():\n+                self.builder.create_branch(endif_block, [then_defs[n].handle for n in names])\n+            # else terminator\n+            self.builder.set_insertion_point_to_end(else_block)\n+            if not else_block.has_terminator():\n+                self.builder.create_branch(endif_block, [else_defs[n].handle for n in names])\n+            for ty in ir_ret_types:\n+                endif_block.add_argument(ty)\n+        # change block\n+        self.builder.set_insertion_point_to_start(endif_block)\n+        # update value\n+        for i, name in enumerate(names):\n+            new_tensor = triton.language.core.tensor(endif_block.arg(i), ret_types[i])\n+            self.set_value(name, new_tensor)\n+\n+    # TODO: refactor\n+    def visit_if_scf(self, cond, node):\n+        with enter_sub_region(self) as sr:\n+            liveins, _ = sr\n+            ip = self.builder.get_insertion_point()\n+            then_block = self.builder.create_block()\n+            else_block = self.builder.create_block() if node.orelse else None\n+            then_defs, else_defs, then_block, else_block, names, ret_types, _ = \\\n+                self.visit_then_else_blocks(node, liveins, then_block, else_block)\n+            # create if op\n+            self.builder.restore_insertion_point(ip)\n+            if_op = self.builder.create_if_op([ty.to_ir(self.builder) for ty in ret_types], cond.handle, True)\n+            then_block.merge_block_before(if_op.get_then_block())\n+            self.builder.set_insertion_point_to_end(if_op.get_then_block())\n+            if len(names) > 0:\n+                self.builder.create_yield_op([then_defs[n].handle for n in names])\n+            if not node.orelse:\n+                else_block = if_op.get_else_block()\n+            else:\n+                else_block.merge_block_before(if_op.get_else_block())\n+            self.builder.set_insertion_point_to_end(if_op.get_else_block())\n+            if len(names) > 0:\n+                self.builder.create_yield_op([else_defs[n].handle for n in names])\n+        # update values\n+        for i, name in enumerate(names):\n+            new_tensor = triton.language.core.tensor(if_op.get_result(i), ret_types[i])\n+            self.set_value(name, new_tensor)\n+\n     def visit_If(self, node):\n         cond = self.visit(node.test)\n         if isinstance(cond, triton.language.tensor):\n             cond = cond.to(triton.language.int1, _builder=self.builder)\n-            with enter_sub_region(self) as sr:\n-                liveins, ip_block = sr\n-                liveins_copy = liveins.copy()\n-                then_block = self.builder.create_block()\n-                self.builder.set_insertion_point_to_start(then_block)\n-                self.visit_compound_statement(node.body)\n-                then_defs = self.local_defs.copy()\n-\n-                # when need an else block when:\n-                # 1. we have an orelse node\n-                #   or\n-                # 2. the then block defines new variable\n-                else_defs = {}\n-                if then_defs or node.orelse:\n-                    if node.orelse:\n-                        self.lscope = liveins\n-                        self.local_defs = {}\n-                        else_block = self.builder.create_block()\n-                        self.builder.set_insertion_point_to_end(else_block)\n-                        self.visit_compound_statement(node.orelse)\n-                        else_defs = self.local_defs.copy()\n-                    else:\n-                        # collect else_defs\n-                        for name in then_defs:\n-                            if name in liveins:\n-                                assert self.is_triton_tensor(then_defs[name])\n-                                assert self.is_triton_tensor(liveins[name])\n-                                else_defs[name] = liveins[name]\n-                # collect yields\n-                names = []\n-                ret_types = []\n-                for then_name in then_defs:\n-                    for else_name in else_defs:\n-                        if then_name == else_name:\n-                            if then_defs[then_name].type == else_defs[else_name].type:\n-                                names.append(then_name)\n-                                ret_types.append(then_defs[then_name].type)\n-\n-                # defined in else block but not in then block\n-                # to find in parent scope and yield them\n-                for else_name in else_defs:\n-                    if else_name in liveins and else_name not in then_defs:\n-                        if else_defs[else_name].type == liveins[else_name].type:\n-                            names.append(else_name)\n-                            ret_types.append(else_defs[else_name].type)\n-                            then_defs[else_name] = liveins_copy[else_name]\n-                self.builder.set_insertion_point_to_end(ip_block)\n-\n-                if then_defs or node.orelse:  # with else block\n-                    if_op = self.builder.create_if_op([ty.to_ir(self.builder) for ty in ret_types], cond.handle, True)\n-                    then_block.merge_block_before(if_op.get_then_block())\n-                    self.builder.set_insertion_point_to_end(if_op.get_then_block())\n-                    if len(names) > 0:\n-                        self.builder.create_yield_op([then_defs[n].handle for n in names])\n-                    if not node.orelse:\n-                        else_block = if_op.get_else_block()\n-                    else:\n-                        else_block.merge_block_before(if_op.get_else_block())\n-                    self.builder.set_insertion_point_to_end(if_op.get_else_block())\n-                    if len(names) > 0:\n-                        self.builder.create_yield_op([else_defs[n].handle for n in names])\n-                else:  # no else block\n-                    if_op = self.builder.create_if_op([ty.to_ir(self.builder) for ty in ret_types], cond.handle, False)\n-                    then_block.merge_block_before(if_op.get_then_block())\n-\n-            # update values yielded by IfOp\n-            for i, name in enumerate(names):\n-                new_tensor = triton.language.core.tensor(if_op.get_result(i), ret_types[i])\n-                self.lscope[name] = new_tensor\n-                self.local_defs[name] = new_tensor\n-\n+            if self.scf_stack or not self.contains_return_op(node):\n+                self.visit_if_scf(cond, node)\n+            else:\n+                self.visit_if_top_level(cond, node)\n         else:\n             if isinstance(cond, triton.language.constexpr):\n                 cond = cond.value\n@@ -474,12 +543,10 @@ def visit_Compare(self, node):\n \n     def visit_UnaryOp(self, node):\n         op = self.visit(node.operand)\n-        if type(node.op) == ast.Not:\n-            assert isinstance(op, triton.language.constexpr), \"`not` only supported for constexpr at the moment\"\n-            return triton.language.constexpr(not op)\n         fn = {\n             ast.USub: '__neg__',\n             ast.UAdd: '__pos__',\n+            ast.Not: '__not__',\n             ast.Invert: '__invert__',\n         }[type(node.op)]\n         if self.is_triton_tensor(op):\n@@ -490,54 +557,65 @@ def visit_While(self, node):\n         with enter_sub_region(self) as sr:\n             liveins, insert_block = sr\n \n-            # condition (the before region)\n-            cond_block = self.builder.create_block()\n-            self.builder.set_insertion_point_to_start(cond_block)\n-            cond = self.visit(node.test)\n-\n             # loop body (the after region)\n-            loop_block = self.builder.create_block()\n-            self.builder.set_insertion_point_to_start(loop_block)\n+            # loop_block = self.builder.create_block()\n+            dummy = self.builder.create_block()\n+            self.builder.set_insertion_point_to_start(dummy)\n+            self.scf_stack.append(node)\n             self.visit_compound_statement(node.body)\n+            self.scf_stack.pop()\n             loop_defs = self.local_defs\n \n             # collect loop-carried values\n             names = []\n             ret_types = []\n             init_args = []\n-            yields = []\n             for name in loop_defs:\n                 if name in liveins:\n                     # We should not def new constexpr\n                     assert self.is_triton_tensor(loop_defs[name])\n                     assert self.is_triton_tensor(liveins[name])\n-                    if loop_defs[name].type == liveins[name].type:\n-                        # these are loop-carried values\n-                        names.append(name)\n-                        ret_types.append(loop_defs[name].type)\n-                        init_args.append(liveins[name])\n-                        yields.append(loop_defs[name])\n+                    assert loop_defs[name].type == liveins[name].type\n+                    # these are loop-carried values\n+                    names.append(name)\n+                    ret_types.append(loop_defs[name].type)\n+                    init_args.append(liveins[name])\n \n             self.builder.set_insertion_point_to_end(insert_block)\n             while_op = self.builder.create_while_op([ty.to_ir(self.builder) for ty in ret_types],\n                                                     [arg.handle for arg in init_args])\n             # merge the condition region\n             before_block = self.builder.create_block_with_parent(while_op.get_before(),\n                                                                  [ty.to_ir(self.builder) for ty in ret_types])\n-            cond_block.merge_block_before(before_block)\n+            self.builder.set_insertion_point_to_start(before_block)\n+            for i, name in enumerate(names):\n+                self.lscope[name] = triton.language.core.tensor(before_block.arg(i), ret_types[i])\n+                self.local_defs[name] = self.lscope[name]\n+            cond = self.visit(node.test)\n             self.builder.set_insertion_point_to_end(before_block)\n             # create ConditionOp: e.g., scf.condition(%cond) %arg0, %arg1, ...\n             self.builder.create_condition_op(cond.handle, [before_block.arg(i) for i in range(len(init_args))])\n             # merge the loop body\n             after_block = self.builder.create_block_with_parent(while_op.get_after(),\n                                                                 [ty.to_ir(self.builder) for ty in ret_types])\n-            loop_block.merge_block_before(after_block)\n-            self.builder.set_insertion_point_to_end(after_block)\n+\n+            # generate loop body\n+            self.builder.set_insertion_point_to_start(after_block)\n+            for i, name in enumerate(names):\n+                self.lscope[name] = triton.language.core.tensor(after_block.arg(i), ret_types[i])\n+                self.local_defs[name] = self.lscope[name]\n+            self.scf_stack.append(node)\n+            self.visit_compound_statement(node.body)\n+            self.scf_stack.pop()\n+            loop_defs = self.local_defs\n+            yields = []\n+            for name in loop_defs:\n+                if name in liveins:\n+                    yields.append(loop_defs[name])\n             self.builder.create_yield_op([y.handle for y in yields])\n \n         # update global uses in while_op\n         for i, name in enumerate(names):\n-            before_block.replace_use_in_block_with(init_args[i].handle, before_block.arg(i))\n             after_block.replace_use_in_block_with(init_args[i].handle, after_block.arg(i))\n \n         # WhileOp defines new values, update the symbol table (lscope, local_defs)\n@@ -562,56 +640,66 @@ def visit_ExtSlice(self, node):\n         return [self.visit(dim) for dim in node.dims]\n \n     def visit_For(self, node):\n-        iterator = self.visit(node.iter.func)\n-        if iterator != self.builtins['range']:\n-            raise RuntimeError('Only `range` iterator currently supported')\n+        IteratorClass = self.visit(node.iter.func)\n+        iter_args = [self.visit(arg) for arg in node.iter.args]\n+        if IteratorClass == triton.language.static_range:\n+            iterator = IteratorClass(*iter_args)\n+            static_range = range(iterator.start.value,\n+                                 iterator.end.value,\n+                                 iterator.step.value)\n+            for i in static_range:\n+                self.lscope[node.target.id] = triton.language.constexpr(i)\n+                self.visit_compound_statement(node.body)\n+                for stmt in node.orelse:\n+                    ast.NodeVisitor.generic_visit(self, stmt)\n+            return\n+\n+        if IteratorClass != self.builtins['range']:\n+            raise RuntimeError('Only `range` and `static_range` iterators are currently supported')\n+\n         # visit iterator arguments\n         # note: only `range` iterator is supported now\n-        iter_args = [self.visit(arg) for arg in node.iter.args]\n         # collect lower bound (lb), upper bound (ub), and step\n         lb = iter_args[0] if len(iter_args) > 1 else self.visit(ast.Num(0))\n         ub = iter_args[1] if len(iter_args) > 1 else self.visit(node.iter.args[0])\n         step = iter_args[2] if len(iter_args) > 2 else self.visit(ast.Num(1))\n-        # static for loops: all iterator arguments are constexpr\n-        if isinstance(lb, triton.language.constexpr) and \\\n-           isinstance(ub, triton.language.constexpr) and \\\n-           isinstance(step, triton.language.constexpr):\n-            sta_range = iterator(lb.value, ub.value, step.value)\n-            static_unrolling = os.environ.get('TRITON_STATIC_LOOP_UNROLLING', False)\n-            if static_unrolling and len(sta_range) <= 10:\n-                for i in sta_range:\n-                    self.lscope[node.target.id] = triton.language.constexpr(i)\n-                    self.visit_compound_statement(node.body)\n-                    for stmt in node.orelse:\n-                        ast.NodeVisitor.generic_visit(self, stmt)\n-                return\n         # handle negative constant step (not supported by scf.for in MLIR)\n         negative_step = False\n         if isinstance(step, triton.language.constexpr) and step.value < 0:\n             step = triton.language.constexpr(-step.value)\n             negative_step = True\n             lb, ub = ub, lb\n+        lb = triton.language.core._to_tensor(lb, self.builder)\n+        ub = triton.language.core._to_tensor(ub, self.builder)\n+        step = triton.language.core._to_tensor(step, self.builder)\n+        # induction variable type\n+        iv_type = triton.language.semantic.integer_promote_impl(lb.dtype, ub.dtype)\n+        iv_type = triton.language.semantic.integer_promote_impl(iv_type, step.dtype)\n+        iv_ir_type = iv_type.to_ir(self.builder)\n         # lb/ub/step might be constexpr, we need to cast them to tensor\n-        lb = triton.language.core._to_tensor(lb, self.builder).handle\n-        ub = triton.language.core._to_tensor(ub, self.builder).handle\n-        step = triton.language.core._to_tensor(step, self.builder).handle\n+        lb = lb.handle\n+        ub = ub.handle\n+        step = step.handle\n         # ForOp can only accept IndexType as lb/ub/step. Cast integer to Index\n         lb = self.builder.create_to_index(lb)\n         ub = self.builder.create_to_index(ub)\n         step = self.builder.create_to_index(step)\n         # Create placeholder for the loop induction variable\n-        iv = self.builder.create_undef(self.builder.get_int32_ty())\n-        self.set_value(node.target.id, triton.language.core.tensor(iv, triton.language.core.int32))\n+        iv = self.builder.create_undef(iv_ir_type)\n+        self.set_value(node.target.id, triton.language.core.tensor(iv, iv_type))\n \n         with enter_sub_region(self) as sr:\n             liveins, insert_block = sr\n+            ip = self.builder.get_insertion_point()\n \n             # create loop body block\n             block = self.builder.create_block()\n             self.builder.set_insertion_point_to_start(block)\n-\n-            # visit loop body\n+            # dry visit loop body\n+            self.scf_stack.append(node)\n             self.visit_compound_statement(node.body)\n+            self.scf_stack.pop()\n+            block.erase()\n \n             # If a variable (name) is defined in both its parent & itself, then it's\n             # a loop-carried variable. (They must be of the same type)\n@@ -622,37 +710,46 @@ def visit_For(self, node):\n                 if name in liveins:\n                     assert self.is_triton_tensor(self.local_defs[name]), f'{name} is not tensor'\n                     assert self.is_triton_tensor(liveins[name])\n-                    if self.local_defs[name].type != liveins[name].type:\n-                        local_value = self.local_defs[name]\n-                        self.local_defs[name] = local_value.to(liveins[name].dtype, _builder=self.builder)\n+                    assert self.local_defs[name].type == liveins[name].type,\\\n+                        f'Loop-carried variable {name} has initial type {liveins[name].type} '\\\n+                        f'but is re-assigned to {self.local_defs[name].type} in loop! '\\\n+                        f'Please make sure that the type stays consistent.'\n+\n                     names.append(name)\n                     init_args.append(triton.language.core._to_tensor(liveins[name], self.builder))\n                     yields.append(triton.language.core._to_tensor(self.local_defs[name], self.builder))\n \n             # create ForOp\n-            self.builder.set_insertion_point_to_end(insert_block)\n+            self.builder.restore_insertion_point(ip)\n             for_op = self.builder.create_for_op(lb, ub, step, [arg.handle for arg in init_args])\n-            block.merge_block_before(for_op.get_body(0))\n \n-            # update induction variable with actual value, and replace all uses\n+            self.scf_stack.append(node)\n             self.builder.set_insertion_point_to_start(for_op.get_body(0))\n-            iv = self.builder.create_index_to_si(for_op.get_induction_var())\n-            if negative_step:\n-                ub_si = self.builder.create_index_to_si(ub)\n-                iv = self.builder.create_sub(ub_si, iv)\n-            self.lscope[node.target.id].handle.replace_all_uses_with(iv)\n-            self.set_value(node.target.id, triton.language.core.tensor(iv, triton.language.core.int32))\n+            for i, name in enumerate(names):\n+                self.set_value(name, triton.language.core.tensor(for_op.get_body(0).arg(i + 1), yields[i].type))\n+            self.visit_compound_statement(node.body)\n+            self.scf_stack.pop()\n+            yields = []\n+            for name in self.local_defs:\n+                if name in liveins:\n+                    yields.append(triton.language.core._to_tensor(self.local_defs[name], self.builder))\n \n             # create YieldOp\n-            self.builder.set_insertion_point_to_end(for_op.get_body(0))\n             if len(yields) > 0:\n                 self.builder.create_yield_op([y.handle for y in yields])\n             for_op_region = for_op.get_body(0).get_parent()\n             assert for_op_region.size() == 1, \"We use SCF, so the loop body should only have one block\"\n-            # replace global uses with block arguments\n-            for i, name in enumerate(names):\n-                # arg0 is the induction variable\n-                for_op.get_body(0).replace_use_in_block_with(init_args[i].handle, for_op.get_body(0).arg(i + 1))\n+\n+            # update induction variable with actual value, and replace all uses\n+            self.builder.set_insertion_point_to_start(for_op.get_body(0))\n+            iv = self.builder.create_index_to_si(for_op.get_induction_var())\n+            iv = self.builder.create_int_cast(iv, iv_ir_type, True)\n+            if negative_step:\n+                ub_si = self.builder.create_index_to_si(ub)\n+                ub_si = self.builder.create_int_cast(ub_si, iv_ir_type, True)\n+                iv = self.builder.create_sub(ub_si, iv)\n+            self.lscope[node.target.id].handle.replace_all_uses_with(iv)\n+            self.set_value(node.target.id, triton.language.core.tensor(iv, iv_type))\n \n         # update lscope & local_defs (ForOp defines new values)\n         for i, name in enumerate(names):\n@@ -674,6 +771,14 @@ def visit_Index(self, node):\n     def visit_keyword(self, node):\n         return {node.arg: self.visit(node.value)}\n \n+    def visit_Assert(self, node) -> Any:\n+        if not self.debug:\n+            return\n+        test = self.visit(node.test)\n+        msg = self.visit(node.msg)\n+        # Convert assert to triton's device_assert which happens on the device\n+        return triton.language.core.device_assert(test, msg, _builder=self.builder)\n+\n     def visit_Call(self, node):\n         fn = self.visit(node.func)\n         if isinstance(fn, triton.language.constexpr):\n@@ -682,6 +787,18 @@ def visit_Call(self, node):\n         for keyword in node.keywords:\n             kws.update(self.visit(keyword))\n         args = [self.visit(arg) for arg in node.args]\n+        if fn.__name__ == \"print\":\n+            fn = self.builtins[\"print\"]\n+        elif fn.__name__ == \"device_assert\":\n+            if not self.debug:\n+                return\n+        elif fn.__name__ in self.static_functions:\n+            if fn.__name__ == \"static_print\":\n+                print(*args, **kws)\n+                return\n+            elif fn.__name__ == \"static_assert\":\n+                assert args[0], args[1]\n+                return\n         if isinstance(fn, triton.runtime.JITFunction):\n             from inspect import getcallargs\n             args = getcallargs(fn.fn, *args, **kws)\n@@ -701,7 +818,7 @@ def visit_Call(self, node):\n             if not self.module.has_function(fn_name):\n                 prototype = triton.language.function_type([], arg_types)\n                 gscope = sys.modules[fn.fn.__module__].__dict__\n-                generator = CodeGenerator(self.builder.context, prototype, gscope, attributes, constants, module=self.module, function_name=fn_name, function_types=self.function_ret_types)\n+                generator = CodeGenerator(self.builder.context, prototype, gscope, attributes, constants, module=self.module, function_name=fn_name, function_types=self.function_ret_types, debug=self.debug)\n                 generator.visit(fn.parse())\n                 callee_ret_type = generator.last_ret_type\n                 self.function_ret_types[fn_name] = callee_ret_type\n@@ -832,7 +949,14 @@ def kernel_suffix(signature, specialization):\n # ------------------------------------------------------------------------------\n \n \n-def build_triton_ir(fn, signature, specialization, constants):\n+def parse_mlir_module(path, context):\n+    module = _triton.ir.parse_mlir_module(path, context)\n+    # module takes ownership of the context\n+    module.context = context\n+    return module\n+\n+\n+def build_triton_ir(fn, signature, specialization, constants, debug=False):\n     # canonicalize signature\n     if isinstance(signature, str):\n         signature = {k: v.strip() for k, v in enumerate(signature.split(\",\"))}\n@@ -852,7 +976,7 @@ def build_triton_ir(fn, signature, specialization, constants):\n     arg_types = [str_to_ty(v) for k, v in signature.items() if k not in constants]\n \n     prototype = triton.language.function_type([], arg_types)\n-    generator = CodeGenerator(context, prototype, gscope=gscope, constants=all_constants, function_name=function_name, attributes=new_attrs, is_kernel=True)\n+    generator = CodeGenerator(context, prototype, gscope=gscope, constants=all_constants, function_name=function_name, attributes=new_attrs, is_kernel=True, debug=debug)\n     try:\n         generator.visit(fn.parse())\n     except Exception as e:\n@@ -874,40 +998,42 @@ def optimize_triton_ir(mod):\n     pm.add_canonicalizer_pass()\n     pm.add_cse_pass()\n     pm.add_licm_pass()\n+    pm.add_symbol_dce_pass()\n     pm.run(mod)\n     return mod\n \n \n-def ast_to_ttir(fn, signature, specialization, constants):\n-    mod, _ = build_triton_ir(fn, signature, specialization, constants)\n+def ast_to_ttir(fn, signature, specialization, constants, debug=False):\n+    mod, _ = build_triton_ir(fn, signature, specialization, constants, debug)\n     return optimize_triton_ir(mod)\n \n \n-def ttir_to_ttgir(mod, num_warps, num_stages, compute_capability):\n+def ttir_to_ttgir(mod, num_warps):\n     pm = _triton.ir.pass_manager(mod.context)\n     pm.add_convert_triton_to_tritongpu_pass(num_warps)\n+    pm.run(mod)\n+    return mod\n+\n+\n+def optimize_ttgir(mod, num_stages, compute_capability):\n+    pm = _triton.ir.pass_manager(mod.context)\n     pm.enable_debug()\n-    pm.add_coalesce_pass()\n-    # The combine pass converts blocked layout to mma layout\n-    # for dot ops so that pipeline can get shared memory swizzled correctly.\n-    pm.add_tritongpu_combine_pass(compute_capability)\n+    pm.add_tritongpu_coalesce_pass()\n+    pm.add_tritongpu_accelerate_matmul_pass(compute_capability)\n+    pm.add_tritongpu_remove_layout_conversions_pass()\n+    pm.add_tritongpu_fuse_transpositions_pass()\n     pm.add_tritongpu_pipeline_pass(num_stages)\n-    # Prefetch must be done after pipeline pass because pipeline pass\n-    # extracts slices from the original tensor.\n     pm.add_tritongpu_prefetch_pass()\n-    pm.add_canonicalizer_pass()\n-    pm.add_cse_pass()\n-    pm.add_tritongpu_combine_pass(compute_capability)\n-    pm.add_licm_pass()\n-    pm.add_tritongpu_combine_pass(compute_capability)\n+    pm.add_tritongpu_fuse_transpositions_pass()\n+    pm.add_tritongpu_remove_layout_conversions_pass()\n+    pm.add_tritongpu_decompose_conversions_pass()\n     if compute_capability // 10 == 7:\n         # The update_mma_for_volta pass helps to compute some information for MMA encoding specifically for MMAv1\n+        # NOTE this pass should be placed after all the passes those modifies mma layout\n         pm.add_tritongpu_update_mma_for_volta_pass()\n-    pm.add_cse_pass()\n-    pm.add_tritongpu_decompose_conversions_pass()\n+    pm.add_tritongpu_reorder_instructions_pass()\n     pm.add_cse_pass()\n     pm.add_symbol_dce_pass()\n-    pm.add_tritongpu_reorder_instructions_pass()\n     pm.run(mod)\n     return mod\n \n@@ -980,15 +1106,14 @@ def ptx_get_version(cuda_version) -> int:\n \n \n def path_to_ptxas():\n-    prefixes = [\n+    base_dir = os.path.dirname(__file__)\n+    paths = [\n         os.environ.get(\"TRITON_PTXAS_PATH\", \"\"),\n-        \"\",\n-        \"/usr\",\n-        os.environ.get('CUDA_PATH', default_cuda_dir())\n+        os.path.join(base_dir, \"third_party\", \"cuda\", \"bin\", \"ptxas\")\n     ]\n-    for prefix in prefixes:\n-        ptxas = os.path.join(prefix, \"bin\", \"ptxas\")\n-        if os.path.exists(ptxas):\n+\n+    for ptxas in paths:\n+        if os.path.exists(ptxas) and os.path.isfile(ptxas):\n             result = subprocess.check_output([ptxas, \"--version\"], stderr=subprocess.STDOUT)\n             if result is not None:\n                 version = re.search(r\".*release (\\d+\\.\\d+).*\", result.decode(\"utf-8\"), flags=re.MULTILINE)\n@@ -1093,7 +1218,7 @@ def format_of(ty):\n \n #define CUDA_CHECK(ans) {{ gpuAssert((ans), __FILE__, __LINE__); }}\n \n-void _launch(int gridX, int gridY, int gridZ, int num_warps, int shared_memory, CUstream stream, CUfunction function, {arg_decls}) {{\n+static void _launch(int gridX, int gridY, int gridZ, int num_warps, int shared_memory, CUstream stream, CUfunction function, {arg_decls}) {{\n   void *params[] = {{ {', '.join(f\"&arg{i}\" for i in signature.keys() if i not in constants)} }};\n   if(gridX*gridY*gridZ > 0){{\n     CUDA_CHECK(cuLaunchKernel(function, gridX, gridY, gridZ, 32*num_warps, 1, 1, shared_memory, stream, params, 0));\n@@ -1129,15 +1254,16 @@ def format_of(ty):\n       return ptr_info;\n     }}\n     ptr_info.dev_ptr = PyLong_AsUnsignedLongLong(ret);\n-    unsigned attr;\n-    CUresult status =\n-        cuPointerGetAttribute(&attr, CU_POINTER_ATTRIBUTE_MEMORY_TYPE, ptr_info.dev_ptr);\n-    if (!(attr == CU_MEMORYTYPE_DEVICE || attr == CU_MEMORYTYPE_UNIFIED) ||\n-        !(status == CUDA_SUCCESS)) {{\n+    if(!ptr_info.dev_ptr)\n+      return ptr_info;\n+    uint64_t dev_ptr;\n+    int status = cuPointerGetAttribute(&dev_ptr, CU_POINTER_ATTRIBUTE_DEVICE_POINTER, ptr_info.dev_ptr);\n+    if (status == CUDA_ERROR_INVALID_VALUE) {{\n         PyErr_Format(PyExc_ValueError,\n                      \"Pointer argument (at %d) cannot be accessed from Triton (cpu tensor?)\", idx);\n         ptr_info.valid = false;\n     }}\n+    ptr_info.dev_ptr = dev_ptr;\n     return ptr_info;\n   }}\n   PyErr_SetString(PyExc_TypeError, \"Pointer argument must be either uint64 or have data_ptr method\");\n@@ -1153,16 +1279,13 @@ def format_of(ty):\n   PyObject *launch_enter_hook = NULL;\n   PyObject *launch_exit_hook = NULL;\n   PyObject *compiled_kernel = NULL;\n-  PyObject *hook_ret = NULL;\n   {' '.join([f\"{_extracted_type(ty)} _arg{i}; \" for i, ty in signature.items()])}\n   if(!PyArg_ParseTuple(args, \\\"{format}\\\", &gridX, &gridY, &gridZ, &num_warps, &shared_memory, &_stream, &_function, &launch_enter_hook, &launch_exit_hook, &compiled_kernel, {', '.join(f\"&_arg{i}\" for i, ty in signature.items())})) {{\n     return NULL;\n   }}\n \n   if (launch_enter_hook != Py_None) {{\n-    PyObject *new_args = PyTuple_Pack(1, compiled_kernel);\n-    hook_ret = PyObject_CallObject(launch_enter_hook, new_args);\n-    Py_DECREF(new_args);\n+    PyObject_CallObject(launch_enter_hook, args);\n   }}\n \n \n@@ -1171,19 +1294,9 @@ def format_of(ty):\n   _launch(gridX, gridY, gridZ, num_warps, shared_memory, (CUstream)_stream, (CUfunction)_function, {', '.join(f\"ptr_info{i}.dev_ptr\" if ty[0]==\"*\" else f\"_arg{i}\"for i, ty in signature.items())});\n \n   if (launch_exit_hook != Py_None) {{\n-    PyObject *new_args = NULL;\n-    if (hook_ret) {{\n-        new_args = PyTuple_Pack(2, compiled_kernel, hook_ret);\n-    }} else {{\n-        new_args = PyTuple_Pack(1, compiled_kernel);\n-    }}\n-    hook_ret = PyObject_CallObject(launch_exit_hook, new_args);\n-    Py_DECREF(new_args);\n+    PyObject_CallObject(launch_exit_hook, args);\n   }}\n \n-  if (hook_ret) {{\n-      Py_DECREF(hook_ret);\n-  }}\n   if(PyErr_Occurred()) {{\n     return NULL;\n   }}\n@@ -1199,13 +1312,13 @@ def format_of(ty):\n \n static struct PyModuleDef ModuleDef = {{\n   PyModuleDef_HEAD_INIT,\n-  \\\"launcher\\\",\n+  \\\"__triton_launcher\\\",\n   NULL, //documentation\n   -1, //size\n   ModuleMethods\n }};\n \n-PyMODINIT_FUNC PyInit_launcher(void) {{\n+PyMODINIT_FUNC PyInit___triton_launcher(void) {{\n   PyObject *m = PyModule_Create(&ModuleDef);\n   if(m == NULL) {{\n     return NULL;\n@@ -1222,11 +1335,6 @@ def default_cache_dir():\n     return os.path.join(os.environ[\"HOME\"], \".triton\", \"cache\")\n \n \n-def default_cuda_dir():\n-    default_dir = \"/usr/local/cuda\"\n-    return os.getenv(\"CUDA_HOME\", default=default_dir)\n-\n-\n class CacheManager:\n \n     def __init__(self, key):\n@@ -1284,8 +1392,15 @@ def quiet():\n \n def _build(name, src, srcdir):\n     cuda_lib_dirs = libcuda_dirs()\n-    cuda_path = os.environ.get('CUDA_PATH', default_cuda_dir())\n+    base_dir = os.path.dirname(__file__)\n+    cuda_path = os.path.join(base_dir, \"third_party\", \"cuda\")\n+\n     cu_include_dir = os.path.join(cuda_path, \"include\")\n+    triton_include_dir = os.path.join(os.path.dirname(__file__), \"include\")\n+    cuda_header = os.path.join(cu_include_dir, \"cuda.h\")\n+    triton_cuda_header = os.path.join(triton_include_dir, \"cuda.h\")\n+    if not os.path.exists(cuda_header) and os.path.exists(triton_cuda_header):\n+        cu_include_dir = triton_include_dir\n     suffix = sysconfig.get_config_var('EXT_SUFFIX')\n     so = os.path.join(srcdir, '{name}{suffix}'.format(name=name, suffix=suffix))\n     # try to avoid setuptools if possible\n@@ -1295,7 +1410,18 @@ def _build(name, src, srcdir):\n         clang = shutil.which(\"clang\")\n         gcc = shutil.which(\"gcc\")\n         cc = gcc if gcc is not None else clang\n-    py_include_dir = get_paths()[\"include\"]\n+        if cc is None:\n+            raise RuntimeError(\"Failed to find C compiler. Please specify via CC environment variable.\")\n+    # This function was renamed and made public in Python 3.10\n+    if hasattr(sysconfig, 'get_default_scheme'):\n+        scheme = sysconfig.get_default_scheme()\n+    else:\n+        scheme = sysconfig._get_default_scheme()\n+    # 'posix_local' is a custom scheme on Debian. However, starting Python 3.10, the default install\n+    # path changes to include 'local'. This change is required to use triton with system-wide python.\n+    if scheme == 'posix_local':\n+        scheme = 'posix_prefix'\n+    py_include_dir = sysconfig.get_paths(scheme=scheme)[\"include\"]\n \n     cc_cmd = [cc, src, \"-O3\", f\"-I{cu_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", \"-lcuda\", \"-o\", so]\n     cc_cmd += [f\"-L{dir}\" for dir in cuda_lib_dirs]\n@@ -1413,14 +1539,14 @@ def make_hash(fn, **kwargs):\n     return hashlib.md5((Path(fn).read_text() + triton.runtime.jit.version_key()).encode(\"utf-8\")).hexdigest()\n \n \n-# - ^\\s*func\\s+ : match the start of the string, any leading whitespace, the keyword func,\n+# - ^\\s*func\\.func\\s+ : match the start of the string, any leading whitespace, the keyword func,\n #    and any following whitespace\n # - (public\\s+)? : optionally match the keyword public and any following whitespace\n # - (@\\w+) : match an @ symbol followed by one or more word characters\n #   (letters, digits, or underscores), and capture it as group 1 (the function name)\n # - (\\((?:%\\w+: \\S+(?: \\{\\S+ = \\S+ : \\S+\\})?(?:, )?)*\\)) : match a pair of parentheses enclosing\n #   zero or more arguments separated by commas, and capture it as group 2 (the argument list)\n-mlir_prototype_pattern = r'^\\s*func\\s+(?:public\\s+)?(@\\w+)(\\((?:%\\w+: \\S+(?: \\{\\S+ = \\S+ : \\S+\\})?(?:, )?)*\\))\\s*\\{\\s*$'\n+mlir_prototype_pattern = r'^\\s*func\\.func\\s+(?:public\\s+)?(@\\w+)(\\((?:%\\w+: \\S+(?: \\{\\S+ = \\S+ : \\S+\\})?(?:, )?)*\\))\\s*\\{\\s*$'\n ptx_prototype_pattern = r\"\\.(?:visible|extern)\\s+\\.(?:entry|func)\\s+(\\w+)\\s*\\(([^)]*)\\)\"\n prototype_pattern = {\n     \"ttir\": mlir_prototype_pattern,\n@@ -1437,7 +1563,22 @@ def make_hash(fn, **kwargs):\n }\n \n \n+def _get_jsonable_constants(constants):\n+    def _is_jsonable(x):\n+        try:\n+            json.dumps(x)\n+            return True\n+        except (TypeError, OverflowError):\n+            return False\n+    serialized_constants = {}\n+    for constant in constants:\n+        if _is_jsonable(constants[constant]):\n+            serialized_constants[constant] = constants[constant]\n+    return serialized_constants\n+\n # def compile(fn, signature: str, device: int = -1, constants=dict(), num_warps: int = 4, num_stages: int = 3, extern_libs=None, configs=None):\n+\n+\n def compile(fn, **kwargs):\n     capability = kwargs.get(\"cc\", None)\n     if capability is None:\n@@ -1453,14 +1594,15 @@ def compile(fn, **kwargs):\n     num_warps = kwargs.get(\"num_warps\", 4)\n     num_stages = kwargs.get(\"num_stages\", 3 if capability >= 75 else 2)\n     extern_libs = kwargs.get(\"extern_libs\", dict())\n+    debug = kwargs.get(\"debug\", False)\n     # build compilation stages\n     stages = {\n         \"ast\": (lambda path: fn, None),\n-        \"ttir\": (lambda path: _triton.ir.parse_mlir_module(path, context),\n-                 lambda src: ast_to_ttir(src, signature, configs[0], constants)),\n-        \"ttgir\": (lambda path: _triton.ir.parse_mlir_module(path, context),\n-                  lambda src: ttir_to_ttgir(src, num_warps, num_stages, capability)),\n-        \"llir\": (lambda path: Path(path).read_bytes(),\n+        \"ttir\": (lambda path: parse_mlir_module(path, context),\n+                 lambda src: ast_to_ttir(src, signature, configs[0], constants, debug)),\n+        \"ttgir\": (lambda path: parse_mlir_module(path, context),\n+                  lambda src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, capability)),\n+        \"llir\": (lambda path: Path(path).read_text(),\n                  lambda src: ttgir_to_llir(src, extern_libs, capability)),\n         \"ptx\": (lambda path: Path(path).read_text(),\n                 lambda src: llir_to_ptx(src, capability)),\n@@ -1510,7 +1652,8 @@ def compile(fn, **kwargs):\n         with open(fn_cache_manager._make_path(f\"{name}.json\")) as f:\n             metadata = json.load(f)\n     else:\n-        metadata = {\"num_warps\": num_warps, \"num_stages\": num_stages, \"ctime\": dict()}\n+        metadata = {\"num_warps\": num_warps, \"num_stages\": num_stages,\n+                    \"constants\": _get_jsonable_constants(constants), \"ctime\": dict(), \"debug\": debug}\n         if ext == \"ptx\":\n             assert \"shared\" in kwargs, \"ptx compilation must provide shared memory size\"\n             metadata[\"shared\"] = kwargs[\"shared\"]\n@@ -1541,7 +1684,7 @@ def compile(fn, **kwargs):\n     # write-back metadata\n     fn_cache_manager.put(json.dumps(metadata), f\"{name}.json\", binary=False)\n     # return handle to compiled kernel\n-    return CompiledKernel(so_path, metadata, asm)\n+    return CompiledKernel(fn, so_path, metadata, asm)\n \n \n class CompiledKernel:\n@@ -1550,17 +1693,19 @@ class CompiledKernel:\n     launch_enter_hook = None\n     launch_exit_hook = None\n \n-    def __init__(self, so_path, metadata, asm):\n+    def __init__(self, fn, so_path, metadata, asm):\n         # initialize launcher\n         import importlib.util\n-        spec = importlib.util.spec_from_file_location(\"launcher\", so_path)\n+        spec = importlib.util.spec_from_file_location(\"__triton_launcher\", so_path)\n         mod = importlib.util.module_from_spec(spec)\n+        self.fn = fn\n         spec.loader.exec_module(mod)\n         self.c_wrapper = getattr(mod, \"launch\")\n         # initialize metadata\n         self.shared = metadata[\"shared\"]\n         self.num_warps = metadata[\"num_warps\"]\n         self.num_stages = metadata[\"num_stages\"]\n+        self.constants = metadata[\"constants\"]\n         # initialize asm dict\n         self.asm = asm\n         # binaries are lazily initialized"}, {"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 32, "deletions": 32, "changes": 64, "file_content_changes": "@@ -15,7 +15,7 @@\n @triton.jit\n def _fwd_kernel(\n     Q, K, V, sm_scale,\n-    TMP, L, M,  # NOTE: TMP is a scratchpad buffer to work around a compiler bug\n+    L, M,\n     Out,\n     stride_qz, stride_qh, stride_qm, stride_qk,\n     stride_kz, stride_kh, stride_kn, stride_kk,\n@@ -39,51 +39,48 @@ def _fwd_kernel(\n     k_ptrs = K + off_k\n     v_ptrs = V + off_v\n     # initialize pointer to m and l\n-    m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\n-    l_i = tl.zeros([BLOCK_M], dtype=tl.float32)\n+    m_prev = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\n+    l_prev = tl.zeros([BLOCK_M], dtype=tl.float32)\n     acc = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32)\n     # load q: it will stay in SRAM throughout\n     q = tl.load(q_ptrs)\n     # loop over k, v and update accumulator\n     for start_n in range(0, (start_m + 1) * BLOCK_M, BLOCK_N):\n-        # start_n = tl.multiple_of(start_n, BLOCK_N)\n         # -- compute qk ----\n-        k = tl.load(k_ptrs + start_n * stride_kn)\n+        k = tl.load(k_ptrs)\n         qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n         qk += tl.dot(q, tl.trans(k))\n         qk *= sm_scale\n-        qk += tl.where(offs_m[:, None] >= (start_n + offs_n[None, :]), 0, float(\"-inf\"))\n-        # -- compute m_ij, p, l_ij\n-        m_ij = tl.max(qk, 1)\n-        p = tl.exp(qk - m_ij[:, None])\n-        l_ij = tl.sum(p, 1)\n-        # -- update m_i and l_i\n-        m_i_new = tl.maximum(m_i, m_ij)\n-        alpha = tl.exp(m_i - m_i_new)\n-        beta = tl.exp(m_ij - m_i_new)\n-        l_i_new = alpha * l_i + beta * l_ij\n-        # -- update output accumulator --\n-        # scale p\n-        p_scale = beta / l_i_new\n-        p = p * p_scale[:, None]\n-        # scale acc\n-        acc_scale = l_i / l_i_new * alpha\n-        acc = acc * acc_scale[:, None]\n+        qk = tl.where(offs_m[:, None] >= (start_n + offs_n[None, :]), qk, float(\"-inf\"))\n+        # compute new m\n+        m_curr = tl.maximum(tl.max(qk, 1), m_prev)\n+        # correct old l\n+        l_prev *= tl.exp(m_prev - m_curr)\n+        # attention weights\n+        p = tl.exp(qk - m_curr[:, None])\n+        l_curr = tl.sum(p, 1) + l_prev\n+        # rescale operands of matmuls\n+        l_rcp = 1. / l_curr\n+        p *= l_rcp\n+        acc *= (l_prev * l_rcp)[:, None]\n         # update acc\n-        v = tl.load(v_ptrs + start_n * stride_vk)\n         p = p.to(tl.float16)\n+        v = tl.load(v_ptrs)\n         acc += tl.dot(p, v)\n         # update m_i and l_i\n-        l_i = l_i_new\n-        m_i = m_i_new\n+        l_prev = l_curr\n+        m_prev = m_curr\n+        # update pointers\n+        k_ptrs += BLOCK_N * stride_kn\n+        v_ptrs += BLOCK_N * stride_vk\n     # rematerialize offsets to save registers\n     start_m = tl.program_id(0)\n     offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M)\n     # write back l and m\n     l_ptrs = L + off_hz * N_CTX + offs_m\n     m_ptrs = M + off_hz * N_CTX + offs_m\n-    tl.store(l_ptrs, l_i)\n-    tl.store(m_ptrs, m_i)\n+    tl.store(l_ptrs, l_prev)\n+    tl.store(m_ptrs, m_prev)\n     # initialize pointers to output\n     offs_n = tl.arange(0, BLOCK_DMODEL)\n     off_o = off_hz * stride_oh + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n@@ -209,14 +206,13 @@ def forward(ctx, q, k, v, sm_scale):\n         assert Lk in {16, 32, 64, 128}\n         o = torch.empty_like(q)\n         grid = (triton.cdiv(q.shape[2], BLOCK), q.shape[0] * q.shape[1], 1)\n-        tmp = torch.empty((q.shape[0] * q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32)\n         L = torch.empty((q.shape[0] * q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32)\n         m = torch.empty((q.shape[0] * q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32)\n         num_warps = 4 if Lk <= 64 else 8\n \n         _fwd_kernel[grid](\n             q, k, v, sm_scale,\n-            tmp, L, m,\n+            L, m,\n             o,\n             q.stride(0), q.stride(1), q.stride(2), q.stride(3),\n             k.stride(0), k.stride(1), k.stride(2), k.stride(3),\n@@ -227,6 +223,7 @@ def forward(ctx, q, k, v, sm_scale):\n             BLOCK_DMODEL=Lk, num_warps=num_warps,\n             num_stages=2,\n         )\n+        # print(h.asm[\"ttgir\"])\n \n         ctx.save_for_backward(q, k, v, o, L, m)\n         ctx.grid = grid\n@@ -264,6 +261,7 @@ def backward(ctx, do):\n             BLOCK_DMODEL=ctx.BLOCK_DMODEL, num_warps=8,\n             num_stages=1,\n         )\n+        # print(h.asm[\"ttgir\"])\n         return dq, dk, dv, None\n \n \n@@ -316,15 +314,15 @@ def test_op(Z, H, N_CTX, D_HEAD, dtype=torch.float16):\n # vary seq length for fixed head and batch=4\n configs = [triton.testing.Benchmark(\n     x_names=['N_CTX'],\n-    x_vals=[2**i for i in range(10, 15)],\n+    x_vals=[2**i for i in range(10, 14)],\n     line_arg='provider',\n     line_vals=['triton'] + (['flash'] if HAS_FLASH else []),\n     line_names=['Triton'] + (['Flash'] if HAS_FLASH else []),\n     styles=[('red', '-'), ('blue', '-')],\n     ylabel='ms',\n     plot_name=f'fused-attention-batch{BATCH}-head{N_HEADS}-d{D_HEAD}-{mode}',\n     args={'H': N_HEADS, 'BATCH': BATCH, 'D_HEAD': D_HEAD, 'dtype': torch.float16, 'mode': mode}\n-) for mode in ['fwd']]\n+) for mode in ['fwd', 'bwd']]\n \n \n @triton.testing.perf_report(configs)\n@@ -357,4 +355,6 @@ def bench_flash_attention(BATCH, H, N_CTX, D_HEAD, mode, provider, dtype=torch.f\n         ms = triton.testing.do_bench(fn, percentiles=None, warmup=warmup, rep=rep)\n         return ms\n \n-# bench_flash_attention.run(save_path='.', print_data=True)\n+\n+# only works on post-Ampere GPUs right now\n+bench_flash_attention.run(save_path='.', print_data=True)"}]