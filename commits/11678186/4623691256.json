[{"filename": "python/triton/compiler/compiler.py", "status": "modified", "additions": 38, "deletions": 22, "changes": 60, "file_content_changes": "@@ -17,7 +17,7 @@\n import triton._C.libtriton.triton as _triton\n # TODO: runtime.errors\n from ..runtime.autotuner import OutOfResources\n-from ..runtime.cache import CacheManager\n+from ..runtime.cache import get_cache_manager\n from ..runtime.driver import get_cuda_utils, get_hip_utils\n from ..tools.disasm import extract\n from .code_generator import ast_to_ttir\n@@ -410,7 +410,7 @@ def compile(fn, **kwargs):\n     # cache manager\n     so_path = make_stub(name, signature, constants)\n     # create cache manager\n-    fn_cache_manager = CacheManager(make_hash(fn, **kwargs))\n+    fn_cache_manager = get_cache_manager(make_hash(fn, **kwargs))\n     # determine name and extension type of provided function\n     if isinstance(fn, triton.runtime.JITFunction):\n         name, ext = fn.__name__, \"ast\"\n@@ -419,14 +419,22 @@ def compile(fn, **kwargs):\n \n     # load metadata if any\n     metadata = None\n-    if fn_cache_manager.has_file(f'{name}.json'):\n-        with open(fn_cache_manager.make_path(f\"{name}.json\")) as f:\n+    metadata_filename = f\"{name}.json\"\n+\n+    # The group is addressed by the metadata\n+    metadata_group = fn_cache_manager.get_group(\n+        metadata_filename\n+    ) or {}\n+\n+    metadata_path = metadata_group.get(metadata_filename)\n+\n+    if metadata_path is not None:\n+        with open(metadata_path) as f:\n             metadata = json.load(f)\n     else:\n         metadata = {\"num_warps\": num_warps,\n                     \"num_stages\": num_stages,\n                     \"constants\": _get_jsonable_constants(constants),\n-                    \"ctime\": dict(),\n                     \"debug\": debug}\n         if ext == \"ptx\":\n             assert \"shared\" in kwargs, \"ptx compilation must provide shared memory size\"\n@@ -437,25 +445,30 @@ def compile(fn, **kwargs):\n     module = fn\n     # run compilation pipeline  and populate metadata\n     for ir, (parse, compile_kernel) in list(stages.items())[first_stage:]:\n-        path = fn_cache_manager.make_path(f\"{name}.{ir}\")\n+        ir_filename = f\"{name}.{ir}\"\n+        \n         if ir == ext:\n             next_module = parse(fn)\n-        elif os.path.exists(path) and\\\n-                ir in metadata[\"ctime\"] and\\\n-                os.path.getctime(path) == metadata[\"ctime\"][ir]:\n-            if ir == \"amdgcn\":\n-                next_module = (parse(path), parse(fn_cache_manager.make_path(f\"{name}.hsaco_path\")))\n-            else:\n-                next_module = parse(path)\n         else:\n-            next_module = compile_kernel(module)\n-            if ir == \"amdgcn\":\n-                fn_cache_manager.put(next_module[0], f\"{name}.{ir}\")\n-                fn_cache_manager.put(next_module[1], f\"{name}.hsaco_path\")\n+            path = metadata_group.get(ir_filename)\n+            if path is None:\n+                next_module = compile_kernel(module)\n+                if ir == \"amdgcn\":\n+                    extra_file_name = f\"{name}.hsaco_path\"\n+                    metadata_group[ir_filename] = fn_cache_manager.put(next_module[0], ir_filename)\n+                    metadata_group[extra_file_name] = fn_cache_manager.put(next_module[1], extra_file_name)\n+                else:\n+                    metadata_group[ir_filename] = fn_cache_manager.put(next_module[0], ir_filename)\n+                    fn_cache_manager.put(next_module, ir_filename)\n             else:\n-                fn_cache_manager.put(next_module, f\"{name}.{ir}\")\n-        if os.path.exists(path):\n-            metadata[\"ctime\"][ir] = os.path.getctime(path)\n+                if ir == \"amdgcn\":\n+                    extra_file_name = f\"{name}.hsaco_path\"\n+                    hasco_path = metadata_group.get(extra_file_name)\n+                    assert hasco_path is not None, \"Expected to have hsaco_path in metadata when we have the amdgcn\"\n+                    next_module = (parse(path), parse(hasco_path))\n+                else:\n+                    next_module = parse(path)\n+\n         if ir == \"cubin\":\n             asm[ir] = next_module\n         elif ir == \"amdgcn\":\n@@ -470,8 +483,11 @@ def compile(fn, **kwargs):\n             metadata[\"name\"] = get_kernel_name(next_module[0], pattern='.globl')\n             asm[\"hsaco_path\"] = next_module[1]\n         module = next_module\n-    # write-back metadata\n-    fn_cache_manager.put(json.dumps(metadata), f\"{name}.json\", binary=False)\n+    # write-back metadata, if it didn't come from the cache\n+    if metadata_path is None:\n+        metadata_group[metadata_filename] = fn_cache_manager.put(json.dumps(metadata), metadata_filename, binary=False)\n+        fn_cache_manager.put_group(metadata_filename, metadata_group)\n+\n     # return handle to compiled kernel\n     return CompiledKernel(fn, so_path, metadata, asm)\n "}, {"filename": "python/triton/runtime/cache.py", "status": "modified", "additions": 53, "deletions": 9, "changes": 62, "file_content_changes": "@@ -3,27 +3,35 @@\n from abc import ABC, abstractmethod\n \n from filelock import FileLock\n+from typing import Dict, Optional\n \n+def default_cache_dir():\n+    return os.path.join(Path.home(), \".triton\", \"cache\")\n \n class CacheManager(ABC):\n     def __init__(self, key):\n        pass\n \n     @abstractmethod\n-    def make_path(self, filename) ->  Path:\n+    def get_file(self, filename) ->  Optional[str]:\n         pass\n \n     @abstractmethod\n     def has_file(self, filename) -> bool:\n         pass\n \n     @abstractmethod\n-    def put(self, data, filename, binary=True):\n-        False\n+    def put(self, data, filename, binary=True) -> str:\n+        pass\n \n+    @abstractmethod\n+    def get_group(self, filename: str) -> Optional[Dict[str, str]]:\n+        pass\n+\n+    @abstractmethod\n+    def put_group(self, filename: str, group: Dict[str, str]):\n+        pass\n \n-def default_cache_dir():\n-    return os.path.join(Path.home(), \".triton\", \"cache\")\n \n class FileCacheManager(CacheManager):\n     def __init__(self, key):\n@@ -36,28 +44,64 @@ def __init__(self, key):\n             self.lock_path = os.path.join(self.cache_dir, \"lock\")\n             os.makedirs(self.cache_dir, exist_ok=True)\n \n-    def make_path(self, filename) -> Path:\n+    def _make_path(self, filename) -> str:\n         return os.path.join(self.cache_dir, filename)\n \n     def has_file(self, filename):\n         if not self.cache_dir:\n             return False\n-        return os.path.exists(self.make_path(filename))\n+        return os.path.exists(self._make_path(filename))\n+\n+    def get_file(self, filename) -> Optional[str]:\n+        if self.has_file(filename):\n+            return self._make_path(filename)\n+        else:\n+            return None\n+\n+    def get_group(self, filename: str) -> Optional[Dict[str, str]]:\n+        grp_filename = f\"__grp__{filename}\"\n+        if not self.has_file(grp_filename):\n+            return None\n+        grp_filepath = self._make_path(grp_filename)\n+        with open(grp_filepath) as f:\n+            grp_data = json.load(f)\n+        child_paths = grp_data.get(\"child_paths\", None)\n+        # Invalid group data.\n+        if child_paths is None:\n+            return None\n+        result = {}\n+        for c in child_paths:\n+            p = self._make_path(c)\n+            if not os.path.exists(p):\n+                raise Exception(f\"Group file {p} does not exist from group {grp_filename} \")\n+            result[c] = p\n+        return result\n+\n+    # Note a group of pushed files as being part of a group\n+    def put_group(self, filename: str, group: Dict[str, str]):\n+        if not self.cache_dir:\n+            return\n+        grp_contents = json.dumps({\"child_paths\": sorted(list(group.keys()))})\n+        grp_filename = f\"__grp__{filename}\"\n+        return self.put(grp_contents, grp_filename, binary = False)\n \n-    def put(self, data, filename, binary=True):\n+    def put(self, data, filename, binary=True) -> str:\n         if not self.cache_dir:\n             return\n         binary = isinstance(data, bytes)\n         if not binary:\n             data = str(data)\n         assert self.lock_path is not None\n-        filepath = self.make_path(filename)\n+        filepath = self._make_path(filename)\n         with FileLock(self.lock_path):\n             # use tempfile to be robust against program interruptions\n             mode = \"wb\" if binary else \"w\"\n             with open(filepath + \".tmp\", mode) as f:\n                 f.write(data)\n             os.rename(filepath + \".tmp\", filepath)\n+        return filepath\n+    \n+\n \n __cache_cls = FileCacheManager\n __cache_cls_nme = \"DEFAULT\""}, {"filename": "python/triton/runtime/driver/cuda.py", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "file_content_changes": "@@ -3,7 +3,7 @@\n import tempfile\n \n from ...common.build import _build\n-from ..cache import CacheManager\n+from ..cache import get_cache_manager\n \n \n def get_cuda_utils():\n@@ -140,18 +140,19 @@ def _generate_src():\n     def __init__(self):\n         src = self._generate_src()\n         key = hashlib.md5(src.encode(\"utf-8\")).hexdigest()\n-        cache = CacheManager(key)\n+        cache = get_cache_manager(key)\n         fname = \"cuda_utils.so\"\n-        if not cache.has_file(fname):\n+        cache_path = cache.get_file(fname)\n+        if cache_path is None:\n             with tempfile.TemporaryDirectory() as tmpdir:\n                 src_path = os.path.join(tmpdir, \"main.c\")\n                 with open(src_path, \"w\") as f:\n                     f.write(src)\n                 so = _build(\"cuda_utils\", src_path, tmpdir)\n                 with open(so, \"rb\") as f:\n-                    cache.put(f.read(), fname, binary=True)\n+                    cache_path = cache.put(f.read(), fname, binary=True)\n         import importlib.util\n-        spec = importlib.util.spec_from_file_location(\"cuda_utils\", cache.make_path(fname))\n+        spec = importlib.util.spec_from_file_location(\"cuda_utils\", cache_path)\n         mod = importlib.util.module_from_spec(spec)\n         spec.loader.exec_module(mod)\n         self.load_binary = mod.load_binary"}, {"filename": "python/triton/runtime/driver/hip.py", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "file_content_changes": "@@ -3,7 +3,7 @@\n import tempfile\n \n from ...common.build import _build\n-from ..cache import CacheManager\n+from ..cache import get_cache_manager\n \n \n def get_hip_utils():\n@@ -139,18 +139,19 @@ def _generate_src(self):\n     def __init__(self):\n         src = self._generate_src()\n         key = hashlib.md5(src.encode(\"utf-8\")).hexdigest()\n-        cache = CacheManager(key)\n+        cache = get_cache_manager(key)\n         fname = \"hip_utils.so\"\n-        if not cache.has_file(fname):\n+        cache_path = cache.get_file(fname)\n+        if cache_path is None:\n             with tempfile.TemporaryDirectory() as tmpdir:\n                 src_path = os.path.join(tmpdir, \"main.c\")\n                 with open(src_path, \"w\") as f:\n                     f.write(src)\n                 so = _build(\"hip_utils\", src_path, tmpdir)\n                 with open(so, \"rb\") as f:\n-                    cache.put(f.read(), fname, binary=True)\n+                    cache_path = cache.put(f.read(), fname, binary=True)\n         import importlib.util\n-        spec = importlib.util.spec_from_file_location(\"hip_utils\", cache.make_path(fname))\n+        spec = importlib.util.spec_from_file_location(\"hip_utils\", cache_path)\n         mod = importlib.util.module_from_spec(spec)\n         spec.loader.exec_module(mod)\n         self.load_binary = mod.load_binary"}]