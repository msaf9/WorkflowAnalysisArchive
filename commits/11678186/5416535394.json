[{"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "file_content_changes": "@@ -74,19 +74,19 @@ class ScanLoweringHelper {\n   // Return the number of elements per thread along axis dim.\n   unsigned getAxisNumElementsPerThreads();\n   // Return the number of elements per thread along non-axis dims.\n-  unsigned getNumParallelElementsPerThread();\n+  unsigned getNonAxisNumElementsPerThread();\n   // Return the number of threads per warp along non-axis dims.\n-  unsigned getNumParrallelThreadsPerWarp();\n+  unsigned getNonAxisNumThreadsPerWarp();\n   // Return the flat numbers of threads computing independent scan results.\n-  unsigned getNumParrallelThreadsPerCTA();\n+  unsigned getNonAxisNumThreadsPerCTA();\n   // Return the number of warps per CTA along axis dim.\n-  unsigned getNumAxisWarps();\n+  unsigned getAxisNumWarps();\n   // Return the number of threads per warp along axis dim.\n   unsigned getAxisNumThreadsPerWarp();\n   // Return the number of blocks along axis dim.\n-  unsigned getNumAxisBlocks();\n+  unsigned getAxisNumBlocks();\n   // Return the number of blocks along non axis dim.\n-  unsigned getNumParallelBlocks();\n+  unsigned getNonAxisNumBlocks();\n   // Return the size of the scratch space needed for scan lowering.\n   unsigned getScratchSizeInBytes();\n "}, {"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -431,7 +431,8 @@ def TT_ReduceReturnOp: TT_Op<\"reduce.return\",\n //\n def TT_ScanOp: TT_Op<\"scan\",\n                        [Pure,\n-                        SameOperandsEncoding,\n+                        SameOperandsAndResultEncoding,\n+                        SameOperandsAndResultElementType,\n                         SingleBlock,\n                         DeclareOpInterfaceMethods<InferTypeOpInterface>]> {\n     let summary = \"Reduction using generic combination algorithm\";"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 11, "deletions": 7, "changes": 18, "file_content_changes": "@@ -121,7 +121,7 @@ unsigned ScanLoweringHelper::getAxisNumElementsPerThreads() {\n   return getEncoding().getSizePerThread()[getAxis()];\n }\n \n-unsigned ScanLoweringHelper::getNumParallelElementsPerThread() {\n+unsigned ScanLoweringHelper::getNonAxisNumElementsPerThread() {\n   SmallVector<unsigned> sizePerThreads(getEncoding().getSizePerThread().begin(),\n                                        getEncoding().getSizePerThread().end());\n   sizePerThreads[getAxis()] = 1;\n@@ -134,26 +134,26 @@ unsigned ScanLoweringHelper::getAxisNumThreadsPerWarp() {\n   return triton::gpu::getThreadsPerWarp(getEncoding())[getAxis()];\n }\n \n-unsigned ScanLoweringHelper::getNumParrallelThreadsPerWarp() {\n+unsigned ScanLoweringHelper::getNonAxisNumThreadsPerWarp() {\n   auto threadsPerWarp = triton::gpu::getThreadsPerWarp(getEncoding());\n   threadsPerWarp[getAxis()] = 1;\n   return product<unsigned>(threadsPerWarp);\n }\n \n // Return the flat numbers of threads computing independent scan results.\n-unsigned ScanLoweringHelper::getNumParrallelThreadsPerCTA() {\n-  unsigned numParallelThreadsPerWarp = getNumParrallelThreadsPerWarp();\n+unsigned ScanLoweringHelper::getNonAxisNumThreadsPerCTA() {\n+  unsigned numParallelThreadsPerWarp = getNonAxisNumThreadsPerWarp();\n   auto warpsPerCTA = triton::gpu::getWarpsPerCTA(getEncoding());\n   warpsPerCTA[getAxis()] = 1;\n   unsigned numParallelWarpsPerCTA = product<unsigned>(warpsPerCTA);\n   return numParallelThreadsPerWarp * numParallelWarpsPerCTA;\n }\n-unsigned ScanLoweringHelper::getNumAxisWarps() {\n+unsigned ScanLoweringHelper::getAxisNumWarps() {\n   auto warpsPerCTA = triton::gpu::getWarpsPerCTA(srcEncoding);\n   return warpsPerCTA[getAxis()];\n }\n \n-unsigned ScanLoweringHelper::getNumAxisBlocks() {\n+unsigned ScanLoweringHelper::getAxisNumBlocks() {\n   auto type = scanOp.getOperand(0).getType().cast<RankedTensorType>();\n   auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding);\n   auto threadsPerWarp = triton::gpu::getThreadsPerWarp(srcEncoding);\n@@ -163,7 +163,7 @@ unsigned ScanLoweringHelper::getNumAxisBlocks() {\n          (sizePerThreads[axis] * threadsPerWarp[axis] * warpsPerCTA[axis]);\n }\n \n-unsigned ScanLoweringHelper::getNumParallelBlocks() {\n+unsigned ScanLoweringHelper::getNonAxisNumBlocks() {\n   auto type = scanOp.getOperand(0).getType().cast<RankedTensorType>();\n   auto sizePerThreads = triton::gpu::getSizePerThread(srcEncoding);\n   auto threadsPerWarp = triton::gpu::getThreadsPerWarp(srcEncoding);\n@@ -180,6 +180,10 @@ unsigned ScanLoweringHelper::getNumParallelBlocks() {\n }\n \n bool ScanLoweringHelper::isSupported() {\n+  // TODO: Support the following cases:\n+  // 1. Scan on the non-fast changing dimension\n+  // 2. Scan on non-blocking encodings\n+  // 3. Scan with multiple operands\n   if (getAxis() != triton::gpu::getOrder(srcEncoding)[0] ||\n       !isa<triton::gpu::BlockedEncodingAttr>(srcEncoding))\n     return false;"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ScanOpToLLVM.cpp", "status": "modified", "additions": 11, "deletions": 12, "changes": 23, "file_content_changes": "@@ -80,8 +80,8 @@ static void warpScan(SmallVector<Value> &srcValues,\n // reduction into shared memory. Each parallel scan and each warp will store its\n // own partial reductions. The shared memory is organized as follow:\n //          -----------------------------------------------------------------\n-// chunk 0: | scan 0 warp 0 | scan 1 warp 0 | scan 0 warp 1 | scan 1 warp 1 |\n-// chunk 1: | scan 0 warp 0 | scan 1 warp 0 | scan 0 warp 1 | scan 1 warp 1 |\n+// chunk 0: | acc[0] warp 0 | acc[1] warp 0 | acc[0] warp 1 | acc[1] warp 1 |\n+// chunk 1: | acc[0] warp 0 | acc[1] warp 0 | acc[0] warp 1 | acc[1] warp 1 |\n static void storeWarpAccumulator(SmallVector<Value> &srcValues,\n                                  ConversionPatternRewriter &rewriter,\n                                  ScanLoweringHelper &helper, Value laneId,\n@@ -90,8 +90,8 @@ static void storeWarpAccumulator(SmallVector<Value> &srcValues,\n   Location loc = helper.getLoc();\n   unsigned scanElementsPerThreads = helper.getAxisNumElementsPerThreads();\n   unsigned scanDim = helper.getAxisNumThreadsPerWarp();\n-  unsigned numParallelLane = helper.getNumParrallelThreadsPerCTA();\n-  unsigned numWarps = helper.getNumAxisWarps();\n+  unsigned numParallelLane = helper.getNonAxisNumThreadsPerCTA();\n+  unsigned numWarps = helper.getAxisNumWarps();\n   unsigned chunkId = 0;\n   for (unsigned j = scanElementsPerThreads - 1; j < srcValues.size();\n        j += scanElementsPerThreads, ++chunkId) {\n@@ -114,19 +114,19 @@ static void AddPartialReduce(SmallVector<Value> &srcValues,\n                              ScanLoweringHelper &helper, Value sharedMemoryPtr,\n                              Value warpId, Value laneId, Value parallelLaneId) {\n   Location loc = helper.getLoc();\n-  unsigned numParallelLane = helper.getNumParrallelThreadsPerCTA();\n-  unsigned numWarps = helper.getNumAxisWarps();\n+  unsigned numParallelLane = helper.getNonAxisNumThreadsPerCTA();\n+  unsigned numWarps = helper.getAxisNumWarps();\n   unsigned scanElementsPerThreads = helper.getAxisNumElementsPerThreads();\n-  unsigned parallelElementsPerThread = helper.getNumParallelElementsPerThread();\n+  unsigned parallelElementsPerThread = helper.getNonAxisNumElementsPerThread();\n   Value maskFirstWarp = icmp_eq(warpId, i32_val(0));\n   Value maskFirstLane = icmp_eq(laneId, i32_val(0));\n   Value maskFirstThread = and_(maskFirstWarp, maskFirstLane);\n   struct Accumulator {\n     Value acc;\n     Value maskedAcc;\n   };\n-  unsigned numScanBlocks = helper.getNumAxisBlocks();\n-  unsigned numParallelBlocks = helper.getNumParallelBlocks();\n+  unsigned numScanBlocks = helper.getAxisNumBlocks();\n+  unsigned numParallelBlocks = helper.getNonAxisNumBlocks();\n   assert(numScanBlocks * numParallelBlocks * parallelElementsPerThread *\n              scanElementsPerThreads ==\n          srcValues.size());\n@@ -251,12 +251,11 @@ ScanOpConversion::getDelinearizedIds(ConversionPatternRewriter &rewriter,\n       linearize(rewriter, loc, multiDimWarpId, warpsPerCTA, order);\n   Value flatIdParallel =\n       add(laneIdParallel,\n-          mul(warpIdParallel, i32_val(helper.getNumParrallelThreadsPerWarp())));\n+          mul(warpIdParallel, i32_val(helper.getNonAxisNumThreadsPerWarp())));\n   return std::make_tuple(laneIdAxis, warpIdAxis, flatIdParallel);\n }\n \n-// Naive lowering of the scan op as a fallback for cases that we don't know\n-// how to generate with warp shuffle ops.\n+// Lowering using warp shuffle operations to do warp level scan.\n LogicalResult\n ScanOpConversion::emitFastScan(triton::ScanOp op, triton::ScanOpAdaptor adaptor,\n                                ConversionPatternRewriter &rewriter) const {"}]