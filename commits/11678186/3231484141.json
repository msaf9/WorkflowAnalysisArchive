[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "file_content_changes": "@@ -2696,7 +2696,7 @@ struct MMA16816ConversionHelper {\n     A = op.a();\n     B = op.b();\n     C = op.c();\n-    D = op.c();\n+    D = op.getResult();\n \n     aTensorTy = A.getType().cast<RankedTensorType>();\n     bTensorTy = B.getType().cast<RankedTensorType>();\n@@ -2755,7 +2755,7 @@ struct MMA16816ConversionHelper {\n       assert(false && \"A's layout is not supported.\");\n     }\n \n-    // step1. Preform loading.\n+    // step1. Perform loading.\n     for (unsigned m = 0; m < numRepM; ++m)\n       for (unsigned k = 0; k < numRepK; ++k)\n         loadFn(2 * m, 2 * k);\n@@ -2805,9 +2805,7 @@ struct MMA16816ConversionHelper {\n         b, std::max(numRepN / 2, 1), numRepK);\n \n     const int fcSize = 4 * numRepM * numRepN;\n-    SmallVector<Value> fc(fcSize);\n-    for (int i = 0; i < fc.size(); i++)\n-      fc[i] = c;\n+    SmallVector<Value> fc(fcSize, c);\n \n     auto callMma = [&](unsigned m, unsigned n, unsigned k) {\n       unsigned colsPerThread = numRepN * 2;"}]