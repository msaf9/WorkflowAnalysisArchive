[{"filename": "lib/Conversion/TritonGPUToLLVM/ReduceOpToLLVM.cpp", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "file_content_changes": "@@ -190,20 +190,17 @@ struct ReduceOpConversion\n     }\n     // The order of the axes for the the threads within the warp\n     auto srcOrd = triton::gpu::getOrder(srcLayout);\n-    // The elements owned by each thread, e.g. [2, 2] means that each thread\n-    // in a warp would own 2x2 elements of the original tensor\n     auto sizePerThread = triton::gpu::getSizePerThread(srcLayout);\n     auto srcShape = srcTy.getShape();\n \n     auto llvmElemTy = getTypeConverter()->convertType(srcTy.getElementType());\n     auto llvmIndexTy = getTypeConverter()->getIndexType();\n     auto elemPtrTy = LLVM::LLVMPointerType::get(llvmElemTy, 3);\n     auto indexPtrTy = LLVM::LLVMPointerType::get(llvmIndexTy, 3);\n-    // The shared memory base address\n+\n     Value smemBase = getSharedMemoryBase(loc, rewriter, op.getOperation());\n     smemBase = bitcast(smemBase, elemPtrTy);\n \n-    // The shape of the shared memory\n     auto smemShape = helper.getScratchConfigBasic();\n     unsigned elems = product<unsigned>(smemShape);\n     Value indexSmemBase = gep(elemPtrTy, smemBase, i32_val(elems));"}]