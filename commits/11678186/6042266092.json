[{"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv1.cpp", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "file_content_changes": "@@ -203,8 +203,8 @@ static Value loadA(Value tensor, const SharedMemoryObject &smemObj,\n   SmallVector<Value> elems;\n   elems.reserve(has.size() * 2);\n   for (auto item : has) { // has is a map, the key should be ordered.\n-    elems.push_back(item.second.first);\n-    elems.push_back(item.second.second);\n+    elems.push_back(bitcast(item.second.first, i32_ty));\n+    elems.push_back(bitcast(item.second.second, i32_ty));\n   }\n \n   Value res = typeConverter->packLLElements(loc, elems, rewriter, resultTy);\n@@ -327,8 +327,8 @@ static Value loadB(Value tensor, const SharedMemoryObject &smemObj,\n \n   SmallVector<Value> elems;\n   for (auto &item : hbs) { // has is a map, the key should be ordered.\n-    elems.push_back(item.second.first);\n-    elems.push_back(item.second.second);\n+    elems.push_back(bitcast(item.second.first, i32_ty));\n+    elems.push_back(bitcast(item.second.second, i32_ty));\n   }\n \n   Value res = typeConverter->packLLElements(loc, elems, rewriter, resultTy);"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TypeConverter.cpp", "status": "modified", "additions": 3, "deletions": 8, "changes": 11, "file_content_changes": "@@ -130,14 +130,9 @@ Type TritonGPUToLLVMTypeConverter::getElementTypeForStruct(\n   auto mmaParent = dotOpLayout.getParent().dyn_cast<MmaEncodingAttr>();\n   if (!mmaParent)\n     return elemTy;\n-  if (mmaParent.isAmpere()) {\n-    int bitwidth = elemTy.getIntOrFloatBitWidth();\n-    assert(bitwidth <= 32);\n-    return IntegerType::get(ctx, 32);\n-  } else {\n-    assert(mmaParent.isVolta());\n-    return vec_ty(elemTy, 2);\n-  }\n+  int bitwidth = elemTy.getIntOrFloatBitWidth();\n+  assert(bitwidth <= 32);\n+  return IntegerType::get(ctx, 32);\n }\n \n Type TritonGPUToLLVMTypeConverter::convertTritonTensorType("}]