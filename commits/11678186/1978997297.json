[{"filename": "python/triton/code_gen.py", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -17,7 +17,6 @@\n \n import torch\n from filelock import FileLock\n-from numpy import isin\n \n import triton\n import triton._C.libtriton.triton as _triton"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 1, "deletions": 7, "changes": 8, "file_content_changes": "@@ -1,11 +1,8 @@\n from __future__ import annotations\n \n-from ctypes import pointer\n from enum import Enum\n from functools import wraps\n-from typing import List, Optional, Tuple\n-\n-from numpy import block, isin\n+from typing import List\n \n import triton\n from . import semantic\n@@ -193,9 +190,6 @@ def to_ir(self, builder: ir.builder) -> ir.type:\n     def __str__(self):\n         return self.name\n \n-    def __repr__(self):\n-        return self.name\n-\n     @property\n     def cache_key_part(self) -> str:\n         \"\"\"See cache_key_part() in triton.cc.\"\"\""}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "file_content_changes": "@@ -234,8 +234,8 @@ def mod(input: tl.tensor,\n     # % int\n     elif scalar_ty.is_int():\n         if scalar_ty.int_signedness != other_scalar_ty.int_signedness:\n-            raise ValueError(\"Cannot mod \" + scalar_ty.__repr__() + \" by \" + other_scalar_ty.__repr__() +\n-                             \" because they have different signedness;\"\n+            raise ValueError(\"Cannot mod \" + scalar_ty.__repr__() + \" by \" + other_scalar_ty.__repr__() + \" \"\n+                             \"because they have different signedness;\"\n                              \"this is unlikely to result in a useful answer. Cast them to the same signedness.\")\n         if scalar_ty.is_int_signed():\n             return tl.tensor(builder.create_srem(input.handle, other.handle), input.dtype)\n@@ -514,8 +514,8 @@ def broadcast_impl_value(lhs: tl.tensor,\n             elif left == right:\n                 ret_shape.append(left)\n             else:\n-                raise ValueError(\"Cannot make_shape_compatible: incompatible dimensions at index \" + str(i) +\n-                                 \": \" + str(left) + \" and \" + str(right))\n+                raise ValueError(\"Cannot make_shape_compatible: incompatible dimensions \"\n+                                 \"at index \" + str(i) + \": \" + str(left) + \" and \" + str(right))\n         if lhs_shape != ret_shape:\n             ret_ty = tl.block_type(lhs_ty.scalar, ret_shape)\n             lhs = tl.tensor(builder.create_broadcast(lhs.handle, ret_shape), ret_ty)\n@@ -546,8 +546,8 @@ def bitcast(input: tl.tensor,\n     src_bits = src_sca_ty.primitive_bitwidth\n     dst_bits = dst_sca_ty.primitive_bitwidth\n     if src_bits != dst_bits:\n-        raise ValueError(\"Cannot bitcast data-type of size \" + str(src_bits) +\n-                         \"to data-type of size \" + str(dst_bits))\n+        raise ValueError(\"Cannot bitcast data-type of size \" + str(src_bits) + \"to \"\n+                         \"data-type of size \" + str(dst_bits))\n     return tl.tensor(builder.create_bitcast(input.handle, dst_ty.to_ir(builder)),\n                      dst_ty)\n \n@@ -588,8 +588,7 @@ def cast(input: tl.tensor,\n \n     # Int cast\n     if src_sca_ty.is_int() and dst_sca_ty.is_int() and \\\n-        (src_sca_ty.int_bitwidth != dst_sca_ty.int_bitwidth or\n-         src_sca_ty.int_signedness != dst_sca_ty.int_signedness):\n+       (src_sca_ty.int_bitwidth != dst_sca_ty.int_bitwidth or src_sca_ty.int_signedness != dst_sca_ty.int_signedness):\n         sign_extend = src_sca_ty.is_int_signed() and not src_sca_ty.is_bool()\n         return tl.tensor(builder.create_int_cast(input.handle,\n                                                  dst_ty.to_ir(builder), sign_extend),"}]