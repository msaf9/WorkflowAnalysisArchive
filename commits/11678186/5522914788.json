[{"filename": "python/test/regression/test_performance.py", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "file_content_changes": "@@ -44,7 +44,6 @@ def nvsmi(attrs):\n         (512, 512, 512): {'float16': 0.061, 'float32': 0.097, 'int8': 0.05},\n         (1024, 1024, 1024): {'float16': 0.283, 'float32': 0.313, 'int8': 0.169},\n         (2048, 2048, 2048): {'float16': 0.618, 'float32': 0.532, 'int8': 0.34},\n-        (4096, 4096, 4096): {'float16': 0.751, 'float32': 0.726, 'int8': 0.46},\n         (8192, 8192, 8192): {'float16': 0.786, 'float32': 0.754, 'int8': 0.51},\n         # tall-skinny\n         (16, 1024, 1024): {'float16': 0.006, 'float32': 0.009, 'int8': 0.005},\n@@ -115,7 +114,6 @@ def _add(x_ptr, y_ptr, output_ptr, n_elements,\n         1024 * 64: {'float16': 0.013, 'float32': 0.026},\n         1024 * 256: {'float16': 0.053, 'float32': 0.105},\n         1024 * 1024: {'float16': 0.212, 'float32': 0.420},\n-        1024 * 4096: {'float16': 0.791, 'float32': 0.668},\n         1024 * 16384: {'float16': 0.762, 'float32': 0.812},\n         1024 * 65536: {'float16': 0.846, 'float32': 0.869},\n         # Non pow 2\n@@ -162,7 +160,7 @@ def test_elementwise(N, dtype_str):\n         (4, 48, 4096, 64, True, True, 'backward', 'bfloat16'): 0.202,\n         (4, 48, 1024, 16, True, True, 'backward', 'float32'): 0.089,\n         (4, 48, 4096, 64, True, False, 'forward', 'float16'): 0.242,\n-        (4, 48, 4096, 64, True, False, 'forward', 'bfloat16'): 0.248,\n+        (4, 48, 4096, 64, True, False, 'forward', 'bfloat16'): 0.220,\n         (4, 48, 1024, 16, True, False, 'forward', 'float32'): 0.069,\n         (4, 48, 4096, 64, True, False, 'backward', 'float16'): 0.136,\n         (4, 48, 4096, 64, True, False, 'backward', 'bfloat16'): 0.135,\n@@ -174,7 +172,7 @@ def test_elementwise(N, dtype_str):\n         (4, 48, 4096, 64, False, True, 'backward', 'bfloat16'): 0.257,\n         (4, 48, 1024, 16, False, True, 'backward', 'float32'): 0.128,\n         (4, 48, 4096, 64, False, False, 'forward', 'float16'): 0.242,\n-        (4, 48, 4096, 64, False, False, 'forward', 'bfloat16'): 0.248,\n+        (4, 48, 4096, 64, False, False, 'forward', 'bfloat16'): 0.220,\n         (4, 48, 1024, 16, False, False, 'forward', 'float32'): 0.069,\n         (4, 48, 4096, 64, False, False, 'backward', 'float16'): 0.159,\n         (4, 48, 4096, 64, False, False, 'backward', 'bfloat16'): 0.138,"}, {"filename": "python/triton/testing.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -74,7 +74,7 @@ def do_bench_cudagraph(fn, rep=20, grad_to_none=None):\n         torch.cuda.synchronize()\n         times = torch.tensor([s.elapsed_time(e) for s, e in zip(start_event, end_event)])\n         ret.append(torch.min(times))\n-    return torch.mean(torch.tensor(ret)).item()\n+    return torch.min(torch.tensor(ret)).item()\n \n \n def do_bench(fn, warmup=25, rep=100, grad_to_none=None,"}]