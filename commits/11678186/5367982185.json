[{"filename": ".github/workflows/integration-tests.yml", "status": "modified", "additions": 109, "deletions": 2, "changes": 111, "file_content_changes": "@@ -25,7 +25,7 @@ jobs:\n         id: set-matrix\n         run: |\n           if [ x\"${{ github.repository }}\" == x\"openai/triton\" ]; then\n-            echo '::set-output name=matrix::[[\"self-hosted\", \"A100\"], [\"self-hosted\", \"V100\"], [\"self-hosted\", \"H100\"], [\"self-hosted\", \"gfx908\"], [\"self-hosted\", \"arc770\"]]'\n+            echo '::set-output name=matrix::[[\"self-hosted\", \"A100\"], [\"self-hosted\", \"H100\"], [\"self-hosted\", \"gfx908\"], [\"self-hosted\", \"arc770\"]]'\n           else\n             echo '::set-output name=matrix::[\"ubuntu-latest\"]'\n           fi\n@@ -140,7 +140,7 @@ jobs:\n         if: ${{(matrix.runner[0] == 'self-hosted') && (matrix.runner[1] == 'V100' || matrix.runner[1] == 'A100' || matrix.runner[1] == 'H100')}}\n         uses: actions/upload-artifact@v2\n         with:\n-          name: artifacts\n+          name: artifacts ${{ matrix.runner[1] }}\n           path: ~/.triton/artifacts.tar.gz\n \n       - name: Run CXX unittests\n@@ -173,3 +173,110 @@ jobs:\n           sudo nvidia-smi -i 0 --lock-gpu-clocks=1350,1350\n           python3 -m pytest -vs .\n           sudo nvidia-smi -i 0 -rgc\n+\n+  Compare-artifacts:\n+    needs: Integration-Tests\n+\n+    runs-on: ubuntu-latest\n+\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v2\n+\n+      - name: Install gh CLI\n+        run: |\n+          sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key 23F3D4EA75716059\n+          echo \"deb [arch=$(dpkg --print-architecture)] https://cli.github.com/packages focal main\" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null\n+          sudo apt update\n+          sudo apt install gh\n+\n+      - name: Download latest main artifacts\n+        env:\n+          ARTIFACT_NAME: artifacts A100\n+          ARTIFACT_JOB_NAME: Integration-Tests\n+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+        run: |\n+          OWNER_REPO=\"${{ github.repository }}\"\n+          PR_NUMBER=$(gh api --method GET repos/$OWNER_REPO/pulls -f state=closed | jq \".[] | select(.merged_at != null) | .number\" | head -1)\n+          echo \"Last merged PR number: $PR_NUMBER\"\n+\n+          BRANCH_NAME=$(gh api repos/$OWNER_REPO/pulls/$PR_NUMBER --jq '.head.ref')\n+          echo \"BRANCH_NAME: $BRANCH_NAME\"\n+          WORKFLOW_RUN_ID=$(gh api --method GET repos/$OWNER_REPO/actions/runs | jq --arg branch_name \"$BRANCH_NAME\" '.workflow_runs[] | select(.head_branch == $branch_name)' | jq '.id' | head -1)\n+          echo \"WORKFLOW_RUN_ID: $WORKFLOW_RUN_ID\"\n+          ARTIFACT_URL=$(gh api repos/$OWNER_REPO/actions/runs/$WORKFLOW_RUN_ID/artifacts | jq --arg artifact_name \"$ARTIFACT_NAME\" '.artifacts[] | select(.name == $artifact_name).archive_download_url' --raw-output)\n+          echo \"ARTIFACT_URL: $ARTIFACT_URL\"\n+\n+          if [ -n \"$ARTIFACT_URL\" ]; then\n+            echo \"Downloading artifact: $ARTIFACT_URL\"\n+            curl --location --remote-header-name -H \"Authorization: token $GH_TOKEN\" -o reference.zip \"$ARTIFACT_URL\"\n+            # Print the size of the downloaded artifact\n+            echo \"Artifact size (stat): $(stat --printf=\"%s bytes\" reference.zip)\"\n+            echo \"Artifact size (du): $(du -sh reference.zip)\"\n+            unzip reference.zip\n+            tar -xzf artifacts.tar.gz\n+            rm reference.zip\n+            rm artifacts.tar.gz\n+            mv cache reference\n+          else\n+            echo \"No artifact found with the name: $ARTIFACT_NAME\"\n+          fi\n+      - name: Download current job artifacts\n+        uses: actions/download-artifact@v2\n+        with:\n+          name: artifacts A100\n+      - name: Unzip current job artifacts\n+        run: |\n+          # Print the size of the downloaded artifact\n+          echo \"Artifact size (stat): $(stat --printf=\"%s bytes\" artifacts.tar.gz)\"\n+          echo \"Artifact size (du): $(du -sh artifacts.tar.gz)\"\n+          tar -xzf artifacts.tar.gz\n+          rm artifacts.tar.gz\n+          mv cache current\n+      - name: Compare artifacts\n+        run: |\n+          set +e\n+          python3 python/test/tools/compare_files.py --path1 reference --path2 current --kernels python/test/kernel_comparison/kernels.yml\n+          exit_code=$?\n+          set -e\n+          echo $exit_code\n+          if [ $exit_code -eq 0 ]; then\n+            echo \"Artifacts are identical\"\n+            echo \"COMPARISON_RESULT=true\" >> $GITHUB_ENV\n+          elif [ $exit_code -eq 1 ]; then\n+            echo \"Artifacts are different\"\n+            echo \"COMPARISON_RESULT=false\" >> $GITHUB_ENV\n+          else\n+            echo \"Error while comparing artifacts\"\n+            echo \"COMPARISON_RESULT=error\" >> $GITHUB_ENV\n+          fi\n+          echo \"COMPARISON_RESULT=env.COMPARISON_RESULT\"\n+      - name: Check exit code and handle failure\n+        if: ${{ env.COMPARISON_RESULT == 'error' }}\n+        run: |\n+          echo \"Error while comparing artifacts\"\n+          exit 1\n+      - name: Fetch Run ID\n+        id: get_run_id\n+        run: echo \"RUN_ID=${{ github.run_id }}\" >> $GITHUB_ENV\n+\n+      - name: Upload results as artifact\n+        uses: actions/upload-artifact@v2\n+        with:\n+          name: kernels-reference-check\n+          path: kernels_reference_check.txt\n+\n+      - name: Check output and comment on PR\n+        if: ${{ env.COMPARISON_RESULT == 'false' }}\n+        uses: actions/github-script@v5\n+        with:\n+          script: |\n+            const run_id = ${{ env.RUN_ID }};\n+            const issue_number = context.payload.pull_request.number;\n+            const message = `:warning: **This PR does not produce bitwise identical kernels as the branch it's merged against.** Please check artifacts for details. [Download the output file here](https://github.com/${{ github.repository }}/actions/runs/${run_id}).`;\n+            await github.rest.issues.createComment({\n+                owner: context.repo.owner,\n+                repo: context.repo.repo,\n+                issue_number: issue_number,\n+                body: message\n+            });"}, {"filename": ".github/workflows/wheels.yml", "status": "modified", "additions": 42, "deletions": 17, "changes": 59, "file_content_changes": "@@ -2,7 +2,7 @@ name: Wheels\n on:\n   workflow_dispatch:\n   schedule:\n-    - cron: \"0 2 * * *\"\n+    - cron: \"20 2 * * *\"\n \n jobs:\n \n@@ -18,25 +18,20 @@ jobs:\n       - name: Checkout\n         uses: actions/checkout@v3\n \n-      - name: Install Azure CLI\n+      # The LATEST_DATE here should be kept in sync with the one in Patch setup.py\n+      - id: check-version\n+        name: Check latest version\n         run: |\n-          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n-\n-      - name: Azure login\n-        uses: azure/login@v1\n-        with:\n-          client-id: ${{ secrets.AZURE_CLIENT_ID }}\n-          tenant-id: ${{ secrets.AZURE_TENANT_ID }}\n-          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\n-\n-      - id: generate-token\n-        name: Generate token\n-        run: |\n-          AZ_TOKEN=$(az account get-access-token --query accessToken)\n-          echo \"::add-mask::$AZ_TOKEN\"\n-          echo \"access_token=$AZ_TOKEN\" >> \"$GITHUB_OUTPUT\"\n+          export PACKAGE_DATE=$(python3 -m pip install --user --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ --dry-run triton-nightly== |& grep -oP '(?<=, )[0-9\\.]+dev[0-9]+(?=\\))' | grep -oP '(?<=dev)[0-9]+')\n+          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d%H%M%S' --format=\"%cd\")\n+          if cmp -s <(echo $PACKAGE_DATE) <(echo $LATEST_DATE); then\n+            echo \"new_commit=false\" >> \"$GITHUB_OUTPUT\"\n+          else\n+            echo \"new_commit=true\" >> \"$GITHUB_OUTPUT\"\n+          fi\n \n       - name: Patch setup.py\n+        if: ${{ steps.check-version.outputs.new_commit == 'true' }}\n         run: |\n           sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n           export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d%H%M%S' --format=\"%cd\")\n@@ -46,6 +41,7 @@ jobs:\n           echo \"base-dir=/project\" >> python/setup.cfg\n \n       - name: Build wheels\n+        if: ${{ steps.check-version.outputs.new_commit == 'true' }}\n         run: |\n           export CIBW_MANYLINUX_X86_64_IMAGE=\"quay.io/pypa/manylinux2014_x86_64:latest\"\n           #export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"quay.io/pypa/manylinux2014_x86_64:latest\"\n@@ -54,6 +50,35 @@ jobs:\n           export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n           python3 -m cibuildwheel python --output-dir wheelhouse\n \n+      - name: Install Azure CLI\n+        if: ${{ steps.check-version.outputs.new_commit == 'true' }}\n+        run: |\n+          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n+\n+      - name: Azure login\n+        if: ${{ steps.check-version.outputs.new_commit == 'true' }}\n+        uses: azure/login@v1\n+        with:\n+          client-id: ${{ secrets.AZURE_CLIENT_ID }}\n+          tenant-id: ${{ secrets.AZURE_TENANT_ID }}\n+          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\n+\n+      - id: generate-token\n+        name: Generate token\n+        if: ${{ steps.check-version.outputs.new_commit == 'true' }}\n+        run: |\n+          AZ_TOKEN=$(az account get-access-token --query accessToken)\n+          echo \"::add-mask::$AZ_TOKEN\"\n+          echo \"access_token=$AZ_TOKEN\" >> \"$GITHUB_OUTPUT\"\n+\n       - name: Publish wheels to Azure DevOps\n+        if: ${{ steps.check-version.outputs.new_commit == 'true' }}\n         run: |\n           python3 -m twine upload -r Triton-Nightly -u TritonArtifactsSP -p ${{ steps.generate-token.outputs.access_token }} --config-file utils/nightly.pypirc --non-interactive --verbose wheelhouse/*\n+\n+      - name: Azure Logout\n+        if: ${{ steps.check-version.outputs.new_commit == 'true' && (success() || failure()) }}\n+        run: |\n+          az logout\n+          az cache purge\n+          az account clear"}, {"filename": "README.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -25,7 +25,7 @@ You can install the latest stable release of Triton from pip:\n ```bash\n pip install triton\n ```\n-Binary wheels are available for CPython 3.8-3.11 and PyPy 3.8-3.9.\n+Binary wheels are available for CPython 3.7-3.11 and PyPy 3.8-3.9.\n \n And the latest nightly release:\n "}, {"filename": "docs/getting-started/installation.rst", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -12,7 +12,7 @@ You can install the latest stable release of Triton from pip:\n \n       pip install triton\n \n-Binary wheels are available for CPython 3.8-3.11 and PyPy 3.8-3.9.\n+Binary wheels are available for CPython 3.7-3.11 and PyPy 3.8-3.9.\n \n And the latest nightly release:\n "}, {"filename": "include/triton/Dialect/Triton/IR/TritonAttrDefs.td", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -3,13 +3,15 @@\n \n include \"mlir/IR/EnumAttr.td\"\n \n-// Attributes for LoadOp\n+// Attributes for LoadOp and StoreOp\n def TT_CacheModifierAttr : I32EnumAttr<\n     \"CacheModifier\", \"\",\n     [\n         I32EnumAttrCase<\"NONE\", 1, \"none\">,\n         I32EnumAttrCase<\"CA\", 2, \"ca\">,\n         I32EnumAttrCase<\"CG\", 3, \"cg\">,\n+        I32EnumAttrCase<\"WB\", 4, \"wb\">,\n+        I32EnumAttrCase<\"CS\", 5, \"cs\">,\n     ]> {\n     let cppNamespace = \"::mlir::triton\";\n }"}, {"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -392,6 +392,7 @@ def TT_DotOp : TT_Op<\"dot\", [Pure,\n     let results = (outs TT_FpIntTensor:$d);\n \n     let assemblyFormat = \"$a`,` $b`,` $c attr-dict `:` type($a) `*` type($b) `->` type($d)\";\n+    let hasVerifier = 1;\n }\n \n //"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 12, "deletions": 4, "changes": 16, "file_content_changes": "@@ -77,7 +77,7 @@ A_{3, 2}  A_{3, 3}  A_{3, 0}  A_{3, 1} ...   [phase 1] /\n     AttrBuilder<(ins \"DotOperandEncodingAttr\":$dotOpEnc,\n                      \"ArrayRef<int64_t>\":$shape,\n                      \"ArrayRef<unsigned>\":$order,\n-                     \"Type\":$eltTy), [{\n+                     \"unsigned\":$typeWidthInBit), [{\n         auto mmaEnc = dotOpEnc.getParent().dyn_cast<MmaEncodingAttr>();\n \n         if(!mmaEnc)\n@@ -87,7 +87,7 @@ A_{3, 2}  A_{3, 3}  A_{3, 0}  A_{3, 1} ...   [phase 1] /\n         int opIdx = dotOpEnc.getOpIdx();\n \n         // number of rows per phase\n-        int perPhase = 128 / (shape[order[0]] * (eltTy.getIntOrFloatBitWidth() / 8));\n+        int perPhase = 128 / (shape[order[0]] * (typeWidthInBit / 8));\n         perPhase = std::max<int>(perPhase, 1);\n \n         // index of the inner dimension in `order`\n@@ -109,9 +109,9 @@ A_{3, 2}  A_{3, 3}  A_{3, 0}  A_{3, 1} ...   [phase 1] /\n         // ---- begin Ampere ----\n         if (mmaEnc.isAmpere()) {\n           std::vector<size_t> matShape = {8, 8,\n-                                          2 * 64 / eltTy.getIntOrFloatBitWidth()};\n+                                          2 * 64 / typeWidthInBit};\n           // for now, disable swizzle when using transposed int8 tensor cores\n-          if (eltTy.isInteger(8) && order[0] == inner)\n+          if (typeWidthInBit == 8 && order[0] == inner)\n             return $_get(context, 1, 1, 1, order);\n \n           // --- handle A operand ---\n@@ -135,6 +135,14 @@ A_{3, 2}  A_{3, 3}  A_{3, 0}  A_{3, 1} ...   [phase 1] /\n \n         // ---- not implemented ----\n         llvm_unreachable(\"unsupported swizzling for provided MMA version\");\n+    }]>,\n+\n+    AttrBuilder<(ins \"DotOperandEncodingAttr\":$dotOpEnc,\n+                     \"ArrayRef<int64_t>\":$shape,\n+                     \"ArrayRef<unsigned>\":$order,\n+                     \"Type\":$eltTy), [{\n+      unsigned bitwidth = eltTy.getIntOrFloatBitWidth();\n+      return get(context, dotOpEnc, shape, order, bitwidth);\n     }]>\n   ];\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 30, "deletions": 0, "changes": 30, "file_content_changes": "@@ -1180,6 +1180,35 @@ struct AbsFOpConversion\n   }\n };\n \n+/// The lowering of index_cast becomes an integer conversion since index\n+/// becomes an integer.  If the bit width of the source and target integer\n+/// types is the same, just erase the cast.  If the target type is wider,\n+/// sign-extend the value, otherwise truncate it.\n+struct IndexCastOpLowering\n+    : public ElementwiseOpConversionBase<arith::IndexCastOp,\n+                                         IndexCastOpLowering> {\n+  using Base =\n+      ElementwiseOpConversionBase<arith::IndexCastOp, IndexCastOpLowering>;\n+  using Base::Base;\n+  using Adaptor = typename Base::OpAdaptor;\n+\n+  Value createDestOp(arith::IndexCastOp op, OpAdaptor adaptor,\n+                     ConversionPatternRewriter &rewriter, Type elemTy,\n+                     ValueRange operands, Location loc) const {\n+    auto inElemTy =\n+        this->getTypeConverter()->convertType(getElementType(op.getIn()));\n+    unsigned targetBits = elemTy.getIntOrFloatBitWidth();\n+    unsigned sourceBits = inElemTy.getIntOrFloatBitWidth();\n+\n+    if (targetBits == sourceBits)\n+      return operands[0];\n+    if (targetBits < sourceBits)\n+      return rewriter.replaceOpWithNewOp<LLVM::TruncOp>(op, elemTy,\n+                                                        operands[0]);\n+    return rewriter.replaceOpWithNewOp<LLVM::SExtOp>(op, elemTy, operands[0]);\n+  }\n+};\n+\n void populateElementwiseOpToLLVMPatterns(\n     TritonGPUToLLVMTypeConverter &typeConverter, RewritePatternSet &patterns,\n     PatternBenefit benefit) {\n@@ -1240,6 +1269,7 @@ void populateElementwiseOpToLLVMPatterns(\n   patterns.add<TruncFOpConversion>(typeConverter, benefit);\n   patterns.add<FPToSIOpConversion>(typeConverter, benefit);\n   patterns.add<SIToFPOpConversion>(typeConverter, benefit);\n+  patterns.add<IndexCastOpLowering>(typeConverter, benefit);\n \n   patterns.add<FpToFpOpConversion>(typeConverter, benefit);\n "}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -354,6 +354,9 @@ struct StoreOpConversion\n       auto &ptxStoreInstr =\n           ptxBuilder.create<>(\"st\")\n               ->global()\n+              .o(\"wb\", op.getCache() == triton::CacheModifier::WB)\n+              .o(\"cg\", op.getCache() == triton::CacheModifier::CG)\n+              .o(\"cs\", op.getCache() == triton::CacheModifier::CS)\n               .o(\"L1::evict_first\",\n                  op.getEvict() == triton::EvictionPolicy::EVICT_FIRST)\n               .o(\"L1::evict_last\","}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -388,7 +388,7 @@ struct GetProgramIdOpConversion\n \n     Value blockId =\n         rewriter.create<::mlir::gpu::BlockIdOp>(loc, dims[op.getAxisAsInt()]);\n-    rewriter.replaceOpWithNewOp<arith::TruncIOp>(op, i32_ty, blockId);\n+    rewriter.replaceOpWithNewOp<arith::IndexCastOp>(op, i32_ty, blockId);\n     return success();\n   }\n \n@@ -410,7 +410,7 @@ struct GetNumProgramsOpConversion\n \n     Value blockId =\n         rewriter.create<::mlir::gpu::GridDimOp>(loc, dims[op.getAxis()]);\n-    rewriter.replaceOpWithNewOp<arith::TruncIOp>(op, i32_ty, blockId);\n+    rewriter.replaceOpWithNewOp<arith::IndexCastOp>(op, i32_ty, blockId);\n \n     return success();\n   }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "file_content_changes": "@@ -217,10 +217,9 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n   }\n \n   Value getThreadId(ConversionPatternRewriter &rewriter, Location loc) const {\n-    auto llvmIndexTy = this->getTypeConverter()->getIndexType();\n     auto tid = rewriter.create<::mlir::gpu::ThreadIdOp>(\n-        loc, rewriter.getIndexType(), ::mlir::gpu::Dimension::x);\n-    return rewriter.create<arith::TruncIOp>(loc, i32_ty, tid);\n+        loc, ::mlir::gpu::Dimension::x);\n+    return rewriter.create<arith::IndexCastOp>(loc, i32_ty, tid);\n   }\n \n   // -----------------------------------------------------------------------"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "file_content_changes": "@@ -6,6 +6,7 @@\n #include \"mlir/IR/OperationSupport.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/Triton/IR/Types.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n \n namespace mlir {\n namespace triton {\n@@ -398,6 +399,25 @@ mlir::LogicalResult mlir::triton::DotOp::inferReturnTypes(\n   return mlir::success();\n }\n \n+LogicalResult mlir::triton::DotOp::verify() {\n+  auto aTy = getOperand(0).getType().cast<RankedTensorType>();\n+  auto bTy = getOperand(1).getType().cast<RankedTensorType>();\n+  if (aTy.getElementType() != bTy.getElementType())\n+    return emitError(\"element types of operands A and B must match\");\n+  auto aEncoding =\n+      aTy.getEncoding().dyn_cast_or_null<triton::gpu::DotOperandEncodingAttr>();\n+  auto bEncoding =\n+      bTy.getEncoding().dyn_cast_or_null<triton::gpu::DotOperandEncodingAttr>();\n+  if (!aEncoding && !bEncoding)\n+    return mlir::success();\n+  // Verify that the encodings are valid.\n+  if (!aEncoding || !bEncoding)\n+    return emitError(\"mismatching encoding between A and B operands\");\n+  if (aEncoding.getMMAv2kWidth() != bEncoding.getMMAv2kWidth())\n+    return emitError(\"mismatching kWidth between A and B operands\");\n+  return mlir::success();\n+}\n+\n //-- ReduceOp --\n static mlir::LogicalResult\n inferReduceReturnShape(const RankedTensorType &argTy, const Type &retEltTy,"}, {"filename": "lib/Dialect/TritonGPU/Transforms/OptimizeDotOperands.cpp", "status": "modified", "additions": 176, "deletions": 50, "changes": 226, "file_content_changes": "@@ -14,6 +14,7 @@ using triton::DotOp;\n using triton::gpu::ConvertLayoutOp;\n using triton::gpu::DotOperandEncodingAttr;\n using triton::gpu::MmaEncodingAttr;\n+using triton::gpu::SharedEncodingAttr;\n using triton::gpu::SliceEncodingAttr;\n \n // convert(trans(convert(arg)))\n@@ -78,16 +79,15 @@ class MoveOpAfterLayoutConversion : public mlir::RewritePattern {\n \n public:\n   MoveOpAfterLayoutConversion(mlir::MLIRContext *context)\n-      : mlir::RewritePattern(triton::gpu::ConvertLayoutOp::getOperationName(),\n-                             1, context) {}\n+      : mlir::RewritePattern(triton::DotOp::getOperationName(), 1, context) {}\n \n   static mlir::LogicalResult\n   isBlockedToDotOperand(mlir::Operation *op,\n                         triton::gpu::DotOperandEncodingAttr &retEncoding,\n                         triton::gpu::BlockedEncodingAttr &srcEncoding) {\n-    if (!op)\n+    auto cvt = dyn_cast_or_null<triton::gpu::ConvertLayoutOp>(op);\n+    if (!cvt)\n       return failure();\n-    auto cvt = cast<triton::gpu::ConvertLayoutOp>(op);\n     auto srcTy = cvt.getOperand().getType().cast<RankedTensorType>();\n     auto retTy = cvt.getResult().getType().dyn_cast<RankedTensorType>();\n     retEncoding =\n@@ -135,63 +135,185 @@ class MoveOpAfterLayoutConversion : public mlir::RewritePattern {\n   mlir::LogicalResult\n   matchAndRewrite(mlir::Operation *op,\n                   mlir::PatternRewriter &rewriter) const override {\n-    auto cvt = cast<triton::gpu::ConvertLayoutOp>(op);\n-    triton::gpu::DotOperandEncodingAttr retEncoding;\n-    triton::gpu::BlockedEncodingAttr srcEncoding;\n-    if (isBlockedToDotOperand(op, retEncoding, srcEncoding).failed())\n-      return mlir::failure();\n-\n+    auto dotOp = cast<triton::DotOp>(op);\n     // only supports dot NT\n-    auto users = cvt->getUsers();\n-    auto dotOp = dyn_cast_or_null<DotOp>(*users.begin());\n-    if (!dotOp)\n-      return failure();\n     if (!isDotNT(dotOp))\n       return failure();\n+    bool changed = false;\n+    for (Value operand : {dotOp.getOperand(0), dotOp.getOperand(1)}) {\n+      auto cvt = operand.getDefiningOp<triton::gpu::ConvertLayoutOp>();\n+      triton::gpu::DotOperandEncodingAttr retEncoding;\n+      triton::gpu::BlockedEncodingAttr srcEncoding;\n+      bool failed =\n+          isBlockedToDotOperand(cvt, retEncoding, srcEncoding).failed();\n+      assert(!failed);\n \n-    // don't move things around when cvt operand is a block arg\n-    Operation *argOp = cvt.getOperand().getDefiningOp();\n-    if (!argOp)\n-      return failure();\n-    //\n-    SetVector<Operation *> processed;\n-    SetVector<Attribute> layout;\n-    llvm::MapVector<Value, Attribute> toConvert;\n-    int numCvts = simulateBackwardRematerialization(cvt, processed, layout,\n-                                                    toConvert, retEncoding);\n-    if (numCvts > 1 || toConvert.size() == 1)\n-      return failure();\n-    for (Operation *op : processed) {\n-      if (op->getNumOperands() != 1)\n+      // don't move things around when cvt operand is a block arg\n+      Operation *argOp = cvt.getOperand().getDefiningOp();\n+      if (!argOp)\n         continue;\n-      auto srcTy = op->getOperand(0).getType().cast<RankedTensorType>();\n-      auto dstTy = op->getResult(0).getType().cast<RankedTensorType>();\n-      // we don't want to push conversions backward if there is a downcast\n-      // since it would result in more shared memory traffic\n-      if (srcTy.getElementType().getIntOrFloatBitWidth() >\n-          dstTy.getElementType().getIntOrFloatBitWidth())\n-        return failure();\n-      // we only push back when the first op in the chain has a load operand\n-      if ((op == processed.back()) &&\n-          !isa<triton::LoadOp>(op->getOperand(0).getDefiningOp()))\n-        return failure();\n-      // we don't want to use ldmatrix for 8-bit data that requires trans\n-      // since Nvidia GPUs can't do it efficiently\n-      int kOrder = retEncoding.getOpIdx() ^ 1;\n-      bool isTrans = kOrder != srcEncoding.getOrder()[0];\n-      bool isInt8 = srcTy.getElementType().getIntOrFloatBitWidth() == 8;\n-      if (isTrans && isInt8)\n-        return failure();\n+      SetVector<Operation *> processed;\n+      SetVector<Attribute> layout;\n+      llvm::MapVector<Value, Attribute> toConvert;\n+      int numCvts = simulateBackwardRematerialization(cvt, processed, layout,\n+                                                      toConvert, retEncoding);\n+      if (numCvts > 1 || toConvert.size() == 1)\n+        continue;\n+      bool replaceOperand = true;\n+      for (Operation *op : processed) {\n+        if (op->getNumOperands() != 1)\n+          continue;\n+        auto srcTy = op->getOperand(0).getType().cast<RankedTensorType>();\n+        auto dstTy = op->getResult(0).getType().cast<RankedTensorType>();\n+        // we don't want to push conversions backward if there is a downcast\n+        // since it would result in more shared memory traffic\n+        if (srcTy.getElementType().getIntOrFloatBitWidth() >\n+            dstTy.getElementType().getIntOrFloatBitWidth()) {\n+          replaceOperand = false;\n+          break;\n+        }\n+        // we only push back when the first op in the chain has a load operand\n+        if ((op == processed.back()) &&\n+            !isa<triton::LoadOp>(op->getOperand(0).getDefiningOp())) {\n+          replaceOperand = false;\n+          break;\n+        }\n+        // we don't want to use ldmatrix for 8-bit data that requires trans\n+        // since Nvidia GPUs can't do it efficiently\n+        int kOrder = retEncoding.getOpIdx() ^ 1;\n+        bool isTrans = kOrder != srcEncoding.getOrder()[0];\n+        bool isInt8 = srcTy.getElementType().getIntOrFloatBitWidth() == 8;\n+        if (isTrans && isInt8) {\n+          replaceOperand = false;\n+          break;\n+        }\n+      }\n+      if (!replaceOperand)\n+        continue;\n+      IRMapping mapping;\n+      rematerializeConversionChain(toConvert, rewriter, processed, mapping);\n+      rewriter.replaceOp(cvt, mapping.lookup(cvt->getOperand(0)));\n+      changed = true;\n     }\n-    IRMapping mapping;\n-    rematerializeConversionChain(toConvert, rewriter, processed, mapping);\n-    rewriter.replaceOp(cvt, mapping.lookup(cvt->getOperand(0)));\n-    return mlir::success();\n+    return mlir::success(changed);\n   }\n };\n \n } // namespace\n \n+static bool isConvertToDotEncoding(Operation *op) {\n+  auto convertLayout = llvm::dyn_cast<ConvertLayoutOp>(op);\n+  if (!convertLayout)\n+    return false;\n+  auto tensorType =\n+      convertLayout.getResult().getType().cast<RankedTensorType>();\n+  return tensorType.getEncoding().isa<DotOperandEncodingAttr>();\n+}\n+\n+static ConvertLayoutOp updateConvert(OpBuilder &builder, ConvertLayoutOp cvt,\n+                                     IRMapping &mapping, Type smallestType) {\n+  auto cvtDstTy = cvt.getResult().getType().cast<RankedTensorType>();\n+  auto cvtDstEnc = cvtDstTy.getEncoding().cast<DotOperandEncodingAttr>();\n+  Value operand = cvt.getOperand();\n+  if (mapping.contains(operand))\n+    operand = mapping.lookup(operand);\n+  auto newDstTy = RankedTensorType::get(\n+      cvtDstTy.getShape(), cvtDstTy.getElementType(),\n+      DotOperandEncodingAttr::get(cvtDstEnc.getContext(), cvtDstEnc.getOpIdx(),\n+                                  cvtDstEnc.getParent(), smallestType));\n+  auto newCvt =\n+      builder.create<ConvertLayoutOp>(cvt.getLoc(), newDstTy, operand);\n+  mapping.map(cvt.getResult(), newCvt.getResult());\n+  return newCvt;\n+}\n+\n+// Update kWidth based on the smallestType found in the given convert ops and\n+// propagate the type change.\n+static void\n+updateDotEncodingLayout(SmallVector<ConvertLayoutOp> &convertsToDotEncoding,\n+                        Type smallestType) {\n+  IRMapping mapping;\n+  OpBuilder builder(smallestType.getContext());\n+  SetVector<Operation *> slices(convertsToDotEncoding.begin(),\n+                                convertsToDotEncoding.end());\n+  // Collect all the operations where the type needs to be propagated.\n+  for (auto cvt : convertsToDotEncoding) {\n+    auto filter = [&](Operation *op) {\n+      for (Value operand : op->getOperands()) {\n+        auto tensorType = operand.getType().dyn_cast<RankedTensorType>();\n+        if (tensorType &&\n+            tensorType.getEncoding().isa<DotOperandEncodingAttr>())\n+          return true;\n+      }\n+      return false;\n+    };\n+    mlir::getForwardSlice(cvt.getResult(), &slices, {filter});\n+  }\n+  // Apply the type change by walking ops in topological order.\n+  slices = mlir::topologicalSort(slices);\n+  for (Operation *op : slices) {\n+    builder.setInsertionPoint(op);\n+    if (isConvertToDotEncoding(op)) {\n+      auto cvt = cast<ConvertLayoutOp>(op);\n+      ConvertLayoutOp newCvt =\n+          updateConvert(builder, cvt, mapping, smallestType);\n+      continue;\n+    }\n+    auto *newOp = cloneWithInferType(builder, op, mapping);\n+    for (auto [result, newResult] :\n+         llvm::zip(op->getResults(), newOp->getResults())) {\n+      result.replaceUsesWithIf(newResult, [&](OpOperand &operand) {\n+        return slices.count(operand.getOwner()) == 0;\n+      });\n+    }\n+  }\n+  for (Operation *op : llvm::reverse(slices))\n+    op->erase();\n+}\n+\n+// Change the layout of dotOperand layout to use the kWidth from the smallest\n+// loaded type. This allows better code generation for mixed-mode matmul.\n+static void optimizeKWidth(triton::FuncOp func) {\n+  SmallVector<ConvertLayoutOp> convertsToDotEncoding;\n+  Type smallestType;\n+  func->walk([&](triton::LoadOp loadOp) {\n+    if (!loadOp.getResult().hasOneUse())\n+      return;\n+    Operation *use = *loadOp.getResult().getUsers().begin();\n+\n+    // Advance to the first conversion as long as the use resides in shared\n+    // memory and it has a single use itself\n+    while (use) {\n+      if (use->getNumResults() != 1 || !use->getResult(0).hasOneUse())\n+        break;\n+      auto tensorType =\n+          use->getResult(0).getType().dyn_cast<RankedTensorType>();\n+      if (!tensorType || !tensorType.getEncoding().isa<SharedEncodingAttr>())\n+        break;\n+      use = *use->getResult(0).getUsers().begin();\n+    }\n+\n+    auto convertLayout = llvm::dyn_cast<ConvertLayoutOp>(use);\n+    if (!convertLayout)\n+      return;\n+    auto tensorType =\n+        convertLayout.getResult().getType().cast<RankedTensorType>();\n+    if (!tensorType.getEncoding().isa<DotOperandEncodingAttr>())\n+      return;\n+    convertsToDotEncoding.push_back(convertLayout);\n+\n+    // Update the smallest type.\n+    auto ty = loadOp.getType().cast<RankedTensorType>();\n+    Type eltTy = ty.getElementType();\n+    if (!smallestType ||\n+        (eltTy.getIntOrFloatBitWidth() < smallestType.getIntOrFloatBitWidth()))\n+      smallestType = eltTy;\n+  });\n+  if (!smallestType)\n+    return;\n+  updateDotEncodingLayout(convertsToDotEncoding, smallestType);\n+}\n+\n #define GEN_PASS_CLASSES\n #include \"triton/Dialect/TritonGPU/Transforms/Passes.h.inc\"\n \n@@ -216,6 +338,10 @@ class TritonGPUOptimizeDotOperandsPass\n       signalPassFailure();\n     if (fixupLoops(m).failed())\n       signalPassFailure();\n+\n+    // Change the layout of dotOperand layout to use the kWidth from the\n+    // smallest loaded type.\n+    m->walk([](triton::FuncOp func) { optimizeKWidth(func); });\n   }\n };\n "}, {"filename": "lib/Dialect/TritonGPU/Transforms/Pipeline.cpp", "status": "modified", "additions": 8, "deletions": 30, "changes": 38, "file_content_changes": "@@ -111,9 +111,6 @@ class LoopPipeliner {\n \n   /// Loads to be pipelined\n   SetVector<Value> validLoads;\n-  /// Smallest data-type for each load (used to optimize swizzle and\n-  /// (create DotOpEncoding layout)\n-  DenseMap<Value, Type> loadsSmallestType;\n   /// The value that each load will be mapped to (after layout conversion)\n   DenseMap<Value, Value> loadsMapping;\n   /// load => buffer\n@@ -485,21 +482,6 @@ Value LoopPipeliner::lookupOrDefault(Value origin, int stage) {\n }\n \n void LoopPipeliner::createBufferTypes() {\n-  // We need to find the smallest common dtype since this determines the layout\n-  // of `mma.sync` operands in mixed-precision mode\n-  Type smallestType;\n-  for (auto loadCvt : loadsMapping) {\n-    auto loadOp = loadCvt.first;\n-    auto ty = loadOp.getType().cast<RankedTensorType>();\n-    Type eltTy = ty.getElementType();\n-    if (!smallestType ||\n-        (eltTy.getIntOrFloatBitWidth() < smallestType.getIntOrFloatBitWidth()))\n-      smallestType = eltTy;\n-  }\n-\n-  for (auto loadCvt : loadsMapping)\n-    loadsSmallestType[loadCvt.first] = smallestType;\n-\n   for (auto loadCvt : loadsMapping) {\n     auto loadOp = loadCvt.first;\n     Value cvt = loadCvt.second;\n@@ -511,9 +493,12 @@ void LoopPipeliner::createBufferTypes() {\n     SmallVector<int64_t> bufferShape(ty.getShape().begin(),\n                                      ty.getShape().end());\n     bufferShape.insert(bufferShape.begin(), numStages);\n-    auto sharedEnc = ttg::SharedEncodingAttr::get(\n-        ty.getContext(), dotOpEnc, ty.getShape(),\n-        ttg::getOrder(ty.getEncoding()), loadsSmallestType[loadOp]);\n+    unsigned bitWidth = dotOpEnc.getMMAv2kWidth()\n+                            ? 32 / dotOpEnc.getMMAv2kWidth()\n+                            : ty.getElementType().getIntOrFloatBitWidth();\n+    auto sharedEnc =\n+        ttg::SharedEncodingAttr::get(ty.getContext(), dotOpEnc, ty.getShape(),\n+                                     ttg::getOrder(ty.getEncoding()), bitWidth);\n     loadsBufferType[loadOp] =\n         RankedTensorType::get(bufferShape, ty.getElementType(), sharedEnc);\n   }\n@@ -789,19 +774,12 @@ scf::ForOp LoopPipeliner::cloneForOp(ArrayRef<Value> newLoopArgs,\n     // we replace the use new load use with a convert layout\n     size_t i = std::distance(validLoads.begin(), it);\n     auto cvtDstTy = op.getResult(0).getType().cast<RankedTensorType>();\n-    auto cvtDstEnc =\n-        cvtDstTy.getEncoding().dyn_cast<ttg::DotOperandEncodingAttr>();\n-    if (!cvtDstEnc) {\n+    if (!cvtDstTy.getEncoding().isa<ttg::DotOperandEncodingAttr>()) {\n       builder.clone(op, mapping);\n       continue;\n     }\n-    auto newDstTy = RankedTensorType::get(\n-        cvtDstTy.getShape(), cvtDstTy.getElementType(),\n-        ttg::DotOperandEncodingAttr::get(\n-            cvtDstEnc.getContext(), cvtDstEnc.getOpIdx(), cvtDstEnc.getParent(),\n-            loadsSmallestType[op.getOperand(0)]));\n     auto cvt = builder.create<ttg::ConvertLayoutOp>(\n-        op.getResult(0).getLoc(), newDstTy,\n+        op.getResult(0).getLoc(), cvtDstTy,\n         newForOp.getRegionIterArgs()[loadIdx + i]);\n     mapping.map(op.getResult(0), cvt.getResult());\n   }"}, {"filename": "python/MANIFEST.in", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -1,4 +1,5 @@\n graft src\n graft triton/third_party\n+graft triton/tools\n graft triton/runtime/backends/\n graft triton/language/extra"}, {"filename": "python/setup.py", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "file_content_changes": "@@ -13,6 +13,7 @@\n \n from setuptools import Extension, setup\n from setuptools.command.build_ext import build_ext\n+from setuptools.command.build_py import build_py\n \n \n # Taken from https://github.com/pytorch/pytorch/blob/master/tools/setup_helpers/env.py\n@@ -146,6 +147,11 @@ def download_and_copy_ptxas():\n \n # ---- cmake extension ----\n \n+class CMakeBuildPy(build_py):\n+    def run(self) -> None:\n+        self.run_command('build_ext')\n+        return super().run()\n+\n \n class CMakeExtension(Extension):\n     def __init__(self, name, path, sourcedir=\"\"):\n@@ -280,7 +286,7 @@ def build_extension(self, ext):\n     ],\n     include_package_data=True,\n     ext_modules=[CMakeExtension(\"triton\", \"triton/_C/\")],\n-    cmdclass={\"build_ext\": CMakeBuild},\n+    cmdclass={\"build_ext\": CMakeBuild, \"build_py\": CMakeBuildPy},\n     zip_safe=False,\n     # for PyPI\n     keywords=[\"Compiler\", \"Deep Learning\"],"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -89,6 +89,8 @@ void init_triton_ir(py::module &&m) {\n       .value(\"NONE\", mlir::triton::CacheModifier::NONE)\n       .value(\"CA\", mlir::triton::CacheModifier::CA)\n       .value(\"CG\", mlir::triton::CacheModifier::CG)\n+      .value(\"WB\", mlir::triton::CacheModifier::WB)\n+      .value(\"CS\", mlir::triton::CacheModifier::CS)\n       .export_values();\n \n   py::enum_<mlir::triton::MemSemantic>(m, \"MEM_SEMANTIC\")"}, {"filename": "python/test/kernel_comparison/kernels.yml", "status": "added", "additions": 31, "deletions": 0, "changes": 31, "file_content_changes": "@@ -0,0 +1,31 @@\n+name_and_extension:\n+  - name: _kernel_0d1d2d34567c89c1011c\n+    extension: ptx\n+  - name: _kernel_0d1d2d3d4d5d6d7c8d9c10d11c\n+    extension: ptx\n+  - name: _kernel_0d1d2d3d4d5d6d7c8c9d10d11c\n+    extension: ptx\n+  - name: _kernel_0d1d2d3456c789c1011c\n+    extension: ptx\n+  - name: _kernel_0d1d2d345d6d7c8c9d1011c\n+    extension: ptx\n+  - name: _kernel_0d1d2d34567c8c91011c\n+    extension: ptx\n+  - name: _kernel_0d1d2d3456c78c91011c\n+    extension: ptx\n+  - name: _kernel_0d1d2d345d6c78c9d1011c\n+    extension: ptx\n+  - name: _kernel_0d1d2d345d6c789c1011c\n+    extension: ptx\n+  - name: _kernel_0d1d2d3d4d5d6c7d8d9c10d11c\n+    extension: ptx\n+  - name: _kernel_0d1d2d3d4d5d6c7d8c9d10d11c\n+    extension: ptx\n+  - name: _kernel_0d1d2d345d6d7c89c1011c\n+    extension: ptx\n+  - name: _bwd_kernel_0d1d2d34d5d6d7d8d9d10d11d12d13d14d15c16d17d18d19c20d21d22d23c2425d26d27\n+    extension: ptx\n+  - name: _fwd_kernel_0d1d2d34d5d6d7d8d9d10c11d12d13d14c15d16d17d18c19d20d21d22c2324d25d\n+    extension: ptx\n+  - name: _bwd_preprocess_0d1d2d3d4d\n+    extension: ptx"}, {"filename": "python/test/tools/compare_files.py", "status": "added", "additions": 261, "deletions": 0, "changes": 261, "file_content_changes": "@@ -0,0 +1,261 @@\n+import argparse\n+import difflib\n+import glob\n+import os\n+import sys\n+from typing import Dict, List, Optional, Tuple\n+\n+import yaml\n+\n+\n+class ComparisonResult:\n+    def __init__(self, name: str, extension: str, numComparisons: int, diffs: List[str] = None, errors: List[str] = None):\n+        self.name = name\n+        self.extension = extension\n+        self.numComparisons = numComparisons\n+        self.diffs = [] if diffs is None else diffs\n+        self.errors = [] if errors is None else errors\n+\n+    def isSuccess(self) -> bool:\n+        return len(self.diffs) == 0 and len(self.errors) == 0\n+\n+    def __str__(self) -> str:\n+        return f\"name={self.name}, extension={self.extension}, numComparisons={self.numComparisons}, success={self.isSuccess()}\"\n+\n+\n+def listFilesWithExtension(path: str, extension: str) -> List[str]:\n+    \"\"\"\n+        Returns a list of files in the given path with the given extension\n+        The files are returned with their full path\n+    \"\"\"\n+    files = glob.glob(os.path.join(path, f'*.{extension}'))\n+    return files\n+\n+\n+def getFileWithExtension(path: str, ext: str) -> Optional[str]:\n+    \"\"\"\n+        Returns a single file in the given path with the given extension\n+    \"\"\"\n+    # get all files in directory with extension\n+    files = listFilesWithExtension(path, ext)\n+    if len(files) == 0:\n+        return None\n+    # filter out files with grp in their name\n+    files = [f for f in files if \"__grp__\" not in f]\n+    if len(files) != 1:\n+        print(f\"Found {len(files)} files in {path} with extension {ext}!\")\n+        sys.exit(2)\n+    return files[0]\n+\n+\n+def loadYamlFile(filePath: str) -> List[Dict[str, str]]:\n+    \"\"\"\n+        Loads a yaml file and returns its content as a list of dictionaries\n+    \"\"\"\n+    with open(filePath, 'r') as file:\n+        content = yaml.safe_load(file)\n+    return content\n+\n+\n+def compareFiles(file1: str, file2: str) -> bool:\n+    \"\"\"\n+        Compares two files and returns True if they are the same, False otherwise\n+    \"\"\"\n+    with open(file1, 'rb') as f1, open(file2, 'rb') as f2:\n+        content1 = f1.read()\n+        content2 = f2.read()\n+\n+    return content1 == content2\n+\n+\n+def diffFiles(file1, file2):\n+    with open(file1, 'r') as f1:\n+        file1_lines = f1.readlines()\n+    with open(file2, 'r') as f2:\n+        file2_lines = f2.readlines()\n+\n+    diff = list(difflib.unified_diff(file1_lines, file2_lines, file1, file2))\n+    return diff\n+\n+\n+def getFileVec(path: str) -> List[Tuple[str, str]]:\n+    \"\"\"\n+        Returns a list of tuples (extension, file) for the given path (note: the path includes the hash)\n+        The returned list must have extensions (json, ttir, ttgir)\n+        in this particular order, unless a file with a certain extension does not exist\n+    \"\"\"\n+    vec = []\n+    for ext in [\"json\", \"ttir\", \"ttgir\"]:\n+        file = getFileWithExtension(path, ext)\n+        if file is not None:\n+            vec.append((ext, file))\n+    return vec\n+\n+\n+def getNameToHashesDict(path: str) -> Dict[str, List[str]]:\n+    \"\"\"\n+        Returns a dictionary that maps kernel names to a list of hashes that have the same kernel name\n+        in the given path\n+        Note: the hashes must have a json file and either a ttir or ttgir file, otherwise they are ignored\n+    \"\"\"\n+    nameToHashes = {}\n+    for hash in os.listdir(path):\n+        fullPath = os.path.join(path, hash)\n+        if not os.path.isdir(fullPath):\n+            print(f\"Path {fullPath} is not a directory!\")\n+            sys.exit(2)\n+        fileVec = getFileVec(fullPath)\n+        if len(fileVec) < 2 or fileVec[0][0] != \"json\":\n+            continue\n+        jsonFile = fileVec[0][1]\n+        # load json file\n+        with open(jsonFile, 'r') as file:\n+            content = yaml.safe_load(file)\n+            # get name\n+            name = content[\"name\"]\n+            nameToHashes.setdefault(name, []).append(hash)\n+    return nameToHashes\n+\n+\n+def doFilesMatch(path1: str, path2: str) -> bool:\n+    \"\"\"\n+        Returns True if the files in the given paths match, False otherwise\n+        The files are considered to match if:\n+        1. The number of files in both paths match\n+        2. The json files match\n+        3. Both paths have a ttir that match, if a ttir does not exist, the ttgir file must exist and match\n+    \"\"\"\n+    filesVec1 = getFileVec(path1)\n+    filesVec2 = getFileVec(path2)\n+    # The number of files must match\n+    if len(filesVec1) != len(filesVec2):\n+        return False\n+\n+    for (ext1, file1), (ext2, file2) in zip(filesVec1, filesVec2):\n+        if ext1 != ext2:\n+            return False\n+        if not compareFiles(file1, file2):\n+            return False\n+        else:\n+            # once we actually compared a ttir or ttgir file, we can break\n+            if ext1 in (\"ttir\", \"ttgir\"):\n+                break\n+    return True\n+\n+\n+def compareMatchingFiles(name: str, extension: str, nameToHashes1: Dict[str, List[str]], nameToHashes2: Dict[str, List[str]], args) -> ComparisonResult:\n+    \"\"\"\n+        Compare files with the given name/extension in all hashes in both paths\n+        Return the first mismatching files as a tuple (file1, file2), otherwise, return an empty tuple\n+    \"\"\"\n+    hashes1 = nameToHashes1.get(name, [])\n+    hashes2 = nameToHashes2.get(name, [])\n+    diffs = []\n+    errors = []\n+    numComparisons = 0\n+    for hash1 in hashes1:\n+        path1 = os.path.join(args.path1, hash1)\n+        for hash2 in hashes2:\n+            path2 = os.path.join(args.path2, hash2)\n+            # check whether both paths have:\n+            # 1. json files that match\n+            # 2. ttir files that match (if they exist), otherwise ttgir files that match (if they exist)\n+            # if any of these contraints is not met, then we can skip this pair of hashes since they are not a match\n+            if not doFilesMatch(path1, path2):\n+                continue\n+            numComparisons += 1\n+            extFile1 = listFilesWithExtension(path1, extension)[0]\n+            extFile2 = listFilesWithExtension(path2, extension)[0]\n+            diff = diffFiles(extFile1, extFile2)\n+            if len(diff) > 0:\n+                diffs.append(diffFiles(extFile2, extFile1))\n+    if numComparisons == 0:\n+        errors.append(f\"Did not find any matching files for {name}\")\n+    return ComparisonResult(name=name, extension=extension, numComparisons=numComparisons, diffs=diffs, errors=errors)\n+\n+\n+def dumpResults(results: List[ComparisonResult], fileName: str):\n+    \"\"\"\n+        Dumps the results to the given file\n+    \"\"\"\n+    with open(fileName, 'w') as file:\n+        for result in results:\n+            file.write(str(result) + \"\\n\")\n+            file.write(\"Diffs:\\n\")\n+            for diff in result.diffs:\n+                for line in diff:\n+                    file.write(line)\n+            file.write(\"Errors:\\n\")\n+            for error in result.errors:\n+                file.write(error)\n+            file.write(\"\\n\\n\")\n+\n+\n+def main(args) -> bool:\n+    \"\"\"\n+        Iterates over all kernels in the given yaml file and compares them\n+        in the given paths\n+    \"\"\"\n+    if args.path1 == args.path2:\n+        print(\"Cannot compare files in the same directory!\")\n+        sys.exit(2)\n+    # Get kernel name to hashes dict, these hashes would have the same kernel name\n+    nameToHashes1 = getNameToHashesDict(args.path1)\n+    nameToHashes2 = getNameToHashesDict(args.path2)\n+\n+    yamlFilePath = args.kernels\n+    if not os.path.exists(yamlFilePath):\n+        print(f\"Path {yamlFilePath} does not exist!\")\n+        sys.exit(2)\n+    nameAndExtension = loadYamlFile(yamlFilePath)[\"name_and_extension\"]\n+\n+    results = []\n+    # iterate over the kernels that need to be checked\n+    for d in nameAndExtension:\n+        name = d[\"name\"]  # kernel name\n+        extension = d[\"extension\"]  # extension of the file to be compared (e.g. ptx)\n+        # Compare all hashes on path 1 with all hashes on path 2\n+        # result is either the mismatching (file1, file2) with \"extension\" or empty tuple if no mismatch\n+        result = compareMatchingFiles(name, extension, nameToHashes1, nameToHashes2, args)\n+        print(result)\n+        # Otherwise, add it to the mismatches\n+        results.append(result)\n+\n+    # Dump results\n+    dumpResults(results, \"kernels_reference_check.txt\")\n+\n+    success = all(result.isSuccess() for result in results)\n+\n+    if not success:\n+        print(\"Failed!\")\n+        sys.exit(1)\n+\n+    print(\"Passed!\")\n+    sys.exit(0)\n+\n+\n+if __name__ == \"__main__\":\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument(\n+        \"--path1\",\n+        type=str,\n+        default=None,\n+        required=True,\n+        help=(\"Path to first cache directory\"),\n+    )\n+    parser.add_argument(\n+        \"--path2\",\n+        type=str,\n+        default=None,\n+        required=True,\n+        help=(\"Path to second cache directory\"),\n+    )\n+    parser.add_argument(\n+        \"--kernels\",\n+        type=str,\n+        default=None,\n+        required=True,\n+        help=(\"Path to kernels yaml file\"),\n+    )\n+    args = parser.parse_args()\n+    main(args)"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 43, "deletions": 3, "changes": 46, "file_content_changes": "@@ -1374,7 +1374,8 @@ def get_reduced_dtype(dtype_str, op):\n                           for op in ['min', 'max',\n                                      'min-with-indices',\n                                      'max-with-indices',\n-                                     'argmin', 'argmax',\n+                                     'argmin-tie-break-left',\n+                                     'argmax-tie-break-left',\n                                      'sum']\n                           for dtype in dtypes_with_bfloat16\n                           for shape in [32, 64, 128, 512]])\n@@ -1390,18 +1391,26 @@ def kernel(X, Z, BLOCK: tl.constexpr):\n \n     if 'with-indices' in op:\n         patch = f'z, _ = tl.{op.split(\"-\")[0]}(x, axis=0, return_indices=True)'\n+    elif 'arg' in op:\n+        tie_break_left = 'tie-break-left' in op\n+        patch = f'z = tl.{op.split(\"-\")[0]}(x, axis=0, tie_break_left={tie_break_left})'\n     else:\n         patch = f'z = tl.{op}(x, axis=0)'\n     kernel = patch_kernel(kernel, {'GENERATE_TEST_HERE': patch})\n     # input\n     rs = RandomState(17)\n     # limit the range of integers so that the sum does not overflow\n     x = numpy_random((shape,), dtype_str=dtype_str, rs=rs)\n-    x_tri = to_triton(x, device=device)\n     numpy_op = {'sum': np.sum, 'max': np.max, 'min': np.min,\n                 'max-with-indices': np.max,\n                 'min-with-indices': np.min,\n-                'argmin': np.argmin, 'argmax': np.argmax}[op]\n+                'argmin-tie-break-fast': np.argmin,\n+                'argmin-tie-break-left': np.argmin,\n+                'argmax-tie-break-fast': np.argmax,\n+                'argmax-tie-break-left': np.argmax}[op]\n+    if 'tie-break-left' in op:\n+        x[3:10] = numpy_op(x)\n+    x_tri = to_triton(x, device=device)\n     # numpy result\n     z_dtype_str = 'int32' if op in ('argmin', 'argmax') else dtype_str\n     z_tri_dtype_str = z_dtype_str\n@@ -2263,6 +2272,37 @@ def _kernel(dst, src, off, N, BLOCK_SIZE: tl.constexpr, HINT: tl.constexpr):\n # test store\n # ---------------\n \n+\n+@pytest.mark.parametrize(\"cache\", [\"\", \".wb\", \".cg\", \".cs\"])\n+def test_store_cache_modifier(cache):\n+    src = torch.empty(128, device='cuda')\n+    dst = torch.empty(128, device='cuda')\n+\n+    @triton.jit\n+    def _kernel(dst, src, CACHE: tl.constexpr):\n+        offsets = tl.arange(0, 128)\n+        x = tl.load(src + offsets)\n+        tl.store(dst + offsets, x, cache_modifier=CACHE)\n+\n+    pgm = _kernel[(1,)](dst, src, CACHE=cache)\n+    ptx = pgm.asm['ptx']\n+    if cache == '':\n+        assert 'st.global.wb' not in ptx\n+        assert 'st.global.cg' not in ptx\n+        assert 'st.global.cs' not in ptx\n+    if cache == '.wb':\n+        assert 'st.global.wb' in ptx\n+        assert 'st.global.cg' not in ptx\n+        assert 'st.global.cs' not in ptx\n+    if cache == '.cg':\n+        assert 'st.global.wb' not in ptx\n+        assert 'st.global.cg' in ptx\n+        assert 'st.global.cs' not in ptx\n+    if cache == '.cs':\n+        assert 'st.global.wb' not in ptx\n+        assert 'st.global.cg' not in ptx\n+        assert 'st.global.cs' in ptx\n+\n # ---------------\n # test if\n # ---------------"}, {"filename": "python/test/unit/operators/test_matmul.py", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -67,6 +67,7 @@ def kernel(Y, X, N, BLOCK_SIZE: tl.constexpr):\n                 (128, 128, 32, 1, 4, 2, 384, 128, 640, AT, BT, DTYPE, DTYPE),\n                 (128, 128, 32, 1, 4, 2, 107, 233, 256, AT, BT, DTYPE, DTYPE),\n                 (128, 128, 32, 1, 4, 2, 107, 233, 311, AT, BT, DTYPE, DTYPE),\n+                (128, 256, 64, 1, 8, 3, 1024, 1024, 1024, AT, BT, DTYPE, DTYPE),\n             ] for DTYPE in [\"float16\", \"bfloat16\", \"float32\"] for AT in [False, True] for BT in [False, True]\n         ],\n         # n-stage\n@@ -131,6 +132,9 @@ def get_input(n, m, t, dtype):\n     th_c = torch.matmul(a, b)\n     try:\n         tt_c = triton.ops.matmul(a, b)\n-        torch.testing.assert_allclose(th_c, tt_c, atol=1e-2, rtol=0)\n+        atol, rtol = 1e-2, 0\n+        if ADTYPE == torch.bfloat16 or BDTYPE == torch.bfloat16:\n+            atol, rtol = 3.5e-2, 0\n+        torch.testing.assert_allclose(th_c, tt_c, atol=atol, rtol=rtol)\n     except triton.OutOfResources as e:\n         pytest.skip(str(e))"}, {"filename": "python/test/unit/tools/test_aot.py", "status": "added", "additions": 205, "deletions": 0, "changes": 205, "file_content_changes": "@@ -0,0 +1,205 @@\n+import glob\n+import os\n+import subprocess\n+import sys\n+import tempfile\n+\n+import numpy as np\n+\n+import triton\n+from triton.common import cuda_include_dir, libcuda_dirs\n+\n+kernel_utils_src = \"\"\"\n+import triton\n+\n+@triton.jit\n+def mul(x, y):\n+    return x * y\n+\"\"\"\n+\n+kernel_src = \"\"\"\n+import triton\n+import triton.language as tl\n+import kernel_utils\n+\n+@triton.jit\n+def kernel(C, A, B,\n+          stride_cm, stride_cn,\n+          stride_am, stride_ak,\n+          stride_bk, stride_bn,\n+          BLOCK_M: tl.constexpr,\n+          BLOCK_N: tl.constexpr,\n+          BLOCK_K: tl.constexpr):\n+  ms = tl.arange(0, BLOCK_M)\n+  ns = tl.arange(0, BLOCK_N)\n+  ks = tl.arange(0, BLOCK_K)\n+  a = tl.load(A + ms[:, None] * stride_am + ks[None, :] * stride_ak)\n+  b = tl.load(B + ks[:, None] * stride_bk + ns[None, :] * stride_bn)\n+  c = tl.dot(a, b)\n+  c = kernel_utils.mul(c, c)\n+  tl.store(C + ms[:, None] * stride_cm + ns[None, :] * stride_cn, c)\n+\"\"\"\n+\n+test_src = \"\"\"\n+#include <cuda.h>\n+#include <stdio.h>\n+#include <stdint.h>\n+#include <string.h>\n+#include \"kernel.h\"\n+\n+static void write_buffer_to_csv(char *filename, int32_t *buffer, int size) {\n+    FILE *file = fopen(filename, \"w\");\n+    if (file == NULL) {\n+        printf(\\\"Could not open file %s\\\\n\\\", filename);\n+        return;\n+    }\n+    for (int i = 0; i < size; i++) {\n+        fprintf(file, \"%d\", buffer[i]);\n+        if (i < size - 1) {\n+            fprintf(file, \",\");\n+        }\n+    }\n+    fclose(file);\n+}\n+\n+static void read_csv_to_buffer(char *filename, int16_t *buffer, int size) {\n+    FILE *file = fopen(filename, \"r\");\n+    if (file == NULL) {\n+        printf(\\\"Could not open file %s\\\\n\\\", filename);\n+        return;\n+    }\n+    int index = 0;\n+    while (fscanf(file, \"%hd,\", &buffer[index]) != EOF && index < size) {\n+        index++;\n+    }\n+    fclose(file);\n+}\n+\n+int main(int argc, char **argv) {\n+  int M = 16, N = 16, K = 16;\n+  int BM = 16, BN = 16, BK = 16;\n+\n+  // initialize CUDA handles\n+  CUdevice dev;\n+  CUcontext ctx;\n+  CUstream stream;\n+  CUdeviceptr A, B, C;\n+  CUresult err = 0;\n+  cuInit(0);\n+  cuDeviceGet(&dev, 0);\n+  cuCtxCreate(&ctx, 0, dev);\n+  cuMemAlloc(&A, M * K * 2);\n+  cuMemAlloc(&B, K * N * 2);\n+  cuMemAlloc(&C, M * N * 4);\n+  cuStreamCreate(&stream, 0);\n+  load_kernel();\n+\n+  // initialize input data\n+  int16_t hA[M*K];\n+  int16_t hB[K*N];\n+  memset(hA, 0, M*K*2);\n+  memset(hB, 0, K*N*2);\n+  read_csv_to_buffer(argv[1], hA, M*K);\n+  read_csv_to_buffer(argv[2], hB, K*N);\n+  cuMemcpyHtoD(A, hA, M*K*2);\n+  cuMemcpyHtoD(B, hB, K*N*2);\n+\n+  // launch kernel\n+  int numWarps = 1;\n+  int gX = 1, gY = 1, gZ = 1;\n+  cuStreamSynchronize(stream);\n+  kernel(stream, M/BM, N/BN, 1, numWarps, C, A, B, N, K, N);\n+  cuStreamSynchronize(stream);\n+\n+  // read data\n+  int32_t hC[M*N];\n+  memset(hC, 0, M*N*4);\n+  cuMemcpyDtoH(hC, C, M*N*4);\n+  write_buffer_to_csv(argv[3], hC, M*N);\n+\n+\n+  // free cuda handles\n+  unload_kernel();\n+  cuMemFree(A);\n+  cuMemFree(B);\n+  cuMemFree(C);\n+  cuCtxDestroy(ctx);\n+}\n+\"\"\"\n+\n+\n+def test_compile_link_matmul():\n+    np.random.seed(3)\n+\n+    with tempfile.TemporaryDirectory() as tmp_dir:\n+        kernel_path = os.path.join(tmp_dir, \"kernel.py\")\n+        with open(kernel_path, \"w\") as file:\n+            file.write(kernel_src)\n+\n+        kernel_utils_path = os.path.join(tmp_dir, \"kernel_utils.py\")\n+        with open(kernel_utils_path, \"w\") as file:\n+            file.write(kernel_utils_src)\n+\n+        compiler_path = os.path.join(triton.tools.__path__[0], \"compile.py\")\n+        linker_path = os.path.join(triton.tools.__path__[0], \"link.py\")\n+\n+        dtype = \"fp16\"\n+        M, N, K = 16, 16, 16\n+        BM, BN, BK = 16, 16, 16\n+\n+        # compile all desired configs\n+        hints = [\":16\", \"\"]\n+        for ha in hints:\n+            for hb in hints:\n+                sig = f'*fp32:16, *{dtype}:16, *{dtype}:16, i32{ha}, 1, i32{hb}, 1, i32:16, 1, {BM}, {BN}, {BK}'\n+                name = f\"matmul_{dtype}x{dtype}_{BM}x{BN}x{BK}\"\n+                subprocess.run([sys.executable, compiler_path, \"-n\", \"kernel\", \"--signature\", sig, \"--out-name\", name, \"-o\", name, kernel_path], check=True, cwd=tmp_dir)\n+\n+        # link all desired configs\n+        h_files = glob.glob(os.path.join(tmp_dir, \"*.h\"))\n+        subprocess.run([sys.executable, linker_path] + h_files + [\"-o\", \"kernel\"], check=True, cwd=tmp_dir)\n+\n+        # compile test case\n+        with open(os.path.join(tmp_dir, \"test.c\"), \"w\") as file:\n+            file.write(test_src)\n+        c_files = glob.glob(os.path.join(tmp_dir, \"*.c\"))\n+        subprocess.run([\"gcc\"] + c_files + [\"-I\", cuda_include_dir(),\n+                                            \"-L\", libcuda_dirs()[0],\n+                                            \"-l\", \"cuda\",\n+                                            \"-o\", \"test\"], check=True, cwd=tmp_dir)\n+\n+        # initialize test data\n+        a = np.random.randn(M * K).astype(np.float16).reshape((M, K))\n+        b = np.random.randn(M * K).astype(np.float16).reshape((K, N))\n+        a_path = os.path.join(tmp_dir, \"a.csv\")\n+        b_path = os.path.join(tmp_dir, \"b.csv\")\n+        c_path = os.path.join(tmp_dir, \"c.csv\")\n+        for x, path in [(a, a_path), (b, b_path)]:\n+            x.view(np.int16).ravel().tofile(path, sep=\",\")\n+\n+        # run test case\n+        subprocess.run([\"./test\", a_path, b_path, c_path], check=True, cwd=tmp_dir)\n+\n+        # read data and compare against reference\n+        c = np.genfromtxt(c_path, delimiter=\",\", dtype=np.int32)\n+        c_tri = c.reshape((M, N)).view(np.float32)\n+        c_ref = np.matmul(a.astype(np.float32), b.astype(np.float32))\n+        np.testing.assert_allclose(c_tri, c_ref * c_ref, atol=1e-4, rtol=0.)\n+\n+\n+def test_ttgir_to_ptx():\n+    src = \"\"\"\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32, \"triton_gpu.threads-per-warp\" = 32 : i32} {\n+  tt.func public @sum_kernel_0d1d(%arg0: !tt.ptr<i32>, %arg1: !tt.ptr<i32>) {\n+    tt.return\n+  }\n+}\n+\"\"\"\n+    with tempfile.TemporaryDirectory() as tmp_dir:\n+        kernel_path = os.path.join(tmp_dir, \"empty_kernel.ttgir\")\n+        with open(kernel_path, \"w\") as fp:\n+            fp.write(src)\n+        k = triton.compile(kernel_path, cc=80)\n+        ptx = k.asm[\"ptx\"]\n+        assert \".target sm_80\" in ptx\n+        assert \".address_size 64\" in ptx"}, {"filename": "python/triton/__init__.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -42,6 +42,7 @@\n     \"runtime\",\n     \"TensorWrapper\",\n     \"testing\",\n+    \"tools\",\n ]\n \n "}, {"filename": "python/triton/common/__init__.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1,3 +1,3 @@\n-from .build import _build\n+from .build import _build, cuda_include_dir, libcuda_dirs\n \n-__all__ = [\"_build\"]\n+__all__ = [\"_build\", \"libcuda_dirs\", \"cuda_include_dir\"]"}, {"filename": "python/triton/common/build.py", "status": "modified", "additions": 8, "deletions": 9, "changes": 17, "file_content_changes": "@@ -37,21 +37,20 @@ def quiet():\n         sys.stdout, sys.stderr = old_stdout, old_stderr\n \n \n+@functools.lru_cache()\n+def cuda_include_dir():\n+    base_dir = os.path.join(os.path.dirname(__file__), os.path.pardir)\n+    cuda_path = os.path.join(base_dir, \"third_party\", \"cuda\")\n+    return os.path.join(cuda_path, \"include\")\n+\n+\n def _build(name, src, srcdir):\n     if is_hip():\n         hip_lib_dir = os.path.join(rocm_path_dir(), \"lib\")\n         hip_include_dir = os.path.join(rocm_path_dir(), \"include\")\n     else:\n         cuda_lib_dirs = libcuda_dirs()\n-        base_dir = os.path.join(os.path.dirname(__file__), os.path.pardir)\n-        cuda_path = os.path.join(base_dir, \"third_party\", \"cuda\")\n-\n-        cu_include_dir = os.path.join(cuda_path, \"include\")\n-        triton_include_dir = os.path.join(os.path.dirname(__file__), \"include\")\n-        cuda_header = os.path.join(cu_include_dir, \"cuda.h\")\n-        triton_cuda_header = os.path.join(triton_include_dir, \"cuda.h\")\n-        if not os.path.exists(cuda_header) and os.path.exists(triton_cuda_header):\n-            cu_include_dir = triton_include_dir\n+        cu_include_dir = cuda_include_dir()\n     suffix = sysconfig.get_config_var('EXT_SUFFIX')\n     so = os.path.join(srcdir, '{name}{suffix}'.format(name=name, suffix=suffix))\n     # try to avoid setuptools if possible"}, {"filename": "python/triton/compiler/__init__.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1,4 +1,4 @@\n-from .compiler import CompiledKernel, compile\n+from .compiler import CompiledKernel, compile, instance_descriptor\n from .errors import CompilationError\n \n-__all__ = [\"compile\", \"CompiledKernel\", \"CompilationError\"]\n+__all__ = [\"compile\", \"instance_descriptor\", \"CompiledKernel\", \"CompilationError\"]"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 66, "deletions": 32, "changes": 98, "file_content_changes": "@@ -1255,15 +1255,21 @@ def abs(x, _builder=None):\n # Reductions\n # -----------------------\n \n-def _add_reduction_docstr(name: str) -> Callable[[T], T]:\n+def _add_reduction_docstr(name: str, return_indices_arg: str = None, tie_break_arg: str = None) -> Callable[[T], T]:\n \n     def _decorator(func: T) -> T:\n         docstr = \"\"\"\n     Returns the {name} of all elements in the :code:`input` tensor along the provided :code:`axis`\n \n     :param input: the input values\n-    :param axis: the dimension along which the reduction should be done\n-    \"\"\"\n+    :param axis: the dimension along which the reduction should be done\"\"\"\n+        if return_indices_arg is not None:\n+            docstr += f\"\"\"\n+    :param {return_indices_arg}: if true, return index corresponding to the {name} value\"\"\"\n+        if tie_break_arg is not None:\n+            docstr += f\"\"\"\n+    :param {tie_break_arg}: if true, return the left-most indices in case of ties for values that aren't NaN\"\"\"\n+\n         func.__doc__ = docstr.format(name=name)\n         return func\n \n@@ -1374,65 +1380,93 @@ def maximum(x, y):\n \n \n @jit\n-def _max_combine(a, b):\n-    return maximum(a, b)\n+def _argmax_combine(value1, index1, value2, index2, tie_break_left):\n+    if tie_break_left:\n+        tie = value1 == value2 and index1 < index2\n+    else:\n+        tie = False\n+    gt = value1 > value2 or tie\n+    v_ret = where(gt, value1, value2)\n+    i_ret = where(gt, index1, index2)\n+    return v_ret, i_ret\n \n \n @jit\n-def _argmax_combine(value1, index1, value2, index2):\n-    gt = value1 > value2\n-    value_ret = where(gt, value1, value2)\n-    index_ret = where(gt, index1, index2)\n-    return value_ret, index_ret\n+def _argmax_combine_tie_break_left(value1, index1, value2, index2):\n+    return _argmax_combine(value1, index1, value2, index2, True)\n \n \n @jit\n-@_add_reduction_docstr(\"maximum\")\n-def max(input, axis=None, return_indices=False):\n+def _argmax_combine_tie_break_fast(value1, index1, value2, index2):\n+    return _argmax_combine(value1, index1, value2, index2, False)\n+\n+\n+@jit\n+@_add_reduction_docstr(\"maximum\",\n+                       return_indices_arg=\"return_indices\",\n+                       tie_break_arg=\"return_indices_tie_break_left\")\n+def max(input, axis=None, return_indices=False, return_indices_tie_break_left=True):\n     input = _promote_reduction_input(input)\n     if return_indices:\n-        return _reduce_with_indices(input, axis, _argmax_combine)\n+        if return_indices_tie_break_left:\n+            return _reduce_with_indices(input, axis, _argmax_combine_tie_break_left)\n+        else:\n+            return _reduce_with_indices(input, axis, _argmax_combine_tie_break_fast)\n     else:\n-        return reduce(input, axis, _max_combine)\n+        return reduce(input, axis, maximum)\n \n \n @jit\n-@_add_reduction_docstr(\"maximum index\")\n-def argmax(input, axis):\n-    (_, ret) = max(input, axis, return_indices=True)\n+@_add_reduction_docstr(\"maximum index\", tie_break_arg=\"tie_break_left\")\n+def argmax(input, axis, tie_break_left=True):\n+    (_, ret) = max(input, axis, return_indices=True, return_indices_tie_break_left=tie_break_left)\n     return ret\n \n # min and argmin\n \n \n @jit\n-def _min_combine(a, b):\n-    # TODO: minimum/maximum doesn't get lowered to fmin/fmax...\n-    return minimum(a, b)\n-\n-\n-@jit\n-def _argmin_combine(value1, index1, value2, index2):\n-    lt = value1 < value2\n+def _argmin_combine(value1, index1, value2, index2, tie_break_left):\n+    if tie_break_left:\n+        tie = value1 == value2 and index1 < index2\n+    else:\n+        tie = False\n+    lt = value1 < value2 or tie\n     value_ret = where(lt, value1, value2)\n     index_ret = where(lt, index1, index2)\n     return value_ret, index_ret\n \n \n @jit\n-@_add_reduction_docstr(\"minimum\")\n-def min(input, axis=None, return_indices=False):\n+def _argmin_combine_tie_break_left(value1, index1, value2, index2):\n+    return _argmin_combine(value1, index1, value2, index2, True)\n+\n+\n+@jit\n+def _argmin_combine_tie_break_fast(value1, index1, value2, index2):\n+    return _argmin_combine(value1, index1, value2, index2, False)\n+\n+\n+@jit\n+@_add_reduction_docstr(\"minimum\",\n+                       return_indices_arg=\"return_indices\",\n+                       tie_break_arg=\"return_indices_tie_break_left\")\n+def min(input, axis=None, return_indices=False, return_indices_tie_break_left=True):\n     input = _promote_reduction_input(input)\n     if return_indices:\n-        return _reduce_with_indices(input, axis, _argmin_combine)\n+        if return_indices_tie_break_left:\n+            return _reduce_with_indices(input, axis, _argmin_combine_tie_break_left)\n+        else:\n+            return _reduce_with_indices(input, axis, _argmin_combine_tie_break_fast)\n     else:\n-        return reduce(input, axis, _min_combine)\n+        return reduce(input, axis, minimum)\n \n \n @jit\n-@_add_reduction_docstr(\"minimum index\")\n-def argmin(input, axis):\n-    _, ret = min(input, axis, return_indices=True)\n+@_add_reduction_docstr(\"minimum index\",\n+                       tie_break_arg=\"tie_break_left\")\n+def argmin(input, axis, tie_break_left=True):\n+    _, ret = min(input, axis, return_indices=True, return_indices_tie_break_left=tie_break_left)\n     return ret\n \n "}, {"filename": "python/triton/language/semantic.py", "status": "modified", "additions": 17, "deletions": 3, "changes": 20, "file_content_changes": "@@ -775,7 +775,7 @@ def cast(input: tl.tensor,\n # ===----------------------------------------------------------------------===//\n \n \n-def _str_to_cache_modifier(cache_modifier):\n+def _str_to_load_cache_modifier(cache_modifier):\n     cache = ir.CACHE_MODIFIER.NONE  # default\n     if cache_modifier:\n         if cache_modifier == \".ca\":\n@@ -787,6 +787,20 @@ def _str_to_cache_modifier(cache_modifier):\n     return cache\n \n \n+def _str_to_store_cache_modifier(cache_modifier):\n+    cache = ir.CACHE_MODIFIER.NONE  # default\n+    if cache_modifier:\n+        if cache_modifier == \".wb\":\n+            cache = ir.CACHE_MODIFIER.WB\n+        elif cache_modifier == \".cg\":\n+            cache = ir.CACHE_MODIFIER.CG\n+        elif cache_modifier == \".cs\":\n+            cache = ir.CACHE_MODIFIER.CS\n+        else:\n+            raise ValueError(f\"Cache modifier {cache_modifier} not supported\")\n+    return cache\n+\n+\n def _str_to_eviction_policy(eviction_policy):\n     eviction = ir.EVICTION_POLICY.NORMAL  # default\n     if eviction_policy:\n@@ -929,7 +943,7 @@ def load(ptr: tl.tensor,\n          is_volatile: bool,\n          builder: ir.builder) -> tl.tensor:\n     # Cache, eviction and padding options\n-    cache = _str_to_cache_modifier(cache_modifier)\n+    cache = _str_to_load_cache_modifier(cache_modifier)\n     eviction = _str_to_eviction_policy(eviction_policy)\n     padding = _str_to_padding_option(padding_option)\n \n@@ -1018,7 +1032,7 @@ def store(ptr: tl.tensor,\n           eviction_policy: str,\n           builder: ir.builder) -> tl.tensor:\n     # Cache and eviction options\n-    cache = _str_to_cache_modifier(cache_modifier)\n+    cache = _str_to_store_cache_modifier(cache_modifier)\n     eviction = _str_to_eviction_policy(eviction_policy)\n \n     if ptr.type.is_ptr() and ptr.type.element_ty.is_block():"}, {"filename": "python/triton/runtime/autotuner.py", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -70,10 +70,11 @@ def _bench(self, *args, config, **meta):\n             )\n         # augment meta-parameters with tunable ones\n         current = dict(meta, **config.kwargs)\n+        full_nargs = {**self.nargs, **current}\n \n         def kernel_call():\n             if config.pre_hook:\n-                config.pre_hook(self.nargs)\n+                config.pre_hook(full_nargs)\n             self.hook(args)\n             self.fn.run(*args, num_warps=config.num_warps, num_stages=config.num_stages, **current)\n         try:\n@@ -106,7 +107,8 @@ def run(self, *args, **kwargs):\n             config = self.configs[0]\n         self.best_config = config\n         if config.pre_hook is not None:\n-            config.pre_hook(self.nargs)\n+            full_nargs = {**self.nargs, **kwargs, **self.best_config.kwargs}\n+            config.pre_hook(full_nargs)\n         return self.fn.run(*args, num_warps=config.num_warps, num_stages=config.num_stages, **kwargs, **config.kwargs)\n \n     def prune_configs(self, kwargs):"}, {"filename": "python/triton/runtime/jit.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -71,7 +71,7 @@ def visit_Attribute(self, node):\n         lhs = self.visit(node.value)\n         while isinstance(lhs, ast.Attribute):\n             lhs = self.visit(lhs.value)\n-        if lhs is None or lhs.__name__ == \"triton\":\n+        if lhs is None or getattr(lhs, \"__name__\", \"\") == \"triton\":\n             return None\n         return getattr(lhs, node.attr)\n "}, {"filename": "python/triton/tools/aot.py", "status": "removed", "additions": 0, "deletions": 117, "changes": 117, "file_content_changes": "@@ -1,117 +0,0 @@\n-import argparse\n-import sys\n-\n-from .._C.libtriton.triton import ir\n-# import triton.compiler.compiler as tc\n-from ..compiler.compiler import (get_amdgpu_arch_fulldetails, llir_to_amdgcn_and_hsaco,\n-                                 llir_to_ptx, optimize_ttgir, optimize_ttir,\n-                                 ttgir_to_llir, ttir_to_ttgir)\n-\n-if __name__ == '__main__':\n-\n-    # valid source and target formats\n-    VALID_FORMATS = ['triton-ir', 'triton-gpu-ir', 'llvm-ir', 'ptx', 'amdgcn']\n-\n-    # set up the argument parser\n-    # TODO: conditional requirements\n-    parser = argparse.ArgumentParser()\n-    parser.add_argument('src', help=\"Source file to compile\")\n-    parser.add_argument('--target', required=True,\n-                        help=\"Target format, one of: \" + ', '.join(VALID_FORMATS))\n-    parser.add_argument('--sm', type=int, help=\"Compute capability to compile for\")\n-    parser.add_argument('--ptx-version', type=int, help=\"PTX version to compile for\")\n-    parser.add_argument('--gfx', type=str, help=\"AMDGPU target to compile for\")\n-    parser.add_argument('--triple', type=str, help=\"target triple, for example: amdgcn-amd-amdhsa\")\n-    parser.add_argument('--features', type=str, help=\"target features, for example: +sramecc,-xnack\")\n-    parser.add_argument('--num_warps', type=int, help=\"number of warps to compile ttgir for\")\n-\n-    # parse the args\n-    args = parser.parse_args()\n-\n-    # TODO: clean-up and re-use triton.compiler primitive functions\n-    # check for validity of format arguments\n-    if args.target not in VALID_FORMATS:\n-        print(\"Invalid target format: \" + args.target)\n-        sys.exit(0)\n-\n-    # parse source file to MLIR module\n-    context = ir.context()\n-    module = ir.parse_mlir_module(args.src, context)\n-    module.context = context\n-\n-    # optimizer triton-ir\n-    module = optimize_ttir(module, arch=args.sm)\n-    if args.target == 'triton-ir':\n-        print(module.str())\n-        sys.exit(0)\n-\n-    if not args.num_warps:\n-        args.num_warps = 4\n-\n-    # llvm-ir -> amdgcn\n-    if args.target == 'amdgcn':\n-        # auto detect available architecture and features\n-        # if nothing detected, set with default values\n-        arch_details = get_amdgpu_arch_fulldetails()\n-        if not arch_details:\n-            arch_name = \"\"\n-            arch_triple = \"amdgcn-amd-amdhsa\"\n-            arch_features = \"\"\n-        else:\n-            arch_triple, arch_name, arch_features = arch_details\n-\n-        # stop processing if architecture name is not automatically detected and is not set manually\n-        if not args.gfx and not arch_name:\n-            raise argparse.ArgumentError(None, \"Must specify --gfx for AMDGCN compilation\")\n-\n-        # rewrite default and automatically detected values with manually provided data\n-        if args.gfx:\n-            arch_name = args.gfx\n-        if args.triple:\n-            arch_triple = args.triple\n-        if args.features:\n-            arch_features = args.features\n-\n-        # triton-ir -> triton-gpu-ir\n-        # use compute_capability == 80\n-        module = ttir_to_ttgir(module, num_warps=args.num_warps)  # num_stages=3, compute_capability=80)\n-        module = optimize_ttgir(module, num_stages=3, arch=80)\n-        # triton-gpu-ir -> llvm-ir\n-        # use compute_capability == 80\n-        module = ttgir_to_llir(module, extern_libs=None, arch=80)\n-        # llvm-ir -> amdgcn asm, hsaco binary\n-        module, hsaco_path = llir_to_amdgcn_and_hsaco(module, arch_name, arch_triple, arch_features)\n-\n-        print(hsaco_path)\n-        print(module)\n-        sys.exit(0)\n-\n-    if not args.sm:\n-        raise argparse.ArgumentError(None, \"Must specify --sm for PTX compilation\")\n-\n-    # triton-ir -> triton-gpu-ir\n-    module = ttir_to_ttgir(module, num_warps=args.num_warps)\n-    module = optimize_ttgir(module, num_stages=3, arch=args.sm)\n-    if args.target == 'triton-gpu-ir':\n-        print(module.str())\n-        sys.exit(0)\n-\n-    # triton-gpu-ir -> llvm-ir\n-    module = ttgir_to_llir(module, extern_libs=None, arch=args.sm)\n-    if args.target == 'llvm-ir':\n-        print(module)\n-        sys.exit(0)\n-\n-    # llvm-ir -> ptx\n-    if args.target == 'ptx':\n-        if not args.ptx_version:\n-            raise argparse.ArgumentError(None, \"Must specify --ptx-version for PTX compilation\")\n-        module = llir_to_ptx(module, arch=args.sm, ptx_version=args.ptx_version)\n-\n-    # llvm-ir -> amdgcn\n-    if args.target == 'amdgcn':\n-        if not args.gfx:\n-            raise argparse.ArgumentError(None, \"Must specify --gfx for AMDGCN compilation\")\n-        module, hsaco_path = llir_to_amdgcn_and_hsaco(module, args.gfx)\n-\n-    print(module)"}, {"filename": "python/triton/tools/compile.c", "status": "added", "additions": 64, "deletions": 0, "changes": 64, "file_content_changes": "@@ -0,0 +1,64 @@\n+/* clang-format off */\n+#include <stdio.h>\n+#include <stdint.h>\n+#include <inttypes.h>\n+#include <string.h>\n+#include <cuda.h>\n+\n+\n+// helpers to check for cuda errors\n+#define CUDA_CHECK(ans) {{\\\n+    gpuAssert((ans), __FILE__, __LINE__);\\\n+  }}\\\n+\n+static inline void gpuAssert(CUresult code, const char *file, int line) {{\n+  if (code != CUDA_SUCCESS) {{\n+    const char *prefix = \"Triton Error [CUDA]: \";\n+    const char *str;\n+    cuGetErrorString(code, &str);\n+    char err[1024] = {{0}};\n+    strcat(err, prefix);\n+    strcat(err, str);\n+    printf(\"%s\\\\n\", err);\n+    exit(code);\n+  }}\n+}}\n+\n+// globals\n+#define CUBIN_NAME {kernel_name}_cubin\n+CUmodule {kernel_name}_mod = NULL;\n+CUfunction {kernel_name}_func = NULL;\n+unsigned char CUBIN_NAME[{bin_size}] = {{ {bin_data} }};\n+\n+\n+void unload_{kernel_name}(void) {{\n+    CUDA_CHECK(cuModuleUnload({kernel_name}_mod));\n+}}\n+\n+// TODO: some code duplication with `runtime/backend/cuda.c`\n+void load_{kernel_name}() {{\n+    int dev = 0;\n+    void *bin = (void *)&CUBIN_NAME;\n+    int shared = {shared};\n+    CUDA_CHECK(cuModuleLoadData(&{kernel_name}_mod, bin));\n+    CUDA_CHECK(cuModuleGetFunction(&{kernel_name}_func, {kernel_name}_mod, \"{kernel_name}\"));\n+    // set dynamic shared memory if necessary\n+    int shared_optin;\n+    CUDA_CHECK(cuDeviceGetAttribute(&shared_optin, CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN, dev));\n+    if (shared > 49152 && shared_optin > 49152) {{\n+      CUDA_CHECK(cuFuncSetCacheConfig({kernel_name}_func, CU_FUNC_CACHE_PREFER_SHARED));\n+      CUDA_CHECK(cuFuncSetAttribute({kernel_name}_func, CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES, shared_optin))\n+    }}\n+}}\n+\n+/*\n+{kernel_docstring}\n+*/\n+CUresult {kernel_name}(CUstream stream, unsigned int gX,unsigned int gY,unsigned int gZ,unsigned int numWarps, {signature}) {{\n+    if ({kernel_name}_func == NULL)\n+       load_{kernel_name}();\n+    void *args[{num_args}] = {{ {arg_pointers} }};\n+    // TODO: shared memory\n+    if(gX * gY * gZ > 0)\n+      return cuLaunchKernel({kernel_name}_func, gX, gY, gZ, numWarps * 32, 1, 1, {shared}, stream, args, NULL);\n+}}"}, {"filename": "python/triton/tools/compile.h", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "file_content_changes": "@@ -0,0 +1,15 @@\n+#ifndef TT_KERNEL_INCLUDES\n+#define TT_KERNEL_INCLUDES\n+\n+#include <cuda.h>\n+#include <inttypes.h>\n+#include <stdint.h>\n+#include <stdio.h>\n+\n+#endif\n+\n+void unload_{kernel_name}(void);\n+void load_{kernel_name}(void);\n+// tt-linker: {kernel_name}:{signature}\n+CUresult{kernel_name}(CUstream stream, unsigned int gX, unsigned int gY,\n+                      unsigned int gZ, unsigned int numWarps, {signature});"}, {"filename": "python/triton/tools/compile.py", "status": "added", "additions": 103, "deletions": 0, "changes": 103, "file_content_changes": "@@ -0,0 +1,103 @@\n+import binascii\n+import importlib.util\n+import sys\n+from argparse import ArgumentParser\n+from pathlib import Path\n+\n+import triton\n+from triton.compiler.code_generator import kernel_suffix\n+from triton.compiler.make_launcher import ty_to_cpp\n+\n+desc = \"\"\"\n+Triton ahead-of-time compiler:\n+\n+This program compiles the kernel with name `kernel-name` in the file at the\n+provided `path` into self-contained C source-code that embeds the `cubin`\n+data along with utilities to load, unload and launch the kernel.\n+\n+signature is provided as a list of (optionally divisibility-hinted) types\n+or constexpr values, e.g.\n+\n+`compile.py --kernel-name kernel --signature \"*f32:16, i32:16, 1024, i32\" --out-name kernel /path/to/kernel.py`\n+\n+will compile triton.JITFunction of name `kernel` inside the file `/path/to/kernel.py`.\n+Said kernel will be specialized such that argument 0, 1 are assumed to be multiple of 16,\n+and argument 2 is assumed to be a compile-time constant of value 1024, i.e. it won't be part of the generated prototype.\n+\n+The resulting entry point will have signature\n+\n+CUresult kernel_{specialization_suffix}(CUstream stream, unsigned gX, unsigned gY, unsigned gZ, unsigned numWarps, float* arg0, int32_t arg1, int32_t arg2)\n+\n+Different such specialized entry points can be combined using the `linker.py` script.\n+\n+NOTE: when resolving the scope of /path/to/kernel.py, the file will be executed from within its parent directory with the python interpreter\n+used to run this `compile.py` script\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+\n+    # command-line arguments\n+    parser = ArgumentParser(description=desc)\n+    parser.add_argument(\"path\", help=\"Path to Python source containing desired kernel in its scope. File will be executed.\")\n+    parser.add_argument(\"--kernel-name\", \"-n\", type=str, default=\"\")\n+    parser.add_argument(\"--out-path\", \"-o\", type=Path, help=\"Out filename\")\n+    parser.add_argument(\"--out-name\", \"-on\", type=str, default=None, help=\"Out name for the compiled kernel\")\n+    parser.add_argument(\"--signature\", \"-s\", type=str, help=\"Signature of the kernel\")\n+    args = parser.parse_args()\n+\n+    # execute python sources and extract functions wrapped in JITFunction\n+    arg_path = Path(args.path)\n+    sys.path.insert(0, str(arg_path.parent))\n+    spec = importlib.util.spec_from_file_location(arg_path.stem, arg_path)\n+    mod = importlib.util.module_from_spec(spec)\n+    spec.loader.exec_module(mod)\n+    kernel = getattr(mod, args.kernel_name)\n+\n+    # validate and parse signature\n+    signature = list(map(lambda s: s.strip(\" \"), args.signature.split(\",\")))\n+\n+    def constexpr(s):\n+        try:\n+            ret = int(s)\n+            return ret\n+        except ValueError:\n+            pass\n+        try:\n+            ret = float(s)\n+            return ret\n+        except ValueError:\n+            pass\n+        return None\n+    hints = {i: constexpr(s.split(\":\")[1]) for i, s in enumerate(signature) if \":\" in s}\n+    hints = {k: v for k, v in hints.items() if v is not None}\n+    constexprs = {i: constexpr(s) for i, s in enumerate(signature)}\n+    constexprs = {k: v for k, v in constexprs.items() if v is not None}\n+    signature = {i: s.split(\":\")[0] for i, s in enumerate(signature) if i not in constexprs}\n+\n+    # compile ast into cubin\n+    for h in hints.values():\n+        assert h in [1, 16], f\"Only 1 and 16 are valid hints, got {h}\"\n+    divisible_by_16 = [i for i, h in hints.items() if h == 16]\n+    equal_to_1 = [i for i, h in hints.items() if h == 1]\n+    config = triton.compiler.instance_descriptor(divisible_by_16=divisible_by_16, equal_to_1=equal_to_1)\n+    ccinfo = triton.compile(kernel, signature=signature, constants=constexprs, configs=[config], num_warps=1)\n+    arg_names = [kernel.arg_names[i] for i in signature.keys()]\n+\n+    # dump C stub code\n+    suffix = kernel_suffix(signature.values(), config)\n+    func_name = '_'.join([kernel.__name__, suffix])\n+    hex_ = str(binascii.hexlify(ccinfo.asm[\"cubin\"]))[2:-1]\n+    params = {\n+        \"kernel_name\": func_name,\n+        \"bin_size\": len(hex_),\n+        \"bin_data\": \", \".join([f\"0x{x}{y}\" for x, y in zip(hex_[::2], hex_[1::2])]),\n+        \"signature\": \", \".join([f\"{ty_to_cpp(ty)} {name}\" for name, ty in zip(arg_names, signature.values())]),\n+        \"arg_pointers\": \", \".join([f\"&{arg}\" for arg in arg_names]),\n+        \"num_args\": len(arg_names),\n+        \"kernel_docstring\": \"\",\n+        \"shared\": ccinfo.shared,\n+    }\n+    for ext in ['h', 'c']:\n+        template_path = Path(__file__).parent / f\"compile.{ext}\"\n+        with args.out_path.with_suffix(f\".{suffix}.{ext}\").open(\"w\") as fp:\n+            fp.write(Path(template_path).read_text().format(**params))"}, {"filename": "python/triton/tools/link.py", "status": "added", "additions": 192, "deletions": 0, "changes": 192, "file_content_changes": "@@ -0,0 +1,192 @@\n+from collections import defaultdict\n+from pathlib import Path\n+from typing import Sequence, Union\n+\n+from dataclasses import dataclass\n+\n+\n+def _exists(x):\n+    return x is not None\n+\n+\n+class LinkerError(Exception):\n+    pass\n+\n+\n+@dataclass\n+class KernelLinkerMeta:\n+    arg_names: Sequence[str]\n+    arg_ctypes: Sequence[str]\n+    sizes: Sequence[Union[int, None]]\n+    suffix: str\n+    num_specs: int\n+    \"\"\" number of specialized arguments \"\"\"\n+\n+\n+class HeaderParser:\n+    def __init__(self) -> None:\n+        import re\n+\n+        # [kernel_name, c signature]\n+        self.linker_directives = re.compile(\"//[\\\\s]*tt-linker:[\\\\s]*([\\\\w]+):(.+)\")\n+        # [name, suffix]\n+        self.kernel_name = re.compile(\"([\\\\w]+)_([\\\\w]+)\")\n+        # [(argnum, d|c)]\n+        self.kernel_suffix = re.compile(\"([0-9]+)([c,d])\")\n+        # [(type, name)]\n+        self.c_sig = re.compile(\"[\\\\s]*(\\\\w+)\\\\s(\\\\w+)[,]?\")\n+\n+        self.kernels = defaultdict(list)\n+\n+    def extract_linker_meta(self, header: str):\n+\n+        for ln in header.splitlines():\n+            if ln.startswith(\"//\"):\n+                m = self.linker_directives.match(ln)\n+                if _exists(m):\n+                    ker_name, c_sig = m.group(1), m.group(2)\n+                    name, suffix = self._match_name(ker_name)\n+                    c_types, arg_names = self._match_c_sig(c_sig)\n+                    num_specs, sizes = self._match_suffix(suffix)\n+                    self._add_kernel(\n+                        name,\n+                        KernelLinkerMeta(\n+                            arg_names=arg_names,\n+                            arg_ctypes=c_types,\n+                            sizes=sizes,\n+                            suffix=suffix,\n+                            num_specs=num_specs,\n+                        ),\n+                    )\n+\n+    def _match_name(self, ker_name: str):\n+        m = self.kernel_name.match(ker_name)\n+        if _exists(m):\n+            name, suffix = m.group(1), m.group(2)\n+            return name, suffix\n+        raise LinkerError(f\"{ker_name} is not a valid kernel name\")\n+\n+    def _match_c_sig(self, c_sig: str):\n+        m = self.c_sig.findall(c_sig)\n+        if len(m):\n+            tys, args = [], []\n+            for (ty, arg_name) in m:\n+                tys.append(ty)\n+                args.append(arg_name)\n+            return tys, args\n+\n+        raise LinkerError(f\"{c_sig} is not a valid argument signature\")\n+\n+    def _match_suffix(self, suffix: str):\n+        m = self.kernel_suffix.findall(suffix)\n+        if not len(m):\n+            raise LinkerError(f\"{suffix} is not a valid kernel suffix\")\n+        sizes = []\n+        num_specs = len(m)\n+        s2i = {\"c\": 1, \"d\": 16}\n+        for (argnum, arg_size_ann) in m:\n+            while len(sizes) < int(argnum):\n+                sizes.append(None)\n+\n+            sizes.append(s2i[arg_size_ann])\n+        return num_specs, sizes\n+\n+    def _add_kernel(self, name: str, ker: KernelLinkerMeta):\n+        if name in self.kernels:\n+            last: KernelLinkerMeta = self.kernels[name][-1]\n+\n+            for (cur, new_) in zip(last.arg_ctypes, ker.arg_ctypes):\n+                if cur != new_:\n+                    raise LinkerError(\n+                        f\"Mismatched signature for kernel {name}: \\n\\texisting sig is: {','.join(last.arg_ctypes)}\\n\\tcurrent is: {','.join(ker.arg_ctypes)}\"\n+                    )\n+\n+        self.kernels[name].append(ker)\n+\n+\n+def gen_signature(m):\n+    return \", \".join([f\"{ty} {arg}\" for ty, arg in zip(m.arg_ctypes, m.arg_names)])\n+\n+\n+def make_decls(name: str, metas: Sequence[KernelLinkerMeta]) -> str:\n+    return f\"\"\"\n+CUresult {name}(CUstream stream, unsigned int gX, unsigned int gY, unsigned int gZ, unsigned int numWarps, {gen_signature(metas[-1])});\n+void load_{name}();\n+void unload_{name}();\n+    \"\"\"\n+\n+\n+def make_kernel_dispatcher(name: str, metas: Sequence[KernelLinkerMeta]) -> str:\n+    src = f\"// launcher for: {name}\\n\"\n+    for meta in sorted(metas, key=lambda m: -m.num_specs):\n+        src += f\"CUresult {name}_{meta.suffix}(CUstream stream, unsigned int gX, unsigned int gY, unsigned int gZ, unsigned int numWarps, {gen_signature(meta)});\\n\"\n+    src += \"\\n\"\n+\n+    src += f\"CUresult {name}(CUstream stream, unsigned int gX, unsigned int gY, unsigned int gZ, unsigned int numWarps, {gen_signature(metas[-1])}){{\"\n+    src += \"\\n\"\n+    for meta in sorted(metas, key=lambda m: -m.num_specs):\n+        cond_fn = lambda val, hint: f\"({val} % {hint} == 0)\" if hint == 16 else f\"({val} == {hint})\" if hint == 1 else None\n+        conds = \" && \".join([cond_fn(val, hint) for val, hint in zip(meta.arg_names, meta.sizes) if hint is not None])\n+        src += f\"  if ({conds})\\n\"\n+        src += f\"    return {name}_{meta.suffix}(stream, gX, gY, gZ, numWarps, {', '.join(meta.arg_names)});\\n\"\n+    src += \"}\\n\"\n+\n+    for mode in [\"load\", \"unload\"]:\n+        src += f\"\\n// {mode} for: {name}\\n\"\n+        for meta in sorted(metas, key=lambda m: -m.num_specs):\n+            src += f\"void {mode}_{name}_{meta.suffix}();\\n\"\n+        src += f\"void {mode}_{name}() {{\"\n+        src += \"\\n\"\n+        for meta in sorted(metas, key=lambda m: -m.num_specs):\n+            src += f\"  {mode}_{name}_{meta.suffix}();\\n\"\n+        src += \"}\\n\"\n+    return src\n+\n+\n+desc = \"\"\"\n+Triton ahead-of-time linker:\n+\n+This program takes in header files generated by compile.py, and generates a\n+single entry-point responsible for dispatching the user's input to the right\n+kernel given the specializations that were compiled.\n+\n+Example usage:\n+python link.py /path/to/headers/*.h -o kernel_name\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    from argparse import ArgumentParser\n+\n+    parser = ArgumentParser(description=desc)\n+    parser.add_argument(\n+        \"headers\",\n+        nargs=\"+\",\n+        help=\"Paths to header files to link. Must include linker directive annotations (autogenerated by ttc)\",\n+    )\n+    parser.add_argument(\"--out\", \"-o\", type=Path, help=\"Out filename\")\n+    parser.add_argument(\"--prefix\", type=str, default=\"\", help=\"String to prefix kernel dispatcher names\")\n+    args = parser.parse_args()\n+\n+    # metadata\n+    parser = HeaderParser()\n+    includes = []\n+    for header in args.headers:\n+        h_path = Path(header)\n+        h_str = h_path.read_text()\n+        includes.append(h_path.name)\n+        parser.extract_linker_meta(h_str)\n+\n+    # generate headers\n+    decls = [make_decls(name, meta) for name, meta in parser.kernels.items()]\n+    with args.out.with_suffix(\".h\").open(\"w\") as fp:\n+        fp.write(\"#include <cuda.h>\\n\" + \"\\n\".join(decls))\n+\n+    # generate source\n+    defs = [make_kernel_dispatcher(name, meta) for name, meta in parser.kernels.items()]\n+    with args.out.with_suffix(\".c\").open(\"w\") as fp:\n+        out = \"\"\n+        out += \"#include <cuda.h>\\n\"\n+        out += \"#include <stdint.h>\\n\"\n+        out += \"\\n\"\n+        out += \"\\n\".join(defs)\n+        fp.write(out)"}, {"filename": "test/Conversion/invalid.mlir", "status": "added", "additions": 41, "deletions": 0, "changes": 41, "file_content_changes": "@@ -0,0 +1,41 @@\n+// RUN: triton-opt %s -split-input-file -verify-diagnostics\n+\n+#mma0 = #triton_gpu.mma<{versionMajor=2, warpsPerCTA=[1,1]}>\n+#dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma0, kWidth=2}>\n+#dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma0, kWidth=2}>\n+module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n+  tt.func @convert_dot(%A: tensor<16x16xf32, #dot_operand_a>, %B: tensor<16x16xf16, #dot_operand_b>, %C: tensor<16x16xf32, #mma0>) {\n+    // expected-error@+1 {{element types of operands A and B must match}}\n+    %D = tt.dot %A, %B, %C {allowTF32 = true, transA = false, transB = false} :\n+        tensor<16x16xf32, #dot_operand_a> * tensor<16x16xf16, #dot_operand_b> -> tensor<16x16xf32, #mma0>\n+    tt.return\n+  }\n+}\n+\n+// -----\n+\n+#mma0 = #triton_gpu.mma<{versionMajor=2, warpsPerCTA=[1,1]}>\n+#dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma0, kWidth=1}>\n+#dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma0, kWidth=2}>\n+module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n+  tt.func @convert_dot(%A: tensor<16x16xf16>, %B: tensor<16x16xf16, #dot_operand_b>, %C: tensor<16x16xf32, #mma0>) {\n+    // expected-error@+1 {{mismatching encoding between A and B operands}}\n+    %D = tt.dot %A, %B, %C {allowTF32 = true, transA = false, transB = false} :\n+        tensor<16x16xf16> * tensor<16x16xf16, #dot_operand_b> -> tensor<16x16xf32, #mma0>\n+    tt.return\n+  }\n+}\n+\n+// -----\n+\n+#mma0 = #triton_gpu.mma<{versionMajor=2, warpsPerCTA=[1,1]}>\n+#dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma0, kWidth=1}>\n+#dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma0, kWidth=2}>\n+module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n+  tt.func @convert_dot(%A: tensor<16x16xf16, #dot_operand_a>, %B: tensor<16x16xf16, #dot_operand_b>, %C: tensor<16x16xf32, #mma0>) {\n+    // expected-error@+1 {{mismatching kWidth between A and B operands}}\n+    %D = tt.dot %A, %B, %C {allowTF32 = true, transA = false, transB = false} :\n+        tensor<16x16xf16, #dot_operand_a> * tensor<16x16xf16, #dot_operand_b> -> tensor<16x16xf32, #mma0>\n+    tt.return\n+  }\n+}"}, {"filename": "test/Target/tritongpu_to_llvmir.mlir", "status": "removed", "additions": 0, "deletions": 16, "changes": 16, "file_content_changes": "@@ -1,16 +0,0 @@\n-// RUN: %PYTHON -m triton.tools.aot %s --target=llvm-ir --sm=80 | FileCheck %s\n-\n-// == LLVM IR check begin ==\n-// CHECK-LABEL: ; ModuleID = 'LLVMDialectModule'\n-// CHECK: define void @test_empty_kernel\n-// CHECK: !nvvm.annotations\n-// CHECK: !{ptr @test_empty_kernel, !\"maxntidx\", i32 128}\n-\n-module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-\n-tt.func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n-\n-  tt.return\n-}\n-\n-}"}, {"filename": "test/Target/tritongpu_to_llvmir_noinline.mlir", "status": "removed", "additions": 0, "deletions": 22, "changes": 22, "file_content_changes": "@@ -1,22 +0,0 @@\n-// RUN: %PYTHON -m triton.tools.aot %s --target=llvm-ir --sm=80 | FileCheck %s\n-\n-// == LLVM IR check begin ==\n-// CHECK-LABEL: ; ModuleID = 'LLVMDialectModule'\n-// CHECK: define void @test_func\n-// CHECK: define void @test_kernel\n-// CHECK: tail call void @test_func\n-\n-module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-\n-tt.func @test_func(%lb : index, %A : !tt.ptr<f16>) attributes { noinline = true } {\n-  %0 = arith.constant 1.0 : f16\n-  tt.store %A, %0 : f16\n-  tt.return\n-}\n-\n-tt.func @test_kernel(%lb : index, %A : !tt.ptr<f16>) {\n-  tt.call @test_func(%lb, %A) : (index, !tt.ptr<f16>) -> ()\n-  tt.return\n-}\n-\n-}"}, {"filename": "test/Target/tritongpu_to_ptx.mlir", "status": "removed", "additions": 0, "deletions": 14, "changes": 14, "file_content_changes": "@@ -1,14 +0,0 @@\n-// RUN: %PYTHON -m triton.tools.aot %s --target=ptx --sm=80 --ptx-version=63 | FileCheck %s\n-// CHECK-LABEL: // Generated by LLVM NVPTX Back-End\n-// CHECK: .version 6.3\n-// CHECK: .target sm_80\n-// CHECK: .address_size 64\n-\n-module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n-\n-tt.func @test_empty_kernel(%lb : index, %A : !tt.ptr<f16>) {\n-\n-  tt.return\n-}\n-\n-}"}, {"filename": "test/TritonGPU/dot-operands.mlir", "status": "modified", "additions": 62, "deletions": 4, "changes": 66, "file_content_changes": "@@ -15,10 +15,12 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n // CHECK: tt.func @push_elementwise1\n // CHECK: %[[ALOAD:.*]] = tt.load %arg0\n-// CHECK: %[[ACVT:.*]] = triton_gpu.convert_layout %[[ALOAD]]\n-// CHECK: %[[AF8E5:.*]] = tt.bitcast %[[ACVT]]\n-// CHECK: %[[AF16:.*]] = tt.fp_to_fp %[[AF8E5]]\n-// CHECK: %[[C:.*]] = tt.dot %[[AF16]]\n+// CHECK: %[[ACVT:.*]] = triton_gpu.convert_layout %[[ALOAD]] {{.*}} #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 4}>>\n+// CHECK: %[[AF8E5:.*]] = tt.bitcast %[[ACVT]] {{.*}} #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 4}>>\n+// CHECK: %[[AF16:.*]] = tt.fp_to_fp %[[AF8E5]] {{.*}} #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 4}>>\n+// CHECK: %[[BCVT:.*]] = triton_gpu.convert_layout %{{.*}} : {{.*}} tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 4}>>\n+// CHECK: %[[C:.*]] = tt.dot %[[AF16]], %[[BCVT]]\n+// CHECK-SAME: tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 4}>> * tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 4}>> -> tensor<16x16xf32, #mma>\n // CHECK: tt.return %[[C]] : tensor<16x16xf32, #mma>\n tt.func @push_elementwise1(\n                    %pa: tensor<16x16x!tt.ptr<i8>, #ALR> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n@@ -125,4 +127,60 @@ tt.func @push_elementwise5(\n   tt.return %newc : tensor<16x16xf32, #Cv1>\n }\n \n+// CHECK: tt.func @succeeds_if_arg_is_not_convert_layout\n+// CHECK: %[[ALOAD:.*]] = tt.load %arg0\n+// CHECK: %[[ACVT:.*]] = triton_gpu.convert_layout %[[ALOAD]]\n+// CHECK: %[[AF8E5:.*]] = tt.bitcast %[[ACVT]]\n+// CHECK: %[[AF16:.*]] = tt.fp_to_fp %[[AF8E5]]\n+// CHECK: %[[C:.*]] = tt.dot %[[AF16]]\n+// CHECK: tt.return %[[C]] : tensor<16x16xf32, #mma>\n+tt.func @succeeds_if_arg_is_not_convert_layout(\n+                   %pa: tensor<16x16x!tt.ptr<i8>, #ALR> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n+                   %pb: tensor<16x16x!tt.ptr<f16>, #BLC> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n+                   %c: tensor<16x16xf32, #Cv2>) -> tensor<16x16xf32, #Cv2>{\n+  %ai8 = tt.load %pa {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xi8, #ALR>\n+  %dotai8 = triton_gpu.convert_layout %ai8 : (tensor<16x16xi8, #ALR>) -> tensor<16x16xi8, #Av2>\n+  %b = tt.load %pb {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #BLC>\n+  %dotaf8 = tt.bitcast %dotai8 : tensor<16x16xi8, #Av2> -> tensor<16x16xf8E5M2, #Av2>\n+  %dota = tt.fp_to_fp %dotaf8 : tensor<16x16xf8E5M2, #Av2> -> tensor<16x16xf16, #Av2>\n+  %dotb = triton_gpu.convert_layout %b : (tensor<16x16xf16, #BLC>) -> tensor<16x16xf16, #Bv2>\n+  %newc = tt.dot %dota, %dotb, %c {allowTF32 = true, transA = false, transB = false} : tensor<16x16xf16, #Av2> * tensor<16x16xf16, #Bv2> -> tensor<16x16xf32, #Cv2>\n+  tt.return %newc : tensor<16x16xf32, #Cv2>\n+}\n+\n+}\n+\n+// -----\n+\n+#blockedA = #triton_gpu.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n+#blockedB = #triton_gpu.blocked<{sizePerThread = [2, 1], threadsPerWarp = [8, 4], warpsPerCTA = [1, 4], order = [0, 1]}>\n+#mma = #triton_gpu.mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [1, 4]}>\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n+\n+// CHECK: #[[BA:.*]] = #triton_gpu.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n+// CHECK: #[[BB:.*]] = #triton_gpu.blocked<{sizePerThread = [2, 1], threadsPerWarp = [8, 4], warpsPerCTA = [1, 4], order = [0, 1]}>\n+// CHECK: #[[MMA:.*]] = #triton_gpu.mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [1, 4]}>\n+\n+// CHECK: tt.func @push_convert_both_operands\n+// CHECK: %[[ALOAD:.*]] = tt.load %{{.*}} {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #[[BA]]>\n+// CHECK: %[[ACVT:.*]] = triton_gpu.convert_layout %[[ALOAD]] : (tensor<16x16xf16, #[[BA]]>) -> tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #[[MMA]], kWidth = 2}>>\n+// CHECK: %[[BLOAD:.*]] = tt.load %{{.*}} {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #[[BB]]>\n+// CHECK: %[[BCVT:.*]] = triton_gpu.convert_layout %[[BLOAD]] : (tensor<16x16xf16, #[[BB]]>) -> tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #[[MMA]], kWidth = 2}>>\n+// CHECK: %[[AEXT:.*]] = arith.extf %[[ACVT]] : tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #[[MMA]], kWidth = 2}>> to tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #[[MMA]], kWidth = 2}>>\n+// CHECK: %[[BEXT:.*]] = arith.extf %[[BCVT]] : tensor<16x16xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #[[MMA]], kWidth = 2}>> to tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #[[MMA]], kWidth = 2}>>\n+// CHECK: tt.dot %[[AEXT]], %[[BEXT]], %{{.*}} {allowTF32 = true} : tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #[[MMA]], kWidth = 2}>> * tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #[[MMA]], kWidth = 2}>> -> tensor<16x16xf32, #mma>\n+tt.func @push_convert_both_operands(\n+                   %pa: tensor<16x16x!tt.ptr<f16>, #blockedA> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n+                   %pb: tensor<16x16x!tt.ptr<f16>, #blockedB> {tt.divisibility=16: i32, tt.contiguity=2 : i32},\n+                   %c: tensor<16x16xf32, #mma>) -> tensor<16x16xf32, #mma>{\n+  %a = tt.load %pa {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #blockedA>\n+  %b = tt.load %pb {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<16x16xf16, #blockedB>\n+  %ae = arith.extf %a : tensor<16x16xf16, #blockedA> to tensor<16x16xf32, #blockedA>\n+  %be = arith.extf %b : tensor<16x16xf16, #blockedB> to tensor<16x16xf32, #blockedB>\n+  %al = triton_gpu.convert_layout %ae : (tensor<16x16xf32, #blockedA>) -> tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>>\n+  %bl = triton_gpu.convert_layout %be : (tensor<16x16xf32, #blockedB>) -> tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>>\n+  %r = tt.dot %al, %bl, %c {allowTF32 = true} : tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x16xf32, #triton_gpu.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<16x16xf32, #mma>\n+  tt.return %r : tensor<16x16xf32, #mma>\n+}\n+\n }"}]