[{"filename": "lib/Conversion/TritonGPUToLLVM/ViewOpToLLVM.cpp", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -22,7 +22,11 @@ struct SplatOpConversion\n                                   ConversionPatternRewriter &rewriter,\n                                   Location loc) {\n     auto tensorTy = resType.cast<RankedTensorType>();\n-    auto srcType = typeConverter->convertType(elemType);\n+    // Check the converted type for the tensor as depending on the encoding the\n+    // converter may pick different element types.\n+    auto srcType = typeConverter->convertType(tensorTy);\n+    if (auto structTy = dyn_cast<LLVM::LLVMStructType>(srcType))\n+      srcType = structTy.getBody()[0];\n     auto llSrc = bitcast(constVal, srcType);\n     size_t elemsPerThread = getTotalElemsPerThread(tensorTy);\n     llvm::SmallVector<Value> elems(elemsPerThread, llSrc);"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 25, "deletions": 0, "changes": 25, "file_content_changes": "@@ -1159,3 +1159,28 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n       tt.return\n   }\n }\n+\n+// -----\n+\n+#mma = #triton_gpu.mma<{versionMajor=2, warpsPerCTA=[2, 2]}>\n+#shared = #triton_gpu.shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>\n+#blocked = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [1, 4], order = [1, 0]}>\n+#dot_operand_a = #triton_gpu.dot_op<{opIdx=0, parent=#mma, kWidth=1}>\n+#dot_operand_b = #triton_gpu.dot_op<{opIdx=1, parent=#mma, kWidth=1}>\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n+  // CHECK-LABEL: matmul_tf32dot_cst_b\n+  tt.func @matmul_tf32dot_cst_b(%ptr:!tt.ptr<f32> {tt.divisibility = 16 : i32},\n+  %a: tensor<32x16xf32, #dot_operand_a>, %c: tensor<32x32xf32, #mma>) {\n+  // CHECK: %[[CST:.+]] = llvm.mlir.constant(1.000000e+00 : f32) : f32\n+  // CHECK: %[[BC:.+]] = llvm.bitcast %[[CST]] : f32 to i32\n+  // CHECK: %[[SI:.+]] = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>\n+  // CHECK: llvm.insertvalue %[[BC]], %[[SI]][0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>\n+    %b_mat = arith.constant dense<1.000000e+00> : tensor<16x32xf32, #dot_operand_b>\n+    %28 = tt.dot %a, %b_mat, %c {allowTF32 = true, transA = false, transB = false} : tensor<32x16xf32, #dot_operand_a> * tensor<16x32xf32, #dot_operand_b> -> tensor<32x32xf32, #mma>\n+    %38 = triton_gpu.convert_layout %28 : (tensor<32x32xf32, #mma>) -> tensor<32x32xf32, #blocked>\n+    %30 = tt.splat %ptr : (!tt.ptr<f32>) -> tensor<32x1x!tt.ptr<f32>, #blocked>\n+    %36 = tt.broadcast %30 : (tensor<32x1x!tt.ptr<f32>, #blocked>) -> tensor<32x32x!tt.ptr<f32>, #blocked>\n+    tt.store %36, %38 : tensor<32x32xf32, #blocked>\n+    tt.return\n+  }\n+}"}]