[{"filename": "include/triton/Analysis/AxisInfo.h", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -132,9 +132,11 @@ class AxisInfoAnalysis : public ForwardDataFlowAnalysis<AxisInfo> {\n   visitOperation(Operation *op,\n                  ArrayRef<LatticeElement<AxisInfo> *> operands) override;\n \n-  unsigned getValueVectorSize(Value ptr);\n+  unsigned getPtrVectorSize(Value ptr);\n \n-  unsigned getValueAlignment(Value val);\n+  unsigned getPtrAlignment(Value ptr);\n+\n+  unsigned getMaskAlignment(Value mask);\n };\n \n } // namespace mlir"}, {"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 15, "deletions": 5, "changes": 20, "file_content_changes": "@@ -276,7 +276,7 @@ ChangeResult AxisInfoAnalysis::visitOperation(\n   return result;\n }\n \n-unsigned AxisInfoAnalysis::getValueVectorSize(Value ptr) {\n+unsigned AxisInfoAnalysis::getPtrVectorSize(Value ptr) {\n   auto tensorTy = ptr.getType().dyn_cast<RankedTensorType>();\n   if (!tensorTy)\n     return 1;\n@@ -286,7 +286,7 @@ unsigned AxisInfoAnalysis::getValueVectorSize(Value ptr) {\n   // Here order should be ordered by contiguous first, so the first element\n   // should have the largest contiguous.\n   auto order = triton::gpu::getOrder(layout);\n-  unsigned align = getValueAlignment(ptr);\n+  unsigned align = getPtrAlignment(ptr);\n \n   unsigned contigPerThread = triton::gpu::getSizePerThread(layout)[order[0]];\n   unsigned vec = std::min(align, contigPerThread);\n@@ -295,11 +295,11 @@ unsigned AxisInfoAnalysis::getValueVectorSize(Value ptr) {\n   return vec;\n }\n \n-unsigned AxisInfoAnalysis::getValueAlignment(Value val) {\n-  auto tensorTy = val.getType().dyn_cast<RankedTensorType>();\n+unsigned AxisInfoAnalysis::getPtrAlignment(Value ptr) {\n+  auto tensorTy = ptr.getType().dyn_cast<RankedTensorType>();\n   if (!tensorTy)\n     return 1;\n-  auto axisInfo = lookupLatticeElement(val)->getValue();\n+  auto axisInfo = lookupLatticeElement(ptr)->getValue();\n   auto layout = tensorTy.getEncoding();\n   auto order = triton::gpu::getOrder(layout);\n   unsigned maxMultiple = axisInfo.getDivisibility(order[0]);\n@@ -308,4 +308,14 @@ unsigned AxisInfoAnalysis::getValueAlignment(Value val) {\n   return alignment;\n }\n \n+unsigned AxisInfoAnalysis::getMaskAlignment(Value mask) {\n+  auto tensorTy = mask.getType().dyn_cast<RankedTensorType>();\n+  if (!tensorTy)\n+    return 1;\n+  auto maskOrder = triton::gpu::getOrder(tensorTy.getEncoding());\n+  auto maskAxis = lookupLatticeElement(mask)->getValue();\n+  auto alignment = std::max<unsigned>(maskAxis.getConstancy(maskOrder[0]), 1);\n+  return alignment;\n+}\n+\n } // namespace mlir"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "file_content_changes": "@@ -822,15 +822,11 @@ struct LoadStoreConversionBase : public ConvertTritonGPUOpToLLVMPatternBase {\n   }\n \n   unsigned getVectorSize(Value ptr) const {\n-    return axisAnalysisPass.getValueVectorSize(ptr);\n+    return axisAnalysisPass.getPtrVectorSize(ptr);\n   }\n \n   unsigned getMaskAlignment(Value mask) const {\n-    // XXX: What if mask is a scalar?\n-    auto tensorTy = mask.getType().cast<RankedTensorType>();\n-    auto maskOrder = getOrder(tensorTy.getEncoding());\n-    auto maskAxis = axisAnalysisPass.lookupLatticeElement(mask)->getValue();\n-    return std::max<int>(maskAxis.getConstancy(maskOrder[0]), 1);\n+    return axisAnalysisPass.getMaskAlignment(mask);\n   }\n \n protected:\n@@ -4601,7 +4597,7 @@ class ConvertTritonGPUToLLVM\n       auto resSharedLayout =\n           dstTy.getEncoding().dyn_cast<triton::gpu::SharedEncodingAttr>();\n       auto resElemTy = dstTy.getElementType();\n-      unsigned inVec = axisInfoAnalysis.getValueVectorSize(src);\n+      unsigned inVec = axisInfoAnalysis.getPtrVectorSize(src);\n       unsigned outVec = resSharedLayout.getVec();\n       unsigned minVec = std::min(outVec, inVec);\n       auto maxBitWidth ="}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -336,7 +336,7 @@ void init_triton_ir(py::module &&m) {\n         return funcs[0];\n       });\n \n-   m.def(\"make_attr\",\n+  m.def(\"make_attr\",\n         [](const std::vector<int> &values, mlir::MLIRContext &context) {\n           return mlir::DenseIntElementsAttr::get(\n                      mlir::RankedTensorType::get("}]