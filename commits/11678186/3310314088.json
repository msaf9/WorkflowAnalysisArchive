[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "file_content_changes": "@@ -2463,6 +2463,13 @@ struct DotOpConversionHelper {\n     return {8, 8};\n   }\n \n+  static std::tuple<int, int> getRepMN(const TensorType &tensorTy) {\n+    int M = tensorTy.getShape()[0];\n+    int N = tensorTy.getShape()[1];\n+    auto [matM, matN] = getMatShapeMN();\n+    return {M / matM, N / matN};\n+  }\n+\n   Type getShemPtrTy() const {\n     switch (mmaType) {\n     case TensorCoreType::FP32_FP16_FP16_FP32:\n@@ -2825,12 +2832,8 @@ struct MMA16816ConversionHelper {\n   // NOTE Only SplatLike tensor is supported now.\n   Value loadC(Value tensor, Value llTensor) const {\n     auto tensorTy = tensor.getType().cast<RankedTensorType>();\n-    int M = tensorTy.getShape()[0];\n-    int N = tensorTy.getShape()[1];\n-    auto [matM, matN] = helper.getMatShapeMN();\n-    int numRepM = M / matM;\n-    int numRepN = N / matN;\n-    size_t fcSize = 4 * numRepM * numRepN;\n+    auto [repM, repN] = DotOpConversionHelper::getRepMN(tensorTy);\n+    size_t fcSize = 4 * repM * repN;\n \n     assert(tensorTy.getEncoding().isa<MmaEncodingAttr>() &&\n            \"Currently, we only support $c with a mma layout.\");\n@@ -3068,9 +3071,7 @@ LogicalResult ConvertLayoutOpConversion::lowerSharedToDotOperand(\n     res = mmaHelper.loadB(src, adaptor.src());\n   } else if (dotOperandLayout.getOpIdx() == 2) {\n     auto tensorTy = src.getType().cast<TensorType>();\n-    int M = tensorTy.getShape()[0];\n-    int N = tensorTy.getShape()[1];\n-    auto [repM, repN] = DotOpConversionHelper::getMatShapeMN();\n+    auto [repM, repN] = DotOpConversionHelper::getRepMN(tensorTy);\n     res = mmaHelper.loadC(src, adaptor.src());\n   }\n "}]