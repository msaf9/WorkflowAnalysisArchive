[{"filename": "lib/Conversion/TritonGPUToLLVM/DotOpHelpers.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -159,7 +159,7 @@ struct DotOpMmaV1ConversionHelper {\n     return M / shapePerCTAM * param.rep[0];\n   }\n \n-  using CoordTy = SmallVector<Value, 2>;\n+  using CoordTy = SmallVector<Value>;\n   // Get the coordinates(m,n) of the elements emit by a thread in accumulator.\n   static SmallVector<CoordTy>\n   getMNCoords(Value thread, ConversionPatternRewriter &rewriter,"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 0, "deletions": 30, "changes": 30, "file_content_changes": "@@ -69,36 +69,6 @@ struct BroadcastOpConversion\n     auto srcOffsets = emitOffsetForLayout(srcLayout, srcShape);\n     auto resultOffsets = emitOffsetForLayout(resultLayout, resultShape);\n     SmallVector<Value> srcVals = getElementsFromStruct(loc, src, rewriter);\n-    if (auto srcMma = srcLayout.dyn_cast<MmaEncodingAttr>()) {\n-\n-      // NOTE: This is just an naive fix, but for MMA layout, and 2-d fix should\n-      // be all right.\n-      // TODO[Superjomn]: Replace this with a generic implementation.\n-      if (srcMma.isVolta()) {\n-        assert(srcTy.getElementType().isF16() &&\n-               \"Unexpected data type on Volta\");\n-        int numElemsPerThread = srcMma.getElemsPerThread(resultTy.getShape());\n-        int srcUniqElems = srcVals.size() / 2;\n-        int dup = numElemsPerThread / srcUniqElems;\n-        SmallVector<Value> retVals;\n-        if (srcShape[0] == 1) { // add-cols\n-          for (int i = 0; i < srcUniqElems; ++i)\n-            for (int k = 0; k < dup; ++k)\n-              retVals.push_back(srcVals[i * 2]);\n-\n-        } else { // add-rows\n-          for (int k = 0; k < dup; ++k)\n-            for (int i = 0; i < srcUniqElems; ++i)\n-              retVals.push_back(srcVals[i]);\n-        }\n-\n-        auto llvmStructTy = getTypeConverter()->convertType(resultTy);\n-        Value ret = getStructFromElements(loc, retVals, rewriter, llvmStructTy);\n-\n-        rewriter.replaceOp(op, {ret});\n-        return success();\n-      }\n-    }\n \n     DenseMap<SmallVector<unsigned>, Value, SmallVectorKeyInfo> srcValues;\n     for (size_t i = 0; i < srcOffsets.size(); i++) {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMBase.h", "status": "modified", "additions": 30, "deletions": 34, "changes": 64, "file_content_changes": "@@ -755,49 +755,48 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n     Value offsetBN = add(offWarpN, offLaneN);\n     // m indices\n     Value offsetCM = add(and_(lane, _1), offsetAM);\n-    // SmallVector<Value> idxM;\n-    // for (unsigned m = 0; m < shape[0]; m += shapePerCTA[0])\n-    //   for (unsigned mm = 0; mm < rep[0]; ++mm)\n-    //     idxM.push_back(add(offsetCM, i32_val(m + mm * 2)));\n-\n     // n indices\n     Value offsetCN = add((and_(lane, _2)), (add(offWarpN, offPairN)));\n-    // SmallVector<Value> idxN;\n-    // for (int n = 0; n < shape[1]; n += shapePerCTA[1]) {\n-    //   for (int nn = 0; nn < rep[1]; ++nn) {\n-    //     idxN.push_back(add(offsetCN, i32_val(n + nn / 2 * 4 +\n-    //                                          (nn % 2) * 2 * fpw[1] *\n-    //                                          rep[1])));\n-    //     idxN.push_back(\n-    //         add(offsetCN,\n-    //             i32_val(n + nn / 2 * 4 + (nn % 2) * 2 * fpw[1] * rep[1] +\n-    //             1)));\n-    //   }\n-    // }\n-\n     return {offsetCM, offsetCN};\n   }\n \n   SmallVector<SmallVector<unsigned>>\n   emitOffsetForMmaLayoutV1(const MmaEncodingAttr &mmaLayout,\n                            ArrayRef<int64_t> shape) const {\n-    SmallVector<SmallVector<unsigned>> ret;\n \n-    for (unsigned i = 0; i < shape[0];\n-         i += getShapePerCTA(mmaLayout, shape)[0]) {\n-      for (unsigned j = 0; j < shape[1];\n-           j += getShapePerCTA(mmaLayout, shape)[1]) {\n-        ret.push_back({i, j});\n-        ret.push_back({i, j + 1});\n-        ret.push_back({i + 2, j});\n-        ret.push_back({i + 2, j + 1});\n-        ret.push_back({i, j + 8});\n-        ret.push_back({i, j + 9});\n-        ret.push_back({i + 2, j + 8});\n-        ret.push_back({i + 2, j + 9});\n+    auto [isARow, isBRow, isAVec4, isBVec4, id] =\n+        mmaLayout.decodeVoltaLayoutStates();\n+    LLVM::DotOpMmaV1ConversionHelper::AParam aParam(isARow, isAVec4);\n+    LLVM::DotOpMmaV1ConversionHelper::BParam bParam(isBRow, isBVec4);\n+    auto wpt = mmaLayout.getWarpsPerCTA();\n+    auto fpw = LLVM::DotOpMmaV1ConversionHelper::fpw;\n+    SmallVector<int, 2> rep({aParam.rep[0], bParam.rep[1]});\n+    SmallVector<int, 2> spw({aParam.spw[0], bParam.spw[1]});\n+    SmallVector<unsigned, 2> shapePerCTA({spw[0] * wpt[0], spw[1] * wpt[1]});\n+\n+    SmallVector<unsigned> idxM;\n+    for (unsigned m = 0; m < shape[0]; m += shapePerCTA[0])\n+      for (unsigned mm = 0; mm < rep[0]; ++mm)\n+        idxM.push_back(m + mm * 2);\n+\n+    SmallVector<unsigned> idxN;\n+    for (int n = 0; n < shape[1]; n += shapePerCTA[1]) {\n+      for (int nn = 0; nn < rep[1]; ++nn) {\n+        idxN.push_back(n + nn / 2 * 4 + (nn % 2) * 2 * fpw[1] * rep[1]);\n+        if (shape[1] > 1)\n+          idxN.push_back(n + nn / 2 * 4 + (nn % 2) * 2 * fpw[1] * rep[1] + 1);\n       }\n     }\n \n+    SmallVector<SmallVector<unsigned>> ret;\n+    for (unsigned x1 : idxN) {   // N\n+      for (unsigned x0 : idxM) { // M\n+        SmallVector<unsigned> idx(2);\n+        idx[0] = x0; // M\n+        idx[1] = x1; // N\n+        ret.push_back(std::move(idx));\n+      }\n+    }\n     return ret;\n   }\n \n@@ -843,9 +842,6 @@ class ConvertTritonGPUOpToLLVMPatternBase {\n   // Emit indices calculation within each ConversionPattern, and returns a\n   // [elemsPerThread X rank] index matrix.\n \n-  // TODO: [phil] redundant indices computation do not appear to hurt\n-  // performance much, but they could still significantly slow down\n-  // computations.\n   SmallVector<SmallVector<Value>> emitIndicesForDistributedLayout(\n       Location loc, ConversionPatternRewriter &rewriter,\n       const Attribute &layout, ArrayRef<int64_t> shape) const {"}, {"filename": "lib/Target/LLVMIR/LLVMIRTranslation.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -282,6 +282,7 @@ translateTritonGPUToLLVMIR(llvm::LLVMContext *llvmContext,\n     return nullptr;\n   }\n \n+  // llvm::outs() << module << \"\\n\";\n   auto llvmIR = translateLLVMToLLVMIR(llvmContext, module);\n   if (!llvmIR) {\n     llvm::errs() << \"Translate to LLVM IR failed\";"}]