[{"filename": "lib/Dialect/TritonGPU/Transforms/Coalesce.cpp", "status": "modified", "additions": 28, "deletions": 3, "changes": 31, "file_content_changes": "@@ -21,6 +21,19 @@ template <class T> SmallVector<unsigned, 4> argSort(const T &arr) {\n   return ret;\n }\n \n+unsigned getElementBitWidth(const Value &val) {\n+  auto valType = val.getType();\n+  if (valType.isa<PointerType>())\n+    valType = valType.cast<PointerType>().getPointeeType();\n+  auto tensorType = valType.cast<RankedTensorType>();\n+\n+  auto typeForMem =\n+      tensorType.getElementType().isa<PointerType>()\n+          ? tensorType.getElementType().cast<PointerType>().getPointeeType()\n+          : tensorType.getElementType();\n+  return typeForMem.getIntOrFloatBitWidth();\n+}\n+\n typedef DenseMap<Value, std::function<Type(Type)>> LayoutMap;\n \n struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n@@ -74,6 +87,18 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n       order = argSort(queryAxisInfo(ptr).getContiguity());\n     }\n \n+    auto matchesOrder = [&refTensorType](const Value &val) {\n+      if (val.getType() == refTensorType) {\n+        return true;\n+      }\n+\n+      auto rttType = val.getType().dyn_cast<RankedTensorType>();\n+      if (!rttType) {\n+        return false;\n+      }\n+      return rttType.getShape() == refTensorType.getShape();\n+    };\n+\n     // The desired divisibility is the maximum divisibility\n     // among all dependent pointers who have the same order as\n     // `ptr`.\n@@ -83,7 +108,7 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     if (refType.isa<RankedTensorType>() && ptr.getDefiningOp()) {\n       for (Operation *op : mlir::multiRootGetSlice(ptr.getDefiningOp())) {\n         for (Value val : op->getResults()) {\n-          if (val.getType() != refTensorType)\n+          if (!matchesOrder(val))\n             continue;\n           auto currOrder =\n               argSort(axisInfoAnalysis.getAxisInfo(val)->getContiguity());\n@@ -109,11 +134,11 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n \n     // Thread tile size depends on memory alignment\n     SmallVector<unsigned, 4> sizePerThread(refTensorType.getRank(), 1);\n-    unsigned elemNumBits = typeForMem.getIntOrFloatBitWidth();\n-    unsigned elemNumBytes = std::max(elemNumBits / 8, 1u);\n     unsigned perThread = 1;\n     for (Value val : withSameOrder) {\n       auto valInfo = queryAxisInfo(val);\n+      unsigned elemNumBits = getElementBitWidth(val);\n+      unsigned elemNumBytes = std::max(elemNumBits / 8, 1u);\n       unsigned maxMultipleBytes = valInfo.getDivisibility(order[0]);\n       unsigned maxMultiple = std::max(maxMultipleBytes / elemNumBytes, 1u);\n       unsigned maxContig ="}, {"filename": "test/TritonGPU/coalesce.mlir", "status": "modified", "additions": 33, "deletions": 0, "changes": 33, "file_content_changes": "@@ -69,3 +69,36 @@ tt.func @load_tensor(%arg0: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32}, %arg1:\n }\n \n }\n+\n+// -----\n+\n+#blocked = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0], CTAsPerCGA = [1], CTASplitNum = [1], CTAOrder = [0]}>\n+module attributes {\"triton_gpu.num-ctas\" = 1 : i32, \"triton_gpu.num-warps\" = 4 : i32, \"triton_gpu.threads-per-warp\" = 32 : i32} {\n+\n+// CHECK-NOT: sizePerThread = [4]\n+// CHECK: #triton_gpu.blocked<{sizePerThread = [8], threadsPerWarp = [32], warpsPerCTA = [4], order = [0], CTAsPerCGA = [1], CTASplitNum = [1], CTAOrder = [0]}>\n+// CHECK-NOT: sizePerThread = [4]\n+tt.func public @load_tensors_two_types(%arg0: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32}, %arg3: i32) attributes {noinline = false} {\n+    %c1024_i32 = arith.constant 1024 : i32\n+    %0 = tt.get_program_id x : i32\n+    %1 = arith.muli %0, %c1024_i32 : i32\n+    %2 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32, #blocked>\n+    %3 = tt.splat %1 : (i32) -> tensor<1024xi32, #blocked>\n+    %4 = arith.addi %3, %2 : tensor<1024xi32, #blocked>\n+    %5 = tt.splat %arg3 : (i32) -> tensor<1024xi32, #blocked>\n+    %6 = \"triton_gpu.cmpi\"(%4, %5) <{predicate = 2 : i64}> : (tensor<1024xi32, #blocked>, tensor<1024xi32, #blocked>) -> tensor<1024xi1, #blocked>\n+    %7 = tt.splat %arg0 : (!tt.ptr<f32, 1>) -> tensor<1024x!tt.ptr<f32, 1>, #blocked>\n+    %8 = tt.addptr %7, %4 : tensor<1024x!tt.ptr<f32, 1>, #blocked>, tensor<1024xi32, #blocked>\n+    %9 = tt.load %8, %6 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<1024xf32, #blocked>\n+    %10 = tt.splat %arg1 : (!tt.ptr<f16, 1>) -> tensor<1024x!tt.ptr<f16, 1>, #blocked>\n+    %11 = tt.addptr %10, %4 : tensor<1024x!tt.ptr<f16, 1>, #blocked>, tensor<1024xi32, #blocked>\n+    %12 = tt.load %11, %6 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<1024xf16, #blocked>\n+    %13 = arith.extf %12 : tensor<1024xf16, #blocked> to tensor<1024xf32, #blocked>\n+    %14 = arith.addf %9, %13 : tensor<1024xf32, #blocked>\n+    %15 = tt.splat %arg2 : (!tt.ptr<f32, 1>) -> tensor<1024x!tt.ptr<f32, 1>, #blocked>\n+    %16 = tt.addptr %15, %4 : tensor<1024x!tt.ptr<f32, 1>, #blocked>, tensor<1024xi32, #blocked>\n+    tt.store %16, %14, %6 {cache = 1 : i32, evict = 1 : i32} : tensor<1024xf32, #blocked>\n+    tt.return\n+}\n+\n+}"}]