[{"filename": "test/Conversion/triton_ops.mlir", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "file_content_changes": "@@ -0,0 +1,55 @@\n+// RUN: triton-opt %s | FileCheck %s\n+\n+func @cast_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_f32: f32, %scalar_i64: i64) {\n+  // scalar -> scalar\n+  // CHECK:  i64 -> !tt.ptr<f32>\n+  %0 = tt.int_to_ptr %scalar_i64 : i64 -> !tt.ptr<f32>\n+  // CHECK: !tt.ptr<f32> -> i64\n+  %1 = tt.ptr_to_int %scalar_ptr : !tt.ptr<f32> -> i64\n+  // CHECK: f32 -> f16\n+  %2 = tt.fp_to_fp %scalar_f32 : f32 -> f16\n+\n+  // 0D tensor -> 0D tensor\n+  %tensor_ptr_0d = tt.splat %scalar_ptr : (!tt.ptr<f32>) -> tensor<!tt.ptr<f32>>\n+  %tensor_f32_0d = tt.splat %scalar_f32 : (f32) -> tensor<f32>\n+  %tensor_i64_0d = tt.splat %scalar_i64 : (i64) -> tensor<i64>\n+\n+  // CHECK: tensor<i64> -> tensor<!tt.ptr<f32>>\n+  %3 = tt.int_to_ptr %tensor_i64_0d : tensor<i64> -> tensor<!tt.ptr<f32>>\n+  // CHECK: tensor<!tt.ptr<f32>> -> tensor<i64>\n+  %4 = tt.ptr_to_int %tensor_ptr_0d : tensor<!tt.ptr<f32>> -> tensor<i64>\n+  // CHECK: tensor<f32> -> tensor<f16>\n+  %5 = tt.fp_to_fp %tensor_f32_0d : tensor<f32> -> tensor<f16>\n+\n+  // 1D tensor -> 1D tensor\n+  %tensor_ptr_1d = tt.splat %scalar_ptr : (!tt.ptr<f32>) -> tensor<16x!tt.ptr<f32>>\n+  %tensor_f32_1d = tt.splat %scalar_f32 : (f32) -> tensor<16xf32>\n+  %tensor_i64_1d = tt.splat %scalar_i64 : (i64) -> tensor<16xi64>\n+\n+  // CHECK: tensor<16xi64> -> tensor<16x!tt.ptr<f32>>\n+  %6 = tt.int_to_ptr %tensor_i64_1d : tensor<16xi64> -> tensor<16x!tt.ptr<f32>>\n+  // CHECK: tensor<16x!tt.ptr<f32>> -> tensor<16xi64>\n+  %7 = tt.ptr_to_int %tensor_ptr_1d : tensor<16x!tt.ptr<f32>> -> tensor<16xi64>\n+  // CHECK: tensor<16xf32> -> tensor<16xf16>\n+  %8 = tt.fp_to_fp %tensor_f32_1d : tensor<16xf32> -> tensor<16xf16>\n+  return\n+}\n+\n+func @addptr_ops(%scalar_ptr: !tt.ptr<f32>, %scalar_i32: i32) {\n+  // scalar -> scalar\n+  // CHECK: !tt.ptr<f32>\n+  %0 = tt.addptr %scalar_ptr, %scalar_i32 : !tt.ptr<f32>\n+\n+  // 0D tensor -> 0D tensor\n+  %tensor_ptr_0d = tt.splat %scalar_ptr : (!tt.ptr<f32>) -> tensor<!tt.ptr<f32>>\n+  %tensor_i32_0d = tt.splat %scalar_i32 : (i32) -> tensor<i32>\n+  // CHECK: tensor<!tt.ptr<f32>>\n+  %1 = tt.addptr %tensor_ptr_0d, %tensor_i32_0d : tensor<!tt.ptr<f32>>\n+\n+  // 1D tensor -> 1D tensor\n+  %tensor_ptr_1d = tt.splat %scalar_ptr : (!tt.ptr<f32>) -> tensor<16x!tt.ptr<f32>>\n+  %tensor_i32_1d = tt.splat %scalar_i32 : (i32) -> tensor<16xi32>\n+  // CHECK: tensor<16x!tt.ptr<f32>>\n+  %2 = tt.addptr %tensor_ptr_1d, %tensor_i32_1d : tensor<16x!tt.ptr<f32>>\n+  return\n+}"}, {"filename": "test/Conversion/triton_to_tritongpu.mlir", "status": "renamed", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "test/Conversion/ops.mlir"}]