[{"filename": "include/triton/Conversion/TritonGPUToLLVM/PTXAsmFormat.h", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "file_content_changes": "@@ -144,7 +144,12 @@ struct PTXBuilder {\n \n   // Create a new operand which is written to, that is, the constraint starts\n   // with \"=\", e.g. \"=r\".\n-  Operand *newOperand(StringRef constraint);\n+  // If the operand will be used in predicated execution,\n+  // users may want to initialize it before use.\n+  // Otherwise if the register is only used in the true branch or the false\n+  // branch but not both, the register is undefined and ptxas can perform\n+  // aggressive optimizations that may lead to incorrect results.\n+  Operand *newOperand(StringRef constraint, bool init = false);\n \n   // Create a constant integer operand.\n   Operand *newConstantOperand(int64_t v);\n@@ -171,6 +176,8 @@ struct PTXBuilder {\n     return argArchive.back().get();\n   }\n \n+  void initOperand(Operand *opr);\n+\n   // Make the operands in argArchive follow the provided \\param order.\n   void reorderArgArchive(ArrayRef<Operand *> order) {\n     assert(order.size() == argArchive.size());"}, {"filename": "lib/Conversion/TritonGPUToLLVM/LoadStoreOpToLLVM.cpp", "status": "modified", "additions": 33, "deletions": 32, "changes": 65, "file_content_changes": "@@ -108,7 +108,7 @@ struct LoadOpConversion\n     }\n \n     // vectorized iteration through all the pointer/mask/other elements\n-    const int valueElemNbits =\n+    const int valueElemNBits =\n         std::max(8u, valueElemTy.getIntOrFloatBitWidth());\n     const int numVecs = numElems / vec;\n \n@@ -117,11 +117,11 @@ struct LoadOpConversion\n       // TODO: optimization when ptr is GEP with constant offset\n       size_t in_off = 0;\n \n-      const size_t maxWordWidth = std::max<size_t>(32, valueElemNbits);\n-      const size_t totalWidth = valueElemNbits * vec;\n+      const size_t maxWordWidth = std::max<size_t>(32, valueElemNBits);\n+      const size_t totalWidth = valueElemNBits * vec;\n       const size_t width = std::min(totalWidth, maxWordWidth);\n       const size_t nWords = std::max<size_t>(1, totalWidth / width);\n-      const size_t wordNElems = width / valueElemNbits;\n+      const size_t wordNElems = width / valueElemNBits;\n       const size_t movWidth = width < 16 ? 16 : width;\n       assert(wordNElems * nWords * numVecs == numElems);\n \n@@ -138,18 +138,12 @@ struct LoadOpConversion\n       const std::string writeConstraint =\n           (width == 64) ? \"=l\" : ((width == 32) ? \"=r\" : \"=c\");\n \n-      PTXInstr &init =\n-          ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(movWidth));\n-      PTXInstr::Operand *zero = ptxBuilder.newConstantOperand(0);\n-\n       // prepare asm operands\n       auto *dstsOpr = ptxBuilder.newListOperand();\n       for (size_t wordIdx = 0; wordIdx < nWords; ++wordIdx) {\n-        auto *opr = ptxBuilder.newOperand(writeConstraint); // =r operations\n+        auto *opr = ptxBuilder.newOperand(writeConstraint,\n+                                          /*init=*/true); // =r operations\n         dstsOpr->listAppend(opr);\n-        // Initialize the destination register, otherwise the register will\n-        // be undefined if the predicate is false.\n-        init(opr, zero);\n       }\n \n       auto *addrOpr =\n@@ -186,7 +180,7 @@ struct LoadOpConversion\n           PTXInstr &mov =\n               ptxBuilder.create<>(\"mov\")->o(\"u\" + std::to_string(movWidth));\n \n-          size_t size = width / valueElemNbits;\n+          size_t size = width / valueElemNBits;\n \n           auto vecTy = LLVM::getFixedVectorType(valueElemTy, size);\n           Value v = undef(vecTy);\n@@ -201,8 +195,8 @@ struct LoadOpConversion\n           PTXInstr::Operand *opr{};\n \n           if (otherIsSplatConstInt) {\n-            for (size_t s = 0; s < 32; s += valueElemNbits)\n-              splatVal |= splatVal << valueElemNbits;\n+            for (size_t s = 0; s < 32; s += valueElemNBits)\n+              splatVal |= splatVal << valueElemNBits;\n             opr = ptxBuilder.newConstantOperand(splatVal);\n           } else\n             opr = ptxBuilder.newOperand(v, readConstraint);\n@@ -233,10 +227,10 @@ struct LoadOpConversion\n           curr = ret;\n         }\n         curr = bitcast(curr, LLVM::getFixedVectorType(valueElemTy,\n-                                                      width / valueElemNbits));\n+                                                      width / valueElemNBits));\n         rets.push_back(curr);\n       }\n-      int tmp = width / valueElemNbits;\n+      int tmp = width / valueElemNBits;\n       for (size_t ii = 0; ii < vec; ++ii) {\n         Value vecIdx = createIndexAttrConstant(\n             rewriter, loc, this->getTypeConverter()->getIndexType(), ii % tmp);\n@@ -312,18 +306,18 @@ struct StoreOpConversion\n \n     const size_t dtsize =\n         std::max<int>(1, valueElemTy.getIntOrFloatBitWidth() / 8);\n-    const size_t valueElemNbits = dtsize * 8;\n+    const size_t valueElemNBits = dtsize * 8;\n \n     const int numVecs = elemsPerThread / vec;\n     for (size_t vecStart = 0; vecStart < elemsPerThread; vecStart += vec) {\n       // TODO: optimization when ptr is AddPtr with constant offset\n       size_t in_off = 0;\n \n-      const size_t maxWordWidth = std::max<size_t>(32, valueElemNbits);\n-      const size_t totalWidth = valueElemNbits * vec;\n+      const size_t maxWordWidth = std::max<size_t>(32, valueElemNBits);\n+      const size_t totalWidth = valueElemNBits * vec;\n       const size_t width = std::min(totalWidth, maxWordWidth);\n       const size_t nWords = std::max<size_t>(1, totalWidth / width);\n-      const size_t wordNElems = width / valueElemNbits;\n+      const size_t wordNElems = width / valueElemNBits;\n       assert(wordNElems * nWords * numVecs == elemsPerThread);\n \n       // TODO(Superjomn) Add cache policy fields to StoreOp.\n@@ -414,6 +408,7 @@ struct AtomicCASOpConversion\n     Type valueElemTy =\n         TensorTy ? getTypeConverter()->convertType(TensorTy.getElementType())\n                  : op.getResult().getType();\n+    auto valueElemNBits = valueElemTy.getIntOrFloatBitWidth();\n     auto tid = tid_val();\n     Value pred = icmp_eq(tid, i32_val(0));\n     PTXBuilder ptxBuilderMemfence;\n@@ -424,13 +419,12 @@ struct AtomicCASOpConversion\n \n     Value atomPtr = getSharedMemoryBase(loc, rewriter, op.getOperation());\n     atomPtr = bitcast(atomPtr, ptr_ty(valueElemTy, 3));\n-\n     Value casPtr = ptrElements[0];\n     Value casCmp = cmpElements[0];\n     Value casVal = valElements[0];\n \n     PTXBuilder ptxBuilderAtomicCAS;\n-    auto *dstOpr = ptxBuilderAtomicCAS.newOperand(\"=r\");\n+    auto *dstOpr = ptxBuilderAtomicCAS.newOperand(\"=r\", /*init=*/true);\n     auto *ptrOpr = ptxBuilderAtomicCAS.newAddrOperand(casPtr, \"l\");\n     auto *cmpOpr = ptxBuilderAtomicCAS.newOperand(casCmp, \"r\");\n     auto *valOpr = ptxBuilderAtomicCAS.newOperand(casVal, \"r\");\n@@ -441,7 +435,7 @@ struct AtomicCASOpConversion\n     barrier();\n \n     PTXBuilder ptxBuilderStore;\n-    auto *dstOprStore = ptxBuilderStore.newAddrOperand(atomPtr, \"l\");\n+    auto *dstOprStore = ptxBuilderStore.newAddrOperand(atomPtr, \"r\");\n     auto *valOprStore = ptxBuilderStore.newOperand(old, \"r\");\n     auto &st = *ptxBuilderStore.create<PTXInstr>(\"st\");\n     st.shared().o(\"b32\");\n@@ -498,7 +492,7 @@ struct AtomicRMWOpConversion\n     Type valueElemTy =\n         tensorTy ? getTypeConverter()->convertType(tensorTy.getElementType())\n                  : op.getResult().getType();\n-    const size_t valueElemNbits = valueElemTy.getIntOrFloatBitWidth();\n+    const size_t valueElemNBits = valueElemTy.getIntOrFloatBitWidth();\n     auto elemsPerThread = getElemsPerThread(val.getType());\n     // vec = 1, numElements = 1 for scalar\n     auto vec = getVectorSize(ptr);\n@@ -529,16 +523,16 @@ struct AtomicRMWOpConversion\n       Value rmwMask = llMask ? and_(mask, maskElements[i]) : mask;\n       std::string sTy;\n       PTXBuilder ptxBuilderAtomicRMW;\n-      std::string tyId = valueElemNbits * vec == 64\n+      std::string tyId = valueElemNBits * vec == 64\n                              ? \"l\"\n-                             : (valueElemNbits * vec == 32 ? \"r\" : \"h\");\n-      auto *dstOpr = ptxBuilderAtomicRMW.newOperand(\"=\" + tyId);\n+                             : (valueElemNBits * vec == 32 ? \"r\" : \"h\");\n+      auto *dstOpr = ptxBuilderAtomicRMW.newOperand(\"=\" + tyId, /*init=*/true);\n       auto *ptrOpr = ptxBuilderAtomicRMW.newAddrOperand(rmwPtr, \"l\");\n       auto *valOpr = ptxBuilderAtomicRMW.newOperand(rmwVal, tyId);\n \n       auto &atom = ptxBuilderAtomicRMW.create<>(\"atom\")->global().o(\"gpu\");\n       auto rmwOp = stringifyRMWOp(atomicRmwAttr).str();\n-      auto sBits = std::to_string(valueElemNbits);\n+      auto sBits = std::to_string(valueElemNBits);\n       switch (atomicRmwAttr) {\n       case RMWOp::AND:\n         sTy = \"b\" + sBits;\n@@ -554,9 +548,9 @@ struct AtomicRMWOpConversion\n         break;\n       case RMWOp::FADD:\n         rmwOp = \"add\";\n-        rmwOp += (valueElemNbits == 16 ? \".noftz\" : \"\");\n+        rmwOp += (valueElemNBits == 16 ? \".noftz\" : \"\");\n         sTy = \"f\" + sBits;\n-        sTy += (vec == 2 && valueElemNbits == 16) ? \"x2\" : \"\";\n+        sTy += (vec == 2 && valueElemNBits == 16) ? \"x2\" : \"\";\n         break;\n       case RMWOp::MAX:\n         sTy = \"s\" + sBits;\n@@ -598,7 +592,14 @@ struct AtomicRMWOpConversion\n         auto old = ptxBuilderAtomicRMW.launch(rewriter, loc, valueElemTy);\n         Value atomPtr = getSharedMemoryBase(loc, rewriter, op.getOperation());\n         atomPtr = bitcast(atomPtr, ptr_ty(valueElemTy, 3));\n-        store(old, atomPtr);\n+        // Only threads with rmwMask = True store the result\n+        PTXBuilder ptxBuilderStore;\n+        auto &storeShared =\n+            ptxBuilderStore.create<>(\"st\")->shared().o(\"b\" + sBits);\n+        auto *ptrOpr = ptxBuilderStore.newAddrOperand(atomPtr, \"r\");\n+        auto *valOpr = ptxBuilderStore.newOperand(old, tyId);\n+        storeShared(ptrOpr, valOpr).predicate(rmwMask);\n+        ptxBuilderStore.launch(rewriter, loc, void_ty(ctx));\n         barrier();\n         Value ret = load(atomPtr);\n         barrier();"}, {"filename": "lib/Conversion/TritonGPUToLLVM/PTXAsmFormat.cpp", "status": "modified", "additions": 24, "deletions": 2, "changes": 26, "file_content_changes": "@@ -19,12 +19,34 @@ PTXBuilder::newOperand(mlir::Value value, StringRef constraint,\n   return opr;\n }\n \n-PTXBuilder::Operand *PTXBuilder::newOperand(StringRef constraint) {\n+void PTXBuilder::initOperand(Operand *opr) {\n+  auto numBits = 0;\n+  // Derive numBits from the constraint.\n+  if (opr->constraint[1] == 'c' || opr->constraint[1] == 'h')\n+    numBits = 16;\n+  else if (opr->constraint[1] == 'r')\n+    numBits = 32;\n+  else if (opr->constraint[1] == 'l')\n+    numBits = 64;\n+  else\n+    llvm_unreachable((\"Unknown constraint: \" + opr->constraint).c_str());\n+  // If numBits is less than 16, we use 16 as default because PTX does not\n+  // support 8-bit mov.\n+  numBits = numBits < 16 ? 16 : numBits;\n+  auto *zero = newConstantOperand(0);\n+  auto &init = create<>(\"mov\")->o(\"u\" + std::to_string(numBits));\n+  init(opr, zero);\n+}\n+\n+PTXBuilder::Operand *PTXBuilder::newOperand(StringRef constraint, bool init) {\n   // Constraint should be something like \"=r\"\n-  assert(!constraint.empty() && constraint[0] == '=');\n+  assert(constraint.size() == 2 && constraint[0] == '=');\n   auto *opr = newOperand();\n   opr->idx = oprCounter++;\n   opr->constraint = constraint;\n+  if (init) {\n+    initOperand(opr);\n+  }\n   return opr;\n }\n "}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "file_content_changes": "@@ -739,6 +739,17 @@ def kernel(X, Z):\n         np.testing.assert_allclose(z_ref, to_numpy(z_tri), rtol=0.01)\n \n \n+def test_atomic_rmw_predicate(device=\"cuda\"):\n+    @triton.jit\n+    def kernel(X):\n+        val = tl.program_id(0)\n+        if val < 64:\n+            tl.atomic_max(X, val)\n+    x = torch.zeros((1,), device=device, dtype=torch.int32)\n+    kernel[(4096,)](x)\n+    assert x.item() == 63\n+\n+\n @pytest.mark.parametrize(\"shape, axis\",\n                          [(shape, axis) for shape in [(2, 2), (2, 8), (8, 2), (8, 8), (32, 32)] for axis in [0, 1]])\n def test_tensor_atomic_rmw(shape, axis, device=\"cuda\"):"}]