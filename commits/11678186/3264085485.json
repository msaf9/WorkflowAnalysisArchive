[{"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 55, "deletions": 39, "changes": 94, "file_content_changes": "@@ -1612,7 +1612,7 @@ struct ConvertLayoutOpConversion\n \n   // shared -> mma_operand\n   LogicalResult\n-  lowerSharedToMmaOperand(triton::gpu::ConvertLayoutOp op, OpAdaptor adapter,\n+  lowerSharedToDotOperand(triton::gpu::ConvertLayoutOp op, OpAdaptor adapter,\n                           ConversionPatternRewriter &rewriter) const;\n };\n \n@@ -1921,37 +1921,6 @@ LogicalResult ConvertLayoutOpConversion::lowerBlockedToShared(\n   return success();\n }\n \n-LogicalResult ConvertLayoutOpConversion::lowerSharedToMmaOperand(\n-    triton::gpu::ConvertLayoutOp op, OpAdaptor adapter,\n-    ConversionPatternRewriter &rewriter) const {\n-  auto loc = op.getLoc();\n-  Value src = op.src();\n-  Value dst = op.result();\n-  auto srcTensorTy = src.getType().cast<RankedTensorType>();\n-  auto dstTensorTy = dst.getType().cast<RankedTensorType>();\n-\n-  auto sharedLayout = srcTensorTy.getEncoding().cast<SharedEncodingAttr>();\n-  auto mmaOperandLayout =\n-      dstTensorTy.getEncoding().cast<DotOperandEncodingAttr>();\n-\n-  auto uses = op.getResult().getUses();\n-  // check all the mma layout in uses are the same.\n-  MmaEncodingAttr preMmaLayout;\n-  for (auto &op : uses) {\n-    auto dotOp = cast<DotOp>(op.getOwner());\n-    auto mmaLayout = dotOp.getResult()\n-                         .getType()\n-                         .cast<RankedTensorType>()\n-                         .getEncoding()\n-                         .cast<MmaEncodingAttr>();\n-    if (preMmaLayout)\n-      assert(preMmaLayout == mmaLayout);\n-    preMmaLayout = mmaLayout;\n-  }\n-\n-  // We randomly get a mmaLayout for all of them are the same.\n-}\n-\n /// ====================== dot codegen begin ==========================\n \n // Data loader for mma.16816 instruction.\n@@ -2702,7 +2671,6 @@ struct MMA16816ConversionHelper {\n   // size_t aElemBytes{}, bElemBytes{};\n \n   DotOpConversionHelper helper;\n-  DotOpAdaptor adapter;\n   ConversionPatternRewriter &rewriter;\n   TypeConverter *typeConverter;\n   Location loc;\n@@ -2711,12 +2679,11 @@ struct MMA16816ConversionHelper {\n   using ValueTable = std::map<std::pair<unsigned, unsigned>, Value>;\n \n   MMA16816ConversionHelper(MmaEncodingAttr mmaLayout, Value thread,\n-                           DotOpAdaptor adapter,\n                            ConversionPatternRewriter &rewriter,\n                            TypeConverter *typeConverter, Location loc)\n-      : mmaLayout(mmaLayout), helper(mmaLayout), adapter(adapter),\n-        rewriter(rewriter), typeConverter(typeConverter), loc(loc),\n-        ctx(mmaLayout.getContext()), thread(thread) {\n+      : mmaLayout(mmaLayout), helper(mmaLayout), rewriter(rewriter),\n+        typeConverter(typeConverter), loc(loc), ctx(mmaLayout.getContext()),\n+        thread(thread) {\n \n     wpt = mmaLayout.getWarpsPerCTA();\n \n@@ -2997,6 +2964,56 @@ struct MMA16816ConversionHelper {\n   }\n };\n \n+LogicalResult ConvertLayoutOpConversion::lowerSharedToDotOperand(\n+    triton::gpu::ConvertLayoutOp op, OpAdaptor adapter,\n+    ConversionPatternRewriter &rewriter) const {\n+  auto loc = op.getLoc();\n+  Value src = op.src();\n+  Value dst = op.result();\n+  auto srcTensorTy = src.getType().cast<RankedTensorType>();\n+  auto dstTensorTy = dst.getType().cast<RankedTensorType>();\n+\n+  auto sharedLayout = srcTensorTy.getEncoding().cast<SharedEncodingAttr>();\n+  auto dotOperandLayout =\n+      dstTensorTy.getEncoding().cast<DotOperandEncodingAttr>();\n+\n+  auto uses = op.getResult().getUses();\n+  // check all the mma layout in uses are the same.\n+  MmaEncodingAttr preMmaLayout;\n+  for (auto &op : uses) {\n+    auto dotOp = cast<DotOp>(op.getOwner());\n+    auto mmaLayout = dotOp.getResult()\n+                         .getType()\n+                         .cast<RankedTensorType>()\n+                         .getEncoding()\n+                         .cast<MmaEncodingAttr>();\n+    if (preMmaLayout)\n+      assert(preMmaLayout == mmaLayout);\n+    preMmaLayout = mmaLayout;\n+  }\n+\n+  // We randomly get a mmaLayout for all of them are the same.\n+  auto mmaLayout = preMmaLayout;\n+\n+  MMA16816ConversionHelper mmaHelper(mmaLayout, getThreadId(rewriter, loc),\n+                                     rewriter, getTypeConverter(), op.getLoc());\n+\n+  Value res;\n+  if (dotOperandLayout.getOpIdx() == 0) {\n+    // operand $a\n+    res = mmaHelper.loadA(src, adapter.src());\n+  } else if (dotOperandLayout.getOpIdx() == 1) {\n+    // operand $b\n+    res = mmaHelper.loadB(src, adapter.src());\n+  } else if (dotOperandLayout.getOpIdx() == 1) {\n+    // operand $c\n+    res = mmaHelper.loadC(src);\n+  }\n+\n+  rewriter.replaceOp(op, res);\n+  return success();\n+}\n+\n LogicalResult\n DotOpConversion::convertMMA16816(triton::DotOp op, OpAdaptor adapter,\n                                  ConversionPatternRewriter &rewriter) const {\n@@ -3007,8 +3024,7 @@ DotOpConversion::convertMMA16816(triton::DotOp op, OpAdaptor adapter,\n                        .getEncoding()\n                        .cast<MmaEncodingAttr>();\n   MMA16816ConversionHelper mmaHelper(mmaLayout, getThreadId(rewriter, loc),\n-                                     adapter, rewriter, getTypeConverter(),\n-                                     loc);\n+                                     rewriter, getTypeConverter(), loc);\n \n   auto A = mmaHelper.loadA(op.a(), adapter.a());\n   auto B = mmaHelper.loadB(op.b(), adapter.b());"}]