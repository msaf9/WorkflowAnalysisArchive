[{"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -825,6 +825,7 @@ void populateElementwiseOpToLLVMPatterns(\n #define POPULATE_TERNARY_OP(SRC_OP, DST_OP)                                    \\\n   patterns.add<ElementwiseOpConversion<SRC_OP, DST_OP>>(typeConverter, benefit);\n   POPULATE_TERNARY_OP(triton::gpu::SelectOp, LLVM::SelectOp)\n+  POPULATE_TERNARY_OP(arith::SelectOp, LLVM::SelectOp)\n #undef POPULATE_TERNARY_OP\n \n #define POPULATE_BINARY_OP(SRC_OP, DST_OP)                                     \\"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 17, "deletions": 8, "changes": 25, "file_content_changes": "@@ -385,17 +385,22 @@ def test_where(dtype):\n     @triton.jit\n     def where_kernel(cond_ptr, a_ptr, b_ptr, output_ptr, n_elements,\n                      BLOCK_SIZE: tl.constexpr,\n-                     TEST_POINTERS: tl.constexpr):\n+                     TEST_POINTERS: tl.constexpr,\n+                     TEST_SCALAR_POINTERS: tl.constexpr):\n         offsets = tl.program_id(axis=0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n         mask = offsets < n_elements\n         decide = tl.load(cond_ptr + offsets, mask=mask)\n-        if TEST_POINTERS:\n-            a = tl.load(a_ptr + offsets, mask=mask).to(tl.pi32_t)\n-            b = tl.load(b_ptr + offsets, mask=mask).to(tl.pi32_t)\n+        if TEST_SCALAR_POINTERS:\n+            ptr = tl.where(tl.load(cond_ptr), a_ptr, b_ptr)\n+            output = tl.load(ptr + offsets, mask=mask)\n         else:\n-            a = tl.load(a_ptr + offsets, mask=mask)\n-            b = tl.load(b_ptr + offsets, mask=mask)\n-        output = tl.where(decide, a, b)\n+            if TEST_POINTERS:\n+                a = tl.load(a_ptr + offsets, mask=mask).to(tl.pi32_t)\n+                b = tl.load(b_ptr + offsets, mask=mask).to(tl.pi32_t)\n+            else:\n+                a = tl.load(a_ptr + offsets, mask=mask)\n+                b = tl.load(b_ptr + offsets, mask=mask)\n+            output = tl.where(decide, a, b)\n         tl.store(output_ptr + offsets, output, mask=mask)\n \n     SIZE = 1_000\n@@ -411,8 +416,12 @@ def where_kernel(cond_ptr, a_ptr, b_ptr, output_ptr, n_elements,\n     z_tri = to_triton(np.empty(SIZE, dtype=z.dtype), device='cuda', dst_type=dtype)\n \n     grid = lambda meta: (triton.cdiv(SIZE, meta['BLOCK_SIZE']),)\n-    where_kernel[grid](cond_tri, x_tri, y_tri, z_tri, SIZE, BLOCK_SIZE=1024, TEST_POINTERS=select_ptrs)\n+    where_kernel[grid](cond_tri, x_tri, y_tri, z_tri, SIZE, BLOCK_SIZE=1024, TEST_POINTERS=select_ptrs, TEST_SCALAR_POINTERS=False)\n     assert (z == to_numpy(z_tri)).all()\n+    if select_ptrs:\n+        where_kernel[grid](cond_tri, x_tri, y_tri, z_tri, SIZE, BLOCK_SIZE=1024, TEST_POINTERS=select_ptrs, TEST_SCALAR_POINTERS=True)\n+        z = np.where(cond[0], x, y)\n+        assert (z == to_numpy(z_tri)).all()\n \n \n def test_where_broadcast():"}]