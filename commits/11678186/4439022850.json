[{"filename": "lib/Analysis/AxisInfo.cpp", "status": "modified", "additions": 17, "deletions": 12, "changes": 29, "file_content_changes": "@@ -164,16 +164,16 @@ class MakeRangeOpAxisInfoVisitor final\n   }\n };\n \n-class ConstantOpAxisInfoVisitor final\n-    : public AxisInfoVisitorImpl<arith::ConstantOp> {\n+template <typename OpTy>\n+class ConstantOpAxisInfoVisitor final : public AxisInfoVisitorImpl<OpTy> {\n public:\n-  using AxisInfoVisitorImpl<arith::ConstantOp>::AxisInfoVisitorImpl;\n+  using AxisInfoVisitorImpl<OpTy>::AxisInfoVisitorImpl;\n \n   AxisInfo\n-  getAxisInfo(arith::ConstantOp op,\n+  getAxisInfo(OpTy op,\n               ArrayRef<const dataflow::Lattice<AxisInfo> *> operands) override {\n-    auto intAttr = op.getValue().dyn_cast<IntegerAttr>();\n-    auto boolAttr = op.getValue().dyn_cast<BoolAttr>();\n+    auto intAttr = op.getValue().template dyn_cast<IntegerAttr>();\n+    auto boolAttr = op.getValue().template dyn_cast<BoolAttr>();\n     if (intAttr || boolAttr) {\n       int64_t value{};\n       if (intAttr)\n@@ -186,10 +186,10 @@ class ConstantOpAxisInfoVisitor final\n                       /*knownConstantValue=*/{value});\n     }\n     // TODO: generalize to dense attr\n-    auto splatAttr = op.getValue().dyn_cast<SplatElementsAttr>();\n+    auto splatAttr = op.getValue().template dyn_cast<SplatElementsAttr>();\n     if (splatAttr && splatAttr.getElementType().isIntOrIndex()) {\n-      int64_t value = splatAttr.getSplatValue<APInt>().getZExtValue();\n-      TensorType ty = splatAttr.getType().cast<TensorType>();\n+      int64_t value = splatAttr.template getSplatValue<APInt>().getZExtValue();\n+      TensorType ty = splatAttr.getType().template cast<TensorType>();\n       return AxisInfo(\n           /*contiguity=*/AxisInfo::DimVectorT(ty.getRank(), 1),\n           /*divisibility=*/\n@@ -233,7 +233,8 @@ class AddSubOpAxisInfoVisitor final : public BinaryOpVisitorImpl<OpTy> {\n     if (lhs.getConstantValue().has_value() &&\n         rhs.getConstantValue().has_value()) {\n       if constexpr (std::is_same_v<OpTy, arith::AddIOp> ||\n-                    std::is_same_v<OpTy, triton::AddPtrOp>) {\n+                    std::is_same_v<OpTy, triton::AddPtrOp> ||\n+                    std::is_same_v<OpTy, LLVM::AddOp>) {\n         return {lhs.getConstantValue().value() +\n                 rhs.getConstantValue().value()};\n       } else if constexpr (std::is_same_v<OpTy, arith::SubIOp>) {\n@@ -812,11 +813,15 @@ AxisInfoAnalysis::AxisInfoAnalysis(DataFlowSolver &solver)\n                   CastOpAxisInfoVisitor<triton::gpu::ConvertLayoutOp>,\n                   CastOpAxisInfoVisitor<mlir::UnrealizedConversionCastOp>,\n                   CastOpAxisInfoVisitor<triton::BitcastOp>>();\n+  // TODO: Remove rules for LLVM::ConstantOp, LLVM::AddOp\n+  // when scf.for supports integers induction variable\n   visitors.append<MakeRangeOpAxisInfoVisitor>();\n-  visitors.append<ConstantOpAxisInfoVisitor>();\n+  visitors.append<ConstantOpAxisInfoVisitor<arith::ConstantOp>,\n+                  ConstantOpAxisInfoVisitor<LLVM::ConstantOp>>();\n   visitors.append<AddSubOpAxisInfoVisitor<triton::AddPtrOp>,\n                   AddSubOpAxisInfoVisitor<arith::AddIOp>,\n-                  AddSubOpAxisInfoVisitor<arith::SubIOp>>();\n+                  AddSubOpAxisInfoVisitor<arith::SubIOp>,\n+                  AddSubOpAxisInfoVisitor<LLVM::AddOp>>();\n   visitors.append<MulIOpAxisInfoVisitor>();\n   visitors.append<DivOpAxisInfoVisitor<arith::DivSIOp>,\n                   DivOpAxisInfoVisitor<arith::DivUIOp>>();"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 17, "deletions": 1, "changes": 18, "file_content_changes": "@@ -905,6 +905,22 @@ def visit_Expr(self, node):\n     def visit_NoneType(self, node):\n         return None\n \n+    def visit_JoinedStr(self, node):\n+        values = list(node.values)\n+        for i, value in enumerate(values):\n+            if isinstance(value, ast.Constant):\n+                values[i] = str(value.value)\n+            elif isinstance(value, ast.FormattedValue):\n+                conversion_code = value.conversion\n+                evaluated = self.visit(value.value)\n+                if not isinstance(evaluated, triton.language.constexpr):\n+                    raise NotImplementedError(\"Cannot evaluate f-string containing non-constexpr conversion values,\"\n+                                              \" found conversion of type \" + str(type(evaluated)))\n+                values[i] = (\"{}\" if conversion_code < 0 else \"{!\" + chr(conversion_code) + \"}\").format(evaluated.value)\n+            else:\n+                raise AssertionError(\"encountered unexpected node of type {} in a JoinedStr node\".format(type(value)))\n+        return ''.join(values)\n+\n     def visit(self, node):\n         if node is not None:\n             self.last_node = node\n@@ -998,7 +1014,7 @@ def build_triton_ir(fn, signature, specialization, constants, debug=False):\n         generator.visit(fn.parse())\n     except Exception as e:\n         node = generator.last_node\n-        if node is None or isinstance(e, (NotImplementedError, CompilationError)):\n+        if node is None or isinstance(e, CompilationError):\n             raise e\n         raise CompilationError(fn.src, node) from e\n     ret = generator.module"}, {"filename": "python/triton/ops/blocksparse/matmul.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -181,8 +181,8 @@ def _dsd_kernel(\n     inc_b = tl.load(pinc)\n     inc_b = tl.multiple_of(inc_b, 8)\n     for k in range(K, 0, -TILE_K):\n-        a = tl.load(pa, mask=True)\n-        b = tl.load(pb, mask=offs_bn[None, :] < DS0)\n+        a = tl.load(pa)\n+        b = tl.load(pb)\n         acc += tl.dot(a, b)\n         pa += inc_a\n         pb += inc_b * stride_bk"}]