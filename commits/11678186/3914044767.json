[{"filename": "python/tutorials/06-fused-attention.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -224,7 +224,7 @@ def forward(ctx, q, k, v, sm_scale):\n             o.stride(0), o.stride(1), o.stride(2), o.stride(3),\n             q.shape[0], q.shape[1], q.shape[2],\n             BLOCK_M=BLOCK, BLOCK_N=BLOCK,\n-            BLOCK_DMODEL=Lk, num_warps=4,\n+            BLOCK_DMODEL=Lk, num_warps=num_warps,\n             num_stages=2,\n         )\n "}]