[{"filename": "include/triton/Dialect/Triton/IR/CMakeLists.txt", "status": "modified", "additions": 11, "deletions": 2, "changes": 13, "file_content_changes": "@@ -1,10 +1,19 @@\n set(LLVM_TARGET_DEFINITIONS TritonOps.td)\n mlir_tablegen(Ops.h.inc -gen-op-decls)\n mlir_tablegen(Ops.cpp.inc -gen-op-defs)\n-mlir_tablegen(Dialect.h.inc -gen-dialect-decls)\n-mlir_tablegen(Dialect.cpp.inc -gen-dialect-defs)\n mlir_tablegen(OpsEnums.h.inc -gen-enum-decls)\n mlir_tablegen(OpsEnums.cpp.inc -gen-enum-defs)\n+\n+set(LLVM_TARGET_DEFINITIONS TritonDialect.td)\n+mlir_tablegen(Dialect.h.inc -gen-dialect-decls)\n+mlir_tablegen(Dialect.cpp.inc -gen-dialect-defs)\n+\n+set(LLVM_TARGET_DEFINITIONS TritonOps.td)\n mlir_tablegen(Types.h.inc -gen-typedef-decls)\n mlir_tablegen(Types.cpp.inc -gen-typedef-defs)\n+\n+set(LLVM_TARGET_DEFINITIONS TritonInterfaces.td)\n+mlir_tablegen(AttrInterfaces.h.inc -gen-attr-interface-decls)\n+mlir_tablegen(AttrInterfaces.cpp.inc -gen-attr-interface-defs)\n+\n add_public_tablegen_target(TritonTableGen)"}, {"filename": "include/triton/Dialect/Triton/IR/Dialect.h", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "file_content_changes": "@@ -17,4 +17,24 @@\n #define GET_OP_CLASSES\n #include \"triton/Dialect/Triton/IR/Ops.h.inc\"\n \n+namespace mlir {\n+namespace triton {\n+\n+class DialectInferLayoutInterface\n+    : public DialectInterface::Base<DialectInferLayoutInterface> {\n+public:\n+  DialectInferLayoutInterface(Dialect *dialect) : Base(dialect) {}\n+\n+  virtual LogicalResult\n+  inferReduceOpEncoding(Attribute operandEncoding, int axis,\n+                        Attribute &resultEncoding) const = 0;\n+\n+  virtual LogicalResult\n+  inferExpandDimsOpEncoding(Attribute operandEncoding, int axis,\n+                            Attribute &resultEncoding) const = 0;\n+};\n+\n+} // namespace triton\n+} // namespace mlir\n+\n #endif // TRITON_IR_DIALECT_H_"}, {"filename": "include/triton/Dialect/Triton/IR/Interfaces.h", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "file_content_changes": "@@ -0,0 +1,9 @@\n+#ifndef TRITON_IR_INTERFACES_H_\n+#define TRITON_IR_INTERFACES_H_\n+\n+#include \"mlir/IR/OpDefinition.h\"\n+\n+#define GET_TYPEDEF_CLASSES\n+#include \"triton/Dialect/Triton/IR/AttrInterfaces.h.inc\"\n+\n+#endif // TRITON_IR_TYPES_H_"}, {"filename": "include/triton/Dialect/Triton/IR/Traits.h", "status": "modified", "additions": 36, "deletions": 39, "changes": 75, "file_content_changes": "@@ -10,50 +10,47 @@\n \n namespace mlir {\n namespace OpTrait {\n-// TODO: should have `namespace triton {}` here\n+\n+// These functions are out-of-line implementations of the methods in the\n+// corresponding trait classes.  This avoids them being template\n+// instantiated/duplicated.\n+namespace impl {\n+LogicalResult verifySameOperandsAndResultEncoding(Operation *op);\n+LogicalResult verifySameOperandsEncoding(Operation *op);\n+// The rationale for this trait is to prevent users from creating programs\n+// that would have catastrophic register pressure and cause the compiler to\n+// hang.\n+// Since H100 has 256KB registers, we should allow users to create tensors\n+// of size up to 256K elements. It will spill for datatypes wider than 1B,\n+// but we probably should limit number of elements (rather than bytes) to\n+// keep specs simple\n+int constexpr maxTensorNumElements = 1048576;\n+LogicalResult verifyTensorSize(Operation *op);\n+} // namespace impl\n \n template <class ConcreteType>\n class TensorSizeTrait : public TraitBase<ConcreteType, TensorSizeTrait> {\n public:\n-  // TODO: move impl to .cc files\n   static LogicalResult verifyTrait(Operation *op) {\n-    // The rationale for this number is to prevent users from creating programs\n-    // that would have catastrophic register pressure and cause the compiler to\n-    // hang.\n-    // Since H100 has 256KB registers, we should allow users to create tensors\n-    // of size up to 256K elements. It will spill for datatypes wider than 1B,\n-    // but we probably should limit number of elements (rather than bytes) to\n-    // keep specs simple\n-    int constexpr maxElement = 1048576;\n-    for (auto opType : op->getOperandTypes()) {\n-      if (auto tensorType = opType.dyn_cast<RankedTensorType>()) {\n-        int64_t numElements = 1;\n-        for (int64_t s : tensorType.getShape())\n-          numElements *= s;\n-        if (numElements > maxElement)\n-          return op->emitError(\"Maximum allowed number of elements is \")\n-                 << maxElement << \", but \" << *op << \" has more than that\";\n-        if ((numElements & (numElements - 1)) != 0)\n-          return op->emitError(\"Number of elements must be power-of-two, but \")\n-                 << *op << \" doesn't follow the rule\";\n-      }\n-    }\n-\n-    for (auto opType : op->getResultTypes()) {\n-      if (auto tensorType = opType.dyn_cast<RankedTensorType>()) {\n-        int64_t numElements = 1;\n-        for (int64_t s : tensorType.getShape())\n-          numElements *= s;\n-        if (numElements > maxElement)\n-          return op->emitError(\"Maximum allowed number of elements is \")\n-                 << maxElement << \", but \" << *op << \" has more than that\";\n-        if ((numElements & (numElements - 1)) != 0)\n-          return op->emitError(\"Number of elements must be power-of-two, but \")\n-                 << *op << \" doesn't follow the rule\";\n-      }\n-    }\n-\n-    return success();\n+    return impl::verifyTensorSize(op);\n+  }\n+};\n+\n+template <typename ConcreteType>\n+class SameOperandsAndResultEncoding\n+    : public TraitBase<ConcreteType, SameOperandsAndResultEncoding> {\n+public:\n+  static LogicalResult verifyTrait(Operation *op) {\n+    return impl::verifySameOperandsAndResultEncoding(op);\n+  }\n+};\n+\n+template <typename ConcreteType>\n+class SameOperandsEncoding\n+    : public TraitBase<ConcreteType, SameOperandsEncoding> {\n+public:\n+  static LogicalResult verifyTrait(Operation *op) {\n+    return impl::verifySameOperandsEncoding(op);\n   }\n };\n "}, {"filename": "include/triton/Dialect/Triton/IR/TritonDialect.td", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -41,4 +41,7 @@ def Triton_Dialect : Dialect {\n   let hasConstantMaterializer = 1;\n }\n \n+include \"triton/Dialect/Triton/IR/TritonTypes.td\"\n+\n+\n #endif // TRITON_DIALECT"}, {"filename": "include/triton/Dialect/Triton/IR/TritonInterfaces.td", "status": "added", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -0,0 +1,6 @@\n+#ifndef TRITON_INTERFACES\n+#define TRITON_INTERFACES\n+\n+include \"mlir/IR/OpBase.td\"\n+\n+#endif // TRITON_INTERFACES\n\\ No newline at end of file"}, {"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 107, "deletions": 67, "changes": 174, "file_content_changes": "@@ -4,18 +4,23 @@\n include \"triton/Dialect/Triton/IR/TritonDialect.td\"\n include \"triton/Dialect/Triton/IR/TritonTypes.td\"\n include \"triton/Dialect/Triton/IR/TritonAttrDefs.td\"\n+include \"triton/Dialect/Triton/IR/TritonInterfaces.td\"\n include \"mlir/IR/OpBase.td\"\n include \"mlir/Interfaces/SideEffectInterfaces.td\" // NoSideEffect\n include \"mlir/Interfaces/ControlFlowInterfaces.td\" // BranchOpInterface\n include \"mlir/Interfaces/InferTypeOpInterface.td\" // SameOperandsAndResultType\n-\n+include \"mlir/Interfaces/SideEffectInterfaces.td\" // NoSideEffect\n \n def TensorSizeTrait : NativeOpTrait<\"TensorSizeTrait\">;\n+def SameOperandsAndResultEncoding : NativeOpTrait<\"SameOperandsAndResultEncoding\">;\n+def SameOperandsEncoding : NativeOpTrait<\"SameOperandsEncoding\">;\n+\n //\n // Op Base\n //\n class TT_Op<string mnemonic, list<Trait> traits = []> :\n-    Op<Triton_Dialect, mnemonic, !listconcat(traits, [TensorSizeTrait])>;\n+    Op<Triton_Dialect, mnemonic, !listconcat(traits, [TensorSizeTrait])> {\n+}\n \n //\n // CastOps\n@@ -25,7 +30,9 @@ class TT_Op<string mnemonic, list<Trait> traits = []> :\n //   fptoui, fptosi, uitofp, sitofp,\n //   extf, tructf,\n //   extui, extsi, tructi\n-def TT_IntToPtrOp : TT_Op<\"int_to_ptr\", [SameOperandsAndResultShape, NoSideEffect,\n+def TT_IntToPtrOp : TT_Op<\"int_to_ptr\", [SameOperandsAndResultShape, \n+                                         SameOperandsAndResultEncoding, \n+                                         NoSideEffect,\n                                          /*DeclareOpInterfaceMethods<CastOpInterface>*/]> {\n     let summary = \"Cast int64 to pointer\";\n \n@@ -36,7 +43,9 @@ def TT_IntToPtrOp : TT_Op<\"int_to_ptr\", [SameOperandsAndResultShape, NoSideEffec\n     let assemblyFormat = \"$from attr-dict `:` type($from) `->` type($result)\";\n }\n \n-def TT_PtrToIntOp : TT_Op<\"ptr_to_int\", [SameOperandsAndResultShape, NoSideEffect,\n+def TT_PtrToIntOp : TT_Op<\"ptr_to_int\", [SameOperandsAndResultShape, \n+                                         SameOperandsAndResultEncoding,\n+                                         NoSideEffect,\n                                          /*DeclareOpInterfaceMethods<CastOpInterface>*/]> {\n     let summary = \"Cast pointer to int64\";\n \n@@ -47,7 +56,9 @@ def TT_PtrToIntOp : TT_Op<\"ptr_to_int\", [SameOperandsAndResultShape, NoSideEffec\n     let assemblyFormat = \"$from attr-dict `:` type($from) `->` type($result)\";\n }\n \n-def TT_FpToFp : TT_Op<\"fp_to_fp\", [SameOperandsAndResultShape, NoSideEffect,\n+def TT_FpToFp : TT_Op<\"fp_to_fp\", [SameOperandsAndResultShape, \n+                                   SameOperandsAndResultEncoding,\n+                                   NoSideEffect,\n                                    /*DeclareOpInterfaceMethods<CastOpInterface>*/]> {\n     let summary = \"Floating point casting for custom types\";\n \n@@ -67,11 +78,33 @@ def TT_FpToFp : TT_Op<\"fp_to_fp\", [SameOperandsAndResultShape, NoSideEffect,\n     // TODO: We need a verifier here.\n }\n \n+//\n+// Pointer Arith Ops\n+//\n+\n+def TT_AddPtrOp : TT_Op<\"addptr\",\n+                     [NoSideEffect, \n+                     SameOperandsAndResultShape,\n+                     SameOperandsAndResultEncoding,\n+                      TypesMatchWith<\"result type matches ptr type\",\n+                                     \"result\", \"ptr\", \"$_self\">,\n+                      TypesMatchWith<\"result shape matches offset shape\",\n+                                     \"result\", \"offset\",\n+                                     \"getI32SameShape($_self)\">]> {\n+    let arguments = (ins TT_PtrLike:$ptr, TT_I32Like:$offset);\n+\n+    let results = (outs TT_PtrLike:$result);\n+\n+    let assemblyFormat = \"$ptr `,` $offset attr-dict `:` type($result)\";\n+}\n+\n+\n //\n // Load/Store Ops\n //\n def TT_LoadOp : TT_Op<\"load\",\n                       [SameOperandsAndResultShape,\n+                       SameOperandsAndResultEncoding,\n                        SameVariadicOperandSize,\n                        MemoryEffects<[MemRead]>,\n                        TypesMatchWith<\"infer ptr type from result type\",\n@@ -110,6 +143,7 @@ def TT_LoadOp : TT_Op<\"load\",\n \n def TT_StoreOp : TT_Op<\"store\",\n                        [SameOperandsShape,\n+                        SameOperandsEncoding,\n                         MemoryEffects<[MemWrite]>,\n                         TypesMatchWith<\"infer ptr type from value type\",\n                                        \"value\", \"ptr\",\n@@ -133,57 +167,87 @@ def TT_StoreOp : TT_Op<\"store\",\n     let hasCanonicalizer = 1;\n }\n \n-def TT_AddPtrOp : TT_Op<\"addptr\",\n-                     [NoSideEffect, SameOperandsAndResultShape,\n-                      TypesMatchWith<\"result type matches ptr type\",\n-                                     \"result\", \"ptr\", \"$_self\">,\n-                      TypesMatchWith<\"result shape matches offset shape\",\n-                                     \"result\", \"offset\",\n-                                     \"getI32SameShape($_self)\">]> {\n-    let arguments = (ins TT_PtrLike:$ptr, TT_I32Like:$offset);\n+//\n+// Atomic Op\n+//\n+def TT_AtomicRMWOp : TT_Op<\"atomic_rmw\", [SameOperandsAndResultShape,\n+                                          SameOperandsAndResultEncoding]> {\n+    let summary = \"atomic rmw\";\n \n-    let results = (outs TT_PtrLike:$result);\n+    let description = [{\n+        load data at $ptr, do $rmw_op with $val, and store result to $ptr.\n \n-    let assemblyFormat = \"$ptr `,` $offset attr-dict `:` type($result)\";\n+        return old value at $ptr\n+    }];\n+\n+    let arguments = (ins TT_AtomicRMWAttr:$atomic_rmw_op, TT_PtrTensor:$ptr,\n+                         TT_Type:$val, I1Tensor:$mask);\n+\n+    let results = (outs TT_Type:$result);\n+}\n+\n+def TT_AtomicCASOp : TT_Op<\"atomic_cas\", [SameOperandsAndResultShape,\n+                                          SameOperandsAndResultEncoding]> {\n+    let summary = \"atomic cas\";\n+\n+    let description = [{\n+        compare $cmp with data $old at location $ptr,\n+\n+        if $old == $cmp, store $val to $ptr,\n+\n+        else store $old to $ptr,\n+\n+        return $old\n+    }];\n+\n+    let arguments = (ins TT_Ptr:$ptr, TT_Type:$cmp, TT_Type:$val);\n+\n+    let results = (outs TT_Type:$result);\n }\n \n \n //\n // Shape Manipulation Ops\n //\n-def TT_ExpandDimsOp : TT_Op<\"expand_dims\", [NoSideEffect, SameOperandsAndResultElementType]> {\n-    let summary = \"expand_dims\";\n+def TT_SplatOp : TT_Op<\"splat\", [NoSideEffect, \n+                                 SameOperandsAndResultElementType]> {\n+    let summary = \"splat\";\n \n-    let arguments = (ins TT_Tensor:$src, I32Attr:$axis);\n+    let arguments = (ins TT_Type:$src);\n \n     let results = (outs TT_Tensor:$result);\n \n     let assemblyFormat = \"$src attr-dict `:` functional-type(operands, results)\";\n+\n+    let hasFolder = 1;\n }\n \n-def TT_ViewOp : TT_Op<\"view\", [NoSideEffect, SameOperandsAndResultElementType]> {\n-    let summary = \"view\";\n+def TT_ExpandDimsOp : TT_Op<\"expand_dims\", [NoSideEffect, \n+                                            DeclareOpInterfaceMethods<InferTypeOpInterface>, \n+                                            SameOperandsAndResultElementType]> {\n+    let summary = \"expand_dims\";\n \n-    let arguments = (ins TT_Tensor:$src);\n+    let arguments = (ins TT_Tensor:$src, I32Attr:$axis);\n \n     let results = (outs TT_Tensor:$result);\n \n     let assemblyFormat = \"$src attr-dict `:` functional-type(operands, results)\";\n }\n \n-def TT_SplatOp : TT_Op<\"splat\", [NoSideEffect, SameOperandsAndResultElementType]> {\n-    let summary = \"splat\";\n+def TT_ViewOp : TT_Op<\"view\", [NoSideEffect, \n+                               SameOperandsAndResultElementType]> {\n+    let summary = \"view\";\n \n-    let arguments = (ins TT_Type:$src);\n+    let arguments = (ins TT_Tensor:$src);\n \n     let results = (outs TT_Tensor:$result);\n \n     let assemblyFormat = \"$src attr-dict `:` functional-type(operands, results)\";\n \n-    let hasFolder = 1;\n }\n \n-def TT_BroadcastOp : TT_Op<\"broadcast\", [NoSideEffect, SameOperandsAndResultElementType]> {\n+def TT_BroadcastOp : TT_Op<\"broadcast\", [NoSideEffect, \n+                                         SameOperandsAndResultElementType]> {\n     let summary = \"broadcast. No left-padding as of now.\";\n \n     let arguments = (ins TT_Type:$src);\n@@ -195,7 +259,8 @@ def TT_BroadcastOp : TT_Op<\"broadcast\", [NoSideEffect, SameOperandsAndResultElem\n     let hasFolder = 1;\n }\n \n-def TT_CatOp : TT_Op<\"cat\", [NoSideEffect, SameOperandsAndResultElementType]> {\n+def TT_CatOp : TT_Op<\"cat\", [NoSideEffect, \n+                             SameOperandsAndResultElementType]> {\n     let summary = \"concatenate 2 tensors\";\n \n     let arguments = (ins TT_Tensor:$lhs, TT_Tensor:$rhs);\n@@ -206,7 +271,7 @@ def TT_CatOp : TT_Op<\"cat\", [NoSideEffect, SameOperandsAndResultElementType]> {\n }\n \n //\n-// builtin Ops\n+// SPMD Ops\n //\n def TT_GetProgramIdOp : TT_Op<\"get_program_id\"> {\n     let arguments = (ins I32Attr:$axis);\n@@ -224,7 +289,11 @@ def TT_GetNumProgramsOp : TT_Op<\"get_num_programs\"> {\n     let assemblyFormat = \"attr-dict `:` type($result)\";\n }\n \n-def TT_DotOp : TT_Op<\"dot\", [NoSideEffect,\n+//\n+// Dot Op\n+//\n+def TT_DotOp : TT_Op<\"dot\", [NoSideEffect, \n+                             DeclareOpInterfaceMethods<InferTypeOpInterface>,\n                              TypesMatchWith<\"result's type matches accumulator's type\",\n                                             \"d\", \"c\", \"$_self\">]> {\n     let summary = \"dot\";\n@@ -238,11 +307,13 @@ def TT_DotOp : TT_Op<\"dot\", [NoSideEffect,\n     let results = (outs TT_FpIntTensor:$d);\n \n     let assemblyFormat = \"$a`,` $b`,` $c attr-dict `:` type($a) `*` type($b) `->` type($d)\";\n-\n-    // let hasCanonicalizer = 1;\n }\n \n-def TT_ReduceOp : TT_Op<\"reduce\", [NoSideEffect]> {\n+//\n+// Reduce Op\n+//\n+def TT_ReduceOp : TT_Op<\"reduce\", [NoSideEffect,\n+                                   DeclareOpInterfaceMethods<InferTypeOpInterface>]> {\n     let summary = \"reduce\";\n \n     let arguments = (ins TT_RedOpAttr:$redOp, TT_Tensor:$operand, I32Attr:$axis);\n@@ -256,43 +327,11 @@ def TT_ReduceOp : TT_Op<\"reduce\", [NoSideEffect]> {\n     let assemblyFormat = \"$operand attr-dict `:` type($operand) `->` type($result)\";\n }\n \n-def TT_AtomicRMWOp : TT_Op<\"atomic_rmw\"> {\n-    let summary = \"atomic rmw\";\n-\n-    let description = [{\n-        load data at $ptr, do $rmw_op with $val, and store result to $ptr.\n-\n-        return old value at $ptr\n-    }];\n-\n-    let arguments = (ins TT_AtomicRMWAttr:$atomic_rmw_op, TT_PtrTensor:$ptr,\n-                         TT_Type:$val, I1Tensor:$mask);\n-\n-    let results = (outs TT_Type:$result);\n-}\n-\n-def TT_AtomicCASOp : TT_Op<\"atomic_cas\"> {\n-    let summary = \"atomic cas\";\n-\n-    let description = [{\n-        compare $cmp with data $old at location $ptr,\n-\n-        if $old == $cmp, store $val to $ptr,\n-\n-        else store $old to $ptr,\n-\n-        return $old\n-    }];\n-\n-    let arguments = (ins TT_Ptr:$ptr, TT_Type:$cmp, TT_Type:$val);\n-\n-    let results = (outs TT_Type:$result);\n-}\n-\n //\n-// External Function Ops\n+// External elementwise op\n //\n def TT_ExtElemwiseOp : TT_Op<\"ext_elemwise\", [NoSideEffect, Elementwise, SameOperandsAndResultShape,\n+                                              SameOperandsAndResultEncoding,\n                                               SameVariadicOperandSize]> {\n     let summary = \"ext_elemwise\";\n \n@@ -307,10 +346,11 @@ def TT_ExtElemwiseOp : TT_Op<\"ext_elemwise\", [NoSideEffect, Elementwise, SameOpe\n     let results = (outs TT_Tensor:$result);\n \n     let assemblyFormat = \"operands attr-dict `:` type(operands) `->` type($result)\";\n+\n }\n \n //\n-// Intrinsics\n+// Make Range Op\n //\n // TODO: should have ConstantLike as Trait\n def TT_MakeRangeOp : TT_Op<\"make_range\", [NoSideEffect]> {"}, {"filename": "include/triton/Dialect/TritonGPU/IR/Dialect.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -11,6 +11,7 @@\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h.inc\"\n \n #define GET_ATTRDEF_CLASSES\n+#include \"triton/Dialect/Triton/IR/AttrInterfaces.h.inc\"\n #include \"triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.h.inc\"\n \n #define GET_OP_CLASSES"}, {"filename": "include/triton/Dialect/TritonGPU/IR/TritonGPUAttrDefs.td", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "file_content_changes": "@@ -2,6 +2,7 @@\n #define TRITONGPU_ATTRDEFS\n \n include \"triton/Dialect/TritonGPU/IR/TritonGPUDialect.td\"\n+include \"triton/Dialect/Triton/IR/TritonInterfaces.td\"\n \n //===----------------------------------------------------------------------===//\n // TritonGPU Attribute Definitions\n@@ -34,6 +35,7 @@ Right now, Triton implements two classes of layouts: shared, and distributed.\n \n   code extraBaseClassDeclaration = [{\n     unsigned getElemsPerThread(ArrayRef<int64_t> shape) const;\n+    ::mlir::LogicalResult verifyLayoutForArg(::mlir::Operation* op, unsigned argNo) const;\n   }];\n }\n \n@@ -301,15 +303,15 @@ def SliceEncodingAttr : DistributedEncoding<\"SliceEncoding\"> {\n     TODO: improve docs\n \n     A = [x  x  x  x  x  x  x  x]\n-        [x  x  x  x  x  x  x  x]\n-    L_parent = [0  1  2  3 ]\n-               [4  5  6  7 ]\n-               [8  9  10 11]\n-               [12 13 14 15]\n+\n+    parent = [0  1  2  3 ]\n+             [4  5  6  7 ]\n+             [8  9  10 11]\n+             [12 13 14 15]\n     dim = 0\n \n     Then the data of A would be distributed as follow between the 16 CUDA threads:\n-    L(A) = [ {0,4,8,12} , {1,5,9,13} , ... {3,7,11,15} ]\n+    L(A) = [ {0,4,8,12} , {1,5,9,13} , ... {3,7,11,15}, {0,4,8,12} , ..., {3,7,11,15} ]\n \n     This is useful for constructing the inverse layout of an expand_dims operation during some optimization passes.\n "}, {"filename": "include/triton/Dialect/TritonGPU/Transforms/Passes.td", "status": "modified", "additions": 0, "deletions": 11, "changes": 11, "file_content_changes": "@@ -76,15 +76,4 @@ def TritonGPUCanonicalizeLoops: Pass<\"tritongpu-canonicalize-loops\", \"mlir::Modu\n   let dependentDialects = [\"mlir::triton::gpu::TritonGPUDialect\"];\n }\n \n-def TritonGPUVerifier : Pass<\"tritongpu-verifier\", \"mlir::ModuleOp\"> {\n-  let summary = \"verify TritonGPU IR\";\n-\n-  let description = [{}];\n-\n-  let constructor = \"mlir::createTritonGPUVerifier()\";\n-\n-  let dependentDialects = [\"mlir::triton::gpu::TritonGPUDialect\",\n-                           \"mlir::gpu::GPUDialect\"];\n-}\n-\n #endif"}, {"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPU.cpp", "status": "modified", "additions": 10, "deletions": 4, "changes": 14, "file_content_changes": "@@ -185,9 +185,16 @@ struct TritonExpandDimsPattern\n     // return type\n     RankedTensorType retType =\n         RankedTensorType::get(retShape, argType.getElementType(), retEncoding);\n+    // convert operand to slice of return type\n+    Attribute newArgEncoding = triton::gpu::SliceEncodingAttr::get(\n+        getContext(), op.axis(), retEncoding);\n+    RankedTensorType newArgType = RankedTensorType::get(\n+        argType.getShape(), argType.getElementType(), newArgEncoding);\n     // construct new op\n-    rewriter.replaceOpWithNewOp<triton::ExpandDimsOp>(\n-        op, retType, adaptor.src(), adaptor.axis());\n+    auto newSrc = rewriter.create<triton::gpu::ConvertLayoutOp>(\n+        op.getLoc(), newArgType, adaptor.src());\n+    rewriter.replaceOpWithNewOp<triton::ExpandDimsOp>(op, newSrc,\n+                                                      adaptor.axis());\n     return success();\n   }\n };\n@@ -310,9 +317,8 @@ struct TritonReducePattern : public OpConversionPattern<triton::ReduceOp> {\n   LogicalResult\n   matchAndRewrite(triton::ReduceOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n-    Type retType = this->getTypeConverter()->convertType(op.getType());\n     auto newOp = rewriter.replaceOpWithNewOp<triton::ReduceOp>(\n-        op, retType, adaptor.redOp(), adaptor.operand(), adaptor.axis());\n+        op, adaptor.redOp(), adaptor.operand(), adaptor.axis());\n     return success();\n   }\n };"}, {"filename": "lib/Dialect/Triton/IR/CMakeLists.txt", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -1,7 +1,9 @@\n add_mlir_dialect_library(TritonIR\n+  Interfaces.cpp\n   Dialect.cpp\n   Ops.cpp\n   Types.cpp\n+  Traits.cpp\n \n   DEPENDS\n   TritonTableGen"}, {"filename": "lib/Dialect/Triton/IR/Dialect.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -1,6 +1,7 @@\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/Triton/IR/Types.h\"\n \n+#include \"triton/Dialect/Triton/IR/AttrInterfaces.h.inc\"\n #include \"llvm/ADT/StringSwitch.h\"\n #include \"llvm/ADT/TypeSwitch.h\"\n #include \"llvm/Support/raw_ostream.h\""}, {"filename": "lib/Dialect/Triton/IR/Interfaces.cpp", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "file_content_changes": "N/A"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 71, "deletions": 1, "changes": 72, "file_content_changes": "@@ -160,18 +160,88 @@ void LoadOp::build(::mlir::OpBuilder &builder, ::mlir::OperationState &state,\n }\n \n //-- DotOp --\n+mlir::LogicalResult mlir::triton::DotOp::inferReturnTypes(\n+    MLIRContext *context, Optional<Location> location, ValueRange operands,\n+    DictionaryAttr attributes, RegionRange regions,\n+    SmallVectorImpl<Type> &inferredReturnTypes) {\n+  // type is the same as the accumulator\n+  auto accTy = operands[2].getType().cast<RankedTensorType>();\n+  inferredReturnTypes.push_back(accTy);\n+  return mlir::success();\n+}\n+\n+//-- ReduceOp --\n+mlir::LogicalResult mlir::triton::ReduceOp::inferReturnTypes(\n+    MLIRContext *context, Optional<Location> location, ValueRange operands,\n+    DictionaryAttr attributes, RegionRange regions,\n+    SmallVectorImpl<Type> &inferredReturnTypes) {\n+  // infer shape\n+  Value arg = operands[0];\n+  auto argTy = arg.getType().cast<RankedTensorType>();\n+  auto retShape = argTy.getShape().vec();\n+  int axis = attributes.get(\"axis\").cast<IntegerAttr>().getInt();\n+  retShape.erase(retShape.begin() + axis);\n+  // infer encoding\n+  Attribute argEncoding = argTy.getEncoding();\n+  Attribute retEncoding;\n+  if (argEncoding) {\n+    Dialect &dialect = argEncoding.getDialect();\n+    auto inferLayoutInterface = dyn_cast<DialectInferLayoutInterface>(&dialect);\n+    if (inferLayoutInterface\n+            ->inferReduceOpEncoding(argEncoding, axis, retEncoding)\n+            .failed()) {\n+      llvm::report_fatal_error(\"failed to infer layout for ReduceOp\");\n+      return mlir::failure();\n+    }\n+  }\n+  // create type\n+  auto argEltTy = argTy.getElementType();\n+  inferredReturnTypes.push_back(\n+      RankedTensorType::get(retShape, argEltTy, retEncoding));\n+  return mlir::success();\n+}\n \n //-- SplatOp --\n OpFoldResult SplatOp::fold(ArrayRef<Attribute> operands) {\n   auto constOperand = src().getDefiningOp<arith::ConstantOp>();\n   if (!constOperand)\n     return {};\n-\n   auto shapedType = getType().cast<ShapedType>();\n   auto ret = SplatElementsAttr::get(shapedType, {constOperand.getValue()});\n   return ret;\n }\n \n+//-- ExpandDimsOp --\n+mlir::LogicalResult mlir::triton::ExpandDimsOp::inferReturnTypes(\n+    MLIRContext *context, Optional<Location> location, ValueRange operands,\n+    DictionaryAttr attributes, RegionRange regions,\n+    SmallVectorImpl<Type> &inferredReturnTypes) {\n+  // infer shape\n+  auto arg = operands[0];\n+  auto argTy = arg.getType().cast<RankedTensorType>();\n+  auto retShape = argTy.getShape().vec();\n+  int axis = attributes.get(\"axis\").cast<IntegerAttr>().getInt();\n+  retShape.insert(retShape.begin() + axis, 1);\n+  // infer encoding\n+  Attribute argEncoding = argTy.getEncoding();\n+  Attribute retEncoding;\n+  if (argEncoding) {\n+    Dialect &dialect = argEncoding.getDialect();\n+    auto inferLayoutInterface = dyn_cast<DialectInferLayoutInterface>(&dialect);\n+    if (inferLayoutInterface\n+            ->inferExpandDimsOpEncoding(argEncoding, axis, retEncoding)\n+            .failed()) {\n+      llvm::report_fatal_error(\"failed to infer layout for ExpandDimsOp\");\n+      return mlir::failure();\n+    }\n+  }\n+  // create type\n+  auto argEltTy = argTy.getElementType();\n+  inferredReturnTypes.push_back(\n+      RankedTensorType::get(retShape, argEltTy, retEncoding));\n+  return mlir::success();\n+}\n+\n //-- BroadcastOp --\n OpFoldResult BroadcastOp::fold(ArrayRef<Attribute> operands) {\n   auto constOperand = src().getDefiningOp<arith::ConstantOp>();"}, {"filename": "lib/Dialect/Triton/IR/Traits.cpp", "status": "added", "additions": 69, "deletions": 0, "changes": 69, "file_content_changes": "@@ -0,0 +1,69 @@\n+#include \"triton/Dialect/Triton/IR/Traits.h\"\n+\n+static mlir::LogicalResult verifySameEncoding(mlir::Type tyA, mlir::Type tyB) {\n+  using namespace mlir;\n+  auto encA = tyA.dyn_cast<RankedTensorType>();\n+  auto encB = tyA.dyn_cast<RankedTensorType>();\n+  if (!encA || !encB)\n+    return success();\n+  return encA.getEncoding() == encB.getEncoding() ? success() : failure();\n+}\n+\n+mlir::LogicalResult\n+mlir::OpTrait::impl::verifySameOperandsAndResultEncoding(Operation *op) {\n+  if (failed(verifyAtLeastNOperands(op, 1)) ||\n+      failed(verifyAtLeastNResults(op, 1)))\n+    return failure();\n+\n+  auto type = op->getOperand(0).getType();\n+  for (auto resultType : op->getResultTypes())\n+    if (failed(verifySameEncoding(resultType, type)))\n+      return op->emitOpError()\n+             << \"requires the same shape for all operands and results\";\n+  return verifySameOperandsEncoding(op);\n+}\n+\n+mlir::LogicalResult\n+mlir::OpTrait::impl::verifySameOperandsEncoding(Operation *op) {\n+  if (failed(verifyAtLeastNOperands(op, 1)))\n+    return failure();\n+\n+  auto type = op->getOperand(0).getType();\n+  for (auto opType : llvm::drop_begin(op->getOperandTypes(), 1))\n+    if (failed(verifySameEncoding(opType, type)))\n+      return op->emitOpError() << \"requires the same encoding for all operands\";\n+\n+  return success();\n+}\n+\n+mlir::LogicalResult mlir::OpTrait::impl::verifyTensorSize(Operation *op) {\n+  for (auto opType : op->getOperandTypes()) {\n+    if (auto tensorType = opType.dyn_cast<RankedTensorType>()) {\n+      int64_t numElements = 1;\n+      for (int64_t s : tensorType.getShape())\n+        numElements *= s;\n+      if (numElements > maxTensorNumElements)\n+        return op->emitError(\"Maximum allowed number of elements is \")\n+               << maxTensorNumElements << \", but \" << *op\n+               << \" has more than that\";\n+      if ((numElements & (numElements - 1)) != 0)\n+        return op->emitError(\"Number of elements must be power-of-two, but \")\n+               << *op << \" doesn't follow the rule\";\n+    }\n+  }\n+  for (auto opType : op->getResultTypes()) {\n+    if (auto tensorType = opType.dyn_cast<RankedTensorType>()) {\n+      int64_t numElements = 1;\n+      for (int64_t s : tensorType.getShape())\n+        numElements *= s;\n+      if (numElements > maxTensorNumElements)\n+        return op->emitError(\"Maximum allowed number of elements is \")\n+               << maxTensorNumElements << \", but \" << *op\n+               << \" has more than that\";\n+      if ((numElements & (numElements - 1)) != 0)\n+        return op->emitError(\"Number of elements must be power-of-two, but \")\n+               << *op << \" doesn't follow the rule\";\n+    }\n+  }\n+  return success();\n+}\n\\ No newline at end of file"}, {"filename": "lib/Dialect/TritonGPU/IR/Dialect.cpp", "status": "modified", "additions": 38, "deletions": 20, "changes": 58, "file_content_changes": "@@ -3,6 +3,7 @@\n #include \"mlir/IR/DialectImplementation.h\"\n #include \"mlir/IR/OpImplementation.h\"\n #include \"triton/Analysis/Utility.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n #include \"llvm/ADT/TypeSwitch.h\"\n \n@@ -288,8 +289,9 @@ Attribute BlockedEncodingAttr::parse(AsmParser &parser, Type type) {\n     }\n   }\n \n-  return parser.getChecked<BlockedEncodingAttr>(\n+  auto ret = parser.getChecked<BlockedEncodingAttr>(\n       parser.getContext(), sizePerThread, threadsPerWarp, warpsPerCTA, order);\n+  return ret;\n }\n \n void BlockedEncodingAttr::print(mlir::AsmPrinter &printer) const {\n@@ -346,27 +348,13 @@ void MmaEncodingAttr::print(AsmPrinter &printer) const {\n Attribute SliceEncodingAttr::parse(AsmParser &parser, Type type) {\n   if (parser.parseLess().failed())\n     return {};\n-  // Parse the data as a dictionary\n-  DictionaryAttr dict;\n-  if (parser.parseAttribute(dict).failed())\n+  NamedAttrList attrs;\n+  if (parser.parseOptionalAttrDict(attrs).failed())\n     return {};\n   if (parser.parseGreater().failed())\n     return {};\n-\n-  unsigned dim = 0;\n-  Attribute parent;\n-\n-  for (const NamedAttribute &attr : dict) {\n-    if (attr.getName() == \"dim\") {\n-      if (parseUInt(parser, attr, dim, \"dim\").failed())\n-        return {};\n-    }\n-    if (attr.getName() == \"parent\") {\n-      if (parser.parseAttribute(parent).failed())\n-        return {};\n-    }\n-  }\n-\n+  unsigned dim = attrs.get(\"dim\").cast<IntegerAttr>().getInt();\n+  Attribute parent = attrs.get(\"parent\");\n   return parser.getChecked<SliceEncodingAttr>(parser.getContext(), dim, parent);\n }\n \n@@ -522,6 +510,35 @@ class TritonGPUOpAsmInterface : public OpAsmDialectInterface {\n   }\n };\n \n+struct TritonGPUInferLayoutInterface\n+    : public triton::DialectInferLayoutInterface {\n+  using DialectInferLayoutInterface::DialectInferLayoutInterface;\n+\n+  LogicalResult inferReduceOpEncoding(Attribute operandEncoding, int axis,\n+                                      Attribute &resultEncoding) const {\n+    resultEncoding = SliceEncodingAttr::get(getDialect()->getContext(), axis,\n+                                            operandEncoding);\n+    return success();\n+  }\n+\n+  LogicalResult inferExpandDimsOpEncoding(Attribute operandEncoding, int axis,\n+                                          Attribute &resultEncoding) const {\n+    auto sliceEncoding = operandEncoding.dyn_cast<SliceEncodingAttr>();\n+    if (!sliceEncoding) {\n+      llvm::report_fatal_error(\n+          \"ExpandDimsOp operand encoding must be SliceEncodingAttr\");\n+      return failure();\n+    }\n+    if (sliceEncoding.getDim() != axis) {\n+      llvm::report_fatal_error(\n+          \"Incompatible slice dimension for ExpandDimsOp operand\");\n+      return failure();\n+    }\n+    resultEncoding = sliceEncoding.getParent();\n+    return success();\n+  }\n+};\n+\n void TritonGPUDialect::initialize() {\n   addAttributes<\n #define GET_ATTRDEF_LIST\n@@ -532,6 +549,7 @@ void TritonGPUDialect::initialize() {\n #include \"triton/Dialect/TritonGPU/IR/Ops.cpp.inc\"\n       >();\n   addInterfaces<TritonGPUOpAsmInterface>();\n+  addInterfaces<TritonGPUInferLayoutInterface>();\n }\n \n //===----------------------------------------------------------------------===//\n@@ -568,4 +586,4 @@ LogicalResult TritonGPUDialect::verifyOperationAttribute(Operation *op,\n                                                          NamedAttribute attr) {\n   // TODO: fill this.\n   return success();\n-}\n+}\n\\ No newline at end of file"}, {"filename": "lib/Dialect/TritonGPU/Transforms/CMakeLists.txt", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -8,7 +8,6 @@ add_mlir_dialect_library(TritonGPUTransforms\n   Combine.cpp\n   Pipeline.cpp\n   Swizzle.cpp\n-  Verifier.cpp\n   TritonGPUConversion.cpp\n \n   DEPENDS"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Verifier.cpp", "status": "removed", "additions": 0, "deletions": 106, "changes": 106, "file_content_changes": "@@ -1,106 +0,0 @@\n-#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n-#include \"triton/Dialect/TritonGPU/Transforms/Passes.h\"\n-\n-#include <memory>\n-\n-using namespace mlir;\n-\n-#define GEN_PASS_CLASSES\n-#include \"triton/Dialect/TritonGPU/Transforms/Passes.h.inc\"\n-\n-class TritonGPUVerifier : public TritonGPUVerifierBase<TritonGPUVerifier> {\n-public:\n-  void runOnOperation() override {\n-    MLIRContext *context = &getContext();\n-    ModuleOp m = getOperation();\n-\n-    // The idea is similar to mlir/lib/IR/Verifier.cpp\n-    verifyImpl(m.getOperation());\n-  }\n-\n-private:\n-  LogicalResult verifySingleOp(Operation *op) {\n-    if (auto dotOp = llvm::dyn_cast<triton::DotOp>(op)) {\n-      Type aType = dotOp.a().getType();\n-      Type bType = dotOp.b().getType();\n-      Type cType = dotOp.c().getType();\n-      Type dType = dotOp.d().getType();\n-      for (auto it : llvm::zip(llvm::SmallVector<Type>{aType, bType},\n-                               llvm::SmallVector<char>{'a', 'b'})) {\n-        Type type = std::get<0>(it);\n-        char name = std::get<1>(it);\n-        if (auto tensorType = type.dyn_cast<RankedTensorType>()) {\n-          Attribute encoding = tensorType.getEncoding();\n-          if (!encoding)\n-            return dotOp.emitError() << name << \" should have encoding\";\n-          if (!encoding.isa<triton::gpu::SharedEncodingAttr>())\n-            return dotOp.emitError() << name << \" should be of shared layout\";\n-        } else\n-          return dotOp.emitError()\n-                 << name << \"'s type should be of RankedTensorType\";\n-      }\n-\n-      Attribute cLayout;\n-      for (auto it : llvm::zip(llvm::SmallVector<Type>{cType, dType},\n-                               llvm::SmallVector<char>{'c', 'd'})) {\n-        Type type = std::get<0>(it);\n-        char name = std::get<1>(it);\n-        if (auto tensorType = type.dyn_cast<RankedTensorType>()) {\n-          Attribute encoding = tensorType.getEncoding();\n-          if (!encoding)\n-            return dotOp.emitError() << name << \" should have encoding\";\n-          if (!encoding.isa<triton::gpu::MmaEncodingAttr>() &&\n-              !encoding.isa<triton::gpu::BlockedEncodingAttr>())\n-            return dotOp.emitError()\n-                   << name << \" should be of distributed layout\";\n-          if (name == 'c')\n-            cLayout = encoding;\n-          else if (encoding != cLayout)\n-            return dotOp.emitError() << \"d & c should have the same layout\";\n-        } else\n-          return dotOp.emitError()\n-                 << name << \"'s type should be of RankedTensorType\";\n-      }\n-\n-      // signalPassFailure();\n-    }\n-    if (auto loadOp = llvm::dyn_cast<triton::LoadOp>(op)) {\n-      // TODO: fill this\n-    }\n-    if (auto storeOp = llvm::dyn_cast<triton::StoreOp>(op)) {\n-      // TODO: fill this\n-    }\n-    if (auto addptrOp = llvm::dyn_cast<triton::AddPtrOp>(op)) {\n-      // TODO: fill this\n-    }\n-    // Triton builtin Ops\n-    if (llvm::isa<triton::GetProgramIdOp, triton::GetNumProgramsOp,\n-                  triton::MakeRangeOp>(op)) {\n-      // TODO: fill this\n-    }\n-    if (auto atomicRmw = llvm::dyn_cast<triton::AtomicRMWOp>(op)) {\n-      // TODO: fill this\n-    }\n-    if (auto atomicCas = llvm::dyn_cast<triton::AtomicCASOp>(op)) {\n-      // TODO: fill this\n-    }\n-\n-    // TODO: Arithmetic, SCF, TritonGPU ops\n-    return success();\n-  }\n-\n-  void verifyImpl(Operation *op) {\n-    if (verifySingleOp(op).failed())\n-      signalPassFailure();\n-\n-    // verify that all child regions are ok\n-    for (Region &region : op->getRegions())\n-      for (Block &block : region)\n-        for (Operation &childOp : block)\n-          verifyImpl(&childOp);\n-  }\n-};\n-\n-std::unique_ptr<Pass> mlir::createTritonGPUVerifier() {\n-  return std::make_unique<TritonGPUVerifier>();\n-}"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "file_content_changes": "@@ -1182,10 +1182,6 @@ void init_triton_ir(py::module &&m) {\n            [](mlir::PassManager &self) {\n              self.addPass(mlir::createTritonGPUCombineOpsPass());\n            })\n-      .def(\"add_triton_gpu_verifier_pass\",\n-           [](mlir::PassManager &self) {\n-             self.addPass(mlir::createTritonGPUVerifier());\n-           })\n       .def(\"add_triton_gpu_to_llvm\",\n            [](mlir::PassManager &self) {\n              self.addPass(mlir::triton::createConvertTritonGPUToLLVMPass());"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "file_content_changes": "@@ -861,7 +861,6 @@ def optimize_tritongpu_ir(mod, num_stages):\n     pm.add_cse_pass()\n     pm.add_coalesce_pass()\n     pm.add_triton_gpu_combine_pass()\n-    pm.add_triton_gpu_verifier_pass()\n     pm.run(mod)\n     return mod\n "}, {"filename": "test/Analysis/test-allocation.mlir", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "file_content_changes": "@@ -1,6 +1,7 @@\n // RUN: triton-opt %s -split-input-file --mlir-disable-threading -test-print-allocation 2>&1 | FileCheck %s\n \n #AL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n+#sliceAd0 = #triton_gpu.slice<{dim = 0, parent = #AL}>\n #BL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n #B = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n@@ -164,7 +165,7 @@ func @alloc(%A : !tt.ptr<f16>) {\n func @scratch() {\n   %cst0 = arith.constant dense<0.000000e+00> : tensor<16x16xf16, #AL>\n   // CHECK: scratch offset = 0, size = 512\n-  %b = tt.reduce %cst0 {redOp = 1 : i32, axis = 0 : i32} : tensor<16x16xf16, #AL> -> tensor<16xf16, #AL>\n+  %b = tt.reduce %cst0 {redOp = 1 : i32, axis = 0 : i32} : tensor<16x16xf16, #AL> -> tensor<16xf16, #sliceAd0>\n   return\n   // CHECK-NEXT: size = 512\n }"}, {"filename": "test/Analysis/test-membar.mlir", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "file_content_changes": "@@ -1,6 +1,7 @@\n // RUN: triton-opt %s -split-input-file --mlir-disable-threading -test-print-membar 2>&1 | FileCheck %s\n \n #AL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n+#sliceAd0 = #triton_gpu.slice<{dim = 0, parent = #AL}>\n #BL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n #B = #triton_gpu.shared<{vec = 2, perPhase = 2, maxPhase = 4, order = [1, 0]}>\n@@ -69,7 +70,8 @@ func @scratch() {\n   // CHECK: Membar 1\n   %a = tt.cat %cst0, %cst0 {axis = 0} : (tensor<16x16xf16, #A>, tensor<16x16xf16, #A>) -> tensor<32x16xf16, #A>\n   // CHECK-NEXT: Membar 3\n-  %b = tt.reduce %a {redOp = 1 : i32, axis = 0 : i32} : tensor<32x16xf16, #A> -> tensor<16xf16, #A>\n+  %aa = triton_gpu.convert_layout %a : (tensor<32x16xf16, #A>) -> tensor<32x16xf16, #AL>\n+  %b = tt.reduce %aa {redOp = 1 : i32, axis = 0 : i32} : tensor<32x16xf16, #AL> -> tensor<16xf16, #sliceAd0>\n   return\n }\n "}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 18, "deletions": 12, "changes": 30, "file_content_changes": "@@ -348,15 +348,17 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #block1 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [8], warpsPerCTA = [4], order = [0]}>\n #block2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [4, 1], warpsPerCTA = [4, 1], order = [1, 0]}>\n #block3 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 8], warpsPerCTA = [1, 4], order = [1, 0]}>\n+#slice2d1 = #triton_gpu.slice<{dim = 1, parent=#block2}>\n+#slice3d0 = #triton_gpu.slice<{dim = 0, parent=#block3}>\n #AL = #triton_gpu.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A = #triton_gpu.shared<{vec = 4, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v4\n   func @basic_insert_slice_async_v4(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n-    %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #block0>\n-    %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<64xi32, #block1>\n-    %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #block0>) -> tensor<16x1xi32, #block2>\n-    %off1 = tt.expand_dims %off1_ {axis = 0 : i32} : (tensor<64xi32, #block1>) -> tensor<1x64xi32, #block3>\n+    %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #slice2d1>\n+    %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<64xi32, #slice3d0>\n+    %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #slice2d1>) -> tensor<16x1xi32, #block2>\n+    %off1 = tt.expand_dims %off1_ {axis = 0 : i32} : (tensor<64xi32, #slice3d0>) -> tensor<1x64xi32, #block3>\n     %broadcast_off0_scalar = tt.broadcast %off0 : (tensor<16x1xi32, #block2>) -> tensor<16x64xi32, #block2>\n     %cst_scalar = arith.constant 64 : i32\n     %cst = tt.splat %cst_scalar : (i32) -> tensor<16x64xi32, #block2>\n@@ -387,15 +389,17 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #block1 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [8], warpsPerCTA = [4], order = [0]}>\n #block2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [4, 1], warpsPerCTA = [4, 1], order = [1, 0]}>\n #block3 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 8], warpsPerCTA = [1, 4], order = [1, 0]}>\n+#slice2d1 = #triton_gpu.slice<{dim = 1, parent=#block2}>\n+#slice3d0 = #triton_gpu.slice<{dim = 0, parent=#block3}>\n #AL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A = #triton_gpu.shared<{vec = 1, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v1\n   func @basic_insert_slice_async_v1(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n-    %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #block0>\n-    %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #block1>\n-    %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #block0>) -> tensor<16x1xi32, #block2>\n-    %off1 = tt.expand_dims %off1_ {axis = 0 : i32} : (tensor<32xi32, #block1>) -> tensor<1x32xi32, #block3>\n+    %off0_ = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #slice2d1>\n+    %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #slice3d0>\n+    %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<16xi32, #slice2d1>) -> tensor<16x1xi32, #block2>\n+    %off1 = tt.expand_dims %off1_ {axis = 0 : i32} : (tensor<32xi32, #slice3d0>) -> tensor<1x32xi32, #block3>\n     %broadcast_off0_scalar = tt.broadcast %off0 : (tensor<16x1xi32, #block2>) -> tensor<16x32xi32, #block2>\n     %cst_scalar = arith.constant 32 : i32\n     %cst = tt.splat %cst_scalar : (i32) -> tensor<16x32xi32, #block2>\n@@ -429,15 +433,17 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n #block0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [8], warpsPerCTA = [4], order = [0]}>\n #block2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [8, 1], warpsPerCTA = [4, 1], order = [1, 0]}>\n #block3 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 8], warpsPerCTA = [1, 4], order = [1, 0]}>\n+#slice2d1 = #triton_gpu.slice<{dim = 1, parent=#block2}>\n+#slice3d0 = #triton_gpu.slice<{dim = 0, parent=#block3}>\n #AL = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>\n #A = #triton_gpu.shared<{vec = 1, perPhase = 1, maxPhase = 4, order = [1, 0]}>\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_insert_slice_async_v1_multictas\n   func @basic_insert_slice_async_v1_multictas(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}) {\n-    %off0_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #block0>\n-    %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #block0>\n-    %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<32xi32, #block0>) -> tensor<32x1xi32, #block2>\n-    %off1 = tt.expand_dims %off1_ {axis = 0 : i32} : (tensor<32xi32, #block0>) -> tensor<1x32xi32, #block3>\n+    %off0_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #slice2d1>\n+    %off1_ = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #slice3d0>\n+    %off0 = tt.expand_dims %off0_ {axis = 1 : i32} : (tensor<32xi32, #slice2d1>) -> tensor<32x1xi32, #block2>\n+    %off1 = tt.expand_dims %off1_ {axis = 0 : i32} : (tensor<32xi32, #slice3d0>) -> tensor<1x32xi32, #block3>\n     %broadcast_off0_scalar = tt.broadcast %off0 : (tensor<32x1xi32, #block2>) -> tensor<32x32xi32, #block2>\n     %cst_scalar = arith.constant 32 : i32\n     %cst = tt.splat %cst_scalar : (i32) -> tensor<32x32xi32, #block2>"}, {"filename": "test/TritonGPU/coalesce.mlir", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "file_content_changes": "@@ -1,8 +1,10 @@\n-// RUN: triton-opt %s -split-input-file -tritongpu-coalesce -canonicalize -tritongpu-verifier | FileCheck %s\n+// RUN: triton-opt %s -split-input-file -tritongpu-coalesce -canonicalize | FileCheck %s\n \n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>\n #blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>\n+#slice1dim1 = #triton_gpu.slice<{dim = 1, parent = #blocked1}>\n+#slice2dim0 = #triton_gpu.slice<{dim = 0, parent = #blocked2}>\n \n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n@@ -23,13 +25,14 @@ func @transpose(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32},\n                 %arg3: i32 {tt.divisibility = 16 : i32}) {\n   %cst = arith.constant dense<true> : tensor<64x64xi1, #blocked1>\n   %cst_0 = arith.constant dense<0.000000e+00> : tensor<64x64xf32, #blocked1>\n-  %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #blocked0>\n-  %1 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<64xi32, #blocked0>) -> tensor<64x1xi32, #blocked1>\n+  %00 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #slice1dim1>\n+  %01 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #slice2dim0>\n+  %1 = tt.expand_dims %00 {axis = 1 : i32} : (tensor<64xi32, #slice1dim1>) -> tensor<64x1xi32, #blocked1>\n   %2 = tt.splat %arg1 : (i32) -> tensor<64x1xi32, #blocked1>\n   %3 = arith.muli %1, %2 : tensor<64x1xi32, #blocked1>\n   %4 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<64x1x!tt.ptr<f32>, #blocked1>\n   %5 = tt.addptr %4, %3 : tensor<64x1x!tt.ptr<f32>, #blocked1>\n-  %6 = tt.expand_dims %0 {axis = 0 : i32} : (tensor<64xi32, #blocked0>) -> tensor<1x64xi32, #blocked2>\n+  %6 = tt.expand_dims %01 {axis = 0 : i32} : (tensor<64xi32, #slice2dim0>) -> tensor<1x64xi32, #blocked2>\n   %7 = tt.broadcast %5 : (tensor<64x1x!tt.ptr<f32>, #blocked1>) -> tensor<64x64x!tt.ptr<f32>, #blocked1>\n   %8 = tt.broadcast %6 : (tensor<1x64xi32, #blocked2>) -> tensor<64x64xi32, #blocked2>\n   %9 = triton_gpu.convert_layout %8 : (tensor<64x64xi32, #blocked2>) -> tensor<64x64xi32, #blocked1>"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "file_content_changes": "@@ -53,7 +53,9 @@ func @remat(%arg0: i32) -> tensor<1024xi32, #layout1> {\n \n #blocked0 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>\n #blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>\n+#slice1dim1 = #triton_gpu.slice<{dim = 1, parent = #blocked1}>\n #blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>\n+#slice2dim0 = #triton_gpu.slice<{dim = 0, parent = #blocked2}>\n #blocked3 = #triton_gpu.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [1, 4], order = [1, 0]}>\n #blocked4 = #triton_gpu.blocked<{sizePerThread = [4, 1], threadsPerWarp = [16, 2], warpsPerCTA = [4, 1], order = [0, 1]}>\n \n@@ -90,13 +92,14 @@ func @transpose(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32 {tt\n   // CHECK: return\n   %cst = arith.constant dense<0.000000e+00> : tensor<64x64xf32, #blocked1>\n   %cst_0 = arith.constant dense<true> : tensor<64x64xi1, #blocked1>\n-  %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #blocked0>\n-  %1 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<64xi32, #blocked0>) -> tensor<64x1xi32, #blocked1>\n+  %00 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #slice1dim1>\n+  %01 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #slice2dim0>\n+  %1 = tt.expand_dims %00 {axis = 1 : i32} : (tensor<64xi32, #slice1dim1>) -> tensor<64x1xi32, #blocked1>\n   %2 = tt.splat %arg1 : (i32) -> tensor<64x1xi32, #blocked1>\n   %3 = arith.muli %1, %2 : tensor<64x1xi32, #blocked1>\n   %4 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<64x1x!tt.ptr<f32>, #blocked1>\n   %5 = tt.addptr %4, %3 : tensor<64x1x!tt.ptr<f32>, #blocked1>\n-  %6 = tt.expand_dims %0 {axis = 0 : i32} : (tensor<64xi32, #blocked0>) -> tensor<1x64xi32, #blocked2>\n+  %6 = tt.expand_dims %01 {axis = 0 : i32} : (tensor<64xi32, #slice2dim0>) -> tensor<1x64xi32, #blocked2>\n   %7 = tt.broadcast %5 : (tensor<64x1x!tt.ptr<f32>, #blocked1>) -> tensor<64x64x!tt.ptr<f32>, #blocked1>\n   %8 = tt.broadcast %6 : (tensor<1x64xi32, #blocked2>) -> tensor<64x64xi32, #blocked2>\n   %9 = triton_gpu.convert_layout %8 : (tensor<64x64xi32, #blocked2>) -> tensor<64x64xi32, #blocked1>\n@@ -138,13 +141,14 @@ func @loop(%arg0: !tt.ptr<f32>, %arg1: i32, %arg2: !tt.ptr<f32>, %arg3: i32, %ar\n     %c32 = arith.constant 32 : index\n     %c0 = arith.constant 0 : index\n     %cst_1 = arith.constant dense<0.000000e+00> : tensor<64x64xf32, #blocked1>\n-    %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #blocked0>\n-    %1 = tt.expand_dims %0 {axis = 1 : i32} : (tensor<64xi32, #blocked0>) -> tensor<64x1xi32, #blocked1>\n+    %00 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #slice1dim1>\n+    %01 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #slice2dim0>\n+    %1 = tt.expand_dims %00 {axis = 1 : i32} : (tensor<64xi32, #slice1dim1>) -> tensor<64x1xi32, #blocked1>\n     %2 = tt.splat %arg1 : (i32) -> tensor<64x1xi32, #blocked1>\n     %3 = arith.muli %1, %2 : tensor<64x1xi32, #blocked1>\n     %4 = tt.splat %arg0 : (!tt.ptr<f32>) -> tensor<64x1x!tt.ptr<f32>, #blocked1>\n     %5 = tt.addptr %4, %3 : tensor<64x1x!tt.ptr<f32>, #blocked1>\n-    %6 = tt.expand_dims %0 {axis = 0 : i32} : (tensor<64xi32, #blocked0>) -> tensor<1x64xi32, #blocked2>\n+    %6 = tt.expand_dims %01 {axis = 0 : i32} : (tensor<64xi32, #slice2dim0>) -> tensor<1x64xi32, #blocked2>\n     %7 = tt.broadcast %5 : (tensor<64x1x!tt.ptr<f32>, #blocked1>) -> tensor<64x64x!tt.ptr<f32>, #blocked1>\n     %8 = tt.broadcast %6 : (tensor<1x64xi32, #blocked2>) -> tensor<64x64xi32, #blocked2>\n     %9 = triton_gpu.convert_layout %8 : (tensor<64x64xi32, #blocked2>) -> tensor<64x64xi32, #blocked1>"}, {"filename": "test/TritonGPU/loop-pipeline.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1,4 +1,4 @@\n-// RUN: triton-opt %s -split-input-file -tritongpu-pipeline=num-stages=3 -canonicalize -tritongpu-verifier | FileCheck %s\n+// RUN: triton-opt %s -split-input-file -tritongpu-pipeline=num-stages=3 -canonicalize | FileCheck %s\n \n // 4 warps\n // matmul: 128x32 @ 32x128 -> 128x128"}]