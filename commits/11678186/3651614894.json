[{"filename": "lib/Conversion/TritonToTritonGPU/TritonToTritonGPU.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -114,6 +114,7 @@ void populateArithmeticPatternsAndLegality(\n       GenericOpPattern<arith::TruncIOp>, GenericOpPattern<arith::TruncFOp>,\n       GenericOpPattern<arith::ExtUIOp>, GenericOpPattern<arith::ExtSIOp>,\n       GenericOpPattern<arith::ExtFOp>, GenericOpPattern<arith::SIToFPOp>,\n+      GenericOpPattern<arith::FPToSIOp>, GenericOpPattern<arith::FPToUIOp>,\n       GenericOpPattern<arith::UIToFPOp>>(typeConverter, context);\n }\n "}, {"filename": "python/tests/test_core.py", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -743,9 +743,11 @@ def test_cast(dtype_x, dtype_z, bitcast, device='cuda'):\n     # triton kernel\n     @triton.jit\n     def kernel(X, Z, BITCAST: tl.constexpr):\n-        x = tl.load(X)\n+        x_ptr = X + tl.arange(0, 1)\n+        z_ptr = Z + tl.arange(0, 1)\n+        x = tl.load(x_ptr)\n         z = x.to(Z.dtype.element_ty, bitcast=BITCAST)\n-        tl.store(Z, z)\n+        tl.store(z_ptr, z)\n \n     dtype_z_np = dtype_z if dtype_z != 'int1' else 'bool_'\n     # triton result"}]