[{"filename": "python/tutorials/03-matrix-multiplication.py", "status": "modified", "additions": 17, "deletions": 18, "changes": 35, "file_content_changes": "@@ -284,17 +284,17 @@ def matmul(a, b, activation=None):\n #\n # We can test our custom matrix multiplication operation against a native torch implementation (i.e., cuBLAS)\n \n-#torch.manual_seed(0)\n-#a = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n-#b = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n-#triton_output = matmul(a, b, activation=None)\n-#torch_output = torch.matmul(a, b)\n-#print(f\"triton_output={triton_output}\")\n-#print(f\"torch_output={torch_output}\")\n-#if triton.testing.allclose(triton_output, torch_output):\n-#    print(\"\u2705 Triton and Torch match\")\n-#else:\n-#    print(\"\u274c Triton and Torch differ\")\n+torch.manual_seed(0)\n+a = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n+b = torch.randn((512, 512), device='cuda', dtype=torch.float16)\n+triton_output = matmul(a, b, activation=None)\n+torch_output = torch.matmul(a, b)\n+print(f\"triton_output={triton_output}\")\n+print(f\"torch_output={torch_output}\")\n+if triton.testing.allclose(triton_output, torch_output):\n+    print(\"\u2705 Triton and Torch match\")\n+else:\n+    print(\"\u274c Triton and Torch differ\")\n \n # %%\n # Benchmark\n@@ -326,13 +326,12 @@ def matmul(a, b, activation=None):\n def benchmark(M, N, K, provider):\n     a = torch.randn((M, K), device='cuda', dtype=torch.float16)\n     b = torch.randn((K, N), device='cuda', dtype=torch.float16)\n-    with triton.testing.set_gpu_clock():\n-        if provider == 'cublas':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(a, b), rep=1)\n-        if provider == 'triton':\n-            ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul(a, b), rep=1)\n-        perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n-        return perf(ms), perf(max_ms), perf(min_ms)\n+    if provider == 'cublas':\n+        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(a, b), rep=100)\n+    if provider == 'triton':\n+        ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul(a, b), rep=100)\n+    perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n+    return perf(ms), perf(max_ms), perf(min_ms)\n \n \n benchmark.run(show_plots=True, print_data=True)"}]