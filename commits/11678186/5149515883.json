[{"filename": "include/triton/Dialect/Triton/IR/TritonAttrDefs.td", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "file_content_changes": "@@ -52,4 +52,16 @@ def TT_AtomicRMWAttr : I32EnumAttr<\n     let cppNamespace = \"::mlir::triton\";\n }\n \n+// Program ID dimensions.\n+def TT_ProgramDim : I32EnumAttr<\n+    \"ProgramIDDim\", \"\",\n+    [\n+        I32EnumAttrCase<\"X\", 0, \"x\">,\n+        I32EnumAttrCase<\"Y\", 1, \"y\">,\n+        I32EnumAttrCase<\"Z\", 2, \"z\">,\n+    ]> {\n+    let cppNamespace = \"::mlir::triton\";\n+}\n+\n+\n #endif"}, {"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "file_content_changes": "@@ -351,11 +351,17 @@ def TT_TransOp : TT_Op<\"trans\", [Pure,\n // SPMD Ops\n //\n def TT_GetProgramIdOp : TT_Op<\"get_program_id\", [Pure]> {\n-    let arguments = (ins I32Attr:$axis);\n+    let arguments = (ins TT_ProgramDim:$axis);\n \n     let results = (outs I32:$result);\n \n-    let assemblyFormat = \"attr-dict `:` type($result)\";\n+    let assemblyFormat = \"$axis attr-dict `:` type($result)\";\n+\n+    let extraClassDeclaration = [{\n+      int32_t getAxisAsInt() {\n+        return static_cast<int32_t>(getAxis());\n+      }\n+    }];\n }\n \n def TT_GetNumProgramsOp : TT_Op<\"get_num_programs\", [Pure]> {"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -384,10 +384,10 @@ struct GetProgramIdOpConversion\n   matchAndRewrite(triton::GetProgramIdOp op, OpAdaptor adaptor,\n                   ConversionPatternRewriter &rewriter) const override {\n     Location loc = op->getLoc();\n-    assert(op.getAxis() < 3);\n+    assert(op.getAxisAsInt() < 3);\n \n     Value blockId =\n-        rewriter.create<::mlir::gpu::BlockIdOp>(loc, dims[op.getAxis()]);\n+        rewriter.create<::mlir::gpu::BlockIdOp>(loc, dims[op.getAxisAsInt()]);\n     rewriter.replaceOpWithNewOp<arith::TruncIOp>(op, i32_ty, blockId);\n     return success();\n   }"}, {"filename": "python/src/triton.cc", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "file_content_changes": "@@ -1325,8 +1325,12 @@ void init_triton_ir(py::module &&m) {\n       .def(\"create_get_program_id\",\n            [](mlir::OpBuilder &self, int axis) -> mlir::Value {\n              auto loc = self.getUnknownLoc();\n+             if (axis < 0 || axis > 3)\n+               throw std::runtime_error(\"program_id must be in [0,3]\");\n              return self.create<mlir::triton::GetProgramIdOp>(\n-                 loc, self.getI32Type(), self.getI32IntegerAttr(axis));\n+                 loc, self.getI32Type(),\n+                 mlir::triton::ProgramIDDimAttr::get(\n+                     loc.getContext(), mlir::triton::ProgramIDDim(axis)));\n            })\n       .def(\"create_get_num_programs\",\n            [](mlir::OpBuilder &self, int axis) -> mlir::Value {"}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 15, "deletions": 1, "changes": 16, "file_content_changes": "@@ -563,6 +563,20 @@ def duplicate_dim2(dummy, N: tl.constexpr):\n         duplicate_dim2[(1,)](dummy_tensor, N)\n \n \n+# ----------------------------\n+# test invalid program id axis\n+# ----------------------------\n+def test_invalid_pid_axis():\n+    dst = torch.empty(128, device='cuda')\n+\n+    @triton.jit\n+    def _kernel(dst):\n+        pid = tl.program_id(20)\n+\n+    with pytest.raises(triton.CompilationError, match=r\"program_id must be in \\[0,3\\]\"):\n+        _kernel[(1,)](dst)\n+\n+\n # ---------------\n # test where\n # ---------------\n@@ -2838,7 +2852,7 @@ def test_globaltimer():\n     def kernel(Out1, Out2):\n         start = tl.extra.cuda.globaltimer()\n         off = tl.arange(0, 128)\n-        for i in range(100):\n+        for i in range(10000):\n             tl.store(Out1 + off, tl.load(Out1 + off) + 1)\n         end = tl.extra.cuda.globaltimer()\n         tl.store(Out2, end - start)"}, {"filename": "test/Analysis/test-alignment.mlir", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "file_content_changes": "@@ -406,7 +406,7 @@ tt.func @permute_2d(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32\n // CHECK-LABEL: @store_constant_align\n tt.func @store_constant_align(%addr: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n: i32 {tt.divisibility = 16 : i32}) {\n   // CHECK: contiguity = [1], divisibility = [1], constancy = [1], constant_value = <none>\n-  %pid = tt.get_program_id {axis = 0 : i32} : i32\n+  %pid = tt.get_program_id x : i32\n   // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [1], constant_value = 128\n   %c128_i32 = arith.constant 128 : i32\n   // CHECK-NEXT: contiguity = [1], divisibility = [128], constancy = [1], constant_value = <none>\n@@ -438,7 +438,7 @@ tt.func @store_constant_align(%addr: !tt.ptr<f32> {tt.divisibility = 16 : i32},\n // CHECK-LABEL: @vecadd_mask_align_16\n tt.func @vecadd_mask_align_16(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32 {tt.divisibility = 16 : i32}) {\n   %c64_i32 = arith.constant 64 : i32\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = arith.muli %0, %c64_i32 : i32\n   %2 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32>\n   %3 = tt.splat %1 : (i32) -> tensor<64xi32>\n@@ -467,7 +467,7 @@ tt.func @vecadd_mask_align_16(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32},\n // CHECK-LABEL: @vecadd_mask_align_1\n tt.func @vecadd_mask_align_1(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32) {\n   %c64_i32 = arith.constant 64 : i32\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = arith.muli %0, %c64_i32 : i32\n   %2 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32>\n   %3 = tt.splat %1 : (i32) -> tensor<64xi32>"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "file_content_changes": "@@ -86,7 +86,7 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n   // CHECK-LABEL: global_load_store_no_vec\n   tt.func @global_load_store_no_vec(%arg0: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 4 : i32}, %arg3: i32) {\n     %c256_i32 = arith.constant 256 : i32\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n     %2 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked0>\n     %3 = tt.splat %1 : (i32) -> tensor<256xi32, #blocked0>\n@@ -138,7 +138,7 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n   // CHECK-LABEL: global_load_store_vec4\n   tt.func @global_load_store_vec4(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32) {\n     %c256_i32 = arith.constant 256 : i32\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n     %2 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked0>\n     %3 = tt.splat %1 : (i32) -> tensor<256xi32, #blocked0>\n@@ -175,7 +175,7 @@ module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 2 : i32} {\n   tt.func @vecadd_masked_vec1(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %n_elements: i32) {\n     %c64_i32 = arith.constant 64 : i32\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %1 = arith.muli %0, %c64_i32 : i32\n     %2 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #blocked>\n     %3 = tt.splat %1 : (i32) -> tensor<64xi32, #blocked>\n@@ -205,7 +205,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: global_load_store_vec2\n     tt.func @global_load_store_vec2(%arg0: !tt.ptr<f32> {tt.divisibility = 8 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 8 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 8 : i32}, %arg3: i32) {\n     %c256_i32 = arith.constant 256 : i32\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n     %2 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked0>\n     %3 = tt.splat %1 : (i32) -> tensor<256xi32, #blocked0>\n@@ -250,7 +250,7 @@ module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n   // CHECK-LABEL: global_load_store_vec8\n     tt.func @global_load_store_vec8(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32) {\n     %c256_i32 = arith.constant 256 : i32\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n     %2 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked0>\n     %3 = tt.splat %1 : (i32) -> tensor<256xi32, #blocked0>\n@@ -357,7 +357,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n   // CHECK-LABEL: basic_program_id\n   tt.func @basic_program_id() {\n     // CHECK: nvvm.read.ptx.sreg.ctaid.x : i32\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     tt.return\n   }\n }\n@@ -1066,9 +1066,9 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n \n tt.func @test_get_program_id(%a: tensor<32x!tt.ptr<i32>, #blocked0>) {\n-  %blockidx = tt.get_program_id {axis=0:i32} : i32\n-  %blockidy = tt.get_program_id {axis=1:i32} : i32\n-  %blockidz = tt.get_program_id {axis=2:i32} : i32\n+  %blockidx = tt.get_program_id x : i32\n+  %blockidy = tt.get_program_id y : i32\n+  %blockidz = tt.get_program_id z : i32\n   // CHECK: nvvm.read.ptx.sreg.ctaid.x\n   // CHECK: nvvm.read.ptx.sreg.ctaid.y\n   // CHECK: nvvm.read.ptx.sreg.ctaid.z"}, {"filename": "test/Triton/rewrite-tensor-pointer.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -10,8 +10,8 @@ tt.func public @matmul_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32},\n   %c32_i32 = arith.constant 32 : i32\n   %c128_i32 = arith.constant 128 : i32\n   %c8_i32 = arith.constant 8 : i32\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n-  %1 = tt.get_program_id {axis = 1 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n+  %1 = tt.get_program_id y : i32\n   %2 = arith.addi %arg3, %c127_i32 : i32\n   %3 = arith.divsi %2, %c128_i32 : i32\n   %4 = arith.addi %arg4, %c31_i32 : i32"}, {"filename": "test/Triton/vecadd.mlir", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -2,7 +2,7 @@\n \n module {\n   tt.func @add_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32__(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) {\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %c256_i32 = arith.constant 256 : i32\n     %1 = arith.muli %0, %c256_i32 : i32\n     %2 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32>\n@@ -49,7 +49,7 @@ module {\n //     %c0 = arith.constant 0 : index\n //     %cst = arith.constant 0.000000e+00 : f32\n //     %c256_i32 = arith.constant 256 : i32\n-//     %0 = tt.get_program_id {axis = 0 : i32} : i32\n+//     %0 = tt.get_program_id x : i32\n //     %1 = arith.muli %0, %c256_i32 : i32\n //     %2 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #triton_gpu<\"coalesced encoding<threadTileSize = 1, blockTileSize = 32, order = 0>\">>\n //     %3 = tt.broadcast %1 : (i32) -> tensor<256xi32, #triton_gpu<\"coalesced encoding<threadTileSize = 1, blockTileSize = 32, order = 0>\">>"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "file_content_changes": "@@ -86,7 +86,7 @@ tt.func @remat_fast_load(%arg: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n tt.func @if(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   // CHECK-NOT: triton_gpu.convert_layout\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout1>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout1>\n   %2 = arith.muli %1, %c32_i32 : tensor<1024xi32, #layout1>\n   %3 = arith.addi %2, %c32_i32 : tensor<1024xi32, #layout1>\n@@ -102,7 +102,7 @@ tt.func @if(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n // CHECK-LABEL: if_convert_else_not\n tt.func @if_convert_else_not(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout0>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout0>\n   %9 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout1>\n   %2 = arith.muli %1, %c32_i32 : tensor<1024xi32, #layout0>\n@@ -123,7 +123,7 @@ tt.func @if_convert_else_not(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility =\n // CHECK-LABEL: if_not_else_convert\n tt.func @if_not_else_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout0>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout0>\n   %9 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout1>\n   %2 = arith.muli %1, %c32_i32 : tensor<1024xi32, #layout0>\n@@ -144,7 +144,7 @@ tt.func @if_not_else_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility =\n // CHECK-LABEL: if_else_both_convert\n tt.func @if_else_both_convert(%arg0: i32, %arg1: !tt.ptr<i32> {tt.divisibility = 16 : i32}) {\n   %c32_i32 = arith.constant dense<32> : tensor<1024xi32, #layout0>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = tt.splat %0 : (i32) -> tensor<1024xi32, #layout0>\n   %2 = arith.muli %1, %c32_i32 : tensor<1024xi32, #layout0>\n   %3 = arith.addi %2, %c32_i32 : tensor<1024xi32, #layout0>\n@@ -323,7 +323,7 @@ tt.func @loop_if(%arg0: !tt.ptr<f32>, %arg1: i32, %arg2: !tt.ptr<f32>, %arg3: i3\n tt.func @vecadd(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: i32) {\n   // CHECK-NOT: triton_gpu.convert_layout\n   %c256_i32 = arith.constant 256 : i32\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = arith.muli %0, %c256_i32 : i32\n   %2 = tt.splat %1 : (i32) -> tensor<256xi32, #layout1>\n   %3 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #layout1>\n@@ -361,7 +361,7 @@ tt.func @select(%arg0: !tt.ptr<f64> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr\n   %c0 = arith.constant 0 : index\n   %cst_1 = arith.constant dense<2048> : tensor<1x1xi32, #blocked2>\n   %cst_2 = arith.constant dense<0.000000e+00> : tensor<1x512xf64, #blocked2>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = tt.make_range {end = 1 : i32, start = 0 : i32} : tensor<1xi32, #blocked0>\n   %2 = triton_gpu.convert_layout %1 : (tensor<1xi32, #blocked0>) -> tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>\n   %3 = tt.expand_dims %2 {axis = 1 : i32} : (tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>) -> tensor<1x1xi32, #blocked1>\n@@ -422,7 +422,7 @@ tt.func public @long_func(%arg0: !tt.ptr<i64> {tt.divisibility = 16 : i32}, %arg\n   %cst_12 = arith.constant dense<1> : tensor<1024xi32, #blocked0>\n   %cst_13 = arith.constant dense<0.000000e+00> : tensor<1024xf32, #blocked0>\n   %cst_14 = arith.constant dense<0> : tensor<1024xi32, #blocked0>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = arith.muli %0, %c1024_i32 : i32\n   %2 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32, #blocked0>\n   %3 = tt.splat %1 : (i32) -> tensor<1024xi32, #blocked0>\n@@ -809,7 +809,7 @@ tt.func public @mnist(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !\n   %cst_2 = arith.constant dense<0xFF800000> : tensor<16x16xf32, #blocked2>\n   %cst_3 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked2>\n   %cst_4 = arith.constant dense<0> : tensor<16x16xi32, #blocked2>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = arith.muli %0, %c16_i32 : i32\n   %2 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked0>\n   %3 = triton_gpu.convert_layout %2 : (tensor<16xi32, #blocked0>) -> tensor<16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>\n@@ -908,7 +908,7 @@ tt.func public @cmp(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt\n   %cst_4 = arith.constant dense<2048> : tensor<64x1xi32, #blocked2>\n   %cst_5 = arith.constant dense<49152> : tensor<64x1xi32, #blocked2>\n   %cst_6 = arith.constant dense<0.000000e+00> : tensor<64x64xf32, #blocked2>\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = arith.muli %0, %c64_i32 : i32\n   %2 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #blocked0>\n   %3 = triton_gpu.convert_layout %2 : (tensor<64xi32, #blocked0>) -> tensor<64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>>\n@@ -1044,7 +1044,7 @@ tt.func public @if_no_tensor(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %\n   %c-1_i64 = arith.constant -1 : i64\n   %cst = arith.constant 0.000000e+00 : f32\n   %c-1_i32 = arith.constant -1 : i32\n-  %0 = tt.get_program_id {axis = 0 : i32} : i32\n+  %0 = tt.get_program_id x : i32\n   %1 = tt.addptr %arg3, %0 : !tt.ptr<i64>, i32\n   %2 = tt.load %1 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : i64\n   %3 = arith.cmpi eq, %2, %c-1_i64 : i64\n@@ -1127,7 +1127,7 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n     %cst_3 = arith.constant dense<196> : tensor<1x256xi32, #blocked>\n     %cst_4 = arith.constant dense<3136> : tensor<1x256xi32, #blocked>\n     %cst_5 = arith.constant dense<256> : tensor<1x1xi32, #blocked>\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %1 = tt.make_range {end = 1 : i32, start = 0 : i32} : tensor<1xi32, #blocked1>\n     %2 = triton_gpu.convert_layout %1 : (tensor<1xi32, #blocked1>) -> tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>\n     %3 = tt.expand_dims %2 {axis = 1 : i32} : (tensor<1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>>) -> tensor<1x1xi32, #blocked2>"}, {"filename": "test/TritonGPU/matmul.mlir", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -12,7 +12,7 @@ tt.func @matmul_kernel__Pfp32_Pfp32_Pfp32_i32_i32_i32_i32_i32_i32_i32_i32_i32__1\n     %c64_i32 = arith.constant 64 : i32\n     %c63_i32 = arith.constant 63 : i32\n     %c8_i32 = arith.constant 8 : i32\n-    %0 = tt.get_program_id {axis = 0 : i32} : i32\n+    %0 = tt.get_program_id x : i32\n     %1 = arith.addi %arg3, %c63_i32 : i32\n     %2 = arith.divsi %1, %c64_i32 : i32\n     %3 = arith.addi %arg4, %c63_i32 : i32"}]