[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "file_content_changes": "@@ -1379,6 +1379,9 @@ def kernel(X, Z, BLOCK: tl.constexpr):\n     for op in ['min', 'max', 'sum', 'argmin', 'argmax']\n     for shape in reduce2d_shapes\n     for axis in [0, 1]\n+] + [\n+    (op, 'float32', [16, 32], None)\n+    for op in ['min', 'max', 'sum']\n ]\n \n \n@@ -1393,7 +1396,9 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n         range_n = tl.arange(0, BLOCK_N)\n         x = tl.load(X + range_m[:, None] * BLOCK_N + range_n[None, :])\n         z = GENERATE_TEST_HERE\n-        if AXIS == 1:\n+        if AXIS is None:\n+            tl.store(Z, z)\n+        elif AXIS == 1:\n             tl.store(Z + range_m, z)\n         else:\n             tl.store(Z + range_n, z)\n@@ -1418,7 +1423,8 @@ def kernel(X, Z, BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, AXIS: tl.constexp\n     else:\n         z_ref = numpy_op(x, axis=axis).astype(getattr(np, z_dtype_str))\n     # triton result\n-    z_tri = to_triton(numpy_random((shape[1 - axis],), dtype_str=z_dtype_str, rs=rs),\n+    ret_numel = 1 if axis is None else shape[1 - axis]\n+    z_tri = to_triton(numpy_random((ret_numel,), dtype_str=z_dtype_str, rs=rs),\n                       device=device, dst_type=z_tri_dtype_str)\n     kernel[(1,)](x_tri, z_tri, BLOCK_M=shape[0], BLOCK_N=shape[1], AXIS=axis)\n     z_tri = to_numpy(z_tri)"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -1386,7 +1386,7 @@ def _argmax_combine(value1, index1, value2, index2):\n \n @triton.jit\n @_add_reduction_docstr(\"maximum index\")\n-def argmax(input, axis=None):\n+def argmax(input, axis):\n     input = _promote_reduction_input(input)\n     return _argreduce(input, axis, _argmax_combine)\n \n@@ -1416,7 +1416,7 @@ def _argmin_combine(value1, index1, value2, index2):\n \n @triton.jit\n @_add_reduction_docstr(\"minimum index\")\n-def argmin(input, axis=None):\n+def argmin(input, axis):\n     input = _promote_reduction_input(input)\n     return _argreduce(input, axis, _argmin_combine)\n "}]