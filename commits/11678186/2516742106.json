[{"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 10, "deletions": 12, "changes": 22, "file_content_changes": "@@ -1198,31 +1198,29 @@ def test_broadcast(dtype_str):\n     SIZE = 128\n \n     @triton.jit\n-    def kernel(X, Y, SIZE: tl.constexpr):\n-        x_offs = tl.arange(0, SIZE)[:]\n+    def kernel(X, Y, SIZE1: tl.constexpr, SIZE2: tl.constexpr, SIZE: tl.constexpr):\n+        x_offs = tl.arange(0, SIZE1)[:, None] * SIZE2 + tl.arange(0, SIZE2)[None, :]\n         y_offs = tl.arange(0, SIZE)[:, None] * SIZE + tl.arange(0, SIZE)[None, :]\n         # broadcast value\n         x = tl.load(X + x_offs)\n         # broadcast shape\n-        GENERATE_TEST_HERE\n+        tl.store(Y + y_offs, x)\n \n     # inputs\n-    kernel1 = patch_kernel(kernel, {'GENERATE_TEST_HERE': \"tl.store(Y + y_offs, x[:])\"})\n-    kernel2 = patch_kernel(kernel, {'GENERATE_TEST_HERE': \"tl.store(Y + y_offs, x[None, :])\"})\n     rs = RandomState(17)\n-    x = numpy_random(SIZE, dtype_str=dtype_str, rs=rs)\n+    x = numpy_random((SIZE, SIZE), dtype_str=dtype_str, rs=rs)\n     y = numpy_random((SIZE, SIZE), dtype_str=dtype_str)\n     x_tri = to_triton(x, device='cuda')\n     y_tri = to_triton(y, device='cuda')\n-    # compute reference\n-    y[:] = x[:]\n-    # compute triton reference\n     try:\n-        kernel1[(1,)](x_tri, y_tri, SIZE)\n-    except triton.code_gen.CompilationError:\n+        kernel[(1,)](x_tri, y_tri, SIZE // 2, SIZE * 2, SIZE)\n+    except triton.code_gen.CompilationError as e:\n         np.testing.assert_(True)\n     except BaseException:\n         np.testing.assert_(False)\n-    kernel2[(1,)](x_tri, y_tri, SIZE)\n+    # compute reference\n+    y[:] = x[0, :]\n+    # compute triton reference\n+    kernel[(1,)](x_tri, y_tri, 1, SIZE, SIZE)\n     y_tri = to_numpy(y_tri)\n     np.testing.assert_equal(y, y_tri)"}]