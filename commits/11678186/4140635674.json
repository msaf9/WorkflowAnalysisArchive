[{"filename": "include/triton/Analysis/Utility.h", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "file_content_changes": "@@ -1,6 +1,7 @@\n #ifndef TRITON_ANALYSIS_UTILITY_H\n #define TRITON_ANALYSIS_UTILITY_H\n \n+#include \"mlir/Analysis/SliceAnalysis.h\"\n #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n #include <algorithm>\n #include <numeric>\n@@ -97,6 +98,11 @@ bool isMmaToDotShortcut(triton::gpu::MmaEncodingAttr &mmaLayout,\n SetVector<Operation *>\n multiRootTopologicalSort(const SetVector<Operation *> &toSort);\n \n+// This uses the toplogicalSort above\n+SetVector<Operation *>\n+multiRootGetSlice(Operation *op, TransitiveFilter backwardFilter = nullptr,\n+                  TransitiveFilter forwardFilter = nullptr);\n+\n } // namespace mlir\n \n #endif // TRITON_ANALYSIS_UTILITY_H"}, {"filename": "lib/Analysis/CMakeLists.txt", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "file_content_changes": "@@ -8,4 +8,7 @@ add_mlir_library(TritonAnalysis\n   DEPENDS\n   TritonTableGen\n   TritonGPUAttrDefsIncGen\n+  \n+  LINK_LIBS PUBLIC\n+  MLIRAnalysis\n )"}, {"filename": "lib/Analysis/Utility.cpp", "status": "modified", "additions": 25, "deletions": 0, "changes": 25, "file_content_changes": "@@ -300,4 +300,29 @@ multiRootTopologicalSort(const SetVector<Operation *> &toSort) {\n   return res;\n }\n \n+SetVector<Operation *> multiRootGetSlice(Operation *op,\n+                                         TransitiveFilter backwardFilter,\n+                                         TransitiveFilter forwardFilter) {\n+  SetVector<Operation *> slice;\n+  slice.insert(op);\n+\n+  unsigned currentIndex = 0;\n+  SetVector<Operation *> backwardSlice;\n+  SetVector<Operation *> forwardSlice;\n+  while (currentIndex != slice.size()) {\n+    auto *currentOp = (slice)[currentIndex];\n+    // Compute and insert the backwardSlice starting from currentOp.\n+    backwardSlice.clear();\n+    getBackwardSlice(currentOp, &backwardSlice, backwardFilter);\n+    slice.insert(backwardSlice.begin(), backwardSlice.end());\n+\n+    // Compute and insert the forwardSlice starting from currentOp.\n+    forwardSlice.clear();\n+    getForwardSlice(currentOp, &forwardSlice, forwardFilter);\n+    slice.insert(forwardSlice.begin(), forwardSlice.end());\n+    ++currentIndex;\n+  }\n+  return multiRootTopologicalSort(slice);\n+}\n+\n } // namespace mlir"}, {"filename": "lib/Dialect/Triton/Transforms/Combine.cpp", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "file_content_changes": "@@ -69,6 +69,7 @@ class CombineSelectMaskedLoadPattern : public mlir::RewritePattern {\n \n     mlir::Value trueValue = selectOp.getTrueValue();\n     mlir::Value falseValue = selectOp.getFalseValue();\n+    mlir::Value condSelect = selectOp.getCondition();\n \n     auto *loadOpCandidate = trueValue.getDefiningOp();\n     auto loadOp = llvm::dyn_cast_or_null<triton::LoadOp>(loadOpCandidate);\n@@ -85,6 +86,10 @@ class CombineSelectMaskedLoadPattern : public mlir::RewritePattern {\n     if (!broadcastOp)\n       return mlir::failure();\n \n+    auto broadcastCond = broadcastOp.src();\n+    if (broadcastCond != condSelect)\n+      return mlir::failure();\n+\n     rewriter.replaceOpWithNewOp<triton::LoadOp>(\n         op, loadOp.ptr(), loadOp.mask(), falseValue, loadOp.cache(),\n         loadOp.evict(), loadOp.isVolatile());"}, {"filename": "lib/Dialect/TritonGPU/Transforms/Coalesce.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -36,7 +36,7 @@ struct CoalescePass : public TritonGPUCoalesceBase<CoalescePass> {\n     SetVector<Value> withSameOrder;\n     withSameOrder.insert(ptr);\n     if (ptr.getDefiningOp())\n-      for (Operation *op : mlir::getSlice(ptr.getDefiningOp())) {\n+      for (Operation *op : mlir::multiRootGetSlice(ptr.getDefiningOp())) {\n         for (Value val : op->getResults()) {\n           if (val.getType() != origType)\n             continue;"}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "file_content_changes": "@@ -1080,7 +1080,7 @@ def path_to_ptxas():\n     ]\n \n     for ptxas in paths:\n-        if os.path.exists(ptxas):\n+        if os.path.exists(ptxas) and os.path.isfile(ptxas):\n             result = subprocess.check_output([ptxas, \"--version\"], stderr=subprocess.STDOUT)\n             if result is not None:\n                 version = re.search(r\".*release (\\d+\\.\\d+).*\", result.decode(\"utf-8\"), flags=re.MULTILINE)"}, {"filename": "test/Triton/combine.mlir", "status": "modified", "additions": 11, "deletions": 5, "changes": 16, "file_content_changes": "@@ -64,19 +64,25 @@ func @test_combine_select_masked_load_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %con\n }\n \n // CHECK-LABEL: @test_combine_select_masked_load_fail_pattern\n-func @test_combine_select_masked_load_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %dummy_load: tensor<8xf32>, %dummy_broadcast: tensor<8xi1>, %cond: i1) -> (tensor<8xf32>, tensor<8xf32>) {\n+func @test_combine_select_masked_load_fail_pattern(%ptr: tensor<8x!tt.ptr<f32>>, %dummy_load: tensor<8xf32>, %dummy_broadcast: tensor<8xi1>, %cond0: i1, %cond1: i1) -> (tensor<8xf32>, tensor<8xf32>, tensor<8xf32>) {\n     %false_val = arith.constant dense<0.0> : tensor<8xf32>\n \n     // Case 1: value at the \"load\" position is not an \"op\".  Select should not be canonicalized.\n     // CHECK: %{{.*}} = select %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n-    %0 = select %cond, %dummy_load, %false_val : tensor<8xf32>\n+    %0 = select %cond0, %dummy_load, %false_val : tensor<8xf32>\n \n     // Case 2: value at the \"broadcast\" position is not an \"op\".  Select should not be canonicalized.\n-    %real_load = tt.load %ptr, %dummy_broadcast, %false_val {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n+    %real_load0 = tt.load %ptr, %dummy_broadcast, %false_val {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n     // CHECK: %{{.*}} = select %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n-    %1 = select %cond, %real_load, %false_val : tensor<8xf32>\n+    %1 = select %cond0, %real_load0, %false_val : tensor<8xf32>\n \n-    return %0, %1 : tensor<8xf32>, tensor<8xf32>\n+    // Case 3: condition of \"broadcast\" is not the same as the condition of \"select\".  Select should not be canonicalized.\n+    %cond0_ = tt.broadcast %cond0 : (i1) -> tensor<8xi1>\n+    %real_load1 = tt.load %ptr, %cond0_, %false_val {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<8xf32>\n+    // CHECK: %{{.*}} = select %{{.*}}, %{{.*}}, %{{.*}} : tensor<8xf32>\n+    %2 = select %cond1, %real_load1, %false_val : tensor<8xf32>\n+\n+    return %0, %1, %2 : tensor<8xf32>, tensor<8xf32>, tensor<8xf32>\n }\n \n // CHECK-LABEL: @test_combine_broadcast_constant_pattern"}]