[{"filename": "python/test/unit/runtime/test_cache.py", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -160,10 +160,10 @@ def kernel_add(a, b, o, N: tl.constexpr):\n     assert len(kernel_add.cache[device]) == 0\n     kernel_add.warmup(torch.float32, torch.float32, torch.float32, 32, grid=(1,))\n     assert len(kernel_add.cache[device]) == 1\n-    os.environ[\"TRITON_DEBUG\"] = \"0\"\n+    kernel_add.debug = False\n     kernel_add.warmup(torch.float32, torch.float32, torch.float32, 32, grid=(1,))\n     assert len(kernel_add.cache[device]) == 1\n-    os.environ[\"TRITON_DEBUG\"] = \"1\"\n+    kernel_add.debug = True\n     kernel_add.warmup(torch.float32, torch.float32, torch.float32, 32, grid=(1,))\n     assert len(kernel_add.cache[device]) == 2\n "}, {"filename": "python/triton/compiler.py", "status": "modified", "additions": 18, "deletions": 10, "changes": 28, "file_content_changes": "@@ -106,7 +106,7 @@ def __exit__(self, *args, **kwargs):\n \n \n class CodeGenerator(ast.NodeVisitor):\n-    def __init__(self, context, prototype, gscope, attributes, constants, function_name, module=None, is_kernel=False, function_types=dict()):\n+    def __init__(self, context, prototype, gscope, attributes, constants, function_name, module=None, is_kernel=False, function_types=dict(), debug=False):\n         self.builder = _triton.ir.builder(context)\n         self.module = self.builder.create_module() if module is None else module\n         self.function_ret_types = function_types\n@@ -118,6 +118,7 @@ def __init__(self, context, prototype, gscope, attributes, constants, function_n\n         self.function_name = function_name\n         self.is_kernel = is_kernel\n         self.last_node = None\n+        self.debug = debug\n         self.builtins = {\n             'range': range,\n             'min': triton.language.minimum,\n@@ -771,6 +772,8 @@ def visit_keyword(self, node):\n         return {node.arg: self.visit(node.value)}\n \n     def visit_Assert(self, node) -> Any:\n+        if not self.debug:\n+            return\n         test = self.visit(node.test)\n         msg = self.visit(node.msg)\n         # Convert assert to triton's device_assert which happens on the device\n@@ -784,8 +787,11 @@ def visit_Call(self, node):\n         for keyword in node.keywords:\n             kws.update(self.visit(keyword))\n         args = [self.visit(arg) for arg in node.args]\n-        if fn.__name__ == 'print':\n-            fn = self.builtins['print']\n+        if fn.__name__ == \"print\":\n+            fn = self.builtins[\"print\"]\n+        elif fn.__name__ == \"device_assert\":\n+            if not self.debug:\n+                return\n         elif fn.__name__ in self.static_functions:\n             if fn.__name__ == \"static_print\":\n                 print(*args, **kws)\n@@ -812,7 +818,7 @@ def visit_Call(self, node):\n             if not self.module.has_function(fn_name):\n                 prototype = triton.language.function_type([], arg_types)\n                 gscope = sys.modules[fn.fn.__module__].__dict__\n-                generator = CodeGenerator(self.builder.context, prototype, gscope, attributes, constants, module=self.module, function_name=fn_name, function_types=self.function_ret_types)\n+                generator = CodeGenerator(self.builder.context, prototype, gscope, attributes, constants, module=self.module, function_name=fn_name, function_types=self.function_ret_types, debug=self.debug)\n                 generator.visit(fn.parse())\n                 callee_ret_type = generator.last_ret_type\n                 self.function_ret_types[fn_name] = callee_ret_type\n@@ -950,7 +956,7 @@ def parse_mlir_module(path, context):\n     return module\n \n \n-def build_triton_ir(fn, signature, specialization, constants):\n+def build_triton_ir(fn, signature, specialization, constants, debug=False):\n     # canonicalize signature\n     if isinstance(signature, str):\n         signature = {k: v.strip() for k, v in enumerate(signature.split(\",\"))}\n@@ -970,7 +976,7 @@ def build_triton_ir(fn, signature, specialization, constants):\n     arg_types = [str_to_ty(v) for k, v in signature.items() if k not in constants]\n \n     prototype = triton.language.function_type([], arg_types)\n-    generator = CodeGenerator(context, prototype, gscope=gscope, constants=all_constants, function_name=function_name, attributes=new_attrs, is_kernel=True)\n+    generator = CodeGenerator(context, prototype, gscope=gscope, constants=all_constants, function_name=function_name, attributes=new_attrs, is_kernel=True, debug=debug)\n     try:\n         generator.visit(fn.parse())\n     except Exception as e:\n@@ -997,8 +1003,8 @@ def optimize_triton_ir(mod):\n     return mod\n \n \n-def ast_to_ttir(fn, signature, specialization, constants):\n-    mod, _ = build_triton_ir(fn, signature, specialization, constants)\n+def ast_to_ttir(fn, signature, specialization, constants, debug=False):\n+    mod, _ = build_triton_ir(fn, signature, specialization, constants, debug)\n     return optimize_triton_ir(mod)\n \n \n@@ -1588,11 +1594,12 @@ def compile(fn, **kwargs):\n     num_warps = kwargs.get(\"num_warps\", 4)\n     num_stages = kwargs.get(\"num_stages\", 3 if capability >= 75 else 2)\n     extern_libs = kwargs.get(\"extern_libs\", dict())\n+    debug = kwargs.get(\"debug\", False)\n     # build compilation stages\n     stages = {\n         \"ast\": (lambda path: fn, None),\n         \"ttir\": (lambda path: parse_mlir_module(path, context),\n-                 lambda src: ast_to_ttir(src, signature, configs[0], constants)),\n+                 lambda src: ast_to_ttir(src, signature, configs[0], constants, debug)),\n         \"ttgir\": (lambda path: parse_mlir_module(path, context),\n                   lambda src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, capability)),\n         \"llir\": (lambda path: Path(path).read_text(),\n@@ -1645,7 +1652,8 @@ def compile(fn, **kwargs):\n         with open(fn_cache_manager._make_path(f\"{name}.json\")) as f:\n             metadata = json.load(f)\n     else:\n-        metadata = {\"num_warps\": num_warps, \"num_stages\": num_stages, \"constants\": _get_jsonable_constants(constants), \"ctime\": dict()}\n+        metadata = {\"num_warps\": num_warps, \"num_stages\": num_stages,\n+                    \"constants\": _get_jsonable_constants(constants), \"ctime\": dict(), \"debug\": debug}\n         if ext == \"ptx\":\n             assert \"shared\" in kwargs, \"ptx compilation must provide shared memory size\"\n             metadata[\"shared\"] = kwargs[\"shared\"]"}, {"filename": "python/triton/language/core.py", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "file_content_changes": "@@ -1363,9 +1363,6 @@ def device_print(prefix, *args, _builder=None):\n \n @builtin\n def device_assert(cond, msg=\"\", _builder=None):\n-    import os\n-    if os.getenv(\"TRITON_DEBUG\", \"0\") == \"0\":\n-        return\n     msg = _constexpr_to_value(msg)\n     import inspect\n     frame = inspect.currentframe()"}, {"filename": "python/triton/runtime/jit.py", "status": "modified", "additions": 9, "deletions": 7, "changes": 16, "file_content_changes": "@@ -155,8 +155,7 @@ def is_divisible_by_16(x):\n             return False\n         divisible_by_16 = {i for i, arg in enumerate(args) if is_divisible_by_16(arg) and i not in self.do_not_specialize}\n         equal_to_1 = {i for i, arg in enumerate(args) if isinstance(arg, int) and arg == 1 and i not in self.do_not_specialize}\n-        debug = os.environ.get(\"TRITON_DEBUG\", \"0\") == \"1\"\n-        return namedtuple(\"instance_descriptor\", [\"divisible_by_16\", \"equal_to_1\", \"debug\"])(tuple(divisible_by_16), tuple(equal_to_1), debug)\n+        return namedtuple(\"instance_descriptor\", [\"divisible_by_16\", \"equal_to_1\"])(tuple(divisible_by_16), tuple(equal_to_1))\n         # return _triton.code_gen.instance_descriptor(divisible_by_16, equal_to_1)\n \n     @staticmethod\n@@ -242,8 +241,7 @@ def {self.fn.__name__}({', '.join(self.arg_names)}, grid, num_warps=4, num_stage\n     sig_key =  {sig_keys},\n     constexpr_key = {f'{constexpr_keys},' if len(constexpr_keys) > 0 else ()}\n     spec_key = {f'{spec_keys},' if len(spec_keys) > 0 else ()}\n-    debug = environ.get(\"TRITON_DEBUG\", \"0\") == \"1\"\n-    key = (version_key, sig_key, constexpr_key, spec_key, num_warps, num_stages, debug)\n+    key = (version_key, sig_key, constexpr_key, spec_key, num_warps, num_stages, self.debug)\n     if not extern_libs is None:\n       key = (key, tuple(extern_libs.items()))\n     assert num_warps > 0 and (num_warps & (num_warps - 1)) == 0, \"num_warps must be a power of 2\"\n@@ -278,7 +276,7 @@ def {self.fn.__name__}({', '.join(self.arg_names)}, grid, num_warps=4, num_stage\n         if callable(arg):\n           raise TypeError(f\"Callable constexpr at index {{i}} is not supported\")\n       if not self._call_hook(key, signature, device, constants, num_warps, num_stages, extern_libs, configs):\n-        bin = triton.compile(self, signature=signature, device=device, constants=constants, num_warps=num_warps, num_stages=num_stages, extern_libs=extern_libs, configs=configs)\n+        bin = triton.compile(self, signature=signature, device=device, constants=constants, num_warps=num_warps, num_stages=num_stages, extern_libs=extern_libs, configs=configs, debug=self.debug)\n         if not warmup:\n             bin.c_wrapper(grid_0, grid_1, grid_2, bin.num_warps, bin.shared, stream, bin.cu_function, triton.compiler.CompiledKernel.launch_enter_hook, triton.compiler.CompiledKernel.launch_exit_hook, bin, *args)\n         self.cache[device][key] = bin\n@@ -287,11 +285,11 @@ def {self.fn.__name__}({', '.join(self.arg_names)}, grid, num_warps=4, num_stage\n \"\"\"\n         scope = {\"version_key\": version_key(), \"get_cuda_stream\": get_cuda_stream,\n                  \"self\": self, \"_spec_of\": self._spec_of, \"_key_of\": self._key_of,\n-                 \"cache\": self.cache, \"triton\": triton, \"torch\": torch, \"environ\": os.environ}\n+                 \"cache\": self.cache, \"triton\": triton, \"torch\": torch}\n         exec(src, scope)\n         return scope[self.fn.__name__]\n \n-    def __init__(self, fn, version=None, do_not_specialize=None):\n+    def __init__(self, fn, version=None, do_not_specialize=None, debug=None):\n         self.fn = fn\n         self.module = fn.__module__\n         self.version = version\n@@ -312,6 +310,7 @@ def __init__(self, fn, version=None, do_not_specialize=None):\n         # when called with a grid using __getitem__\n         self.kernel_decorators = []\n         self.kernel = None\n+        self.debug = os.environ.get(\"TRITON_DEBUG\", \"0\") == \"1\" if debug is None else debug\n         # annotations\n         self.annotations = {self.arg_names.index(name): ty for name, ty in fn.__annotations__.items()}\n         self.__annotations__ = fn.__annotations__\n@@ -380,6 +379,7 @@ def jit(\n     *,\n     version=None,\n     do_not_specialize: Optional[Iterable[int]] = None,\n+    debug: Optional[bool] = None,\n ) -> Callable[[T], JITFunction[T]]:\n     ...\n \n@@ -389,6 +389,7 @@ def jit(\n     *,\n     version=None,\n     do_not_specialize: Optional[Iterable[int]] = None,\n+    debug: Optional[bool] = None,\n ) -> Union[JITFunction[T], Callable[[T], JITFunction[T]]]:\n     \"\"\"\n     Decorator for JIT-compiling a function using the Triton compiler.\n@@ -413,6 +414,7 @@ def decorator(fn: T) -> JITFunction[T]:\n             fn,\n             version=version,\n             do_not_specialize=do_not_specialize,\n+            debug=debug,\n         )\n \n     if fn is not None:"}]