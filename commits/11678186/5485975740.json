[{"filename": "lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp", "status": "modified", "additions": 321, "deletions": 272, "changes": 593, "file_content_changes": "@@ -225,6 +225,20 @@ const std::string Bf16_to_Fp8E4M3 =\n     \"or.b32 $0, nosign, sign;                    \\n\" // restore sign\n     \"}\";\n \n+/* ----- Packed integer to BF16 ------ */\n+const std::string S8_to_Bf16 =\n+    \"{                                           \\n\"\n+    \".reg .s8 s<4>;                              \\n\"\n+    \".reg .f32 f<4>;                             \\n\"\n+    \"mov.b32 {s0, s1, s2, s3}, $2;               \\n\" // unpack\n+    \"cvt.rn.f32.s8 f0, s0;                       \\n\" // no s8->bf16 pre-Hopper\n+    \"cvt.rn.f32.s8 f1, s1;                       \\n\" // fi[0:15] is always 0\n+    \"cvt.rn.f32.s8 f2, s2;                       \\n\" //\n+    \"cvt.rn.f32.s8 f3, s3;                       \\n\" //\n+    \"prmt.b32 $0, f0, f1, 0x7632;                \\n\" // f32->bf16 + pack\n+    \"prmt.b32 $1, f2, f3, 0x7632;                \\n\" //\n+    \"}\";\n+\n static SmallVector<Value> reorderValues(const SmallVector<Value> &values,\n                                         Type inType, Type ouType) {\n   auto inTensorTy = inType.dyn_cast<RankedTensorType>();\n@@ -350,71 +364,172 @@ inline SmallVector<Value> packI32(const SmallVector<Value> &inValues,\n   return outValues;\n }\n \n-struct FpToFpOpConversion\n-    : public ConvertTritonGPUOpToLLVMPattern<triton::FpToFpOp> {\n-  using ConvertTritonGPUOpToLLVMPattern<\n-      triton::FpToFpOp>::ConvertTritonGPUOpToLLVMPattern;\n-\n-  typedef std::function<SmallVector<Value>(\n-      Location, ConversionPatternRewriter &, const Value &, const Value &,\n-      const Value &, const Value &)>\n-      ConvertorT;\n-  /* ------------------ */\n-  // FP8 -> FP16\n-  /* ------------------ */\n-\n-  static ConvertorT makeConverterFromPtx(const std::string &ptxAsm, Type inType,\n-                                         Type outType) {\n-\n-    ConvertorT converter =\n-        [ptxAsm, inType,\n-         outType](Location loc, ConversionPatternRewriter &rewriter,\n-                  const Value &v0, const Value &v1, const Value &v2,\n-                  const Value &v3) -> SmallVector<Value> {\n-      SmallVector<Value> v = {v0, v1, v2, v3};\n-      auto ctx = rewriter.getContext();\n-      int inBitwidth = inType.getIntOrFloatBitWidth();\n-      int outBitwidth = outType.getIntOrFloatBitWidth();\n-      // first, we pack `v` into 32-bit ints\n-      int inVecWidth = 32 / inBitwidth;\n-      auto inVecTy = vec_ty(inType, inVecWidth);\n-      SmallVector<Value> inPacked(4 / inVecWidth, undef(inVecTy));\n-      for (size_t i = 0; i < 4; i++)\n-        inPacked[i / inVecWidth] = insert_element(\n-            inVecTy, inPacked[i / inVecWidth], v[i], i32_val(i % inVecWidth));\n-      for (size_t i = 0; i < inPacked.size(); i++)\n-        inPacked[i] = bitcast(inPacked[i], i32_ty);\n-\n-      // then, we run the provided inline PTX\n-      int outVecWidth = 32 / outBitwidth;\n-      int outNums = 4 / outVecWidth;\n-      PTXBuilder builder;\n-      SmallVector<PTXBuilder::Operand *> operands;\n+typedef std::function<SmallVector<Value>(Location, ConversionPatternRewriter &,\n+                                         const Value &, const Value &,\n+                                         const Value &, const Value &)>\n+    ConverterT;\n+\n+static ConverterT makeConverterFromPtx(const std::string &ptxAsm, Type inType,\n+                                       Type outType) {\n+\n+  ConverterT converter = [ptxAsm, inType, outType](\n+                             Location loc, ConversionPatternRewriter &rewriter,\n+                             const Value &v0, const Value &v1, const Value &v2,\n+                             const Value &v3) -> SmallVector<Value> {\n+    SmallVector<Value> v = {v0, v1, v2, v3};\n+    auto ctx = rewriter.getContext();\n+    int inBitwidth = inType.getIntOrFloatBitWidth();\n+    int outBitwidth = outType.getIntOrFloatBitWidth();\n+    // first, we pack `v` into 32-bit ints\n+    int inVecWidth = 32 / inBitwidth;\n+    auto inVecTy = vec_ty(inType, inVecWidth);\n+    SmallVector<Value> inPacked(4 / inVecWidth, undef(inVecTy));\n+    for (size_t i = 0; i < 4; i++)\n+      inPacked[i / inVecWidth] = insert_element(\n+          inVecTy, inPacked[i / inVecWidth], v[i], i32_val(i % inVecWidth));\n+    for (size_t i = 0; i < inPacked.size(); i++)\n+      inPacked[i] = bitcast(inPacked[i], i32_ty);\n+\n+    // then, we run the provided inline PTX\n+    int outVecWidth = 32 / outBitwidth;\n+    int outNums = 4 / outVecWidth;\n+    PTXBuilder builder;\n+    SmallVector<PTXBuilder::Operand *> operands;\n+    for (int i = 0; i < outNums; i++)\n+      operands.push_back(builder.newOperand(\"=r\"));\n+    for (Value inVal : inPacked)\n+      operands.push_back(builder.newOperand(inVal, \"r\"));\n+    auto &ptxOp = *builder.create(ptxAsm);\n+    ptxOp(operands, /*onlyAttachMLIRArgs=*/true);\n+    auto outVecTy = vec_ty(outType, outVecWidth);\n+    SmallVector<Value> outPacked;\n+    if (outNums == 1)\n+      outPacked.push_back(builder.launch(rewriter, loc, outVecTy, false));\n+    else {\n+      auto outStructTy = struct_ty(SmallVector<Type>(outNums, outVecTy));\n+      auto outStruct = builder.launch(rewriter, loc, outStructTy, false);\n       for (int i = 0; i < outNums; i++)\n-        operands.push_back(builder.newOperand(\"=r\"));\n-      for (Value inVal : inPacked)\n-        operands.push_back(builder.newOperand(inVal, \"r\"));\n-      auto &ptxOp = *builder.create(ptxAsm);\n-      ptxOp(operands, /*onlyAttachMLIRArgs=*/true);\n-      auto outVecTy = vec_ty(outType, outVecWidth);\n-      SmallVector<Value> outPacked;\n-      if (outNums == 1)\n-        outPacked.push_back(builder.launch(rewriter, loc, outVecTy, false));\n-      else {\n-        auto outStructTy = struct_ty(SmallVector<Type>(outNums, outVecTy));\n-        auto outStruct = builder.launch(rewriter, loc, outStructTy, false);\n-        for (int i = 0; i < outNums; i++)\n-          outPacked.push_back(extract_val(outVecTy, outStruct, i));\n+        outPacked.push_back(extract_val(outVecTy, outStruct, i));\n+    }\n+    // unpack the output\n+    SmallVector<Value> ret;\n+    for (size_t i = 0; i < 4; i++)\n+      ret.push_back(extract_element(outType, outPacked[i / outVecWidth],\n+                                    i32_val(i % outVecWidth)));\n+    return ret;\n+  };\n+  return converter;\n+}\n+\n+class MultipleOperandsRange\n+    : public iterator_range<SmallVector<SmallVector<Value>>::iterator> {\n+  using ContainerT = SmallVector<SmallVector<Value>>;\n+\n+public:\n+  using iterator_range<ContainerT::iterator>::iterator_range;\n+  ContainerT::reference operator[](ContainerT::size_type idx) {\n+    return begin()[idx];\n+  }\n+  ContainerT::const_reference operator[](ContainerT::size_type idx) const {\n+    return begin()[idx];\n+  }\n+  ContainerT::size_type size() const { return end() - begin(); }\n+};\n+\n+// Base pattern for elementwise conversion using ConcreteT. Unpacks individual\n+// elements from a `!llvm.struct` via `llvm.extactvalue`, calls\n+// ConcreteT::createDestOps on each element, and packs them back into an\n+// `!llvm.struct` using `llvm.insertvalue`.\n+//\n+// Also supports processing the inputs in a vectorized form by consuming and\n+// producing multiple operand sets in ConcreteT::createDestOps.\n+template <typename SourceOp, typename ConcreteT>\n+class ElementwiseOpConversionBase\n+    : public ConvertTritonGPUOpToLLVMPattern<SourceOp> {\n+public:\n+  using OpAdaptor = typename SourceOp::Adaptor;\n+\n+  explicit ElementwiseOpConversionBase(\n+      TritonGPUToLLVMTypeConverter &typeConverter, PatternBenefit benefit = 1)\n+      : ConvertTritonGPUOpToLLVMPattern<SourceOp>(typeConverter, benefit) {}\n+\n+  LogicalResult\n+  matchAndRewrite(SourceOp op, OpAdaptor adaptor,\n+                  ConversionPatternRewriter &rewriter) const override {\n+    auto resultTy = op.getType();\n+    Location loc = op->getLoc();\n+    // element type\n+    auto resultElementTy = getElementTypeOrSelf(resultTy);\n+    Type elemTy = this->getTypeConverter()->convertType(resultElementTy);\n+    SmallVector<SmallVector<Value>> allOperands;\n+    for (auto operand : adaptor.getOperands()) {\n+      auto argTy = op->getOperand(0).getType();\n+      auto subOperands = this->getTypeConverter()->unpackLLElements(\n+          loc, operand, rewriter, argTy);\n+      subOperands = unpackI32(subOperands, argTy, rewriter, loc,\n+                              this->getTypeConverter());\n+      allOperands.resize(subOperands.size());\n+      for (auto v : llvm::enumerate(subOperands))\n+        allOperands[v.index()].push_back(v.value());\n+    }\n+    if (allOperands.size() == 0)\n+      allOperands.push_back({});\n+\n+    SmallVector<Value> resultVals;\n+    for (auto it = allOperands.begin(), end = allOperands.end(); it != end;) {\n+      auto curr = static_cast<const ConcreteT *>(this)->createDestOps(\n+          op, adaptor, rewriter, elemTy, MultipleOperandsRange(it, end), loc);\n+      for (auto v : curr) {\n+        if (!static_cast<bool>(v))\n+          return failure();\n+        resultVals.push_back(v);\n       }\n-      // unpack the output\n-      SmallVector<Value> ret;\n-      for (size_t i = 0; i < 4; i++)\n-        ret.push_back(extract_element(outType, outPacked[i / outVecWidth],\n-                                      i32_val(i % outVecWidth)));\n-      return ret;\n-    };\n-    return converter;\n+      it += curr.size();\n+    }\n+    if (op->getNumOperands() > 0) {\n+      auto argTy = op->getOperand(0).getType();\n+      resultVals = reorderValues(resultVals, argTy, resultTy);\n+    }\n+    resultVals =\n+        packI32(resultVals, resultTy, rewriter, loc, this->getTypeConverter());\n+    Value view = this->getTypeConverter()->packLLElements(loc, resultVals,\n+                                                          rewriter, resultTy);\n+    rewriter.replaceOp(op, view);\n+\n+    return success();\n+  }\n+};\n+\n+template <typename SourceOp, typename DestOp>\n+struct ElementwiseOpConversion\n+    : public ElementwiseOpConversionBase<\n+          SourceOp, ElementwiseOpConversion<SourceOp, DestOp>> {\n+  using Base =\n+      ElementwiseOpConversionBase<SourceOp,\n+                                  ElementwiseOpConversion<SourceOp, DestOp>>;\n+  using Base::Base;\n+  using OpAdaptor = typename Base::OpAdaptor;\n+\n+  explicit ElementwiseOpConversion(LLVMTypeConverter &typeConverter,\n+                                   PatternBenefit benefit = 1)\n+      : ElementwiseOpConversionBase<SourceOp, ElementwiseOpConversion>(\n+            typeConverter, benefit) {}\n+\n+  // An interface to support variant DestOp builder.\n+  SmallVector<DestOp> createDestOps(SourceOp op, OpAdaptor adaptor,\n+                                    ConversionPatternRewriter &rewriter,\n+                                    Type elemTy, MultipleOperandsRange operands,\n+                                    Location loc) const {\n+    return {rewriter.create<DestOp>(loc, elemTy, operands[0],\n+                                    adaptor.getAttributes().getValue())};\n   }\n+};\n+\n+// Attempts to use vectorized conversions via inline PTX when possible.\n+struct FpToFpOpConversion\n+    : public ElementwiseOpConversionBase<triton::FpToFpOp, FpToFpOpConversion> {\n+  using ElementwiseOpConversionBase<\n+      triton::FpToFpOp, FpToFpOpConversion>::ElementwiseOpConversionBase;\n \n   static Value convertBf16ToFp32(Location loc,\n                                  ConversionPatternRewriter &rewriter,\n@@ -462,7 +577,7 @@ struct FpToFpOpConversion\n     return builder.launch(rewriter, loc, f16_ty, false);\n   }\n \n-  ConvertorT getConversionFunc(Type srcTy, Type dstTy) const {\n+  ConverterT getConversionFunc(Type srcTy, Type dstTy) const {\n     auto F8E4M3B15TyID = TypeID::get<mlir::Float8E4M3B11FNUZType>();\n     auto F8E4M3TyID = TypeID::get<mlir::Float8E4M3FNUZType>();\n     auto F8E5M2TyID = TypeID::get<mlir::Float8E5M2Type>();\n@@ -498,127 +613,31 @@ struct FpToFpOpConversion\n                                 getTypeConverter()->convertType(dstTy));\n   }\n \n-  LogicalResult\n-  matchAndRewrite(triton::FpToFpOp op, OpAdaptor adaptor,\n-                  ConversionPatternRewriter &rewriter) const override {\n-    auto srcTensorType = op.getFrom().getType().cast<mlir::RankedTensorType>();\n-    auto dstTensorType =\n-        op.getResult().getType().cast<mlir::RankedTensorType>();\n-    auto srcElementType = srcTensorType.getElementType();\n-    auto dstElementType = dstTensorType.getElementType();\n-    auto loc = op->getLoc();\n-    // check that the number of elements is divisible by 4\n-    // Unpack value\n-    auto inVals = getTypeConverter()->unpackLLElements(loc, adaptor.getFrom(),\n-                                                       rewriter, srcTensorType);\n-    inVals =\n-        unpackI32(inVals, srcTensorType, rewriter, loc, getTypeConverter());\n-    // Cast\n-    SmallVector<Value> outVals;\n-    auto elems = inVals.size();\n-    assert(elems % 4 == 0 &&\n+  SmallVector<Value> createDestOps(triton::FpToFpOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n+    assert(operands.size() % 4 == 0 &&\n            \"FP8 casting only support tensors with 4-aligned sizes\");\n-    bool isFP32src = srcElementType.isF32();\n-    bool isFP32dst = dstElementType.isF32();\n-    auto cvtFunc = getConversionFunc(isFP32src ? f16_ty : srcElementType,\n-                                     isFP32dst ? f16_ty : dstElementType);\n-    if (isFP32src)\n+    auto srcElementType = getElementType(op.getFrom());\n+    auto dstElementType = getElementType(op.getResult());\n+    bool isSrcFP32 = srcElementType.isF32();\n+    bool isDstFP32 = dstElementType.isF32();\n+    auto cvtFunc = getConversionFunc(isSrcFP32 ? f16_ty : srcElementType,\n+                                     isDstFP32 ? f16_ty : dstElementType);\n+    SmallVector<Value> inVals = {operands[0][0], operands[1][0], operands[2][0],\n+                                 operands[3][0]};\n+    if (isSrcFP32)\n       for (Value &v : inVals)\n         v = convertFp32ToFp16(loc, rewriter, v);\n-    for (size_t i = 0; i < elems; i += 4)\n-      outVals.append(cvtFunc(loc, rewriter, inVals[i], inVals[i + 1],\n-                             inVals[i + 2], inVals[i + 3]));\n-    if (isFP32dst)\n+    SmallVector<Value> outVals =\n+        cvtFunc(loc, rewriter, inVals[0], inVals[1], inVals[2], inVals[3]);\n+    assert(outVals.size() == operands.size());\n+    if (isDstFP32)\n       for (Value &v : outVals)\n         v = convertFp16ToFp32(loc, rewriter, v);\n     // Pack values\n-    assert(outVals.size() == elems);\n-    outVals = reorderValues(outVals, srcTensorType, dstTensorType);\n-    outVals =\n-        packI32(outVals, dstTensorType, rewriter, loc, getTypeConverter());\n-    auto result = getTypeConverter()->packLLElements(loc, outVals, rewriter,\n-                                                     dstTensorType);\n-    rewriter.replaceOp(op, result);\n-    return success();\n-  }\n-};\n-\n-template <typename SourceOp, typename ConcreteT>\n-class ElementwiseOpConversionBase\n-    : public ConvertTritonGPUOpToLLVMPattern<SourceOp> {\n-public:\n-  using OpAdaptor = typename SourceOp::Adaptor;\n-\n-  explicit ElementwiseOpConversionBase(\n-      TritonGPUToLLVMTypeConverter &typeConverter, PatternBenefit benefit = 1)\n-      : ConvertTritonGPUOpToLLVMPattern<SourceOp>(typeConverter, benefit) {}\n-\n-  LogicalResult\n-  matchAndRewrite(SourceOp op, OpAdaptor adaptor,\n-                  ConversionPatternRewriter &rewriter) const override {\n-    auto resultTy = op.getType();\n-    Location loc = op->getLoc();\n-    // element type\n-    auto resultElementTy = getElementTypeOrSelf(resultTy);\n-    Type elemTy = this->getTypeConverter()->convertType(resultElementTy);\n-    SmallVector<Value> resultVals;\n-    //\n-    SmallVector<SmallVector<Value>> allOperands;\n-    for (auto operand : adaptor.getOperands()) {\n-      auto argTy = op->getOperand(0).getType();\n-      auto sub_operands = this->getTypeConverter()->unpackLLElements(\n-          loc, operand, rewriter, argTy);\n-      sub_operands = unpackI32(sub_operands, argTy, rewriter, loc,\n-                               this->getTypeConverter());\n-      allOperands.resize(sub_operands.size());\n-      for (auto v : llvm::enumerate(sub_operands))\n-        allOperands[v.index()].push_back(v.value());\n-    }\n-    if (allOperands.size() == 0)\n-      allOperands.push_back({});\n-    for (const SmallVector<Value> &operands : allOperands) {\n-      Value curr =\n-          ((ConcreteT *)(this))\n-              ->createDestOp(op, adaptor, rewriter, elemTy, operands, loc);\n-      if (!bool(curr))\n-        return failure();\n-      resultVals.push_back(curr);\n-    }\n-    if (op->getNumOperands() > 0) {\n-      auto argTy = op->getOperand(0).getType();\n-      resultVals = reorderValues(resultVals, argTy, resultTy);\n-    }\n-    resultVals =\n-        packI32(resultVals, resultTy, rewriter, loc, this->getTypeConverter());\n-    Value view = this->getTypeConverter()->packLLElements(loc, resultVals,\n-                                                          rewriter, resultTy);\n-    rewriter.replaceOp(op, view);\n-\n-    return success();\n-  }\n-};\n-\n-template <typename SourceOp, typename DestOp>\n-struct ElementwiseOpConversion\n-    : public ElementwiseOpConversionBase<\n-          SourceOp, ElementwiseOpConversion<SourceOp, DestOp>> {\n-  using Base =\n-      ElementwiseOpConversionBase<SourceOp,\n-                                  ElementwiseOpConversion<SourceOp, DestOp>>;\n-  using Base::Base;\n-  using OpAdaptor = typename Base::OpAdaptor;\n-\n-  explicit ElementwiseOpConversion(LLVMTypeConverter &typeConverter,\n-                                   PatternBenefit benefit = 1)\n-      : ElementwiseOpConversionBase<SourceOp, ElementwiseOpConversion>(\n-            typeConverter, benefit) {}\n-\n-  // An interface to support variant DestOp builder.\n-  DestOp createDestOp(SourceOp op, OpAdaptor adaptor,\n-                      ConversionPatternRewriter &rewriter, Type elemTy,\n-                      ValueRange operands, Location loc) const {\n-    return rewriter.create<DestOp>(loc, elemTy, operands,\n-                                   adaptor.getAttributes().getValue());\n+    return outVals;\n   }\n };\n \n@@ -631,12 +650,13 @@ struct CmpIOpConversion\n   using Adaptor = typename Base::OpAdaptor;\n \n   // An interface to support variant DestOp builder.\n-  LLVM::ICmpOp createDestOp(triton::gpu::CmpIOp op, OpAdaptor adaptor,\n-                            ConversionPatternRewriter &rewriter, Type elemTy,\n-                            ValueRange operands, Location loc) const {\n-    return rewriter.create<LLVM::ICmpOp>(\n-        loc, elemTy, ArithCmpIPredicateToLLVM(op.getPredicate()), operands[0],\n-        operands[1]);\n+  SmallVector<LLVM::ICmpOp>\n+  createDestOps(triton::gpu::CmpIOp op, OpAdaptor adaptor,\n+                ConversionPatternRewriter &rewriter, Type elemTy,\n+                MultipleOperandsRange operands, Location loc) const {\n+    return {rewriter.create<LLVM::ICmpOp>(\n+        loc, elemTy, ArithCmpIPredicateToLLVM(op.getPredicate()),\n+        operands[0][0], operands[0][1])};\n   }\n \n   static LLVM::ICmpPredicate\n@@ -672,13 +692,13 @@ struct CmpFOpConversion\n   using Adaptor = typename Base::OpAdaptor;\n \n   // An interface to support variant DestOp builder.\n-  static LLVM::FCmpOp createDestOp(triton::gpu::CmpFOp op, OpAdaptor adaptor,\n-                                   ConversionPatternRewriter &rewriter,\n-                                   Type elemTy, ValueRange operands,\n-                                   Location loc) {\n-    return rewriter.create<LLVM::FCmpOp>(\n-        loc, elemTy, ArithCmpFPredicateToLLVM(op.getPredicate()), operands[0],\n-        operands[1]);\n+  static SmallVector<LLVM::FCmpOp>\n+  createDestOps(triton::gpu::CmpFOp op, OpAdaptor adaptor,\n+                ConversionPatternRewriter &rewriter, Type elemTy,\n+                MultipleOperandsRange operands, Location loc) {\n+    return {rewriter.create<LLVM::FCmpOp>(\n+        loc, elemTy, ArithCmpFPredicateToLLVM(op.getPredicate()),\n+        operands[0][0], operands[0][1])};\n   }\n \n   static LLVM::FCmpPredicate\n@@ -719,17 +739,19 @@ struct ExternElementwiseOpConversion\n   using Adaptor = typename Base::OpAdaptor;\n   typedef typename Base::OpAdaptor OpAdaptor;\n \n-  Value createDestOp(T op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(T op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     StringRef funcName = op.getSymbol();\n     if (funcName.empty())\n       llvm::errs() << \"ExternElementwiseOpConversion\";\n \n-    Type funcType = getFunctionType(elemTy, operands);\n+    Type funcType = getFunctionType(elemTy, operands[0]);\n     LLVM::LLVMFuncOp funcOp =\n         appendOrGetFuncOp(rewriter, op, funcName, funcType);\n-    return rewriter.create<LLVM::CallOp>(loc, funcOp, operands).getResult();\n+    return {\n+        rewriter.create<LLVM::CallOp>(loc, funcOp, operands[0]).getResult()};\n   }\n \n private:\n@@ -765,9 +787,10 @@ struct FDivOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::DivFOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::arith::DivFOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     PTXBuilder ptxBuilder;\n     auto &fdiv = *ptxBuilder.create<PTXInstr>(\"div\");\n     unsigned bitwidth = elemTy.getIntOrFloatBitWidth();\n@@ -780,12 +803,14 @@ struct FDivOpConversion\n     }\n \n     auto res = ptxBuilder.newOperand(bitwidth == 32 ? \"=r\" : \"=l\");\n-    auto lhs = ptxBuilder.newOperand(operands[0], bitwidth == 32 ? \"r\" : \"l\");\n-    auto rhs = ptxBuilder.newOperand(operands[1], bitwidth == 32 ? \"r\" : \"l\");\n+    auto lhs =\n+        ptxBuilder.newOperand(operands[0][0], bitwidth == 32 ? \"r\" : \"l\");\n+    auto rhs =\n+        ptxBuilder.newOperand(operands[0][1], bitwidth == 32 ? \"r\" : \"l\");\n     fdiv(res, lhs, rhs);\n \n     Value ret = ptxBuilder.launch(rewriter, loc, elemTy, false);\n-    return ret;\n+    return {ret};\n   }\n };\n \n@@ -796,9 +821,10 @@ struct FMulOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::MulFOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::arith::MulFOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto lhsElemTy = getElementType(op.getLhs());\n     auto rhsElemTy = getElementType(op.getRhs());\n     if (lhsElemTy.isBF16() && rhsElemTy.isBF16()) {\n@@ -808,13 +834,13 @@ struct FMulOpConversion\n                     \"    fma.rn.bf16 $0, $1, $2, c; } \\n\";\n       auto &fMul = *builder.create<PTXInstr>(ptxAsm);\n       auto res = builder.newOperand(\"=h\");\n-      auto lhs = builder.newOperand(operands[0], \"h\");\n-      auto rhs = builder.newOperand(operands[1], \"h\");\n+      auto lhs = builder.newOperand(operands[0][0], \"h\");\n+      auto rhs = builder.newOperand(operands[0][1], \"h\");\n       fMul({res, lhs, rhs}, /*onlyAttachMLIRArgs=*/true);\n-      return builder.launch(rewriter, loc, i16_ty, false);\n+      return {builder.launch(rewriter, loc, i16_ty, false)};\n     } else {\n-      return rewriter.create<LLVM::FMulOp>(loc, elemTy, operands[0],\n-                                           operands[1]);\n+      return {rewriter.create<LLVM::FMulOp>(loc, elemTy, operands[0][0],\n+                                            operands[0][1])};\n     }\n   }\n };\n@@ -826,9 +852,10 @@ struct FAddOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::AddFOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::arith::AddFOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto lhsElemTy = getElementType(op.getLhs());\n     auto rhsElemTy = getElementType(op.getRhs());\n     if (lhsElemTy.isBF16() && rhsElemTy.isBF16()) {\n@@ -838,13 +865,13 @@ struct FAddOpConversion\n                     \"   fma.rn.bf16 $0, $1, c, $2; } \\n\";\n       auto &fAdd = *builder.create<PTXInstr>(ptxAsm);\n       auto res = builder.newOperand(\"=h\");\n-      auto lhs = builder.newOperand(operands[0], \"h\");\n-      auto rhs = builder.newOperand(operands[1], \"h\");\n+      auto lhs = builder.newOperand(operands[0][0], \"h\");\n+      auto rhs = builder.newOperand(operands[0][1], \"h\");\n       fAdd({res, lhs, rhs}, /*onlyAttachMLIRArgs=*/true);\n-      return builder.launch(rewriter, loc, i16_ty, false);\n+      return {builder.launch(rewriter, loc, i16_ty, false)};\n     } else {\n-      return rewriter.create<LLVM::FAddOp>(loc, elemTy, operands[0],\n-                                           operands[1]);\n+      return {rewriter.create<LLVM::FAddOp>(loc, elemTy, operands[0][0],\n+                                            operands[0][1])};\n     }\n   }\n };\n@@ -856,9 +883,10 @@ struct FSubOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::SubFOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::arith::SubFOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto lhsElemTy = getElementType(op.getLhs());\n     auto rhsElemTy = getElementType(op.getRhs());\n     if (lhsElemTy.isBF16() && rhsElemTy.isBF16()) {\n@@ -868,33 +896,44 @@ struct FSubOpConversion\n                     \"    fma.rn.bf16 $0, $2, c, $1;} \\n\";\n       auto &fSub = *builder.create<PTXInstr>(ptxAsm);\n       auto res = builder.newOperand(\"=h\");\n-      auto lhs = builder.newOperand(operands[0], \"h\");\n-      auto rhs = builder.newOperand(operands[1], \"h\");\n+      auto lhs = builder.newOperand(operands[0][0], \"h\");\n+      auto rhs = builder.newOperand(operands[0][1], \"h\");\n       fSub({res, lhs, rhs}, /*onlyAttachMLIRArgs=*/true);\n-      return builder.launch(rewriter, loc, i16_ty, false);\n+      return {builder.launch(rewriter, loc, i16_ty, false)};\n     } else {\n-      return rewriter.create<LLVM::FSubOp>(loc, elemTy, operands[0],\n-                                           operands[1]);\n+      return {rewriter.create<LLVM::FSubOp>(loc, elemTy, operands[0][0],\n+                                            operands[0][1])};\n     }\n   }\n };\n \n+// Uses inline ptx to convert s8/u8 to bf16, since the\n struct SIToFPOpConversion\n     : ElementwiseOpConversionBase<mlir::arith::SIToFPOp, SIToFPOpConversion> {\n   using Base =\n       ElementwiseOpConversionBase<mlir::arith::SIToFPOp, SIToFPOpConversion>;\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::SIToFPOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n-    auto outElemTy = getElementType(op.getOut());\n-    if (outElemTy.isBF16()) {\n-      auto value = rewriter.create<LLVM::SIToFPOp>(loc, f32_ty, operands[0]);\n-      return FpToFpOpConversion::convertFp32ToBf16(loc, rewriter, value);\n+  SmallVector<Value> createDestOps(mlir::arith::SIToFPOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n+    Type inElemTy = getElementType(op.getIn());\n+    Type outElemTy = getElementType(op.getOut());\n+    if (outElemTy.isBF16() && inElemTy.isInteger(8) && operands.size() >= 4) {\n+      auto cvtFunc = makeConverterFromPtx(\n+          S8_to_Bf16, getTypeConverter()->convertType(inElemTy),\n+          getTypeConverter()->convertType(outElemTy));\n+      auto outVals = cvtFunc(loc, rewriter, operands[0][0], operands[1][0],\n+                             operands[2][0], operands[3][0]);\n+      assert(outVals.size() == 4);\n+      return outVals;\n+    } else if (outElemTy.isBF16()) {\n+      auto value = rewriter.create<LLVM::SIToFPOp>(loc, f32_ty, operands[0][0]);\n+      return {FpToFpOpConversion::convertFp32ToBf16(loc, rewriter, value)};\n     } else {\n-      return rewriter.create<LLVM::SIToFPOp>(loc, elemTy, operands[0]);\n+      return {rewriter.create<LLVM::SIToFPOp>(loc, elemTy, operands[0][0])};\n     }\n   }\n };\n@@ -906,16 +945,17 @@ struct FPToSIOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::FPToSIOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::arith::FPToSIOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto inElemTy = getElementType(op.getIn());\n     if (inElemTy.isBF16()) {\n       auto value =\n-          FpToFpOpConversion::convertBf16ToFp32(loc, rewriter, operands[0]);\n-      return rewriter.create<LLVM::FPToSIOp>(loc, elemTy, value);\n+          FpToFpOpConversion::convertBf16ToFp32(loc, rewriter, operands[0][0]);\n+      return {rewriter.create<LLVM::FPToSIOp>(loc, elemTy, value)};\n     } else {\n-      return rewriter.create<LLVM::FPToSIOp>(loc, elemTy, operands[0]);\n+      return {rewriter.create<LLVM::FPToSIOp>(loc, elemTy, operands[0][0])};\n     }\n   }\n };\n@@ -927,16 +967,18 @@ struct ExtFOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::ExtFOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::arith::ExtFOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto inElemTy = getElementType(op.getIn());\n     if (inElemTy.isBF16()) {\n       auto outElemTy = getElementType(op.getOut());\n       assert(outElemTy.isF32() && \"unsupported conversion\");\n-      return FpToFpOpConversion::convertBf16ToFp32(loc, rewriter, operands[0]);\n+      return {\n+          FpToFpOpConversion::convertBf16ToFp32(loc, rewriter, operands[0][0])};\n     } else {\n-      return rewriter.create<LLVM::FPExtOp>(loc, elemTy, operands[0]);\n+      return {rewriter.create<LLVM::FPExtOp>(loc, elemTy, operands[0][0])};\n     }\n   }\n };\n@@ -948,16 +990,18 @@ struct TruncFOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::arith::TruncFOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::arith::TruncFOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto outElemTy = getElementType(op.getOut());\n     if (outElemTy.isBF16()) {\n       auto inElemTy = getElementType(op.getIn());\n       assert(inElemTy.isF32() && \"unsupported conversion\");\n-      return FpToFpOpConversion::convertFp32ToBf16(loc, rewriter, operands[0]);\n+      return {\n+          FpToFpOpConversion::convertFp32ToBf16(loc, rewriter, operands[0][0])};\n     } else {\n-      return rewriter.create<LLVM::FPTruncOp>(loc, elemTy, operands[0]);\n+      return {rewriter.create<LLVM::FPTruncOp>(loc, elemTy, operands[0][0])};\n     }\n   }\n };\n@@ -969,22 +1013,23 @@ struct ExpOpConversionApprox\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::math::ExpOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::math::ExpOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     // For non-FP32 input, call __nv_expf for higher-precision calculation\n     if (elemTy.getIntOrFloatBitWidth() != 32)\n       return {};\n \n     const double log2e = 1.4426950408889634;\n-    Value prod = fmul(f32_ty, operands[0], f32_val(log2e));\n+    Value prod = fmul(f32_ty, operands[0][0], f32_val(log2e));\n \n     PTXBuilder ptxBuilder;\n     auto &exp2 = ptxBuilder.create<PTXInstr>(\"ex2\")->o(\"approx\").o(\"f32\");\n     auto output = ptxBuilder.newOperand(\"=f\");\n     auto input = ptxBuilder.newOperand(prod, \"f\");\n     exp2(output, input);\n-    return ptxBuilder.launch(rewriter, loc, f32_ty, false);\n+    return {ptxBuilder.launch(rewriter, loc, f32_ty, false)};\n   }\n };\n \n@@ -995,13 +1040,14 @@ struct AbsIOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::math::AbsIOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::math::AbsIOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto boolFalse = rewriter.getBoolAttr(false);\n     auto constFalse = rewriter.create<LLVM::ConstantOp>(loc, boolFalse);\n-    return rewriter.create<LLVM::AbsOp>(loc, elemTy, operands[0],\n-                                        /*is_int_min_poison=*/constFalse);\n+    return {rewriter.create<LLVM::AbsOp>(loc, elemTy, operands[0][0],\n+                                         /*is_int_min_poison=*/constFalse)};\n   }\n };\n \n@@ -1012,9 +1058,10 @@ struct AbsFOpConversion\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(mlir::math::AbsFOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(mlir::math::AbsFOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     if (llvm::isa<IntegerType>(elemTy)) {\n       // Mask out the sign bit\n       auto num_bits =\n@@ -1023,10 +1070,10 @@ struct AbsFOpConversion\n       auto mask = (1u << (num_bits - 1u)) - 1u;\n       auto maskAttr = rewriter.getIntegerAttr(elemTy, mask);\n       auto maskConst = rewriter.create<LLVM::ConstantOp>(loc, maskAttr);\n-      return and_(operands[0], maskConst);\n+      return {and_(operands[0][0], maskConst)};\n     }\n \n-    return rewriter.create<LLVM::FAbsOp>(loc, elemTy, operands[0]);\n+    return {rewriter.create<LLVM::FAbsOp>(loc, elemTy, operands[0][0])};\n   }\n };\n \n@@ -1042,20 +1089,22 @@ struct IndexCastOpLowering\n   using Base::Base;\n   using Adaptor = typename Base::OpAdaptor;\n \n-  Value createDestOp(arith::IndexCastOp op, OpAdaptor adaptor,\n-                     ConversionPatternRewriter &rewriter, Type elemTy,\n-                     ValueRange operands, Location loc) const {\n+  SmallVector<Value> createDestOps(arith::IndexCastOp op, OpAdaptor adaptor,\n+                                   ConversionPatternRewriter &rewriter,\n+                                   Type elemTy, MultipleOperandsRange operands,\n+                                   Location loc) const {\n     auto inElemTy =\n         this->getTypeConverter()->convertType(getElementType(op.getIn()));\n     unsigned targetBits = elemTy.getIntOrFloatBitWidth();\n     unsigned sourceBits = inElemTy.getIntOrFloatBitWidth();\n \n     if (targetBits == sourceBits)\n-      return operands[0];\n+      return {operands[0][0]};\n     if (targetBits < sourceBits)\n-      return rewriter.replaceOpWithNewOp<LLVM::TruncOp>(op, elemTy,\n-                                                        operands[0]);\n-    return rewriter.replaceOpWithNewOp<LLVM::SExtOp>(op, elemTy, operands[0]);\n+      return {rewriter.replaceOpWithNewOp<LLVM::TruncOp>(op, elemTy,\n+                                                         operands[0][0])};\n+    return {\n+        rewriter.replaceOpWithNewOp<LLVM::SExtOp>(op, elemTy, operands[0][0])};\n   }\n };\n "}, {"filename": "python/test/unit/language/test_core.py", "status": "modified", "additions": 17, "deletions": 13, "changes": 30, "file_content_changes": "@@ -1101,6 +1101,7 @@ def serialized_add(data, Lock, SEM: tl.constexpr):\n     ('bfloat16', 'float32', False),\n     ('float32', 'int32', True),\n     ('float32', 'int1', False),\n+    ('int8', 'bfloat16', False),\n ] + [\n     (f'uint{x}', f'int{x}', True) for x in [8, 16, 32, 64]\n ] + [\n@@ -1111,43 +1112,46 @@ def test_cast(dtype_x, dtype_z, bitcast, device):\n     check_type_supported(dtype_x, device)\n     check_type_supported(dtype_z, device)\n \n+    size = 1024\n     # This is tricky because numpy doesn't have bfloat, and torch doesn't have uints.\n-    x0 = 43 if dtype_x in int_dtypes else 43.5\n-    if dtype_x in float_dtypes and dtype_z == 'int1':\n-        x0 = 0.5\n     if dtype_x.startswith('bfloat'):\n-        x_tri = torch.tensor([x0], dtype=getattr(torch, dtype_x), device=device)\n+        x_tri = torch.randn(size, dtype=getattr(torch, dtype_x), device=device)\n     else:\n-        x = np.array([x0], dtype=getattr(np, dtype_x))\n+        x = numpy_random(size, dtype_str=dtype_x, low=-10, high=10) * 10\n+        # Triton clamps negative values to zero, while numpy wraps around\n+        # intmax, so avoid negatives for now.\n+        # TODO: figure out which one should actually be happening, and test it\n+        if dtype_z in uint_dtypes:\n+          x = np.absolute(x)\n         x_tri = to_triton(x, device=device)\n \n     # triton kernel\n     @triton.jit\n-    def kernel(X, Z, BITCAST: tl.constexpr):\n-        x_ptr = X + tl.arange(0, 1)\n-        z_ptr = Z + tl.arange(0, 1)\n+    def kernel(X, Z, BITCAST: tl.constexpr, SIZE: tl.constexpr):\n+        x_ptr = X + tl.arange(0, SIZE)\n+        z_ptr = Z + tl.arange(0, SIZE)\n         x = tl.load(x_ptr)\n         z = x.to(Z.dtype.element_ty, bitcast=BITCAST)\n         tl.store(z_ptr, z)\n \n     dtype_z_np = dtype_z if dtype_z != 'int1' else 'bool_'\n     # triton result\n     if dtype_z.startswith('bfloat'):\n-        z_tri = torch.empty((1,), dtype=getattr(torch, dtype_z), device=device)\n+        z_tri = torch.empty((size,), dtype=getattr(torch, dtype_z), device=device)\n     else:\n-        z_tri = to_triton(np.empty((1, ), dtype=getattr(np, dtype_z_np)), device=device)\n-    kernel[(1, )](x_tri, z_tri, BITCAST=bitcast)\n+        z_tri = to_triton(np.empty((size, ), dtype=getattr(np, dtype_z_np)), device=device)\n+    kernel[(1, )](x_tri, z_tri, BITCAST=bitcast, SIZE=size, num_warps=1)\n     # torch result\n     if dtype_z.startswith('bfloat') or dtype_x.startswith('bfloat'):\n         assert bitcast is False\n         z_ref = x_tri.to(z_tri.dtype)\n-        assert z_tri == z_ref\n+        torch.testing.assert_close(z_ref, z_tri, rtol=0, atol=0)\n     else:\n         if bitcast:\n             z_ref = x.view(getattr(np, dtype_z_np))\n         else:\n             z_ref = x.astype(getattr(np, dtype_z_np))\n-        assert to_numpy(z_tri) == z_ref\n+        np.testing.assert_allclose(z_ref, to_numpy(z_tri), rtol=0, atol=0)\n \n \n @pytest.mark.parametrize(\"dtype_str, num_warps\", [(dtype_str, num_warps) for dtype_str in int_dtypes + float_dtypes for num_warps in [4, 8]])"}, {"filename": "test/Conversion/tritongpu_to_llvm.mlir", "status": "modified", "additions": 30, "deletions": 0, "changes": 30, "file_content_changes": "@@ -1223,3 +1223,33 @@ module attributes {\"triton_gpu.num-warps\" = 4 : i32, \"triton_gpu.threads-per-war\n     tt.return\n   }\n }\n+\n+// -----\n+#blocked = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [1], order = [0]}>\n+module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n+  // CHECK-LABEL: test_s8_to_bf16_conversion\n+  tt.func @test_s8_to_bf16_conversion(%in: tensor<32xi8, #blocked>) {\n+    // We can't vectorize if we only process\n+    // CHECK-NOT: llvm.inline_asm\n+    // CHECK: llvm.sitofp\n+    // CHECK-NOT: llvm.sitofp\n+    %out = arith.sitofp %in : tensor<32xi8, #blocked> to tensor<32xbf16, #blocked>\n+    tt.return\n+  }\n+}\n+\n+// -----\n+#mma = #triton_gpu.mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [1, 1]}>\n+#dot = #triton_gpu.dot_op<{opIdx = 0, parent = #mma, kWidth = 4}>\n+module attributes {\"triton_gpu.num-warps\" = 1 : i32} {\n+  // CHECK-LABEL: test_s8_to_bf16_vectorized_conversion\n+  tt.func @test_s8_to_bf16_vectorized_conversion(%in: tensor<16x16xi8, #mma>) {\n+    // CHECK-NOT: llvm.sitofp\n+    // 8 elements per thread => we should process 2 vectors of 4\n+    // CHECK: llvm.inline_asm\n+    // CHECK: llvm.inline_asm\n+    // CHECK-NOT: llvm.inline_asm\n+    %out = arith.sitofp %in : tensor<16x16xi8, #mma> to tensor<16x16xbf16, #mma>\n+    tt.return\n+  }\n+}"}]