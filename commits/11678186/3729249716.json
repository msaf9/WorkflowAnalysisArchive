[{"filename": "lib/Dialect/TritonGPU/Transforms/Combine.cpp", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "file_content_changes": "@@ -90,9 +90,12 @@ class SimplifyReduceCvt : public mlir::RewritePattern {\n                   mlir::PatternRewriter &rewriter) const override {\n     auto reduce = cast<triton::ReduceOp>(*op);\n     auto reduceArg = dyn_cast<triton::gpu::ConvertLayoutOp>(reduce.getOperand().getDefiningOp());\n-\n     if(!reduceArg)\n       return mlir::failure();\n+    // this may generate unsupported conversions in the LLVM codegen\n+    if(reduceArg.getOperand().getType().cast<RankedTensorType>()\n+                .getEncoding().isa<triton::gpu::MmaEncodingAttr>())\n+      return mlir::failure();\n     auto newReduce = rewriter.create<triton::ReduceOp>(\n         op->getLoc(), reduce.redOp(), reduceArg.getOperand(), reduce.axis());\n     if(isa<triton::gpu::ConvertLayoutOp>(*reduceArg.getOperand().getDefiningOp()))\n@@ -1208,7 +1211,7 @@ class TritonGPUCombineOpsPass\n     patterns.add<OptimizeConvertToDotOperand>(context);\n     patterns.add<SimplifyConversion>(context);\n     patterns.add<SimplifyReduceCvt>(context);\n-    // patterns.add<FoldConvertAndReduce>(context);\n+    patterns.add<FoldConvertAndReduce>(context);\n     patterns.add<DecomposeDotOperand>(context);\n     patterns.add<RematerializeBackward>(context);\n     patterns.add<RematerializeForward>(context);\n@@ -1225,6 +1228,7 @@ class TritonGPUCombineOpsPass\n     if (applyPatternsAndFoldGreedily(m, std::move(loopFixup)).failed()) {\n       signalPassFailure();\n     }\n+\n   }\n };\n "}]