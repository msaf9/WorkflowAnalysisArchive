[{"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -576,8 +576,8 @@ struct ConvertLayoutOpConversion\n     unsigned inVec = 0;\n     unsigned outVec = 0;\n     auto paddedRepShape = getScratchConfigForCvtLayout(op, inVec, outVec);\n-    if (getElementTypeOrSelf(op.getType()).isa<mlir::Float8E4M3B11FNUZType>() ||\n-        getElementTypeOrSelf(op.getType()).isa<mlir::Float8E4M3FNType>()) {\n+    if (getElementTypeOrSelf(op.getType())\n+            .isa<mlir::Float8E4M3B11FNUZType, mlir::Float8E4M3FNType>()) {\n       assert(inVec % 4 == 0 && \"conversion not supported for FP8E4M3B15\");\n       assert(outVec % 4 == 0 && \"conversion not supported for FP8E4M3B15\");\n     }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/ConvertLayoutOpToLLVM/SharedToDotOperandMMAv2.cpp", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "file_content_changes": "@@ -503,11 +503,7 @@ std::function<void(int, int)> getLoadMatrixFn(\n   if (tensor.getType()\n           .cast<RankedTensorType>()\n           .getElementType()\n-          .isa<mlir::Float8E4M3B11FNUZType>() ||\n-      tensor.getType()\n-          .cast<RankedTensorType>()\n-          .getElementType()\n-          .isa<mlir::Float8E4M3FNType>()) {\n+          .isa<mlir::Float8E4M3B11FNUZType, mlir::Float8E4M3FNType>()) {\n     bool noTrans = (isA ^ (order[0] == 0));\n     assert(noTrans && \"float8e4b15 must have row-col layout\");\n   }"}, {"filename": "lib/Conversion/TritonGPUToLLVM/TritonGPUToLLVMPass.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "file_content_changes": "@@ -610,8 +610,8 @@ class ConvertTritonGPUToLLVM\n   void decomposeFp8e4b15Convert(ModuleOp mod) const {\n     mod.walk([&](triton::gpu::ConvertLayoutOp cvtOp) -> void {\n       OpBuilder builder(cvtOp);\n-      if (!getElementTypeOrSelf(cvtOp).isa<mlir::Float8E4M3B11FNUZType>() &&\n-          !getElementTypeOrSelf(cvtOp).isa<mlir::Float8E4M3FNType>())\n+      if (!getElementTypeOrSelf(cvtOp)\n+               .isa<mlir::Float8E4M3B11FNUZType, mlir::Float8E4M3FNType>())\n         return;\n       auto shape = cvtOp.getType().cast<RankedTensorType>().getShape();\n       auto argEncoding ="}]