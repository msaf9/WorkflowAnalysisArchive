[{"filename": "include/triton/Dialect/Triton/IR/TritonOps.td", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "file_content_changes": "@@ -498,6 +498,8 @@ def TT_MakeRangeOp : TT_Op<\"make_range\", [Pure]> {\n     let results = (outs TT_IntTensor:$result);\n \n     let assemblyFormat = \"attr-dict `:` type($result)\";\n+\n+    let hasFolder = 1;\n }\n \n //"}, {"filename": "lib/Dialect/Triton/IR/Ops.cpp", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "file_content_changes": "@@ -428,6 +428,16 @@ LogicalResult mlir::triton::DotOp::verify() {\n                                                      bEncoding);\n }\n \n+//-- MakeRangeOp --\n+OpFoldResult MakeRangeOp::fold(FoldAdaptor adaptor) {\n+  // make_range(start, start + 1) -> constant(start)\n+  if (adaptor.getStart() + 1 == adaptor.getEnd()) {\n+    auto shapedType = getType().cast<ShapedType>();\n+    return SplatElementsAttr::get(shapedType, adaptor.getStartAttr());\n+  }\n+  return {};\n+}\n+\n //-- ReduceOp --\n static mlir::LogicalResult\n inferReduceReturnShape(const RankedTensorType &argTy, const Type &retEltTy,"}, {"filename": "test/Triton/canonicalize.mlir", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "file_content_changes": "@@ -10,3 +10,18 @@ tt.func @dead_load(%ptr: tensor<32x128x!tt.ptr<f16>>) {\n   %b = tt.load %ptr, %mask, %other {cache = 1 : i32, evict = 1 : i32, isVolatile = true} : tensor<32x128xf16>\n   tt.return\n }\n+\n+\n+// CHECK-LABEL: make_range\n+tt.func @make_range() -> (tensor<128x1xi32>, tensor<1xi32>) {\n+  // CHECK-DAG: %[[c:.*]] = arith.constant dense<0> : tensor<128x1xi32>\n+  %a = tt.make_range {end = 1 : i32, start = 0 : i32} : tensor<1xi32>\n+  %b = tt.expand_dims %a {axis = 1 : i32} : (tensor<1xi32>) -> tensor<1x1xi32>\n+  %c = tt.broadcast %b : (tensor<1x1xi32>) -> tensor<128x1xi32>\n+\n+  // CHECK-DAG: %[[d:.*]] = arith.constant dense<1> : tensor<1xi32>\n+  %d = tt.make_range {end = 2 : i32, start = 1 : i32} : tensor<1xi32>\n+\n+  // CHECK-DAG: tt.return %[[c]], %[[d]] : tensor<128x1xi32>, tensor<1xi32>\n+  tt.return %c, %d : tensor<128x1xi32>, tensor<1xi32>\n+}"}]