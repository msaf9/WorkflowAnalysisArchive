[{"filename": "lib/Dialect/TritonGPU/Transforms/RemoveLayoutConversions.cpp", "status": "modified", "additions": 27, "deletions": 9, "changes": 36, "file_content_changes": "@@ -177,6 +177,7 @@ class LayoutPropagation {\n   Operation *rewriteForOp(scf::ForOp forOp);\n   Operation *rewriteIfOp(scf::IfOp ifOp);\n   Operation *rewriteYieldOp(scf::YieldOp yieldOp);\n+  Operation *rewriteReduceToScalar(Operation *reduceOp);\n   Operation *cloneElementwise(OpBuilder &rewriter, Operation *op,\n                               Attribute encoding);\n   // Map the original value to the rewritten one.\n@@ -366,14 +367,11 @@ void LayoutPropagation::dump() {\n \n void LayoutPropagation::rewrite() { rewriteRegion(funcOp->getRegion(0)); }\n \n-static bool allowChangingSrcEncoding(Operation *op) {\n+static bool reduceToScalar(Operation *op) {\n   // For reductions returning a scalar we can change the src encoding without\n   // affecting the output.\n-  if (isa<triton::ReduceOp>(op) &&\n-      !op->getResultTypes()[0].isa<RankedTensorType>() &&\n-      op->getNumOperands() == 1)\n-    return true;\n-  return false;\n+  return isa<triton::ReduceOp>(op) &&\n+         !op->getResultTypes()[0].isa<RankedTensorType>();\n }\n \n void LayoutPropagation::rewriteRegion(Region &region) {\n@@ -404,8 +402,9 @@ void LayoutPropagation::rewriteRegion(Region &region) {\n           queue.push_back(&R);\n       } else if (auto yieldOp = dyn_cast<scf::YieldOp>(&op)) {\n         rewriteYieldOp(yieldOp);\n+      } else if (reduceToScalar(&op)) {\n+        rewriteReduceToScalar(&op);\n       } else {\n-        bool canChangeSrcEncoding = allowChangingSrcEncoding(&op);\n         // If we don't need to rewrite the op we still need to remap the\n         // operands.\n         for (OpOperand &operand : op.getOpOperands()) {\n@@ -414,8 +413,6 @@ void LayoutPropagation::rewriteRegion(Region &region) {\n             continue;\n           Attribute encoding =\n               operand.get().getType().cast<RankedTensorType>().getEncoding();\n-          if (canChangeSrcEncoding)\n-            encoding = it->second.encodings[0];\n           Value newOperand = getValueAs(operand.get(), encoding);\n           op.setOperand(operand.getOperandNumber(), newOperand);\n         }\n@@ -568,6 +565,27 @@ Operation *LayoutPropagation::rewriteYieldOp(scf::YieldOp yieldOp) {\n   return newYield;\n }\n \n+Operation *LayoutPropagation::rewriteReduceToScalar(Operation *reduceOp) {\n+  OpBuilder rewriter(reduceOp);\n+  Attribute srcEncoding;\n+  // Since all the operands need to have the same encoding pick the first one\n+  // and use it for all the operands.\n+  for (Value operand : reduceOp->getOperands()) {\n+    auto it = layouts.find(operand);\n+    if (it != layouts.end()) {\n+      srcEncoding = it->second.encodings[0];\n+      break;\n+    }\n+  }\n+  if (!srcEncoding)\n+    return reduceOp;\n+  for (OpOperand &operand : reduceOp->getOpOperands()) {\n+    Value newOperand = getValueAs(operand.get(), srcEncoding);\n+    reduceOp->setOperand(operand.getOperandNumber(), newOperand);\n+  }\n+  return reduceOp;\n+}\n+\n Operation *LayoutPropagation::rewriteOp(Operation *op) {\n   opToDelete.push_back(op);\n   if (auto forOp = dyn_cast<scf::ForOp>(op))"}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "file_content_changes": "@@ -1776,3 +1776,30 @@ tt.func @axis_mismatch(%arg0: f32) -> tensor<1xf32, #triton_gpu.slice<{dim = 0,\n   %3 = triton_gpu.convert_layout %2 : (tensor<1xf32, #blocked1>) -> tensor<1xf32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>\n   tt.return %3: tensor<1xf32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>\n }\n+\n+// -----\n+\n+#blocked = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [4], order = [0], CTAsPerCGA = [1], CTASplitNum = [1], CTAOrder = [0]}>\n+#blocked1 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0], CTAsPerCGA = [1], CTASplitNum = [1], CTAOrder = [0]}>\n+module attributes {\"triton_gpu.num-warps\" = 4 : i32} {\n+// CHECK-LABEL: reduce_to_scalar\n+//   CHECK-NOT:   triton_gpu.convert_layout\n+//       CHECK:   tt.return\n+tt.func @reduce_to_scalar(%ptr: tensor<1024x!tt.ptr<f32>, #blocked>) -> (f32, i32) {\n+  %0 = tt.load %ptr {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<1024xf32, #blocked>\n+  %1 = triton_gpu.convert_layout %0 : (tensor<1024xf32, #blocked>) -> tensor<1024xf32, #blocked1>\n+  %2 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32, #blocked1>\n+  %3:2 = \"tt.reduce\"(%1, %2) <{axis = 0 : i32}> ({\n+    ^bb0(%arg7: f32, %arg8: i32, %arg9: f32, %arg10: i32):\n+    %51 = \"triton_gpu.cmpf\"(%arg7, %arg9) <{predicate = 1 : i64}> : (f32, f32) -> i1\n+    %52 = \"triton_gpu.cmpi\"(%arg8, %arg10) <{predicate = 2 : i64}> : (i32, i32) -> i1\n+    %53 = arith.andi %51, %52 : i1\n+    %54 = \"triton_gpu.cmpf\"(%arg7, %arg9) <{predicate = 2 : i64}> : (f32, f32) -> i1\n+    %55 = arith.ori %54, %53 : i1\n+    %56 = arith.select %55, %arg7, %arg9 : f32\n+    %57 = arith.select %55, %arg8, %arg10 : i32\n+    tt.reduce.return %56, %57 : f32, i32\n+  }) : (tensor<1024xf32, #blocked1>, tensor<1024xi32, #blocked1>) -> (f32, i32)\n+  tt.return %3#0, %3#1: f32, i32\n+}\n+}"}]