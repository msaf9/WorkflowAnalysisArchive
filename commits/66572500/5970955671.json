[{"filename": "README.md", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -35,6 +35,7 @@ Tentative Agenda for the conference (subject to change):\n |3:40 PM|Writing Grouped GEMMs in Triton|Vinod Grover (Nvidia)|\n |4:00 PM|**Reception**||\n \n+\n # Triton\n \n This is the development repository of Triton, a language and compiler for writing highly efficient custom Deep-Learning primitives. The aim of Triton is to provide an open-source environment to write fast code at higher productivity than CUDA, but also with higher flexibility than other existing DSLs."}, {"filename": "lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp", "status": "modified", "additions": 34, "deletions": 0, "changes": 34, "file_content_changes": "@@ -102,6 +102,8 @@ warpsPerTileV3(tt::DotOp dotOp, const ArrayRef<int64_t> shape, int numWarps,\n class BlockedToMMA : public mlir::RewritePattern {\n   int computeCapability;\n   mutable int mmaV1Counter{}; // used to generate ID for MMAv1 encoding\n+  mutable llvm::SmallVector<llvm::SetVector<Operation *>> dotOpSetVector;\n+  mutable llvm::SmallVector<unsigned> mmaV3InstrNs;\n \n   static bool bwdFilter(Operation *op) {\n     return op->getNumOperands() == 1 &&\n@@ -144,6 +146,36 @@ class BlockedToMMA : public mlir::RewritePattern {\n     }\n   }\n \n+  unsigned getMmaV3InstrN(tt::DotOp dotOp, unsigned currN) const {\n+    auto type = dotOp.getResult().getType().cast<RankedTensorType>();\n+    if (type.getEncoding().isa<MmaEncodingAttr>())\n+      return currN;\n+    for (size_t i = 0; i < dotOpSetVector.size(); ++i) {\n+      if (dotOpSetVector[i].count(dotOp.getOperation()) > 0)\n+        return mmaV3InstrNs[i];\n+    }\n+\n+    SetVector<Operation *> slices;\n+    mlir::getForwardSlice(dotOp.getResult(), &slices);\n+    mlir::getBackwardSlice(dotOp.getOperation(), &slices);\n+    unsigned N = currN;\n+    llvm::SetVector<Operation *> dotOpSet;\n+    for (Operation *iter : slices) {\n+      if (auto nextDotOp = dyn_cast<tt::DotOp>(iter)) {\n+        auto type = nextDotOp.getResult().getType().cast<RankedTensorType>();\n+        auto AType = nextDotOp.getOperand(0).getType().cast<RankedTensorType>();\n+        auto shapePerCTA = ttg::getShapePerCTA(type);\n+        auto instrShape = mmaVersionToInstrShape(3, shapePerCTA, AType);\n+        dotOpSet.insert(iter);\n+        if (instrShape[1] < N)\n+          N = instrShape[1];\n+      }\n+    }\n+    mmaV3InstrNs.push_back(N);\n+    dotOpSetVector.push_back(dotOpSet);\n+    return N;\n+  }\n+\n   static Value getMMAv3Operand(Value v, mlir::PatternRewriter &rewriter,\n                                int opIdx) {\n     auto cvtOp = dyn_cast_or_null<ttg::ConvertLayoutOp>(v.getDefiningOp());\n@@ -201,6 +233,8 @@ class BlockedToMMA : public mlir::RewritePattern {\n \n     auto instrShape =\n         mmaVersionToInstrShape(versionMajor, retShapePerCTA, AType);\n+    if (versionMajor == 3)\n+      instrShape[1] = getMmaV3InstrN(dotOp, instrShape[1]);\n \n     // operands\n     Value a = dotOp.getA();"}]