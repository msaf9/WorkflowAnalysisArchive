[{"filename": "lib/Dialect/TritonGPU/Transforms/Utility.cpp", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "file_content_changes": "@@ -251,7 +251,8 @@ static std::optional<Attribute> inferDstEncoding(triton::ExpandDimsOp op,\n   auto sliceEncoding = encoding.dyn_cast<triton::gpu::SliceEncodingAttr>();\n   if (!sliceEncoding)\n     return std::nullopt;\n-  assert(op.getAxis() == sliceEncoding.getDim());\n+  if (op.getAxis() != sliceEncoding.getDim())\n+    return std::nullopt;\n   return sliceEncoding.getParent();\n }\n \n@@ -260,7 +261,8 @@ static std::optional<Attribute> inferSrcEncoding(triton::ReduceOp op,\n   auto sliceEncoding = encoding.dyn_cast<triton::gpu::SliceEncodingAttr>();\n   if (!sliceEncoding)\n     return std::nullopt;\n-  assert(op.getAxis() == sliceEncoding.getDim());\n+  if (op.getAxis() != sliceEncoding.getDim())\n+    return std::nullopt;\n   return sliceEncoding.getParent();\n }\n "}, {"filename": "test/TritonGPU/combine.mlir", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "file_content_changes": "@@ -1740,3 +1740,23 @@ module attributes {\"triton_gpu.compute-capability\" = 90 : i32, \"triton_gpu.num-c\n     tt.return\n   }\n }\n+\n+// -----\n+\n+#blocked = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1], CTAsPerCGA = [1, 1], CTASplitNum = [1, 1], CTAOrder = [0, 1]}>\n+#blocked1 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0], CTAsPerCGA = [1], CTASplitNum = [1], CTAOrder = [0]}>\n+// CHECK-LABEL: axis_mismatch\n+tt.func @axis_mismatch(%arg0: f32) -> tensor<1xf32, #triton_gpu.slice<{dim = 0, parent = #blocked}>> {\n+// CHECK: %[[R:.+]] = \"tt.reduce\"(%0) <{axis = 1 : i32}>\n+// CHECK: %[[C:.+]] = triton_gpu.convert_layout %[[R]]\n+// CHECK: tt.return %[[C]]\n+  %0 = tt.splat %arg0 : (f32) -> tensor<1x16xf32, #blocked>\n+  %1 = \"tt.reduce\"(%0) <{axis = 1 : i32}> ({\n+    ^bb0(%arg9: f32, %arg10: f32):\n+    %60 = arith.addf %arg9, %arg10 : f32\n+    tt.reduce.return %60 : f32\n+  }) : (tensor<1x16xf32, #blocked>) -> tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>\n+  %2 = triton_gpu.convert_layout %1 : (tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked}>>) -> tensor<1xf32, #blocked1>\n+  %3 = triton_gpu.convert_layout %2 : (tensor<1xf32, #blocked1>) -> tensor<1xf32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>\n+  tt.return %3: tensor<1xf32, #triton_gpu.slice<{dim = 0, parent = #blocked}>>\n+}"}]