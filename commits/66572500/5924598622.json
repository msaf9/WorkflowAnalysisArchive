[{"filename": "lib/Dialect/TritonNvidiaGPU/Transforms/WSPipeline.cpp", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "file_content_changes": "@@ -173,6 +173,10 @@ scf::ForOp appendPipelineIdxToLoopArgs(scf::ForOp forOp, int numStages,\n     initValue = parentForOp.getBody()->getArguments().back();\n     Value numSteps = builder.createWithAgentIds<arith::SubIOp>(\n         loc, forOp.getUpperBound(), forOp.getLowerBound());\n+    auto one = builder.createWithAgentIds<arith::ConstantIntOp>(loc, 1, 32);\n+    numSteps = builder.createWithAgentIds<arith::AddIOp>(loc, numSteps,\n+                                                         forOp.getStep());\n+    numSteps = builder.createWithAgentIds<arith::SubIOp>(loc, numSteps, one);\n     numSteps = builder.createWithAgentIds<arith::DivUIOp>(loc, numSteps,\n                                                           forOp.getStep());\n     initValue ="}, {"filename": "python/test/unit/hopper/test_persistent_warp_specialized_gemm.py", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "file_content_changes": "@@ -701,6 +701,7 @@ def full_static_persistent_matmul_kernel(\n                                  # bad from cublas-important-layers\n                                  [4096, 1, 1024, False, False],\n                                  [2048, 204, 1000, True, False],\n+                                 [16, 524288, 32, False, True],\n                              ]\n                              for out_dtype in ['float16', 'float32']\n                              for use_tma_store in [False, True]"}]