[{"filename": "docs/conf.py", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "file_content_changes": "@@ -105,7 +105,8 @@ def documenter(app, obj, parent):\n     'within_subsection_order': FileNameSortKey,\n     'reference_url': {\n         'sphinx_gallery': None,\n-    }\n+    },\n+    'abort_on_example_error': True,\n }\n \n # Add any paths that contain templates here, relative to this directory.\n@@ -144,7 +145,7 @@ def documenter(app, obj, parent):\n #\n # This is also used if you do content translation via gettext catalogs.\n # Usually you set \"language\" from the command line for these cases.\n-language = None\n+language = 'en'\n \n # List of patterns, relative to source directory, that match files and\n # directories to ignore when looking for source files."}, {"filename": "python/tutorials/09-experimental-tma-matrix-multiplication.py", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "file_content_changes": "@@ -32,6 +32,11 @@\n import triton\n import triton.language as tl\n \n+if torch.cuda.get_device_capability()[0] < 9:\n+    import sys\n+    print(\"Skipping TMA benchmark for GPU with compute capability < 9\")\n+    sys.exit(0)\n+\n \n @triton.autotune(\n     configs=[\n@@ -191,10 +196,5 @@ def perf(ms):\n     return perf(ms), perf(max_ms), perf(min_ms)\n \n \n-if torch.cuda.get_device_capability()[0] < 9:\n-    import sys\n-    print(\"Skipping TMA benchmark for GPU with compute capability < 9\")\n-    sys.exit(0)\n-\n test_matmul()\n benchmark.run(show_plots=False, print_data=True)"}, {"filename": "python/tutorials/10-experimental-tma-store-matrix-multiplication.py", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "file_content_changes": "@@ -32,6 +32,11 @@\n import triton\n import triton.language as tl\n \n+if torch.cuda.get_device_capability()[0] < 9:\n+    import sys\n+    print(\"Skipping TMA benchmark for GPU with compute capability < 9\")\n+    sys.exit(0)\n+\n \n @triton.autotune(\n     configs=[\n@@ -171,9 +176,4 @@ def perf(ms):\n     return perf(ms), perf(max_ms), perf(min_ms)\n \n \n-if torch.cuda.get_device_capability()[0] < 9:\n-    import sys\n-    print(\"Skipping TMA benchmark for GPU with compute capability < 9\")\n-    sys.exit(0)\n-\n benchmark.run(show_plots=False, print_data=True)"}]