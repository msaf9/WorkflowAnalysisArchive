[{"filename": ".github/workflows/torchinductor/scripts/check_perf.py", "status": "modified", "additions": 11, "deletions": 10, "changes": 21, "file_content_changes": "@@ -4,43 +4,44 @@\n \n # Create a named tuple for the output of the benchmark\n BenchmarkOutput = namedtuple(\n-    'BenchmarkOutput', ['dev', 'name', 'batch_size', 'speedup'])\n+    'BenchmarkOutput', ['dev', 'name', 'batch_size', 'speedup', 'latency'])\n \n \n def parse_output(file_path: str) -> dict:\n     entries = {}\n     with open(file_path) as f:\n         reader = csv.reader(f)\n         for i, row in enumerate(reader):\n-            if i == 0:\n+            if i == 0 or len(row) < 5:\n                 continue\n             dev = row[0]\n             name = row[1]\n             batch_size = row[2]\n             speedup = float(row[3])\n-            entries[name] = BenchmarkOutput(dev, name, batch_size, speedup)\n+            latency = float(row[4])\n+            entries[name] = BenchmarkOutput(dev, name, batch_size, speedup, latency)\n     return entries\n \n \n def compare(baseline: dict, new: dict, threshold: float) -> bool:\n     for key in new:\n         if key not in baseline:\n             print(f\"New benchmark {key} not found in baseline\")\n-        baseline_speedup = baseline[key].speedup\n-        new_speedup = new[key].speedup\n-        if new_speedup < baseline_speedup * (1 - threshold):\n+        baseline_latency = baseline[key].latency\n+        new_latency = new[key].latency\n+        if new_latency < baseline_latency * (1 - threshold):\n             print(\n-                f\"New benchmark {key} is slower than baseline: {new_speedup} vs {baseline_speedup}\")\n-        elif new_speedup > baseline_speedup * (1 + threshold):\n+                f\"New benchmark {key} is slower than baseline: {new_latency} vs {baseline_latency}\")\n+        elif new_latency > baseline_latency * (1 + threshold):\n             print(\n-                f\"New benchmark {key} is faster than baseline: {new_speedup} vs {baseline_speedup}\")\n+                f\"New benchmark {key} is faster than baseline: {new_latency} vs {baseline_latency}\")\n \n \n def main():\n     parser = argparse.ArgumentParser()\n     parser.add_argument('--baseline', required=True)\n     parser.add_argument('--new', required=True)\n-    parser.add_argument('--threshold', type=float, default=0.02)\n+    parser.add_argument('--threshold', type=float, default=0.05)\n     args = parser.parse_args()\n     baseline = parse_output(args.baseline)\n     new = parse_output(args.new)"}]